{"textgrid.poem.49137": {"metadata": {"author": {"name": "R\u00f6ling, Johann", "birth": "N.A.", "death": "N.A."}, "title": "Von der Himmelfahrt Jesu Christi", "genre": "verse", "period": "N.A.", "pub_year": 1656, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gnug, o Jesu, gnug gestritten,", "tokens": ["Gnug", ",", "o", "Je\u00b7su", ",", "gnug", "ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "NE", "$,", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gnug ertragen und gelitten,", "tokens": ["Gnug", "er\u00b7tra\u00b7gen", "und", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gnug gedienet, theurer Held;", "tokens": ["Gnug", "ge\u00b7die\u00b7net", ",", "theu\u00b7rer", "Held", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kehr' in deine Wohnung wieder,", "tokens": ["Kehr'", "in", "dei\u00b7ne", "Woh\u00b7nung", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Setz auff deinen Stuhl dich nieder", "tokens": ["Setz", "auff", "dei\u00b7nen", "Stuhl", "dich", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN", "PPER", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und regier wie vor die Welt.", "tokens": ["Und", "re\u00b7gier", "wie", "vor", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Tod-Besieger, H\u00f6llen-Zwinger,", "tokens": ["To\u00b7dBe\u00b7sie\u00b7ger", ",", "H\u00f6l\u00b7len\u00b7Zwin\u00b7ger", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00fcnden-B\u00fc\u00dfer, Friedens-Bringer,", "tokens": ["S\u00fcn\u00b7den\u00b7B\u00fc\u00b7\u00dfer", ",", "Frie\u00b7dens\u00b7Brin\u00b7ger", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fahre heim, wir folgen dir.", "tokens": ["Fah\u00b7re", "heim", ",", "wir", "fol\u00b7gen", "dir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht betr\u00fcbet uns dein Scheiden,", "tokens": ["Nicht", "be\u00b7tr\u00fc\u00b7bet", "uns", "dein", "Schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn du gehst zu deinen Freuden", "tokens": ["Denn", "du", "gehst", "zu", "dei\u00b7nen", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und nur eine Weile f\u00fcr.", "tokens": ["Und", "nur", "ei\u00b7ne", "Wei\u00b7le", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "War dein Hau\u00df doch, Herr, verschlo\u00dfen,", "tokens": ["War", "dein", "Hau\u00df", "doch", ",", "Herr", ",", "ver\u00b7schlo\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "$,", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seit wir jenes Baums geno\u00dfen,", "tokens": ["Seit", "wir", "je\u00b7nes", "Baums", "ge\u00b7no\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und gantz w\u00fcst dahin die Bahn,", "tokens": ["Und", "gantz", "w\u00fcst", "da\u00b7hin", "die", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PAV", "ART", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Du wirst, Liebster, Weg und Th\u00fcre,", "tokens": ["Du", "wirst", ",", "Liebs\u00b7ter", ",", "Weg", "und", "Th\u00fc\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und da\u00df uns hie Nichts verf\u00fchre,", "tokens": ["Und", "da\u00df", "uns", "hie", "Nichts", "ver\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fchrt dein Geist uns selber an.", "tokens": ["F\u00fchrt", "dein", "Geist", "uns", "sel\u00b7ber", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Menschen-Retter, Lebens-Geber,", "tokens": ["Men\u00b7schen\u00b7Ret\u00b7ter", ",", "Le\u00b7bens\u00b7Ge\u00b7ber", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "O, Durchbrecher unsrer Gr\u00e4ber", "tokens": ["O", ",", "Durch\u00b7bre\u00b7cher", "uns\u00b7rer", "Gr\u00e4\u00b7ber"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und des Himmels minder nicht,", "tokens": ["Und", "des", "Him\u00b7mels", "min\u00b7der", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fahre heim, fahr heim gesegnet,", "tokens": ["Fah\u00b7re", "heim", ",", "fahr", "heim", "ge\u00b7seg\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schau, was dir f\u00fcr Lob begegnet", "tokens": ["Schau", ",", "was", "dir", "f\u00fcr", "Lob", "be\u00b7geg\u00b7net"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWS", "PPER", "APPR", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da du deinen Zug verricht.", "tokens": ["Da", "du", "dei\u00b7nen", "Zug", "ver\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Tausend Diener gehn zur Seiten,", "tokens": ["Tau\u00b7send", "Die\u00b7ner", "gehn", "zur", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tausend Wagen, Herr, begleiten", "tokens": ["Tau\u00b7send", "Wa\u00b7gen", ",", "Herr", ",", "be\u00b7glei\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["CARD", "NN", "$,", "NN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deinen Einzug vor und nach;", "tokens": ["Dei\u00b7nen", "Ein\u00b7zug", "vor", "und", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "KON", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Helden-Lorbeers, Sieges-Palmen,", "tokens": ["Hel\u00b7den\u00b7Lor\u00b7beers", ",", "Sie\u00b7ges\u00b7Pal\u00b7men", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gnaden-\u00d6lzweig, Freuden-Psalmen", "tokens": ["Gna\u00b7den\u00b7\u00d6l\u00b7zweig", ",", "Freu\u00b7den\u00b7P\u00b7sal\u00b7men"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist ganz voll das Stern-Gemach.", "tokens": ["Ist", "ganz", "voll", "das", "Stern\u00b7Ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "So gehst du zu deinem Throne", "tokens": ["So", "gehst", "du", "zu", "dei\u00b7nem", "Thro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nimmst den Zepter und die Krone", "tokens": ["Nimmst", "den", "Zep\u00b7ter", "und", "die", "Kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner ewgen Majest\u00e4t,", "tokens": ["Dei\u00b7ner", "ew\u00b7gen", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hebst dich an des Vaters Rechte,", "tokens": ["Hebst", "dich", "an", "des", "Va\u00b7ters", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo die Schaar der reinen Knechte", "tokens": ["Wo", "die", "Schaar", "der", "rei\u00b7nen", "Knech\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Um dich fr\u00f6lich steht und geht.", "tokens": ["Um", "dich", "fr\u00f6\u00b7lich", "steht", "und", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Fahre, Jesu, fahre heime,", "tokens": ["Fah\u00b7re", ",", "Je\u00b7su", ",", "fah\u00b7re", "hei\u00b7me", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "$,", "VVFIN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fahr', es folgen meine Reime", "tokens": ["Fahr'", ",", "es", "fol\u00b7gen", "mei\u00b7ne", "Rei\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ich selbst zu seiner Zeit;", "tokens": ["Und", "ich", "selbst", "zu", "sei\u00b7ner", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich, dein Glied, mu\u00df hingelangen,", "tokens": ["Ich", ",", "dein", "Glied", ",", "mu\u00df", "hin\u00b7ge\u00b7lan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo mein Haupt ist hingegangen,", "tokens": ["Wo", "mein", "Haupt", "ist", "hin\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dies nennst selbst du Billigkeit.", "tokens": ["Dies", "nennst", "selbst", "du", "Bil\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Wo der Schatz, da ist das Hertze,", "tokens": ["Wo", "der", "Schatz", ",", "da", "ist", "das", "Hert\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ADV", "VAFIN", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So lehrst du, der Lehrer Kertze;", "tokens": ["So", "lehrst", "du", ",", "der", "Leh\u00b7rer", "Kert\u00b7ze", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ART", "NN", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ach, mein einger Schatz allhier,", "tokens": ["Ach", ",", "mein", "ein\u00b7ger", "Schatz", "all\u00b7hier", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine H\u00fclle, F\u00fcll' und Gabe", "tokens": ["Mei\u00b7ne", "H\u00fcl\u00b7le", ",", "F\u00fcll'", "und", "Ga\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bist nur du, Herr, die ich habe,", "tokens": ["Bist", "nur", "du", ",", "Herr", ",", "die", "ich", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "$,", "NN", "$,", "PRELS", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So mu\u00df ich auch seyn bey dir.", "tokens": ["So", "mu\u00df", "ich", "auch", "seyn", "bey", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPOSAT", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Ja, ich h\u00e4ng' an dir, dir Einem,", "tokens": ["Ja", ",", "ich", "h\u00e4ng'", "an", "dir", ",", "dir", "Ei\u00b7nem", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "APPR", "PPER", "$,", "PPER", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dir, mein Heyl, und sonsten Keinem,", "tokens": ["Dir", ",", "mein", "Heyl", ",", "und", "sons\u00b7ten", "Kei\u00b7nem", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, ich bin, ich bin bey dir,", "tokens": ["Ja", ",", "ich", "bin", ",", "ich", "bin", "bey", "dir", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Du bist, dem ich gantz mich gebe,", "tokens": ["Du", "bist", ",", "dem", "ich", "gantz", "mich", "ge\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ich hie noch bin und lebe,", "tokens": ["Was", "ich", "hie", "noch", "bin", "und", "le\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VAFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist mein Schatten nur von mir.", "tokens": ["Ist", "mein", "Schat\u00b7ten", "nur", "von", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ach, ich koste schon mit Freuden,", "tokens": ["Ach", ",", "ich", "kos\u00b7te", "schon", "mit", "Freu\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie du k\u00fcnfftig mich wirst weiden,", "tokens": ["Wie", "du", "k\u00fcnff\u00b7tig", "mich", "wirst", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "PPER", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deinen Nectar und dein Mann';", "tokens": ["Dei\u00b7nen", "Nec\u00b7tar", "und", "dein", "Mann'", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mir d\u00fcnkt, als kan ich sehen,", "tokens": ["Und", "mir", "d\u00fcnkt", ",", "als", "kan", "ich", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie geehrt es mir wird stehen,", "tokens": ["Wie", "ge\u00b7ehrt", "es", "mir", "wird", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "PPER", "PPER", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn ich deinen Rock hab' an.", "tokens": ["Wenn", "ich", "dei\u00b7nen", "Rock", "hab'", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Jesu, mein Mond, meine Sonne,", "tokens": ["Je\u00b7su", ",", "mein", "Mond", ",", "mei\u00b7ne", "Son\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mein gantz Himmelreich voll Wonne,", "tokens": ["Mein", "gantz", "Him\u00b7mel\u00b7reich", "voll", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJD", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ehren-K\u00f6nig, Lebens-F\u00fcrst,", "tokens": ["Eh\u00b7ren\u00b7K\u00f6\u00b7nig", ",", "Le\u00b7bens\u00b7F\u00fcrst", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jesu, Jesu, sey gepriesen,", "tokens": ["Je\u00b7su", ",", "Je\u00b7su", ",", "sey", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df du mir so viel erwiesen", "tokens": ["Da\u00df", "du", "mir", "so", "viel", "er\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und noch mehr erweisen wirst.", "tokens": ["Und", "noch", "mehr", "er\u00b7wei\u00b7sen", "wirst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}