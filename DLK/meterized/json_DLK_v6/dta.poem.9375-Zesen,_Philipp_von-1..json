{"dta.poem.9375": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.57", "no:0.28", "sv:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Unl\u00e4ngst ist der Neidhart kommen", "tokens": ["Un\u00b7l\u00e4ngst", "ist", "der", "Neid\u00b7hart", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in das edle Sachsenland/", "tokens": ["in", "das", "ed\u00b7le", "Sach\u00b7sen\u00b7land", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "an den blancken Elbenstrand/", "tokens": ["an", "den", "blan\u00b7cken", "El\u00b7ben\u00b7strand", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und sein l\u00e4ger da genommen/", "tokens": ["und", "sein", "l\u00e4\u00b7ger", "da", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wo der gro\u00dfe Daphnis wohnt/", "tokens": ["wo", "der", "gro\u00b7\u00dfe", "Daph\u00b7nis", "wohnt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da die Tugend wird belohnt.", "tokens": ["da", "die", "Tu\u00b7gend", "wird", "be\u00b7lohnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wolte sich in hohe sachen/", "tokens": ["Wol\u00b7te", "sich", "in", "ho\u00b7he", "sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "ADJA", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "o der Thorheit! mischen ein/", "tokens": ["o", "der", "Thor\u00b7heit", "!", "mi\u00b7schen", "ein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM", "ART", "NN", "$.", "VVFIN", "ART", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nichtes kont Jhm eben seyn/", "tokens": ["nich\u00b7tes", "kont", "Jhm", "e\u00b7ben", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADV", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wolte tadelhafftig machen", "tokens": ["wol\u00b7te", "ta\u00b7del\u00b7haff\u00b7tig", "ma\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "selbsten den ber\u00fchmten Ort/", "tokens": ["selbs\u00b7ten", "den", "be\u00b7r\u00fchm\u00b7ten", "Ort", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wo mann h\u00f6rt ein g\u00f6ttlich Wort.", "tokens": ["wo", "mann", "h\u00f6rt", "ein", "g\u00f6tt\u00b7lich", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ART", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Aus dem Munde gingen flammen/", "tokens": ["Aus", "dem", "Mun\u00b7de", "gin\u00b7gen", "flam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die den edlen Himmels-flu\u00df/", "tokens": ["die", "den", "ed\u00b7len", "Him\u00b7mels\u00b7flu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der dich/ Rom/ auch trotzen mu\u00df/", "tokens": ["der", "dich", "/", "Rom", "/", "auch", "trot\u00b7zen", "mu\u00df", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$(", "NE", "$(", "ADV", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "solten d\u00e4mpfen allzusammen;", "tokens": ["sol\u00b7ten", "d\u00e4mp\u00b7fen", "all\u00b7zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Brennt er aber noch so sehr/", "tokens": ["Brennt", "er", "a\u00b7ber", "noch", "so", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "quillt der Flu\u00df doch mehr und mehr.", "tokens": ["quillt", "der", "Flu\u00df", "doch", "mehr", "und", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADV", "KON", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wunder! da\u00df sich so erk\u00fchnet/", "tokens": ["Wun\u00b7der", "!", "da\u00df", "sich", "so", "er\u00b7k\u00fch\u00b7net", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "PRF", "ADV", "VVFIN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "dieser schwefel-blaue Mann/", "tokens": ["die\u00b7ser", "schwe\u00b7fel\u00b7blaue", "Mann", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "den die Helle liebgewann/", "tokens": ["den", "die", "Hel\u00b7le", "lieb\u00b7ge\u00b7wann", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "der den Furien aufdienet/", "tokens": ["der", "den", "Fu\u00b7ri\u00b7en", "auf\u00b7die\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "den der Styx gezeuget hatt", "tokens": ["den", "der", "Styx", "ge\u00b7zeu\u00b7get", "hatt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVPP", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und sich nimmer frisset satt.", "tokens": ["und", "sich", "nim\u00b7mer", "fris\u00b7set", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Neidhart packe dich von hinnen/", "tokens": ["Neid\u00b7hart", "pa\u00b7cke", "dich", "von", "hin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bleibe wo dein Bleiben ist/", "tokens": ["blei\u00b7be", "wo", "dein", "Blei\u00b7ben", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWAV", "PPOSAT", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wo du sonst herkommen bist/", "tokens": ["wo", "du", "sonst", "her\u00b7kom\u00b7men", "bist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVINF", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und ver\u00fcbe dein Beginnen/", "tokens": ["und", "ver\u00b7\u00fc\u00b7be", "dein", "Be\u00b7gin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wo der Schwefel-rauch entspringt/", "tokens": ["wo", "der", "Schwe\u00b7fel\u00b7rauch", "ent\u00b7springt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und sich in die L\u00fcffte schwingt.", "tokens": ["und", "sich", "in", "die", "L\u00fcff\u00b7te", "schwingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Mann kann deiner wohl entbehren;", "tokens": ["Mann", "kann", "dei\u00b7ner", "wohl", "ent\u00b7beh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPOSAT", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deine Kunst und Zierrath ist/", "tokens": ["Dei\u00b7ne", "Kunst", "und", "Zier\u00b7rath", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00e4stern/ L\u00fcgen/ Leugnen/ List;", "tokens": ["L\u00e4s\u00b7tern", "/", "L\u00fc\u00b7gen", "/", "Leug\u00b7nen", "/", "List", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich wil deiner nicht begehren/", "tokens": ["Ich", "wil", "dei\u00b7ner", "nicht", "be\u00b7geh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "bin dier feind von anbegin/", "tokens": ["bin", "dier", "feind", "von", "an\u00b7be\u00b7gin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "backe dich nur jmmer hin.", "tokens": ["ba\u00b7cke", "dich", "nur", "jm\u00b7mer", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "unser Sinn soll doch nicht wancken/", "tokens": ["un\u00b7ser", "Sinn", "soll", "doch", "nicht", "wan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sondern standhafft hier bestehn/", "tokens": ["son\u00b7dern", "stand\u00b7hafft", "hier", "be\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wo die g\u00fcldnen quelle gehn;", "tokens": ["wo", "die", "g\u00fcld\u00b7nen", "quel\u00b7le", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er soll bleiben in den schrancken/", "tokens": ["Er", "soll", "blei\u00b7ben", "in", "den", "schran\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "ART", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Er soll seyn zu tag und nacht", "tokens": ["Er", "soll", "seyn", "zu", "tag", "und", "nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VAINF", "APPR", "NN", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "auf best\u00e4ndigkeit bedacht.", "tokens": ["auf", "be\u00b7st\u00e4n\u00b7dig\u00b7keit", "be\u00b7dacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}