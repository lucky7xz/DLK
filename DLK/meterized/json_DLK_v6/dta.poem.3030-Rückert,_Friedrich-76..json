{"dta.poem.3030": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "76.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich hab' ein schlichtes Buch gelesen, unverziert,", "tokens": ["Ich", "hab'", "ein", "schlich\u00b7tes", "Buch", "ge\u00b7le\u00b7sen", ",", "un\u00b7ver\u00b7ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Unverschraubt, unverf\u00e4lscht, unverfilosofirt.", "tokens": ["Un\u00b7ver\u00b7schraubt", ",", "un\u00b7ver\u00b7f\u00e4lscht", ",", "un\u00b7ver\u00b7fi\u00b7lo\u00b7so\u00b7firt", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Ansichten, R\u00fccksichten, Absichten waren nicht,", "tokens": ["An\u00b7sich\u00b7ten", ",", "R\u00fcck\u00b7sich\u00b7ten", ",", "Ab\u00b7sich\u00b7ten", "wa\u00b7ren", "nicht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "VAFIN", "PTKNEG", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Aus Umsicht aber ward Einsicht und Uebersicht.", "tokens": ["Aus", "Um\u00b7sicht", "a\u00b7ber", "ward", "Ein\u00b7sicht", "und", "Ue\u00b7ber\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Man sah, der Sache war gesehen auf den Grund;", "tokens": ["Man", "sah", ",", "der", "Sa\u00b7che", "war", "ge\u00b7se\u00b7hen", "auf", "den", "Grund", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "ART", "NN", "VAFIN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Kenners Kunde gab sich dem Unkenner kund.", "tokens": ["Des", "Ken\u00b7ners", "Kun\u00b7de", "gab", "sich", "dem", "Un\u00b7ken\u00b7ner", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Das ist Filosofie, doch andere als die", "tokens": ["Das", "ist", "Fi\u00b7lo\u00b7so\u00b7fie", ",", "doch", "an\u00b7de\u00b7re", "als", "die"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NE", "$,", "ADV", "PIS", "KOKOM", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So hoch nun steckt ihr Ziel, da\u00df sie's erreichet nie.", "tokens": ["So", "hoch", "nun", "steckt", "ihr", "Ziel", ",", "da\u00df", "sie's", "er\u00b7rei\u00b7chet", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "PPOSAT", "NN", "$,", "KOUS", "PIS", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Filosofie, die man nicht fertig mit sich bringt,", "tokens": ["Fi\u00b7lo\u00b7so\u00b7fie", ",", "die", "man", "nicht", "fer\u00b7tig", "mit", "sich", "bringt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PIS", "PTKNEG", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die aus der Forschung selbst dem Forscher erst entspringt.", "tokens": ["Die", "aus", "der", "For\u00b7schung", "selbst", "dem", "For\u00b7scher", "erst", "ent\u00b7springt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Filosofie, die will nicht machen selbst die Sachen,", "tokens": ["Fi\u00b7lo\u00b7so\u00b7fie", ",", "die", "will", "nicht", "ma\u00b7chen", "selbst", "die", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDS", "VMFIN", "PTKNEG", "VVINF", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fein zusieht ernst und still, wie sich die Sachen machen.", "tokens": ["Fein", "zu\u00b7sieht", "ernst", "und", "still", ",", "wie", "sich", "die", "Sa\u00b7chen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "KON", "ADJD", "$,", "PWAV", "PRF", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}}}}