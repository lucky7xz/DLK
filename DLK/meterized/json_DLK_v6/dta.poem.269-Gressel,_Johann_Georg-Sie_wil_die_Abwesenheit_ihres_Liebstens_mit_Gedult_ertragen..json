{"dta.poem.269": {"metadata": {"author": {"name": "Gressel, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "Sie wil die Abwesenheit ihres Liebstens  \n mit Gedult ertragen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1716", "urn": "urn:nbn:de:kobv:b4-200905199041", "language": ["de:0.99"], "booktitle": "Celander [i. e. Gressel, Johann Georg]: Verliebte-Galante/ Sinn-Vermischte und Grab-Gedichte. Hamburg u. a., 1716."}, "poem": {"stanza.1": {"line.1": {"text": "Scheint die Hoffnung meines Lebens", "tokens": ["Scheint", "die", "Hoff\u00b7nung", "mei\u00b7nes", "Le\u00b7bens"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon zu schwinden in der Lufft/", "tokens": ["Schon", "zu", "schwin\u00b7den", "in", "der", "Lufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Qu\u00e4hl ich mich doch nur vergebens/", "tokens": ["Qu\u00e4hl", "ich", "mich", "doch", "nur", "ver\u00b7ge\u00b7bens", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und bereite mir die Grufft/", "tokens": ["Und", "be\u00b7rei\u00b7te", "mir", "die", "Grufft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Darum weicht/ Gedancken weichet/", "tokens": ["Da\u00b7rum", "weicht", "/", "Ge\u00b7dan\u00b7cken", "wei\u00b7chet", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$(", "NN", "VVFIN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Da\u00df mein Hertz die Ruh\u2019 erreichet.", "tokens": ["Da\u00df", "mein", "Hertz", "die", "Ruh'", "er\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Solte denn kein Stern mehr sternen?", "tokens": ["Sol\u00b7te", "denn", "kein", "Stern", "mehr", "ster\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der ein gut Gel\u00fccke zeigt/", "tokens": ["Der", "ein", "gut", "Ge\u00b7l\u00fc\u00b7cke", "zeigt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "NN", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wenn ein Liebster durch Entfernen", "tokens": ["Wenn", "ein", "Liebs\u00b7ter", "durch", "Ent\u00b7fer\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur auf wenig Monden weicht;", "tokens": ["Nur", "auf", "we\u00b7nig", "Mon\u00b7den", "weicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja! auf kurtze Zeiten scheiden", "tokens": ["Ja", "!", "auf", "kurt\u00b7ze", "Zei\u00b7ten", "schei\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "APPR", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Bringt vor Ungl\u00fcck s\u00fcsse Freuden.", "tokens": ["Bringt", "vor", "Un\u00b7gl\u00fcck", "s\u00fcs\u00b7se", "Freu\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "So erhohle dich mein Hetze", "tokens": ["So", "er\u00b7hoh\u00b7le", "dich", "mein", "Het\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lasse deinen Schatz nur ziehn/", "tokens": ["Las\u00b7se", "dei\u00b7nen", "Schatz", "nur", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dencke/ da\u00df zuletzt der Schmertze", "tokens": ["Den\u00b7cke", "/", "da\u00df", "zu\u00b7letzt", "der", "Schmert\u00b7ze"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "KOUS", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mu\u00df zur schwartzen H\u00f6llen fliehn.", "tokens": ["Mu\u00df", "zur", "schwart\u00b7zen", "H\u00f6l\u00b7len", "fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein gew\u00fcnschtes Wiedersehen", "tokens": ["Ein", "ge\u00b7w\u00fcnschtes", "Wie\u00b7der\u00b7se\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "L\u00e4st dich nicht zu Grunde gehen.", "tokens": ["L\u00e4st", "dich", "nicht", "zu", "Grun\u00b7de", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Fahr denn wohl geliebte Seele/", "tokens": ["Fahr", "denn", "wohl", "ge\u00b7lieb\u00b7te", "See\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Grosser Himmel steh ihm bey/", "tokens": ["Gros\u00b7ser", "Him\u00b7mel", "steh", "ihm", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schaffe/ da\u00df des Todes-H\u00f6le", "tokens": ["Schaf\u00b7fe", "/", "da\u00df", "des", "To\u00b7des\u00b7H\u00f6le"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "KOUS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht vor ihme offen sey;", "tokens": ["Nicht", "vor", "ih\u00b7me", "of\u00b7fen", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lasse meine Tr\u00e4ume l\u00fcgen/", "tokens": ["Las\u00b7se", "mei\u00b7ne", "Tr\u00e4u\u00b7me", "l\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und mich frisch ihn wieder kriegen.", "tokens": ["Und", "mich", "frisch", "ihn", "wie\u00b7der", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Mehr indessen seine Liebe/", "tokens": ["Mehr", "in\u00b7des\u00b7sen", "sei\u00b7ne", "Lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie sich meine t\u00e4glich mehrt/", "tokens": ["Wie", "sich", "mei\u00b7ne", "t\u00e4g\u00b7lich", "mehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flamm noch an die heissen Triebe/", "tokens": ["Flamm", "noch", "an", "die", "heis\u00b7sen", "Trie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die schon unser Hertze nehrt.", "tokens": ["Die", "schon", "un\u00b7ser", "Hert\u00b7ze", "nehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "VVFIN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lasse uns so hefftig lieben/", "tokens": ["Las\u00b7se", "uns", "so", "heff\u00b7tig", "lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als ein Mensch je k\u00f6nnen \u00fcben.", "tokens": ["Als", "ein", "Mensch", "je", "k\u00f6n\u00b7nen", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}