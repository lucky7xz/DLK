{"dta.poem.20585": {"metadata": {"author": {"name": "Hebel, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Gespenst an der Kanderer  \n Stra\u00dfe .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1803", "urn": "urn:nbn:de:kobv:b4-200905192133", "language": ["de:0.99"], "booktitle": "[Hebel, Johann Peter]: Allemannische Gedichte. Karlsruhe, 1803."}, "poem": {"stanza.1": {"line.1": {"text": "\u2019s git Gspenster, sel isch us und isch verbey!", "tokens": ["'s", "git", "Gs\u00b7pens\u00b7ter", ",", "sel", "isch", "us", "und", "isch", "ver\u00b7bey", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "FM", "FM", "FM", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gang nummen in der Nacht vo Chander hei\u2019,", "tokens": ["Gang", "num\u00b7men", "in", "der", "Nacht", "vo", "Chan\u00b7der", "hei'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und bring e Ruusch! De trifsch e Pl\u00e4tzli a,", "tokens": ["und", "bring", "e", "Ruusch", "!", "De", "trifsch", "e", "Pl\u00e4tz\u00b7li", "a", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "$.", "FM", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und d\u00f6rt verirrsch. J setz e B\u00fce\u00dfli dra.", "tokens": ["und", "d\u00f6rt", "ver\u00b7irrsch", ".", "J", "setz", "e", "B\u00fce\u00df\u00b7li", "dra", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Vor Ziten isch nit wit vo sellem Platz", "tokens": ["Vor", "Zi\u00b7ten", "isch", "nit", "wit", "vo", "sel\u00b7lem", "Platz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "PTKNEG", "FM", "FM", "FM", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "e H\u00fcsli gsi; e Frau, e Chind, e Chatz", "tokens": ["e", "H\u00fcs\u00b7li", "gsi", ";", "e", "Frau", ",", "e", "Chind", ",", "e", "Chatz"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "$.", "ADJA", "NN", "$,", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "hen g\u2019othmet drinn; der Ma het vorem Zelt", "tokens": ["hen", "g'\u00b7oth\u00b7met", "drinn", ";", "der", "Ma", "het", "vo\u00b7rem", "Zelt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PTKVZ", "$.", "ART", "NE", "VAFIN", "ADJA", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "si Lebe g\u2019lo im Heltelinger Feld.", "tokens": ["si", "Le\u00b7be", "g'\u00b7lo", "im", "Hel\u00b7te\u00b7lin\u00b7ger", "Feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "APPRART", "NN", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Und wo sie h\u00f6rt: \u201eDi Ma lit unterm Sand\u201c", "tokens": ["Und", "wo", "sie", "h\u00f6rt", ":", "\u201e", "Di", "Ma", "lit", "un\u00b7term", "Sand", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$.", "$(", "NE", "NE", "NE", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "se het me gmeint, sie sto\u00df der Chopf an d\u2019Wand;", "tokens": ["se", "het", "me", "gmeint", ",", "sie", "sto\u00df", "der", "Chopf", "an", "d'\u00b7Wand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,", "PPER", "VVFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "---+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "doch holt sie d\u2019 Pappe no am F\u00fc\u00fcr und blost,", "tokens": ["doch", "holt", "sie", "d'", "Pap\u00b7pe", "no", "am", "F\u00fc\u00fcr", "und", "blost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NE", "NE", "APPRART", "NN", "KON", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und gits im Chind, und seit: \u201eDu bisch mi", "tokens": ["und", "gits", "im", "Chind", ",", "und", "seit", ":", "\u201e", "Du", "bisch", "mi"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$,", "KON", "NN", "$.", "$(", "PPER", "ADV", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Trost!\u201c", "tokens": ["Trost", "!", "\u201c"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Und\u2019s w\u00e4rs au gsi! Doch schlicht e mol mi", "tokens": ["Un\u00b7d's", "w\u00e4rs", "au", "gsi", "!", "Doch", "schlicht", "e", "mol", "mi"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NE", "NE", "$.", "KON", "VVFIN", "NE", "NE", "NE"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Chind", "tokens": ["Chind"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "zur Th\u00fcren us, und d\u2019 Mutter sizt und spinnt,", "tokens": ["zur", "Th\u00fc\u00b7ren", "us", ",", "und", "d'", "Mut\u00b7ter", "sizt", "und", "spinnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "$,", "KON", "NE", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und meint, \u2019s seig in der Chuchchi, r\u00fceft", "tokens": ["und", "meint", ",", "'s", "seig", "in", "der", "Chuch\u00b7chi", ",", "r\u00fceft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "ART", "NE", "$,", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "und goht,", "tokens": ["und", "goht", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "und sieht no iust, wie\u2019s uffem Fu\u00dfweg stoht.", "tokens": ["und", "sieht", "no", "i\u00b7ust", ",", "wie's", "uf\u00b7fem", "Fu\u00df\u00b7weg", "stoht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "$,", "KOUS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Und dr\u00fcber lauft e Ma, voll Wi und Brenz,", "tokens": ["Und", "dr\u00fc\u00b7ber", "lauft", "e", "Ma", ",", "voll", "Wi", "und", "Brenz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "NE", "NE", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "vo Chander her ans Chind und \u00fcberrennt\u2019s,", "tokens": ["vo", "Chan\u00b7der", "her", "ans", "Chind", "und", "\u00fc\u00b7ber\u00b7rennt's", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APZR", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und bis sie \u2019m helfe will, sen ischs scho hi,", "tokens": ["und", "bis", "sie", "'m", "hel\u00b7fe", "will", ",", "sen", "ischs", "scho", "hi", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "VMFIN", "$,", "FM", "FM", "FM", "FM", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und r\u00fcehrt si nit \u2014 e fl\u00f6sche Bueb ischs gsi.", "tokens": ["und", "r\u00fc\u00b7ehrt", "si", "nit", "e", "fl\u00f6\u00b7sche", "Bu\u00b7eb", "ischs", "gsi", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$(", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Jez r\u00fcstet sie ne Grab im tiefe Wald,", "tokens": ["Jez", "r\u00fcs\u00b7tet", "sie", "ne", "Grab", "im", "tie\u00b7fe", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und deckt ihr Chind, und seit: \u201eJ folg der bald!\u201c", "tokens": ["und", "deckt", "ihr", "Chind", ",", "und", "seit", ":", "\u201e", "J", "folg", "der", "bald", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,", "KON", "NN", "$.", "$(", "NE", "NN", "ART", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sezt si nider, h\u00fctet\u2019s Grab und wacht,", "tokens": ["Sie", "sezt", "si", "ni\u00b7der", ",", "h\u00fc\u00b7tet's", "Grab", "und", "wacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und endli stirbt sie in der n\u00fcnte Nacht.", "tokens": ["und", "end\u00b7li", "stirbt", "sie", "in", "der", "n\u00fcn\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und so verwest der Lib in Luft und Wind;", "tokens": ["Und", "so", "ver\u00b7west", "der", "Lib", "in", "Luft", "und", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch sizt der Geist no d\u00f6rt, und h\u00fcetet\u2019s Chind,", "tokens": ["Doch", "sizt", "der", "Geist", "no", "d\u00f6rt", ",", "und", "h\u00fce\u00b7tet's", "Chind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NE", "VVFIN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und h\u00fctigs Tags, de Trunkene zum Tort", "tokens": ["und", "h\u00fc\u00b7tigs", "Tags", ",", "de", "Trun\u00b7ke\u00b7ne", "zum", "Tort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "NE", "NE", "APPRART", "NN"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.4": {"text": "goht d\u2019 Chand\u2019rer Stro\u00df verbey an selbem Ort.", "tokens": ["goht", "d'", "Chan\u00b7d'\u00b7rer", "Stro\u00df", "ver\u00b7bey", "an", "sel\u00b7bem", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "NE", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Und schwankt vo Chander her e trunkene Ma,", "tokens": ["Und", "schwankt", "vo", "Chan\u00b7der", "her", "e", "trun\u00b7ke\u00b7ne", "Ma", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "APZR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "se siehts der Geist si\u2019m Gang vo witem a,", "tokens": ["se", "siehts", "der", "Geist", "si'm", "Gang", "vo", "wi\u00b7tem", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und f\u00fchrt en abw\u00e4rts; seig er, wer er sey,", "tokens": ["und", "f\u00fchrt", "en", "ab\u00b7w\u00e4rts", ";", "seig", "er", ",", "wer", "er", "sey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "PTKVZ", "$.", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "er lo\u00dft en um kei Pris am Grab verbey.", "tokens": ["er", "lo\u00dft", "en", "um", "kei", "Pris", "am", "Grab", "ver\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "FM", "APPR", "PIAT", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Er chunnt vom Weg, er tr\u00fcmmlet h\u00fcst und", "tokens": ["Er", "chunnt", "vom", "Weg", ",", "er", "tr\u00fcmm\u00b7let", "h\u00fcst", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "VVFIN", "ADJD", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "hott;", "tokens": ["hott", ";"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-", "measure": "single.down"}, "line.3": {"text": "z\u2019lezt seit er: \u201eBini echterst, woni sott?\u201c", "tokens": ["z'\u00b7lezt", "seit", "er", ":", "\u201e", "Bi\u00b7ni", "ech\u00b7terst", ",", "wo\u00b7ni", "sott", "?", "\u201c"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "PPER", "$.", "$(", "FM", "FM", "$,", "PWAV", "ADJD", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Er luegt und lost, und mauet \u00f6bbe d\u2019 Chatz,", "tokens": ["Er", "luegt", "und", "lost", ",", "und", "mau\u00b7et", "\u00f6b\u00b7be", "d'", "Chatz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "KON", "VVFIN", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "se meint er, \u2019s chreih e Guhl an sellem Platz.", "tokens": ["se", "meint", "er", ",", "'s", "chreih", "e", "Guhl", "an", "sel\u00b7lem", "Platz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "NE", "NE", "NE", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Er goht druf dar, und \u00fcber Steg und Bruck", "tokens": ["Er", "goht", "druf", "dar", ",", "und", "\u00fc\u00b7ber", "Steg", "und", "Bruck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "$,", "KON", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "se maut sie\u2019m eben all\u2019wil witer z\u2019ruck;", "tokens": ["se", "maut", "sie'm", "e\u00b7ben", "all'\u00b7wil", "wi\u00b7ter", "z'\u00b7ruck", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "und wenn er meint, er seig iez bald dehei,", "tokens": ["und", "wenn", "er", "meint", ",", "er", "seig", "iez", "bald", "de\u00b7hei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ADV", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "se stoht er wieder vor der Weserey.", "tokens": ["se", "stoht", "er", "wie\u00b7der", "vor", "der", "We\u00b7se\u00b7rey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Doch, wandle selli Stro\u00df her n\u00fcchteri L\u00fct,", "tokens": ["Doch", ",", "wand\u00b7le", "sel\u00b7li", "Stro\u00df", "her", "n\u00fcch\u00b7te\u00b7ri", "L\u00fct", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "se seit der Geist: \u201eIhr th\u00fcent mi\u2019m B\u00fcebli", "tokens": ["se", "seit", "der", "Geist", ":", "\u201e", "Ihr", "th\u00fcent", "mi'm", "B\u00fceb\u00b7li"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "$.", "$(", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "n\u00fct!\u201c", "tokens": ["n\u00fct", "!", "\u201c"], "token_info": ["word", "punct", "punct"], "pos": ["VVFIN", "$.", "$("], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Er r\u00fchrt si nit, er lo\u00dft sie ordeli", "tokens": ["Er", "r\u00fchrt", "si", "nit", ",", "er", "lo\u00dft", "sie", "or\u00b7de\u00b7li"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "VVFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "passieren ihres Wegs. ", "tokens": ["pas\u00b7sie\u00b7ren", "ih\u00b7res", "Wegs", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}