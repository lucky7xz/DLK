{"textgrid.poem.35473": {"metadata": {"author": {"name": "Conradi, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Anna", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist wohl meine ganz \u00bbverfluchte Pflicht", "tokens": ["Es", "ist", "wohl", "mei\u00b7ne", "ganz", "\u00bb", "ver\u00b7fluch\u00b7te", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "ADV", "$(", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und Schuldigkeit\u00ab, geliebtes M\u00e4dchen, dir", "tokens": ["Und", "Schul\u00b7dig\u00b7keit", "\u00ab", ",", "ge\u00b7lieb\u00b7tes", "M\u00e4d\u00b7chen", ",", "dir"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["KON", "NN", "$(", "$,", "ADJA", "NN", "$,", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In diesem meinem ersten Liederbuche", "tokens": ["In", "die\u00b7sem", "mei\u00b7nem", "ers\u00b7ten", "Lie\u00b7der\u00b7bu\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Auch schlie\u00dflich ein paar Zeilen zu verehren ...", "tokens": ["Auch", "schlie\u00df\u00b7lich", "ein", "paar", "Zei\u00b7len", "zu", "ver\u00b7eh\u00b7ren", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "PIAT", "NN", "PTKZU", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich halte mir zwar jetzt aus Prinzip", "tokens": ["Ich", "hal\u00b7te", "mir", "zwar", "jetzt", "aus", "Prin\u00b7zip"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Zehn Schritt vom Leibe alles, was nach \u00bbLiebe\u00ab", "tokens": ["Zehn", "Schritt", "vom", "Lei\u00b7be", "al\u00b7les", ",", "was", "nach", "\u00bb", "Lie\u00b7be", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "PIS", "$,", "PRELS", "APPR", "$(", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Nur im Geringsten schmecken, riechen mag ...", "tokens": ["Nur", "im", "Ge\u00b7rings\u00b7ten", "schme\u00b7cken", ",", "rie\u00b7chen", "mag", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVINF", "$,", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denn siehe! Ich begriff: Die \u00bbLiebe\u00ab ist", "tokens": ["Denn", "sie\u00b7he", "!", "Ich", "be\u00b7griff", ":", "Die", "\u00bb", "Lie\u00b7be", "\u00ab", "ist"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KON", "VVIMP", "$.", "PPER", "VVFIN", "$.", "ART", "$(", "NN", "$(", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Zuweilen zwar ein wunderk\u00f6stlich Ding", "tokens": ["Zu\u00b7wei\u00b7len", "zwar", "ein", "wun\u00b7der\u00b7k\u00f6st\u00b7lich", "Ding"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und mit dem Herrgott ziemlich nah verwandt ...", "tokens": ["Und", "mit", "dem", "Herr\u00b7gott", "ziem\u00b7lich", "nah", "ver\u00b7wandt", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Doch ist sie auch hinwiederum recht launisch,", "tokens": ["Doch", "ist", "sie", "auch", "hin\u00b7wie\u00b7de\u00b7rum", "recht", "lau\u00b7nisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und Kummer und Bedr\u00e4ngnis, St\u00f6rung, Aerger,", "tokens": ["Und", "Kum\u00b7mer", "und", "Be\u00b7dr\u00e4ng\u00b7nis", ",", "St\u00f6\u00b7rung", ",", "A\u00b7er\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Gie\u00dft sie in breiten Str\u00f6men schnippisch aus ...", "tokens": ["Gie\u00dft", "sie", "in", "brei\u00b7ten", "Str\u00f6\u00b7men", "schnip\u00b7pisch", "aus", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Daf\u00fcr mu\u00df ich doch danken ... Denn ich bin", "tokens": ["Da\u00b7f\u00fcr", "mu\u00df", "ich", "doch", "dan\u00b7ken", "...", "Denn", "ich", "bin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "VVINF", "$(", "KON", "PPER", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit allen Fibern meiner Dichterseele", "tokens": ["Mit", "al\u00b7len", "Fi\u00b7bern", "mei\u00b7ner", "Dich\u00b7ter\u00b7see\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Seit kurzem ein getreuer \u00bbSohn der Zeit\u00ab ...", "tokens": ["Seit", "kur\u00b7zem", "ein", "ge\u00b7treu\u00b7er", "\u00bb", "Sohn", "der", "Zeit", "\u00ab", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "ART", "ADJA", "$(", "NN", "ART", "NN", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und diese Zeit \u2013 man nennt sie auch \u00bbmodern\u00ab \u2013", "tokens": ["Und", "die\u00b7se", "Zeit", "\u2013", "man", "nennt", "sie", "auch", "\u00bb", "mo\u00b7dern", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "PDAT", "NN", "$(", "PIS", "VVFIN", "PPER", "ADV", "$(", "ADJD", "$(", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie hat wahrhaftig keine Zeit mehr \u00fcbrig", "tokens": ["Sie", "hat", "wahr\u00b7haf\u00b7tig", "kei\u00b7ne", "Zeit", "mehr", "\u00fcb\u00b7rig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "PIAT", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "F\u00fcr solch Allotria, wie eben Liebe.", "tokens": ["F\u00fcr", "solch", "Al\u00b7lo\u00b7tria", ",", "wie", "e\u00b7ben", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "ADV", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Da aber andrerseits dies arme B\u00fcchlein", "tokens": ["Da", "a\u00b7ber", "an\u00b7drer\u00b7seits", "dies", "ar\u00b7me", "B\u00fcch\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "PDS", "ADJA", "NN"], "meter": "-+-----+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Sich lobesam bestrebt, von meinem Leben", "tokens": ["Sich", "lo\u00b7be\u00b7sam", "be\u00b7strebt", ",", "von", "mei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADJD", "VVFIN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein ziemlich treues Konterfei zu geben,", "tokens": ["Ein", "ziem\u00b7lich", "treu\u00b7es", "Kon\u00b7ter\u00b7fei", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Darf ich auch dich, dereinst geliebtes M\u00e4dchen,", "tokens": ["Darf", "ich", "auch", "dich", ",", "de\u00b7reinst", "ge\u00b7lieb\u00b7tes", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPER", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wahrhaftig nicht vergessen \u2013 holder Liebling", "tokens": ["Wahr\u00b7haf\u00b7tig", "nicht", "ver\u00b7ges\u00b7sen", "\u2013", "hol\u00b7der", "Lieb\u00b7ling"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "PTKNEG", "VVPP", "$(", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Du meiner schw\u00e4rmerischen Knabenseele!", "tokens": ["Du", "mei\u00b7ner", "schw\u00e4r\u00b7me\u00b7ri\u00b7schen", "Kna\u00b7ben\u00b7see\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wie lang ist's her doch, da\u00df mein junges Herz", "tokens": ["Wie", "lang", "ist's", "her", "doch", ",", "da\u00df", "mein", "jun\u00b7ges", "Herz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So ganz f\u00fcr dich schlug und f\u00fcr deine Sch\u00f6nheit! ...", "tokens": ["So", "ganz", "f\u00fcr", "dich", "schlug", "und", "f\u00fcr", "dei\u00b7ne", "Sch\u00f6n\u00b7heit", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVFIN", "KON", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dein blondes Haar \u2013 dein Auge blau \u2013 nicht wahr? \u2013", "tokens": ["Dein", "blon\u00b7des", "Haar", "\u2013", "dein", "Au\u00b7ge", "blau", "\u2013", "nicht", "wahr", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "PPOSAT", "NN", "ADJD", "$(", "PTKNEG", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der zarte Teint \u2013 dein leiskokettes Wesen:", "tokens": ["Der", "zar\u00b7te", "Teint", "\u2013", "dein", "leis\u00b7ko\u00b7ket\u00b7tes", "We\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie brachten mich nur zu bald an die Angel ...", "tokens": ["Sie", "brach\u00b7ten", "mich", "nur", "zu", "bald", "an", "die", "An\u00b7gel", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mein Gott! Das ist zwar ganz nat\u00fcrlich, ja! \u2013", "tokens": ["Mein", "Gott", "!", "Das", "ist", "zwar", "ganz", "na\u00b7t\u00fcr\u00b7lich", ",", "ja", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$.", "PDS", "VAFIN", "ADV", "ADV", "ADV", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und doch kommt's heute mir urkomisch vor,", "tokens": ["Und", "doch", "kommt's", "heu\u00b7te", "mir", "ur\u00b7ko\u00b7misch", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Obwohl ich mir ganz ernstlich eingedrillt,", "tokens": ["Ob\u00b7wohl", "ich", "mir", "ganz", "ernst\u00b7lich", "ein\u00b7ge\u00b7drillt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "K\u00fchl bis ans Herz hinan ein jedes Ding", "tokens": ["K\u00fchl", "bis", "ans", "Herz", "hi\u00b7nan", "ein", "je\u00b7des", "Ding"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "APPRART", "NN", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "In echt exakt historischer Betrachtung,", "tokens": ["In", "echt", "ex\u00b7akt", "his\u00b7to\u00b7ri\u00b7scher", "Be\u00b7trach\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ganz ", "tokens": ["Ganz"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.12": {"text": "Einfach aus seinen Gr\u00fcnden zu begreifen ...", "tokens": ["Ein\u00b7fach", "aus", "sei\u00b7nen", "Gr\u00fcn\u00b7den", "zu", "be\u00b7grei\u00b7fen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Das legt dem Aerger \u2013 dieser Modus n\u00e4mlich \u2013", "tokens": ["Das", "legt", "dem", "A\u00b7er\u00b7ger", "\u2013", "die\u00b7ser", "Mo\u00b7dus", "n\u00e4m\u00b7lich", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "PDAT", "NN", "ADV", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "(man kann f\u00fcr \u00bbModus\u00ab auch \u00bbMethode\u00ab sagen)", "tokens": ["(", "man", "kann", "f\u00fcr", "\u00bb", "Mo\u00b7dus", "\u00ab", "auch", "\u00bb", "Me\u00b7tho\u00b7de", "\u00ab", "sa\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "PIS", "VMFIN", "APPR", "$(", "NE", "$(", "ADV", "$(", "NN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ganz hageb\u00fcchen Zaum und Z\u00fcgel an", "tokens": ["Ganz", "ha\u00b7ge\u00b7b\u00fc\u00b7chen", "Zaum", "und", "Z\u00fc\u00b7gel", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und spielt sich auf als \u00e4u\u00dferst netter D\u00e4mpfer,", "tokens": ["Und", "spielt", "sich", "auf", "als", "\u00e4u\u00b7\u00dferst", "net\u00b7ter", "D\u00e4mp\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "KOKOM", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der jedem hei\u00dfen Blute zu empfehlen ...", "tokens": ["Der", "je\u00b7dem", "hei\u00b7\u00dfen", "Blu\u00b7te", "zu", "emp\u00b7feh\u00b7len", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ich schweifte ab und bitte um Verzeihung!", "tokens": ["Ich", "schweif\u00b7te", "ab", "und", "bit\u00b7te", "um", "Ver\u00b7zei\u00b7hung", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nun denn \u2013 was wollt' ich sagen? Ja, jetzt wei\u00df ich! \u2013", "tokens": ["Nun", "denn", "\u2013", "was", "wollt'", "ich", "sa\u00b7gen", "?", "Ja", ",", "jetzt", "wei\u00df", "ich", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$.", "PTKANT", "$,", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es will mich n\u00e4mlich heute noch sehr schnurrig", "tokens": ["Es", "will", "mich", "n\u00e4m\u00b7lich", "heu\u00b7te", "noch", "sehr", "schnur\u00b7rig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bed\u00fcnken, da\u00df ich dereinst geliebt,", "tokens": ["Be\u00b7d\u00fcn\u00b7ken", ",", "da\u00df", "ich", "de\u00b7reinst", "ge\u00b7liebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Glanzstern du meiner Sekundanertage \u2013 \u2013", "tokens": ["Glanz\u00b7stern", "du", "mei\u00b7ner", "Se\u00b7kun\u00b7da\u00b7ner\u00b7ta\u00b7ge", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$(", "$("], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.6": {"text": "Und auch in Prima war's noch nicht ganz richtig ...", "tokens": ["Und", "auch", "in", "Pri\u00b7ma", "wa\u00b7r's", "noch", "nicht", "ganz", "rich\u00b7tig", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Ja! Das ist lange her \u2013 und unterweilen", "tokens": ["Ja", "!", "Das", "ist", "lan\u00b7ge", "her", "\u2013", "und", "un\u00b7ter\u00b7wei\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$.", "PDS", "VAFIN", "ADV", "PTKVZ", "$(", "KON", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ging ich beim Leben selber in die Schule ...", "tokens": ["Ging", "ich", "beim", "Le\u00b7ben", "sel\u00b7ber", "in", "die", "Schu\u00b7le", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Willst du ausf\u00fchrlicher dar\u00fcber h\u00f6ren \u2013", "tokens": ["Willst", "du", "aus\u00b7f\u00fchr\u00b7li\u00b7cher", "da\u00b7r\u00fc\u00b7ber", "h\u00f6\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "PAV", "VVINF", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Ich sag' es halb und halb in Parenthese \u2013", "tokens": ["Ich", "sag'", "es", "halb", "und", "halb", "in", "Pa\u00b7ren\u00b7the\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Dann bitte bl\u00e4ttre mit den schlanken Fingern,", "tokens": ["Dann", "bit\u00b7te", "bl\u00e4tt\u00b7re", "mit", "den", "schlan\u00b7ken", "Fin\u00b7gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Den wei\u00dfen Fingern mit den Rosenn\u00e4geln,", "tokens": ["Den", "wei\u00b7\u00dfen", "Fin\u00b7gern", "mit", "den", "Ro\u00b7sen\u00b7n\u00e4\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Dies Heft nach vorn und r\u00fcckw\u00e4rts durch \u2013 du wirst", "tokens": ["Dies", "Heft", "nach", "vorn", "und", "r\u00fcck\u00b7w\u00e4rts", "durch", "\u2013", "du", "wirst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "NN", "APPR", "ADV", "KON", "ADV", "APPR", "$(", "PPER", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Schon manch gepfeffertes Kapitel finden,", "tokens": ["Schon", "manch", "ge\u00b7pfef\u00b7fer\u00b7tes", "Ka\u00b7pi\u00b7tel", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "So manch Gest\u00e4ndnis tragikom'scher S\u00fcnden,", "tokens": ["So", "manch", "Ge\u00b7st\u00e4nd\u00b7nis", "tra\u00b7gi\u00b7kom'\u00b7scher", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Die dir vielleicht ein bi\u00dfchen von Interesse \u2013", "tokens": ["Die", "dir", "viel\u00b7leicht", "ein", "bi\u00df\u00b7chen", "von", "In\u00b7ter\u00b7es\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ART", "PIS", "APPR", "NN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Sind sie auch manchmal nicht Delikatesse ...", "tokens": ["Sind", "sie", "auch", "manch\u00b7mal", "nicht", "De\u00b7li\u00b7ka\u00b7tes\u00b7se", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.8": {"line.1": {"text": "Denn, Anna, oft tickt's mich unwiderstehlich,", "tokens": ["Denn", ",", "An\u00b7na", ",", "oft", "tickt's", "mich", "un\u00b7wi\u00b7der\u00b7steh\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NE", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit offenem Wort, urw\u00fcchsigen Geb\u00e4rden", "tokens": ["Mit", "of\u00b7fe\u00b7nem", "Wort", ",", "ur\u00b7w\u00fcch\u00b7si\u00b7gen", "Ge\u00b7b\u00e4r\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Herauszusagen, was ein andrer erst", "tokens": ["Her\u00b7aus\u00b7zu\u00b7sa\u00b7gen", ",", "was", "ein", "an\u00b7drer", "erst"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "ADJA", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zehnmal verklausuliert und elfmal einpackt", "tokens": ["Zehn\u00b7mal", "ver\u00b7klau\u00b7su\u00b7liert", "und", "elf\u00b7mal", "ein\u00b7packt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "KON", "ADV", "VVPP"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.5": {"text": "In dichtgesponnene L\u00fcgen-Emballagen.", "tokens": ["In", "dicht\u00b7ge\u00b7spon\u00b7ne\u00b7ne", "L\u00fc\u00b7gen\u00b7Em\u00b7bal\u00b7la\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Doch halt! Ich bin von neuem abgekommen,", "tokens": ["Doch", "halt", "!", "Ich", "bin", "von", "neu\u00b7em", "ab\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VAFIN", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und die Geschichte wird nun ganz verschwommen ...", "tokens": ["Und", "die", "Ge\u00b7schich\u00b7te", "wird", "nun", "ganz", "ver\u00b7schwom\u00b7men", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Fatal! Wie wird der Rezensentenschwarm", "tokens": ["Fa\u00b7tal", "!", "Wie", "wird", "der", "Re\u00b7zen\u00b7sen\u00b7ten\u00b7schwarm"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "PWAV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sich auf mich st\u00fcrzen \u2013 mein Gelenk umklammernd,", "tokens": ["Sich", "auf", "mich", "st\u00fcr\u00b7zen", "\u2013", "mein", "Ge\u00b7lenk", "um\u00b7klam\u00b7mernd", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PPER", "VVINF", "$(", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schreit er mir zu: du mu\u00dft viel klarer sein,", "tokens": ["Schreit", "er", "mir", "zu", ":", "du", "mu\u00dft", "viel", "kla\u00b7rer", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "PTKVZ", "$.", "PPER", "VMFIN", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn daraus findet sich ja kaum ein Schw ...", "tokens": ["Denn", "da\u00b7raus", "fin\u00b7det", "sich", "ja", "kaum", "ein", "Schw", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PRF", "ADV", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Geschweige denn ein Mensch \u2013 je nun \u2013 er hat", "tokens": ["Ge\u00b7schwei\u00b7ge", "denn", "ein", "Mensch", "\u2013", "je", "nun", "\u2013", "er", "hat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "ART", "NN", "$(", "ADV", "ADV", "$(", "PPER", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So unrecht nicht! ... Da\u00df er mir huldvoll bliebe,", "tokens": ["So", "un\u00b7recht", "nicht", "!", "...", "Da\u00df", "er", "mir", "huld\u00b7voll", "blie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKNEG", "$.", "$(", "KOUS", "PPER", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Bericht' ich nun von diesem Augenblick", "tokens": ["Be\u00b7richt'", "ich", "nun", "von", "die\u00b7sem", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ganz \u00bbsachgem\u00e4\u00df\u00ab von meiner Jugendliebe,", "tokens": ["Ganz", "\u00bb", "sach\u00b7ge\u00b7m\u00e4\u00df", "\u00ab", "von", "mei\u00b7ner", "Ju\u00b7gend\u00b7lie\u00b7be", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADJD", "$(", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Von meinem \u00fcbersonnten Jugendgl\u00fcck! ...", "tokens": ["Von", "mei\u00b7nem", "\u00fc\u00b7ber\u00b7sonn\u00b7ten", "Ju\u00b7gend\u00b7gl\u00fcck", "!", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Ich war ein Kind von zirka siebzehn Jahren \u2013", "tokens": ["Ich", "war", "ein", "Kind", "von", "zir\u00b7ka", "sieb\u00b7zehn", "Jah\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NE", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch eigentlich recht alt schon, find' ich heute \u2013", "tokens": ["Doch", "ei\u00b7gent\u00b7lich", "recht", "alt", "schon", ",", "find'", "ich", "heu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "ADV", "$,", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als ich mich in dein L\u00e4rvchen flugs vergafft ...", "tokens": ["Als", "ich", "mich", "in", "dein", "L\u00e4rv\u00b7chen", "flugs", "ver\u00b7gafft", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit reichlich respektabler Leidenschaft.", "tokens": ["Mit", "reich\u00b7lich", "res\u00b7pek\u00b7tab\u00b7ler", "Lei\u00b7den\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.12": {"line.1": {"text": "Ich wu\u00dfte meinem Leibe keinen Rat,", "tokens": ["Ich", "wu\u00df\u00b7te", "mei\u00b7nem", "Lei\u00b7be", "kei\u00b7nen", "Rat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und Tag und Nacht sann ich auf eine Tat,", "tokens": ["Und", "Tag", "und", "Nacht", "sann", "ich", "auf", "ei\u00b7ne", "Tat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie ich von meiner hei\u00dfen Herzensneigung", "tokens": ["Wie", "ich", "von", "mei\u00b7ner", "hei\u00b7\u00dfen", "Her\u00b7zens\u00b7nei\u00b7gung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu Sinn dir br\u00e4chte ernste Ueberzeugung ...", "tokens": ["Zu", "Sinn", "dir", "br\u00e4ch\u00b7te", "erns\u00b7te", "Ue\u00b7ber\u00b7zeu\u00b7gung", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Da f\u00fcgte es der Zufall, da\u00df wir beide", "tokens": ["Da", "f\u00fcg\u00b7te", "es", "der", "Zu\u00b7fall", ",", "da\u00df", "wir", "bei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns eines Tages in den Bergen trafen ...", "tokens": ["Uns", "ei\u00b7nes", "Ta\u00b7ges", "in", "den", "Ber\u00b7gen", "tra\u00b7fen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Ach ja! Im Harz war's \u2013 in den Hundstagsferien.", "tokens": ["Ach", "ja", "!", "Im", "Harz", "wa\u00b7r's", "\u2013", "in", "den", "Hunds\u00b7tags\u00b7fe\u00b7ri\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "APPRART", "NN", "VAFIN", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Zwei heiterernste Schulbankkameraden,", "tokens": ["Zwei", "hei\u00b7te\u00b7rerns\u00b7te", "Schul\u00b7bank\u00b7ka\u00b7me\u00b7ra\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die meinem Herzen auch sonst n\u00e4her standen,", "tokens": ["Die", "mei\u00b7nem", "Her\u00b7zen", "auch", "sonst", "n\u00e4\u00b7her", "stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ich \u2013 wir drei: wir kriegten pl\u00f6tzlich Sehnsucht,", "tokens": ["Und", "ich", "\u2013", "wir", "drei", ":", "wir", "krieg\u00b7ten", "pl\u00f6tz\u00b7lich", "Sehn\u00b7sucht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "PPER", "CARD", "$.", "PPER", "VVFIN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Unb\u00e4nd'ge, hei\u00dfe, namenlose Sehnsucht,", "tokens": ["Un\u00b7b\u00e4n\u00b7d'\u00b7ge", ",", "hei\u00b7\u00dfe", ",", "na\u00b7men\u00b7lo\u00b7se", "Sehn\u00b7sucht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Nach jenen H\u00f6ckern, welche da und dort", "tokens": ["Nach", "je\u00b7nen", "H\u00f6\u00b7ckern", ",", "wel\u00b7che", "da", "und", "dort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das alte M\u00fctterchen, die Erde, tr\u00e4gt:", "tokens": ["Das", "al\u00b7te", "M\u00fct\u00b7ter\u00b7chen", ",", "die", "Er\u00b7de", ",", "tr\u00e4gt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Die Sache wurde schleunigst \u00fcberlegt \u2013", "tokens": ["Die", "Sa\u00b7che", "wur\u00b7de", "schleu\u00b7nigst", "\u00fc\u00b7ber\u00b7legt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und eines Morgens war's, im Julimond,", "tokens": ["Und", "ei\u00b7nes", "Mor\u00b7gens", "wa\u00b7r's", ",", "im", "Ju\u00b7li\u00b7mond", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VAFIN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als wir die Domstadt, die ehrw\u00fcrdig alte \u2013", "tokens": ["Als", "wir", "die", "Dom\u00b7stadt", ",", "die", "ehr\u00b7w\u00fcr\u00b7dig", "al\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "ADJA", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Im Herzen ist sie schon ein wenig br\u00fcchig,", "tokens": ["Im", "Her\u00b7zen", "ist", "sie", "schon", "ein", "we\u00b7nig", "br\u00fc\u00b7chig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ADV", "ART", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Verdumpft und stockig \u2013 \u00bbkurzer Hand\u00ab verlie\u00dfen ...", "tokens": ["Ver\u00b7dumpft", "und", "sto\u00b7ckig", "\u2013", "\u00bb", "kur\u00b7zer", "Hand", "\u00ab", "ver\u00b7lie\u00b7\u00dfen", "..."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "$(", "$(", "ADJA", "NN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Das Reiseziel \u2013 bei Gott! \u2013 es war nicht Gie\u00dfen,", "tokens": ["Das", "Rei\u00b7se\u00b7ziel", "\u2013", "bei", "Gott", "!", "\u2013", "es", "war", "nicht", "Gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "NN", "$.", "$(", "PPER", "VAFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie es der Reim fast zu verlangen scheint \u2013", "tokens": ["Wie", "es", "der", "Reim", "fast", "zu", "ver\u00b7lan\u00b7gen", "scheint", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vielmehr der Harz, wie ich schon oben sagte,", "tokens": ["Viel\u00b7mehr", "der", "Harz", ",", "wie", "ich", "schon", "o\u00b7ben", "sag\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "$,", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Thale zun\u00e4chst und nachher Treseburg ...", "tokens": ["Tha\u00b7le", "zu\u00b7n\u00e4chst", "und", "nach\u00b7her", "Tre\u00b7se\u00b7burg", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "ADJA", "NN", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.18": {"line.1": {"text": "In Treseburg \u2013 wo die Erinnrung wieder", "tokens": ["In", "Tre\u00b7se\u00b7burg", "\u2013", "wo", "die", "E\u00b7rinn\u00b7rung", "wie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$(", "PWAV", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mich \u00fcberkommt an seiner Tannenw\u00e4lder", "tokens": ["Mich", "\u00fc\u00b7ber\u00b7kommt", "an", "sei\u00b7ner", "Tan\u00b7nen\u00b7w\u00e4l\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hirnkl\u00e4rende Parf\u00fcms, die unbezahlbar", "tokens": ["Hirn\u00b7kl\u00e4\u00b7ren\u00b7de", "Par\u00b7f\u00fcms", ",", "die", "un\u00b7be\u00b7zahl\u00b7bar"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NE", "$,", "PRELS", "ADJD"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "F\u00fcr Adam Homos stadtluftgrames Herz;", "tokens": ["F\u00fcr", "A\u00b7dam", "Ho\u00b7mos", "stadt\u00b7luft\u00b7gra\u00b7mes", "Herz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "An seine saatbestandnen Bergeslehnen,", "tokens": ["An", "sei\u00b7ne", "saat\u00b7be\u00b7stand\u00b7nen", "Ber\u00b7ges\u00b7leh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "An seine heimlichen Poetenpfade,", "tokens": ["An", "sei\u00b7ne", "heim\u00b7li\u00b7chen", "Poe\u00b7ten\u00b7pfa\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "An seiner Wohner kraftgesundes Trachten! \u2013 \u2013", "tokens": ["An", "sei\u00b7ner", "Woh\u00b7ner", "kraft\u00b7ge\u00b7sun\u00b7des", "Trach\u00b7ten", "!", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch halt! Ich mu\u00df der Parenthese achten,", "tokens": ["Doch", "halt", "!", "Ich", "mu\u00df", "der", "Pa\u00b7ren\u00b7the\u00b7se", "ach\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die meine Sehnsucht ungeb\u00fchrlich dehnt \u2013", "tokens": ["Die", "mei\u00b7ne", "Sehn\u00b7sucht", "un\u00b7ge\u00b7b\u00fchr\u00b7lich", "dehnt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "In Treseburg also \u2013 der Wirt hie\u00df M\u00fcller \u2013", "tokens": ["In", "Tre\u00b7se\u00b7burg", "al\u00b7so", "\u2013", "der", "Wirt", "hie\u00df", "M\u00fcl\u00b7ler", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "$(", "ART", "NN", "VVFIN", "NE", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ja! M\u00fcllers gibt es in der ganzen Welt! \u2013", "tokens": ["Ja", "!", "M\u00fcl\u00b7lers", "gibt", "es", "in", "der", "gan\u00b7zen", "Welt", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$.", "NE", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Quartierten wir uns ein auf vierzehn Tage ...", "tokens": ["Quar\u00b7tier\u00b7ten", "wir", "uns", "ein", "auf", "vier\u00b7zehn", "Ta\u00b7ge", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Am Abend sah ich dich! Du hattest zwar", "tokens": ["Am", "A\u00b7bend", "sah", "ich", "dich", "!", "Du", "hat\u00b7test", "zwar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PRF", "$.", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dein feines, stolzes, leiskokettes Wesen", "tokens": ["Dein", "fei\u00b7nes", ",", "stol\u00b7zes", ",", "leis\u00b7ko\u00b7ket\u00b7tes", "We\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auch in die Berge mitgebracht \u2013 und doch:", "tokens": ["Auch", "in", "die", "Ber\u00b7ge", "mit\u00b7ge\u00b7bracht", "\u2013", "und", "doch", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$(", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich liebte dich einmal und hoffte stark:", "tokens": ["Ich", "lieb\u00b7te", "dich", "ein\u00b7mal", "und", "hoff\u00b7te", "stark", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Es l\u00e4\u00dft sich schon Gelegenheit erzwingen,", "tokens": ["Es", "l\u00e4\u00dft", "sich", "schon", "Ge\u00b7le\u00b7gen\u00b7heit", "er\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ganz stilvoll mein Gest\u00e4ndnis anzubringen.", "tokens": ["Ganz", "stil\u00b7voll", "mein", "Ge\u00b7st\u00e4nd\u00b7nis", "an\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Ich bracht' es denn auch wirklich an \u2013 das hei\u00dft:", "tokens": ["Ich", "bracht'", "es", "denn", "auch", "wirk\u00b7lich", "an", "\u2013", "das", "hei\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "PTKVZ", "$(", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich mu\u00df mich eigentlich noch heute sch\u00e4men! \u2013", "tokens": ["Ich", "mu\u00df", "mich", "ei\u00b7gent\u00b7lich", "noch", "heu\u00b7te", "sch\u00e4\u00b7men", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "War vor dem Treffpunkt \u2013 wie es kam: ich wei\u00df nicht!", "tokens": ["War", "vor", "dem", "Treff\u00b7punkt", "\u2013", "wie", "es", "kam", ":", "ich", "wei\u00df", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "$(", "PWAV", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Doch haben's meine Freunde mich versichert,", "tokens": ["Doch", "ha\u00b7ben's", "mei\u00b7ne", "Freun\u00b7de", "mich", "ver\u00b7si\u00b7chert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Besonders wenn sie nicht \u2013 ", "tokens": ["Be\u00b7son\u00b7ders", "wenn", "sie", "nicht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PTKNEG", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Kurz also: mein Benehmen gegen Sie,", "tokens": ["Kurz", "al\u00b7so", ":", "mein", "Be\u00b7neh\u00b7men", "ge\u00b7gen", "Sie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$.", "PPOSAT", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Mein hochverehrtes Fr\u00e4ulein, war zur Unzeit", "tokens": ["Mein", "hoch\u00b7ver\u00b7ehr\u00b7tes", "Fr\u00e4u\u00b7lein", ",", "war", "zur", "Un\u00b7zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ganz f\u00fcrchterlich emp\u00f6rend, \u00bbkraftgenial\u00ab,", "tokens": ["Ganz", "f\u00fcrch\u00b7ter\u00b7lich", "em\u00b7p\u00f6\u00b7rend", ",", "\u00bb", "kraft\u00b7ge\u00b7ni\u00b7al", "\u00ab", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,", "$(", "ADJD", "$(", "$,"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.9": {"text": "\u00bbvon oben runter\u00ab, souver\u00e4n, blasiert,", "tokens": ["\u00bb", "von", "o\u00b7ben", "run\u00b7ter", "\u00ab", ",", "sou\u00b7ve\u00b7r\u00e4n", ",", "bla\u00b7siert", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "APPR", "ADV", "ADJA", "$(", "$,", "ADV", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sehr selbstbewu\u00dft, \u00bbbis in die Puppen frech\u00ab,", "tokens": ["Sehr", "selbst\u00b7be\u00b7wu\u00dft", ",", "\u00bb", "bis", "in", "die", "Pup\u00b7pen", "frech", "\u00ab", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "$(", "ADV", "APPR", "ART", "NN", "ADJD", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ironisch, gallig, unanst\u00e4ndig, grob \u2013", "tokens": ["I\u00b7ron\u00b7isch", ",", "gal\u00b7lig", ",", "un\u00b7an\u00b7st\u00e4n\u00b7dig", ",", "grob", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Mit einem Wort: beleid'gend bis zum Tz ...", "tokens": ["Mit", "ei\u00b7nem", "Wort", ":", "be\u00b7lei\u00b7d'\u00b7gend", "bis", "zum", "Tz", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "VVPP", "APPR", "APPRART", "NN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.21": {"line.1": {"text": "Ich halte diesen Umstand wohl f\u00fcr m\u00f6glich", "tokens": ["Ich", "hal\u00b7te", "die\u00b7sen", "Um\u00b7stand", "wohl", "f\u00fcr", "m\u00f6g\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "ADV", "APPR", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So, wie ich meine Wenigkeit taxiere ...", "tokens": ["So", ",", "wie", "ich", "mei\u00b7ne", "We\u00b7nig\u00b7keit", "ta\u00b7xie\u00b7re", "..."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Denn eine alte Angewohnheit ist's \u2013", "tokens": ["Denn", "ei\u00b7ne", "al\u00b7te", "An\u00b7ge\u00b7wohn\u00b7heit", "ist's", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich mu\u00df sie leider eingestehen \u2013 da\u00df", "tokens": ["Ich", "mu\u00df", "sie", "lei\u00b7der", "ein\u00b7ge\u00b7ste\u00b7hen", "\u2013", "da\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$(", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich \u00f6fter pl\u00f6tzlich Sehnsucht kriege, einem,", "tokens": ["Ich", "\u00f6f\u00b7ter", "pl\u00f6tz\u00b7lich", "Sehn\u00b7sucht", "krie\u00b7ge", ",", "ei\u00b7nem", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "NN", "VVFIN", "$,", "ART", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Besonders gerne einem, den ich liebe,", "tokens": ["Be\u00b7son\u00b7ders", "ger\u00b7ne", "ei\u00b7nem", ",", "den", "ich", "lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Einmal die vorgebundene Faschingsmaske", "tokens": ["Ein\u00b7mal", "die", "vor\u00b7ge\u00b7bun\u00b7de\u00b7ne", "Fa\u00b7schings\u00b7mas\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "Herabzurei\u00dfen und ihm nun die Wahrheit", "tokens": ["Her\u00b7ab\u00b7zu\u00b7rei\u00b7\u00dfen", "und", "ihm", "nun", "die", "Wahr\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Saugrob wie Bohnenstroh drauflos zu geigen ...", "tokens": ["Sau\u00b7grob", "wie", "Boh\u00b7nen\u00b7stroh", "drauf\u00b7los", "zu", "gei\u00b7gen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.10": {"text": "Soll man zeitweilig nicht die Z\u00e4hne zeigen?", "tokens": ["Soll", "man", "zeit\u00b7wei\u00b7lig", "nicht", "die", "Z\u00e4h\u00b7ne", "zei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADJD", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wozu hat man sie denn? ... Nun also: damals", "tokens": ["Wo\u00b7zu", "hat", "man", "sie", "denn", "?", "...", "Nun", "al\u00b7so", ":", "da\u00b7mals"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["PWAV", "VAFIN", "PIS", "PPER", "ADV", "$.", "$(", "ADV", "ADV", "$.", "ADV"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "War's denn vorbei \u2013 ich machte schlechte Witze \u2013", "tokens": ["Wa\u00b7r's", "denn", "vor\u00b7bei", "\u2013", "ich", "mach\u00b7te", "schlech\u00b7te", "Wit\u00b7ze", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKVZ", "$(", "PPER", "VVFIN", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Bei Gott! Ich kann den Kitzel nicht verknebeln! \u2013", "tokens": ["Bei", "Gott", "!", "Ich", "kann", "den", "Kit\u00b7zel", "nicht", "ver\u00b7kne\u00b7beln", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$.", "PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Da trafen mich der G\u00f6tter Racheblitze", "tokens": ["Da", "tra\u00b7fen", "mich", "der", "G\u00f6t\u00b7ter", "Ra\u00b7che\u00b7blit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und wollten mich aus der Gesellschaft s\u00e4beln \u2013 \u2013", "tokens": ["Und", "woll\u00b7ten", "mich", "aus", "der", "Ge\u00b7sell\u00b7schaft", "s\u00e4\u00b7beln", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "ART", "NN", "VVFIN", "$(", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Das war nun so \u2013 ich mu\u00dfte flugs verzichten", "tokens": ["Das", "war", "nun", "so", "\u2013", "ich", "mu\u00df\u00b7te", "flugs", "ver\u00b7zich\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "$(", "PPER", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Und konnte dich in Zukunft nur bedichten ...", "tokens": ["Und", "konn\u00b7te", "dich", "in", "Zu\u00b7kunft", "nur", "be\u00b7dich\u00b7ten", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Wir sahen uns zwar sp\u00e4ter manchmal noch \u2013", "tokens": ["Wir", "sa\u00b7hen", "uns", "zwar", "sp\u00e4\u00b7ter", "manch\u00b7mal", "noch", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und doch! Ein Etwas stellte sich dazwischen", "tokens": ["Und", "doch", "!", "Ein", "Et\u00b7was", "stell\u00b7te", "sich", "da\u00b7zwi\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "ART", "ADV", "VVFIN", "PRF", "PAV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und suchte auch das Letzte zu verwischen,", "tokens": ["Und", "such\u00b7te", "auch", "das", "Letz\u00b7te", "zu", "ver\u00b7wi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was uns vielleicht noch zueinander zog ...", "tokens": ["Was", "uns", "viel\u00b7leicht", "noch", "zu\u00b7ei\u00b7nan\u00b7der", "zog", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ja! Ja! ", "tokens": ["Ja", "!", "Ja", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["PTKANT", "$.", "PTKANT", "$."], "meter": "++", "measure": "spondeus"}}, "stanza.23": {"line.1": {"text": "Und weiter \u2013 auseinander immer weiter", "tokens": ["Und", "wei\u00b7ter", "\u2013", "aus\u00b7ein\u00b7an\u00b7der", "im\u00b7mer", "wei\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$(", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Trieb uns seitdem ein ernster Schicksalswind ...", "tokens": ["Trieb", "uns", "seit\u00b7dem", "ein", "erns\u00b7ter", "Schick\u00b7sals\u00b7wind", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PAV", "ART", "ADJA", "NN", "$("], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ich reifte aus zum m\u00fchbeladnen Streiter \u2013", "tokens": ["Ich", "reif\u00b7te", "aus", "zum", "m\u00fch\u00b7be\u00b7lad\u00b7nen", "Strei\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du wurdest eine Dame, weltumworben \u2013", "tokens": ["Du", "wur\u00b7dest", "ei\u00b7ne", "Da\u00b7me", ",", "wel\u00b7tum\u00b7wor\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PWAT", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Kindertr\u00e4ume sind dir l\u00e4ngst gestorben \u2013", "tokens": ["Die", "Kin\u00b7der\u00b7tr\u00e4u\u00b7me", "sind", "dir", "l\u00e4ngst", "ge\u00b7stor\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Du wei\u00dft nicht, was Erinnerungen sind ...", "tokens": ["Du", "wei\u00dft", "nicht", ",", "was", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen", "sind", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWS", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.8": {"text": "Will's Gott, sehn mich im n\u00e4chsten Lenz die Berge,", "tokens": ["Will's", "Gott", ",", "sehn", "mich", "im", "n\u00e4chs\u00b7ten", "Lenz", "die", "Ber\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die Harzerberge, endlich einmal wieder ...", "tokens": ["Die", "Har\u00b7zer\u00b7ber\u00b7ge", ",", "end\u00b7lich", "ein\u00b7mal", "wie\u00b7der", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Dann setz' ich mich auf meine Lieblingsbank \u2013", "tokens": ["Dann", "setz'", "ich", "mich", "auf", "mei\u00b7ne", "Lieb\u00b7lings\u00b7bank", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich hoffe sie zu finden! \u2013 tr\u00e4ume m\u00e4hlich,", "tokens": ["Ich", "hof\u00b7fe", "sie", "zu", "fin\u00b7den", "!", "\u2013", "tr\u00e4u\u00b7me", "m\u00e4h\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$.", "$(", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So'n bi\u00dfchen echtgermanisch heimwehkrank,", "tokens": ["So'n", "bi\u00df\u00b7chen", "echt\u00b7ger\u00b7ma\u00b7nisch", "heim\u00b7weh\u00b7krank", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "In ferne Sommertage mich zur\u00fcck \u2013", "tokens": ["In", "fer\u00b7ne", "Som\u00b7mer\u00b7ta\u00b7ge", "mich", "zu\u00b7r\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "In Sommertage, die von Gl\u00fcck fast troffen,", "tokens": ["In", "Som\u00b7mer\u00b7ta\u00b7ge", ",", "die", "von", "Gl\u00fcck", "fast", "trof\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bis in gewissen Nebeln sie ersoffen ...", "tokens": ["Bis", "in", "ge\u00b7wis\u00b7sen", "Ne\u00b7beln", "sie", "er\u00b7sof\u00b7fen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Und doch! Selbst heute noch in D\u00e4mmerstunden,", "tokens": ["Und", "doch", "!", "Selbst", "heu\u00b7te", "noch", "in", "D\u00e4m\u00b7mer\u00b7stun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "ADV", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Wenn alles schweigt und nur die Schatten schweben,", "tokens": ["Wenn", "al\u00b7les", "schweigt", "und", "nur", "die", "Schat\u00b7ten", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ich halb unbewu\u00dft den Weg gefunden", "tokens": ["Und", "ich", "halb", "un\u00b7be\u00b7wu\u00dft", "den", "Weg", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJD", "ADJD", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zur\u00fcck zu meiner Jugend Schw\u00e4rmerleben \u2013", "tokens": ["Zu\u00b7r\u00fcck", "zu", "mei\u00b7ner", "Ju\u00b7gend", "Schw\u00e4r\u00b7mer\u00b7le\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Selbst heute noch ist's mir, als suchte dich", "tokens": ["Selbst", "heu\u00b7te", "noch", "ist's", "mir", ",", "als", "such\u00b7te", "dich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "PPER", "$,", "KOUS", "VVFIN", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mein armes Herz mit seinem tiefsten Sehnen \u2013 \u2013", "tokens": ["Mein", "ar\u00b7mes", "Herz", "mit", "sei\u00b7nem", "tiefs\u00b7ten", "Seh\u00b7nen", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und doch \u2013 ich wei\u00df genau: Ich irre mich \u2013", "tokens": ["Und", "doch", "\u2013", "ich", "wei\u00df", "ge\u00b7nau", ":", "Ich", "ir\u00b7re", "mich", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "PPER", "VVFIN", "ADJD", "$.", "PPER", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Den liebt' ich nicht seitdem noch drei Helenen,", "tokens": ["Den", "liebt'", "ich", "nicht", "seit\u00b7dem", "noch", "drei", "He\u00b7le\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "PAV", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mathilde, Dora, Emmy, zwei Louisen? \u2013 \u2013", "tokens": ["Ma\u00b7thil\u00b7de", ",", "Do\u00b7ra", ",", "Em\u00b7my", ",", "zwei", "Lou\u00b7i\u00b7sen", "?", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "CARD", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Mein Herz sucht sicher eine nur von diesen ...", "tokens": ["Mein", "Herz", "sucht", "si\u00b7cher", "ei\u00b7ne", "nur", "von", "die\u00b7sen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "ART", "ADV", "APPR", "PDAT", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}