{"textgrid.poem.26408": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: Schrecklich viel darauf beruht,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schrecklich viel darauf beruht,", "tokens": ["Schreck\u00b7lich", "viel", "da\u00b7rauf", "be\u00b7ruht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PAV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn die rechte Hand nicht wei\u00df,", "tokens": ["Wenn", "die", "rech\u00b7te", "Hand", "nicht", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was die linke Hand Dir tut.", "tokens": ["Was", "die", "lin\u00b7ke", "Hand", "Dir", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So erging es Kasian.", "tokens": ["So", "er\u00b7ging", "es", "Ka\u00b7si\u00b7an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Stets gedenkt er siedend hei\u00df,", "tokens": ["Stets", "ge\u00b7denkt", "er", "sie\u00b7dend", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Was zwei H\u00e4nde ihm getan.", "tokens": ["Was", "zwei", "H\u00e4n\u00b7de", "ihm", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "CARD", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Zum Verzweifeln h\u00e4\u00dflich ist er.", "tokens": ["Zum", "Ver\u00b7zwei\u00b7feln", "h\u00e4\u00df\u00b7lich", "ist", "er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VAFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur da\u00df nichts er daf\u00fcr kann.", "tokens": ["Nur", "da\u00df", "nichts", "er", "da\u00b7f\u00fcr", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "PPER", "PAV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hebammen sind manchmal Biester,", "tokens": ["He\u00b7bam\u00b7men", "sind", "manch\u00b7mal", "Bies\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie ist Schuld am Kasian.", "tokens": ["Sie", "ist", "Schuld", "am", "Ka\u00b7si\u00b7an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00dcber sie er heut' noch murrt,", "tokens": ["\u00dc\u00b7ber", "sie", "er", "heut'", "noch", "murrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre Hand tat es ihm an.", "tokens": ["Ih\u00b7re", "Hand", "tat", "es", "ihm", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie zog auf die Nachgeburt", "tokens": ["Sie", "zog", "auf", "die", "Nach\u00b7ge\u00b7burt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und warf fort den Kasian.", "tokens": ["Und", "warf", "fort", "den", "Ka\u00b7si\u00b7an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "ART", "NE", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.4": {"line.1": {"text": "Aus Versehen es geschah,", "tokens": ["Aus", "Ver\u00b7se\u00b7hen", "es", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df man's nicht mal strafen kann.", "tokens": ["Da\u00df", "man's", "nicht", "mal", "stra\u00b7fen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, so h\u00e4\u00dflich steht er da,", "tokens": ["Ach", ",", "so", "h\u00e4\u00df\u00b7lich", "steht", "er", "da", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "ADJD", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schon von Weitem denkt man dran.", "tokens": ["Schon", "von", "Wei\u00b7tem", "denkt", "man", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Nachgeburten sind kaum Wesen!", "tokens": ["Nach\u00b7ge\u00b7bur\u00b7ten", "sind", "kaum", "We\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fort warf man den rechten Mann.", "tokens": ["Fort", "warf", "man", "den", "rech\u00b7ten", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sch\u00f6ner w\u00e4r' er sonst gewesen.", "tokens": ["Sch\u00f6\u00b7ner", "w\u00e4r'", "er", "sonst", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Scheu\u00dflich ist jetzt Kasian.", "tokens": ["Scheu\u00df\u00b7lich", "ist", "jetzt", "Ka\u00b7si\u00b7an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Immer wirkt er nur als Rest.", "tokens": ["Im\u00b7mer", "wirkt", "er", "nur", "als", "Rest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "KOUS", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gl\u00fccklich er nie werden kann.", "tokens": ["Gl\u00fcck\u00b7lich", "er", "nie", "wer\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ADV", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Heut', am Nachgeburtstagsfest,", "tokens": ["Heut'", ",", "am", "Nach\u00b7ge\u00b7burts\u00b7tags\u00b7fest", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6tete sich Kasian.", "tokens": ["T\u00f6\u00b7te\u00b7te", "sich", "Ka\u00b7si\u00b7an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Seele ganz und ohne Leib", "tokens": ["See\u00b7le", "ganz", "und", "oh\u00b7ne", "Leib"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fchlt er sich jetzt w\u00fcrdig an.", "tokens": ["F\u00fchlt", "er", "sich", "jetzt", "w\u00fcr\u00b7dig", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fand im Himmel gleich ein Weib,", "tokens": ["Fand", "im", "Him\u00b7mel", "gleich", "ein", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das ihn seelisch lieben kann.", "tokens": ["Das", "ihn", "see\u00b7lisch", "lie\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nur der Erde bleiben fern", "tokens": ["Nur", "der", "Er\u00b7de", "blei\u00b7ben", "fern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leute wie der Kasian.", "tokens": ["Leu\u00b7te", "wie", "der", "Ka\u00b7si\u00b7an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Reste hat die Erd' nicht gern.", "tokens": ["Res\u00b7te", "hat", "die", "Erd'", "nicht", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gl\u00fcck macht nur ein ganzer Mann.", "tokens": ["Gl\u00fcck", "macht", "nur", "ein", "gan\u00b7zer", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}