{"textgrid.poem.48374": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die einen sagen, wir haben gewonnen,", "tokens": ["Die", "ei\u00b7nen", "sa\u00b7gen", ",", "wir", "ha\u00b7ben", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die andern sagen, sie haben gewonnen,", "tokens": ["Die", "an\u00b7dern", "sa\u00b7gen", ",", "sie", "ha\u00b7ben", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich aber sage das eine nur:", "tokens": ["Ich", "a\u00b7ber", "sa\u00b7ge", "das", "ei\u00b7ne", "nur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "ART", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es ward viel gelaufen bei Sherifmur,", "tokens": ["Es", "ward", "viel", "ge\u00b7lau\u00b7fen", "bei", "She\u00b7rif\u00b7mur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "APPR", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wir sind gelaufen und sie sind gelaufen,", "tokens": ["Wir", "sind", "ge\u00b7lau\u00b7fen", "und", "sie", "sind", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gelaufen einzeln und in Haufen.", "tokens": ["Ge\u00b7lau\u00b7fen", "ein\u00b7zeln", "und", "in", "Hau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wir haben den linken Fl\u00fcgel geschlagen,", "tokens": ["Wir", "ha\u00b7ben", "den", "lin\u00b7ken", "Fl\u00fc\u00b7gel", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der rechte Fl\u00fcgel hat uns geschlagen,", "tokens": ["Der", "rech\u00b7te", "Fl\u00fc\u00b7gel", "hat", "uns", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Eine Rennbahn war die ganze Flur,", "tokens": ["Ei\u00b7ne", "Renn\u00b7bahn", "war", "die", "gan\u00b7ze", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Es ward viel gelaufen bei Sherifmur,", "tokens": ["Es", "ward", "viel", "ge\u00b7lau\u00b7fen", "bei", "She\u00b7rif\u00b7mur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "APPR", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wir sind gelaufen und sie sind gelaufen,", "tokens": ["Wir", "sind", "ge\u00b7lau\u00b7fen", "und", "sie", "sind", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gelaufen einzeln und in Haufen.", "tokens": ["Ge\u00b7lau\u00b7fen", "ein\u00b7zeln", "und", "in", "Hau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Rob Roy, o w\u00e4rst du zu Hilf' uns gekommen,", "tokens": ["Rob", "Roy", ",", "o", "w\u00e4rst", "du", "zu", "Hil\u00b7f'", "uns", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "VAFIN", "PPER", "APPR", "NE", "PPER", "VVPP", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Es h\u00e4tt' ein andres Ende genommen,", "tokens": ["Es", "h\u00e4tt'", "ein", "and\u00b7res", "En\u00b7de", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So aber war das Ende nur:", "tokens": ["So", "a\u00b7ber", "war", "das", "En\u00b7de", "nur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es ward viel gelaufen bei Sherifmur,", "tokens": ["Es", "ward", "viel", "ge\u00b7lau\u00b7fen", "bei", "She\u00b7rif\u00b7mur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "APPR", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wir sind gelaufen und sie sind gelaufen,", "tokens": ["Wir", "sind", "ge\u00b7lau\u00b7fen", "und", "sie", "sind", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gelaufen einzeln und in Haufen.", "tokens": ["Ge\u00b7lau\u00b7fen", "ein\u00b7zeln", "und", "in", "Hau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}