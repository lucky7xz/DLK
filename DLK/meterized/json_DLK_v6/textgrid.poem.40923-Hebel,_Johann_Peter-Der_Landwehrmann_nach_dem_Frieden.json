{"textgrid.poem.40923": {"metadata": {"author": {"name": "Hebel, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Der Landwehrmann nach dem Frieden", "genre": "verse", "period": "N.A.", "pub_year": 1793, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nei lueg, nei lueg am Mattebach", "tokens": ["Nei", "lu\u00b7eg", ",", "nei", "lu\u00b7eg", "am", "Mat\u00b7te\u00b7bach"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["XY", "XY", "$,", "APPR", "NE", "APPRART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "wer w\u00e4scht so spot,", "tokens": ["wer", "w\u00e4scht", "so", "spot", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "so blutig rot", "tokens": ["so", "blu\u00b7tig", "rot"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "si Plunder us mit Weh und Ach?", "tokens": ["si", "Plun\u00b7der", "us", "mit", "Weh", "und", "Ach", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er luegt si alte S\u00e4bel a,", "tokens": ["Er", "luegt", "si", "al\u00b7te", "S\u00e4\u00b7bel", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "verschrickt frei drab", "tokens": ["ver\u00b7schrickt", "frei", "drab"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADJD", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "und w\u00e4scht en ab", "tokens": ["und", "w\u00e4scht", "en", "ab"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NE", "PTKVZ"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "vom Blut, und luegt en wieder a.", "tokens": ["vom", "Blut", ",", "und", "luegt", "en", "wie\u00b7der", "a."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "abbreviation"], "pos": ["APPRART", "NN", "$,", "KON", "VVFIN", "FM", "ADV", "APPRART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Er lengt si Sack, er chert en um:", "tokens": ["Er", "lengt", "si", "Sack", ",", "er", "chert", "en", "um", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "'s isch alles us,", "tokens": ["'s", "isch", "al\u00b7les", "us", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PIS", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "'s fallt nit me drus,", "tokens": ["'s", "fallt", "nit", "me", "drus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "FM", "FM", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.12": {"text": "i g\u00e4b ke halbe Chr\u00fctzer drum.", "tokens": ["i", "g\u00e4b", "ke", "hal\u00b7be", "Chr\u00fct\u00b7zer", "drum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "E bitzeli Tubak mu\u00df er no", "tokens": ["E", "bit\u00b7ze\u00b7li", "Tu\u00b7bak", "mu\u00df", "er", "no"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["XY", "XY", "NN", "VMFIN", "PPER", "NE"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "im Pfifli ha:", "tokens": ["im", "Pfif\u00b7li", "ha", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "er z\u00fcndet's a;", "tokens": ["er", "z\u00fcn\u00b7det's", "a", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "du arme Tropf! 's will n\u00fcmme goh.", "tokens": ["du", "ar\u00b7me", "Tropf", "!", "'s", "will", "n\u00fcm\u00b7me", "goh", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "PPER", "VMFIN", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Jez fahrt's en wie ne Schrecken a;", "tokens": ["Jez", "fahrt's", "en", "wie", "ne", "Schre\u00b7cken", "a", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "KOKOM", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "er schlicht dervo.", "tokens": ["er", "schlicht", "der\u00b7vo", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.19": {"text": "'s wird \u00f6pper cho:", "tokens": ["'s", "wird", "\u00f6p\u00b7per", "cho", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "$."], "meter": "++-+-", "measure": "iambic.di"}, "line.20": {"text": "de muesch e sufers Gwisse ha.", "tokens": ["de", "mu\u00b7esch", "e", "su\u00b7fers", "Gwis\u00b7se", "ha", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.21": {"text": "Nei lueg, was springt d\u00f6rt \u00fcbere Hag", "tokens": ["Nei", "lu\u00b7eg", ",", "was", "springt", "d\u00f6rt", "\u00fc\u00b7be\u00b7re", "Hag"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["XY", "XY", "$,", "PWS", "VVFIN", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.22": {"text": "mit frischem Sprung,", "tokens": ["mit", "fri\u00b7schem", "Sprung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.23": {"text": "so lieb und jung", "tokens": ["so", "lieb", "und", "jung"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}}}}}