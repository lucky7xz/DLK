{"dta.poem.9134": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Xi.  \n Han\u00df in allen gassen.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Zwey m\u00e4dgen auf einmal/ f\u00fcrwahr das ist zu viel/", "tokens": ["Zwey", "m\u00e4d\u00b7gen", "auf", "ein\u00b7mal", "/", "f\u00fcr\u00b7wahr", "das", "ist", "zu", "viel", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ADV", "$(", "ADV", "PDS", "VAFIN", "PTKA", "PIS", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch weil die liebe mich also beth\u00f6ren will/", "tokens": ["Doch", "weil", "die", "lie\u00b7be", "mich", "al\u00b7so", "be\u00b7th\u00f6\u00b7ren", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "VVFIN", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Darff ich nicht widerstehen/", "tokens": ["Darff", "ich", "nicht", "wi\u00b7der\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Ich seh mein elend an/", "tokens": ["Ich", "seh", "mein", "e\u00b7lend", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und la\u00df es immer gehen", "tokens": ["Und", "la\u00df", "es", "im\u00b7mer", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "So gut es gehen kan.", "tokens": ["So", "gut", "es", "ge\u00b7hen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Ich wei\u00df nicht welche mir am besten anla\u00df gibt/", "tokens": ["Ich", "wei\u00df", "nicht", "wel\u00b7che", "mir", "am", "bes\u00b7ten", "an\u00b7la\u00df", "gibt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PRELS", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie beyde sind polit/ sie beyde sind beliebt/", "tokens": ["Sie", "bey\u00b7de", "sind", "po\u00b7lit", "/", "sie", "bey\u00b7de", "sind", "be\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VAFIN", "NE", "$(", "PPER", "PIS", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An ihrer sch\u00f6nen jugend/", "tokens": ["An", "ih\u00b7rer", "sch\u00f6\u00b7nen", "ju\u00b7gend", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "An ihrer h\u00f6fligkeit/", "tokens": ["An", "ih\u00b7rer", "h\u00f6f\u00b7lig\u00b7keit", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "An ihrer liebes-tugend/", "tokens": ["An", "ih\u00b7rer", "lie\u00b7bes\u00b7tu\u00b7gend", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ist gar kein unterscheid.", "tokens": ["Ist", "gar", "kein", "un\u00b7ter\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. Was eine lieblich macht/ das fehlt der andern nicht/", "tokens": ["Was", "ei\u00b7ne", "lieb\u00b7lich", "macht", "/", "das", "fehlt", "der", "an\u00b7dern", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJD", "VVFIN", "$(", "PDS", "VVFIN", "ART", "ADJA", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da ist ein augen-glantz/ da ist ein angesicht/", "tokens": ["Da", "ist", "ein", "au\u00b7gen\u00b7glantz", "/", "da", "ist", "ein", "an\u00b7ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$(", "ADV", "VAFIN", "ART", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die allersch\u00f6nsten finger", "tokens": ["Die", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "fin\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das wollen-weiche zwey/", "tokens": ["Das", "wol\u00b7len\u00b7wei\u00b7che", "zwey", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "CARD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der halb-versteckten dinger/", "tokens": ["Der", "halb\u00b7ver\u00b7steck\u00b7ten", "din\u00b7ger", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ist alles einerley.", "tokens": ["Ist", "al\u00b7les", "ei\u00b7ner\u00b7ley", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "4. Wann diese gegen mir ein bi\u00dfgen freundlich thut/", "tokens": ["Wann", "die\u00b7se", "ge\u00b7gen", "mir", "ein", "bi\u00df\u00b7gen", "freund\u00b7lich", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "APPR", "PPER", "ART", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So denck ich jene dort die kan es gleich so gut/", "tokens": ["So", "denck", "ich", "je\u00b7ne", "dort", "die", "kan", "es", "gleich", "so", "gut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PDS", "ADV", "ART", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und komm ich zu der andern/", "tokens": ["Und", "komm", "ich", "zu", "der", "an\u00b7dern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So la\u00df ich meinen sinn", "tokens": ["So", "la\u00df", "ich", "mei\u00b7nen", "sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zur ersten wieder wandern/", "tokens": ["Zur", "ers\u00b7ten", "wie\u00b7der", "wan\u00b7dern", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Da ich gewesen bin.", "tokens": ["Da", "ich", "ge\u00b7we\u00b7sen", "bin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "5. In dessen wei\u00df ich nicht/ wasich behalten soll/", "tokens": ["In", "des\u00b7sen", "wei\u00df", "ich", "nicht", "/", "wa\u00b7sich", "be\u00b7hal\u00b7ten", "soll", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "PPER", "PTKNEG", "$(", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dann jener bin ich gut/ und die gef\u00e4lt mir wol/", "tokens": ["Dann", "je\u00b7ner", "bin", "ich", "gut", "/", "und", "die", "ge\u00b7f\u00e4lt", "mir", "wol", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "PPER", "ADJD", "$(", "KON", "ART", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Soll ich das hertze fassen", "tokens": ["Soll", "ich", "das", "hert\u00b7ze", "fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ein geliebtes kind", "tokens": ["Und", "ein", "ge\u00b7lieb\u00b7tes", "kind"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Von diesen beyden lassen/", "tokens": ["Von", "die\u00b7sen", "bey\u00b7den", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PIS", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "So bin ich taub und blind.", "tokens": ["So", "bin", "ich", "taub", "und", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "6. Es ist doch nun geschehn/ das geht am besten an/", "tokens": ["Es", "ist", "doch", "nun", "ge\u00b7schehn", "/", "das", "geht", "am", "bes\u00b7ten", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$(", "PDS", "VVFIN", "PTKA", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo ich sie alle zwey vor mich behalten kan/", "tokens": ["Wo", "ich", "sie", "al\u00b7le", "zwey", "vor", "mich", "be\u00b7hal\u00b7ten", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "PIAT", "CARD", "APPR", "PRF", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein hertz! es k\u00f6mmt ja besser/", "tokens": ["Mein", "hertz", "!", "es", "k\u00f6mmt", "ja", "bes\u00b7ser", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VVFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In dem du als ein gast", "tokens": ["In", "dem", "du", "als", "ein", "gast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "KOUS", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der eitelkeit/ zwey messer", "tokens": ["Der", "ei\u00b7tel\u00b7keit", "/", "zwey", "mes\u00b7ser"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als keins im vorrath hast.", "tokens": ["Als", "keins", "im", "vor\u00b7rath", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "7. Ein solcher wechsel stutzt/ und steht vortreflich sch\u00f6n/", "tokens": ["Ein", "sol\u00b7cher", "wech\u00b7sel", "stutzt", "/", "und", "steht", "vor\u00b7tre\u00b7flich", "sch\u00f6n", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$(", "KON", "VVFIN", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wann eine sauer siht kan ich zur andern gehn/", "tokens": ["Wann", "ei\u00b7ne", "sau\u00b7er", "siht", "kan", "ich", "zur", "an\u00b7dern", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJD", "VVFIN", "VMFIN", "PPER", "APPRART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Tr\u00e4gt die ein ungefallen/", "tokens": ["Tr\u00e4gt", "die", "ein", "un\u00b7ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So komm ich dorten ein/", "tokens": ["So", "komm", "ich", "dor\u00b7ten", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und so kan ich bey allen", "tokens": ["Und", "so", "kan", "ich", "bey", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "APPR", "PIAT"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Verliebt und lustig seyn.", "tokens": ["Ver\u00b7liebt", "und", "lus\u00b7tig", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}