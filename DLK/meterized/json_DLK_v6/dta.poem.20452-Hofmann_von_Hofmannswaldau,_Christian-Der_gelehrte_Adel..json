{"dta.poem.20452": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Der gelehrte Adel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ihr/ die ihr schlacken-werck vor reines silber wehlet/", "tokens": ["Ihr", "/", "die", "ihr", "schla\u00b7cken\u00b7\u00b7werck", "vor", "rei\u00b7nes", "sil\u00b7ber", "weh\u00b7let", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PRELS", "PPER", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und schlechtes spiegel-gla\u00df gleich diamanten sch\u00e4tzt/", "tokens": ["Und", "schlech\u00b7tes", "spie\u00b7gel\u00b7gla\u00df", "gleich", "di\u00b7a\u00b7man\u00b7ten", "sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Euch meyn\u2019 ich/ die ihr nur der ahnen menge zehlet/", "tokens": ["Euch", "meyn'", "ich", "/", "die", "ihr", "nur", "der", "ah\u00b7nen", "men\u00b7ge", "zeh\u00b7let", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PRELS", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und selbst als nulle scheint den nullen beygesetzt/", "tokens": ["Und", "selbst", "als", "nul\u00b7le", "scheint", "den", "nul\u00b7len", "bey\u00b7ge\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "ADV", "VVFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die ihr das g\u00f6tzen-bild des kahlen Adels ehrt/", "tokens": ["Die", "ihr", "das", "g\u00f6t\u00b7zen\u00b7bild", "des", "kah\u00b7len", "A\u00b7dels", "ehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ihr seyd/ verzeiht es mir/ recht ungemein beth\u00f6rt.", "tokens": ["Ihr", "seyd", "/", "ver\u00b7zeiht", "es", "mir", "/", "recht", "un\u00b7ge\u00b7mein", "be\u00b7th\u00f6rt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VVFIN", "PPER", "PPER", "$(", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was n\u00fctzt der bunte kram geerbter ritter-fahnen/", "tokens": ["Was", "n\u00fctzt", "der", "bun\u00b7te", "kram", "ge\u00b7erb\u00b7ter", "rit\u00b7ter\u00b7fah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was dient der b\u00fcffels-kopff der euer wapen ziert/", "tokens": ["Was", "dient", "der", "b\u00fcf\u00b7fels\u00b7kopff", "der", "eu\u00b7er", "wa\u00b7pen", "ziert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was helffen helm und schild von l\u00e4ngst verfaulten ahnen/", "tokens": ["Was", "helf\u00b7fen", "helm", "und", "schild", "von", "l\u00e4ngst", "ver\u00b7faul\u00b7ten", "ah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "KON", "ADJD", "APPR", "ADV", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der polierte stahl/ den euer harnisch f\u00fchrt", "tokens": ["Und", "der", "po\u00b7lier\u00b7te", "stahl", "/", "den", "eu\u00b7er", "har\u00b7nisch", "f\u00fchrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "$(", "ART", "PPOSAT", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von tausend jahren her? Ein kluger macht den schlu\u00df:", "tokens": ["Von", "tau\u00b7send", "jah\u00b7ren", "her", "?", "Ein", "klu\u00b7ger", "macht", "den", "schlu\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "PTKVZ", "$.", "ART", "ADJA", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df dieser haus-rath noch den tr\u00f6del f\u00fcllen mu\u00df.", "tokens": ["Da\u00df", "die\u00b7ser", "haus\u00b7rath", "noch", "den", "tr\u00f6\u00b7del", "f\u00fcl\u00b7len", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Den Adel schelt\u2019 ich nicht/ ich kenne seine g\u00fcte;", "tokens": ["Den", "A\u00b7del", "schelt'", "ich", "nicht", "/", "ich", "ken\u00b7ne", "sei\u00b7ne", "g\u00fc\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Di\u00df enge saal-athen zeigt manchen edelmann/", "tokens": ["Di\u00df", "en\u00b7ge", "saa\u00b7la\u00b7then", "zeigt", "man\u00b7chen", "e\u00b7del\u00b7mann", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Der hoch-gebohren ist von ankunfft und gebl\u00fcte:", "tokens": ["Der", "hoch\u00b7ge\u00b7boh\u00b7ren", "ist", "von", "an\u00b7kunfft", "und", "ge\u00b7bl\u00fc\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "APPR", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sieht ein sch\u00f6nes buch doch mit vergn\u00fcgen an.", "tokens": ["Und", "sieht", "ein", "sch\u00f6\u00b7nes", "buch", "doch", "mit", "ver\u00b7gn\u00fc\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ADV", "APPR", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein/ werden Adel blo\u00df in fahn und ahnen sucht/", "tokens": ["Nein", "/", "wer\u00b7den", "A\u00b7del", "blo\u00df", "in", "fahn", "und", "ah\u00b7nen", "sucht", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "VAFIN", "NN", "ADV", "APPR", "NE", "KON", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist ein verha\u00dftes bild der leeren sodoms-frucht.", "tokens": ["Ist", "ein", "ver\u00b7ha\u00df\u00b7tes", "bild", "der", "lee\u00b7ren", "so\u00b7doms\u00b7frucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Gesetzt/ da\u00df dein geschlecht von alten helden stammet/", "tokens": ["Ge\u00b7setzt", "/", "da\u00df", "dein", "ge\u00b7schlecht", "von", "al\u00b7ten", "hel\u00b7den", "stam\u00b7met", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "KOUS", "PPOSAT", "VVPP", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der ruhm ist eitelkeit/ und ein geborgtes gut:", "tokens": ["Der", "ruhm", "ist", "ei\u00b7tel\u00b7keit", "/", "und", "ein", "ge\u00b7borg\u00b7tes", "gut", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "KON", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Im fall die tugend dich als mi\u00dfgeburt verdammet/", "tokens": ["Im", "fall", "die", "tu\u00b7gend", "dich", "als", "mi\u00df\u00b7ge\u00b7burt", "ver\u00b7dam\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PPER", "KOUS", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und keine helden-that beweist das edle blut.", "tokens": ["Und", "kei\u00b7ne", "hel\u00b7den\u00b7that", "be\u00b7weist", "das", "ed\u00b7le", "blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Viel h\u00f6her steigt dein werth/ wenn du Achilles bist/", "tokens": ["Viel", "h\u00f6\u00b7her", "steigt", "dein", "werth", "/", "wenn", "du", "A\u00b7chil\u00b7les", "bist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPOSAT", "ADJD", "$(", "KOUS", "PPER", "NE", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ob schon/ der dich gezeugt/ Thersites selber ist.", "tokens": ["Ob", "schon", "/", "der", "dich", "ge\u00b7zeugt", "/", "Ther\u00b7si\u00b7tes", "sel\u00b7ber", "ist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$(", "PRELS", "PPER", "VVPP", "$(", "NE", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der alten Adel wuchs auff keinen fremden zweigen/", "tokens": ["Der", "al\u00b7ten", "A\u00b7del", "wuchs", "auff", "kei\u00b7nen", "frem\u00b7den", "zwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr auge merckte nicht entlehnten zierrath an/", "tokens": ["Ihr", "au\u00b7ge", "merck\u00b7te", "nicht", "ent\u00b7lehn\u00b7ten", "zier\u00b7rath", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKNEG", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kont\u2019 iemand sich nicht selbst durch tapffre thaten zeigen/", "tokens": ["Kont'", "ie\u00b7mand", "sich", "nicht", "selbst", "durch", "tapf\u00b7fre", "tha\u00b7ten", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PRF", "PTKNEG", "ADV", "APPR", "ADJA", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch tugend/ durch verstand/ der war kein edelmann.", "tokens": ["Durch", "tu\u00b7gend", "/", "durch", "ver\u00b7stand", "/", "der", "war", "kein", "e\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "APPR", "VVFIN", "$(", "ART", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nun aber hat das blat sich/ leider! umgewand:", "tokens": ["Nun", "a\u00b7ber", "hat", "das", "blat", "sich", "/", "lei\u00b7der", "!", "um\u00b7ge\u00b7wand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PDS", "VVFIN", "PRF", "$(", "ADV", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Indem ein esel offt vor edel wird erkannt.", "tokens": ["In\u00b7dem", "ein", "e\u00b7sel", "offt", "vor", "e\u00b7del", "wird", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der/ den der pfeffer reich/ der reichthum stoltz gemachet/", "tokens": ["Der", "/", "den", "der", "pfef\u00b7fer", "reich", "/", "der", "reicht\u00b7hum", "stoltz", "ge\u00b7ma\u00b7chet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ART", "ART", "NN", "ADJD", "$(", "ART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kaufft in den Adel sich vor tausend thaler ein/", "tokens": ["Kaufft", "in", "den", "A\u00b7del", "sich", "vor", "tau\u00b7send", "tha\u00b7ler", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PRF", "APPR", "CARD", "NN", "ART", "$("], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.3": {"text": "Und giebt den handel an: Indem der weise lachet/", "tokens": ["Und", "giebt", "den", "han\u00b7del", "an", ":", "In\u00b7dem", "der", "wei\u00b7se", "la\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "KOUS", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df solch ein pfeffer-sack will strenger juncker seyn.", "tokens": ["Da\u00df", "solch", "ein", "pfef\u00b7fer\u00b7sack", "will", "stren\u00b7ger", "jun\u00b7cker", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "NN", "VMFIN", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So kommt der offne helm auff kind und kindes kind/", "tokens": ["So", "kommt", "der", "off\u00b7ne", "helm", "auff", "kind", "und", "kin\u00b7des", "kind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ihrem vater gleich an witz und tugend sind.", "tokens": ["Die", "ih\u00b7rem", "va\u00b7ter", "gleich", "an", "witz", "und", "tu\u00b7gend", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "APPR", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Aus solchem holtze nun wird ein Mercur geschnitten/", "tokens": ["Aus", "sol\u00b7chem", "holt\u00b7ze", "nun", "wird", "ein", "Mer\u00b7cur", "ge\u00b7schnit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VVFIN", "ADV", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den der gemeine mann fast wie den f\u00fcrsten ehrt:", "tokens": ["Den", "der", "ge\u00b7mei\u00b7ne", "mann", "fast", "wie", "den", "f\u00fcrs\u00b7ten", "ehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "ADV", "KOKOM", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kommt aber an den hof ein ander freund geschritten/", "tokens": ["Kommt", "a\u00b7ber", "an", "den", "hof", "ein", "an\u00b7der", "freund", "ge\u00b7schrit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der in das blasse reich der wissenschafft geh\u00f6rt/", "tokens": ["Der", "in", "das", "blas\u00b7se", "reich", "der", "wis\u00b7sen\u00b7schafft", "ge\u00b7h\u00f6rt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "ADJD", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und h\u00e4lt um einen dienst gantz tieff geb\u00fccket an/", "tokens": ["Und", "h\u00e4lt", "um", "ei\u00b7nen", "dienst", "gantz", "tieff", "ge\u00b7b\u00fc\u00b7cket", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADV", "ADV", "ADJD", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So fragt man ihn: Monsieur/ ist er ein edelmann?", "tokens": ["So", "fragt", "man", "ihn", ":", "Mon\u00b7si\u00b7eur", "/", "ist", "er", "ein", "e\u00b7del\u00b7mann", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "$.", "FM", "$(", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+-+---+-+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "O spott! Heist di\u00df allein aus edlen stamm entsprossen/", "tokens": ["O", "spott", "!", "Heist", "di\u00df", "al\u00b7lein", "aus", "ed\u00b7len", "stamm", "ent\u00b7spros\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "NN", "PDS", "ADV", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn man den mutter-heerd/ sonst aber nichts geschaut/", "tokens": ["Wenn", "man", "den", "mut\u00b7ter\u00b7he\u00b7erd", "/", "sonst", "a\u00b7ber", "nichts", "ge\u00b7schaut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "$(", "ADV", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und vor das vaterland mehr wein als blut vergossen?", "tokens": ["Und", "vor", "das", "va\u00b7ter\u00b7land", "mehr", "wein", "als", "blut", "ver\u00b7gos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PIAT", "NN", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So steht der Adel wohl auff schlechten grund gebaut.", "tokens": ["So", "steht", "der", "A\u00b7del", "wohl", "auff", "schlech\u00b7ten", "grund", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch hat ein f\u00fcrst nur nicht von leim ein hertz gemacht/", "tokens": ["Doch", "hat", "ein", "f\u00fcrst", "nur", "nicht", "von", "leim", "ein", "hertz", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADV", "ADV", "PTKNEG", "APPR", "NE", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So wird er nimmermehr auff diesen wahn gebracht.", "tokens": ["So", "wird", "er", "nim\u00b7mer\u00b7mehr", "auff", "die\u00b7sen", "wahn", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Er kennt/ was tugend sey/ und ein gelehrtes wissen:", "tokens": ["Er", "kennt", "/", "was", "tu\u00b7gend", "sey", "/", "und", "ein", "ge\u00b7lehr\u00b7tes", "wis\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWS", "VVPP", "VAFIN", "$(", "KON", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer diesen Adel hat/ den zeucht er jenem vor/", "tokens": ["Wer", "die\u00b7sen", "A\u00b7del", "hat", "/", "den", "zeucht", "er", "je\u00b7nem", "vor", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VAFIN", "$(", "ART", "VVFIN", "PPER", "PDAT", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die mit der ahnen glantz sich nur behelffen m\u00fcssen/", "tokens": ["Die", "mit", "der", "ah\u00b7nen", "glantz", "sich", "nur", "be\u00b7hel\u00b7ffen", "m\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "PRF", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und \u00f6ffnet ihm zur burg der ehren th\u00fcr und thor.", "tokens": ["Und", "\u00f6ff\u00b7net", "ihm", "zur", "burg", "der", "eh\u00b7ren", "th\u00fcr", "und", "thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Apollo schreibt sein lob ans hohe sternen-haus/", "tokens": ["A\u00b7pol\u00b7lo", "schreibt", "sein", "lob", "ans", "ho\u00b7he", "ster\u00b7nen\u00b7haus", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Fama streut es hier mit tausend zungen aus.", "tokens": ["Und", "Fa\u00b7ma", "streut", "es", "hier", "mit", "tau\u00b7send", "zun\u00b7gen", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "ADV", "APPR", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die Juno beut ihm dar den schl\u00fcssel zu den sch\u00e4tzen/", "tokens": ["Die", "Ju\u00b7no", "beut", "ihm", "dar", "den", "schl\u00fcs\u00b7sel", "zu", "den", "sch\u00e4t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "ART", "NN", "APPR", "ART", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Daran es gar zu offt dem strengen juncker fehlt:", "tokens": ["Da\u00b7ran", "es", "gar", "zu", "offt", "dem", "stren\u00b7gen", "jun\u00b7cker", "fehlt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "PTKA", "ADV", "ART", "ADJA", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Minerva steht bereit den hut ihm auffzusetzen/", "tokens": ["Mi\u00b7ner\u00b7va", "steht", "be\u00b7reit", "den", "hut", "ihm", "auff\u00b7zu\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "ART", "VVFIN", "PPER", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Der von der niedrigkeit ihn weit entfernet zehlt:", "tokens": ["Der", "von", "der", "nied\u00b7rig\u00b7keit", "ihn", "weit", "ent\u00b7fer\u00b7net", "zehlt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PPER", "ADJD", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die liebes-g\u00f6ttin selbst/ der sch\u00f6nheit richterin/", "tokens": ["Die", "lie\u00b7bes\u00b7g\u00f6t\u00b7tin", "selbst", "/", "der", "sch\u00f6n\u00b7heit", "rich\u00b7te\u00b7rin", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "ART", "NN", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Reicht diesem werthen sohn ihr liebstes kleinod hin.", "tokens": ["Reicht", "die\u00b7sem", "wert\u00b7hen", "sohn", "ihr", "liebs\u00b7tes", "klei\u00b7nod", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "So r\u00fchmt nun/ wie ihr wollt/ den Adel eurer ahnen/", "tokens": ["So", "r\u00fchmt", "nun", "/", "wie", "ihr", "wollt", "/", "den", "A\u00b7del", "eu\u00b7rer", "ah\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$(", "PWAV", "PPER", "VMFIN", "$(", "ART", "NN", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dir ihr sonst nichts besitzt das r\u00fchmens w\u00fcrdig ist:", "tokens": ["Dir", "ihr", "sonst", "nichts", "be\u00b7sitzt", "das", "r\u00fch\u00b7mens", "w\u00fcr\u00b7dig", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "PIS", "VVFIN", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Trotzt immer auff den kram zerlappter krieges-fahnen/", "tokens": ["Trotzt", "im\u00b7mer", "auff", "den", "kram", "zer\u00b7lapp\u00b7ter", "krie\u00b7ge\u00b7sfah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und pflantzt die unart fort auff euers vaters mist.", "tokens": ["Und", "pflantzt", "die", "un\u00b7art", "fort", "auff", "eu\u00b7ers", "va\u00b7ters", "mist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJD", "PTKVZ", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gelahrheit legt inde\u00df ein ander r\u00fcsthau\u00df an/", "tokens": ["Ge\u00b7lahr\u00b7heit", "legt", "in\u00b7de\u00df", "ein", "an\u00b7der", "r\u00fcst\u00b7hau\u00df", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "ADJD", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das auch die richtschnur selbst mit nichten tadeln kan.", "tokens": ["Das", "auch", "die", "richt\u00b7schnur", "selbst", "mit", "nich\u00b7ten", "ta\u00b7deln", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ADV", "APPR", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ihr helm ist die gedult bey emsigem studieren/", "tokens": ["Ihr", "helm", "ist", "die", "ge\u00b7dult", "bey", "em\u00b7si\u00b7gem", "stu\u00b7die\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Darauff ein gr\u00fcner busch von hoffnungs-federn steckt:", "tokens": ["Dar\u00b7auff", "ein", "gr\u00fc\u00b7ner", "busch", "von", "hoff\u00b7nungs\u00b7fe\u00b7dern", "steckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erfahrung pfleget sie an pantzers statt zu f\u00fchren/", "tokens": ["Er\u00b7fah\u00b7rung", "pfle\u00b7get", "sie", "an", "pant\u00b7zers", "statt", "zu", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und demut ist der schild/ der ihren leib bedeckt.", "tokens": ["Und", "de\u00b7mut", "ist", "der", "schild", "/", "der", "ih\u00b7ren", "leib", "be\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ART", "ADJD", "$(", "ART", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die kluge wachsamkeit ist ihr ber\u00fchmtes schwerd/", "tokens": ["Die", "klu\u00b7ge", "wach\u00b7sam\u00b7keit", "ist", "ihr", "be\u00b7r\u00fchm\u00b7tes", "schwerd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ein geschicktes buch das beste tummel-pferd.", "tokens": ["Und", "ein", "ge\u00b7schick\u00b7tes", "buch", "das", "bes\u00b7te", "tum\u00b7mel\u00b7pferd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ihr wapen ist ein feld/ halb wei\u00df/ halb blau gemahlet/", "tokens": ["Ihr", "wa\u00b7pen", "ist", "ein", "feld", "/", "halb", "wei\u00df", "/", "halb", "blau", "ge\u00b7mah\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$(", "ADJD", "VVFIN", "$(", "ADJD", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Darinn Medusen haupt und schlangen-haar erscheint;", "tokens": ["Da\u00b7rinn", "Me\u00b7du\u00b7sen", "haupt", "und", "schlan\u00b7gen\u00b7haar", "er\u00b7scheint", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "NN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wei\u00df zeigt die unschuld an/ so in dem wandel strahlet/", "tokens": ["Wei\u00df", "zeigt", "die", "un\u00b7schuld", "an", "/", "so", "in", "dem", "wan\u00b7del", "strah\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$(", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alle thaten schm\u00fcckt: Blau da\u00df mans treulich meynt.", "tokens": ["Und", "al\u00b7le", "tha\u00b7ten", "schm\u00fcckt", ":", "Blau", "da\u00df", "mans", "treu\u00b7lich", "meynt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "VVFIN", "$.", "NN", "KOUS", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Und der bekandte kopff/ so manchen feind erschreckt/", "tokens": ["Und", "der", "be\u00b7kand\u00b7te", "kopff", "/", "so", "man\u00b7chen", "feind", "er\u00b7schreckt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$(", "ADV", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zielt auff die wunder-krafft/ die in den k\u00fcnsten steckt.", "tokens": ["Zielt", "auff", "die", "wun\u00b7der\u00b7krafft", "/", "die", "in", "den", "k\u00fcns\u00b7ten", "steckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$(", "ART", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Der wahl-spruch/ den sie ihr aus tausenden erwehlet/", "tokens": ["Der", "wahl\u00b7spruch", "/", "den", "sie", "ihr", "aus", "tau\u00b7sen\u00b7den", "er\u00b7weh\u00b7let", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "PPER", "PPER", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gieng kurtze zeit zuvor durch Alexanders mund/", "tokens": ["Gieng", "kurt\u00b7ze", "zeit", "zu\u00b7vor", "durch", "A\u00b7lex\u00b7an\u00b7ders", "mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "ADV", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Eh\u2019 ihn des himmels-schlu\u00df den todten zugezehlet/", "tokens": ["Eh'", "ihn", "des", "him\u00b7mels\u00b7schlu\u00df", "den", "tod\u00b7ten", "zu\u00b7ge\u00b7zeh\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und als die treue schaar noch um sein lager stund;", "tokens": ["Und", "als", "die", "treu\u00b7e", "schaar", "noch", "um", "sein", "la\u00b7ger", "stund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Er sprach: Dem w\u00fcrdigsten verla\u00df ich meinen thron.", "tokens": ["Er", "sprach", ":", "Dem", "w\u00fcr\u00b7digs\u00b7ten", "ver\u00b7la\u00df", "ich", "mei\u00b7nen", "thron", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PDS", "VAFIN", "VVIMP", "PPER", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Dem w\u00fcrdigsten/ spricht sie/ geh\u00f6rt mein ehren-lohn.", "tokens": ["Dem", "w\u00fcr\u00b7digs\u00b7ten", "/", "spricht", "sie", "/", "ge\u00b7h\u00f6rt", "mein", "eh\u00b7ren\u00b7lohn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "VVFIN", "PPER", "$(", "VVFIN", "PPOSAT", "NN", "$."], "meter": "----+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Zu dieser hoheit kan kein kahler juncker kommen/", "tokens": ["Zu", "die\u00b7ser", "ho\u00b7heit", "kan", "kein", "kah\u00b7ler", "jun\u00b7cker", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "PIAT", "ADJA", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nie gesch\u00e4fftig ist/ als wenn er hasen hetzt.", "tokens": ["Der", "nie", "ge\u00b7sch\u00e4ff\u00b7tig", "ist", "/", "als", "wenn", "er", "ha\u00b7sen", "hetzt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "$(", "KOKOM", "KOUS", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du aber/ edler held/ bist freundlich auffgenommen/", "tokens": ["Du", "a\u00b7ber", "/", "ed\u00b7ler", "held", "/", "bist", "freund\u00b7lich", "auff\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "ADJA", "NN", "$(", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hast den purpur-hut h\u00f6chst-w\u00fcrdig auffgesetzt.", "tokens": ["Und", "hast", "den", "pur\u00b7pur\u00b7hut", "h\u00f6chst\u00b7w\u00fcr\u00b7dig", "auff\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer nun auff gleichen schlag sich auffw\u00e4rts schwingen kan/", "tokens": ["Wer", "nun", "auff", "glei\u00b7chen", "schlag", "sich", "auf\u00b7fw\u00e4rts", "schwin\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ADJA", "VVFIN", "PRF", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Macht durch den adlers-flug sich selbst zum edelmann.", "tokens": ["Macht", "durch", "den", "ad\u00b7ler\u00b7sflug", "sich", "selbst", "zum", "e\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PRF", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Dem dieses nicht vergunt/ bewundert nur dein gl\u00e4ntzen;", "tokens": ["Dem", "die\u00b7ses", "nicht", "ver\u00b7gunt", "/", "be\u00b7wun\u00b7dert", "nur", "dein", "gl\u00e4nt\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "PTKNEG", "ADJD", "$(", "VVFIN", "ADV", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du bist der sonnen gleich/ die hat ihr eigen licht/", "tokens": ["Du", "bist", "der", "son\u00b7nen", "gleich", "/", "die", "hat", "ihr", "ei\u00b7gen", "licht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "$(", "PDS", "VAFIN", "PPER", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Adel/ den du f\u00fchrst/ hegt nicht so schlechte grentzen/", "tokens": ["Der", "A\u00b7del", "/", "den", "du", "f\u00fchrst", "/", "hegt", "nicht", "so", "schlech\u00b7te", "grent\u00b7zen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "PPER", "VVFIN", "$(", "VVFIN", "PTKNEG", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dadurch der scharffe zahn des tollen neides bricht.", "tokens": ["Da\u00b7durch", "der", "scharf\u00b7fe", "zahn", "des", "tol\u00b7len", "nei\u00b7des", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Di\u00df ist der sch\u00f6ne danck/ wohl-edler/ f\u00fcr den flei\u00df", "tokens": ["Di\u00df", "ist", "der", "sch\u00f6\u00b7ne", "danck", "/", "wohl\u00b7ed\u00b7ler", "/", "f\u00fcr", "den", "flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "NE", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den die gelehrte zunfft nicht gnug zu r\u00fchmen wei\u00df.", "tokens": ["Den", "die", "ge\u00b7lehr\u00b7te", "zunfft", "nicht", "gnug", "zu", "r\u00fch\u00b7men", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "PTKNEG", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Das auge Schlesiens/ der st\u00e4dte zier und krone/", "tokens": ["Das", "au\u00b7ge", "Schle\u00b7si\u00b7ens", "/", "der", "st\u00e4d\u00b7te", "zier", "und", "kro\u00b7ne", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Budorgis freuet sich; es jauchzet Herren-stadt;", "tokens": ["Bu\u00b7dor\u00b7gis", "freu\u00b7et", "sich", ";", "es", "jauch\u00b7zet", "Her\u00b7ren\u00b7stadt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "$.", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Saline schmeichelt dir als neuem ehren-sohne;", "tokens": ["Sa\u00b7li\u00b7ne", "schmei\u00b7chelt", "dir", "als", "neu\u00b7em", "eh\u00b7ren\u00b7soh\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "KOUS", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Den sie nur gar zu gern in ihren armen hat.", "tokens": ["Den", "sie", "nur", "gar", "zu", "gern", "in", "ih\u00b7ren", "ar\u00b7men", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "PTKA", "ADV", "APPR", "PPOSAT", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja was die feder itzt nicht f\u00fcglich melden kan/", "tokens": ["Ja", "was", "die", "fe\u00b7der", "itzt", "nicht", "f\u00fcg\u00b7lich", "mel\u00b7den", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PRELS", "ART", "NN", "ADV", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Beut ", "tokens": ["Beut"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.18": {"line.1": {"text": "Indes da manche faust sich h\u00f6chst verbunden sch\u00e4tzet/", "tokens": ["In\u00b7des", "da", "man\u00b7che", "faust", "sich", "h\u00f6chst", "ver\u00b7bun\u00b7den", "sch\u00e4t\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "VVFIN", "PRF", "ADV", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu steigen in dein lob durch ein geschicktes blat/", "tokens": ["Zu", "stei\u00b7gen", "in", "dein", "lob", "durch", "ein", "ge\u00b7schick\u00b7tes", "blat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wird ein kurtzer wunsch von mir hieher gesetzet/", "tokens": ["So", "wird", "ein", "kurt\u00b7zer", "wunsch", "von", "mir", "hie\u00b7her", "ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "APPR", "PPER", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der wenig von der kunst ge\u00fcbter dichter hat:", "tokens": ["Der", "we\u00b7nig", "von", "der", "kunst", "ge\u00b7\u00fcb\u00b7ter", "dich\u00b7ter", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wohl-edler musen-freund/ sey himmel-ab begl\u00fcckt;", "tokens": ["Wohl\u00b7ed\u00b7ler", "mu\u00b7sen\u00b7freund", "/", "sey", "him\u00b7mel\u00b7ab", "be\u00b7gl\u00fcckt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So lange/ bi\u00df der artzt zum patienten schickt.", "tokens": ["So", "lan\u00b7ge", "/", "bi\u00df", "der", "artzt", "zum", "pa\u00b7ti\u00b7en\u00b7ten", "schickt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}