{"textgrid.poem.48641": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "4. Heinsii sein holl\u00e4ndisches Domin\u00e6 servitium libertatis summa est", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Alle, die ihr habet Neid", "tokens": ["Al\u00b7le", ",", "die", "ihr", "ha\u00b7bet", "Neid"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "PPER", "VAFIN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und auf mich erz\u00fcrnet seid,", "tokens": ["und", "auf", "mich", "er\u00b7z\u00fcr\u00b7net", "seid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "la\u00dft nun blicken euren Mut", "tokens": ["la\u00dft", "nun", "bli\u00b7cken", "eu\u00b7ren", "Mut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00fcber mein ber\u00fchmtstes Gut!", "tokens": ["\u00fc\u00b7ber", "mein", "be\u00b7r\u00fchmts\u00b7tes", "Gut", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wisset, da\u00df mein Gl\u00fccke steht", "tokens": ["Wis\u00b7set", ",", "da\u00df", "mein", "Gl\u00fc\u00b7cke", "steht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und euch Allen \u00fcbergeht!", "tokens": ["und", "euch", "Al\u00b7len", "\u00fc\u00b7ber\u00b7geht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemand ist so gro\u00df von Kraft,", "tokens": ["Nie\u00b7mand", "ist", "so", "gro\u00df", "von", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "der mir was zu schaffen schafft.", "tokens": ["der", "mir", "was", "zu", "schaf\u00b7fen", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ganz kein K\u00f6nig auf der Welt", "tokens": ["Ganz", "kein", "K\u00f6\u00b7nig", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ist; der mir die Wage h\u00e4lt.", "tokens": ["ist", ";", "der", "mir", "die", "Wa\u00b7ge", "h\u00e4lt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$.", "ART", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "F\u00fcrsten, Herren, den und dich", "tokens": ["F\u00fcrs\u00b7ten", ",", "Her\u00b7ren", ",", "den", "und", "dich"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "ART", "KON", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "stell' ich weit, weit unter mich.", "tokens": ["stell'", "ich", "weit", ",", "weit", "un\u00b7ter", "mich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "ADJD", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Gestern sp\u00e4te bei der Nacht", "tokens": ["Ge\u00b7stern", "sp\u00e4\u00b7te", "bei", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "hab' ich den Stand an mich bracht,", "tokens": ["hab'", "ich", "den", "Stand", "an", "mich", "bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "als ich ward der Sch\u00f6nsten Knecht,", "tokens": ["als", "ich", "ward", "der", "Sch\u00f6ns\u00b7ten", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "die den Namen f\u00fchrt mit Recht.", "tokens": ["die", "den", "Na\u00b7men", "f\u00fchrt", "mit", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Alle meine Zier und Pracht", "tokens": ["Al\u00b7le", "mei\u00b7ne", "Zier", "und", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ist kein Reichtum, keine Macht,", "tokens": ["ist", "kein", "Reich\u00b7tum", ",", "kei\u00b7ne", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nur da\u00df sie eins g\u00fcnstiglich", "tokens": ["nur", "da\u00df", "sie", "eins", "g\u00fcns\u00b7tig\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PIS", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "von der Seite sah auf mich,", "tokens": ["von", "der", "Sei\u00b7te", "sah", "auf", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "da\u00df sie mir gab ihren Mund", "tokens": ["da\u00df", "sie", "mir", "gab", "ih\u00b7ren", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "der mich t\u00f6tlich machet wund;", "tokens": ["der", "mich", "t\u00f6t\u00b7lich", "ma\u00b7chet", "wund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da mein' arme Seele webt,", "tokens": ["da", "mein'", "ar\u00b7me", "See\u00b7le", "webt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da sie wohnt und allzeit lebt.", "tokens": ["da", "sie", "wohnt", "und", "all\u00b7zeit", "lebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Mit den T\u00fcren von Koral,", "tokens": ["Mit", "den", "T\u00fc\u00b7ren", "von", "Ko\u00b7ral", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da Kupido hat den Saal,", "tokens": ["da", "Ku\u00b7pi\u00b7do", "hat", "den", "Saal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "spielte sie ein liebes Spiel.", "tokens": ["spiel\u00b7te", "sie", "ein", "lie\u00b7bes", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine Lippen war'n ihr Ziel.", "tokens": ["Mei\u00b7ne", "Lip\u00b7pen", "wa\u00b7r'n", "ihr", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Drauf gab sie ein Lachen drein,", "tokens": ["Drauf", "gab", "sie", "ein", "La\u00b7chen", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "das nicht k\u00f6nte sachter sein.", "tokens": ["das", "nicht", "k\u00f6n\u00b7te", "sach\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Di\u00df besinnet so mein Sin,", "tokens": ["Di\u00df", "be\u00b7sin\u00b7net", "so", "mein", "Sin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df ich tot bei Leben bin.", "tokens": ["da\u00df", "ich", "tot", "bei", "Le\u00b7ben", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Und die Worte, die f\u00fcr Pein", "tokens": ["Und", "die", "Wor\u00b7te", ",", "die", "f\u00fcr", "Pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "mein Herz hei\u00dfen sicher sein,", "tokens": ["mein", "Herz", "hei\u00b7\u00dfen", "si\u00b7cher", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und der g\u00f6ttliche Verstand,", "tokens": ["und", "der", "g\u00f6tt\u00b7li\u00b7che", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "den der Himmel hat gesandt,", "tokens": ["den", "der", "Him\u00b7mel", "hat", "ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "das ist Honig, das ist Wein,", "tokens": ["das", "ist", "Ho\u00b7nig", ",", "das", "ist", "Wein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "$,", "PDS", "VAFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "das soll meine Z\u00e4hlung sein!", "tokens": ["das", "soll", "mei\u00b7ne", "Z\u00e4h\u00b7lung", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hierf\u00fcr, wie auch will mein Sin,", "tokens": ["Hier\u00b7f\u00fcr", ",", "wie", "auch", "will", "mein", "Sin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PWAV", "ADV", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "ist nun meine Freiheit hin.", "tokens": ["ist", "nun", "mei\u00b7ne", "Frei\u00b7heit", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}