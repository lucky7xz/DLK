{"textgrid.poem.50428": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "17. Heloise an Abelard", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mit Schmertzen kam' es mir zu Ohren,", "tokens": ["Mit", "Schmert\u00b7zen", "kam'", "es", "mir", "zu", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dass du, ", "tokens": ["Dass", "du", ","], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "PPER", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Dass dich mein Ohm so sehr gekr\u00e4nckt:", "tokens": ["Dass", "dich", "mein", "Ohm", "so", "sehr", "ge\u00b7kr\u00e4nckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach w\u00e4rt ihr beyde aufgehenckt.", "tokens": ["Ach", "w\u00e4rt", "ihr", "bey\u00b7de", "auf\u00b7ge\u00b7henckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "H\u00e4ttst du mir nicht gelehrt ", "tokens": ["H\u00e4ttst", "du", "mir", "nicht", "ge\u00b7lehrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "So w\u00e4r ich ", "tokens": ["So", "w\u00e4r", "ich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Und w\u00fcst' itzt nicht zu meiner Reu',", "tokens": ["Und", "w\u00fcst'", "itzt", "nicht", "zu", "mei\u00b7ner", "Reu'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dass ich ein ", "tokens": ["Dass", "ich", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Doch ohne mir den Kopf zu brechen,", "tokens": ["Doch", "oh\u00b7ne", "mir", "den", "Kopf", "zu", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So werd' ich mich an dir schon r\u00e4chen;", "tokens": ["So", "werd'", "ich", "mich", "an", "dir", "schon", "r\u00e4\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Und weil man es so gerne w\u00fcst',", "tokens": ["Und", "weil", "man", "es", "so", "ger\u00b7ne", "w\u00fcst'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Im kurtzen sagen, ", "tokens": ["Im", "kurt\u00b7zen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}}}}}