{"textgrid.poem.57071": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einem Kloster, voll von Nonnen,", "tokens": ["Ei\u00b7nem", "Klos\u00b7ter", ",", "voll", "von", "Non\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "waren Menschen wohlgesonnen.", "tokens": ["wa\u00b7ren", "Men\u00b7schen", "wohl\u00b7ge\u00b7son\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und sie schickten, gute Christen,", "tokens": ["Und", "sie", "schick\u00b7ten", ",", "gu\u00b7te", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihm nach Rom die sch\u00f6nsten Kisten:", "tokens": ["ihm", "nach", "Rom", "die", "sch\u00f6ns\u00b7ten", "Kis\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00c4pfel, Birnen, Kuchen, Socken,", "tokens": ["\u00c4p\u00b7fel", ",", "Bir\u00b7nen", ",", "Ku\u00b7chen", ",", "So\u00b7cken", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "eine Spieluhr, kleine Glocken,", "tokens": ["ei\u00b7ne", "Spie\u00b7luhr", ",", "klei\u00b7ne", "Glo\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Gartenwerkzeug, Schuhe, Sch\u00fcrzen ...", "tokens": ["Gar\u00b7ten\u00b7werk\u00b7zeug", ",", "Schu\u00b7he", ",", "Sch\u00fcr\u00b7zen", "..."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Au\u00dfen aber stand: Nicht st\u00fcrzen!", "tokens": ["Au\u00b7\u00dfen", "a\u00b7ber", "stand", ":", "Nicht", "st\u00fcr\u00b7zen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$.", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Oder: Vorsicht! oder welche", "tokens": ["O\u00b7der", ":", "Vor\u00b7sicht", "!", "o\u00b7der", "wel\u00b7che"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$.", "NN", "$.", "KON", "PWAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wiesen schwarzgemalte Kelche.", "tokens": ["wie\u00b7sen", "schwarz\u00b7ge\u00b7mal\u00b7te", "Kel\u00b7che", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und auf jeder Kiste stand", "tokens": ["Und", "auf", "je\u00b7der", "Kis\u00b7te", "stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbespedito\u00ab, kurzerhand.", "tokens": ["\u00bb", "es\u00b7pe\u00b7di\u00b7to", "\u00ab", ",", "kur\u00b7zer\u00b7hand", "."], "token_info": ["punct", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Unsre Nonnen, die nicht wu\u00dften,", "tokens": ["Uns\u00b7re", "Non\u00b7nen", ",", "die", "nicht", "wu\u00df\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wem sie daf\u00fcr danken mu\u00dften,", "tokens": ["wem", "sie", "da\u00b7f\u00fcr", "dan\u00b7ken", "mu\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PAV", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "denn das Gut kam anonym,", "tokens": ["denn", "das", "Gut", "kam", "an\u00b7o\u00b7nym", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "dankten vorderhand nur IHM,", "tokens": ["dank\u00b7ten", "vor\u00b7der\u00b7hand", "nur", "IhM", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "rieten aber doch ohn Ende", "tokens": ["rie\u00b7ten", "a\u00b7ber", "doch", "ohn", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "nach dem Sender solcher Spende.", "tokens": ["nach", "dem", "Sen\u00b7der", "sol\u00b7cher", "Spen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Pl\u00f6tzlich rief die Schwester Pia", "tokens": ["Pl\u00f6tz\u00b7lich", "rief", "die", "Schwes\u00b7ter", "Pia"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "eines Morgens: Santa mia!", "tokens": ["ei\u00b7nes", "Mor\u00b7gens", ":", "San\u00b7ta", "mia", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "$.", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Nicht von Juden, nicht von Christen", "tokens": ["Nicht", "von", "Ju\u00b7den", ",", "nicht", "von", "Chris\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "NN", "$,", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "stammen diese Wunderkisten \u2013", "tokens": ["stam\u00b7men", "die\u00b7se", "Wun\u00b7der\u00b7kis\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Expeditus, o Geschwister,", "tokens": ["Ex\u00b7pe\u00b7di\u00b7tus", ",", "o", "Ge\u00b7schwis\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "NN", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.2": {"text": "hei\u00dft er, und ein Heiliger ist er!", "tokens": ["hei\u00dft", "er", ",", "und", "ein", "Hei\u00b7li\u00b7ger", "ist", "er", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "ART", "NN", "VAFIN", "PPER", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Und sie fielen auf die Kniee.", "tokens": ["Und", "sie", "fie\u00b7len", "auf", "die", "Kni\u00b7ee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Heilige sprach: Siehe!", "tokens": ["Und", "der", "Hei\u00b7li\u00b7ge", "sprach", ":", "Sie\u00b7he", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "$.", "VVIMP", "$."], "meter": "--+--++-", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "Endlich habt ihr mich erkannt.", "tokens": ["End\u00b7lich", "habt", "ihr", "mich", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und nun malt mich an die Wand!", "tokens": ["Und", "nun", "malt", "mich", "an", "die", "Wand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Und sie lie\u00dfen einen kommen,", "tokens": ["Und", "sie", "lie\u00b7\u00dfen", "ei\u00b7nen", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "einen Maler, einen frommen.", "tokens": ["ei\u00b7nen", "Ma\u00b7ler", ",", "ei\u00b7nen", "from\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Und es malte der Artiste", "tokens": ["Und", "es", "mal\u00b7te", "der", "Ar\u00b7tis\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Expeditum mit der Kiste.", "tokens": ["Ex\u00b7pe\u00b7di\u00b7tum", "mit", "der", "Kis\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Und der Kult gewann an Breite.", "tokens": ["Und", "der", "Kult", "ge\u00b7wann", "an", "Brei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jeder, der beschenkt ward, weihte", "tokens": ["Je\u00b7der", ",", "der", "be\u00b7schenkt", "ward", ",", "weih\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PIS", "$,", "PRELS", "VVPP", "VAFIN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "kleine Tafeln ihm und Kerzen.", "tokens": ["klei\u00b7ne", "Ta\u00b7feln", "ihm", "und", "Ker\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kurz, er war in aller Herzen.", "tokens": ["Kurz", ",", "er", "war", "in", "al\u00b7ler", "Her\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}