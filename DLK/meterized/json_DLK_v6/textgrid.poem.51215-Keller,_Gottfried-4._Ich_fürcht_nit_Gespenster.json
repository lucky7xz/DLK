{"textgrid.poem.51215": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "4. Ich f\u00fcrcht nit Gespenster", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich f\u00fcrcht nit Gespenster,", "tokens": ["Ich", "f\u00fcrcht", "nit", "Ge\u00b7spens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Keine Hexen und Feen,", "tokens": ["Kei\u00b7ne", "He\u00b7xen", "und", "Feen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und lieb's, in ihre tiefen", "tokens": ["Und", "lie\u00b7b's", ",", "in", "ih\u00b7re", "tie\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "$,", "APPR", "PPOSAT", "ADJA"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Gl\u00fchaugen zu sehn.", "tokens": ["Gl\u00fc\u00b7hau\u00b7gen", "zu", "sehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Am Wald in dem gr\u00fcnen", "tokens": ["Am", "Wald", "in", "dem", "gr\u00fc\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Unheimlichen See,", "tokens": ["Un\u00b7heim\u00b7li\u00b7chen", "See", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Da wohnet ein Nachtweib,", "tokens": ["Da", "woh\u00b7net", "ein", "Nacht\u00b7weib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Das ist wei\u00df wie der Schnee.", "tokens": ["Das", "ist", "wei\u00df", "wie", "der", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Es ha\u00dft meiner Sch\u00f6nheit", "tokens": ["Es", "ha\u00dft", "mei\u00b7ner", "Sch\u00f6n\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Unschuldige Zier;", "tokens": ["Un\u00b7schul\u00b7di\u00b7ge", "Zier", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wenn ich sp\u00e4t noch vorbeigeh,", "tokens": ["Wenn", "ich", "sp\u00e4t", "noch", "vor\u00b7bei\u00b7geh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So zankt es mit mir.", "tokens": ["So", "zankt", "es", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "J\u00fcngst, als ich im Mondschein", "tokens": ["J\u00fcngst", ",", "als", "ich", "im", "Mond\u00b7schein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Am Waldwasser stand,", "tokens": ["Am", "Wald\u00b7was\u00b7ser", "stand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Fuhr sie auf ohne Schleier,", "tokens": ["Fuhr", "sie", "auf", "oh\u00b7ne", "Schlei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ohne alles Gewand.", "tokens": ["Oh\u00b7ne", "al\u00b7les", "Ge\u00b7wand", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Es schwammen ihre Glieder", "tokens": ["Es", "schwam\u00b7men", "ih\u00b7re", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "In der taghellen Nacht;", "tokens": ["In", "der", "ta\u00b7ghel\u00b7len", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Himmel war trunken", "tokens": ["Der", "Him\u00b7mel", "war", "trun\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Von der h\u00f6llischen Pracht.", "tokens": ["Von", "der", "h\u00f6l\u00b7li\u00b7schen", "Pracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Aber ich hab entbl\u00f6\u00dfet", "tokens": ["A\u00b7ber", "ich", "hab", "ent\u00b7bl\u00f6\u00b7\u00dfet"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "VVFIN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Meine lebendige Brust;", "tokens": ["Mei\u00b7ne", "le\u00b7ben\u00b7di\u00b7ge", "Brust", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Da hat sie mit Schande", "tokens": ["Da", "hat", "sie", "mit", "Schan\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Versinken gemu\u00dft!", "tokens": ["Ver\u00b7sin\u00b7ken", "ge\u00b7mu\u00dft", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}}}}