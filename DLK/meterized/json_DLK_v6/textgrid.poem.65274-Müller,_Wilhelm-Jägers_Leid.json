{"textgrid.poem.65274": {"metadata": {"author": {"name": "M\u00fcller, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "J\u00e4gers Leid", "genre": "verse", "period": "N.A.", "pub_year": 1810, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es hat so gr\u00fcn ges\u00e4uselt", "tokens": ["Es", "hat", "so", "gr\u00fcn", "ge\u00b7s\u00e4u\u00b7selt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Am Fenster die ganze Nacht \u2013", "tokens": ["Am", "Fens\u00b7ter", "die", "gan\u00b7ze", "Nacht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mein Schatz im Tannenwalde,", "tokens": ["Mein", "Schatz", "im", "Tan\u00b7nen\u00b7wal\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hast wohl an mich gedacht?", "tokens": ["Hast", "wohl", "an", "mich", "ge\u00b7dacht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und wann alle B\u00e4ume rauschen", "tokens": ["Und", "wann", "al\u00b7le", "B\u00e4u\u00b7me", "rau\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Im weiten Jagdrevier,", "tokens": ["Im", "wei\u00b7ten", "Jagd\u00b7re\u00b7vier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und weht kein L\u00fcftchen am Himmel,", "tokens": ["Und", "weht", "kein", "L\u00fcft\u00b7chen", "am", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Herzliebste, dann fing' ich von dir!", "tokens": ["Herz\u00b7liebs\u00b7te", ",", "dann", "fing'", "ich", "von", "dir", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Und wann alle Zweige sich neigen", "tokens": ["Und", "wann", "al\u00b7le", "Zwei\u00b7ge", "sich", "nei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIAT", "NN", "PRF", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und nicken dir Gr\u00fc\u00dfe zu,", "tokens": ["Und", "ni\u00b7cken", "dir", "Gr\u00fc\u00b7\u00dfe", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Herzliebste, das ist mein Sehnen,", "tokens": ["Herz\u00b7liebs\u00b7te", ",", "das", "ist", "mein", "Seh\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Hat nimmer Rast, noch Ruh'!", "tokens": ["Hat", "nim\u00b7mer", "Rast", ",", "noch", "Ruh'", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$,", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ach Welt, ich mu\u00df dich fragen,", "tokens": ["Ach", "Welt", ",", "ich", "mu\u00df", "dich", "fra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Warum du bist so weit?", "tokens": ["Wa\u00b7rum", "du", "bist", "so", "weit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach Liebe, ferne Liebe,", "tokens": ["Ach", "Lie\u00b7be", ",", "fer\u00b7ne", "Lie\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Warum nicht hei\u00dft du Leid?", "tokens": ["Wa\u00b7rum", "nicht", "hei\u00dft", "du", "Leid", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich m\u00f6chte die B\u00fcchse laden,", "tokens": ["Ich", "m\u00f6ch\u00b7te", "die", "B\u00fcch\u00b7se", "la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nicht laden mit Pulver und Schrot,", "tokens": ["Nicht", "la\u00b7den", "mit", "Pul\u00b7ver", "und", "Schrot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Ich m\u00f6cht' in die L\u00fcfte schie\u00dfen", "tokens": ["Ich", "m\u00f6cht'", "in", "die", "L\u00fcf\u00b7te", "schie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "All' meine Liebesnoth.", "tokens": ["All'", "mei\u00b7ne", "Lie\u00b7bes\u00b7noth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und wenn von allen B\u00e4umen", "tokens": ["Und", "wenn", "von", "al\u00b7len", "B\u00e4u\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "St\u00fcrzen die Waldv\u00f6gelein,", "tokens": ["St\u00fcr\u00b7zen", "die", "Wald\u00b7v\u00f6\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Dann ist der Schu\u00df gefallen \u2013", "tokens": ["Dann", "ist", "der", "Schu\u00df", "ge\u00b7fal\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wer soll nun S\u00e4nger sein?", "tokens": ["Wer", "soll", "nun", "S\u00e4n\u00b7ger", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}