{"textgrid.poem.31740": {"metadata": {"author": {"name": "Weerth, Georg", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der alte Wirt in Lancashire,", "genre": "verse", "period": "N.A.", "pub_year": 1839, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der alte Wirt in Lancashire,", "tokens": ["Der", "al\u00b7te", "Wirt", "in", "Lan\u00b7cas\u00b7hi\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der zapft ein j\u00e4mmerliches Bier.", "tokens": ["Der", "zapft", "ein", "j\u00e4m\u00b7mer\u00b7li\u00b7ches", "Bier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er zapft' es gestern, zapft es heute,", "tokens": ["Er", "zapft'", "es", "ge\u00b7stern", ",", "zapft", "es", "heu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Er zapft es immer f\u00fcr arme Leute.", "tokens": ["Er", "zapft", "es", "im\u00b7mer", "f\u00fcr", "ar\u00b7me", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Die armen Leut in Lancashire,", "tokens": ["Die", "ar\u00b7men", "Leut", "in", "Lan\u00b7cas\u00b7hi\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die gehen oft durch seine T\u00fcr;", "tokens": ["Die", "ge\u00b7hen", "oft", "durch", "sei\u00b7ne", "T\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie gehn in Schuhen, die verschlissen,", "tokens": ["Sie", "gehn", "in", "Schu\u00b7hen", ",", "die", "ver\u00b7schlis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie kommen in R\u00f6cken, die zerrissen.", "tokens": ["Sie", "kom\u00b7men", "in", "R\u00f6\u00b7cken", ",", "die", "zer\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "PRELS", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Der erste von dem armen Pack,", "tokens": ["Der", "ers\u00b7te", "von", "dem", "ar\u00b7men", "Pack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ist der bleiche, stille Jack.", "tokens": ["Das", "ist", "der", "blei\u00b7che", ",", "stil\u00b7le", "Jack", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der spricht: \u00bbUnd was ich auch begonnen \u2013", "tokens": ["Der", "spricht", ":", "\u00bb", "Und", "was", "ich", "auch", "be\u00b7gon\u00b7nen", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "$(", "KON", "PWS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hab nimmer Seide dabei gesponnen!\u00ab", "tokens": ["Hab", "nim\u00b7mer", "Sei\u00b7de", "da\u00b7bei", "ge\u00b7spon\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "VVFIN", "PAV", "VVPP", "$.", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Und Tom begann: \u00bbSchon manches Jahr", "tokens": ["Und", "Tom", "be\u00b7gann", ":", "\u00bb", "Schon", "man\u00b7ches", "Jahr"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "$.", "$(", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spann ich die F\u00e4den fein und klar;", "tokens": ["Spann", "ich", "die", "F\u00e4\u00b7den", "fein", "und", "klar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das wollene Kleid mocht manchem frommen \u2013", "tokens": ["Das", "wol\u00b7le\u00b7ne", "Kleid", "mocht", "man\u00b7chem", "from\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "ADJA", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bin selbst aber nie in die Wolle gekommen!\u00ab", "tokens": ["Bin", "selbst", "a\u00b7ber", "nie", "in", "die", "Wol\u00b7le", "ge\u00b7kom\u00b7men", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$.", "$("], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Und Bill darauf: \u00bbMit treuer Hand", "tokens": ["Und", "Bill", "da\u00b7rauf", ":", "\u00bb", "Mit", "treu\u00b7er", "Hand"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "NN", "PAV", "$.", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fchrt ich den Pflug durch britisch Land;", "tokens": ["F\u00fchrt", "ich", "den", "Pflug", "durch", "bri\u00b7tisch", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Saaten sah ich lustig prangen \u2013", "tokens": ["Die", "Saa\u00b7ten", "sah", "ich", "lus\u00b7tig", "pran\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bin selbst aber hungrig nach Bett gegangen!\u00ab", "tokens": ["Bin", "selbst", "a\u00b7ber", "hung\u00b7rig", "nach", "Bett", "ge\u00b7gan\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "APPR", "NN", "VVPP", "$.", "$("], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}}, "stanza.6": {"line.1": {"text": "Und weiter schallt's: \u00bbAus tiefem Schacht", "tokens": ["Und", "wei\u00b7ter", "schallt's", ":", "\u00bb", "Aus", "tie\u00b7fem", "Schacht"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "$.", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Ben manch Fuder Kohlen gebracht;", "tokens": ["Hat", "Ben", "manch", "Fu\u00b7der", "Koh\u00b7len", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PIAT", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Doch als sein Weib ein Kind geboren \u2013", "tokens": ["Doch", "als", "sein", "Weib", "ein", "Kind", "ge\u00b7bo\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Goddam \u2013 ist Weib und Kind erfroren!\u00ab", "tokens": ["God\u00b7dam", "\u2013", "ist", "Weib", "und", "Kind", "er\u00b7fro\u00b7ren", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$(", "VAFIN", "NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und Jack und Tom und Bill und Ben \u2013", "tokens": ["Und", "Jack", "und", "Tom", "und", "Bill", "und", "Ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NN", "KON", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie riefen allesamt: \u00bbGoddam!\u00ab", "tokens": ["Sie", "rie\u00b7fen", "al\u00b7le\u00b7samt", ":", "\u00bb", "God\u00b7dam", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "$(", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und selbe Nacht auf weichem Flaume", "tokens": ["Und", "sel\u00b7be", "Nacht", "auf", "wei\u00b7chem", "Flau\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Reicher lag in b\u00f6sem Traume.", "tokens": ["Ein", "Rei\u00b7cher", "lag", "in", "b\u00f6\u00b7sem", "Trau\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}