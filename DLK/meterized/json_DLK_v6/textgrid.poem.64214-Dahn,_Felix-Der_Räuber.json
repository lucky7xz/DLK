{"textgrid.poem.64214": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Der R\u00e4uber", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Heut' am Vogelherde sa\u00df ich,", "tokens": ["Heut'", "am", "Vo\u00b7gel\u00b7her\u00b7de", "sa\u00df", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo der Buchwald streift ans Feld:", "tokens": ["Wo", "der", "Buch\u00b7wald", "streift", "ans", "Feld", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch des Vogelfangs verga\u00df ich,", "tokens": ["Doch", "des", "Vo\u00b7gel\u00b7fangs", "ver\u00b7ga\u00df", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sah vertr\u00e4umt ins Himmelszelt.", "tokens": ["Sah", "ver\u00b7tr\u00e4umt", "ins", "Him\u00b7mels\u00b7zelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hoch in Wolken kreist er wieder,", "tokens": ["Hoch", "in", "Wol\u00b7ken", "kreist", "er", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jener R\u00e4uber k\u00fchn und klug,", "tokens": ["Je\u00b7ner", "R\u00e4u\u00b7ber", "k\u00fchn", "und", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stark von F\u00e4ngen und Gefieder,", "tokens": ["Stark", "von", "F\u00e4n\u00b7gen", "und", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Scharf von Auge, stolz von Flug.", "tokens": ["Scharf", "von", "Au\u00b7ge", ",", "stolz", "von", "Flug", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Jener Bussard, schrill erkreischend,", "tokens": ["Je\u00b7ner", "Bus\u00b7sard", ",", "schrill", "er\u00b7krei\u00b7schend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "NE", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rittelnd bald an gleichem Ort,", "tokens": ["Rit\u00b7telnd", "bald", "an", "glei\u00b7chem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00fcstern sp\u00e4hend, Beute heischend,", "tokens": ["L\u00fcs\u00b7tern", "sp\u00e4\u00b7hend", ",", "Beu\u00b7te", "hei\u00b7schend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "All' sein Sehnen Raub und Mord:", "tokens": ["All'", "sein", "Seh\u00b7nen", "Raub", "und", "Mord", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bald im Flugspiel Bogen ziehend,", "tokens": ["Bald", "im", "Flug\u00b7spiel", "Bo\u00b7gen", "zie\u00b7hend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Reglos, schweigend, schattenhaft,", "tokens": ["Reg\u00b7los", ",", "schwei\u00b7gend", ",", "schat\u00b7ten\u00b7haft", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fallend, steigend, nahend, fliehend,", "tokens": ["Fal\u00b7lend", ",", "stei\u00b7gend", ",", "na\u00b7hend", ",", "flie\u00b7hend", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stolz und froh der Schwingen Kraft.", "tokens": ["Stolz", "und", "froh", "der", "Schwin\u00b7gen", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Bussard, frei wie du ist keiner,", "tokens": ["Bus\u00b7sard", ",", "frei", "wie", "du", "ist", "kei\u00b7ner", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "KOKOM", "PPER", "VAFIN", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und, gleich dir im L\u00fcftereich,", "tokens": ["Und", ",", "gleich", "dir", "im", "L\u00fcf\u00b7te\u00b7reich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "PPER", "APPRART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Flog auf Erden nur noch einer", "tokens": ["Flog", "auf", "Er\u00b7den", "nur", "noch", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "ADV", "ADV", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hoch zu Ro\u00df: der W\u00fcstenscheich!", "tokens": ["Hoch", "zu", "Ro\u00df", ":", "der", "W\u00fcs\u00b7ten\u00b7scheich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$.", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ja, du mahnst mich, k\u00fchner Vogel,", "tokens": ["Ja", ",", "du", "mahnst", "mich", ",", "k\u00fch\u00b7ner", "Vo\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An den Scheich, braun, rasch und keck,", "tokens": ["An", "den", "Scheich", ",", "braun", ",", "rasch", "und", "keck", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der von Karmels hohem Kogel", "tokens": ["Der", "von", "Kar\u00b7mels", "ho\u00b7hem", "Ko\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NE", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Niederstie\u00df, der Franken Schreck. \u2013", "tokens": ["Nie\u00b7ders\u00b7tie\u00df", ",", "der", "Fran\u00b7ken", "Schreck", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "H\u00f6re nun, du schriller Schreier,", "tokens": ["H\u00f6\u00b7re", "nun", ",", "du", "schril\u00b7ler", "Schrei\u00b7er", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kreisend hoch im Bogenring,", "tokens": ["Krei\u00b7send", "hoch", "im", "Bo\u00b7gen\u00b7ring", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6re nun, du Taubengeier,", "tokens": ["H\u00f6\u00b7re", "nun", ",", "du", "Tau\u00b7ben\u00b7gei\u00b7er", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie's dem M\u00e4dchengeier ging.", "tokens": ["Wie's", "dem", "M\u00e4d\u00b7chen\u00b7gei\u00b7er", "ging", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Doch: dort meinem Lockfinkweibe", "tokens": ["Doch", ":", "dort", "mei\u00b7nem", "Lock\u00b7fink\u00b7wei\u00b7be"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["KON", "$.", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bleibe fern, bleibst gern du heil:", "tokens": ["Blei\u00b7be", "fern", ",", "bleibst", "gern", "du", "heil", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VVFIN", "ADV", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eisen fliegt dir sonst zu Leibe: \u2013", "tokens": ["Ei\u00b7sen", "fliegt", "dir", "sonst", "zu", "Lei\u00b7be", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf der Sehne liegt mein Pfeil. \u2013", "tokens": ["Auf", "der", "Seh\u00b7ne", "liegt", "mein", "Pfeil", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "H\u00f6re nun! \u2013 Auf schnellstem Rosse,", "tokens": ["H\u00f6\u00b7re", "nun", "!", "\u2013", "Auf", "schnells\u00b7tem", "Ros\u00b7se", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$.", "$(", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unhaschbar, der Otter gleich,", "tokens": ["Un\u00b7haschbar", ",", "der", "Ot\u00b7ter", "gleich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "ADV", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Glitt durch unsre Speergeschosse", "tokens": ["Glitt", "durch", "uns\u00b7re", "Speer\u00b7ge\u00b7schos\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nahend, fliehend Ali Scheich.", "tokens": ["Na\u00b7hend", ",", "flie\u00b7hend", "A\u00b7li", "Scheich", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Von der Seite, wie dem T\u00e4uber", "tokens": ["Von", "der", "Sei\u00b7te", ",", "wie", "dem", "T\u00e4u\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du die Turteltaube rei\u00df'st,", "tokens": ["Du", "die", "Tur\u00b7tel\u00b7tau\u00b7be", "rei\u00df'st", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So durchbrach der k\u00fchne R\u00e4uber,", "tokens": ["So", "durch\u00b7brach", "der", "k\u00fch\u00b7ne", "R\u00e4u\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Der sie n\u00e4chtelang umkreist,", "tokens": ["Der", "sie", "n\u00e4ch\u00b7tel\u00b7ang", "um\u00b7kreist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Jede Pilgerkarawane,", "tokens": ["Je\u00b7de", "Pil\u00b7ger\u00b7ka\u00b7ra\u00b7wa\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die mit Frau'n gen Zion ging:", "tokens": ["Die", "mit", "Frau'n", "gen", "Zi\u00b7on", "ging", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus dem Schatten unsrer Fahne", "tokens": ["Aus", "dem", "Schat\u00b7ten", "uns\u00b7rer", "Fah\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stets das sch\u00f6nste Weib er sing.", "tokens": ["Stets", "das", "sch\u00f6ns\u00b7te", "Weib", "er", "sing", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Und bevor den Sporn nur sp\u00fcrte", "tokens": ["Und", "be\u00b7vor", "den", "Sporn", "nur", "sp\u00fcr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser schwerer Friesenhengst,", "tokens": ["Un\u00b7ser", "schwe\u00b7rer", "Frie\u00b7sen\u00b7hengst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch die W\u00fcste die Entf\u00fchrte", "tokens": ["Durch", "die", "W\u00fcs\u00b7te", "die", "Ent\u00b7f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Trug das Ro\u00df des R\u00e4ubers l\u00e4ngst.", "tokens": ["Trug", "das", "Ro\u00df", "des", "R\u00e4u\u00b7bers", "l\u00e4ngst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Esmeralda de Rivalta,", "tokens": ["Es\u00b7me\u00b7ral\u00b7da", "de", "Ri\u00b7val\u00b7ta", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gabriele Lusignan,", "tokens": ["Ga\u00b7bri\u00b7e\u00b7le", "Lu\u00b7sig\u00b7nan", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bellaflor de Vallecalta,", "tokens": ["Bel\u00b7laf\u00b7lor", "de", "Val\u00b7le\u00b7cal\u00b7ta", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So der freche Feind gewann. \u2013", "tokens": ["So", "der", "fre\u00b7che", "Feind", "ge\u00b7wann", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Doch als Irmengard von Schwaben", "tokens": ["Doch", "als", "Ir\u00b7men\u00b7gard", "von", "Schwa\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NE", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nahm das Kreuz des Pilgerkleids,", "tokens": ["Nahm", "das", "Kreuz", "des", "Pil\u00b7ger\u00b7kleids", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da erbat, statt Ehrengaben,", "tokens": ["Da", "er\u00b7bat", ",", "statt", "Eh\u00b7ren\u00b7ga\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich das Recht mir des Geleits. \u2013", "tokens": ["Ich", "das", "Recht", "mir", "des", "Ge\u00b7leits", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ART", "NN", "PPER", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Tag f\u00fcr Tag nun durft' ich traben,", "tokens": ["Tag", "f\u00fcr", "Tag", "nun", "durft'", "ich", "tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Damask bis Askalon,", "tokens": ["Von", "Da\u00b7mask", "bis", "As\u00b7ka\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NE", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Neben Irmengard von Schwaben: \u2013", "tokens": ["Ne\u00b7ben", "Ir\u00b7men\u00b7gard", "von", "Schwa\u00b7ben", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das war meiner Kreuzfahrt Lohn.", "tokens": ["Das", "war", "mei\u00b7ner", "Kreuz\u00b7fahrt", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "N\u00e4chtens schlugen wir die Zelte,", "tokens": ["N\u00e4ch\u00b7tens", "schlu\u00b7gen", "wir", "die", "Zel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df die Herzogtochter schlief, \u2013", "tokens": ["Da\u00df", "die", "Her\u00b7zog\u00b7toch\u00b7ter", "schlief", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00f6we br\u00fcllte, Schakal bellte,", "tokens": ["L\u00f6\u00b7we", "br\u00fcll\u00b7te", ",", "Scha\u00b7kal", "bell\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch die Herrin ruhte tief:", "tokens": ["Doch", "die", "Her\u00b7rin", "ruh\u00b7te", "tief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Bangensfrei \u2013: sie wu\u00dfte, Walther", "tokens": ["Ban\u00b7gens\u00b7frei", "\u2013", ":", "sie", "wu\u00df\u00b7te", ",", "Walt\u00b7her"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$(", "$.", "PPER", "VVFIN", "$,", "NE"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "Mit dem Speer hielt drau\u00dfen Wacht. \u2013", "tokens": ["Mit", "dem", "Speer", "hielt", "drau\u00b7\u00dfen", "Wacht", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Manches Lied aus deutschem Psalter", "tokens": ["Man\u00b7ches", "Lied", "aus", "deut\u00b7schem", "Psal\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Klang in blaue W\u00fcstennacht.", "tokens": ["Klang", "in", "blau\u00b7e", "W\u00fcs\u00b7ten\u00b7nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Sterne gl\u00e4nzten, Sterne schossen,", "tokens": ["Ster\u00b7ne", "gl\u00e4nz\u00b7ten", ",", "Ster\u00b7ne", "schos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Palmenwipfel wogten leis,", "tokens": ["Pal\u00b7men\u00b7wip\u00b7fel", "wog\u00b7ten", "leis", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und um Mensch und Tiere flossen", "tokens": ["Und", "um", "Mensch", "und", "Tie\u00b7re", "flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fcstend\u00fcnste schwer und hei\u00df.", "tokens": ["W\u00fcs\u00b7ten\u00b7d\u00fcns\u00b7te", "schwer", "und", "hei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Schlaf flo\u00df allbezwingend nieder,", "tokens": ["Schlaf", "flo\u00df", "all\u00b7be\u00b7zwin\u00b7gend", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Selbst die Lagerwache schlief:", "tokens": ["Selbst", "die", "La\u00b7ger\u00b7wa\u00b7che", "schlief", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Langgestreckt im Sand die Glieder", "tokens": ["Lang\u00b7ge\u00b7streckt", "im", "Sand", "die", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schnauften die Kamele tief. \u2013", "tokens": ["Schnauf\u00b7ten", "die", "Ka\u00b7me\u00b7le", "tief", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Pl\u00f6tzlich naht's mit Windeseile: \u2013", "tokens": ["Pl\u00f6tz\u00b7lich", "naht's", "mit", "Win\u00b7de\u00b7sei\u00b7le", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Strau\u00dfenlauf? Gazellenschritt?", "tokens": ["Strau\u00b7\u00dfen\u00b7lauf", "?", "Ga\u00b7zel\u00b7len\u00b7schritt", "?"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leis und rasch wie Todespfeile,", "tokens": ["Leis", "und", "rasch", "wie", "To\u00b7des\u00b7pfei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KOKOM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kaum du, Bussard, fl\u00f6gest mit.", "tokens": ["Kaum", "du", ",", "Bus\u00b7sard", ",", "fl\u00f6\u00b7gest", "mit", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "NE", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Unerwacht, durchbohrt, vom Rosse", "tokens": ["Un\u00b7er\u00b7wacht", ",", "durch\u00b7bohrt", ",", "vom", "Ros\u00b7se"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "VVPP", "$,", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sinkt der Lagerw\u00e4chter rot:", "tokens": ["Sinkt", "der", "La\u00b7ger\u00b7w\u00e4ch\u00b7ter", "rot", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ringsum S\u00e4bel und Geschosse,", "tokens": ["Ring\u00b7sum", "S\u00e4\u00b7bel", "und", "Ge\u00b7schos\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dunkle Reiter und der Tod.", "tokens": ["Dunk\u00b7le", "Rei\u00b7ter", "und", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Vor mir h\u00e4lt ein Pferd: da gleitet's", "tokens": ["Vor", "mir", "h\u00e4lt", "ein", "Pferd", ":", "da", "glei\u00b7tet's"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "$.", "KOUS", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Panthergleich vom Sattel sacht,", "tokens": ["Pan\u00b7ther\u00b7gleich", "vom", "Sat\u00b7tel", "sacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An die Zeltt\u00fcr kauernd schreitet's: \u2013", "tokens": ["An", "die", "Zelt\u00b7t\u00fcr", "kau\u00b7ernd", "schrei\u00b7tet's", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbstirb, denn hier h\u00e4lt Walther Wacht!\u00ab", "tokens": ["\u00bb", "stirb", ",", "denn", "hier", "h\u00e4lt", "Walt\u00b7her", "Wacht", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "$,", "KON", "ADV", "VVFIN", "NE", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Rief's und tief den Speer vergrub ich", "tokens": ["Rie\u00b7f's", "und", "tief", "den", "Speer", "ver\u00b7grub", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "ADJD", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In des Scheichs goldbr\u00fcnn'ge Brust,", "tokens": ["In", "des", "Scheichs", "gold\u00b7br\u00fcnn'\u00b7ge", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Laut den Siegesschrei erhub ich", "tokens": ["Laut", "den", "Sie\u00b7ges\u00b7schrei", "er\u00b7hub", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wir schlugen sie mit Lust:", "tokens": ["Und", "wir", "schlu\u00b7gen", "sie", "mit", "Lust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Folgten eine gute Weil' noch \u2013 \u2013 \u2013", "tokens": ["Folg\u00b7ten", "ei\u00b7ne", "gu\u00b7te", "Weil'", "noch", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ADV", "$(", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Halt, Herr Bussard, du warst schnell, \u2013", "tokens": ["Halt", ",", "Herr", "Bus\u00b7sard", ",", "du", "warst", "schnell", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "NN", "NE", "$,", "PPER", "VAFIN", "ADJD", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber schneller war mein Pfeil noch \u2013:", "tokens": ["A\u00b7ber", "schnel\u00b7ler", "war", "mein", "Pfeil", "noch", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN", "ADV", "$(", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tot nun liegst du, Raubgesell',", "tokens": ["Tot", "nun", "liegst", "du", ",", "Raub\u00b7ge\u00b7sell'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Bei der Finkin, brustdurchschossen!", "tokens": ["Bei", "der", "Fin\u00b7kin", ",", "brust\u00b7durch\u00b7schos\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebe Finkin, bange nicht:", "tokens": ["Lie\u00b7be", "Fin\u00b7kin", ",", "ban\u00b7ge", "nicht", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eh' dich grimm sein Fang umschlossen,", "tokens": ["Eh'", "dich", "grimm", "sein", "Fang", "um\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Traf ihn Walthers Strafgericht.", "tokens": ["Traf", "ihn", "Walt\u00b7hers", "Straf\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Zwitschernd nun, mein Ohr zu laben,", "tokens": ["Zwit\u00b7schernd", "nun", ",", "mein", "Ohr", "zu", "la\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Singst du leise, dankend schier?", "tokens": ["Singst", "du", "lei\u00b7se", ",", "dan\u00b7kend", "schier", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So hat Irmengard von Schwaben", "tokens": ["So", "hat", "Ir\u00b7men\u00b7gard", "von", "Schwa\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dankend auch gefl\u00fcstert mir.", "tokens": ["Dan\u00b7kend", "auch", "ge\u00b7fl\u00fcs\u00b7tert", "mir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}