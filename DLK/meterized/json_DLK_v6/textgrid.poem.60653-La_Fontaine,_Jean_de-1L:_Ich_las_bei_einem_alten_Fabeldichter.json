{"textgrid.poem.60653": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich las bei einem alten Fabeldichter", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich las bei einem alten Fabeldichter", "tokens": ["Ich", "las", "bei", "ei\u00b7nem", "al\u00b7ten", "Fa\u00b7bel\u00b7dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von einem Nagespeck dem Zweiten,", "tokens": ["Von", "ei\u00b7nem", "Na\u00b7ge\u00b7speck", "dem", "Zwei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der war ein wahrer Katzen-Alexander,", "tokens": ["Der", "war", "ein", "wah\u00b7rer", "Kat\u00b7zen\u00b7A\u00b7lex\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "War eine Gei\u00dfel f\u00fcr das Diebsgelichter", "tokens": ["War", "ei\u00b7ne", "Gei\u00b7\u00dfel", "f\u00fcr", "das", "Diebs\u00b7ge\u00b7lich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der M\u00e4use in vergangnen Zeiten", "tokens": ["Der", "M\u00e4u\u00b7se", "in", "ver\u00b7gang\u00b7nen", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und trieb gleich einem Attila sie durcheinander.", "tokens": ["Und", "trieb", "gleich", "ei\u00b7nem", "At\u00b7ti\u00b7la", "sie", "durch\u00b7ein\u00b7an\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ich sage euch, ich las bei jenem Dichter,", "tokens": ["Ich", "sa\u00b7ge", "euch", ",", "ich", "las", "bei", "je\u00b7nem", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df unser Kater wie ein H\u00f6llenhund", "tokens": ["Da\u00df", "un\u00b7ser", "Ka\u00b7ter", "wie", "ein", "H\u00f6l\u00b7len\u00b7hund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Auf Meilenweite rings gef\u00fcrchtet war,", "tokens": ["Auf", "Mei\u00b7len\u00b7wei\u00b7te", "rings", "ge\u00b7f\u00fcrch\u00b7tet", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Als sei er ausersehn, das Erdenrund", "tokens": ["Als", "sei", "er", "au\u00b7ser\u00b7sehn", ",", "das", "Er\u00b7den\u00b7rund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "VVINF", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ganz zu entv\u00f6lkern von der M\u00e4use Schar.", "tokens": ["Ganz", "zu", "ent\u00b7v\u00f6l\u00b7kern", "von", "der", "M\u00e4u\u00b7se", "Schar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Schlagbretter, Gift und Fallen \u2013", "tokens": ["Schlag\u00b7bret\u00b7ter", ",", "Gift", "und", "Fal\u00b7len", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Ach, alles war nur Kinderspiel", "tokens": ["Ach", ",", "al\u00b7les", "war", "nur", "Kin\u00b7der\u00b7spiel"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PIS", "VAFIN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Verglichen dem, was seinen Krallen", "tokens": ["Ver\u00b7gli\u00b7chen", "dem", ",", "was", "sei\u00b7nen", "Kral\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und Z\u00e4hnen rings zum Opfer fiel.", "tokens": ["Und", "Z\u00e4h\u00b7nen", "rings", "zum", "Op\u00b7fer", "fiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Da nun der W\u00fcrger merkte, da\u00df die M\u00e4use", "tokens": ["Da", "nun", "der", "W\u00fcr\u00b7ger", "merk\u00b7te", ",", "da\u00df", "die", "M\u00e4u\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Sich bang verbargen in dem Schlupfgeh\u00e4use", "tokens": ["Sich", "bang", "ver\u00b7bar\u00b7gen", "in", "dem", "Schlupf\u00b7ge\u00b7h\u00e4u\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Der engen L\u00f6cher und bei Tag und Nacht nicht mehr", "tokens": ["Der", "en\u00b7gen", "L\u00f6\u00b7cher", "und", "bei", "Tag", "und", "Nacht", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "APPR", "NN", "KON", "NN", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Herauszugehen wagten, sann er hin und her", "tokens": ["Her\u00b7aus\u00b7zu\u00b7ge\u00b7hen", "wag\u00b7ten", ",", "sann", "er", "hin", "und", "her"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$,", "VVFIN", "PPER", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Auf schlauen Streich. Er spielte einen Toten,", "tokens": ["Auf", "schlau\u00b7en", "Streich", ".", "Er", "spiel\u00b7te", "ei\u00b7nen", "To\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Hing sich an Stricken mit den Hinterpfoten", "tokens": ["Hing", "sich", "an", "Stri\u00b7cken", "mit", "den", "Hin\u00b7ter\u00b7pfo\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "NN", "APPR", "ART", "NN"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.22": {"text": "Am Deckenbalken auf, den Kopf nach unten.", "tokens": ["Am", "De\u00b7cken\u00b7bal\u00b7ken", "auf", ",", "den", "Kopf", "nach", "un\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "ART", "NN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Das M\u00e4usevolk lugt aus den L\u00f6chern drunten", "tokens": ["Das", "M\u00e4u\u00b7se\u00b7volk", "lugt", "aus", "den", "L\u00f6\u00b7chern", "drun\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Und meint, er habe, was auch ihm verboten,", "tokens": ["Und", "meint", ",", "er", "ha\u00b7be", ",", "was", "auch", "ihm", "ver\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "$,", "PRELS", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Diebstahl an K\u00e4se oder Fleisch begangen,", "tokens": ["Dieb\u00b7stahl", "an", "K\u00e4\u00b7se", "o\u00b7der", "Fleisch", "be\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Vielleicht sogar noch schlimmre Sachen,", "tokens": ["Viel\u00b7leicht", "so\u00b7gar", "noch", "schlimm\u00b7re", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Und sei zur Strafe aufgehangen;", "tokens": ["Und", "sei", "zur", "Stra\u00b7fe", "auf\u00b7ge\u00b7han\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und einig darin waren alle,", "tokens": ["Und", "ei\u00b7nig", "da\u00b7rin", "wa\u00b7ren", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PAV", "VAFIN", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Bei der Beerdigung zu lachen.", "tokens": ["Bei", "der", "Be\u00b7er\u00b7di\u00b7gung", "zu", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Doch selbst des Totgeglaubten Kralle", "tokens": ["Doch", "selbst", "des", "Tot\u00b7ge\u00b7glaub\u00b7ten", "Kral\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Erweckt noch Furcht; sie heben zwar", "tokens": ["Er\u00b7weckt", "noch", "Furcht", ";", "sie", "he\u00b7ben", "zwar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "NN", "$.", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Die Nasen hoch und zeigen gar", "tokens": ["Die", "Na\u00b7sen", "hoch", "und", "zei\u00b7gen", "gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Die K\u00f6pfe, doch im Augenblick", "tokens": ["Die", "K\u00f6p\u00b7fe", ",", "doch", "im", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Zieht alles wieder sich zur\u00fcck.", "tokens": ["Zieht", "al\u00b7les", "wie\u00b7der", "sich", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "In neuem Anlauf wagt die Schar", "tokens": ["In", "neu\u00b7em", "An\u00b7lauf", "wagt", "die", "Schar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Sich einige Schritte k\u00fchn voran.", "tokens": ["Sich", "ei\u00b7ni\u00b7ge", "Schrit\u00b7te", "k\u00fchn", "vo\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "Dann endlich fangen l\u00fcstern sie", "tokens": ["Dann", "end\u00b7lich", "fan\u00b7gen", "l\u00fcs\u00b7tern", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Nach rechts und links zu suchen an.", "tokens": ["Nach", "rechts", "und", "links", "zu", "su\u00b7chen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "KON", "ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Ein blutiges Fest, das nun begann!", "tokens": ["Ein", "blu\u00b7ti\u00b7ges", "Fest", ",", "das", "nun", "be\u00b7gann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "Lebendig auferstand das Vieh,", "tokens": ["Le\u00b7ben\u00b7dig", "auf\u00b7er\u00b7stand", "das", "Vieh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.41": {"text": "Das starr und steif am Balken hing,", "tokens": ["Das", "starr", "und", "steif", "am", "Bal\u00b7ken", "hing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "KON", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Fiel nieder, schnappte zu", "tokens": ["Fiel", "nie\u00b7der", ",", "schnapp\u00b7te", "zu"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.43": {"text": "Und griff und schlug im Nu", "tokens": ["Und", "griff", "und", "schlug", "im", "Nu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.44": {"text": "So manches arme Schn\u00fcffelding,", "tokens": ["So", "man\u00b7ches", "ar\u00b7me", "Schn\u00fcf\u00b7fel\u00b7ding", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "Das nicht geschwind ein Schlupfloch fand.", "tokens": ["Das", "nicht", "ge\u00b7schwind", "ein", "Schlupf\u00b7loch", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Rot f\u00e4rbte sich die M\u00f6rderhand.", "tokens": ["Rot", "f\u00e4rb\u00b7te", "sich", "die", "M\u00f6r\u00b7der\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Der B\u00f6se rief den Fl\u00fcchtigen hinterdrein:", "tokens": ["Der", "B\u00f6\u00b7se", "rief", "den", "Fl\u00fcch\u00b7ti\u00b7gen", "hin\u00b7ter\u00b7drein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.48": {"text": "\u00bbauf Wiedersehn! Das war die erste List,", "tokens": ["\u00bb", "auf", "Wie\u00b7der\u00b7sehn", "!", "Das", "war", "die", "ers\u00b7te", "List", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.49": {"text": "Und wie mir diese wohlgeraten ist,", "tokens": ["Und", "wie", "mir", "die\u00b7se", "wohl\u00b7ge\u00b7ra\u00b7ten", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PDAT", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.50": {"text": "So soll's auch mit der n\u00e4chsten sein.", "tokens": ["So", "soll's", "auch", "mit", "der", "n\u00e4chs\u00b7ten", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "APPR", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Ich warne euch! Die H\u00f6hlen retten", "tokens": ["Ich", "war\u00b7ne", "euch", "!", "Die", "H\u00f6h\u00b7len", "ret\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$.", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.52": {"text": "Euch nur f\u00fcr kurze Galgenfrist,", "tokens": ["Euch", "nur", "f\u00fcr", "kur\u00b7ze", "Gal\u00b7gen\u00b7frist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.53": {"text": "In meinen Bauch will ich euch alle betten.\u00ab", "tokens": ["In", "mei\u00b7nen", "Bauch", "will", "ich", "euch", "al\u00b7le", "bet\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "PPER", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.54": {"text": "Und Meister Leisetritt sprach keine L\u00fcgen,", "tokens": ["Und", "Meis\u00b7ter", "Lei\u00b7se\u00b7tritt", "sprach", "kei\u00b7ne", "L\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.55": {"text": "Denn es gelang ihm ohne Fehl,", "tokens": ["Denn", "es", "ge\u00b7lang", "ihm", "oh\u00b7ne", "Fehl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "Auf neue Art die M\u00e4use zu betr\u00fcgen.", "tokens": ["Auf", "neu\u00b7e", "Art", "die", "M\u00e4u\u00b7se", "zu", "be\u00b7tr\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.57": {"text": "Sehr fein sogar. Er nahm in Mehl", "tokens": ["Sehr", "fein", "so\u00b7gar", ".", "Er", "nahm", "in", "Mehl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "$.", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Ein Vollbad, wei\u00df verkleidet legte", "tokens": ["Ein", "Voll\u00b7bad", ",", "wei\u00df", "ver\u00b7klei\u00b7det", "leg\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "VVPP", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.59": {"text": "Er sich in einen Backtrog nieder.", "tokens": ["Er", "sich", "in", "ei\u00b7nen", "Back\u00b7trog", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.60": {"text": "Als bei den M\u00e4usen sich der Hunger regte,", "tokens": ["Als", "bei", "den", "M\u00e4u\u00b7sen", "sich", "der", "Hun\u00b7ger", "reg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Kam eine nach der andern wieder.", "tokens": ["Kam", "ei\u00b7ne", "nach", "der", "an\u00b7dern", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "APPR", "ART", "ADJA", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.62": {"text": "Zu ihrem Unheil kamen sie!", "tokens": ["Zu", "ih\u00b7rem", "Un\u00b7heil", "ka\u00b7men", "sie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "Triumphe feierte des Katers Strategie.", "tokens": ["Tri\u00b7um\u00b7phe", "fei\u00b7er\u00b7te", "des", "Ka\u00b7ters", "Stra\u00b7te\u00b7gie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Nur eine alte Maus, ein pfiffiges Genie,", "tokens": ["Nur", "ei\u00b7ne", "al\u00b7te", "Maus", ",", "ein", "pfif\u00b7fi\u00b7ges", "Ge\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Die schon in einer Schlacht den Schwanz einb\u00fc\u00dfte,", "tokens": ["Die", "schon", "in", "ei\u00b7ner", "Schlacht", "den", "Schwanz", "ein\u00b7b\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Bezwang die Lust. Von weitem nur begr\u00fc\u00dfte", "tokens": ["Be\u00b7zwang", "die", "Lust", ".", "Von", "wei\u00b7tem", "nur", "be\u00b7gr\u00fc\u00df\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$.", "APPR", "PIS", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.67": {"text": "Sie den bemehlten Block und rief voll Vorsicht hin:", "tokens": ["Sie", "den", "be\u00b7mehl\u00b7ten", "Block", "und", "rief", "voll", "Vor\u00b7sicht", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "KON", "VVFIN", "ADJD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "\u00bbmir macht das Mehl nichts weis, ich ahne Krallen drin.", "tokens": ["\u00bb", "mir", "macht", "das", "Mehl", "nichts", "weis", ",", "ich", "ah\u00b7ne", "Kral\u00b7len", "drin", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "PIS", "PTKVZ", "$,", "PPER", "VVFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Und w\u00e4rst du auch ein Sack, ich k\u00e4me dir nicht nah.\u00ab", "tokens": ["Und", "w\u00e4rst", "du", "auch", "ein", "Sack", ",", "ich", "k\u00e4\u00b7me", "dir", "nicht", "nah", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das war ein heller Kopf, der so dahinter sah.", "tokens": ["Das", "war", "ein", "hel\u00b7ler", "Kopf", ",", "der", "so", "da\u00b7hin\u00b7ter", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Man soll auf \u00e4u\u00dfern Schein nicht bauen,", "tokens": ["Man", "soll", "auf", "\u00e4u\u00b7\u00dfern", "Schein", "nicht", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den besten Schutz gew\u00e4hrt Mi\u00dftrauen.", "tokens": ["Den", "bes\u00b7ten", "Schutz", "ge\u00b7w\u00e4hrt", "Mi\u00df\u00b7trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}