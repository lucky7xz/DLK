{"textgrid.poem.56583": {"metadata": {"author": {"name": "Groth, Klaus", "birth": "N.A.", "death": "N.A."}, "title": "1L: To Lunden v\u0153r de Rathhusd\u0153r", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "To Lunden v\u0153r de Rathhusd\u0153r", "tokens": ["To", "Lun\u00b7den", "v\u0153r", "de", "Ra\u00b7th\u00b7hus\u00b7d\u0153r"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Geit Herr Jehannis hin un h\u0119r.", "tokens": ["Geit", "Herr", "Je\u00b7han\u00b7nis", "hin", "un", "h\u0119r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "++-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "He geit hendal, he geit herop:", "tokens": ["He", "geit", "hen\u00b7dal", ",", "he", "geit", "he\u00b7rop", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "NE", "$,", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kumt Keen un makt de D\u0153r em op.", "tokens": ["Kumt", "Ke\u00b7en", "un", "makt", "de", "D\u0153r", "em", "op."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "He geit wul op, he geit wul dal:", "tokens": ["He", "geit", "wul", "op", ",", "he", "geit", "wul", "dal", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kumt Keen, de em herinner hal.", "tokens": ["Kumt", "Ke\u00b7en", ",", "de", "em", "he\u00b7rin\u00b7ner", "hal", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Do stiggt de Hitt em inne Kopp", "tokens": ["Do", "stiggt", "de", "Hitt", "em", "in\u00b7ne", "Kopp"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un iwri geit he dal un op.", "tokens": ["Un", "iw\u00b7ri", "geit", "he", "dal", "un", "op."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbun sta ik denn v\u0153r Rech un Rath", "tokens": ["\u00bb", "un", "sta", "ik", "denn", "v\u0153r", "Rech", "un", "Rath"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "NN"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "As arme S\u00fcnner oppe Strat?", "tokens": ["As", "ar\u00b7me", "S\u00fcn\u00b7ner", "op\u00b7pe", "Strat", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Un heff ik feilt v\u0153r Volk un Land,", "tokens": ["Un", "heff", "ik", "feilt", "v\u0153r", "Volk", "un", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Verlang ik Rech na Rang un Stand!", "tokens": ["Ver\u00b7lang", "ik", "Rech", "na", "Rang", "un", "Stand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Verlang ik Rech na Stand un Ehr,", "tokens": ["Ver\u00b7lang", "ik", "Rech", "na", "Stand", "un", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Un wenn't bi Dod un D\u00f6wel weer!\u00ab", "tokens": ["Un", "wenn't", "bi", "Dod", "un", "D\u00f6\u00b7wel", "weer", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "V\u0153r Iwer gnisch he mit de T\u00e4hn,", "tokens": ["V\u0153r", "I\u00b7wer", "gnisch", "he", "mit", "de", "T\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un pett en Hoofis inne Steen.", "tokens": ["Un", "pett", "en", "Hoo\u00b7fis", "in\u00b7ne", "Steen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Do geit de D\u0153r, he rin in Wuth,", "tokens": ["Do", "geit", "de", "D\u0153r", ",", "he", "rin", "in", "Wuth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Ognblick st\u00f6rtt he wedder rut", "tokens": ["In", "O\u00b7gnblick", "st\u00f6rtt", "he", "wed\u00b7der", "rut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "NE", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Un smitt sik inne Hast in Wagn", "tokens": ["Un", "smitt", "sik", "in\u00b7ne", "Hast", "in", "Wagn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "NN", "PTKVZ", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un lett den Kutscher v\u0153rwarts jagn.", "tokens": ["Un", "lett", "den", "Kut\u00b7scher", "v\u0153r\u00b7warts", "jagn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wer kennt den Kutscher oppen Buck?", "tokens": ["Wer", "kennt", "den", "Kut\u00b7scher", "op\u00b7pen", "Buck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "He hett den Hot in Ogen tuck.", "tokens": ["He", "hett", "den", "Hot", "in", "O\u00b7gen", "tuck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Veer Hingsten swart ahn Prick un Prack:", "tokens": ["Veer", "Hings\u00b7ten", "swart", "ahn", "Prick", "un", "Prack", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wa fleegt de Mahnhaar umme Nack!", "tokens": ["Wa", "fleegt", "de", "Mahn\u00b7haar", "um\u00b7me", "Nack", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Wa fl\u00fcggt dat F\u00fcr ut Ogn un Steen!", "tokens": ["Wa", "fl\u00fcggt", "dat", "F\u00fcr", "ut", "Ogn", "un", "Steen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "FM", "FM", "FM", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wa fl\u00fcggt de Damp um N\u0153s un Been!", "tokens": ["Wa", "fl\u00fcggt", "de", "Damp", "um", "N\u0153s", "un", "Be\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wohin? wohin? segg jo ni na!", "tokens": ["Wo\u00b7hin", "?", "wo\u00b7hin", "?", "segg", "jo", "ni", "na", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "FM.it", "FM.it", "FM.it", "FM.it", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De Marschl\u00fcd stat un seht em na.", "tokens": ["De", "Mar\u00b7schl\u00fcd", "stat", "un", "seht", "em", "na", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Dat geit na B\u00fcsum \u0153wern Dik,", "tokens": ["Dat", "geit", "na", "B\u00fc\u00b7sum", "\u0153wern", "Dik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dat geit na B\u00fcsum d\u0153r den Slick.", "tokens": ["Dat", "geit", "na", "B\u00fc\u00b7sum", "d\u0153r", "den", "Slick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "ART", "NN", "$."], "meter": "-----+-+", "measure": "unknown.measure.di"}}, "stanza.16": {"line.1": {"text": "Do wis' de Kutscher mit de Sw\u0119p,", "tokens": ["Do", "wis'", "de", "Kut\u00b7scher", "mit", "de", "Sw\u0119p", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Do teek Jehannis na de Deep.", "tokens": ["Do", "teek", "Je\u00b7han\u00b7nis", "na", "de", "Deep", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Do jagn se langs den widen Strand,", "tokens": ["Do", "jagn", "se", "langs", "den", "wi\u00b7den", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.it", "FM.it", "FM.it", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nix blev der, as en Spor int Sand,", "tokens": ["Nix", "blev", "der", ",", "as", "en", "Spor", "int", "Sand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.18": {"line.1": {"text": "Nix blev der, as de Spor in Steen,", "tokens": ["Nix", "blev", "der", ",", "as", "de", "Spor", "in", "Steen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "$,", "FM", "FM", "FM", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De kann man noch to Lunden sehn.", "tokens": ["De", "kann", "man", "noch", "to", "Lun\u00b7den", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIS", "ADV", "FM", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}