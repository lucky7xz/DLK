{"textgrid.poem.54420": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "Zweyte Fabel", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auch unter Thieren ist es mehr als zu gemein,", "tokens": ["Auch", "un\u00b7ter", "Thie\u00b7ren", "ist", "es", "mehr", "als", "zu", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VAFIN", "PPER", "PIAT", "KOKOM", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ob dieselben gleich vernunftlos m\u00fcssen seyn,", "tokens": ["Da\u00df", "ob", "die\u00b7sel\u00b7ben", "gleich", "ver\u00b7nunft\u00b7los", "m\u00fcs\u00b7sen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PDAT", "ADV", "ADJD", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie doch bey Zank und Streit, und zwar des Vorzugs wegen", "tokens": ["Sie", "doch", "bey", "Zank", "und", "Streit", ",", "und", "zwar", "des", "Vor\u00b7zugs", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "NN", "KON", "NN", "$,", "KON", "ADV", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Einander weh zu thun und auszuspotten pflegen.", "tokens": ["Ein\u00b7an\u00b7der", "weh", "zu", "thun", "und", "aus\u00b7zu\u00b7spot\u00b7ten", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "KON", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein jedes schmeichelt sich der allergr\u00f6sten Zier;", "tokens": ["Ein", "je\u00b7des", "schmei\u00b7chelt", "sich", "der", "al\u00b7ler\u00b7gr\u00f6s\u00b7ten", "Zier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein jedes d\u00fcnket sich das allerkl\u00fcgste Thier", "tokens": ["Ein", "je\u00b7des", "d\u00fcn\u00b7ket", "sich", "das", "al\u00b7ler\u00b7kl\u00fcgs\u00b7te", "Thier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "VVFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vor anderen zu seyn. Es tadelt sein Beginnen,", "tokens": ["Vor", "an\u00b7de\u00b7ren", "zu", "seyn", ".", "Es", "ta\u00b7delt", "sein", "Be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PTKZU", "VAINF", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und andre wissen gleich was wieder auszusinnen.", "tokens": ["Und", "and\u00b7re", "wis\u00b7sen", "gleich", "was", "wie\u00b7der", "aus\u00b7zu\u00b7sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "PWS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Reyher, der ganz still an eines Teiches Rand", "tokens": ["Ein", "Rey\u00b7her", ",", "der", "ganz", "still", "an", "ei\u00b7nes", "Tei\u00b7ches", "Rand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bey fr\u00fcher Morgenzeit in dem Geh\u00f6lze stand,", "tokens": ["Bey", "fr\u00fc\u00b7her", "Mor\u00b7gen\u00b7zeit", "in", "dem", "Ge\u00b7h\u00f6l\u00b7ze", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Bestrebte sich daselbst mit eifrigem Verlangen,", "tokens": ["Be\u00b7streb\u00b7te", "sich", "da\u00b7selbst", "mit", "eif\u00b7ri\u00b7gem", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Weil ihn der Hunger trieb, von Fischwerk was zu fangen.", "tokens": ["Weil", "ihn", "der", "Hun\u00b7ger", "trieb", ",", "von", "Fischwerk", "was", "zu", "fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "APPR", "NN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Er schielte hier und dar so vor als hinter sich,", "tokens": ["Er", "schiel\u00b7te", "hier", "und", "dar", "so", "vor", "als", "hin\u00b7ter", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "PAV", "ADV", "PTKVZ", "KOKOM", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zu sehn, ob etwan was daselbst vor\u00fcber schlich,", "tokens": ["Zu", "sehn", ",", "ob", "et\u00b7wan", "was", "da\u00b7selbst", "vor\u00b7\u00fc\u00b7ber", "schlich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "ADV", "PWS", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das seinen trockenen und leeren Magen f\u00fcllte,", "tokens": ["Das", "sei\u00b7nen", "tro\u00b7cke\u00b7nen", "und", "lee\u00b7ren", "Ma\u00b7gen", "f\u00fcll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "ADJA", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und ihm die Hungersnoth, die er versp\u00fchrte, stillte.", "tokens": ["Und", "ihm", "die", "Hun\u00b7gers\u00b7noth", ",", "die", "er", "ver\u00b7sp\u00fchr\u00b7te", ",", "still\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dies trieb er lange Zeit; bis endlich ihn ein Staar,", "tokens": ["Dies", "trieb", "er", "lan\u00b7ge", "Zeit", ";", "bis", "end\u00b7lich", "ihn", "ein", "Staar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "NN", "$.", "KON", "ADV", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der auch mit in den Wald zugleich geflogen war,", "tokens": ["Der", "auch", "mit", "in", "den", "Wald", "zu\u00b7gleich", "ge\u00b7flo\u00b7gen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "APPR", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Um Ufer stehen sah, und nach so langem Schweigen", "tokens": ["Um", "U\u00b7fer", "ste\u00b7hen", "sah", ",", "und", "nach", "so", "lan\u00b7gem", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "VVFIN", "VVFIN", "$,", "KON", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Auf ihn vor Zorn entbrannt begunte her zu steigen.", "tokens": ["Auf", "ihn", "vor", "Zorn", "ent\u00b7brannt", "be\u00b7gun\u00b7te", "her", "zu", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "NN", "ADJD", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Was sprach er, schleichst du denn so lange Zeit herum,", "tokens": ["Was", "sprach", "er", ",", "schleichst", "du", "denn", "so", "lan\u00b7ge", "Zeit", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und stehst, als w\u00e4rest du bey nahe taub und stumm,", "tokens": ["Und", "stehst", ",", "als", "w\u00e4\u00b7rest", "du", "bey", "na\u00b7he", "taub", "und", "stumm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "APPR", "ADJD", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Da dir doch V\u00f6gel gnug allhier zur Seite stehen,", "tokens": ["Da", "dir", "doch", "V\u00f6\u00b7gel", "gnug", "all\u00b7hier", "zur", "Sei\u00b7te", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die an dem sch\u00f6nen Tag zur Lust zusammen gehen?", "tokens": ["Die", "an", "dem", "sch\u00f6\u00b7nen", "Tag", "zur", "Lust", "zu\u00b7sam\u00b7men", "ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "APPRART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wie sch\u00f6ne l\u00e4\u00dft es nicht, wenn man will ganz allein,", "tokens": ["Wie", "sch\u00f6\u00b7ne", "l\u00e4\u00dft", "es", "nicht", ",", "wenn", "man", "will", "ganz", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PIS", "VMFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ein solcher Sonderling in der Gesellschaft seyn?", "tokens": ["Ein", "sol\u00b7cher", "Son\u00b7der\u00b7ling", "in", "der", "Ge\u00b7sell\u00b7schaft", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Du willst dich mit Gewalt zu stummen Thieren schreiben,", "tokens": ["Du", "willst", "dich", "mit", "Ge\u00b7walt", "zu", "stum\u00b7men", "Thie\u00b7ren", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und was man dich auch fragt, die Antwort schuldig bleiben.", "tokens": ["Und", "was", "man", "dich", "auch", "fragt", ",", "die", "Ant\u00b7wort", "schul\u00b7dig", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PRF", "ADV", "VVFIN", "$,", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Flammt dich der Hoffartsgeist zum Stilleschweigen an?", "tokens": ["Flammt", "dich", "der", "Hof\u00b7farts\u00b7geist", "zum", "Stil\u00b7le\u00b7schwei\u00b7gen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Findst du kein kluges Thier, das mit dir reden kann?", "tokens": ["Findst", "du", "kein", "klu\u00b7ges", "Thier", ",", "das", "mit", "dir", "re\u00b7den", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADJA", "NN", "$,", "PRELS", "APPR", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Ja ja, du suchst vielleicht uns alle zu belauschen,", "tokens": ["Ja", "ja", ",", "du", "suchst", "viel\u00b7leicht", "uns", "al\u00b7le", "zu", "be\u00b7lau\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Ob dies und jenes l\u00e4\u00dft etwan ein Wort mit rauschen,", "tokens": ["Ob", "dies", "und", "je\u00b7nes", "l\u00e4\u00dft", "et\u00b7wan", "ein", "Wort", "mit", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "KON", "PDS", "VVFIN", "ADV", "ART", "NN", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Das dir, indem dein Geist sich in sich selbst verliebt,", "tokens": ["Das", "dir", ",", "in\u00b7dem", "dein", "Geist", "sich", "in", "sich", "selbst", "ver\u00b7liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "$,", "KOUS", "PPOSAT", "NN", "PRF", "APPR", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Hernach Gelegenheit uns durchzuhecheln giebt:", "tokens": ["Her\u00b7nach", "Ge\u00b7le\u00b7gen\u00b7heit", "uns", "durch\u00b7zu\u00b7he\u00b7cheln", "giebt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Man weis wahrhaftig nicht, wenn oft in unsern Ch\u00f6ren", "tokens": ["Man", "weis", "wahr\u00b7haf\u00b7tig", "nicht", ",", "wenn", "oft", "in", "un\u00b7sern", "Ch\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "PTKVZ", "ADJD", "PTKNEG", "$,", "KOUS", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Ein solcher Schleicher sitzt, der gar kein Wort l\u00e4\u00dft h\u00f6ren,", "tokens": ["Ein", "sol\u00b7cher", "Schlei\u00b7cher", "sitzt", ",", "der", "gar", "kein", "Wort", "l\u00e4\u00dft", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "PRELS", "ADV", "PIAT", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ob man verrathen ist: dieweil man immer denkt", "tokens": ["Ob", "man", "ver\u00b7ra\u00b7then", "ist", ":", "die\u00b7weil", "man", "im\u00b7mer", "denkt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVPP", "VAFIN", "$.", "KOUS", "PIS", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Er d\u00fcrfte, wenn man noch so klug die Zunge lenkt,", "tokens": ["Er", "d\u00fcrf\u00b7te", ",", "wenn", "man", "noch", "so", "klug", "die", "Zun\u00b7ge", "lenkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PIS", "ADV", "ADV", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Doch jedes Wort von uns, das ihm vielleicht entgegen", "tokens": ["Doch", "je\u00b7des", "Wort", "von", "uns", ",", "das", "ihm", "viel\u00b7leicht", "ent\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPR", "PPER", "$,", "PRELS", "PPER", "ADV", "PTKVZ"], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.40": {"text": "Und nicht recht schmackbar ist, wohl auf die Wage legen.", "tokens": ["Und", "nicht", "recht", "schmack\u00b7bar", "ist", ",", "wohl", "auf", "die", "Wa\u00b7ge", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADJD", "VAFIN", "$,", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Dies frey Geschw\u00e4tze gieng dem Reyher freylich nah,", "tokens": ["Dies", "frey", "Ge\u00b7schw\u00e4t\u00b7ze", "gieng", "dem", "Rey\u00b7her", "frey\u00b7lich", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "NN", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Der sich, zumal vom Staar, dergleichen nicht versah.", "tokens": ["Der", "sich", ",", "zu\u00b7mal", "vom", "Staar", ",", "derg\u00b7lei\u00b7chen", "nicht", "ver\u00b7sah", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "$,", "KOUS", "APPRART", "NN", "$,", "PIS", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Er meynt, und dies mit Recht, als ob es seine Ehre", "tokens": ["Er", "meynt", ",", "und", "dies", "mit", "Recht", ",", "als", "ob", "es", "sei\u00b7ne", "Eh\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "PDS", "APPR", "NN", "$,", "KOKOM", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und dem so guten Ruf gar stark zuwider w\u00e4re.", "tokens": ["Und", "dem", "so", "gu\u00b7ten", "Ruf", "gar", "stark", "zu\u00b7wi\u00b7der", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADJA", "NN", "ADV", "ADJD", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Drum str\u00e4ubte Zorn und Grimm ihm sein Gefieder auf,", "tokens": ["Drum", "str\u00e4ub\u00b7te", "Zorn", "und", "Grimm", "ihm", "sein", "Ge\u00b7fie\u00b7der", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "KON", "NE", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "So glatt es vorher war; wie? sprach er gleich hierauf,", "tokens": ["So", "glatt", "es", "vor\u00b7her", "war", ";", "wie", "?", "sprach", "er", "gleich", "hier\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VAFIN", "$.", "PWAV", "$.", "VVFIN", "PPER", "ADV", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Betr\u00fcbte Creatur! darfst du so keck es wagen", "tokens": ["Be\u00b7tr\u00fcb\u00b7te", "Crea\u00b7tur", "!", "darfst", "du", "so", "keck", "es", "wa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "VMFIN", "PPER", "ADV", "ADJD", "PPER", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.48": {"text": "So unbedachtsam Zeug mir selber vorzusagen?", "tokens": ["So", "un\u00b7be\u00b7dacht\u00b7sam", "Zeug", "mir", "sel\u00b7ber", "vor\u00b7zu\u00b7sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Was geht dich Plappergeist, doch wohl mein Schweigen an,", "tokens": ["Was", "geht", "dich", "Plap\u00b7per\u00b7geist", ",", "doch", "wohl", "mein", "Schwei\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "NN", "$,", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Wodurch der Reyher nie hat andern weh gethan?", "tokens": ["Wo\u00b7durch", "der", "Rey\u00b7her", "nie", "hat", "an\u00b7dern", "weh", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Er wird, und w\u00fcst er auch noch so geheime Sachen", "tokens": ["Er", "wird", ",", "und", "w\u00fcst", "er", "auch", "noch", "so", "ge\u00b7hei\u00b7me", "Sa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Von unsrer V\u00f6gel Zunft, doch kein Geplerre machen.", "tokens": ["Von", "uns\u00b7rer", "V\u00f6\u00b7gel", "Zunft", ",", "doch", "kein", "Ge\u00b7pler\u00b7re", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Wer ist, der nicht den Werth von dieser Kunst erkennt,", "tokens": ["Wer", "ist", ",", "der", "nicht", "den", "Werth", "von", "die\u00b7ser", "Kunst", "er\u00b7kennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "PTKNEG", "ART", "NN", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Die, weil sie es verdient, man mehr als g\u00fclden nennt?", "tokens": ["Die", ",", "weil", "sie", "es", "ver\u00b7dient", ",", "man", "mehr", "als", "g\u00fcl\u00b7den", "nennt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,", "PIS", "PIAT", "KOKOM", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Es ist nichts l\u00f6blicher, als mit Bedacht zu schweigen;", "tokens": ["Es", "ist", "nichts", "l\u00f6b\u00b7li\u00b7cher", ",", "als", "mit", "Be\u00b7dacht", "zu", "schwei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADJA", "$,", "KOUS", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Wie leichte kann man sich mit einem Wort versteigen,", "tokens": ["Wie", "leich\u00b7te", "kann", "man", "sich", "mit", "ei\u00b7nem", "Wort", "ver\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "VMFIN", "PIS", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Das man nicht recht erwegt? wer immer plaudern will,", "tokens": ["Das", "man", "nicht", "recht", "er\u00b7wegt", "?", "wer", "im\u00b7mer", "plau\u00b7dern", "will", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PTKNEG", "ADJD", "VVPP", "$.", "PWS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Der mischt in sein Geschw\u00e4tz auch oftermals sehr viel,", "tokens": ["Der", "mischt", "in", "sein", "Ge\u00b7schw\u00e4tz", "auch", "of\u00b7ter\u00b7mals", "sehr", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "ADV", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Das schlecht und albern klingt, und uns kann wenig n\u00fctzen;", "tokens": ["Das", "schlecht", "und", "al\u00b7bern", "klingt", ",", "und", "uns", "kann", "we\u00b7nig", "n\u00fct\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "ADJD", "VVFIN", "$,", "KON", "PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Denn was sein Herze denkt mu\u00df auf der Zunge sitzen.", "tokens": ["Denn", "was", "sein", "Her\u00b7ze", "denkt", "mu\u00df", "auf", "der", "Zun\u00b7ge", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Du hast, sch\u00e4mst du dich nicht der tollen Schw\u00e4tzerey?", "tokens": ["Du", "hast", ",", "sch\u00e4mst", "du", "dich", "nicht", "der", "tol\u00b7len", "Schw\u00e4t\u00b7ze\u00b7rey", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "VVFIN", "PPER", "PRF", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Wohl grosses Recht dazu, da\u00df du noch ein Geschrey", "tokens": ["Wohl", "gros\u00b7ses", "Recht", "da\u00b7zu", ",", "da\u00df", "du", "noch", "ein", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "PAV", "$,", "KOUS", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Von deiner Redekunst, die du nicht kannst beweisen,", "tokens": ["Von", "dei\u00b7ner", "Re\u00b7de\u00b7kunst", ",", "die", "du", "nicht", "kannst", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Elender Vogel, machst, um sie mir anzupreisen.", "tokens": ["E\u00b7len\u00b7der", "Vo\u00b7gel", ",", "machst", ",", "um", "sie", "mir", "an\u00b7zu\u00b7prei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "$,", "KOUI", "PPER", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "O weist du nicht, wie sehr dich das Gefl\u00fcgel scheut,", "tokens": ["O", "weist", "du", "nicht", ",", "wie", "sehr", "dich", "das", "Ge\u00b7fl\u00fc\u00b7gel", "scheut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Das dich, nach deinem Werth, auf tausend Meilen weit", "tokens": ["Das", "dich", ",", "nach", "dei\u00b7nem", "Werth", ",", "auf", "tau\u00b7send", "Mei\u00b7len", "weit"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "APPR", "CARD", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Von sich entfernet w\u00fcnscht, wenn man dich ungebeten,", "tokens": ["Von", "sich", "ent\u00b7fer\u00b7net", "w\u00fcnscht", ",", "wenn", "man", "dich", "un\u00b7ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVFIN", "VVFIN", "$,", "KOUS", "PIS", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "In die Gesellschaft sieht, verha\u00dfter Vogel, treten.", "tokens": ["In", "die", "Ge\u00b7sell\u00b7schaft", "sieht", ",", "ver\u00b7ha\u00df\u00b7ter", "Vo\u00b7gel", ",", "tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Dein Eintritt schreckt uns gleich; die Lust wird hier gest\u00f6rt,", "tokens": ["Dein", "Ein\u00b7tritt", "schreckt", "uns", "gleich", ";", "die", "Lust", "wird", "hier", "ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$.", "ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Weil zur vertrauten Zunft kein W\u00e4scher mit geh\u00f6rt:", "tokens": ["Weil", "zur", "ver\u00b7trau\u00b7ten", "Zunft", "kein", "W\u00e4\u00b7scher", "mit", "ge\u00b7h\u00f6rt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "ADJA", "NN", "PIAT", "NN", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Wir wissen, klopfst du an, wie viel es hat geschlagen,", "tokens": ["Wir", "wis\u00b7sen", ",", "klopfst", "du", "an", ",", "wie", "viel", "es", "hat", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "PIS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Und werden dich forthin aus unsern Reihen jagen.", "tokens": ["Und", "wer\u00b7den", "dich", "for\u00b7thin", "aus", "un\u00b7sern", "Rei\u00b7hen", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Warum? ein jedes Wort, das man hervorgebracht,", "tokens": ["Wa\u00b7rum", "?", "ein", "je\u00b7des", "Wort", ",", "das", "man", "her\u00b7vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ART", "PIAT", "NN", "$,", "PRELS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "So Unschuldvoll es klingt, wird gleich bekannt gemacht;", "tokens": ["So", "Un\u00b7schuld\u00b7voll", "es", "klingt", ",", "wird", "gleich", "be\u00b7kannt", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Du weist das Ende nicht von deinem dummen Plaudern;", "tokens": ["Du", "weist", "das", "En\u00b7de", "nicht", "von", "dei\u00b7nem", "dum\u00b7men", "Plau\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und sind wir alle weg, so sieht man dich noch zaudern.", "tokens": ["Und", "sind", "wir", "al\u00b7le", "weg", ",", "so", "sieht", "man", "dich", "noch", "zau\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "PTKVZ", "$,", "ADV", "VVFIN", "PIS", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Ein jeder Zweig und Ast mu\u00df eine B\u00fchne seyn,", "tokens": ["Ein", "je\u00b7der", "Zweig", "und", "Ast", "mu\u00df", "ei\u00b7ne", "B\u00fch\u00b7ne", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "VMFIN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Auf deren H\u00f6he du pflegst alles auszuschreyn", "tokens": ["Auf", "de\u00b7ren", "H\u00f6\u00b7he", "du", "pflegst", "al\u00b7les", "aus\u00b7zu\u00b7schreyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "PPER", "VVFIN", "PIS", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Was du erschnappet hast. Ey, da\u00df bey deinem Waschen,", "tokens": ["Was", "du", "er\u00b7schnap\u00b7pet", "hast", ".", "Ey", ",", "da\u00df", "bey", "dei\u00b7nem", "Wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$.", "NN", "$,", "KOUS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.80": {"text": "Dich nicht im Augenblick der Habicht soll erhaschen!", "tokens": ["Dich", "nicht", "im", "Au\u00b7gen\u00b7blick", "der", "Ha\u00b7bicht", "soll", "er\u00b7ha\u00b7schen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPRART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Bespiegelt euch hieran, ihr, die ihr von dem Staar", "tokens": ["Be\u00b7spie\u00b7gelt", "euch", "hie\u00b7ran", ",", "ihr", ",", "die", "ihr", "von", "dem", "Staar"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PAV", "$,", "PPER", "$,", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.82": {"text": "Dies Laster mit erlernt, und t\u00e4glich hier und dar,", "tokens": ["Dies", "Las\u00b7ter", "mit", "er\u00b7lernt", ",", "und", "t\u00e4g\u00b7lich", "hier", "und", "dar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "APPR", "VVPP", "$,", "KON", "ADJD", "ADV", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Das was ihr h\u00f6rt und seht, zu jedermanns Erstaunen", "tokens": ["Das", "was", "ihr", "h\u00f6rt", "und", "seht", ",", "zu", "je\u00b7der\u00b7manns", "Er\u00b7stau\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "PRELS", "PPER", "VVFIN", "KON", "VVFIN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Auf allen Gassen m\u00fc\u00dft gleich wieder ausposaunen.", "tokens": ["Auf", "al\u00b7len", "Gas\u00b7sen", "m\u00fc\u00dft", "gleich", "wie\u00b7der", "aus\u00b7po\u00b7sau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Was hilft es da\u00df ihr euch mit andrer Worten tragt,", "tokens": ["Was", "hilft", "es", "da\u00df", "ihr", "euch", "mit", "an\u00b7drer", "Wor\u00b7ten", "tragt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "KOUS", "PPER", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Und einem Echo gleicht, das alles wieder sagt?", "tokens": ["Und", "ei\u00b7nem", "E\u00b7cho", "gleicht", ",", "das", "al\u00b7les", "wie\u00b7der", "sagt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "So viel, da\u00df man vor euch ein grosses Kreuze machet,", "tokens": ["So", "viel", ",", "da\u00df", "man", "vor", "euch", "ein", "gros\u00b7ses", "Kreu\u00b7ze", "ma\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PIS", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und eure Plauderey, wie sie verdient, verlachet.", "tokens": ["Und", "eu\u00b7re", "Plau\u00b7de\u00b7rey", ",", "wie", "sie", "ver\u00b7dient", ",", "ver\u00b7la\u00b7chet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Es flieht euch alle Welt. Wi\u00dft ihr, ihr W\u00e4scher nicht", "tokens": ["Es", "flieht", "euch", "al\u00b7le", "Welt", ".", "Wi\u00dft", "ihr", ",", "ihr", "W\u00e4\u00b7scher", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "$.", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Was man von euch zum Spott in der Gesellschaft spricht:", "tokens": ["Was", "man", "von", "euch", "zum", "Spott", "in", "der", "Ge\u00b7sell\u00b7schaft", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PPER", "APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Ihr h\u00e4ttet, weil euch recht die Plaudersucht besessen,", "tokens": ["Ihr", "h\u00e4t\u00b7tet", ",", "weil", "euch", "recht", "die", "Plau\u00b7der\u00b7sucht", "be\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Vom Huhn das Hintertheil unfehlbar mit gefressen.", "tokens": ["Vom", "Huhn", "das", "Hin\u00b7ter\u00b7theil", "un\u00b7fehl\u00b7bar", "mit", "ge\u00b7fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADJD", "APPR", "VVPP", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}}}}