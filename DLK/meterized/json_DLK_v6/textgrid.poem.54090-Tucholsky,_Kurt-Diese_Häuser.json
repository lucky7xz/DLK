{"textgrid.poem.54090": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Diese H\u00e4user", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Diese H\u00e4user werden l\u00e4nger leben als du.", "tokens": ["Die\u00b7se", "H\u00e4u\u00b7ser", "wer\u00b7den", "l\u00e4n\u00b7ger", "le\u00b7ben", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADJD", "VVFIN", "KOUS", "PPER", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.2": {"text": "Du hast geglaubt, f\u00fcr dich seien sie gebaut.", "tokens": ["Du", "hast", "ge\u00b7glaubt", ",", "f\u00fcr", "dich", "sei\u00b7en", "sie", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "APPR", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Aber sie waren vorher da.", "tokens": ["A\u00b7ber", "sie", "wa\u00b7ren", "vor\u00b7her", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Du hast geglaubt: du wirst sie \u00fcberleben.", "tokens": ["Du", "hast", "ge\u00b7glaubt", ":", "du", "wirst", "sie", "\u00fc\u00b7berl\u00b7e\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie werden aber noch nach dir da sein.", "tokens": ["Sie", "wer\u00b7den", "a\u00b7ber", "noch", "nach", "dir", "da", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Diese H\u00e4user werden l\u00e4nger leben als du.", "tokens": ["Die\u00b7se", "H\u00e4u\u00b7ser", "wer\u00b7den", "l\u00e4n\u00b7ger", "le\u00b7ben", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADJD", "VVFIN", "KOUS", "PPER", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.7": {"text": "Wenn du durch die Stadt trollst", "tokens": ["Wenn", "du", "durch", "die", "Stadt", "trollst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.8": {"text": "mit einem Papierpacken, den du gekauft hast, du Tropf \u2013", "tokens": ["mit", "ei\u00b7nem", "Pa\u00b7pier\u00b7pa\u00b7cken", ",", "den", "du", "ge\u00b7kauft", "hast", ",", "du", "Tropf", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$,", "PPER", "NN", "$("], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "weil das dein Leben ist:", "tokens": ["weil", "das", "dein", "Le\u00b7ben", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "acht Stunden herumzupetern,", "tokens": ["acht", "Stun\u00b7den", "her\u00b7um\u00b7zu\u00b7pe\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVINF", "$,"], "meter": "-+----+-", "measure": "dactylic.init"}, "line.11": {"text": "um eine zu genie\u00dfen,", "tokens": ["um", "ei\u00b7ne", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "und die verregnet . . .", "tokens": ["und", "die", "ver\u00b7reg\u00b7net", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ART", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "wenn du durch die Stadt trottest,", "tokens": ["wenn", "du", "durch", "die", "Stadt", "trot\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "dann sehn sie dich an,", "tokens": ["dann", "sehn", "sie", "dich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "die Herren H\u00e4user,", "tokens": ["die", "Her\u00b7ren", "H\u00e4u\u00b7ser", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.16": {"text": "und grinsen mit breiten T\u00fcrm\u00e4ulern.", "tokens": ["und", "grin\u00b7sen", "mit", "brei\u00b7ten", "T\u00fcr\u00b7m\u00e4u\u00b7lern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Sie werden l\u00e4nger leben als du.", "tokens": ["Sie", "wer\u00b7den", "l\u00e4n\u00b7ger", "le\u00b7ben", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVFIN", "KOUS", "PPER", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "Wenn du von jener Dame kommst,", "tokens": ["Wenn", "du", "von", "je\u00b7ner", "Da\u00b7me", "kommst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "bei der du arbeiten l\u00e4\u00dft,", "tokens": ["bei", "der", "du", "ar\u00b7bei\u00b7ten", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "(oder sie bei dir \u2013 so genau ist das nicht zu unterscheiden),", "tokens": ["(", "o\u00b7der", "sie", "bei", "dir", "\u2013", "so", "ge\u00b7nau", "ist", "das", "nicht", "zu", "un\u00b7ter\u00b7schei\u00b7den", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PPER", "APPR", "PPER", "$(", "ADV", "ADJD", "VAFIN", "PDS", "PTKNEG", "PTKZU", "VVINF", "$(", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.21": {"text": "dann stehn diese Dinger herum,", "tokens": ["dann", "stehn", "die\u00b7se", "Din\u00b7ger", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.22": {"text": "die H\u00e4user;", "tokens": ["die", "H\u00e4u\u00b7ser", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.23": {"text": "unz\u00e4hlige Male hast du deine Liebe an sie geklebt,", "tokens": ["un\u00b7z\u00e4h\u00b7li\u00b7ge", "Ma\u00b7le", "hast", "du", "dei\u00b7ne", "Lie\u00b7be", "an", "sie", "ge\u00b7klebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "+---+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.24": {"text": "sie geben sie schwach wieder.", "tokens": ["sie", "ge\u00b7ben", "sie", "schwach", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Sie sind kalt.", "tokens": ["Sie", "sind", "kalt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.26": {"text": "Da stehn die H\u00e4user,", "tokens": ["Da", "stehn", "die", "H\u00e4u\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.27": {"text": "und lassen in sich hausen,", "tokens": ["und", "las\u00b7sen", "in", "sich", "hau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.28": {"text": "und stehn wie die Mauern", "tokens": ["und", "stehn", "wie", "die", "Mau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.29": {"text": "\u2013 nat\u00fcrlich wie die Mauern \u2013", "tokens": ["\u2013", "na\u00b7t\u00fcr\u00b7lich", "wie", "die", "Mau\u00b7ern", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.30": {"text": "und werden l\u00e4nger leben als du.", "tokens": ["und", "wer\u00b7den", "l\u00e4n\u00b7ger", "le\u00b7ben", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "VVFIN", "KOUS", "PPER", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.31": {"text": "Wenn du zum Arzt gehst,", "tokens": ["Wenn", "du", "zum", "Arzt", "gehst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.32": {"text": "ob . . . ob nicht . . . vielleicht . . .", "tokens": ["ob", ".", ".", ".", "ob", "nicht", ".", ".", ".", "viel\u00b7leicht", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["KOUS", "$.", "$.", "$.", "KOUS", "PTKNEG", "$.", "$.", "$.", "ADV", "$.", "$.", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.33": {"text": "die Angst im Wartezimmer,", "tokens": ["die", "Angst", "im", "War\u00b7te\u00b7zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.34": {"text": "bevor du herankommst!", "tokens": ["be\u00b7vor", "du", "her\u00b7an\u00b7kommst", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.35": {"text": "Nie wieder! schw\u00f6rst du dir leise \u2013", "tokens": ["Nie", "wie\u00b7der", "!", "schw\u00f6rst", "du", "dir", "lei\u00b7se", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "VVFIN", "PPER", "PPER", "ADJD", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.36": {"text": "es ist dein dreiundachtzigster Schwur in dieser Beziehung . . .", "tokens": ["es", "ist", "dein", "drei\u00b7un\u00b7dacht\u00b7zigs\u00b7ter", "Schwur", "in", "die\u00b7ser", "Be\u00b7zie\u00b7hung", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "VVFIN", "APPR", "PDAT", "NN", "$.", "$.", "$."], "meter": "----+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "wenn du zum Arzt l\u00e4ufst,", "tokens": ["wenn", "du", "zum", "Arzt", "l\u00e4ufst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.38": {"text": "f\u00fcr nichts empf\u00e4nglich, mit einer einzigen fixen Idee im Kopf:", "tokens": ["f\u00fcr", "nichts", "emp\u00b7f\u00e4ng\u00b7lich", ",", "mit", "ei\u00b7ner", "ein\u00b7zi\u00b7gen", "fi\u00b7xen", "I\u00b7dee", "im", "Kopf", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADJD", "$,", "APPR", "ART", "ADJA", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+--+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.39": {"text": "dann h\u00e4usern sie da um dich herum", "tokens": ["dann", "h\u00e4u\u00b7sern", "sie", "da", "um", "dich", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PRF", "APZR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "\u2013 da kannst du machen, was du willst \u2013", "tokens": ["\u2013", "da", "kannst", "du", "ma\u00b7chen", ",", "was", "du", "willst", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "sie werden l\u00e4nger leben als du.", "tokens": ["sie", "wer\u00b7den", "l\u00e4n\u00b7ger", "le\u00b7ben", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVFIN", "KOUS", "PPER", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.42": {"text": "Und noch,", "tokens": ["Und", "noch", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.43": {"text": "wenn sie dich zu Grabe blasen,", "tokens": ["wenn", "sie", "dich", "zu", "Gra\u00b7be", "bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.44": {"text": "nein, heute blasen sie ja nicht mehr . . .", "tokens": ["nein", ",", "heu\u00b7te", "bla\u00b7sen", "sie", "ja", "nicht", "mehr", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "$.", "$.", "$."], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.45": {"text": "wenn sie dich in einem schwarz angestrichenen Wagen nach drau\u00dfen fahren,", "tokens": ["wenn", "sie", "dich", "in", "ei\u00b7nem", "schwarz", "an\u00b7ge\u00b7stri\u00b7che\u00b7nen", "Wa\u00b7gen", "nach", "drau\u00b7\u00dfen", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "ADJD", "ADJA", "NN", "APPR", "ADV", "VVINF", "$,"], "meter": "+-+-+-+--+--+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.46": {"text": "im Auto,", "tokens": ["im", "Au\u00b7to", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.47": {"text": "nat\u00fcrlich!", "tokens": ["na\u00b7t\u00fcr\u00b7lich", "!"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.48": {"text": "weil du es doch so eilig hast!", "tokens": ["weil", "du", "es", "doch", "so", "ei\u00b7lig", "hast", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Denke: du k\u00f6nntest etwas vers\u00e4umen!", "tokens": ["Den\u00b7ke", ":", "du", "k\u00f6nn\u00b7test", "et\u00b7was", "ver\u00b7s\u00e4u\u00b7men", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.50": {"text": "Wenn sie dich einpflanzen", "tokens": ["Wenn", "sie", "dich", "ein\u00b7pflan\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.51": {"text": "oder verbrennen,", "tokens": ["o\u00b7der", "ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.52": {"text": "so du 4 Mark 85 Mitgliedsbeitrag gezahlt hast", "tokens": ["so", "du", "4", "Mark", "85", "Mit\u00b7glieds\u00b7bei\u00b7trag", "ge\u00b7zahlt", "hast"], "token_info": ["word", "word", "number", "word", "number", "word", "word", "word"], "pos": ["ADV", "PPER", "CARD", "NN", "CARD", "NN", "VVPP", "VAFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.53": {"text": "und ein K\u00f6niglich Preu\u00dfischer Freidenker bist \u2013", "tokens": ["und", "ein", "K\u00f6\u00b7nig\u00b7lich", "Preu\u00b7\u00dfi\u00b7scher", "Frei\u00b7den\u00b7ker", "bist", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "VAFIN", "$("], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.54": {"text": "wenn sie dich dahin expedieren,", "tokens": ["wenn", "sie", "dich", "da\u00b7hin", "ex\u00b7pe\u00b7die\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.55": {"text": "wohin du, Sache Gewordener, dann geh\u00f6rst,", "tokens": ["wo\u00b7hin", "du", ",", "Sa\u00b7che", "Ge\u00b7wor\u00b7de\u00b7ner", ",", "dann", "ge\u00b7h\u00f6rst", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "NN", "NN", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.56": {"text": "weil du nun den andern tragisch-l\u00e4stig f\u00e4llst \u2013:", "tokens": ["weil", "du", "nun", "den", "an\u00b7dern", "tra\u00b7gischl\u00e4s\u00b7tig", "f\u00e4llst", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "ADJD", "VVFIN", "$(", "$."], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.57": {"text": "dann stehn da die H\u00e4user,", "tokens": ["dann", "stehn", "da", "die", "H\u00e4u\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.58": {"text": "die deine Dummheiten seit deiner Geburt mit angesehen haben,", "tokens": ["die", "dei\u00b7ne", "Dumm\u00b7hei\u00b7ten", "seit", "dei\u00b7ner", "Ge\u00b7burt", "mit", "an\u00b7ge\u00b7se\u00b7hen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "APPR", "VVPP", "VAINF", "$,"], "meter": "-+--+--+--+-+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.59": {"text": "und sind l\u00e4nger H\u00e4user, als du Mensch gewesen bist,", "tokens": ["und", "sind", "l\u00e4n\u00b7ger", "H\u00e4u\u00b7ser", ",", "als", "du", "Mensch", "ge\u00b7we\u00b7sen", "bist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "NN", "$,", "KOUS", "PPER", "NN", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.60": {"text": "und werden l\u00e4nger leben", "tokens": ["und", "wer\u00b7den", "l\u00e4n\u00b7ger", "le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.61": {"text": "als du.", "tokens": ["als", "du", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "PPER", "$."], "meter": "-+", "measure": "iambic.single"}}}}}