{"dta.poem.5335": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Belehrendes Gleichni\u00df.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wie wir, wenn wir gebohren werden,", "tokens": ["Wie", "wir", ",", "wenn", "wir", "ge\u00b7boh\u00b7ren", "wer\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "KOUS", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den gantzen Zustand unsrer Erden", "tokens": ["Den", "gant\u00b7zen", "Zu\u00b7stand", "uns\u00b7rer", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Schon sattsam zugerichtet finden;", "tokens": ["Schon", "satt\u00b7sam", "zu\u00b7ge\u00b7rich\u00b7tet", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So werden wir, wenn wir erblassen,", "tokens": ["So", "wer\u00b7den", "wir", ",", "wenn", "wir", "er\u00b7blas\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie in demselben Zustand lassen:", "tokens": ["Sie", "in", "dem\u00b7sel\u00b7ben", "Zu\u00b7stand", "las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Welt wird nicht einmahl gewahr, da\u00df wir verschwin-", "tokens": ["Die", "Welt", "wird", "nicht", "ein\u00b7mahl", "ge\u00b7wahr", ",", "da\u00df", "wir", "ver\u00b7schwin"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,", "KOUS", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie hoch, wie n\u00f6htig wir uns sch\u00e4tzen;", "tokens": ["Wie", "hoch", ",", "wie", "n\u00f6h\u00b7tig", "wir", "uns", "sch\u00e4t\u00b7zen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "PWAV", "ADJD", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So finden sich, an unsrer Stelle,", "tokens": ["So", "fin\u00b7den", "sich", ",", "an", "uns\u00b7rer", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.9": {"text": "Mit neuer Kraft sich hebt und steigt,", "tokens": ["Mit", "neu\u00b7er", "Kraft", "sich", "hebt", "und", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So bald die erste sich zum Untergange neigt)", "tokens": ["So", "bald", "die", "ers\u00b7te", "sich", "zum", "Un\u00b7ter\u00b7gan\u00b7ge", "neigt", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "PRF", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch immer neue gnug, die unsern Platz ersetzen.", "tokens": ["Doch", "im\u00b7mer", "neu\u00b7e", "gnug", ",", "die", "un\u00b7sern", "Platz", "er\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "ADV", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wenn wir nun alles lassen m\u00fcssen,", "tokens": ["Wenn", "wir", "nun", "al\u00b7les", "las\u00b7sen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum sind wir denn nicht geflissen,", "tokens": ["Wa\u00b7rum", "sind", "wir", "denn", "nicht", "ge\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den kurtzen Durchgang einzurichten,", "tokens": ["Den", "kurt\u00b7zen", "Durch\u00b7gang", "ein\u00b7zu\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jm fr\u00f6lichen Gebrauch der Sinnen, nach den Pflichten,", "tokens": ["Jm", "fr\u00f6\u00b7li\u00b7chen", "Ge\u00b7brauch", "der", "Sin\u00b7nen", ",", "nach", "den", "Pflich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die der, so alles schuf, wenn man es nur bedenckt,", "tokens": ["Die", "der", ",", "so", "al\u00b7les", "schuf", ",", "wenn", "man", "es", "nur", "be\u00b7denckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "$,", "ADV", "PIS", "VVFIN", "$,", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Uns in die Seelen eingesenckt?", "tokens": ["Uns", "in", "die", "See\u00b7len", "ein\u00b7ge\u00b7senckt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ob wir nun, da wir also handeln,", "tokens": ["Ob", "wir", "nun", ",", "da", "wir", "al\u00b7so", "han\u00b7deln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier, wie wir wandeln solten, wandeln,", "tokens": ["Hier", ",", "wie", "wir", "wan\u00b7deln", "sol\u00b7ten", ",", "wan\u00b7deln", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "VVFIN", "VMFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da wir den Wunder-Bau der Welt so wenig sch\u00e4tzen,", "tokens": ["Da", "wir", "den", "Wun\u00b7der\u00b7Bau", "der", "Welt", "so", "we\u00b7nig", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dar\u00fcber will ich dich jetzt selbst zum Richter setzen.", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "will", "ich", "dich", "jetzt", "selbst", "zum", "Rich\u00b7ter", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PRF", "ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wenn einst ein grosser Herr, zu seiner Ehre,", "tokens": ["Wenn", "einst", "ein", "gros\u00b7ser", "Herr", ",", "zu", "sei\u00b7ner", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "H\u00e4tt\u2019 einen Pallast aufgef\u00fchrt,", "tokens": ["H\u00e4tt'", "ei\u00b7nen", "Pal\u00b7last", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und da\u00df derselbige mit aller Pracht geziert,", "tokens": ["Und", "da\u00df", "der\u00b7sel\u00b7bi\u00b7ge", "mit", "al\u00b7ler", "Pracht", "ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wundersch\u00f6n von ihm geschm\u00fccket w\u00e4re,", "tokens": ["Und", "wun\u00b7der\u00b7sch\u00f6n", "von", "ihm", "ge\u00b7schm\u00fc\u00b7cket", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und er erlaubet\u2019 etwann Zween", "tokens": ["Und", "er", "er\u00b7lau\u00b7bet'", "et\u00b7wann", "Zween"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Pallasts Herrlichkeit zu sehen;", "tokens": ["Des", "Pal\u00b7lasts", "Herr\u00b7lich\u00b7keit", "zu", "se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der eine nun bewunderte die Pracht,", "tokens": ["Der", "ei\u00b7ne", "nun", "be\u00b7wun\u00b7der\u00b7te", "die", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Vergn\u00fcgte sich, er s\u00e4h\u2019 bald vorwerts, bald zur\u00fcck,", "tokens": ["Ver\u00b7gn\u00fcg\u00b7te", "sich", ",", "er", "s\u00e4h'", "bald", "vor\u00b7werts", ",", "bald", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "PPER", "VVFIN", "ADV", "ADV", "$,", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es g\u00e4b\u2019, auf jeden Schritt, sein aufger\u00e4umter Blick", "tokens": ["Es", "g\u00e4b'", ",", "auf", "je\u00b7den", "Schritt", ",", "sein", "auf\u00b7ge\u00b7r\u00e4um\u00b7ter", "Blick"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PIAT", "NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit frohen Minen zu verstehn,", "tokens": ["Mit", "fro\u00b7hen", "Mi\u00b7nen", "zu", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie er die Weisheit und die Macht", "tokens": ["Wie", "er", "die", "Weis\u00b7heit", "und", "die", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Des Herrn, der alles Wunder-sch\u00f6n", "tokens": ["Des", "Herrn", ",", "der", "al\u00b7les", "Wun\u00b7der\u00b7sch\u00f6n"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Geordnet und erbaut, nicht oft gnug zu erwegen,", "tokens": ["Ge\u00b7ord\u00b7net", "und", "er\u00b7baut", ",", "nicht", "oft", "gnug", "zu", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVPP", "$,", "PTKNEG", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nicht gnug zu sch\u00e4tzen, zu verehren,", "tokens": ["Nicht", "gnug", "zu", "sch\u00e4t\u00b7zen", ",", "zu", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKZU", "VVINF", "$,", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Noch zu erh\u00f6hen w\u00fcst\u2019, der andere hingegen", "tokens": ["Noch", "zu", "er\u00b7h\u00f6\u00b7hen", "w\u00fcst'", ",", "der", "an\u00b7de\u00b7re", "hin\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PTKZU", "VVINF", "VVFIN", "$,", "PRELS", "PIS", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "S\u00e4h\u2019 immer unter sich; Pracht, Ordnung, Glantz und", "tokens": ["S\u00e4h'", "im\u00b7mer", "un\u00b7ter", "sich", ";", "Pracht", ",", "Ord\u00b7nung", ",", "Glantz", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PRF", "$.", "NN", "$,", "NN", "$,", "NN", "KON"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Mit allem Reitz, n\u00e4hm\u2019 seinen Blick nicht ein,", "tokens": ["Mit", "al\u00b7lem", "Reitz", ",", "n\u00e4hm'", "sei\u00b7nen", "Blick", "nicht", "ein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "$,", "VVFIN", "PPOSAT", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Als den er blos allein", "tokens": ["Als", "den", "er", "blos", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "PPER", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Besch\u00e4ftigt\u2019, um ein wenig Sand,", "tokens": ["Be\u00b7sch\u00e4f\u00b7tigt'", ",", "um", "ein", "we\u00b7nig", "Sand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUI", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Der auf dem Boden gl\u00e4ntzt, zu suchen, und die Hand", "tokens": ["Der", "auf", "dem", "Bo\u00b7den", "gl\u00e4ntzt", ",", "zu", "su\u00b7chen", ",", "und", "die", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Jhn aufzuheben, auszustrecken", "tokens": ["Jhn", "auf\u00b7zu\u00b7he\u00b7ben", ",", "aus\u00b7zu\u00b7stre\u00b7cken"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPER", "VVIZU", "$,", "VVIZU"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Und ihn bey Kleinigkeiten einzustecken,", "tokens": ["Und", "ihn", "bey", "Klei\u00b7nig\u00b7kei\u00b7ten", "ein\u00b7zu\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Ob es ihm gleich nicht unbekannt,", "tokens": ["Ob", "es", "ihm", "gleich", "nicht", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Da\u00df man, beym Ausgang ihm, von dieser seiner B\u00fcrde,", "tokens": ["Da\u00df", "man", ",", "beym", "Aus\u00b7gang", "ihm", ",", "von", "die\u00b7ser", "sei\u00b7ner", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "APPRART", "NN", "PPER", "$,", "APPR", "PDAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Nicht das geringste lassen w\u00fcrde:", "tokens": ["Nicht", "das", "ge\u00b7rings\u00b7te", "las\u00b7sen", "w\u00fcr\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Sprich du nun selber, wessen Weise,", "tokens": ["Sprich", "du", "nun", "sel\u00b7ber", ",", "wes\u00b7sen", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Den sch\u00f6nen Pallast durchzugehn,", "tokens": ["Den", "sch\u00f6\u00b7nen", "Pal\u00b7last", "durch\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Gereicht von beiden doch am meisten dem zum Preise,", "tokens": ["Ge\u00b7reicht", "von", "bei\u00b7den", "doch", "am", "meis\u00b7ten", "dem", "zum", "Prei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "ADV", "PTKA", "PIS", "ART", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Der ihn so herrlich auferbauet?", "tokens": ["Der", "ihn", "so", "herr\u00b7lich", "au\u00b7fer\u00b7bau\u00b7et", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Auf denn, ihr Sterblichen, die ihr hier Wandrer seid,", "tokens": ["Auf", "denn", ",", "ihr", "Sterb\u00b7li\u00b7chen", ",", "die", "ihr", "hier", "Wand\u00b7rer", "seid", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erweget, was ihr thut, besinnet euch! beschauet", "tokens": ["Er\u00b7we\u00b7get", ",", "was", "ihr", "thut", ",", "be\u00b7sin\u00b7net", "euch", "!", "be\u00b7schau\u00b7et"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$.", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf eurer Wanderschaft, mit Lust, die Herrlichkeit", "tokens": ["Auf", "eu\u00b7rer", "Wan\u00b7der\u00b7schaft", ",", "mit", "Lust", ",", "die", "Herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des Pallasts dieser Welt! La\u00dft Sand und Erde liegen", "tokens": ["Des", "Pal\u00b7lasts", "die\u00b7ser", "Welt", "!", "La\u00dft", "Sand", "und", "Er\u00b7de", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PDAT", "NN", "$.", "VVIMP", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und sucht das W\u00fcrdigste die Seele zu vergn\u00fcgen.", "tokens": ["Und", "sucht", "das", "W\u00fcr\u00b7digs\u00b7te", "die", "See\u00b7le", "zu", "ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}