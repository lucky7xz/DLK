{"textgrid.poem.49710": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Erstklassige Menschen", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Aus Berlin kam eine neue Kunde,", "tokens": ["Aus", "Ber\u00b7lin", "kam", "ei\u00b7ne", "neu\u00b7e", "Kun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Die den guten Menschenfreund entsetzt,", "tokens": ["Die", "den", "gu\u00b7ten", "Men\u00b7schen\u00b7freund", "ent\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Denn es wurde bis zu dieser Stunde", "tokens": ["Denn", "es", "wur\u00b7de", "bis", "zu", "die\u00b7ser", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Nie so tief das Heiligste verletzt.", "tokens": ["Nie", "so", "tief", "das", "Hei\u00b7ligs\u00b7te", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "ART", "ADJA", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Dieses schwere Ungl\u00fcck mu\u00dften leiden", "tokens": ["Die\u00b7ses", "schwe\u00b7re", "Un\u00b7gl\u00fcck", "mu\u00df\u00b7ten", "lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Bankdirektorehegattens Koch.", "tokens": ["Bank\u00b7di\u00b7rek\u00b7to\u00b7re\u00b7he\u00b7gat\u00b7tens", "Koch", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Menschen erster Klasse sind die beiden \u2013", "tokens": ["Men\u00b7schen", "ers\u00b7ter", "Klas\u00b7se", "sind", "die", "bei\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VAFIN", "ART", "PIAT", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Oder waren es vor kurzem noch.", "tokens": ["O\u00b7der", "wa\u00b7ren", "es", "vor", "kur\u00b7zem", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "ADJA", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Ihnen kam ein kleiner Sohn abhanden,", "tokens": ["Ih\u00b7nen", "kam", "ein", "klei\u00b7ner", "Sohn", "ab\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ausgeblasen ward sein Lebensdocht.", "tokens": ["Aus\u00b7ge\u00b7bla\u00b7sen", "ward", "sein", "Le\u00b7bens\u00b7docht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Vor den Augen seiner Anverwandten", "tokens": ["Vor", "den", "Au\u00b7gen", "sei\u00b7ner", "An\u00b7ver\u00b7wand\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ward die b\u00f6se Greueltat vermocht.", "tokens": ["Ward", "die", "b\u00f6\u00b7se", "Greu\u00b7el\u00b7tat", "ver\u00b7mocht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "F\u00fcrchterlich gepeinigt von dem Schinder", "tokens": ["F\u00fcrch\u00b7ter\u00b7lich", "ge\u00b7pei\u00b7nigt", "von", "dem", "Schin\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVPP", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ging der Knabe in den Todesschlaf.", "tokens": ["Ging", "der", "Kna\u00b7be", "in", "den", "To\u00b7des\u00b7schlaf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und man zweifelt stark, ob mehr, ob minder", "tokens": ["Und", "man", "zwei\u00b7felt", "stark", ",", "ob", "mehr", ",", "ob", "min\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "ADJD", "$,", "KOUS", "ADV", "$,", "KOUS", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Nicht die Eltern eine Schuld betraf.", "tokens": ["Nicht", "die", "El\u00b7tern", "ei\u00b7ne", "Schuld", "be\u00b7traf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Tausend Stimmen haben laut geschrieen,", "tokens": ["Tau\u00b7send", "Stim\u00b7men", "ha\u00b7ben", "laut", "ge\u00b7schri\u00b7een", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df ein \u00bbJa\u00ab in Deutschland widerhallt!", "tokens": ["Da\u00df", "ein", "\u00bb", "Ja", "\u00ab", "in", "Deutschland", "wi\u00b7der\u00b7hallt", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "PTKANT", "$(", "APPR", "NE", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Nur ein einziger hat es verziehen:", "tokens": ["Nur", "ein", "ein\u00b7zi\u00b7ger", "hat", "es", "ver\u00b7zie\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wohlgeboren der Herr Staatsanwalt.", "tokens": ["Wohl\u00b7ge\u00b7bo\u00b7ren", "der", "Herr", "Staats\u00b7an\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$."], "meter": "+-+--++-+", "measure": "trochaic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Fr\u00e4gt mich einer, wie ich das erfasse?", "tokens": ["Fr\u00e4gt", "mich", "ei\u00b7ner", ",", "wie", "ich", "das", "er\u00b7fas\u00b7se", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "$,", "PWAV", "PPER", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Diese Meinung von der Elternpflicht?", "tokens": ["Die\u00b7se", "Mei\u00b7nung", "von", "der", "El\u00b7tern\u00b7pflicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u2013 Nun, es standen Menschen erster Klasse,", "tokens": ["\u2013", "Nun", ",", "es", "stan\u00b7den", "Men\u00b7schen", "ers\u00b7ter", "Klas\u00b7se", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PPER", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Will mich recht bed\u00fcnken, vor Gericht.", "tokens": ["Will", "mich", "recht", "be\u00b7d\u00fcn\u00b7ken", ",", "vor", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}