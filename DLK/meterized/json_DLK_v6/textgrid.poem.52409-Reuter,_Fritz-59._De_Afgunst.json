{"textgrid.poem.52409": {"metadata": {"author": {"name": "Reuter, Fritz", "birth": "N.A.", "death": "N.A."}, "title": "59. De Afgunst", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "De Fisch, de wull'n en K\u00f6nig w\u00e4hlen.", "tokens": ["De", "Fisch", ",", "de", "wull'n", "en", "K\u00f6\u00b7nig", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "FM", "FM", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Je, wer s\u00fcll't sin?", "tokens": ["Je", ",", "wer", "s\u00fcll't", "sin", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VVFIN", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Na, wer am fixsten swemmen k\u00fcnn,", "tokens": ["Na", ",", "wer", "am", "fix\u00b7sten", "swem\u00b7men", "k\u00fcnn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "De s\u00fcll von nu an K\u00f6nig spelen", "tokens": ["De", "s\u00fcll", "von", "nu", "an", "K\u00f6\u00b7nig", "spe\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Un in de Ostsee kummandieren.", "tokens": ["Un", "in", "de", "Ost\u00b7see", "kum\u00b7man\u00b7die\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sei s\u00fcnd denn nu ok alltausamen", "tokens": ["Sei", "s\u00fcnd", "denn", "nu", "ok", "all\u00b7tau\u00b7sa\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "KON", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Heranne treckt von nah un firn,", "tokens": ["Her\u00b7an\u00b7ne", "treckt", "von", "nah", "un", "firn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ADJD", "FM", "FM", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Ut B\u00e4k un Strom un Landsee kamen", "tokens": ["Ut", "B\u00e4k", "un", "Strom", "un", "Land\u00b7see", "ka\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "FM", "FM", "FM", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Tau de, de in de See all wir'n.", "tokens": ["Tau", "de", ",", "de", "in", "de", "See", "all", "wir'", "n."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["NE", "NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Dat Mal w\u00fcrd prickt entlang den Strand", "tokens": ["Dat", "Mal", "w\u00fcrd", "prickt", "ent\u00b7lang", "den", "Strand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Von Travem\u00fcn'n bet Warnem\u00fcn'n,", "tokens": ["Von", "Tra\u00b7ve\u00b7m\u00fcn'n", "bet", "War\u00b7ne\u00b7m\u00fcn'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Un an de beiden En'n, dor st\u00fcnn'n", "tokens": ["Un", "an", "de", "bei\u00b7den", "En'n", ",", "dor", "st\u00fcnn'n"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "APPR", "NE", "PIAT", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "De Wils un D\u00f6sch mit Fahnen in de Hand,", "tokens": ["De", "Wils", "un", "D\u00f6sch", "mit", "Fah\u00b7nen", "in", "de", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "NN", "APPR", "NN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Denn de w\u00fcrd'n dor as Richters stahn,", "tokens": ["Denn", "de", "w\u00fcrd'n", "dor", "as", "Rich\u00b7ters", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "NN", "VVFIN", "$,"], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.15": {"text": "Dat all'ns mit Rechten tau s\u00fcll gahn.", "tokens": ["Dat", "all'ns", "mit", "Rech\u00b7ten", "tau", "s\u00fcll", "gahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "De Fohrt geiht los, los geiht de Jagd.", "tokens": ["De", "Fohrt", "geiht", "los", ",", "los", "geiht", "de", "Jagd", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PTKVZ", "$,", "ADJD", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Wo hett dat Volk sick afmaracht!", "tokens": ["Wo", "hett", "dat", "Volk", "sick", "af\u00b7ma\u00b7racht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Dat jappt un snappt un swabt un spaddelt", "tokens": ["Dat", "jappt", "un", "snappt", "un", "swabt", "un", "spad\u00b7delt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "VVFIN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.19": {"text": "Mit Keim un Mul, mit Start un Flott,", "tokens": ["Mit", "Keim", "un", "Mul", ",", "mit", "Start", "un", "Flott", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "FM", "NN", "$,", "APPR", "NN", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Un m\u00e4nnigein hett, leiwer Gott!,", "tokens": ["Un", "m\u00e4n\u00b7ni\u00b7gein", "hett", ",", "lei\u00b7wer", "Gott", "!", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "VAFIN", "$,", "ADJD", "NN", "$.", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Sick richtig bet tau Dod afmaddelt.", "tokens": ["Sick", "rich\u00b7tig", "bet", "tau", "Dod", "af\u00b7mad\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVFIN", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "So kamen s' gegen Dobberan,", "tokens": ["So", "ka\u00b7men", "s'", "ge\u00b7gen", "Dob\u00b7be\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPR", "NE", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.23": {"text": "Dunn is dat d\u00f6rch ehr pustig Reih'n", "tokens": ["Dunn", "is", "dat", "d\u00f6rch", "ehr", "pus\u00b7tig", "Reih'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.nl", "FM.nl", "FM.nl", "FM.nl", "FM.nl", "ADJD", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.24": {"text": "Denn hen un her mit Fragen gahn.", "tokens": ["Denn", "hen", "un", "her", "mit", "Fra\u00b7gen", "gahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.25": {"text": "\u00bbwer is nu v\u00f6r?\u00ab fr\u00f6ggt irst de ein.", "tokens": ["\u00bb", "wer", "is", "nu", "v\u00f6r", "?", "\u00ab", "fr\u00f6ggt", "irst", "de", "ein", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "FM", "FM", "FM", "$.", "$(", "VVFIN", "ADV", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "\u00bbwer is nu v\u00f6r?\u00ab fr\u00f6ggt all's tausamen.", "tokens": ["\u00bb", "wer", "is", "nu", "v\u00f6r", "?", "\u00ab", "fr\u00f6ggt", "all's", "tau\u00b7sa\u00b7men", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "FM", "FM", "FM", "$.", "$(", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "\u00bbde Hiring!\u00ab r\u00f6ppt't von V\u00f6ren her,", "tokens": ["\u00bb", "de", "Hi\u00b7ring", "!", "\u00ab", "r\u00f6ppt't", "von", "V\u00f6\u00b7ren", "her", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "$.", "$(", "VVFIN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "\u00bbde Hiring hett de Spitz uns namen!", "tokens": ["\u00bb", "de", "Hi\u00b7ring", "hett", "de", "Spitz", "uns", "na\u00b7men", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "VAFIN", "NE", "NE", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "De Hiring! Hiring! De is v\u00f6r!", "tokens": ["De", "Hi\u00b7ring", "!", "Hi\u00b7ring", "!", "De", "is", "v\u00f6r", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "NN", "$.", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Mit den'n k\u00fcmmt h\u00fct kein Deuwel mit.\u00ab", "tokens": ["Mit", "den'n", "k\u00fcmmt", "h\u00fct", "kein", "Deu\u00b7wel", "mit", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDS", "VVFIN", "ADJD", "PIAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "\u00bbde nakte Hiring!\u00ab seggt de B\u00fctt", "tokens": ["\u00bb", "de", "nak\u00b7te", "Hi\u00b7ring", "!", "\u00ab", "seggt", "de", "B\u00fctt"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "NE", "ADJA", "NN", "$.", "$(", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Un tog ehr leiwes Mul verquer,", "tokens": ["Un", "tog", "ehr", "lei\u00b7wes", "Mul", "ver\u00b7quer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.33": {"text": "\u00bbde nakte Hiring! De is v\u00f6r!", "tokens": ["\u00bb", "de", "nak\u00b7te", "Hi\u00b7ring", "!", "De", "is", "v\u00f6r", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ADJA", "NN", "$.", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Nu kik doch mal!\u00ab", "tokens": ["Nu", "kik", "doch", "mal", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NN", "ADV", "ADV", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.35": {"text": "Un tog ehr leiwes Mul v\u00f6r Afgunst dal.", "tokens": ["Un", "tog", "ehr", "lei\u00b7wes", "Mul", "v\u00f6r", "Af\u00b7gunst", "dal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.36": {"text": "Dunn st\u00f6dd de Bedklock tau Dobb'ran,", "tokens": ["Dunn", "st\u00f6dd", "de", "Bed\u00b7klock", "tau", "Dob\u00b7b'\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "Dunn blew dat Mul ehr scheiw bestahn.", "tokens": ["Dunn", "blew", "dat", "Mul", "ehr", "scheiw", "be\u00b7stahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}