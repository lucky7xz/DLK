{"textgrid.poem.64759": {"metadata": {"author": {"name": "K\u00e4stner, Abraham Gotthelf", "birth": "N.A.", "death": "N.A."}, "title": "6. Anakreontische Ode", "genre": "verse", "period": "N.A.", "pub_year": 1751, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich kann kein ", "tokens": ["Ich", "kann", "kein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Und in erhabnen Liedern", "tokens": ["Und", "in", "er\u00b7hab\u00b7nen", "Lie\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von hoher Weisheit singen;", "tokens": ["Von", "ho\u00b7her", "Weis\u00b7heit", "sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich kann nicht, muntres Scherzen", "tokens": ["Ich", "kann", "nicht", ",", "mun\u00b7tres", "Scher\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "$,", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit Wissenschaft zu zieren,", "tokens": ["Mit", "Wis\u00b7sen\u00b7schaft", "zu", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Nach ", "tokens": ["Nach"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Viel lesen und viel denken;", "tokens": ["Viel", "le\u00b7sen", "und", "viel", "den\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "ADV", "VVINF", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.8": {"text": "Ich kann mit ", "tokens": ["Ich", "kann", "mit"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.10": {"text": "Kein Trauerspiel erfinden;", "tokens": ["Kein", "Trau\u00b7er\u00b7spiel", "er\u00b7fin\u00b7den", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Ich kann nicht Fabeln machen,", "tokens": ["Ich", "kann", "nicht", "Fa\u00b7beln", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.14": {"text": "Ich kann nicht, k\u00fchn wie ", "tokens": ["Ich", "kann", "nicht", ",", "k\u00fchn", "wie"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "$,", "ADJD", "KOKOM"], "meter": "+---+", "measure": "dactylic.init"}, "line.15": {"text": "In pr\u00e4chtgen neuen T\u00f6nen", "tokens": ["In", "pr\u00e4cht\u00b7gen", "neu\u00b7en", "T\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Die M\u00e4dchen ernsten Tiefsinn,", "tokens": ["Die", "M\u00e4d\u00b7chen", "erns\u00b7ten", "Tief\u00b7sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Die Stutzer Andacht lehren.", "tokens": ["Die", "Stut\u00b7zer", "An\u00b7dacht", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Auch kann ich nicht wie ", "tokens": ["Auch", "kann", "ich", "nicht", "wie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "KOKOM"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.19": {"text": "Von Thieren, Pflanzen, Steinen,", "tokens": ["Von", "Thie\u00b7ren", ",", "Pflan\u00b7zen", ",", "Stei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "Von T\u00fcrken und Gespenstern,", "tokens": ["Von", "T\u00fcr\u00b7ken", "und", "Ge\u00b7spens\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Selbst Weisen zum Erg\u00f6tzen,", "tokens": ["Selbst", "Wei\u00b7sen", "zum", "Er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.22": {"text": "Sind sie nur keine Alten,", "tokens": ["Sind", "sie", "nur", "kei\u00b7ne", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Sind sie nur keine T\u00fcrken,", "tokens": ["Sind", "sie", "nur", "kei\u00b7ne", "T\u00fcr\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "Sind sie nur keine Steine,", "tokens": ["Sind", "sie", "nur", "kei\u00b7ne", "Stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Anakreontisch scherzen.", "tokens": ["A\u00b7nak\u00b7re\u00b7on\u00b7tisch", "scher\u00b7zen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Was Henker soll ich machen,", "tokens": ["Was", "Hen\u00b7ker", "soll", "ich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df ich ein Dichter werde?", "tokens": ["Da\u00df", "ich", "ein", "Dich\u00b7ter", "wer\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gedankenleere Prose,", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7lee\u00b7re", "Pro\u00b7se", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In ungereimten Zeilen,", "tokens": ["In", "un\u00b7ge\u00b7reim\u00b7ten", "Zei\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "In Dreyquerfingerzeilen,", "tokens": ["In", "Drey\u00b7quer\u00b7fin\u00b7ger\u00b7zei\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Von M\u00e4dchen und von Weine,", "tokens": ["Von", "M\u00e4d\u00b7chen", "und", "von", "Wei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Von Weine und von M\u00e4dchen,", "tokens": ["Von", "Wei\u00b7ne", "und", "von", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Von Trinken und von K\u00fcssen,", "tokens": ["Von", "Trin\u00b7ken", "und", "von", "K\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Von K\u00fcssen und von Trinken,", "tokens": ["Von", "K\u00fcs\u00b7sen", "und", "von", "Trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Und wieder Wein und M\u00e4dchen,", "tokens": ["Und", "wie\u00b7der", "Wein", "und", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Und wieder Ku\u00df und Trinken,", "tokens": ["Und", "wie\u00b7der", "Ku\u00df", "und", "Trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und lauter Wein und M\u00e4dchen", "tokens": ["Und", "lau\u00b7ter", "Wein", "und", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Und lauter Ku\u00df und Trinken,", "tokens": ["Und", "lau\u00b7ter", "Ku\u00df", "und", "Trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Und nichts als Wein und M\u00e4dchen", "tokens": ["Und", "nichts", "als", "Wein", "und", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "KOKOM", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Und nichts als Ku\u00df und Trinken,", "tokens": ["Und", "nichts", "als", "Ku\u00df", "und", "Trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Und immer so gekindert,", "tokens": ["Und", "im\u00b7mer", "so", "ge\u00b7kin\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Will ich halbschlafend schreiben.", "tokens": ["Will", "ich", "halb\u00b7schla\u00b7fend", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.18": {"text": "Das hei\u00dfen unsere Zeiten", "tokens": ["Das", "hei\u00b7\u00dfen", "un\u00b7se\u00b7re", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}