{"textgrid.poem.41474": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Lauf der Welt", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Unz\u00e4hlich ist der Schmeichler Haufen,", "tokens": ["Un\u00b7z\u00e4h\u00b7lich", "ist", "der", "Schmeich\u00b7ler", "Hau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die jeden Gro\u00dfen \u00fcberlaufen,", "tokens": ["Die", "je\u00b7den", "Gro\u00b7\u00dfen", "\u00fc\u00b7berl\u00b7au\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So lang er sich erh\u00e4lt.", "tokens": ["So", "lang", "er", "sich", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch gleitet er von seinen H\u00f6hen;", "tokens": ["Doch", "glei\u00b7tet", "er", "von", "sei\u00b7nen", "H\u00f6\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So kann er bald sich einsam sehen.", "tokens": ["So", "kann", "er", "bald", "sich", "ein\u00b7sam", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ein D\u00fcrftiger sucht seine Freunde:", "tokens": ["Ein", "D\u00fcrf\u00b7ti\u00b7ger", "sucht", "sei\u00b7ne", "Freun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch alle meiden ihn als Feinde;", "tokens": ["Doch", "al\u00b7le", "mei\u00b7den", "ihn", "als", "Fein\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein er erbet' Geld.", "tokens": ["Al\u00b7lein", "er", "er\u00b7bet'", "Geld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Sogleich erscheinen zehn Bekannten", "tokens": ["Sog\u00b7leich", "er\u00b7schei\u00b7nen", "zehn", "Be\u00b7kann\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJA", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und zehn entbehrliche Verwandten.", "tokens": ["Und", "zehn", "ent\u00b7behr\u00b7li\u00b7che", "Ver\u00b7wand\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ein Schulfuchs hofft mit d\u00fcrren Gr\u00fcnden", "tokens": ["Ein", "Schul\u00b7fuchs", "hofft", "mit", "d\u00fcr\u00b7ren", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Beifall aller Welt zu finden:", "tokens": ["Den", "Bei\u00b7fall", "al\u00b7ler", "Welt", "zu", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein er wird geprellt.", "tokens": ["Al\u00b7lein", "er", "wird", "ge\u00b7prellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mein M\u00e4dchen macht oft falsche Schl\u00fcsse:", "tokens": ["Mein", "M\u00e4d\u00b7chen", "macht", "oft", "fal\u00b7sche", "Schl\u00fcs\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch \u00fcberzeugt sie mich durch K\u00fcsse.", "tokens": ["Doch", "\u00fc\u00b7berz\u00b7eugt", "sie", "mich", "durch", "K\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ein freies Weib von zwanzig Jahren", "tokens": ["Ein", "frei\u00b7es", "Weib", "von", "zwan\u00b7zig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist zwar in vielem unerfahren:", "tokens": ["Ist", "zwar", "in", "vie\u00b7lem", "un\u00b7er\u00b7fah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch, was sie sagt, gef\u00e4llt.", "tokens": ["Doch", ",", "was", "sie", "sagt", ",", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Gebt ihr noch zwanzig Jahre dr\u00fcber:", "tokens": ["Gebt", "ihr", "noch", "zwan\u00b7zig", "Jah\u00b7re", "dr\u00fc\u00b7ber", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "CARD", "NN", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So h\u00f6rt man ihre Tochter lieber.", "tokens": ["So", "h\u00f6rt", "man", "ih\u00b7re", "Toch\u00b7ter", "lie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Leander stimmet s\u00fc\u00dfe T\u00f6ne,", "tokens": ["Le\u00b7an\u00b7der", "stim\u00b7met", "s\u00fc\u00b7\u00dfe", "T\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und singt und seufzet seiner Sch\u00f6ne,", "tokens": ["Und", "singt", "und", "seuf\u00b7zet", "sei\u00b7ner", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bis ihr das Ohr fast gellt.", "tokens": ["Bis", "ihr", "das", "Ohr", "fast", "gellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Allein, eh' er recht ausgesungen,", "tokens": ["Al\u00b7lein", ",", "eh'", "er", "recht", "aus\u00b7ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hat schon ein andrer sie bezwungen.", "tokens": ["Hat", "schon", "ein", "an\u00b7drer", "sie", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Stax sucht am Montag Doris K\u00fcsse:", "tokens": ["Stax", "sucht", "am", "Mon\u00b7tag", "Do\u00b7ris", "K\u00fcs\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "NE", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Am Dienstag find't er Hindernisse:", "tokens": ["Am", "Diens\u00b7tag", "find't", "er", "Hin\u00b7der\u00b7nis\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Am Mittwoch siegt der Held.", "tokens": ["Am", "Mitt\u00b7woch", "siegt", "der", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Am Donnerstag vergehn die Triebe:", "tokens": ["Am", "Don\u00b7ners\u00b7tag", "ver\u00b7gehn", "die", "Trie\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Am Freitag sucht er neue Liebe.", "tokens": ["Am", "Frei\u00b7tag", "sucht", "er", "neu\u00b7e", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Cephise schw\u00f6rt: Sie will ihr Leben", "tokens": ["Ce\u00b7phi\u00b7se", "schw\u00f6rt", ":", "Sie", "will", "ihr", "Le\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "PPER", "VMFIN", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der stillen Einsamkeit ergeben,", "tokens": ["Der", "stil\u00b7len", "Ein\u00b7sam\u00b7keit", "er\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und h\u00f6hnt was sich gesellt.", "tokens": ["Und", "h\u00f6hnt", "was", "sich", "ge\u00b7sellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PRF", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Drauf will sie sich durch Heirath adeln,", "tokens": ["Drauf", "will", "sie", "sich", "durch", "Hei\u00b7rath", "a\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und spricht zu allen, die sie tadeln:", "tokens": ["Und", "spricht", "zu", "al\u00b7len", ",", "die", "sie", "ta\u00b7deln", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIS", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ein M\u00e4dchen voller Weisheitsgr\u00fcnde", "tokens": ["Ein", "M\u00e4d\u00b7chen", "vol\u00b7ler", "Weis\u00b7heits\u00b7gr\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt jeden Ku\u00df f\u00fcr eine S\u00fcnde,", "tokens": ["H\u00e4lt", "je\u00b7den", "Ku\u00df", "f\u00fcr", "ei\u00b7ne", "S\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bis ihr ein Freund gef\u00e4llt.", "tokens": ["Bis", "ihr", "ein", "Freund", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hat dieser sie dann \u00fcberwunden,", "tokens": ["Hat", "die\u00b7ser", "sie", "dann", "\u00fc\u00b7berw\u00b7un\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So sagt sie selbst in frohen Stunden:", "tokens": ["So", "sagt", "sie", "selbst", "in", "fro\u00b7hen", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wenn junge Wittwen traurig scheinen,", "tokens": ["Wenn", "jun\u00b7ge", "Witt\u00b7wen", "trau\u00b7rig", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und in dem Mann sich selbst beweinen,", "tokens": ["Und", "in", "dem", "Mann", "sich", "selbst", "be\u00b7wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So ist es unverstellt.", "tokens": ["So", "ist", "es", "un\u00b7ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch keine sieht den Trauerschleier", "tokens": ["Doch", "kei\u00b7ne", "sieht", "den", "Trau\u00b7er\u00b7schlei\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit gr\u00f6\u00dfrer Lust, als einen Freier.", "tokens": ["Mit", "gr\u00f6\u00df\u00b7rer", "Lust", ",", "als", "ei\u00b7nen", "Frei\u00b7er", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Lauf der Welt.", "tokens": ["Das", "ist", "der", "Lauf", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}