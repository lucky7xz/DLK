{"dta.poem.9414": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "Denen  \n Ehrenvesten/ Vor Achtbahren/ und  \n Wohlgel\u00e4hrten  \n  Herrn M. Johann B\u00f6hmen/  \n Keyserlichen Poeten/ bey der Schu-  \n len zu Dre\u00dfden wohlverordneten  \n Rectorn/  \n  Herrn Christian Brehmen/  \n Chur- und F\u00fcrstlichen S\u00e4chst-  \n schen Bedienten/ etc.  \n  Herrn Johann Cramern/  \n aus Frie\u00dfland.  \n  Herrn Christian B\u00fcrgern/  \n von Dre\u00dfden.  \n  Herrn Julius August Tucker-  \n mannen/ von Wolffenb\u00fcttel.  \n  W. G. u. D.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es ging in einen Wald ein J\u00fcngling ausspazieren/", "tokens": ["Es", "ging", "in", "ei\u00b7nen", "Wald", "ein", "J\u00fcng\u00b7ling", "aus\u00b7spa\u00b7zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und fand ein Jungfer Volck den sch\u00f6nen reyhen", "tokens": ["und", "fand", "ein", "Jung\u00b7fer", "Volck", "den", "sch\u00f6\u00b7nen", "rey\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "f\u00fchren:", "tokens": ["f\u00fch\u00b7ren", ":"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Gott gr\u00fc\u00df' Euch alle zehn/ jhr sch\u00f6nen Jungfern", "tokens": ["Gott", "gr\u00fc\u00df'", "Euch", "al\u00b7le", "zehn", "/", "jhr", "sch\u00f6\u00b7nen", "Jung\u00b7fern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PIAT", "CARD", "$(", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Jhr/", "tokens": ["Ihr", "/"], "token_info": ["word", "punct"], "pos": ["PPER", "$("], "meter": "-", "measure": "single.down"}, "line.6": {"text": "fing er z-jhnen an; Die eine tritt herf\u00fcr", "tokens": ["fing", "er", "z\u00b7jh\u00b7nen", "an", ";", "Die", "ei\u00b7ne", "tritt", "her\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJA", "PTKVZ", "$.", "ART", "PIS", "VVFIN", "ADV"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.7": {"text": "und spricht/ mit gunst/ mein Freund/ wie? wenn wir", "tokens": ["und", "spricht", "/", "mit", "gunst", "/", "mein", "Freund", "/", "wie", "?", "wenn", "wir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "$(", "APPR", "NN", "$(", "PPOSAT", "NN", "$(", "PWAV", "$.", "KOUS", "PPER"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "alle weren", "tokens": ["al\u00b7le", "we\u00b7ren"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "noch eins so viel als jtzt/ ja wenn uns wolte mehren", "tokens": ["noch", "eins", "so", "viel", "als", "jtzt", "/", "ja", "wenn", "uns", "wol\u00b7te", "meh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "ADV", "PIAT", "KOKOM", "ADV", "$(", "ADV", "KOUS", "PPER", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "das dritte theil dazu: so weren wir allein", "tokens": ["das", "drit\u00b7te", "theil", "da\u00b7zu", ":", "so", "we\u00b7ren", "wir", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "so viel von drei\u00dfigen/ al\u00df \u00fcber zehn wir seyn.", "tokens": ["so", "viel", "von", "drei\u00b7\u00dfi\u00b7gen", "/", "al\u00df", "\u00fc\u00b7ber", "zehn", "wir", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "VVINF", "$(", "KOUS", "APPR", "CARD", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nun/ weil der J\u00fcngling nicht die rechte zahl getroffen/", "tokens": ["Nun", "/", "weil", "der", "J\u00fcng\u00b7ling", "nicht", "die", "rech\u00b7te", "zahl", "ge\u00b7trof\u00b7fen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "ART", "NN", "PTKNEG", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So rechne du hieraus und la\u00df nicht lang' uns hoffen/", "tokens": ["So", "rech\u00b7ne", "du", "hier\u00b7aus", "und", "la\u00df", "nicht", "lang'", "uns", "hof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "KON", "VVIMP", "PTKNEG", "ADV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "wirstu die rechte zahl uns balde machen kunt/", "tokens": ["wirs\u00b7tu", "die", "rech\u00b7te", "zahl", "uns", "bal\u00b7de", "ma\u00b7chen", "kunt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "PPER", "ADV", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So soll die eine dier von jhnen seyn vergunt!", "tokens": ["So", "soll", "die", "ei\u00b7ne", "dier", "von", "jh\u00b7nen", "seyn", "ver\u00b7gunt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ART", "NN", "APPR", "PPER", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}