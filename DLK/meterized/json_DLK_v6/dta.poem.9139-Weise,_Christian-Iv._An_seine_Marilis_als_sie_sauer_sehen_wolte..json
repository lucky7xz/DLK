{"dta.poem.9139": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  \n An seine Marilis/ als sie sauer sehen wolte.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.71", "en:0.28"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ach! mein Marilis/ was hab ich dann gethan/", "tokens": ["Ach", "!", "mein", "Ma\u00b7ri\u00b7lis", "/", "was", "hab", "ich", "dann", "ge\u00b7than", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPOSAT", "NE", "$(", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "We\u00dfwegen sihst du mich mit solchen augen an/", "tokens": ["We\u00df\u00b7we\u00b7gen", "sihst", "du", "mich", "mit", "sol\u00b7chen", "au\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "APPR", "PIAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist dann die gunst schon aus/ und soll der augen schein", "tokens": ["Ist", "dann", "die", "gunst", "schon", "aus", "/", "und", "soll", "der", "au\u00b7gen", "schein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "PTKVZ", "$(", "KON", "VMFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der meine sonne war/ nun mein comete seyn.", "tokens": ["Der", "mei\u00b7ne", "son\u00b7ne", "war", "/", "nun", "mein", "co\u00b7me\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$(", "ADV", "PPOSAT", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "2. Was hast du dann darvon/ da\u00df sich das rosenfeld", "tokens": ["Was", "hast", "du", "dann", "dar\u00b7von", "/", "da\u00df", "sich", "das", "ro\u00b7sen\u00b7feld"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "PAV", "$(", "KOUS", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der wangen also rauh als wie ein dornbusch stellt?", "tokens": ["Der", "wan\u00b7gen", "al\u00b7so", "rauh", "als", "wie", "ein", "dorn\u00b7busch", "stellt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "KOKOM", "KOKOM", "ART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und da\u00df der sch\u00f6ne mund/ der sonst so s\u00fcsse lacht/", "tokens": ["Und", "da\u00df", "der", "sch\u00f6\u00b7ne", "mund", "/", "der", "sonst", "so", "s\u00fcs\u00b7se", "lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "$(", "ART", "ADV", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mir alle fr\u00f6lichkeit zu lauter nichte macht.", "tokens": ["Mir", "al\u00b7le", "fr\u00f6\u00b7lich\u00b7keit", "zu", "lau\u00b7ter", "nich\u00b7te", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "APPR", "PIAT", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "3. Du allerliebstes kind/ wo ist die werthe hand/", "tokens": ["Du", "al\u00b7ler\u00b7liebs\u00b7tes", "kind", "/", "wo", "ist", "die", "wert\u00b7he", "hand", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "PWAV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sich vor dieser zeit umb meine finger wand?", "tokens": ["Die", "sich", "vor", "die\u00b7ser", "zeit", "umb", "mei\u00b7ne", "fin\u00b7ger", "wand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat sie mich gnug gedr\u00fcckt/ mein hertz/ und soll ich nun", "tokens": ["Hat", "sie", "mich", "gnug", "ge\u00b7dr\u00fcckt", "/", "mein", "hertz", "/", "und", "soll", "ich", "nun"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "VVPP", "$(", "PPOSAT", "NN", "$(", "KON", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In deiner gegenwart nicht mehr so freundlich thun?", "tokens": ["In", "dei\u00b7ner", "ge\u00b7gen\u00b7wart", "nicht", "mehr", "so", "freund\u00b7lich", "thun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "4. Wo ist das liebe ding/ die s\u00fcsse Marilis/", "tokens": ["Wo", "ist", "das", "lie\u00b7be", "ding", "/", "die", "s\u00fcs\u00b7se", "Ma\u00b7ri\u00b7lis", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ihren diener sonst so fein willkommen hie\u00df?", "tokens": ["Die", "ih\u00b7ren", "die\u00b7ner", "sonst", "so", "fein", "will\u00b7kom\u00b7men", "hie\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du bist es warlich nicht dein ansehn das mich plagt/", "tokens": ["Du", "bist", "es", "war\u00b7lich", "nicht", "dein", "an\u00b7sehn", "das", "mich", "plagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "PPOSAT", "VVINF", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat meine bl\u00f6digkeit fast aus der welt gejagt.", "tokens": ["Hat", "mei\u00b7ne", "bl\u00f6\u00b7dig\u00b7keit", "fast", "aus", "der", "welt", "ge\u00b7jagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "5. Ach kan ein m\u00e4dgen auch ein bi\u00dfgen b\u00f6se seyn/", "tokens": ["Ach", "kan", "ein", "m\u00e4d\u00b7gen", "auch", "ein", "bi\u00df\u00b7gen", "b\u00f6\u00b7se", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "ADJA", "ADV", "ART", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nim\u0303t der eyfer auch die jungfer-hertzen ein?", "tokens": ["Und", "nim\u0303t", "der", "ey\u00b7fer", "auch", "die", "jung\u00b7fer\u00b7hert\u00b7zen", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich h\u00e4tt es nicht vermeynt/ dieweil betr\u00fcbt und sch\u00f6n/", "tokens": ["Ich", "h\u00e4tt", "es", "nicht", "ver\u00b7meynt", "/", "die\u00b7weil", "be\u00b7tr\u00fcbt", "und", "sch\u00f6n", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$(", "ADV", "VVPP", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Belieblich und erz\u00fcrnt nicht wohl beysammen stehn.", "tokens": ["Be\u00b7lieb\u00b7lich", "und", "er\u00b7z\u00fcrnt", "nicht", "wohl", "bey\u00b7sam\u00b7men", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "PTKNEG", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "6. Nun f\u00fchl ich deinen zorn der mir den tag zur nacht/", "tokens": ["Nun", "f\u00fchl", "ich", "dei\u00b7nen", "zorn", "der", "mir", "den", "tag", "zur", "nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "ART", "PPER", "ART", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die nacht zu lauter angst/ die angst zur speise macht.", "tokens": ["Die", "nacht", "zu", "lau\u00b7ter", "angst", "/", "die", "angst", "zur", "spei\u00b7se", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$(", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach meine Marilis/ hab ich dir was gethan?", "tokens": ["Ach", "mei\u00b7ne", "Ma\u00b7ri\u00b7lis", "/", "hab", "ich", "dir", "was", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PPOSAT", "NE", "$(", "VAFIN", "PPER", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie? oder stellst du dich also zum possen an.", "tokens": ["Wie", "?", "o\u00b7der", "stellst", "du", "dich", "al\u00b7so", "zum", "pos\u00b7sen", "an", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KON", "VVFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "7. Ich h\u00f6re doch nicht auf dir an die hand zu gehn/", "tokens": ["Ich", "h\u00f6\u00b7re", "doch", "nicht", "auf", "dir", "an", "die", "hand", "zu", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wilst du meine pflicht aus bo\u00dfheit nicht verstehn;", "tokens": ["Und", "wilst", "du", "mei\u00b7ne", "pflicht", "aus", "bo\u00df\u00b7heit", "nicht", "ver\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wei\u00df ich da\u00df der trost in meinem hertzen gr\u00fcnt/", "tokens": ["So", "wei\u00df", "ich", "da\u00df", "der", "trost", "in", "mei\u00b7nem", "hert\u00b7zen", "gr\u00fcnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich habe deinen zorn mit willen nicht verdient.", "tokens": ["Ich", "ha\u00b7be", "dei\u00b7nen", "zorn", "mit", "wil\u00b7len", "nicht", "ver\u00b7dient", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}