{"dta.poem.19792": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Don Geishaar .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "M\u00fcller, warum thust erbleichen?               ", "tokens": ["M\u00fcl\u00b7ler", ",", "wa\u00b7rum", "thust", "er\u00b7blei\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00dfe Farb bez\u00fcchtigt dich,", "tokens": ["Wei\u00b7\u00dfe", "Farb", "be\u00b7z\u00fcch\u00b7tigt", "dich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aller Muth will von dir weichen,", "tokens": ["Al\u00b7ler", "Muth", "will", "von", "dir", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ist dir, dich frage ich,", "tokens": ["Was", "ist", "dir", ",", "dich", "fra\u00b7ge", "ich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Diebst\u00e4hl dir vielleicht einfallen", "tokens": ["Dieb\u00b7st\u00e4hl", "dir", "viel\u00b7leicht", "ein\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVINF"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Die begangen hast beim Mahlen,", "tokens": ["Die", "be\u00b7gan\u00b7gen", "hast", "beim", "Mah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "VAFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Weisser M\u00fcller ohne Scham,", "tokens": ["Weis\u00b7ser", "M\u00fcl\u00b7ler", "oh\u00b7ne", "Scham", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weil du f\u00fchrst ein Diebesnahm.", "tokens": ["Weil", "du", "f\u00fchrst", "ein", "Die\u00b7bes\u00b7nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Schneiderlein, was thust du fragen?", "tokens": ["Schnei\u00b7derl\u00b7ein", ",", "was", "thust", "du", "fra\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warum ich ganz wei\u00df erschein,", "tokens": ["Wa\u00b7rum", "ich", "ganz", "wei\u00df", "er\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Solltest mir zuvor erst sagen,", "tokens": ["Soll\u00b7test", "mir", "zu\u00b7vor", "erst", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was bedeut' die R\u00f6the dein?", "tokens": ["Was", "be\u00b7deut'", "die", "R\u00f6\u00b7the", "dein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Roth bist du vor lauter Fleckel,", "tokens": ["Roth", "bist", "du", "vor", "lau\u00b7ter", "Fle\u00b7ckel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die gestohlen du Geisb\u00f6ckel,", "tokens": ["Die", "ge\u00b7stoh\u00b7len", "du", "Geis\u00b7b\u00f6\u00b7ckel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Schneider grossen Diebstahl \u00fcbt,", "tokens": ["Schnei\u00b7der", "gros\u00b7sen", "Dieb\u00b7stahl", "\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Gar nichts als den Abschnitt liebt.", "tokens": ["Gar", "nichts", "als", "den", "Ab\u00b7schnitt", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Mehldieb sei nicht also trutzig,", "tokens": ["Mehl\u00b7dieb", "sei", "nicht", "al\u00b7so", "trut\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Halte mir nicht Diebstahl f\u00fcr,", "tokens": ["Hal\u00b7te", "mir", "nicht", "Dieb\u00b7stahl", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "NN", "APPR", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mache dich nicht so unn\u00fctzig,", "tokens": ["Ma\u00b7che", "dich", "nicht", "so", "un\u00b7n\u00fct\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Kehre nur vor deiner Th\u00fcr,", "tokens": ["Keh\u00b7re", "nur", "vor", "dei\u00b7ner", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schwarzmehl du f\u00fcr wei\u00df thust geben,", "tokens": ["Schwarz\u00b7mehl", "du", "f\u00fcr", "wei\u00df", "thust", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Davon stiehlst du noch daneben,", "tokens": ["Da\u00b7von", "stiehlst", "du", "noch", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PAV", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Ja die Kleien stiehlst du auch,", "tokens": ["Ja", "die", "Klei\u00b7en", "stiehlst", "du", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Das ist ja der M\u00fcller Brauch.", "tokens": ["Das", "ist", "ja", "der", "M\u00fcl\u00b7ler", "Brauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Was thut doch der Gei\u00dfbock mecken,", "tokens": ["Was", "thut", "doch", "der", "Gei\u00df\u00b7bock", "me\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "F\u00e4ngt da mit mir H\u00e4ndel an,", "tokens": ["F\u00e4ngt", "da", "mit", "mir", "H\u00e4n\u00b7del", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Will ihn in ein Beutel stecken,", "tokens": ["Will", "ihn", "in", "ein", "Beu\u00b7tel", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00e4ngen auf am Hosenband.", "tokens": ["H\u00e4n\u00b7gen", "auf", "am", "Ho\u00b7sen\u00b7band", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Diebstahl will er mir vorstossen,", "tokens": ["Dieb\u00b7stahl", "will", "er", "mir", "vor\u00b7stos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der doch voller Diebespossen,", "tokens": ["Der", "doch", "vol\u00b7ler", "Die\u00b7be\u00b7spos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sag, wie ist das Kleid doch dein,", "tokens": ["Sag", ",", "wie", "ist", "das", "Kleid", "doch", "dein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VAFIN", "ART", "NN", "ADV", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da's gestohlne Fleckel sein.", "tokens": ["Da's", "ge\u00b7stohl\u00b7ne", "Fle\u00b7ckel", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Seckelleerer, magst so l\u00fcgen", "tokens": ["Se\u00b7ckel\u00b7lee\u00b7rer", ",", "magst", "so", "l\u00fc\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VMFIN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schweige mir nur alsbald still,", "tokens": ["Schwei\u00b7ge", "mir", "nur", "als\u00b7bald", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sonsten deinen Mehlmuth biegen,", "tokens": ["Sons\u00b7ten", "dei\u00b7nen", "Mehl\u00b7muth", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich mit meiner Elle will,", "tokens": ["Ich", "mit", "mei\u00b7ner", "El\u00b7le", "will", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Meinst, ich pfleg vom Raub zu leben,", "tokens": ["Meinst", ",", "ich", "pfleg", "vom", "Raub", "zu", "le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "NE", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil du es so machest eben,", "tokens": ["Weil", "du", "es", "so", "ma\u00b7chest", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Dein Kropf ist Diebstahli voll", "tokens": ["Dein", "Kropf", "ist", "Dieb\u00b7stah\u00b7li", "voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Weil dein Kopf schmirali toll.", "tokens": ["Weil", "dein", "Kopf", "schmi\u00b7ra\u00b7li", "toll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Brauch die Elle nur zum messen,", "tokens": ["Brauch", "die", "El\u00b7le", "nur", "zum", "mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADV", "APPRART", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fleckeldieb und nicht f\u00fcr mich,", "tokens": ["Fle\u00b7ckel\u00b7dieb", "und", "nicht", "f\u00fcr", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKNEG", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doppelt messen thu vergessen,", "tokens": ["Dop\u00b7pelt", "mes\u00b7sen", "thu", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hiezu mahnt Don Mahlmehl dich,", "tokens": ["Hie\u00b7zu", "mahnt", "Don", "Mahl\u00b7mehl", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doppelt Tuch und doppelt Seiden", "tokens": ["Dop\u00b7pelt", "Tuch", "und", "dop\u00b7pelt", "Sei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "KON", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Doppelt Kn\u00f6pf brauchst beim Zuschneiden,", "tokens": ["Dop\u00b7pelt", "Kn\u00f6pf", "brauchst", "beim", "Zu\u00b7schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ja noch dieses nicht erkleckt,", "tokens": ["Ja", "noch", "die\u00b7ses", "nicht", "er\u00b7kleckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KON", "PDS", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weiter sich dein Geitz erstreckt.", "tokens": ["Wei\u00b7ter", "sich", "dein", "Geitz", "er\u00b7streckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "M\u00fcller, Mahler, Rockenstehler", "tokens": ["M\u00fcl\u00b7ler", ",", "Mah\u00b7ler", ",", "Ro\u00b7cken\u00b7steh\u00b7ler"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sag, womit erh\u00e4lst dein Schwein,", "tokens": ["Sag", ",", "wo\u00b7mit", "er\u00b7h\u00e4lst", "dein", "Schwein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kaufst Getraid nicht um ein Heller,", "tokens": ["Kaufst", "Ge\u00b7traid", "nicht", "um", "ein", "Hel\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mu\u00df doch fett wie du ja sein.", "tokens": ["Mu\u00df", "doch", "fett", "wie", "du", "ja", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "KOKOM", "PPER", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Andre m\u00fcssen sich ern\u00e4hren,", "tokens": ["And\u00b7re", "m\u00fcs\u00b7sen", "sich", "er\u00b7n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Du thust fremdes Gut verzehren", "tokens": ["Du", "thust", "frem\u00b7des", "Gut", "ver\u00b7zeh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Gleich ein Habicht R\u00e4uber lebst,", "tokens": ["Gleich", "ein", "Ha\u00b7bicht", "R\u00e4u\u00b7ber", "lebst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und in lauter Diebsiahl schwebst.", "tokens": ["Und", "in", "lau\u00b7ter", "Dieb\u00b7si\u00b7ahl", "schwebst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Wie prangst du mit Silberkn\u00f6pfen,", "tokens": ["Wie", "prangst", "du", "mit", "Sil\u00b7ber\u00b7kn\u00f6p\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit Seiden ausgen\u00e4htem Tuch,", "tokens": ["Mit", "Sei\u00b7den", "aus\u00b7ge\u00b7n\u00e4h\u00b7tem", "Tuch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weib und Tochter auch mit Sch\u00f6pfen,", "tokens": ["Weib", "und", "Toch\u00b7ter", "auch", "mit", "Sch\u00f6p\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit Spitz, B\u00e4ndern, hohem Schmuck,", "tokens": ["Mit", "Spitz", ",", "B\u00e4n\u00b7dern", ",", "ho\u00b7hem", "Schmuck", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann dies sind gestohlne Waaren,", "tokens": ["Dann", "dies", "sind", "ge\u00b7stohl\u00b7ne", "Waa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die da zieren Hoffahrts Narren,", "tokens": ["Die", "da", "zie\u00b7ren", "Hof\u00b7fahrts", "Nar\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Bist ein rechter Papagai,", "tokens": ["Bist", "ein", "rech\u00b7ter", "Pa\u00b7pa\u00b7gai", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist nichts dein, als das Geschrei.", "tokens": ["Ist", "nichts", "dein", ",", "als", "das", "Ge\u00b7schrei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPOSAT", "$,", "KOUS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Mein M\u00fchlesel thu betrachten,", "tokens": ["Mein", "M\u00fch\u00b7le\u00b7sel", "thu", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Zieh dich bei der Nasen doch,", "tokens": ["Zieh", "dich", "bei", "der", "Na\u00b7sen", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deinen Kropf thu beobachten", "tokens": ["Dei\u00b7nen", "Kropf", "thu", "be\u00b7ob\u00b7ach\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "VVINF"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Mit demselben hurtig poch,", "tokens": ["Mit", "dem\u00b7sel\u00b7ben", "hur\u00b7tig", "poch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die Natur hat dir ihn geben,", "tokens": ["Die", "Na\u00b7tur", "hat", "dir", "ihn", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df du sollst bezeichnet leben.", "tokens": ["Da\u00df", "du", "sollst", "be\u00b7zeich\u00b7net", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "VVPP", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Dieser ist ein Ueberflu\u00df,", "tokens": ["Die\u00b7ser", "ist", "ein", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Gleich wie dir dein Diebsgenu\u00df.", "tokens": ["Gleich", "wie", "dir", "dein", "Diebs\u00b7ge\u00b7nu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "H\u00e4ttst ein Kropf, du w\u00e4rest schwerer,", "tokens": ["H\u00e4ttst", "ein", "Kropf", ",", "du", "w\u00e4\u00b7rest", "schwe\u00b7rer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "D\u00fcrfst nicht tragen 's B\u00f6geleis,", "tokens": ["D\u00fcrfst", "nicht", "tra\u00b7gen", "'s", "B\u00f6\u00b7ge\u00b7leis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Der Wind dich hinweht du Leerer,", "tokens": ["Der", "Wind", "dich", "hin\u00b7weht", "du", "Lee\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Du versch\u00fcttest deine . . . .!", "tokens": ["Du", "ver\u00b7sch\u00fct\u00b7test", "dei\u00b7ne", ".", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "$.", "$.", "$.", "$.", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Geh du deine Finger reiben,", "tokens": ["Geh", "du", "dei\u00b7ne", "Fin\u00b7ger", "rei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df du kannst die Zeit vertreiben,", "tokens": ["Da\u00df", "du", "kannst", "die", "Zeit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Unrecht Gut heraus dir f\u00e4hrt,", "tokens": ["Un\u00b7recht", "Gut", "he\u00b7raus", "dir", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Gesunder Haut bist du nicht werth.", "tokens": ["Ge\u00b7sun\u00b7der", "Haut", "bist", "du", "nicht", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Eines mu\u00df ich dich noch fragen,", "tokens": ["Ei\u00b7nes", "mu\u00df", "ich", "dich", "noch", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warum machst die S\u00e4ck so leer,", "tokens": ["Wa\u00b7rum", "machst", "die", "S\u00e4ck", "so", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden voll dir zugetragen,", "tokens": ["Wer\u00b7den", "voll", "dir", "zu\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kehren heim nicht halb so schwer.", "tokens": ["Keh\u00b7ren", "heim", "nicht", "halb", "so", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "PTKNEG", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Geld brauchst du f\u00fcr deine Kinder,", "tokens": ["Geld", "brauchst", "du", "f\u00fcr", "dei\u00b7ne", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die nicht kl\u00fcger als die Rinder,", "tokens": ["Die", "nicht", "kl\u00fc\u00b7ger", "als", "die", "Rin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder f\u00fcr dein Lumpgesind,", "tokens": ["O\u00b7der", "f\u00fcr", "dein", "Lump\u00b7ge\u00b7sind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wenns nicht durch die Gurgel rinnt.", "tokens": ["Wenns", "nicht", "durch", "die", "Gur\u00b7gel", "rinnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Sag mir auch du Fingerreiber,", "tokens": ["Sag", "mir", "auch", "du", "Fin\u00b7ger\u00b7rei\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu was so viel Futter ist,", "tokens": ["Zu", "was", "so", "viel", "Fut\u00b7ter", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch nicht so viel Diebstahl treibe,", "tokens": ["Doch", "nicht", "so", "viel", "Dieb\u00b7stahl", "trei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Schau man kennt schon deine List,", "tokens": ["Schau", "man", "kennt", "schon", "dei\u00b7ne", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Steifleinwand, Kameelhaar eben", "tokens": ["Stei\u00b7flein\u00b7wand", ",", "Ka\u00b7me\u00b7el\u00b7haar", "e\u00b7ben"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "ADV"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Mu\u00df man dir ja doppelt geben,", "tokens": ["Mu\u00df", "man", "dir", "ja", "dop\u00b7pelt", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Damit kleidest du die dein,", "tokens": ["Da\u00b7mit", "klei\u00b7dest", "du", "die", "dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ach la\u00df doch das Stehlen sein.", "tokens": ["Ach", "la\u00df", "doch", "das", "Steh\u00b7len", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVIMP", "ADV", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Waitzendieb, Roggendieb, Gerstendieb,", "tokens": ["Wait\u00b7zen\u00b7dieb", ",", "Rog\u00b7gen\u00b7dieb", ",", "Gers\u00b7ten\u00b7dieb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Korndieb, Kleiendieb, Breiendieb,", "tokens": ["Korn\u00b7dieb", ",", "Klei\u00b7en\u00b7dieb", ",", "Brei\u00b7en\u00b7dieb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Erbsendieb, du, du, du Linsendieb,", "tokens": ["Erb\u00b7sen\u00b7dieb", ",", "du", ",", "du", ",", "du", "Lin\u00b7sen\u00b7dieb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "$,", "PPER", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Graubendieb du, du, du Mehlbeutel,", "tokens": ["Grau\u00b7ben\u00b7dieb", "du", ",", "du", ",", "du", "Mehl\u00b7beu\u00b7tel", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "PPER", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.5": {"text": "L\u00fcgenveitel, Wasserkropf, Eselsknopf,", "tokens": ["L\u00fc\u00b7gen\u00b7vei\u00b7tel", ",", "Was\u00b7ser\u00b7kropf", ",", "E\u00b7sels\u00b7knopf", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "M\u00fchlnarr, du, du, du Me Me Mehldieb,", "tokens": ["M\u00fchl\u00b7narr", ",", "du", ",", "du", ",", "du", "Me", "Me", "Mehl\u00b7dieb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "$,", "PPER", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Du bist ein Dieb, ja ja ja, nein nein nein,", "tokens": ["Du", "bist", "ein", "Dieb", ",", "ja", "ja", "ja", ",", "nein", "nein", "nein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADV", "ADV", "ADV", "$,", "PTKANT", "PTKANT", "PTKANT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ich nicht, du du du.", "tokens": ["Ich", "nicht", ",", "du", "du", "du", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "$,", "PPER", "PPER", "PPER", "$."], "meter": "--+-+", "measure": "anapaest.init"}}, "stanza.14": {"line.1": {"text": "Tuchdieb, Zeugdieb, Hosendieb, Seidendieb,", "tokens": ["Tuch\u00b7dieb", ",", "Zeug\u00b7dieb", ",", "Ho\u00b7sen\u00b7dieb", ",", "Sei\u00b7den\u00b7dieb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Fadendieb, Bordendieb, S\u00e4ckeldieb,", "tokens": ["Fa\u00b7den\u00b7dieb", ",", "Bor\u00b7den\u00b7dieb", ",", "S\u00e4\u00b7ckel\u00b7dieb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Fleckeldieb, du, du, du Kameelhaardieb,", "tokens": ["Fle\u00b7ckel\u00b7dieb", ",", "du", ",", "du", ",", "du", "Ka\u00b7me\u00b7el\u00b7haar\u00b7dieb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "$,", "PPER", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Manchesterdieb, du, du, du Knopfdieb,", "tokens": ["Man\u00b7ches\u00b7ter\u00b7dieb", ",", "du", ",", "du", ",", "du", "Kno\u00b7pf\u00b7di\u00b7eb", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "$,", "PPER", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.5": {"text": "Fingerreiber, Bocktreiber, Ziegenbart,", "tokens": ["Fin\u00b7ger\u00b7rei\u00b7ber", ",", "Bock\u00b7trei\u00b7ber", ",", "Zie\u00b7gen\u00b7bart", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Armer Tropf, meck meck meck, Ziegenknopf,", "tokens": ["Ar\u00b7mer", "Tropf", ",", "meck", "meck", "meck", ",", "Zie\u00b7gen\u00b7knopf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NE", "NE", "NE", "$,", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Du bist ein Dieb, meck meck meck, ja ja ja,", "tokens": ["Du", "bist", "ein", "Dieb", ",", "meck", "meck", "meck", ",", "ja", "ja", "ja", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "NE", "NE", "NE", "$,", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ich nicht, du, du, du!", "tokens": ["Ich", "nicht", ",", "du", ",", "du", ",", "du", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "PTKNEG", "$,", "PPER", "$,", "PPER", "$,", "PPER", "$."], "meter": "--+-+", "measure": "anapaest.init"}}, "stanza.15": {"line.1": {"text": "Es ist ein Dieb da!", "tokens": ["Es", "ist", "ein", "Dieb", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Es ist ein Bock da!", "tokens": ["Es", "ist", "ein", "Bock", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NE", "ADV", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.17": {"line.1": {"text": "Wer ist er?", "tokens": ["Wer", "ist", "er", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.18": {"line.1": {"text": "Wer ist er?", "tokens": ["Wer", "ist", "er", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.19": {"line.1": {"text": "Der Mahlmehl.", "tokens": ["Der", "Mahl\u00b7mehl", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.20": {"line.1": {"text": "Der Geishaar.", "tokens": ["Der", "Geis\u00b7haar", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}