{"textgrid.poem.42638": {"metadata": {"author": {"name": "Ratschky, Joseph Franz", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr Herren, die ihr euch, verf\u00fchrt von eitler Ehre,", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Herren, die ihr euch, verf\u00fchrt von eitler Ehre,", "tokens": ["Ihr", "Her\u00b7ren", ",", "die", "ihr", "euch", ",", "ver\u00b7f\u00fchrt", "von", "eit\u00b7ler", "Eh\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "PPER", "$,", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Namen starke Geister gebt,", "tokens": ["Den", "Na\u00b7men", "star\u00b7ke", "Geis\u00b7ter", "gebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und bloss nach dem Gesetz, das die Natur gab, lebt,", "tokens": ["Und", "bloss", "nach", "dem", "Ge\u00b7setz", ",", "das", "die", "Na\u00b7tur", "gab", ",", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die ihr der frommen Vorwelt Lehre", "tokens": ["Die", "ihr", "der", "from\u00b7men", "Vor\u00b7welt", "Leh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Ziel profanen Witzes macht,", "tokens": ["Zum", "Ziel", "pro\u00b7fa\u00b7nen", "Wit\u00b7zes", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Blindheit unsrer Ahnen lacht,", "tokens": ["Der", "Blind\u00b7heit", "uns\u00b7rer", "Ah\u00b7nen", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Euch lieblos des Verfalls der Bonzenherrschaft freuet,", "tokens": ["Euch", "lieb\u00b7los", "des", "Ver\u00b7falls", "der", "Bon\u00b7zen\u00b7herr\u00b7schaft", "freu\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Klausnerheiligkeit als Gleissnerey verschreyet,", "tokens": ["Und", "Klaus\u00b7ner\u00b7hei\u00b7lig\u00b7keit", "als", "Gleiss\u00b7ne\u00b7rey", "ver\u00b7schre\u00b7yet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die ihr auf Bann und Interdikt", "tokens": ["Die", "ihr", "auf", "Bann", "und", "In\u00b7ter\u00b7dikt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit stolzem L\u00e4cheln niederblickt,", "tokens": ["Mit", "stol\u00b7zem", "L\u00e4\u00b7cheln", "nie\u00b7der\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und sie als Gaukelspiel verachtet,", "tokens": ["Und", "sie", "als", "Gau\u00b7kel\u00b7spiel", "ver\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ja selbst die H\u00f6lle wenig achtet,", "tokens": ["Ja", "selbst", "die", "H\u00f6l\u00b7le", "we\u00b7nig", "ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Verw\u00e4gne! spitzt die Ohren nur,", "tokens": ["Ver\u00b7w\u00e4g\u00b7ne", "!", "spitzt", "die", "Oh\u00b7ren", "nur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und h\u00f6ret, was mir j\u00fcngst (noch klappern mir die Z\u00e4hne", "tokens": ["Und", "h\u00f6\u00b7ret", ",", "was", "mir", "j\u00fcngst", "(", "noch", "klap\u00b7pern", "mir", "die", "Z\u00e4h\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PWS", "PPER", "ADV", "$(", "ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bey der Erinnerung an diese Schreckenscene)", "tokens": ["Bey", "der", "E\u00b7rin\u00b7ne\u00b7rung", "an", "die\u00b7se", "Schre\u00b7cken\u00b7sce\u00b7ne", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PDAT", "NN", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.16": {"text": "Zur Mitternachtzeit wiederfuhr!", "tokens": ["Zur", "Mit\u00b7ter\u00b7nacht\u00b7zeit", "wie\u00b7der\u00b7fuhr", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich stand auf einmal an der Pforte", "tokens": ["Ich", "stand", "auf", "ein\u00b7mal", "an", "der", "Pfor\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu jenem unterird'schen Orte,", "tokens": ["Zu", "je\u00b7nem", "un\u00b7ter\u00b7ird'\u00b7schen", "Or\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von dem manch Buch mit Recht so b\u00f6se Ding' erz\u00e4hlt,", "tokens": ["Von", "dem", "manch", "Buch", "mit", "Recht", "so", "b\u00f6\u00b7se", "Ding'", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "APPR", "NN", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wo, von gleicher Pein gequ\u00e4lt,", "tokens": ["Und", "wo", ",", "von", "glei\u00b7cher", "Pein", "ge\u00b7qu\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Erde stolze Potentaten", "tokens": ["Der", "Er\u00b7de", "stol\u00b7ze", "Po\u00b7ten\u00b7ta\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit armem Bettlervolk auf einem Roste braten.", "tokens": ["Mit", "ar\u00b7mem", "Bett\u00b7ler\u00b7volk", "auf", "ei\u00b7nem", "Ros\u00b7te", "bra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Rings um die M\u00fcndung wallte hoch", "tokens": ["Rings", "um", "die", "M\u00fcn\u00b7dung", "wall\u00b7te", "hoch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein dicker Dampf empor, der schwefel\u00e4hnlich roch:", "tokens": ["Ein", "di\u00b7cker", "Dampf", "em\u00b7por", ",", "der", "schwe\u00b7fe\u00b7l\u00e4hn\u00b7lich", "roch", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,", "PRELS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es herrschte weit und breit ein schaudervolles Schweigen,", "tokens": ["Es", "herrschte", "weit", "und", "breit", "ein", "schau\u00b7der\u00b7vol\u00b7les", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.10": {"text": "Und da ich weder Mensch, noch Their", "tokens": ["Und", "da", "ich", "we\u00b7der", "Mensch", ",", "noch", "Their"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "KON", "NN", "$,", "ADV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Entdeckte, wagt' ich es, gereitzt von Neubegier,", "tokens": ["Ent\u00b7deck\u00b7te", ",", "wagt'", "ich", "es", ",", "ge\u00b7reitzt", "von", "Neu\u00b7be\u00b7gier", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "PPER", "$,", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den finstern Schacht hinabzusteigen.", "tokens": ["Den", "fins\u00b7tern", "Schacht", "hin\u00b7ab\u00b7zu\u00b7stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Doch stellt euch mein Entsetzen vor!", "tokens": ["Doch", "stellt", "euch", "mein", "Ent\u00b7set\u00b7zen", "vor", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Kaum war ich innerhalb der Schwelle,", "tokens": ["Kaum", "war", "ich", "in\u00b7ner\u00b7halb", "der", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "So schloss mit wildem Knall sich hinter mir das Thor,", "tokens": ["So", "schloss", "mit", "wil\u00b7dem", "Knall", "sich", "hin\u00b7ter", "mir", "das", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "PRF", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und ach! ich armer Tropf befand mich in der H\u00f6lle.", "tokens": ["Und", "ach", "!", "ich", "ar\u00b7mer", "Tropf", "be\u00b7fand", "mich", "in", "der", "H\u00f6l\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PPER", "ADJA", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dem Wandrer, neben dem ein Blitz herabf\u00e4hrt, gleich,", "tokens": ["Dem", "Wand\u00b7rer", ",", "ne\u00b7ben", "dem", "ein", "Blitz", "her\u00b7ab\u00b7f\u00e4hrt", ",", "gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ART", "NN", "VVPP", "$,", "ADV", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Stand ich, bis in das Mark ersch\u00fcttert, stumm und bleich,", "tokens": ["Stand", "ich", ",", "bis", "in", "das", "Mark", "er\u00b7sch\u00fct\u00b7tert", ",", "stumm", "und", "bleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "APPR", "ART", "NN", "VVPP", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und streckte zitternd beyde H\u00e4nde", "tokens": ["Und", "streck\u00b7te", "zit\u00b7ternd", "bey\u00b7de", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verzweiflungsvoll empor: doch eh' ich mir's versah,", "tokens": ["Ver\u00b7zwei\u00b7flungs\u00b7voll", "em\u00b7por", ":", "doch", "eh'", "ich", "mir's", "ver\u00b7sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$.", "ADV", "KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "War schon ein scheusslich Unthier da,", "tokens": ["War", "schon", "ein", "scheuss\u00b7lich", "Un\u00b7thier", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das einem Teufel der Legende,", "tokens": ["Das", "ei\u00b7nem", "Teu\u00b7fel", "der", "Le\u00b7gen\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So wie ein Ey dem andern, glich.", "tokens": ["So", "wie", "ein", "Ey", "dem", "an\u00b7dern", ",", "glich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ART", "ADJA", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wen sucht er, br\u00fcllte f\u00fcrchterlich", "tokens": ["Wen", "sucht", "er", ",", "br\u00fcll\u00b7te", "f\u00fcrch\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Unhold, hier bey uns? was f\u00fchrt ihn von der Erde", "tokens": ["Der", "Un\u00b7hold", ",", "hier", "bey", "uns", "?", "was", "f\u00fchrt", "ihn", "von", "der", "Er\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "PPER", "$.", "PWS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zur Unterwelt herab? will er an Satans Herde", "tokens": ["Zur", "Un\u00b7ter\u00b7welt", "her\u00b7ab", "?", "will", "er", "an", "Sa\u00b7tans", "Her\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "$.", "VMFIN", "PPER", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sich w\u00e4rmen? Nur herbey! ... Ein kalter Schauer lief", "tokens": ["Sich", "w\u00e4r\u00b7men", "?", "Nur", "her\u00b7bey", "!", "...", "Ein", "kal\u00b7ter", "Schau\u00b7er", "lief"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PRF", "VVINF", "$.", "ADV", "PTKVZ", "$.", "$(", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bey diesem Antrag mir vom Kopf bis zu den F\u00fcssen", "tokens": ["Bey", "die\u00b7sem", "An\u00b7trag", "mir", "vom", "Kopf", "bis", "zu", "den", "F\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PPER", "APPRART", "NN", "APPR", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Durch jedes Glied. Nein, nein, ich bitte, rief", "tokens": ["Durch", "je\u00b7des", "Glied", ".", "Nein", ",", "nein", ",", "ich", "bit\u00b7te", ",", "rief"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "$.", "PTKANT", "$,", "PTKANT", "$,", "PPER", "ADV", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ich zitternd, nur das Thor mir wieder aufzuschliessen.", "tokens": ["Ich", "zit\u00b7ternd", ",", "nur", "das", "Thor", "mir", "wie\u00b7der", "auf\u00b7zu\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "ADV", "ART", "NN", "PPER", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Gemach! erwiedert' er, so ist es nicht gemeint:", "tokens": ["Ge\u00b7mach", "!", "er\u00b7wie\u00b7dert'", "er", ",", "so", "ist", "es", "nicht", "ge\u00b7meint", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPER", "$,", "ADV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wer einmal hier ist, guter Freund!", "tokens": ["Wer", "ein\u00b7mal", "hier", "ist", ",", "gu\u00b7ter", "Freund", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VAFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Muss ", "tokens": ["Muss"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.18": {"text": "In Ewigkeit bey uns f\u00fcrlieb zu nehmen.", "tokens": ["In", "E\u00b7wig\u00b7keit", "bey", "uns", "f\u00fcr\u00b7lieb", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Drum denk' er ja an keine Wiederkehr!", "tokens": ["Drum", "denk'", "er", "ja", "an", "kei\u00b7ne", "Wie\u00b7der\u00b7kehr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Das Privilegium, von hier einst loszukommen,", "tokens": ["Das", "Pri\u00b7vi\u00b7le\u00b7gi\u00b7um", ",", "von", "hier", "einst", "los\u00b7zu\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Das Abbadona sich, so wie ich j\u00fcngst vernommen,", "tokens": ["Das", "Ab\u00b7ba\u00b7do\u00b7na", "sich", ",", "so", "wie", "ich", "j\u00fcngst", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "$,", "ADV", "KOKOM", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Erschlichen haben soll, erh\u00e4lt wohl keiner mehr.", "tokens": ["Er\u00b7schli\u00b7chen", "ha\u00b7ben", "soll", ",", "er\u00b7h\u00e4lt", "wohl", "kei\u00b7ner", "mehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "VMFIN", "$,", "VVFIN", "ADV", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Auf! folg' er mir, wohin ich ihn geleite!", "tokens": ["Auf", "!", "fol\u00b7g'", "er", "mir", ",", "wo\u00b7hin", "ich", "ihn", "ge\u00b7lei\u00b7te", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "PPER", "$,", "PWAV", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.24": {"text": "Nur da hinaus zur linken Seite!", "tokens": ["Nur", "da", "hin\u00b7aus", "zur", "lin\u00b7ken", "Sei\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APZR", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Mein Str\u00e4uben half hier nichts; drum gieng ich willig mit,", "tokens": ["Mein", "Str\u00e4u\u00b7ben", "half", "hier", "nichts", ";", "drum", "gieng", "ich", "wil\u00b7lig", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PIS", "$.", "PAV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir wanderten ganz sachte, Schritt f\u00fcr Schritt,", "tokens": ["Wir", "wan\u00b7der\u00b7ten", "ganz", "sach\u00b7te", ",", "Schritt", "f\u00fcr", "Schritt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVFIN", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "(denn wo kein Scheiterhaufen gl\u00fchet,", "tokens": ["(", "denn", "wo", "kein", "Schei\u00b7ter\u00b7hau\u00b7fen", "gl\u00fc\u00b7het", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWAV", "PIAT", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Bey dem man S\u00fcnder br\u00e4t und br\u00fchet,", "tokens": ["Bey", "dem", "man", "S\u00fcn\u00b7der", "br\u00e4t", "und", "br\u00fc\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist's, wie sich leicht erachten l\u00e4sst,", "tokens": ["Ist's", ",", "wie", "sich", "leicht", "e\u00b7rach\u00b7ten", "l\u00e4sst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PRF", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht wenig finster in der H\u00f6lle)", "tokens": ["Nicht", "we\u00b7nig", "fins\u00b7ter", "in", "der", "H\u00f6l\u00b7le", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und kamen endlich an die Stelle,", "tokens": ["Und", "ka\u00b7men", "end\u00b7lich", "an", "die", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wo Seelen ohne Zahl, in Pfannen eingepresst,", "tokens": ["Wo", "See\u00b7len", "oh\u00b7ne", "Zahl", ",", "in", "Pfan\u00b7nen", "ein\u00b7ge\u00b7presst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "NN", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gebraten auf dem Rost, und aufgehenkt an Spiessen,", "tokens": ["Ge\u00b7bra\u00b7ten", "auf", "dem", "Rost", ",", "und", "auf\u00b7ge\u00b7henkt", "an", "Spies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "F\u00fcr eines St\u00fcndchens L\u00fcsternheit,", "tokens": ["F\u00fcr", "ei\u00b7nes", "St\u00fcnd\u00b7chens", "L\u00fcs\u00b7tern\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die keinem Beichtiger zur \u00f6sterlichen Zeit", "tokens": ["Die", "kei\u00b7nem", "Beich\u00b7ti\u00b7ger", "zur", "\u00f6s\u00b7ter\u00b7li\u00b7chen", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "In's Ohr gefl\u00fcstert ward, nun ewig schmachten m\u00fcssen.", "tokens": ["In's", "Ohr", "ge\u00b7fl\u00fcs\u00b7tert", "ward", ",", "nun", "e\u00b7wig", "schmach\u00b7ten", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$,", "ADV", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "O Himmel, hilf! welch ungeheure Schaar", "tokens": ["O", "Him\u00b7mel", ",", "hilf", "!", "welch", "un\u00b7ge\u00b7heu\u00b7re", "Schaar"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$,", "VVIMP", "$.", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Verworfener von mancherley Gelichter", "tokens": ["Ver\u00b7wor\u00b7fe\u00b7ner", "von", "man\u00b7cher\u00b7ley", "Ge\u00b7lich\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PIAT", "NN"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.15": {"text": "Bot rings umher sich meinen Blicken dar!", "tokens": ["Bot", "rings", "um\u00b7her", "sich", "mei\u00b7nen", "Bli\u00b7cken", "dar", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "PRF", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.16": {"text": "Hier schnitt ein Potentat erb\u00e4rmliche Gesichter,", "tokens": ["Hier", "schnitt", "ein", "Po\u00b7ten\u00b7tat", "er\u00b7b\u00e4rm\u00b7li\u00b7che", "Ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und rief: ich Thor! warum gab ich des Volkes Schweiss,", "tokens": ["Und", "rief", ":", "ich", "Thor", "!", "wa\u00b7rum", "gab", "ich", "des", "Vol\u00b7kes", "Schweiss", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "NN", "$.", "PWAV", "VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Den \u00f6ffentlichen Schatz nicht meinen Bonzen preis?", "tokens": ["Den", "\u00f6f\u00b7fent\u00b7li\u00b7chen", "Schatz", "nicht", "mei\u00b7nen", "Bon\u00b7zen", "preis", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.19": {"text": "Ich w\u00e4re dann wohl fern von Satans Bratenwender,", "tokens": ["Ich", "w\u00e4\u00b7re", "dann", "wohl", "fern", "von", "Sa\u00b7tans", "Bra\u00b7ten\u00b7wen\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ja st\u00fcnd' als Heiliger im r\u00f6mischen Kalender.", "tokens": ["Ja", "st\u00fcnd'", "als", "Hei\u00b7li\u00b7ger", "im", "r\u00f6\u00b7mi\u00b7schen", "Ka\u00b7len\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "KOUS", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Dort riss ein Philosoph das Haar sich aus dem Kopf,", "tokens": ["Dort", "riss", "ein", "Phi\u00b7lo\u00b7soph", "das", "Haar", "sich", "aus", "dem", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und heulte laut: weh mir! ach! h\u00e4tt' ich armer Tropf", "tokens": ["Und", "heul\u00b7te", "laut", ":", "weh", "mir", "!", "ach", "!", "h\u00e4tt'", "ich", "ar\u00b7mer", "Tropf"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "$.", "ADV", "PPER", "$.", "XY", "$.", "VAFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Doch alles blind geglaubt, und meine dreiste Nase", "tokens": ["Doch", "al\u00b7les", "blind", "ge\u00b7glaubt", ",", "und", "mei\u00b7ne", "dreis\u00b7te", "Na\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADJD", "VVPP", "$,", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "In kein profanes Buch gesteckt,", "tokens": ["In", "kein", "pro\u00b7fa\u00b7nes", "Buch", "ge\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "So l\u00e4g' ich nun nicht hier auf Kohlen hingestreckt,", "tokens": ["So", "l\u00e4g'", "ich", "nun", "nicht", "hier", "auf", "Koh\u00b7len", "hin\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und w\u00e4r' im Himmelreich bey meiner alten Base.", "tokens": ["Und", "w\u00e4r'", "im", "Him\u00b7mel\u00b7reich", "bey", "mei\u00b7ner", "al\u00b7ten", "Ba\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Dienstfertig und galant, wie jeder Franzmann ist,", "tokens": ["Dienst\u00b7fer\u00b7tig", "und", "ga\u00b7lant", ",", "wie", "je\u00b7der", "Franz\u00b7mann", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,", "PWAV", "PIAT", "NN", "VAFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Kam Meister Rabelais, mich freundlich zu empfangen,", "tokens": ["Kam", "Meis\u00b7ter", "Ra\u00b7be\u00b7lais", ",", "mich", "freund\u00b7lich", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und als er mich wohl zwanzigmal gek\u00fcsst,", "tokens": ["Und", "als", "er", "mich", "wohl", "zwan\u00b7zig\u00b7mal", "ge\u00b7k\u00fcsst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Begann er mich auf mein Verlangen", "tokens": ["Be\u00b7gann", "er", "mich", "auf", "mein", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit der verw\u00e4gnen Frevlerzunft,", "tokens": ["Mit", "der", "ver\u00b7w\u00e4g\u00b7nen", "Frev\u00b7ler\u00b7zunft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die, was von B\u00e4ndigung der menschlichen Vernunft", "tokens": ["Die", ",", "was", "von", "B\u00e4n\u00b7di\u00b7gung", "der", "menschli\u00b7chen", "Ver\u00b7nunft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "PRELS", "APPR", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Die schwarzen Herrn von ihrem Dreyfuss sprachen,", "tokens": ["Die", "schwar\u00b7zen", "Herrn", "von", "ih\u00b7rem", "Drey\u00b7fuss", "spra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nicht achtete, bekannt zu machen.", "tokens": ["Nicht", "ach\u00b7te\u00b7te", ",", "be\u00b7kannt", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Hier, sprach er, sehen Sie den Sp\u00f6tter Lucian,", "tokens": ["Hier", ",", "sprach", "er", ",", "se\u00b7hen", "Sie", "den", "Sp\u00f6t\u00b7ter", "Lu\u00b7ci\u00b7an", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Erbfeind frommer Scharlatane,", "tokens": ["Den", "Erb\u00b7feind", "from\u00b7mer", "Schar\u00b7la\u00b7ta\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Der l\u00e4chelnd dem verj\u00e4hrten Wahne", "tokens": ["Der", "l\u00e4\u00b7chelnd", "dem", "ver\u00b7j\u00e4hr\u00b7ten", "Wah\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Die Spitze bot. O Freund! das ist ein Wundermann,", "tokens": ["Die", "Spit\u00b7ze", "bot", ".", "O", "Freund", "!", "das", "ist", "ein", "Wun\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "NE", "NN", "$.", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der durch des Witzes Talisman", "tokens": ["Der", "durch", "des", "Wit\u00b7zes", "Ta\u00b7lis\u00b7man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "NE"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.14": {"text": "Nicht selten selbst dem b\u00f6sen Feinde", "tokens": ["Nicht", "sel\u00b7ten", "selbst", "dem", "b\u00f6\u00b7sen", "Fein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ein L\u00e4cheln abgewinnen kann.", "tokens": ["Ein", "L\u00e4\u00b7cheln", "ab\u00b7ge\u00b7win\u00b7nen", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Die ganze h\u00f6llische Gemeinde", "tokens": ["Die", "gan\u00b7ze", "h\u00f6l\u00b7li\u00b7sche", "Ge\u00b7mein\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Ist ihm von Herzen zugethan.", "tokens": ["Ist", "ihm", "von", "Her\u00b7zen", "zu\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Dort sitzt Professor Bayl', und sinnt auf neue Zweifel,", "tokens": ["Dort", "sitzt", "Pro\u00b7fes\u00b7sor", "Bayl'", ",", "und", "sinnt", "auf", "neu\u00b7e", "Zwei\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "$,", "KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wodurch er dann und wann die Existenz der Teufel", "tokens": ["Wo\u00b7durch", "er", "dann", "und", "wann", "die", "E\u00b7xis\u00b7tenz", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "KON", "PWAV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Auch hier trotz allem, was er sieht", "tokens": ["Auch", "hier", "trotz", "al\u00b7lem", ",", "was", "er", "sieht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PIS", "$,", "PWS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Und h\u00f6ret, ungewiss zu machen sich bem\u00fcht,", "tokens": ["Und", "h\u00f6\u00b7ret", ",", "un\u00b7ge\u00b7wiss", "zu", "ma\u00b7chen", "sich", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADJD", "PTKZU", "VVINF", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Bis Lucifers Gefolg zu neuer Wuth erwachet,", "tokens": ["Bis", "Lu\u00b7ci\u00b7fers", "Ge\u00b7folg", "zu", "neu\u00b7er", "Wuth", "er\u00b7wa\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und ihn ein schwarzer Polyphem", "tokens": ["Und", "ihn", "ein", "schwar\u00b7zer", "Po\u00b7ly\u00b7phem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Unwiderlegbar f\u00fchlen machet,", "tokens": ["Un\u00b7wi\u00b7der\u00b7leg\u00b7bar", "f\u00fch\u00b7len", "ma\u00b7chet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Des Teufels Wirklichkeit sey mehr als ein Problem.", "tokens": ["Des", "Teu\u00b7fels", "Wirk\u00b7lich\u00b7keit", "sey", "mehr", "als", "ein", "Prob\u00b7lem", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "In einer heissen Tonne sitzend,", "tokens": ["In", "ei\u00b7ner", "heis\u00b7sen", "Ton\u00b7ne", "sit\u00b7zend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Und, einem Braten gleich, am ganzen Leibe schwitzend,", "tokens": ["Und", ",", "ei\u00b7nem", "Bra\u00b7ten", "gleich", ",", "am", "gan\u00b7zen", "Lei\u00b7be", "schwit\u00b7zend", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "NN", "ADV", "$,", "APPRART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Seufzt in dem Winkel dort der arme Dechant Swift,", "tokens": ["Seufzt", "in", "dem", "Win\u00b7kel", "dort", "der", "ar\u00b7me", "De\u00b7chant", "Swift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.29": {"text": "Der einst des Spottes \u00e4tzend Gift", "tokens": ["Der", "einst", "des", "Spot\u00b7tes", "\u00e4t\u00b7zend", "Gift"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Hohnl\u00e4chelnd auf Kalvin und auf den Papst zu triefen", "tokens": ["Hohn\u00b7l\u00e4\u00b7chelnd", "auf", "Kal\u00b7vin", "und", "auf", "den", "Papst", "zu", "trie\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "APPR", "NN", "KON", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Sich unterstand, und drum itzt in den Tiefen", "tokens": ["Sich", "un\u00b7ter\u00b7stand", ",", "und", "drum", "itzt", "in", "den", "Tie\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "VVFIN", "$,", "KON", "PAV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Des H\u00f6llenschlunds, vermaledeit", "tokens": ["Des", "H\u00f6l\u00b7len\u00b7schlunds", ",", "ver\u00b7ma\u00b7le\u00b7deit"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Von zweyer Kirchen Theologen,", "tokens": ["Von", "zwey\u00b7er", "Kir\u00b7chen", "Theo\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.34": {"text": "Die er durch seinen Kiel sich auf den Hals gezogen,", "tokens": ["Die", "er", "durch", "sei\u00b7nen", "Kiel", "sich", "auf", "den", "Hals", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Sich hinterm Ohre kratzt, und, was er schrieb, bereut.", "tokens": ["Sich", "hin\u00b7term", "Oh\u00b7re", "kratzt", ",", "und", ",", "was", "er", "schrieb", ",", "be\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "VVFIN", "$,", "KON", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "In jener Ecke harrt schon vorl\u00e4ngst auf Volt\u00e4ren", "tokens": ["In", "je\u00b7ner", "E\u00b7cke", "harrt", "schon", "vor\u00b7l\u00e4ngst", "auf", "Vol\u00b7t\u00e4\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Nicht fern von Lucian ein unbesetzter Stuhl,", "tokens": ["Nicht", "fern", "von", "Lu\u00b7ci\u00b7an", "ein", "un\u00b7be\u00b7setz\u00b7ter", "Stuhl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Falls Frankreichs Bonzen nicht, eh' ihn der Feuerpfuhl", "tokens": ["Falls", "Fran\u00b7kreichs", "Bon\u00b7zen", "nicht", ",", "eh'", "ihn", "der", "Feu\u00b7er\u00b7pfuhl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "NN", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Mit Haut und Haar verschlingt, den alten Gauch bekehren.", "tokens": ["Mit", "Haut", "und", "Haar", "ver\u00b7schlingt", ",", "den", "al\u00b7ten", "Gauch", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Noch zeigte Meister Rabelais", "tokens": ["Noch", "zeig\u00b7te", "Meis\u00b7ter", "Ra\u00b7be\u00b7lais"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im traulichen Gespr\u00e4ch mir manchen, dessen Schriften", "tokens": ["Im", "trau\u00b7li\u00b7chen", "Ge\u00b7spr\u00e4ch", "mir", "man\u00b7chen", ",", "des\u00b7sen", "Schrif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "PPER", "VVINF", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Beym blinden Layenvolk so vieles Unheil stiften,", "tokens": ["Beym", "blin\u00b7den", "La\u00b7yen\u00b7volk", "so", "vie\u00b7les", "Un\u00b7heil", "stif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der daf\u00fcr nun ewig Ach und Weh", "tokens": ["Und", "der", "da\u00b7f\u00fcr", "nun", "e\u00b7wig", "Ach", "und", "Weh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PAV", "ADV", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Im H\u00f6llenabgrund ruft. So ist denn wirklich, dachte", "tokens": ["Im", "H\u00f6l\u00b7len\u00b7ab\u00b7grund", "ruft", ".", "So", "ist", "denn", "wirk\u00b7lich", ",", "dach\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["APPRART", "NN", "VVFIN", "$.", "ADV", "VAFIN", "ADV", "ADJD", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich endlich bey mir selbst, so ist denn alles das,", "tokens": ["Ich", "end\u00b7lich", "bey", "mir", "selbst", ",", "so", "ist", "denn", "al\u00b7les", "das", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPER", "ADV", "$,", "ADV", "VAFIN", "ADV", "PIS", "PDS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was ich von Satans Reich in Kochems Werken las,", "tokens": ["Was", "ich", "von", "Sa\u00b7tans", "Reich", "in", "Ko\u00b7chems", "Wer\u00b7ken", "las", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NE", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kein blosses M\u00e4rchen? und erwachte.", "tokens": ["Kein", "blos\u00b7ses", "M\u00e4r\u00b7chen", "?", "und", "er\u00b7wach\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$.", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "O m\u00f6chte doch diess gr\u00e4ssliche Gesicht,", "tokens": ["O", "m\u00f6ch\u00b7te", "doch", "diess", "gr\u00e4ss\u00b7li\u00b7che", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr losen Sp\u00f6tter, euch zur ernsten Lehre dienen!", "tokens": ["Ihr", "lo\u00b7sen", "Sp\u00f6t\u00b7ter", ",", "euch", "zur", "erns\u00b7ten", "Leh\u00b7re", "die\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPER", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "M\u00f6cht' euer frecher Mund der H\u00f6lle Strafgericht", "tokens": ["M\u00f6cht'", "eu\u00b7er", "fre\u00b7cher", "Mund", "der", "H\u00f6l\u00b7le", "Straf\u00b7ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein Pfaffenm\u00e4rchen mehr zu schelten sich erk\u00fchnen!", "tokens": ["Kein", "Pfaf\u00b7fen\u00b7m\u00e4r\u00b7chen", "mehr", "zu", "schel\u00b7ten", "sich", "er\u00b7k\u00fch\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "PTKZU", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch leider! h\u00f6r' ich schon die Herren eures Schlags", "tokens": ["Doch", "lei\u00b7der", "!", "h\u00f6r'", "ich", "schon", "die", "Her\u00b7ren", "eu\u00b7res", "Schlags"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "VVFIN", "PPER", "ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auch \u00fcber diese Warnung spassen:", "tokens": ["Auch", "\u00fc\u00b7ber", "die\u00b7se", "War\u00b7nung", "spas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbmit Lucian und seinen Sch\u00fclern mag's", "tokens": ["\u00bb", "mit", "Lu\u00b7ci\u00b7an", "und", "sei\u00b7nen", "Sch\u00fc\u00b7lern", "mag's"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "NE", "KON", "PPOSAT", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbsich selbst im H\u00f6llenpfuhl nicht \u00fcbel leben lassen.\u00ab", "tokens": ["\u00bb", "sich", "selbst", "im", "H\u00f6l\u00b7len\u00b7pfuhl", "nicht", "\u00fc\u00b7bel", "le\u00b7ben", "las\u00b7sen", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PRF", "ADV", "APPRART", "NN", "PTKNEG", "ADJD", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ja, Freunde, d\u00fcrfte man dort unten sich die Zeit", "tokens": ["Ja", ",", "Freun\u00b7de", ",", "d\u00fcrf\u00b7te", "man", "dort", "un\u00b7ten", "sich", "die", "Zeit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "VMFIN", "PIS", "ADV", "ADV", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch munteres Gespr\u00e4ch und frohen Witz vertreiben,", "tokens": ["Durch", "mun\u00b7te\u00b7res", "Ge\u00b7spr\u00e4ch", "und", "fro\u00b7hen", "Witz", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So st\u00fcnd' auch meine Hand bereit,", "tokens": ["So", "st\u00fcnd'", "auch", "mei\u00b7ne", "Hand", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Durch Ketzereyn sich wund zu schreiben.", "tokens": ["Durch", "Ket\u00b7ze\u00b7reyn", "sich", "wund", "zu", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Allein beym mindsten Scherz, der euch entschl\u00fcpfet, giesst", "tokens": ["Al\u00b7lein", "beym", "minds\u00b7ten", "Scherz", ",", "der", "euch", "ent\u00b7schl\u00fcp\u00b7fet", ",", "giesst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein Teufel, der schon alt und wetterlaunisch ist,", "tokens": ["Ein", "Teu\u00b7fel", ",", "der", "schon", "alt", "und", "wet\u00b7ter\u00b7lau\u00b7nisch", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Euch siedend Pech auf's Haupt: dann lasst ihr's gerne bleiben.", "tokens": ["Euch", "sie\u00b7dend", "Pech", "auf's", "Haupt", ":", "dann", "lasst", "ih\u00b7r's", "ger\u00b7ne", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "NN", "APPRART", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Drum, meine Herren, \u00fcberdenkt", "tokens": ["Drum", ",", "mei\u00b7ne", "Her\u00b7ren", ",", "\u00fc\u00b7ber\u00b7denkt"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["PAV", "$,", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die Sache reiflich, und beschr\u00e4nkt", "tokens": ["Die", "Sa\u00b7che", "reif\u00b7lich", ",", "und", "be\u00b7schr\u00e4nkt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADJD", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Die leidige Vernunft um eures Heiles willen!", "tokens": ["Die", "lei\u00b7di\u00b7ge", "Ver\u00b7nunft", "um", "eu\u00b7res", "Hei\u00b7les", "wil\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Bereuet, widerruft, wirkt Buss', und schreibt Postillen!", "tokens": ["Be\u00b7re\u00b7u\u00b7et", ",", "wi\u00b7der\u00b7ruft", ",", "wirkt", "Buss'", ",", "und", "schreibt", "Pos\u00b7til\u00b7len", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVFIN", "NE", "$,", "KON", "VVFIN", "NN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.20": {"text": "Denn wahrlich, wahrlich sag' ich euch:", "tokens": ["Denn", "wahr\u00b7lich", ",", "wahr\u00b7lich", "sag'", "ich", "euch", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Die Ewigkeit ist lang, zumal im H\u00f6llenreich.", "tokens": ["Die", "E\u00b7wig\u00b7keit", "ist", "lang", ",", "zu\u00b7mal", "im", "H\u00f6l\u00b7len\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "KOUS", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}