{"textgrid.poem.63145": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Montezuma", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Er schritt, die Krone mit den Hahnenfedern", "tokens": ["Er", "schritt", ",", "die", "Kro\u00b7ne", "mit", "den", "Hah\u00b7nen\u00b7fe\u00b7dern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Aufs Haupt gesetzt, durch Fliederbuschspalier.", "tokens": ["Aufs", "Haupt", "ge\u00b7setzt", ",", "durch", "Flie\u00b7der\u00b7buschs\u00b7pa\u00b7lier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er trug ein Wams aus vielen Menschenledern,", "tokens": ["Er", "trug", "ein", "Wams", "aus", "vie\u00b7len", "Men\u00b7schen\u00b7le\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Und auf der ganzen Erde war kein Tier,", "tokens": ["Und", "auf", "der", "gan\u00b7zen", "Er\u00b7de", "war", "kein", "Tier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das nicht zu seiner Kleidung beigetragen.", "tokens": ["Das", "nicht", "zu", "sei\u00b7ner", "Klei\u00b7dung", "bei\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es gab f\u00fcr ihn kein da und dort: nur hier.", "tokens": ["Es", "gab", "f\u00fcr", "ihn", "kein", "da", "und", "dort", ":", "nur", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PIAT", "ADV", "KON", "ADV", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Er durfte, was er wollte, w\u00e4gend wagen,", "tokens": ["Er", "durf\u00b7te", ",", "was", "er", "woll\u00b7te", ",", "w\u00e4\u00b7gend", "wa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PWS", "PPER", "VMFIN", "$,", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn Stern und Mond war goldenes Gespiel.", "tokens": ["Denn", "Stern", "und", "Mond", "war", "gol\u00b7de\u00b7nes", "Ge\u00b7spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Am Abend liess sich viel zu ihnen sagen,", "tokens": ["Am", "A\u00b7bend", "liess", "sich", "viel", "zu", "ih\u00b7nen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PRF", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Am Morgen bot die Sonne sich zum Ziel.", "tokens": ["Am", "Mor\u00b7gen", "bot", "die", "Son\u00b7ne", "sich", "zum", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Man schoss nach ihr mit kleinen Bambusrohren,", "tokens": ["Man", "schoss", "nach", "ihr", "mit", "klei\u00b7nen", "Bam\u00b7bus\u00b7roh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn der Pfeile einer niederfiel,", "tokens": ["Und", "wenn", "der", "Pfei\u00b7le", "ei\u00b7ner", "nie\u00b7der\u00b7fiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "PIS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "In eines Dieners Scheitel sich zu bohren,", "tokens": ["In", "ei\u00b7nes", "Die\u00b7ners", "Schei\u00b7tel", "sich", "zu", "boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hob er f\u00fcr einen Augenblick die Stirn.", "tokens": ["Hob", "er", "f\u00fcr", "ei\u00b7nen", "Au\u00b7gen\u00b7blick", "die", "Stirn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man sah die Stirne sich im Strahl umfloren,", "tokens": ["Man", "sah", "die", "Stir\u00b7ne", "sich", "im", "Strahl", "um\u00b7flo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Man h\u00f6rte ihn die Lieblingsdogge kirrn.", "tokens": ["Man", "h\u00f6r\u00b7te", "ihn", "die", "Lieb\u00b7lings\u00b7dog\u00b7ge", "kirrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er warf zum Frasse ihr den Leichnam vor", "tokens": ["Er", "warf", "zum", "Fras\u00b7se", "ihr", "den", "Leich\u00b7nam", "vor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und sprach: Er fand den Pfad, dieweil wir irrn.", "tokens": ["Und", "sprach", ":", "Er", "fand", "den", "Pfad", ",", "die\u00b7weil", "wir", "irrn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Der, der hier liegt, ging ein durchs letzte Tor.", "tokens": ["Der", ",", "der", "hier", "liegt", ",", "ging", "ein", "durchs", "letz\u00b7te", "Tor", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADV", "VVFIN", "$,", "VVFIN", "ART", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er starb den sch\u00f6nsten Tod: von Sonnenhand,", "tokens": ["Er", "starb", "den", "sch\u00f6ns\u00b7ten", "Tod", ":", "von", "Son\u00b7nen\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$.", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die unsern Pfeil auf ihn zur\u00fcckgesandt.", "tokens": ["Die", "un\u00b7sern", "Pfeil", "auf", "ihn", "zu\u00b7r\u00fcck\u00b7ge\u00b7sandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Er aber wusste nichts von Gut und B\u00f6se,", "tokens": ["Er", "a\u00b7ber", "wuss\u00b7te", "nichts", "von", "Gut", "und", "B\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PIS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn die Erscheinung war ihm lieb und wert.", "tokens": ["Denn", "die", "Er\u00b7schei\u00b7nung", "war", "ihm", "lieb", "und", "wert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er schluchzte tief in eines Hunds Gekr\u00f6se,", "tokens": ["Er", "schluchz\u00b7te", "tief", "in", "ei\u00b7nes", "Hunds", "Ge\u00b7kr\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Er weinte tagelang mit einem Pferd,", "tokens": ["Er", "wein\u00b7te", "ta\u00b7ge\u00b7lang", "mit", "ei\u00b7nem", "Pferd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dass ihn sein Wiehern von dem Wort erl\u00f6se:", "tokens": ["Dass", "ihn", "sein", "Wie\u00b7hern", "von", "dem", "Wort", "er\u00b7l\u00f6\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zu wissen nichts, dass eines Wissens wert.", "tokens": ["Zu", "wis\u00b7sen", "nichts", ",", "dass", "ei\u00b7nes", "Wis\u00b7sens", "wert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PIS", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Er h\u00e4tte t\u00e4glich l\u00e4chelnd sterben k\u00f6nnen,", "tokens": ["Er", "h\u00e4t\u00b7te", "t\u00e4g\u00b7lich", "l\u00e4\u00b7chelnd", "ster\u00b7ben", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn Tod war ihm ein Wort wie andre auch.", "tokens": ["Denn", "Tod", "war", "ihm", "ein", "Wort", "wie", "and\u00b7re", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ART", "NN", "KOKOM", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ob bei den Kinderopfern Tr\u00e4nen r\u00f6nnen:", "tokens": ["Ob", "bei", "den", "Kin\u00b7der\u00b7op\u00b7fern", "Tr\u00e4\u00b7nen", "r\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Das war nur Zeremonie und ein Brauch.", "tokens": ["Das", "war", "nur", "Ze\u00b7re\u00b7mo\u00b7nie", "und", "ein", "Brauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn sie zu lachen \u00fcber sich gew\u00f6nnen", "tokens": ["Wenn", "sie", "zu", "la\u00b7chen", "\u00fc\u00b7ber", "sich", "ge\u00b7w\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKZU", "VVINF", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Im Tode und im Todeskrampf der Bauch", "tokens": ["Im", "To\u00b7de", "und", "im", "To\u00b7des\u00b7krampf", "der", "Bauch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Sich im Gel\u00e4chter der Vernichtung w\u00e4nde:", "tokens": ["Sich", "im", "Ge\u00b7l\u00e4ch\u00b7ter", "der", "Ver\u00b7nich\u00b7tung", "w\u00e4n\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "W\u00e4rs nicht ein Gott gef\u00e4lligeres Ende?", "tokens": ["W\u00e4rs", "nicht", "ein", "Gott", "ge\u00b7f\u00e4l\u00b7li\u00b7ge\u00b7res", "En\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Und als man ihm das weisse M\u00e4dchen brachte,", "tokens": ["Und", "als", "man", "ihm", "das", "weis\u00b7se", "M\u00e4d\u00b7chen", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "War er erstaunt wie ein Geburtstagskind.", "tokens": ["War", "er", "er\u00b7staunt", "wie", "ein", "Ge\u00b7burts\u00b7tags\u00b7kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er lobte ihre Weisse, und er lachte", "tokens": ["Er", "lob\u00b7te", "ih\u00b7re", "Weis\u00b7se", ",", "und", "er", "lach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und rief zur Schau das sch\u00e4mige Gesind.", "tokens": ["Und", "rief", "zur", "Schau", "das", "sch\u00e4\u00b7mi\u00b7ge", "Ge\u00b7sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und runzelte die sch\u00f6ne Stirn und dachte", "tokens": ["Und", "run\u00b7zel\u00b7te", "die", "sch\u00f6\u00b7ne", "Stirn", "und", "dach\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "An einen Goldfasan, den als Gebind", "tokens": ["An", "ei\u00b7nen", "Gold\u00b7fa\u00b7san", ",", "den", "als", "Ge\u00b7bind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "KOUS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Er gern dem wunderlichen Wahn vermachte,", "tokens": ["Er", "gern", "dem", "wun\u00b7der\u00b7li\u00b7chen", "Wahn", "ver\u00b7mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wie die Weissen in der Liebe sind,", "tokens": ["Und", "wie", "die", "Weis\u00b7sen", "in", "der", "Lie\u00b7be", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dies wars, was ihn zu sachter Glut entfachte.", "tokens": ["Dies", "wars", ",", "was", "ihn", "zu", "sach\u00b7ter", "Glut", "ent\u00b7fach\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Er f\u00fchrte sie in ein Gemach, und lind", "tokens": ["Er", "f\u00fchr\u00b7te", "sie", "in", "ein", "Ge\u00b7mach", ",", "und", "lind"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Erl\u00f6st er ihre Haut von h\u00e4nfner Kette,", "tokens": ["Er\u00b7l\u00f6st", "er", "ih\u00b7re", "Haut", "von", "h\u00e4nf\u00b7ner", "Ket\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Indes ihr Blut vor Angst und Qual gerinnt.", "tokens": ["In\u00b7des", "ihr", "Blut", "vor", "Angst", "und", "Qual", "ge\u00b7rinnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Denn an den W\u00e4nden stehen viel Skelette,", "tokens": ["Denn", "an", "den", "W\u00e4n\u00b7den", "ste\u00b7hen", "viel", "Ske\u00b7let\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gepflastert ist der Boden mit Gebein.", "tokens": ["Ge\u00b7pflas\u00b7tert", "ist", "der", "Bo\u00b7den", "mit", "Ge\u00b7bein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Sockel auch am bunten Liebesbette:", "tokens": ["Die", "So\u00b7ckel", "auch", "am", "bun\u00b7ten", "Lie\u00b7bes\u00b7bet\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Es m\u00fcssen toter Menschen Knochen sein.", "tokens": ["Es", "m\u00fcs\u00b7sen", "to\u00b7ter", "Men\u00b7schen", "Kno\u00b7chen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie will mit einem Fall ins Knie sich retten,", "tokens": ["Sie", "will", "mit", "ei\u00b7nem", "Fall", "ins", "Knie", "sich", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er aber l\u00e4chelt unerbittlich nein.", "tokens": ["Er", "a\u00b7ber", "l\u00e4\u00b7chelt", "un\u00b7er\u00b7bitt\u00b7lich", "nein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "PTKANT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Er hebt mit einem Pfiffe wie von Ratten", "tokens": ["Er", "hebt", "mit", "ei\u00b7nem", "Pfif\u00b7fe", "wie", "von", "Rat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie auf das Bett, sie t\u00f6dlich zu begatten.", "tokens": ["Sie", "auf", "das", "Bett", ",", "sie", "t\u00f6d\u00b7lich", "zu", "be\u00b7gat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Und als den letzten Kuss von ihrem Munde,", "tokens": ["Und", "als", "den", "letz\u00b7ten", "Kuss", "von", "ih\u00b7rem", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dem schon erkalteten, er gierig nahm,", "tokens": ["Dem", "schon", "er\u00b7kal\u00b7te\u00b7ten", ",", "er", "gie\u00b7rig", "nahm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVINF", "$,", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da f\u00fchlte er an seinem Leib die Wunde", "tokens": ["Da", "f\u00fchl\u00b7te", "er", "an", "sei\u00b7nem", "Leib", "die", "Wun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Die ewig blutende. Und schritt und kam", "tokens": ["Die", "e\u00b7wig", "blu\u00b7ten\u00b7de", ".", "Und", "schritt", "und", "kam"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "$.", "KON", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu seines Adels innerlichstem Grunde,", "tokens": ["Zu", "sei\u00b7nes", "A\u00b7dels", "in\u00b7ner\u00b7lichs\u00b7tem", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und f\u00fchlte seines Lebens Schuld und Scham.", "tokens": ["Und", "f\u00fchl\u00b7te", "sei\u00b7nes", "Le\u00b7bens", "Schuld", "und", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Darf hoffen, wer so krank, dass er gesunde?", "tokens": ["Darf", "hof\u00b7fen", ",", "wer", "so", "krank", ",", "dass", "er", "ge\u00b7sun\u00b7de", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PWS", "ADV", "ADJD", "$,", "KOUS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er hinkte durch die Kammer, lendenlahm,", "tokens": ["Er", "hink\u00b7te", "durch", "die", "Kam\u00b7mer", ",", "len\u00b7den\u00b7lahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und z\u00e4hlte zitternd jede neue Stunde.", "tokens": ["Und", "z\u00e4hl\u00b7te", "zit\u00b7ternd", "je\u00b7de", "neu\u00b7e", "Stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Warum bin ich verdammt, ach ohn Err\u00f6ten", "tokens": ["Wa\u00b7rum", "bin", "ich", "ver\u00b7dammt", ",", "ach", "ohn", "Er\u00b7r\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "VVPP", "$,", "XY", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Wesen, die ich lieben muss, zu t\u00f6ten?", "tokens": ["Die", "We\u00b7sen", ",", "die", "ich", "lie\u00b7ben", "muss", ",", "zu", "t\u00f6\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Indem er sich aus seinen Kissen hob,", "tokens": ["In\u00b7dem", "er", "sich", "aus", "sei\u00b7nen", "Kis\u00b7sen", "hob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Verfiel sein Blick auf einen goldnen Affen,", "tokens": ["Ver\u00b7fiel", "sein", "Blick", "auf", "ei\u00b7nen", "gold\u00b7nen", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Um den die Morgensonne Strahlen stob.", "tokens": ["Um", "den", "die", "Mor\u00b7gen\u00b7son\u00b7ne", "Strah\u00b7len", "stob", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Und als er n\u00e4her trat, ihn zu begaffen", "tokens": ["Und", "als", "er", "n\u00e4\u00b7her", "trat", ",", "ihn", "zu", "be\u00b7ga\u00b7ffen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "$,", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Noch zweifelnd, ob mit Tadel oder Lob", "tokens": ["Noch", "zwei\u00b7felnd", ",", "ob", "mit", "Ta\u00b7del", "o\u00b7der", "Lob"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er ihn bedenke: sah er ihn entraffen", "tokens": ["Er", "ihn", "be\u00b7den\u00b7ke", ":", "sah", "er", "ihn", "en\u00b7traf\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PPER", "VVFIN", "$.", "VVFIN", "PPER", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Im Teppich sich, den seine Amme wob.", "tokens": ["Im", "Tep\u00b7pich", "sich", ",", "den", "sei\u00b7ne", "Am\u00b7me", "wob", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er stand im Morgenlicht vor dem Gewebe:", "tokens": ["Er", "stand", "im", "Mor\u00b7gen\u00b7licht", "vor", "dem", "Ge\u00b7we\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Affe gl\u00e4nzt. Ich sp\u00fcre, dass ich lebe.", "tokens": ["Der", "Af\u00b7fe", "gl\u00e4nzt", ".", "Ich", "sp\u00fc\u00b7re", ",", "dass", "ich", "le\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Der fremde Ritter in der schwarzen R\u00fcstung", "tokens": ["Der", "frem\u00b7de", "Rit\u00b7ter", "in", "der", "schwar\u00b7zen", "R\u00fcs\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Begegnete dem Gruss des Kaisers streng.", "tokens": ["Be\u00b7ge\u00b7gne\u00b7te", "dem", "Gruss", "des", "Kai\u00b7sers", "streng", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Der lehnte schwach und schw\u00e4chlich an der Br\u00fcstung,", "tokens": ["Der", "lehn\u00b7te", "schwach", "und", "schw\u00e4ch\u00b7lich", "an", "der", "Br\u00fcs\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Als risse seiner Adern blau Gestr\u00e4ng,", "tokens": ["Als", "ris\u00b7se", "sei\u00b7ner", "A\u00b7dern", "blau", "Ge\u00b7str\u00e4ng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPOSAT", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als w\u00e4r er nur ein Schachtelhalm im Winde", "tokens": ["Als", "w\u00e4r", "er", "nur", "ein", "Schach\u00b7tel\u00b7halm", "im", "Win\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vor jenem, dem er seine Demut s\u00e4ng.", "tokens": ["Vor", "je\u00b7nem", ",", "dem", "er", "sei\u00b7ne", "De\u00b7mut", "s\u00e4ng", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Als tr\u00fcg er vor den Augen eine Binde", "tokens": ["Als", "tr\u00fcg", "er", "vor", "den", "Au\u00b7gen", "ei\u00b7ne", "Bin\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und s\u00e4he nun nach innen. Und darin", "tokens": ["Und", "s\u00e4\u00b7he", "nun", "nach", "in\u00b7nen", ".", "Und", "da\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADV", "$.", "KON", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War nichts als Eitelkeit und eitle S\u00fcnde,", "tokens": ["War", "nichts", "als", "Ei\u00b7tel\u00b7keit", "und", "eit\u00b7le", "S\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "KOKOM", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Und war nur Sinnlichkeit und war kein Sinn", "tokens": ["Und", "war", "nur", "Sinn\u00b7lich\u00b7keit", "und", "war", "kein", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "NN", "KON", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und war kein edles Ziel, kein zarter Zweck.", "tokens": ["Und", "war", "kein", "ed\u00b7les", "Ziel", ",", "kein", "zar\u00b7ter", "Zweck", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ginge er an diesem Tag dahin,", "tokens": ["Und", "gin\u00b7ge", "er", "an", "die\u00b7sem", "Tag", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PDAT", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Es bliebe nichts als eine Handvoll Dreck. \u2013", "tokens": ["Es", "blie\u00b7be", "nichts", "als", "ei\u00b7ne", "Hand\u00b7voll", "Dreck", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIS", "KOKOM", "ART", "NN", "NE", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Ritter sprach: Ich bin der Abgesandte", "tokens": ["Der", "Rit\u00b7ter", "sprach", ":", "Ich", "bin", "der", "Ab\u00b7ge\u00b7sand\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Des grossen weissen Herrschers \u00fcberm Meer.", "tokens": ["Des", "gros\u00b7sen", "weis\u00b7sen", "Herr\u00b7schers", "\u00fc\u00b7berm", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Ich kam, weil deine Dunkelheit ich kannte,", "tokens": ["Ich", "kam", ",", "weil", "dei\u00b7ne", "Dun\u00b7kel\u00b7heit", "ich", "kann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit hunderttausend hellen Helden her.", "tokens": ["Mit", "hun\u00b7dert\u00b7tau\u00b7send", "hel\u00b7len", "Hel\u00b7den", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So unterwirf dich, eh er dich berannte", "tokens": ["So", "un\u00b7ter\u00b7wirf", "dich", ",", "eh", "er", "dich", "be\u00b7rann\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Mit seinem unbesiegten Engelheer.", "tokens": ["Mit", "sei\u00b7nem", "un\u00b7be\u00b7sieg\u00b7ten", "En\u00b7gel\u00b7heer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du bist vor seinen Augen ganz geringe,", "tokens": ["Du", "bist", "vor", "sei\u00b7nen", "Au\u00b7gen", "ganz", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So neig dich, eh ich dich zur Neigung zwinge.", "tokens": ["So", "neig", "dich", ",", "eh", "ich", "dich", "zur", "Nei\u00b7gung", "zwin\u00b7ge", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Du hast die reinste Schwester uns gesch\u00e4ndet,", "tokens": ["Du", "hast", "die", "reins\u00b7te", "Schwes\u00b7ter", "uns", "ge\u00b7sch\u00e4n\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil du nur Wunschgewalt, nicht Liebe kennst.", "tokens": ["Weil", "du", "nur", "Wunschge\u00b7walt", ",", "nicht", "Lie\u00b7be", "kennst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "$,", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie bald hast du dein Pfauensein geendet,", "tokens": ["Wie", "bald", "hast", "du", "dein", "Pfau\u00b7en\u00b7sein", "ge\u00b7en\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Wenn du dir selbst als Totenfackel brennst.", "tokens": ["Wenn", "du", "dir", "selbst", "als", "To\u00b7ten\u00b7fa\u00b7ckel", "brennst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das Schicksal hat zur Schickung sich gewendet.", "tokens": ["Das", "Schick\u00b7sal", "hat", "zur", "Schi\u00b7ckung", "sich", "ge\u00b7wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ob du in Gebeten flammst und flennst:", "tokens": ["Und", "ob", "du", "in", "Ge\u00b7be\u00b7ten", "flammst", "und", "flennst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "Es darf von dir auf Erden nicht ein Hauch sein.", "tokens": ["Es", "darf", "von", "dir", "auf", "Er\u00b7den", "nicht", "ein", "Hauch", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "APPR", "NN", "PTKNEG", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du wirst verbrannt. Dein Letztes wird dein Rauch sein.", "tokens": ["Du", "wirst", "ver\u00b7brannt", ".", "Dein", "Letz\u00b7tes", "wird", "dein", "Rauch", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPOSAT", "ADJA", "VAFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Und jener zitterte und brach ins Knie", "tokens": ["Und", "je\u00b7ner", "zit\u00b7ter\u00b7te", "und", "brach", "ins", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und wusste nichts, als dass er seines Hortes", "tokens": ["Und", "wuss\u00b7te", "nichts", ",", "als", "dass", "er", "sei\u00b7nes", "Hor\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "$,", "KOKOM", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "H\u00fcter nun nicht mehr sei, und wie ein Vieh", "tokens": ["H\u00fc\u00b7ter", "nun", "nicht", "mehr", "sei", ",", "und", "wie", "ein", "Vieh"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PTKNEG", "ADV", "VAFIN", "$,", "KON", "PWAV", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.38": {"line.1": {"text": "Ein ganz vom Hunger und vom Durst verdorrtes", "tokens": ["Ein", "ganz", "vom", "Hun\u00b7ger", "und", "vom", "Durst", "ver\u00b7dorr\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "KON", "APPRART", "NN", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er bis zur Kuppel des Palastes schrie.", "tokens": ["Er", "bis", "zur", "Kup\u00b7pel", "des", "Pa\u00b7las\u00b7tes", "schrie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er str\u00e4ubte seine Haare wie ein Puma.", "tokens": ["Er", "str\u00e4ub\u00b7te", "sei\u00b7ne", "Haa\u00b7re", "wie", "ein", "Pu\u00b7ma", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Der andre sprach: So huldige, Montezuma,", "tokens": ["Der", "and\u00b7re", "sprach", ":", "So", "hul\u00b7di\u00b7ge", ",", "Mon\u00b7te\u00b7zu\u00b7ma", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "ADV", "VVFIN", "$,", "NE", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Des weissen Kaisers Abgesandtem: Cortez!", "tokens": ["Des", "weis\u00b7sen", "Kai\u00b7sers", "Ab\u00b7ge\u00b7sand\u00b7tem", ":", "Cor\u00b7tez", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$.", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}