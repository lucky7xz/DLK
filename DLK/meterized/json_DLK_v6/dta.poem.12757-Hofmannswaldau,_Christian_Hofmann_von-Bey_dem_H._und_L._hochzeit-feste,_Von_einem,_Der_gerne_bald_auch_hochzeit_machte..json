{"dta.poem.12757": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Bey dem H. und L. hochzeit-feste,  \n Von einem,  \n  Der gerne bald auch hochzeit machte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So bl\u00fchet endlich dein gel\u00fccke,", "tokens": ["So", "bl\u00fc\u00b7het", "end\u00b7lich", "dein", "ge\u00b7l\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der himmel lacht dich an, und schenckt dir liebes-blicke,", "tokens": ["Der", "him\u00b7mel", "lacht", "dich", "an", ",", "und", "schenckt", "dir", "lie\u00b7bes\u00b7bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er giebt dir eine liebe braut,", "tokens": ["Er", "giebt", "dir", "ei\u00b7ne", "lie\u00b7be", "braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sich in dich verliebet schaut,", "tokens": ["Die", "sich", "in", "dich", "ver\u00b7lie\u00b7bet", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Was du schon l\u00e4ngst gew\u00fcnscht, das ist dir nunmehr worden;", "tokens": ["Was", "du", "schon", "l\u00e4ngst", "ge\u00b7w\u00fcnscht", ",", "das", "ist", "dir", "nun\u00b7mehr", "wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVPP", "$,", "PDS", "VAFIN", "PPER", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du bist gesetzt in m\u00e4nner-orden.", "tokens": ["Du", "bist", "ge\u00b7setzt", "in", "m\u00e4n\u00b7ner\u00b7or\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich f\u00fchre noch mein einsam leben,", "tokens": ["Ich", "f\u00fch\u00b7re", "noch", "mein", "ein\u00b7sam", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du hast der einsamkeit nunmehr valet gegeben;", "tokens": ["Du", "hast", "der", "ein\u00b7sam\u00b7keit", "nun\u00b7mehr", "va\u00b7let", "ge\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Das bette steigst du nun selb-ander ein,", "tokens": ["Das", "bet\u00b7te", "steigst", "du", "nun", "selb\u00b7\u00b7an\u00b7der", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn andre in der nacht allein", "tokens": ["Wenn", "and\u00b7re", "in", "der", "nacht", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Durch einen falschen traum das kalte bett-tuch k\u00fcssen,", "tokens": ["Durch", "ei\u00b7nen", "fal\u00b7schen", "traum", "das", "kal\u00b7te", "bet\u00b7ttuch", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kanst du viel andre lust geniessen.", "tokens": ["Kanst", "du", "viel", "and\u00b7re", "lust", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ach! wie viel werden doch zum narren,", "tokens": ["Ach", "!", "wie", "viel", "wer\u00b7den", "doch", "zum", "nar\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PWAV", "PIS", "VAFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn sie auf den termin so lange m\u00fcssen harren,", "tokens": ["Wenn", "sie", "auf", "den", "ter\u00b7min", "so", "lan\u00b7ge", "m\u00fcs\u00b7sen", "har\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ADV", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Und geht es mit der zeit noch an,", "tokens": ["Und", "geht", "es", "mit", "der", "zeit", "noch", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man mit m\u00e4gdgen l\u00f6ffeln kan,", "tokens": ["Da\u00df", "man", "mit", "m\u00e4gd\u00b7gen", "l\u00f6f\u00b7feln", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Mit was vor schwerer noth, m\u00fch, schreiben, schicken, lauffen,", "tokens": ["Mit", "was", "vor", "schwe\u00b7rer", "noth", ",", "m\u00fch", ",", "schrei\u00b7ben", ",", "schi\u00b7cken", ",", "lauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "ADJA", "NN", "$,", "ADJD", "$,", "VVFIN", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mu\u00df man nicht diese lust erkauffen?", "tokens": ["Mu\u00df", "man", "nicht", "die\u00b7se", "lust", "er\u00b7kauf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKNEG", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da l\u00e4st man sich wohin bestellen,", "tokens": ["Da", "l\u00e4st", "man", "sich", "wo\u00b7hin", "be\u00b7stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wenn es richtig ist, h\u00f6rt man ein h\u00fcndgen bellen,", "tokens": ["Und", "wenn", "es", "rich\u00b7tig", "ist", ",", "h\u00f6rt", "man", "ein", "h\u00fcnd\u00b7gen", "bel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "VVFIN", "PIS", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Da\u00df man mit \u00e4userstem verdru\u00df", "tokens": ["Da\u00df", "man", "mit", "\u00e4u\u00b7sers\u00b7tem", "ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sich von der liebsten machen mu\u00df.", "tokens": ["Sich", "von", "der", "liebs\u00b7ten", "ma\u00b7chen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "So will das schicksal sich an unsrer liebe r\u00e4chen,", "tokens": ["So", "will", "das", "schick\u00b7sal", "sich", "an", "uns\u00b7rer", "lie\u00b7be", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDS", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "VVINF", "$,"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und solt es uns ein bein zerbrechen.", "tokens": ["Und", "solt", "es", "uns", "ein", "bein", "zer\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dann mu\u00df man sich bereden lassen,", "tokens": ["Dann", "mu\u00df", "man", "sich", "be\u00b7re\u00b7den", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PRF", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die kinder tragen sich damit auf allen gassen:", "tokens": ["Die", "kin\u00b7der", "tra\u00b7gen", "sich", "da\u00b7mit", "auf", "al\u00b7len", "gas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PAV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Da liegt man wie ein \u2012 \u2012 \u2012 hut,", "tokens": ["Da", "liegt", "man", "wie", "ein", "\u2012", "\u2012", "\u2012", "hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "KOKOM", "ART", "$(", "$(", "$(", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der schmertz thut weh, es sinckt der muth,", "tokens": ["Der", "schmertz", "thut", "weh", ",", "es", "sinckt", "der", "muth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Man scharret sich im grind, und schl\u00e4gt die augen nieder,", "tokens": ["Man", "schar\u00b7ret", "sich", "im", "grind", ",", "und", "schl\u00e4gt", "die", "au\u00b7gen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPRART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor scham err\u00f6then alle glieder.", "tokens": ["Vor", "scham", "er\u00b7r\u00f6\u00b7then", "al\u00b7le", "glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Freund! du hast es wohl getroffen,", "tokens": ["Mein", "Freund", "!", "du", "hast", "es", "wohl", "ge\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dein thun ist nicht gericht auf ein betr\u00fcglich hoffen;", "tokens": ["Dein", "thun", "ist", "nicht", "ge\u00b7richt", "auf", "ein", "be\u00b7tr\u00fcg\u00b7lich", "hof\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "VAFIN", "PTKNEG", "VVPP", "APPR", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Wenn andere vor liebes-pein", "tokens": ["Wenn", "an\u00b7de\u00b7re", "vor", "lie\u00b7bes\u00b7pein"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie hirse-brey so m\u00fcrbe seyn,", "tokens": ["Wie", "hir\u00b7se\u00b7brey", "so", "m\u00fcr\u00b7be", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADV", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Darff dir nicht furcht und noth gestrenge lehren schreiben,", "tokens": ["Darff", "dir", "nicht", "furcht", "und", "noth", "ge\u00b7stren\u00b7ge", "leh\u00b7ren", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "NN", "KON", "NN", "VVFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du kanst ja hahn im korbe bleiben.", "tokens": ["Du", "kanst", "ja", "hahn", "im", "kor\u00b7be", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Drum la\u00df der liebe freyen z\u00fcgel,", "tokens": ["Drum", "la\u00df", "der", "lie\u00b7be", "frey\u00b7en", "z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jm alter schmeckt kein ku\u00df, der liebe wahres siegel,", "tokens": ["Jm", "al\u00b7ter", "schmeckt", "kein", "ku\u00df", ",", "der", "lie\u00b7be", "wah\u00b7res", "sie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "PIAT", "NN", "$,", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}}, "stanza.13": {"line.1": {"text": "Wenn alte treiben courtesie,", "tokens": ["Wenn", "al\u00b7te", "trei\u00b7ben", "cour\u00b7te\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So schmecket es, ich wei\u00df nicht wie?", "tokens": ["So", "schme\u00b7cket", "es", ",", "ich", "wei\u00df", "nicht", "wie", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PTKNEG", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Es darff ein runtzel-balg von frischen liebes-sachen", "tokens": ["Es", "darff", "ein", "runt\u00b7zel\u00b7balg", "von", "fri\u00b7schen", "lie\u00b7bes\u00b7sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wahrhafftig keinen staat mehr machen.", "tokens": ["Wahr\u00b7haff\u00b7tig", "kei\u00b7nen", "staat", "mehr", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nun wenn wir uns zu tische setzen,", "tokens": ["Nun", "wenn", "wir", "uns", "zu", "ti\u00b7sche", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "So wird dich Venus noch mit andrer kost ergetzen;", "tokens": ["So", "wird", "dich", "Ve\u00b7nus", "noch", "mit", "an\u00b7drer", "kost", "er\u00b7get\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Da legt sie deiner braut und dir", "tokens": ["Da", "legt", "sie", "dei\u00b7ner", "braut", "und", "dir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "VVFIN", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den wundersch\u00f6nen segen f\u00fcr,", "tokens": ["Den", "wun\u00b7der\u00b7sch\u00f6\u00b7nen", "se\u00b7gen", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Den ihr zwar k\u00f6nnt mit l\u00f6ffeln essen,", "tokens": ["Den", "ihr", "zwar", "k\u00f6nnt", "mit", "l\u00f6f\u00b7feln", "es\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "APPR", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch werdet \u00fcbers jahr ihr ihn mit mulden messen.", "tokens": ["Doch", "wer\u00b7det", "\u00fc\u00b7bers", "jahr", "ihr", "ihn", "mit", "mul\u00b7den", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "PPER", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}