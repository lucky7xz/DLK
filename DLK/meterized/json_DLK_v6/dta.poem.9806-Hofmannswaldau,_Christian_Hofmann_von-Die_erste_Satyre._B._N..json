{"dta.poem.9806": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Die erste Satyre.  \n B. N.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Damon/ der grosse mann/ der so geraume zeit/", "tokens": ["Da\u00b7mon", "/", "der", "gros\u00b7se", "mann", "/", "der", "so", "ge\u00b7rau\u00b7me", "zeit", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ART", "ADJA", "NN", "$(", "ART", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch seinen musen-schertz hat hof und stadt erfreut/", "tokens": ["Durch", "sei\u00b7nen", "mu\u00b7sen\u00b7schertz", "hat", "hof", "und", "stadt", "er\u00b7freut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "NN", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Inzwischen aber sich in grobes tuch nur kleidet:", "tokens": ["I\u00b7nzwi\u00b7schen", "a\u00b7ber", "sich", "in", "gro\u00b7bes", "tuch", "nur", "klei\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "APPR", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jm winter k\u00e4lt und frost/ im sommer hitze leidet;", "tokens": ["Jm", "win\u00b7ter", "k\u00e4lt", "und", "frost", "/", "im", "som\u00b7mer", "hit\u00b7ze", "lei\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "KON", "ADJD", "$(", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und dessen trockner leib und hungrige gestalt", "tokens": ["Und", "des\u00b7sen", "trock\u00b7ner", "leib", "und", "hung\u00b7ri\u00b7ge", "ge\u00b7stalt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den ruhm gar sehr beschimpfft/ der doch von ihm erschallt/", "tokens": ["Den", "ruhm", "gar", "sehr", "be\u00b7schimpfft", "/", "der", "doch", "von", "ihm", "er\u00b7schallt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADJD", "$(", "ART", "ADV", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ward endlich m\u00fcd und satt sein g\u00fctgen zu verschwenden/", "tokens": ["Ward", "end\u00b7lich", "m\u00fcd", "und", "satt", "sein", "g\u00fct\u00b7gen", "zu", "ver\u00b7schwen\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "KON", "ADJD", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und so viel sauren schwei\u00df an einen reim zu wenden/", "tokens": ["Und", "so", "viel", "sau\u00b7ren", "schwei\u00df", "an", "ei\u00b7nen", "reim", "zu", "wen\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "ADJD", "APPR", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dadurch er nichts verdient/ wohl aber in gefahr/", "tokens": ["Da\u00b7durch", "er", "nichts", "ver\u00b7dient", "/", "wohl", "a\u00b7ber", "in", "ge\u00b7fahr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PIS", "VVPP", "$(", "ADV", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In schulden/ um sein kleid und alles kommen war;", "tokens": ["In", "schul\u00b7den", "/", "um", "sein", "kleid", "und", "al\u00b7les", "kom\u00b7men", "war", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$(", "APPR", "PPOSAT", "NN", "KON", "PIS", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So da\u00df er nichts bey sich als seinen kummer f\u00fchrte:", "tokens": ["So", "da\u00df", "er", "nichts", "bey", "sich", "als", "sei\u00b7nen", "kum\u00b7mer", "f\u00fchr\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PIS", "APPR", "PRF", "KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Drum sucht er fried und ruh/ die er doch nirgends sp\u00fcrte/", "tokens": ["Drum", "sucht", "er", "fried", "und", "ruh", "/", "die", "er", "doch", "nir\u00b7gends", "sp\u00fcr\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "KON", "NN", "$(", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und sann auf sichre flucht und einen w\u00fcsten hayn/", "tokens": ["Und", "sann", "auf", "sich\u00b7re", "flucht", "und", "ei\u00b7nen", "w\u00fcs\u00b7ten", "hayn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "VVFIN", "KON", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wo weder rath noch knecht ihm k\u00f6nte sch\u00e4dlich seyn.", "tokens": ["Wo", "we\u00b7der", "rath", "noch", "knecht", "ihm", "k\u00f6n\u00b7te", "sch\u00e4d\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "NN", "ADV", "VVFIN", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bevor die krumme hand der ihm verhasten rechte", "tokens": ["Be\u00b7vor", "die", "krum\u00b7me", "hand", "der", "ihm", "ver\u00b7has\u00b7ten", "rech\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "PPER", "VVFIN", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Jhn in das finstre loch des kerckers werffen m\u00f6chte/", "tokens": ["Jhn", "in", "das", "finst\u00b7re", "loch", "des", "ker\u00b7ckers", "werf\u00b7fen", "m\u00f6ch\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.17": {"text": "Und er noch etwan gar sich schimpflich m\u00fcste sehn", "tokens": ["Und", "er", "noch", "et\u00b7wan", "gar", "sich", "schimpf\u00b7lich", "m\u00fcs\u00b7te", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ADV", "ADV", "PRF", "ADJD", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Bey seiner lorbeer-pracht im gr\u00fcnen hute gehn.", "tokens": ["Bey", "sei\u00b7ner", "lor\u00b7beer\u00b7pracht", "im", "gr\u00fc\u00b7nen", "hu\u00b7te", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Jedoch indem er schied/ gantz bla\u00df und abgezehret", "tokens": ["Je\u00b7doch", "in\u00b7dem", "er", "schied", "/", "gantz", "bla\u00df", "und", "ab\u00b7ge\u00b7zeh\u00b7ret"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$(", "ADV", "ADJD", "KON", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Als einer/ den die last der s\u00fcnde noch beschweret/", "tokens": ["Als", "ei\u00b7ner", "/", "den", "die", "last", "der", "s\u00fcn\u00b7de", "noch", "be\u00b7schwe\u00b7ret", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "ART", "ART", "VVFIN", "ART", "ADJA", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zur letzten fasten-zeit; so sah er auf sein hau\u00df", "tokens": ["Zur", "letz\u00b7ten", "fas\u00b7ten\u00b7zeit", ";", "so", "sah", "er", "auf", "sein", "hau\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$.", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und stie\u00df voll grimm und feu\u2019r noch diese w\u00f6rter aus:", "tokens": ["Und", "stie\u00df", "voll", "grimm", "und", "feu'r", "noch", "die\u00b7se", "w\u00f6r\u00b7ter", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADJD", "KON", "NN", "ADV", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Weil denn in dieser stadt/ wo Ph\u00f6dus stets gewohnet/", "tokens": ["Weil", "denn", "in", "die\u00b7ser", "stadt", "/", "wo", "Ph\u00f6\u00b7dus", "stets", "ge\u00b7woh\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PDAT", "NN", "$(", "PWAV", "NE", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Verdienst und klugheit nicht wie vormahls wird belohnet;", "tokens": ["Ver\u00b7dienst", "und", "klug\u00b7heit", "nicht", "wie", "vor\u00b7mahls", "wird", "be\u00b7loh\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKNEG", "KOKOM", "ADV", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Weil die Poeten ja von GOtt verlassen sind/", "tokens": ["Weil", "die", "Po\u00b7et\u00b7en", "ja", "von", "Gott", "ver\u00b7las\u00b7sen", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und man hier weder scham/ noch wahre tugend findt;", "tokens": ["Und", "man", "hier", "we\u00b7der", "scham", "/", "noch", "wah\u00b7re", "tu\u00b7gend", "findt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "KON", "ADJD", "$(", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So last uns einen ort in hohlen felsen suchen/", "tokens": ["So", "last", "uns", "ei\u00b7nen", "ort", "in", "hoh\u00b7len", "fel\u00b7sen", "su\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wo uns kein h\u00e4scher-knecht/ kein scherge mehr darff fluchen.", "tokens": ["Wo", "uns", "kein", "h\u00e4\u00b7scher\u00b7knecht", "/", "kein", "scher\u00b7ge", "mehr", "darff", "flu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "$(", "PIAT", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und weil wir ohne dem umsonst zum himmel schreyn/", "tokens": ["Und", "weil", "wir", "oh\u00b7ne", "dem", "um\u00b7sonst", "zum", "him\u00b7mel", "schreyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So la\u00dft der zeit zu trotz uns einst verborgen seyn.", "tokens": ["So", "la\u00dft", "der", "zeit", "zu", "trotz", "uns", "einst", "ver\u00b7bor\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "APPR", "PPER", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Dieweil noch meinen fu\u00df kein schwerer fessel dr\u00fccket;", "tokens": ["Die\u00b7weil", "noch", "mei\u00b7nen", "fu\u00df", "kein", "schwe\u00b7rer", "fes\u00b7sel", "dr\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "PTKVZ", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Dieweil sich nicht mein leib f\u00fcr grauem alter b\u00fccket/", "tokens": ["Die\u00b7weil", "sich", "nicht", "mein", "leib", "f\u00fcr", "grau\u00b7em", "al\u00b7ter", "b\u00fc\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PTKNEG", "PPOSAT", "NN", "APPR", "ADJA", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Mein gang/ gleichwie zuvor/ noch alle schritte mi\u00dft/", "tokens": ["Mein", "gang", "/", "gleich\u00b7wie", "zu\u00b7vor", "/", "noch", "al\u00b7le", "schrit\u00b7te", "mi\u00dft", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "KON", "ADV", "$(", "ADV", "PIAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Und meines lebens rest nicht gantz versponnen ist:", "tokens": ["Und", "mei\u00b7nes", "le\u00b7bens", "rest", "nicht", "gantz", "ver\u00b7spon\u00b7nen", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKNEG", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "Das ist der beste rath/ den ich mir ietzt kan geben.", "tokens": ["Das", "ist", "der", "bes\u00b7te", "rath", "/", "den", "ich", "mir", "ietzt", "kan", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "PRELS", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Es lebe G\u00f6rg\u2019 allhier/ weil G\u00f6rge hier kan leben/", "tokens": ["Es", "le\u00b7be", "G\u00f6r\u00b7g'", "all\u00b7hier", "/", "weil", "G\u00f6r\u00b7ge", "hier", "kan", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "ADV", "$(", "KOUS", "NN", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.37": {"text": "Den eine million/ die sein betrug erschnellt/", "tokens": ["Den", "ei\u00b7ne", "mil\u00b7li\u00b7on", "/", "die", "sein", "be\u00b7trug", "er\u00b7schnellt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Aus einem pfaff und knecht in grafen hat verstellt.", "tokens": ["Aus", "ei\u00b7nem", "pfaff", "und", "knecht", "in", "gra\u00b7fen", "hat", "ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "VVFIN", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Es lebe Jacob hier/ der durch sein kluges scheren", "tokens": ["Es", "le\u00b7be", "Ja\u00b7cob", "hier", "/", "der", "durch", "sein", "klu\u00b7ges", "sche\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "ADV", "$(", "ART", "APPR", "PPOSAT", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Uns noch mehr schaden wird/ als pest und krieg geb\u00e4hren;", "tokens": ["Uns", "noch", "mehr", "scha\u00b7den", "wird", "/", "als", "pest", "und", "krieg", "ge\u00b7b\u00e4h\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVINF", "VAFIN", "$(", "KOKOM", "VVFIN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Der seine rennten gar ins A. B. C. gebracht/", "tokens": ["Der", "sei\u00b7ne", "renn\u00b7ten", "gar", "ins", "A.", "B.", "C.", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "abbreviation", "abbreviation", "word", "punct"], "pos": ["ART", "PPOSAT", "VVFIN", "ADV", "APPRART", "APPRART", "NN", "NE", "VVPP", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.42": {"text": "Und einen band daraus/ wie Cale\u00dfin/ erdacht;", "tokens": ["Und", "ei\u00b7nen", "band", "da\u00b7raus", "/", "wie", "Ca\u00b7le\u00b7\u00dfin", "/", "er\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "PAV", "$(", "KOKOM", "NE", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Er herrsch\u2019 in dieser stadt! Er kan mit rechte lachen.", "tokens": ["Er", "herr\u00b7sch'", "in", "die\u00b7ser", "stadt", "!", "Er", "kan", "mit", "rech\u00b7te", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "$.", "PPER", "VMFIN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.44": {"text": "Ich aber in Paris was solt ich doch hier machen?", "tokens": ["Ich", "a\u00b7ber", "in", "Pa\u00b7ris", "was", "solt", "ich", "doch", "hier", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NE", "PWS", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Ich bin nicht auff betrug und falschheit abgericht;", "tokens": ["Ich", "bin", "nicht", "auff", "be\u00b7trug", "und", "falschheit", "ab\u00b7ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPR", "VVFIN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Und w\u00e4r ich es auch gleich/ nein/ l\u00fcgen mag ich nicht.", "tokens": ["Und", "w\u00e4r", "ich", "es", "auch", "gleich", "/", "nein", "/", "l\u00fc\u00b7gen", "mag", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "ADV", "ADV", "$(", "PTKANT", "$(", "VVINF", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Ich kan den \u00fcbermuth der narren nicht verschweigen/", "tokens": ["Ich", "kan", "den", "\u00fc\u00b7ber\u00b7muth", "der", "nar\u00b7ren", "nicht", "ver\u00b7schwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "F\u00fcr denen andre sich des soldes wegen beugen:", "tokens": ["F\u00fcr", "de\u00b7nen", "and\u00b7re", "sich", "des", "sol\u00b7des", "we\u00b7gen", "beu\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "PRF", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Ich schreibe kein sonnet mit schmeicheln in die welt/", "tokens": ["Ich", "schrei\u00b7be", "kein", "son\u00b7net", "mit", "schmei\u00b7cheln", "in", "die", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "VVFIN", "APPR", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.50": {"text": "Und wen ich loben will/ den lob ich ohne geld.", "tokens": ["Und", "wen", "ich", "lo\u00b7ben", "will", "/", "den", "lob", "ich", "oh\u00b7ne", "geld", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$(", "ART", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "F\u00fcr ein so schlechtes amt bin ich zu hoch gebohren:", "tokens": ["F\u00fcr", "ein", "so", "schlech\u00b7tes", "amt", "bin", "ich", "zu", "hoch", "ge\u00b7boh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "VAFIN", "PPER", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Mein geist ist etwas starck und b\u00e4urisch abgejohren;", "tokens": ["Mein", "geist", "ist", "et\u00b7was", "starck", "und", "b\u00e4u\u00b7risch", "ab\u00b7ge\u00b7joh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ich sage/ wie es ist. Ein sieb nenn\u2019 ich ein sieb/", "tokens": ["Ich", "sa\u00b7ge", "/", "wie", "es", "ist", ".", "Ein", "sieb", "nenn'", "ich", "ein", "sieb", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWAV", "PPER", "VAFIN", "$.", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Ein k\u00e4tzgen eine katz/ und Rolet einen dieb.", "tokens": ["Ein", "k\u00e4tz\u00b7gen", "ei\u00b7ne", "katz", "/", "und", "Ro\u00b7let", "ei\u00b7nen", "dieb", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "$(", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Verliebten wei\u00df ich nichts geschicktes auszusinnen/", "tokens": ["Ver\u00b7lieb\u00b7ten", "wei\u00df", "ich", "nichts", "ge\u00b7schick\u00b7tes", "aus\u00b7zu\u00b7sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PIS", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Ich kan auch nicht die kunst die m\u00e4gdchen zu gewinnen/", "tokens": ["Ich", "kan", "auch", "nicht", "die", "kunst", "die", "m\u00e4gd\u00b7chen", "zu", "ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "ART", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und leb in dieser stadt so einsam und verzagt/", "tokens": ["Und", "leb", "in", "die\u00b7ser", "stadt", "so", "ein\u00b7sam", "und", "ver\u00b7zagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "ADV", "ADJD", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Als ein halb-todter leib/ den die verstopffung plagt.", "tokens": ["Als", "ein", "halb\u00b7tod\u00b7ter", "leib", "/", "den", "die", "ver\u00b7stopf\u00b7fung", "plagt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$(", "ART", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Wer aber/ wirfft man ein/ heist solche tugend lieben/", "tokens": ["Wer", "a\u00b7ber", "/", "wirfft", "man", "ein", "/", "heist", "sol\u00b7che", "tu\u00b7gend", "lie\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$(", "VVFIN", "PIS", "ART", "$(", "VAFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Die man sonst nirgends sieht als in spit\u00e4len \u00fcben?", "tokens": ["Die", "man", "sonst", "nir\u00b7gends", "sieht", "als", "in", "spi\u00b7t\u00e4\u00b7len", "\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "VVFIN", "KOKOM", "APPR", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Die hoffart stehet nur bey gut und gelde fein/", "tokens": ["Die", "hof\u00b7fart", "ste\u00b7het", "nur", "bey", "gut", "und", "gel\u00b7de", "fein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ADJD", "KON", "ADJA", "NN", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.62": {"text": "Ein armer aber mu\u00df zum dienen willig seyn.", "tokens": ["Ein", "ar\u00b7mer", "a\u00b7ber", "mu\u00df", "zum", "die\u00b7nen", "wil\u00b7lig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VMFIN", "APPRART", "PDS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Durch kuppeln kan ein mann den noth und hunger schw\u00e4chen/", "tokens": ["Durch", "kup\u00b7peln", "kan", "ein", "mann", "den", "noth", "und", "hun\u00b7ger", "schw\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "VMFIN", "ART", "NN", "ART", "NN", "KON", "ADJD", "VVINF", "$("], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.64": {"text": "Den einflu\u00df und die macht der falschen sterne brechen.", "tokens": ["Den", "ein\u00b7flu\u00df", "und", "die", "macht", "der", "fal\u00b7schen", "ster\u00b7ne", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.65": {"text": "Durch kuppeln hebt das gl\u00fcck/ bey dieser harten zeit/", "tokens": ["Durch", "kup\u00b7peln", "hebt", "das", "gl\u00fcck", "/", "bey", "die\u00b7ser", "har\u00b7ten", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$(", "APPR", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Auch schreiber/ wenn es will/ zur h\u00f6chsten herrligkeit.", "tokens": ["Auch", "schrei\u00b7ber", "/", "wenn", "es", "will", "/", "zur", "h\u00f6chs\u00b7ten", "herr\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "KOUS", "PPER", "VMFIN", "$(", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "So gar ist tugend ietzt vom schicksal unterdr\u00fccket.", "tokens": ["So", "gar", "ist", "tu\u00b7gend", "ietzt", "vom", "schick\u00b7sal", "un\u00b7ter\u00b7dr\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADJD", "ADV", "APPRART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Ein schulfuchs triumphirt und wird empor ger\u00fccket/", "tokens": ["Ein", "schul\u00b7fuchs", "tri\u00b7um\u00b7phirt", "und", "wird", "em\u00b7por", "ge\u00b7r\u00fc\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVPP", "KON", "VAFIN", "PTKVZ", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Der/ h\u00e4tt\u2019 er \u00f6ffters nicht durch falsche wissenschafft", "tokens": ["Der", "/", "h\u00e4tt'", "er", "\u00f6ff\u00b7ters", "nicht", "durch", "fal\u00b7sche", "wis\u00b7sen\u00b7schafft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$(", "VAFIN", "PPER", "ADV", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Das grade krumm gemacht/ und durch der stimmen krafft", "tokens": ["Das", "gra\u00b7de", "krumm", "ge\u00b7macht", "/", "und", "durch", "der", "stim\u00b7men", "krafft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADJD", "VVPP", "$(", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Das arme land gepre\u00dft/ wol sonst an seinem wagen", "tokens": ["Das", "ar\u00b7me", "land", "ge\u00b7pre\u00dft", "/", "wol", "sonst", "an", "sei\u00b7nem", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP", "$(", "ADV", "ADV", "APPR", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Selbst w\u00fcrde kutscher seyn und liebereyen tragen.", "tokens": ["Selbst", "w\u00fcr\u00b7de", "kut\u00b7scher", "seyn", "und", "lie\u00b7be\u00b7re\u00b7yen", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "VAINF", "KON", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Ich wei\u00df wohl/ da\u00df die furcht/ von wegen dieser that/", "tokens": ["Ich", "wei\u00df", "wohl", "/", "da\u00df", "die", "furcht", "/", "von", "we\u00b7gen", "die\u00b7ser", "that", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "KOUS", "ART", "NN", "$(", "APPR", "APPR", "PDAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Erst neulich einen mann von uns entfernet hat:", "tokens": ["Erst", "neu\u00b7lich", "ei\u00b7nen", "mann", "von", "uns", "ent\u00b7fer\u00b7net", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Allein die taxe hat ihn nur umsonst geschrecket:", "tokens": ["Al\u00b7lein", "die", "ta\u00b7xe", "hat", "ihn", "nur", "um\u00b7sonst", "ge\u00b7schre\u00b7cket", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Man wird ihn wieder bald mit fremder pracht bedecket/", "tokens": ["Man", "wird", "ihn", "wie\u00b7der", "bald", "mit", "frem\u00b7der", "pracht", "be\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Und r\u00e4uberey gespickt durch alle gassen gehn/", "tokens": ["Und", "r\u00e4u\u00b7be\u00b7rey", "ge\u00b7spickt", "durch", "al\u00b7le", "gas\u00b7sen", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Und GOtt/ der ihn doch ha\u00dft/ verzweiffelt pochen sehn.", "tokens": ["Und", "Gott", "/", "der", "ihn", "doch", "ha\u00dft", "/", "ver\u00b7zweif\u00b7felt", "po\u00b7chen", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "PRELS", "PPER", "ADV", "VVFIN", "$(", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Inde\u00df/ da\u00df Pelletier den todten knochen gleichet/", "tokens": ["In\u00b7de\u00df", "/", "da\u00df", "Pel\u00b7le\u00b7tier", "den", "tod\u00b7ten", "kno\u00b7chen", "glei\u00b7chet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Und stets von einer th\u00fcr zur andern betteln schleichet/", "tokens": ["Und", "stets", "von", "ei\u00b7ner", "th\u00fcr", "zur", "an\u00b7dern", "bet\u00b7teln", "schlei\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APPRART", "ADJA", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Der doch die kunst versteht/ die ieder kluger ehrt/", "tokens": ["Der", "doch", "die", "kunst", "ver\u00b7steht", "/", "die", "ie\u00b7der", "klu\u00b7ger", "ehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$(", "ART", "PIAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Und Monmaur eher zeit hat in Paris gelehrt.", "tokens": ["Und", "Mon\u00b7maur", "e\u00b7her", "zeit", "hat", "in", "Pa\u00b7ris", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "NN", "VAFIN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Zwar unser k\u00f6nig zieht zu unserm grossen gl\u00fccke", "tokens": ["Zwar", "un\u00b7ser", "k\u00f6\u00b7nig", "zieht", "zu", "un\u00b7serm", "gros\u00b7sen", "gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJD", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Den schwachen Ph\u00f6bus noch aus dem spital zur\u00fccke/", "tokens": ["Den", "schwa\u00b7chen", "Ph\u00f6\u00b7bus", "noch", "aus", "dem", "spi\u00b7tal", "zu\u00b7r\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ART", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.85": {"text": "Erh\u00e4lt ihn f\u00fcr dem fall und wirfft bey krieg und ruh", "tokens": ["Er\u00b7h\u00e4lt", "ihn", "f\u00fcr", "dem", "fall", "und", "wirfft", "bey", "krieg", "und", "ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "KON", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Den Musen offtermals geneigte blicke zu.", "tokens": ["Den", "Mu\u00b7sen", "off\u00b7ter\u00b7mals", "ge\u00b7neig\u00b7te", "bli\u00b7cke", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJA", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Man wei\u00df/ da\u00df dieser held blo\u00df nach verdienst erhebet:", "tokens": ["Man", "wei\u00df", "/", "da\u00df", "die\u00b7ser", "held", "blo\u00df", "nach", "ver\u00b7dienst", "er\u00b7he\u00b7bet", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "KOUS", "PDS", "VVFIN", "ADV", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Was aber hilfft August/ wo kein Mec\u00e4nas lebet?", "tokens": ["Was", "a\u00b7ber", "hilfft", "Au\u00b7gust", "/", "wo", "kein", "Me\u00b7c\u00e4\u00b7nas", "le\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "NN", "$(", "PWAV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Wer wolte sich doch wohl bey meiner schweren pein", "tokens": ["Wer", "wol\u00b7te", "sich", "doch", "wohl", "bey", "mei\u00b7ner", "schwe\u00b7ren", "pein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PRF", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "So viel erniedrigen und meine st\u00fctze seyn?", "tokens": ["So", "viel", "er\u00b7nied\u00b7ri\u00b7gen", "und", "mei\u00b7ne", "st\u00fct\u00b7ze", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "KON", "PPOSAT", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Und w\u00e4r auch dieses gleich; wie br\u00e4ch ich durch den hauffen", "tokens": ["Und", "w\u00e4r", "auch", "die\u00b7ses", "gleich", ";", "wie", "br\u00e4ch", "ich", "durch", "den", "hauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PDAT", "ADV", "$.", "PWAV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Der reimer/ die ihn meist aus hunger \u00fcberlauffen/", "tokens": ["Der", "rei\u00b7mer", "/", "die", "ihn", "meist", "aus", "hun\u00b7ger", "\u00fc\u00b7berl\u00b7auf\u00b7fen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "PRELS", "PPER", "ADV", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Die stets die ersten sind/ wo seine hand sich r\u00fchrt/", "tokens": ["Die", "stets", "die", "ers\u00b7ten", "sind", "/", "wo", "sei\u00b7ne", "hand", "sich", "r\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "VAFIN", "$(", "PWAV", "PPOSAT", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Und stehlen/ was doch offt dem letzten nur geb\u00fchrt.", "tokens": ["Und", "steh\u00b7len", "/", "was", "doch", "offt", "dem", "letz\u00b7ten", "nur", "ge\u00b7b\u00fchrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "PWS", "ADV", "ADV", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Gleichwie die wespen thun/ die selber nichts verdienen/", "tokens": ["Gleich\u00b7wie", "die", "wes\u00b7pen", "thun", "/", "die", "sel\u00b7ber", "nichts", "ver\u00b7die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$(", "ART", "ADV", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Und doch den honigseim der arbeits-vollen bienen", "tokens": ["Und", "doch", "den", "ho\u00b7ni\u00b7gseim", "der", "ar\u00b7beits\u00b7vol\u00b7len", "bie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "In ihren rachen ziehn. Drum habet gute nacht/", "tokens": ["In", "ih\u00b7ren", "ra\u00b7chen", "ziehn", ".", "Drum", "ha\u00b7bet", "gu\u00b7te", "nacht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$.", "PAV", "VAFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Gewinste/ weil ihr nur verwegne gl\u00fccklich macht.", "tokens": ["Ge\u00b7wins\u00b7te", "/", "weil", "ihr", "nur", "ver\u00b7weg\u00b7ne", "gl\u00fcck\u00b7lich", "macht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "PPER", "ADV", "VVFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Amandus hatte nichts als seine kunst zum besten/", "tokens": ["A\u00b7man\u00b7dus", "hat\u00b7te", "nichts", "als", "sei\u00b7ne", "kunst", "zum", "bes\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIS", "KOKOM", "PPOSAT", "NN", "APPRART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Sein gut und erbtheil war ein rock mit einer westen/", "tokens": ["Sein", "gut", "und", "erbt\u00b7heil", "war", "ein", "rock", "mit", "ei\u00b7ner", "wes\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "KON", "ADJD", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Ein blat/ wo fiat stund/ ein bett\u2019/ ein str\u00fcmpffchen lichts/", "tokens": ["Ein", "blat", "/", "wo", "fiat", "stund", "/", "ein", "bett'", "/", "ein", "str\u00fcmpffc\u00b7hen", "lichts", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWAV", "VVFIN", "ADJD", "$(", "ART", "ADJD", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.102": {"text": "Und endlich kurtz gesagt: Amandus hatte nichts.", "tokens": ["Und", "end\u00b7lich", "kurtz", "ge\u00b7sagt", ":", "A\u00b7man\u00b7dus", "hat\u00b7te", "nichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVPP", "$.", "NE", "VAFIN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Als er nun m\u00fcde war sein leben so zu f\u00fchren/", "tokens": ["Als", "er", "nun", "m\u00fc\u00b7de", "war", "sein", "le\u00b7ben", "so", "zu", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "PPOSAT", "VVFIN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Dacht er durch dieses nichts dem gl\u00fccke nachzusp\u00fcren/", "tokens": ["Dacht", "er", "durch", "die\u00b7ses", "nichts", "dem", "gl\u00fc\u00b7cke", "nach\u00b7zu\u00b7sp\u00fc\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "PIS", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Und kam zu einer zeit bey hofe/ voller wahn/", "tokens": ["Und", "kam", "zu", "ei\u00b7ner", "zeit", "bey", "ho\u00b7fe", "/", "vol\u00b7ler", "wahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "APPR", "VVFIN", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Mit einer gantzen last von sch\u00f6nen versen an.", "tokens": ["Mit", "ei\u00b7ner", "gant\u00b7zen", "last", "von", "sch\u00f6\u00b7nen", "ver\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Wie lieff es aber ab? Er kam mit schimpffe wieder/", "tokens": ["Wie", "lieff", "es", "a\u00b7ber", "ab", "?", "Er", "kam", "mit", "schimpf\u00b7fe", "wie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Warff voller schand und spott sich auf das bette nieder/", "tokens": ["Warff", "vol\u00b7ler", "schand", "und", "spott", "sich", "auf", "das", "bet\u00b7te", "nie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "PDS", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Und seuffzte/ bi\u00df zuletzt das fieber und der gram/", "tokens": ["Und", "seuffz\u00b7te", "/", "bi\u00df", "zu\u00b7letzt", "das", "fie\u00b7ber", "und", "der", "gram", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "ADV", "ADV", "ART", "ADJA", "KON", "ART", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Noch eh\u2019 er hungers starb/ ihn von der erde nahm.", "tokens": ["Noch", "eh'", "er", "hun\u00b7gers", "starb", "/", "ihn", "von", "der", "er\u00b7de", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "VVFIN", "$(", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Poeten waren zwar vordem bey hofe mode;", "tokens": ["Po\u00b7et\u00b7en", "wa\u00b7ren", "zwar", "vor\u00b7dem", "bey", "ho\u00b7fe", "mo\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "APPR", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Heut aber schmecken sie der welt nach narren-sode.", "tokens": ["Heut", "a\u00b7ber", "schme\u00b7cken", "sie", "der", "welt", "nach", "nar\u00b7ren\u00b7so\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Schreib einer noch so klug/ und mit der gr\u00f6sten m\u00fch/", "tokens": ["Schreib", "ei\u00b7ner", "noch", "so", "klug", "/", "und", "mit", "der", "gr\u00f6s\u00b7ten", "m\u00fch", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "ADV", "ADJD", "$(", "KON", "APPR", "ART", "ADJA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "So hat er doch nicht mehr das gl\u00fcck des Angeli.", "tokens": ["So", "hat", "er", "doch", "nicht", "mehr", "das", "gl\u00fcck", "des", "An\u00b7ge\u00b7li", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Was soll ich denn nun thun mein elend einst zu enden?", "tokens": ["Was", "soll", "ich", "denn", "nun", "thun", "mein", "e\u00b7lend", "einst", "zu", "en\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "VVFIN", "PPOSAT", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Soll ich vom Helicon zum Bartolus mich wenden?", "tokens": ["Soll", "ich", "vom", "He\u00b7li\u00b7con", "zum", "Bar\u00b7to\u00b7lus", "mich", "wen\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Und Louets buch durchgehn/ das so viel z\u00e4ucker macht?", "tokens": ["Und", "Lou\u00b7ets", "buch", "durch\u00b7gehn", "/", "das", "so", "viel", "z\u00e4u\u00b7cker", "macht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "VVINF", "$(", "PDS", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Wie? oder soll ich gar in einer langen tracht", "tokens": ["Wie", "?", "o\u00b7der", "soll", "ich", "gar", "in", "ei\u00b7ner", "lan\u00b7gen", "tracht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "KON", "VMFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Den advocaten-saal mit meinem rocke kehren?", "tokens": ["Den", "ad\u00b7vo\u00b7ca\u00b7ten\u00b7saal", "mit", "mei\u00b7nem", "ro\u00b7cke", "keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Ach! dieses blosse wort kan meinen muth verzehren.", "tokens": ["Ach", "!", "die\u00b7ses", "blos\u00b7se", "wort", "kan", "mei\u00b7nen", "muth", "ver\u00b7zeh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PDAT", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Ich? solt ein anwald seyn in dieser wilden stadt?", "tokens": ["Ich", "?", "solt", "ein", "an\u00b7wald", "seyn", "in", "die\u00b7ser", "wil\u00b7den", "stadt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "VMFIN", "ART", "ADJD", "VAINF", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Wo die gerechtigkeit l\u00e4ngst ihren abschied hat;", "tokens": ["Wo", "die", "ge\u00b7rech\u00b7tig\u00b7keit", "l\u00e4ngst", "ih\u00b7ren", "ab\u00b7schied", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Die unschuld betteln geht/ und bey so vielen rechten", "tokens": ["Die", "un\u00b7schuld", "bet\u00b7teln", "geht", "/", "und", "bey", "so", "vie\u00b7len", "rech\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$(", "KON", "APPR", "ADV", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Ein ieder mit gewalt das unrecht will verfechten;", "tokens": ["Ein", "ie\u00b7der", "mit", "ge\u00b7walt", "das", "un\u00b7recht", "will", "ver\u00b7fech\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "APPR", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Wo man das schwartze wei\u00df/ wei\u00df schwartz zu machen sinnt;", "tokens": ["Wo", "man", "das", "schwart\u00b7ze", "wei\u00df", "/", "wei\u00df", "schwartz", "zu", "ma\u00b7chen", "sinnt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "ADJA", "VVFIN", "$(", "VVFIN", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Wo Patru weniger als Mazier gewinnt/", "tokens": ["Wo", "Pat\u00b7ru", "we\u00b7ni\u00b7ger", "als", "Ma\u00b7zier", "ge\u00b7winnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "KOUS", "NN", "VVFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.127": {"text": "Und zungen-drescher offt den Cicero besch\u00e4men?", "tokens": ["Und", "zun\u00b7gen\u00b7dre\u00b7scher", "offt", "den", "Ci\u00b7ce\u00b7ro", "be\u00b7sch\u00e4\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Ha! eh\u2019 ein solcher schlu\u00df soll meinen sinn einnehmen/", "tokens": ["Ha", "!", "eh'", "ein", "sol\u00b7cher", "schlu\u00df", "soll", "mei\u00b7nen", "sinn", "ein\u00b7neh\u00b7men", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "KOUS", "ART", "PIAT", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Eh soll auf sanct Johann das wasser ei\u00df und stein/", "tokens": ["Eh", "soll", "auf", "sanct", "Jo\u00b7hann", "das", "was\u00b7ser", "ei\u00df", "und", "stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "VVFIN", "NE", "ART", "ADJA", "NN", "KON", "ADJD", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.130": {"text": "Arnaud ein Huguenot/ Pavin ein heuchler seyn.", "tokens": ["Ar\u00b7naud", "ein", "Hu\u00b7gu\u00b7e\u00b7not", "/", "Pa\u00b7vin", "ein", "heuch\u00b7ler", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$(", "NN", "ART", "ADJA", "VAINF", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.131": {"text": "Wolan! so last uns denn di\u00df freche land verlassen/", "tokens": ["Wo\u00b7lan", "!", "so", "last", "uns", "denn", "di\u00df", "fre\u00b7che", "land", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVFIN", "PPER", "ADV", "PDS", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Wo gl\u00fcck und redligkeit sich unauffh\u00f6rlich hassen:", "tokens": ["Wo", "gl\u00fcck", "und", "red\u00b7lig\u00b7keit", "sich", "un\u00b7auff\u00b7h\u00f6r\u00b7lich", "has\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "VVFIN", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Wo laster/ schand\u2019 und list mit voller macht regiert/", "tokens": ["Wo", "las\u00b7ter", "/", "schand'", "und", "list", "mit", "vol\u00b7ler", "macht", "re\u00b7giert", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$(", "ADJD", "KON", "VVFIN", "APPR", "ADJA", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Die falschheit cron und schwerd/ betrug den scepter f\u00fchrt:", "tokens": ["Die", "falschheit", "cron", "und", "schwerd", "/", "be\u00b7trug", "den", "scep\u00b7ter", "f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADJD", "$(", "VVFIN", "ART", "ADJA", "VVFIN", "$."], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}, "line.135": {"text": "Wo man die wissenschafft verfolget/ dr\u00fccket/ plaget/", "tokens": ["Wo", "man", "die", "wis\u00b7sen\u00b7schafft", "ver\u00b7fol\u00b7get", "/", "dr\u00fc\u00b7cket", "/", "pla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVFIN", "$(", "VVFIN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Und als ein huren-kind von hau\u00df und hoff verjaget:", "tokens": ["Und", "als", "ein", "hu\u00b7ren\u00b7kind", "von", "hau\u00df", "und", "hoff", "ver\u00b7ja\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "NN", "KON", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Wo man auff nichts mehr denckt/ als wie man stehlen will:", "tokens": ["Wo", "man", "auff", "nichts", "mehr", "denckt", "/", "als", "wie", "man", "steh\u00b7len", "will", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "PIS", "ADV", "VVFIN", "$(", "KOUS", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Wo alles mich verdreust: wo \u2012 \u2012 doch ich schweige still.", "tokens": ["Wo", "al\u00b7les", "mich", "ver\u00b7dreust", ":", "wo", "\u2012", "\u2012", "doch", "ich", "schwei\u00b7ge", "still", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "$.", "PWAV", "$(", "$(", "KON", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.139": {"text": "Wer ist nun wohl so kalt/ der ob so groben s\u00fcnden/", "tokens": ["Wer", "ist", "nun", "wohl", "so", "kalt", "/", "der", "ob", "so", "gro\u00b7ben", "s\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$(", "ART", "KOUS", "ADV", "ADJA", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Wenn er sie t\u00e4glich sieht/ nicht solte zorn empfinden?", "tokens": ["Wenn", "er", "sie", "t\u00e4g\u00b7lich", "sieht", "/", "nicht", "sol\u00b7te", "zorn", "emp\u00b7fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVFIN", "$(", "PTKNEG", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Und dem nicht/ wenn er sie mit ernste durch-wil ziehn/", "tokens": ["Und", "dem", "nicht", "/", "wenn", "er", "sie", "mit", "erns\u00b7te", "durch\u00b7wil", "ziehn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "$(", "KOUS", "PPER", "PPER", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.142": {"text": "Auch ohne Ph\u00f6bus krafft die besten reime bl\u00fchn?", "tokens": ["Auch", "oh\u00b7ne", "Ph\u00f6\u00b7bus", "krafft", "die", "bes\u00b7ten", "rei\u00b7me", "bl\u00fchn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "VVFIN", "ART", "ADJA", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Nein/ nein/ so offt man sich hierinnen sucht zu zeigen/", "tokens": ["Nein", "/", "nein", "/", "so", "offt", "man", "sich", "hie\u00b7rin\u00b7nen", "sucht", "zu", "zei\u00b7gen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PTKANT", "$(", "ADV", "ADV", "PIS", "PRF", "PAV", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "So darff man nicht/ wie sonst/ auff den Parnassus steigen:", "tokens": ["So", "darff", "man", "nicht", "/", "wie", "sonst", "/", "auff", "den", "Par\u00b7nas\u00b7sus", "stei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PTKNEG", "$(", "KOKOM", "ADV", "$(", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-++-++-+-", "measure": "unknown.measure.septa"}, "line.145": {"text": "Apollo darff auch nicht erst unser helffer seyn;", "tokens": ["A\u00b7pol\u00b7lo", "darff", "auch", "nicht", "erst", "un\u00b7ser", "helf\u00b7fer", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "PTKNEG", "ADV", "PPOSAT", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Denn was er sagen kan/ giebt schon der eifer ein.", "tokens": ["Denn", "was", "er", "sa\u00b7gen", "kan", "/", "giebt", "schon", "der", "ei\u00b7fer", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$(", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Sieh\u2019 da/ spricht mancher hier/ du f\u00e4ngest an zu rasen.", "tokens": ["Sieh'", "da", "/", "spricht", "man\u00b7cher", "hier", "/", "du", "f\u00e4n\u00b7gest", "an", "zu", "ra\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$(", "VVFIN", "PIS", "ADV", "$(", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.148": {"text": "So hohe redens-art schmeckt nach gelehrten hasen.", "tokens": ["So", "ho\u00b7he", "re\u00b7den\u00b7sart", "schmeckt", "nach", "ge\u00b7lehr\u00b7ten", "ha\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Geh\u2019 auf die cantzel hin/ und j\u00fcckt dich ja das maul/", "tokens": ["Geh'", "auf", "die", "cant\u00b7zel", "hin", "/", "und", "j\u00fcckt", "dich", "ja", "das", "maul", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKVZ", "$(", "KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "So mache da das volck durch deine reden faul.", "tokens": ["So", "ma\u00b7che", "da", "das", "volck", "durch", "dei\u00b7ne", "re\u00b7den", "faul", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Da kanst du was du wilst/ gut oder \u00fcbel sprechen.", "tokens": ["Da", "kanst", "du", "was", "du", "wilst", "/", "gut", "o\u00b7der", "\u00fc\u00b7bel", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PWS", "PPER", "VMFIN", "$(", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "So schwatzt ein blinder narr/ den meine schrifften stechen.", "tokens": ["So", "schwatzt", "ein", "blin\u00b7der", "narr", "/", "den", "mei\u00b7ne", "schriff\u00b7ten", "ste\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Der bey der thorheit sich gantz klug und sicher acht/", "tokens": ["Der", "bey", "der", "thor\u00b7heit", "sich", "gantz", "klug", "und", "si\u00b7cher", "acht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PRF", "ADV", "ADJD", "KON", "ADJD", "CARD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Wenn er fein h\u00f6hnisch nur mein ernstes thun verlacht/", "tokens": ["Wenn", "er", "fein", "h\u00f6h\u00b7nisch", "nur", "mein", "erns\u00b7tes", "thun", "ver\u00b7lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADJD", "ADV", "PPOSAT", "ADJA", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Der bald den himmel pocht/ bald wie die fr\u00f6sche zittert/", "tokens": ["Der", "bald", "den", "him\u00b7mel", "pocht", "/", "bald", "wie", "die", "fr\u00f6\u00b7sche", "zit\u00b7tert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$(", "ADV", "KOKOM", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Der GOtt nicht eher kennt/ bi\u00df er ein fieber wittert/", "tokens": ["Der", "Gott", "nicht", "e\u00b7her", "kennt", "/", "bi\u00df", "er", "ein", "fie\u00b7ber", "wit\u00b7tert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VVFIN", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Und keine hand auffhebt/ als wenn es knallt und blitzt;", "tokens": ["Und", "kei\u00b7ne", "hand", "auff\u00b7hebt", "/", "als", "wenn", "es", "knallt", "und", "blitzt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$(", "KOKOM", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "So bald es aber klar/ schon wieder spotten sitzt.", "tokens": ["So", "bald", "es", "a\u00b7ber", "klar", "/", "schon", "wie\u00b7der", "spot\u00b7ten", "sitzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "ADJD", "$(", "ADV", "ADV", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Denn da\u00df ein solcher mensch alsdenn zu dencken pflege/", "tokens": ["Denn", "da\u00df", "ein", "sol\u00b7cher", "mensch", "als\u00b7denn", "zu", "den\u00b7cken", "pfle\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "PIAT", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Da\u00df GOtt durch seine macht den bau der welt bewege/", "tokens": ["Da\u00df", "Gott", "durch", "sei\u00b7ne", "macht", "den", "bau", "der", "welt", "be\u00b7we\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "VVFIN", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Und da\u00df nach dieser zeit ein ander leben sey/", "tokens": ["Und", "da\u00df", "nach", "die\u00b7ser", "zeit", "ein", "an\u00b7der", "le\u00b7ben", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "PDAT", "NN", "ART", "ADJD", "VVINF", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Wird er zum wenigsten bey seiner pralerey/", "tokens": ["Wird", "er", "zum", "we\u00b7nigs\u00b7ten", "bey", "sei\u00b7ner", "pra\u00b7le\u00b7rey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "PIS", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.163": {"text": "Doch m\u00fcndlich nicht gestehn: ich aber/ der ich gl\u00e4ube/", "tokens": ["Doch", "m\u00fcnd\u00b7lich", "nicht", "ge\u00b7stehn", ":", "ich", "a\u00b7ber", "/", "der", "ich", "gl\u00e4u\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKNEG", "VVPP", "$.", "PPER", "ADV", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Da\u00df keine seele sterb\u2019 und GOtt den donner treibe/", "tokens": ["Da\u00df", "kei\u00b7ne", "see\u00b7le", "sterb'", "und", "Gott", "den", "don\u00b7ner", "trei\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VVFIN", "KON", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Befinde/ da\u00df ich mich von hier entfernen soll.", "tokens": ["Be\u00b7fin\u00b7de", "/", "da\u00df", "ich", "mich", "von", "hier", "ent\u00b7fer\u00b7nen", "soll", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "PPER", "PRF", "APPR", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Wohlan! ich weiche denn. Paris/ gehab dich wohl!", "tokens": ["Wo\u00b7hlan", "!", "ich", "wei\u00b7che", "denn", ".", "Pa\u00b7ris", "/", "ge\u00b7hab", "dich", "wohl", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "ADV", "$.", "NE", "$(", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}