{"textgrid.poem.26464": {"metadata": {"author": {"name": "Whitman, Walt", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr S\u00fcnder auf der Bank vor Gericht!", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr S\u00fcnder auf der Bank vor Gericht!", "tokens": ["Ihr", "S\u00fcn\u00b7der", "auf", "der", "Bank", "vor", "Ge\u00b7richt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ihr Str\u00e4flinge in Zellen,", "tokens": ["Ihr", "Str\u00e4f\u00b7lin\u00b7ge", "in", "Zel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ihr Totschl\u00e4ger in eisernen Fu\u00dfketten", "tokens": ["Ihr", "Tot\u00b7schl\u00e4\u00b7ger", "in", "ei\u00b7ser\u00b7nen", "Fu\u00df\u00b7ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+---+--+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und schweren Handschellen,", "tokens": ["Und", "schwe\u00b7ren", "Hand\u00b7schel\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.5": {"text": "Wer bin ich denn, der ich ", "tokens": ["Wer", "bin", "ich", "denn", ",", "der", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$,", "PRELS", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Nicht im Gef\u00e4ngnis sitze?", "tokens": ["Nicht", "im", "Ge\u00b7f\u00e4ng\u00b7nis", "sit\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ich, so ruchlos und teuflisch wie nur je einer!", "tokens": ["Ich", ",", "so", "ruch\u00b7los", "und", "teuf\u00b7lisch", "wie", "nur", "je", "ei\u00b7ner", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "ADJD", "KON", "ADJD", "KOKOM", "ADV", "ADV", "ART", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.8": {"text": "Warum haben meine Hand- und Fu\u00dfgelenke nicht", "tokens": ["Wa\u00b7rum", "ha\u00b7ben", "mei\u00b7ne", "Han\u00b7d", "und", "Fu\u00df\u00b7ge\u00b7len\u00b7ke", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPOSAT", "TRUNC", "KON", "NN", "PTKNEG"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.9": {"text": "Auch schwere Eisenklammern?", "tokens": ["Auch", "schwe\u00b7re", "Ei\u00b7sen\u00b7klam\u00b7mern", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ihr Dirnen, die ihr vor\u00fcbergeht,", "tokens": ["Ihr", "Dir\u00b7nen", ",", "die", "ihr", "vor\u00b7\u00fc\u00b7ber\u00b7geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Prunkend zwischen den Pr\u00fcden", "tokens": ["Prun\u00b7kend", "zwi\u00b7schen", "den", "Pr\u00fc\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Auf dem B\u00fcrgersteige,", "tokens": ["Auf", "dem", "B\u00fcr\u00b7ger\u00b7stei\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Oder schamlos l\u00fcstern", "tokens": ["O\u00b7der", "scham\u00b7los", "l\u00fcs\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJD", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "In eurer Kammer \u2013", "tokens": ["In", "eu\u00b7rer", "Kam\u00b7mer", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Wer bin ich, da\u00df ich euch schamloser schelte", "tokens": ["Wer", "bin", "ich", ",", "da\u00df", "ich", "euch", "scham\u00b7lo\u00b7ser", "schel\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Als mich selbst?", "tokens": ["Als", "mich", "selbst", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "O schuldig!", "tokens": ["O", "schul\u00b7dig", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "ADJD", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ich bekenne mich, ich entbl\u00f6\u00dfe mich selbst.", "tokens": ["Ich", "be\u00b7ken\u00b7ne", "mich", ",", "ich", "ent\u00b7bl\u00f6\u00b7\u00dfe", "mich", "selbst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "(o Verehrer, verehrt mich nicht, lobt mich nicht,", "tokens": ["(", "o", "Ver\u00b7eh\u00b7rer", ",", "ver\u00b7ehrt", "mich", "nicht", ",", "lobt", "mich", "nicht", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ihr macht mich beben,", "tokens": ["Ihr", "macht", "mich", "be\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Denn ich sehe, was ihr nicht seht \u2013 wei\u00df, was ihr nicht wi\u00dft!)", "tokens": ["Denn", "ich", "se\u00b7he", ",", "was", "ihr", "nicht", "seht", "\u2013", "wei\u00df", ",", "was", "ihr", "nicht", "wi\u00dft", "!", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWS", "PPER", "PTKNEG", "VVFIN", "$(", "VVFIN", "$,", "PWS", "PPER", "PTKNEG", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.5": {"line.1": {"text": "Hinter meinem Brustkorb ersticke ich vor unreiner Lust,", "tokens": ["Hin\u00b7ter", "mei\u00b7nem", "Brust\u00b7korb", "er\u00b7sti\u00b7cke", "ich", "vor", "un\u00b7rei\u00b7ner", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+-+--+", "measure": "trochaic.septa.relaxed"}}, "stanza.6": {"line.1": {"text": "Hinter meinem Antlitz, das so unbewegt scheint,", "tokens": ["Hin\u00b7ter", "mei\u00b7nem", "Ant\u00b7litz", ",", "das", "so", "un\u00b7be\u00b7wegt", "scheint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.2": {"text": "Flie\u00dfen der H\u00f6lle Feuerfluten friedlos!", "tokens": ["Flie\u00b7\u00dfen", "der", "H\u00f6l\u00b7le", "Feu\u00b7er\u00b7flu\u00b7ten", "fried\u00b7los", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "ADJD", "$."], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.3": {"text": "L\u00fcsten und Lastern bin ich zug\u00e4nglich,", "tokens": ["L\u00fcs\u00b7ten", "und", "Las\u00b7tern", "bin", "ich", "zu\u00b7g\u00e4ng\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Ich verkehre mit den Misset\u00e4tern leidenschaftlich gern!", "tokens": ["Ich", "ver\u00b7keh\u00b7re", "mit", "den", "Mis\u00b7se\u00b7t\u00e4\u00b7tern", "lei\u00b7den\u00b7schaft\u00b7lich", "gern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADJD", "ADV", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.8": {"line.1": {"text": "Ich f\u00fchle, da\u00df ich ihresgleichen bin,", "tokens": ["Ich", "f\u00fch\u00b7le", ",", "da\u00df", "ich", "ih\u00b7res\u00b7glei\u00b7chen", "bin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich geh\u00f6re zu diesen Str\u00e4flingen und Ausgesto\u00dfenen,", "tokens": ["Ich", "ge\u00b7h\u00f6\u00b7re", "zu", "die\u00b7sen", "Str\u00e4f\u00b7lin\u00b7gen", "und", "Aus\u00b7ge\u00b7sto\u00b7\u00dfe\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "KON", "NN", "$,"], "meter": "--+--+--+--+-+--", "measure": "anapaest.tetra.plus"}, "line.3": {"text": "Fortan will ich sie nicht verleugnen,", "tokens": ["For\u00b7tan", "will", "ich", "sie", "nicht", "ver\u00b7leug\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn wie kann ich mich selbst verleugnen?", "tokens": ["Denn", "wie", "kann", "ich", "mich", "selbst", "ver\u00b7leug\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}