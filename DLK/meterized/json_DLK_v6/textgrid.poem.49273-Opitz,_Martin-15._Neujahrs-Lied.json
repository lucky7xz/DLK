{"textgrid.poem.49273": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "15. Neujahrs-Lied", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Jahr ist fortgelauffen", "tokens": ["Das", "Jahr", "ist", "fort\u00b7ge\u00b7lauf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hat seiner Tage Hauffen", "tokens": ["Hat", "sei\u00b7ner", "Ta\u00b7ge", "Hauf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das letzte Ziel gemacht;", "tokens": ["Das", "letz\u00b7te", "Ziel", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Was haben wir indessen", "tokens": ["Was", "ha\u00b7ben", "wir", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr Missethat vergessen,", "tokens": ["F\u00fcr", "Mis\u00b7se\u00b7that", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "F\u00fcr gutes Werck vollbracht?", "tokens": ["F\u00fcr", "gu\u00b7tes", "Werck", "voll\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Gro\u00df ist die Zahl der Stunden,", "tokens": ["Gro\u00df", "ist", "die", "Zahl", "der", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch wird sie \u00fcberwunden", "tokens": ["Noch", "wird", "sie", "\u00fc\u00b7berw\u00b7un\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Rechnung unsrer Schuld:", "tokens": ["Von", "Rech\u00b7nung", "uns\u00b7rer", "Schuld", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch, Christe, dein Gem\u00fcthe", "tokens": ["Doch", ",", "Chris\u00b7te", ",", "dein", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ADJA", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Reicht weiter zu an G\u00fcte,", "tokens": ["Reicht", "wei\u00b7ter", "zu", "an", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKZU", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "An Langmuth und Gedult.", "tokens": ["An", "Lang\u00b7muth", "und", "Ge\u00b7dult", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Was deiner Herde Sachen", "tokens": ["Was", "dei\u00b7ner", "Her\u00b7de", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nicht wissen gut zu machen,", "tokens": ["Nicht", "wis\u00b7sen", "gut", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zahlt deine Liebesbrunst.", "tokens": ["Zahlt", "dei\u00b7ne", "Lie\u00b7bes\u00b7brunst", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ach! la\u00df auch k\u00fcnfftig schauen,", "tokens": ["Ach", "!", "la\u00df", "auch", "k\u00fcnff\u00b7tig", "schau\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVIMP", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie billich, da\u00df wir bauen", "tokens": ["Wie", "bil\u00b7lich", ",", "da\u00df", "wir", "bau\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Auff solche treue Gunst.", "tokens": ["Auff", "sol\u00b7che", "treu\u00b7e", "Gunst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Es sey ein mal ein Ende", "tokens": ["Es", "sey", "ein", "mal", "ein", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dem Kriege, der die H\u00e4nde", "tokens": ["Dem", "Krie\u00b7ge", ",", "der", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sehr tieff hat eingesetzt;", "tokens": ["Sehr", "tieff", "hat", "ein\u00b7ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wir m\u00fcssen bald erliegen,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "bald", "er\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Woferren durch dein Siegen", "tokens": ["Wo\u00b7fer\u00b7ren", "durch", "dein", "Sie\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das Leyd nicht wird ersetzt.", "tokens": ["Das", "Leyd", "nicht", "wird", "er\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Nun, Herr, du wirst dich regen", "tokens": ["Nun", ",", "Herr", ",", "du", "wirst", "dich", "re\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "PPER", "VAFIN", "PPER", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit einem neuen Segen,", "tokens": ["Mit", "ei\u00b7nem", "neu\u00b7en", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auff dieses neue Jahr;", "tokens": ["Auff", "die\u00b7ses", "neu\u00b7e", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Gieb, also nur zu leben,", "tokens": ["Gieb", ",", "al\u00b7so", "nur", "zu", "le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df wir dir Anla\u00df geben", "tokens": ["Da\u00df", "wir", "dir", "An\u00b7la\u00df", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Zu retten deine Schar.", "tokens": ["Zu", "ret\u00b7ten", "dei\u00b7ne", "Schar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}