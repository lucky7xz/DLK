{"dta.poem.9161": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  \n Auf einen einf\u00e4ltigen G\u00fcmpel.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Mein sch\u00e4tzgen ist ein flegel/", "tokens": ["Mein", "sch\u00e4tz\u00b7gen", "ist", "ein", "fle\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er stolpert \u00fcbern schlegel", "tokens": ["Er", "stol\u00b7pert", "\u00fc\u00b7bern", "schle\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So offt er zu mir geht/", "tokens": ["So", "offt", "er", "zu", "mir", "geht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und zeigt mit seinen sparren/", "tokens": ["Und", "zeigt", "mit", "sei\u00b7nen", "spar\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df er vor einen narren", "tokens": ["Da\u00df", "er", "vor", "ei\u00b7nen", "nar\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Bey aller welt besteht.", "tokens": ["Bey", "al\u00b7ler", "welt", "be\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Er treibt so lahme possen/", "tokens": ["Er", "treibt", "so", "lah\u00b7me", "pos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als w\u00e4r er recht geschossen", "tokens": ["Als", "w\u00e4r", "er", "recht", "ge\u00b7schos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit groben hasen-schrot:", "tokens": ["Mit", "gro\u00b7ben", "ha\u00b7sen\u00b7schrot", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Drum wer sich mu\u00df beqvemen/", "tokens": ["Drum", "wer", "sich", "mu\u00df", "be\u00b7qve\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PWS", "PRF", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ihn zur seite nehmen/", "tokens": ["Und", "ihn", "zur", "sei\u00b7te", "neh\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Der hat die h\u00e4rtste noth.", "tokens": ["Der", "hat", "die", "h\u00e4rts\u00b7te", "noth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. Ach wann die complimenten", "tokens": ["Ach", "wann", "die", "com\u00b7pli\u00b7men\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ITJ", "PWAV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie pech und schwefel brennten/", "tokens": ["Wie", "pech", "und", "schwe\u00b7fel", "brenn\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So wers um uns geschehn:", "tokens": ["So", "wers", "um", "uns", "ge\u00b7schehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wir h\u00e4tten unsre gassen/", "tokens": ["Wir", "h\u00e4t\u00b7ten", "uns\u00b7re", "gas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da wir uns niederlassen/", "tokens": ["Da", "wir", "uns", "nie\u00b7der\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Schon in der gluth gesehn.", "tokens": ["Schon", "in", "der", "gluth", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "4. Bald seh ich ihm zusauer/", "tokens": ["Bald", "seh", "ich", "ihm", "zu\u00b7sau\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bald hei\u00df ich gar ein bauer/", "tokens": ["Bald", "hei\u00df", "ich", "gar", "ein", "bau\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bald hat er sonsten was:", "tokens": ["Bald", "hat", "er", "sons\u00b7ten", "was", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Es mangelt nicht ein dreyer/", "tokens": ["Es", "man\u00b7gelt", "nicht", "ein", "drey\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So heist der albre freyer", "tokens": ["So", "heist", "der", "alb\u00b7re", "frey\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Mich gar ein raben-aa\u00df.", "tokens": ["Mich", "gar", "ein", "ra\u00b7ben\u00b7aa\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "5. Und doch der gute kerle", "tokens": ["Und", "doch", "der", "gu\u00b7te", "ker\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sieht selbst wie eine perle", "tokens": ["Sieht", "selbst", "wie", "ei\u00b7ne", "per\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "KOKOM", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die auff dem miste liegt/", "tokens": ["Die", "auff", "dem", "mis\u00b7te", "liegt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und ist so tr\u00fcb und dunckel", "tokens": ["Und", "ist", "so", "tr\u00fcb", "und", "dun\u00b7ckel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Als wie ein schwartz carfunckel", "tokens": ["Als", "wie", "ein", "schwartz", "car\u00b7fun\u00b7ckel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Den man im ofen kriegt.", "tokens": ["Den", "man", "im", "o\u00b7fen", "kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "6. Bey meiner treu ich wette", "tokens": ["Bey", "mei\u00b7ner", "treu", "ich", "wet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er hat im hasen fette", "tokens": ["Er", "hat", "im", "ha\u00b7sen", "fet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bi\u00df \u00fcbers knie gesteckt/", "tokens": ["Bi\u00df", "\u00fc\u00b7bers", "knie", "ge\u00b7steckt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Nun ist kein hund im lande", "tokens": ["Nun", "ist", "kein", "hund", "im", "lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der ihm die grosse schande", "tokens": ["Der", "ihm", "die", "gros\u00b7se", "schan\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Von seinen str\u00fcmpffen leckt.", "tokens": ["Von", "sei\u00b7nen", "str\u00fcmpf\u00b7fen", "leckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "7. Die grossen hasen-ohren", "tokens": ["Die", "gros\u00b7sen", "ha\u00b7sen\u00b7oh\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die sind ihm angebohren;", "tokens": ["Die", "sind", "ihm", "an\u00b7ge\u00b7boh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jedoch der schiefer nicht/", "tokens": ["Je\u00b7doch", "der", "schie\u00b7fer", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "PTKNEG", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der hat ihn erst gestochen/", "tokens": ["Der", "hat", "ihn", "erst", "ge\u00b7sto\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Als man vor wenig wochen", "tokens": ["Als", "man", "vor", "we\u00b7nig", "wo\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das kirch dach angericht.", "tokens": ["Das", "kirch", "dach", "an\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "8. Das ausserlesne sch\u00e4tzgen", "tokens": ["Das", "aus\u00b7ser\u00b7les\u00b7ne", "sch\u00e4tz\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Begehrt wol gar ein schm\u00e4tzgen/", "tokens": ["Be\u00b7gehrt", "wol", "gar", "ein", "schm\u00e4tz\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und bitt mich noch so sehr:", "tokens": ["Und", "bitt", "mich", "noch", "so", "sehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ja/ ja ihr armer teuffel/", "tokens": ["Ja", "/", "ja", "ihr", "ar\u00b7mer", "teuf\u00b7fel", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Daran ist gar kein zweiffel/", "tokens": ["Da\u00b7ran", "ist", "gar", "kein", "zweif\u00b7fel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "PIAT", "NN", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "H\u00f6rt morgen wieder her.", "tokens": ["H\u00f6rt", "mor\u00b7gen", "wie\u00b7der", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "9. Ach ihr verliebter hase", "tokens": ["Ach", "ihr", "ver\u00b7lieb\u00b7ter", "ha\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ITJ", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jhr stosst euch an die nase/", "tokens": ["Ihr", "stosst", "euch", "an", "die", "na\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "K\u00fcsst mir das angesicht", "tokens": ["K\u00fcsst", "mir", "das", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da mir die nase mangelt/", "tokens": ["Da", "mir", "die", "na\u00b7se", "man\u00b7gelt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So habt ihr recht geangelt/", "tokens": ["So", "habt", "ihr", "recht", "ge\u00b7an\u00b7gelt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und ihr verbrennt euch nicht.", "tokens": ["Und", "ihr", "ver\u00b7brennt", "euch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "10. Ach Hans spann an/ und f\u00fchre", "tokens": ["Ach", "Hans", "spann", "an", "/", "und", "f\u00fch\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "NE", "VVFIN", "PTKVZ", "$(", "KON", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den esel vor die th\u00fcre/", "tokens": ["Den", "e\u00b7sel", "vor", "die", "th\u00fc\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das haus ist viel zu gut:", "tokens": ["Das", "haus", "ist", "viel", "zu", "gut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Er wird auff dieser erden", "tokens": ["Er", "wird", "auff", "die\u00b7ser", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nun wohl nicht anders werden/", "tokens": ["Nun", "wohl", "nicht", "an\u00b7ders", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "VAINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Er bleibt ein \u2012 \u2012 \u2012 \u2012 \u2012 \u2012", "tokens": ["Er", "bleibt", "ein", "\u2012", "\u2012", "\u2012", "\u2012", "\u2012", "\u2012"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "$(", "$(", "$(", "$(", "$(", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "11. Wiewol er mag es bleiben/", "tokens": ["Wie\u00b7wol", "er", "mag", "es", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und seine zeit vertreiben/", "tokens": ["Und", "sei\u00b7ne", "zeit", "ver\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie wo und wenn er wil:", "tokens": ["Wie", "wo", "und", "wenn", "er", "wil", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PWAV", "KON", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Jedoch da\u00df ich die plagen", "tokens": ["Je\u00b7doch", "da\u00df", "ich", "die", "pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Fast st\u00fcndlich mu\u00df ertragen/", "tokens": ["Fast", "st\u00fcnd\u00b7lich", "mu\u00df", "er\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das ist f\u00fcr mich zu viel.", "tokens": ["Das", "ist", "f\u00fcr", "mich", "zu", "viel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "PTKA", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "12. Steckt ihm den kopff voll h\u00f6rner", "tokens": ["Steckt", "ihm", "den", "kopff", "voll", "h\u00f6r\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Reibt ihm den stei\u00df voll d\u00f6rner/", "tokens": ["Reibt", "ihm", "den", "stei\u00df", "voll", "d\u00f6r\u00b7ner", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "VVFIN", "ADJD", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das maul voll theriack:", "tokens": ["Das", "maul", "voll", "the\u00b7riack", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Schickt ihn mit solchem kleister", "tokens": ["Schickt", "ihn", "mit", "sol\u00b7chem", "kleis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der narren obermeister", "tokens": ["Der", "nar\u00b7ren", "o\u00b7ber\u00b7meis\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Zum gr\u00fcnen donnerstag.", "tokens": ["Zum", "gr\u00fc\u00b7nen", "don\u00b7ners\u00b7tag", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}