{"dta.poem.19748": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Gedankenstille .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "V\u00f6gel thut euch nicht verweilen,               ", "tokens": ["V\u00f6\u00b7gel", "thut", "euch", "nicht", "ver\u00b7wei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommet, eilet schnell herzu,", "tokens": ["Kom\u00b7met", ",", "ei\u00b7let", "schnell", "her\u00b7zu", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00f6lfe h\u00f6ret auf zu heulen,", "tokens": ["W\u00f6l\u00b7fe", "h\u00f6\u00b7ret", "auf", "zu", "heu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn ihr st\u00f6ret meine Ruh.", "tokens": ["Denn", "ihr", "st\u00f6\u00b7ret", "mei\u00b7ne", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "G\u00f6tter kommt und helft mir klagen,", "tokens": ["G\u00f6t\u00b7ter", "kommt", "und", "helft", "mir", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihr sollt alle Zeugen seyn,", "tokens": ["Ihr", "sollt", "al\u00b7le", "Zeu\u00b7gen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VAINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "D\u00fcrft ich es den L\u00fcften sagen", "tokens": ["D\u00fcrft", "ich", "es", "den", "L\u00fcf\u00b7ten", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und entdecken meine Pein.", "tokens": ["Und", "ent\u00b7de\u00b7cken", "mei\u00b7ne", "Pein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wehet nur ihr sanften Winde,", "tokens": ["We\u00b7het", "nur", "ihr", "sanf\u00b7ten", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "B\u00e4chlein rauschet nicht so sehr,", "tokens": ["B\u00e4ch\u00b7lein", "rau\u00b7schet", "nicht", "so", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fliest und wehet jetzt gelinde", "tokens": ["Fliest", "und", "we\u00b7het", "jetzt", "ge\u00b7lin\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "ADV", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gebt doch meinem Lied Geh\u00f6r.", "tokens": ["Gebt", "doch", "mei\u00b7nem", "Lied", "Ge\u00b7h\u00f6r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Aest und Zweige thut nicht wanken,", "tokens": ["A\u00b7est", "und", "Zwei\u00b7ge", "thut", "nicht", "wan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "B\u00e4um und Bl\u00e4tter haltet still,", "tokens": ["B\u00e4um", "und", "Bl\u00e4t\u00b7ter", "hal\u00b7tet", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ich jetzo in Gedanken,", "tokens": ["Weil", "ich", "jet\u00b7zo", "in", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Euch mein Lied entdecken will.", "tokens": ["Euch", "mein", "Lied", "ent\u00b7de\u00b7cken", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}