{"dta.poem.4165": {"metadata": {"author": {"name": "M\u00fcller, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Wir wissen uns zu finden.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1821", "urn": "urn:nbn:de:kobv:b4-200905194209", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Schwester, trockne deine Z\u00e4hren!", "tokens": ["Schwes\u00b7ter", ",", "trock\u00b7ne", "dei\u00b7ne", "Z\u00e4h\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hin ist hin, und todt ist todt.", "tokens": ["Hin", "ist", "hin", ",", "und", "todt", "ist", "todt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "$,", "KON", "ADJD", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts bei uns kann ewig w\u00e4hren,", "tokens": ["Nichts", "bei", "uns", "kann", "e\u00b7wig", "w\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PPER", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heute bleich, was gestern roth.", "tokens": ["Heu\u00b7te", "bleich", ",", "was", "ge\u00b7stern", "roth", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PRELS", "ADV", "ADJD", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Eins auch wolle noch bedenken:", "tokens": ["Eins", "auch", "wol\u00b7le", "noch", "be\u00b7den\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VMFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ungl\u00fcck kann zum Gl\u00fcck sich lenken,", "tokens": ["Un\u00b7gl\u00fcck", "kann", "zum", "Gl\u00fcck", "sich", "len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Einen Bessern kannst du frein.", "tokens": ["Ei\u00b7nen", "Bes\u00b7sern", "kannst", "du", "frein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Reiche Wittwen sterben selten:", "tokens": ["Rei\u00b7che", "Witt\u00b7wen", "ster\u00b7ben", "sel\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Darum, Schwester, gieb dich drein,", "tokens": ["Da\u00b7rum", ",", "Schwes\u00b7ter", ",", "gieb", "dich", "drein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "NN", "$,", "VVIMP", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}