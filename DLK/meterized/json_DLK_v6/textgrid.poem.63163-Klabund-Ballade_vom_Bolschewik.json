{"textgrid.poem.63163": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Ballade vom Bolschewik", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir kamen in die St\u00e4dte aus der Steppe", "tokens": ["Wir", "ka\u00b7men", "in", "die", "St\u00e4d\u00b7te", "aus", "der", "Step\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gleich W\u00f6lfen mager, hungrig und verlaust.", "tokens": ["Gleich", "W\u00f6l\u00b7fen", "ma\u00b7ger", ",", "hung\u00b7rig", "und", "ver\u00b7laust", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJD", "$,", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie seidig rauscht der sch\u00f6nen Damen Schleppe,", "tokens": ["Wie", "sei\u00b7dig", "rauscht", "der", "sch\u00f6\u00b7nen", "Da\u00b7men", "Schlep\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Um die der S\u00fcdwind unsrer Sehnsucht braust.", "tokens": ["Um", "die", "der", "S\u00fcd\u00b7wind", "uns\u00b7rer", "Sehn\u00b7sucht", "braust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wir hatten harte Erde zu beackern,", "tokens": ["Wir", "hat\u00b7ten", "har\u00b7te", "Er\u00b7de", "zu", "be\u00b7ac\u00b7kern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der arme Vater und der \u00e4rmre Sohn.", "tokens": ["Der", "ar\u00b7me", "Va\u00b7ter", "und", "der", "\u00e4rm\u00b7re", "Sohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir h\u00f6rten fr\u00fch um f\u00fcnf die H\u00fchner gackern,", "tokens": ["Wir", "h\u00f6r\u00b7ten", "fr\u00fch", "um", "f\u00fcnf", "die", "H\u00fch\u00b7ner", "ga\u00b7ckern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "CARD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und bis um zehn Uhr abends nichts als Fron.", "tokens": ["Und", "bis", "um", "zehn", "Uhr", "a\u00b7bends", "nichts", "als", "Fron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "CARD", "NN", "ADV", "PIS", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Des Mittags gab es eine d\u00fcnne Suppe,", "tokens": ["Des", "Mit\u00b7tags", "gab", "es", "ei\u00b7ne", "d\u00fcn\u00b7ne", "Sup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Am Sonntag schwamm ein Klumpen Fleisch darin.", "tokens": ["Am", "Sonn\u00b7tag", "schwamm", "ein", "Klum\u00b7pen", "Fleisch", "da\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "NN", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auf der Waldai s\u00fcss bestrahlter Kuppe", "tokens": ["Auf", "der", "Wal\u00b7dai", "s\u00fcss", "be\u00b7strahl\u00b7ter", "Kup\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Sass thronend unsrer Herzen Herzogin.", "tokens": ["Sass", "thro\u00b7nend", "uns\u00b7rer", "Her\u00b7zen", "Her\u00b7zo\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wir dachten ohne Kopf: nur kahle St\u00fcmpfe,", "tokens": ["Wir", "dach\u00b7ten", "oh\u00b7ne", "Kopf", ":", "nur", "kah\u00b7le", "St\u00fcmp\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$.", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wenn wir tanzten, tanzte nur das Bein.", "tokens": ["Und", "wenn", "wir", "tanz\u00b7ten", ",", "tanz\u00b7te", "nur", "das", "Bein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die braune Tiefe der Rokitnos\u00fcmpfe", "tokens": ["Die", "brau\u00b7ne", "Tie\u00b7fe", "der", "Ro\u00b7kit\u00b7no\u00b7s\u00fcmp\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gebar der Kr\u00f6te leise Litanein.", "tokens": ["Ge\u00b7bar", "der", "Kr\u00f6\u00b7te", "lei\u00b7se", "Li\u00b7tan\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Zuweilen, von der Sonne \u00fcberspiegelt,", "tokens": ["Zu\u00b7wei\u00b7len", ",", "von", "der", "Son\u00b7ne", "\u00fc\u00b7bers\u00b7pie\u00b7gelt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sank eine tr\u00e4ge Frau mit uns in Gott.", "tokens": ["Sank", "ei\u00b7ne", "tr\u00e4\u00b7ge", "Frau", "mit", "uns", "in", "Gott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann flogen wir f\u00fcr einen Tag befl\u00fcgelt", "tokens": ["Dann", "flo\u00b7gen", "wir", "f\u00fcr", "ei\u00b7nen", "Tag", "be\u00b7fl\u00fc\u00b7gelt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zum Fr\u00fchlingsfest nach Nischni-Nowgorod.", "tokens": ["Zum", "Fr\u00fch\u00b7lings\u00b7fest", "nach", "Nischni\u00b7Now\u00b7go\u00b7rod", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Wir t\u00f6teten, doch sanft und nicht geh\u00e4ssig.", "tokens": ["Wir", "t\u00f6\u00b7te\u00b7ten", ",", "doch", "sanft", "und", "nicht", "ge\u00b7h\u00e4s\u00b7sig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADJD", "KON", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir soffen literweise Schnaps und Bier.", "tokens": ["Wir", "sof\u00b7fen", "li\u00b7ter\u00b7wei\u00b7se", "Schnaps", "und", "Bier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man schlug uns lachend. Und wir lasen l\u00e4ssig", "tokens": ["Man", "schlug", "uns", "la\u00b7chend", ".", "Und", "wir", "la\u00b7sen", "l\u00e4s\u00b7sig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "$.", "KON", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Popen zart zerlesenes Brevier.", "tokens": ["Des", "Po\u00b7pen", "zart", "zer\u00b7le\u00b7se\u00b7nes", "Bre\u00b7vier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Wir aus den Tiefen sind nun hochgekommen,", "tokens": ["Wir", "aus", "den", "Tie\u00b7fen", "sind", "nun", "hoch\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir armen Armen wurden endlich reich.", "tokens": ["Wir", "ar\u00b7men", "Ar\u00b7men", "wur\u00b7den", "end\u00b7lich", "reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In unsrer D\u00e4mmrung ist ein Licht erglommen,", "tokens": ["In", "uns\u00b7rer", "D\u00e4mm\u00b7rung", "ist", "ein", "Licht", "er\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Heiligenschein begl\u00e4nzt die Stirnen bleich.", "tokens": ["Ein", "Hei\u00b7li\u00b7gen\u00b7schein", "be\u00b7gl\u00e4nzt", "die", "Stir\u00b7nen", "bleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Wie auf.der Kirmes in die Luft geschaukelt", "tokens": ["Wie", "auf", ".", "der", "Kir\u00b7mes", "in", "die", "Luft", "ge\u00b7schau\u00b7kelt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PTKVZ", "$.", "ART", "NN", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist unser Schicksal jetzt. Nun pr\u00fcgeln wir,", "tokens": ["Ist", "un\u00b7ser", "Schick\u00b7sal", "jetzt", ".", "Nun", "pr\u00fc\u00b7geln", "wir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "$.", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Von Schmetterling und Nachtigall umgaukelt,", "tokens": ["Von", "Schmet\u00b7ter\u00b7ling", "und", "Nach\u00b7ti\u00b7gall", "um\u00b7gau\u00b7kelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Kaiserpferd und -hure z\u00fcgeln wir.", "tokens": ["Und", "Kai\u00b7ser\u00b7pferd", "und", "z\u00fc\u00b7geln", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Nun darf er fressen, br\u00fcllen, saufen, huren,", "tokens": ["Nun", "darf", "er", "fres\u00b7sen", ",", "br\u00fcl\u00b7len", ",", "sau\u00b7fen", ",", "hu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie Zar und K\u00f6nig einst: der Bolschewik.", "tokens": ["Wie", "Zar", "und", "K\u00f6\u00b7nig", "einst", ":", "der", "Bol\u00b7sche\u00b7wik", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die blutend in das Fegefeuer fuhren:", "tokens": ["Die", "blu\u00b7tend", "in", "das", "Fe\u00b7ge\u00b7feu\u00b7er", "fuh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie liessen ihm ihr diamantnes Gl\u00fcck.", "tokens": ["Sie", "lies\u00b7sen", "ihm", "ihr", "di\u00b7a\u00b7mant\u00b7nes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Es jagt mit seinem Weib in der Karosse", "tokens": ["Es", "jagt", "mit", "sei\u00b7nem", "Weib", "in", "der", "Ka\u00b7ros\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Kommiss\u00e4r, um den der Weihrauch dampft.", "tokens": ["Der", "Kom\u00b7mis\u00b7s\u00e4r", ",", "um", "den", "der", "Weih\u00b7rauch", "dampft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUI", "ART", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Entrechtet w\u00e4lzt sich in der grauen Gosse", "tokens": ["Ent\u00b7rech\u00b7tet", "w\u00e4lzt", "sich", "in", "der", "grau\u00b7en", "Gos\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Bourgeois, geknechtet und zerstampft.", "tokens": ["Der", "Bour\u00b7ge\u00b7ois", ",", "ge\u00b7knech\u00b7tet", "und", "zer\u00b7stampft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Die Prinzen winselten im Kirchenchore,", "tokens": ["Die", "Prin\u00b7zen", "win\u00b7sel\u00b7ten", "im", "Kir\u00b7chen\u00b7cho\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Des Hofes Damen schleifte man am Haar.", "tokens": ["Des", "Ho\u00b7fes", "Da\u00b7men", "schleif\u00b7te", "man", "am", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PIS", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Thron zerborst. Auf der Palastempore", "tokens": ["Der", "Thron", "zer\u00b7borst", ".", "Auf", "der", "Pa\u00b7las\u00b7tem\u00b7po\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Steht mager, bleich und klein der rote Zar!", "tokens": ["Steht", "ma\u00b7ger", ",", "bleich", "und", "klein", "der", "ro\u00b7te", "Zar", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ihr alle Br\u00fcder einer dumpfen Rasse,", "tokens": ["Ihr", "al\u00b7le", "Br\u00fc\u00b7der", "ei\u00b7ner", "dum\u00b7pfen", "Ras\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihr Untersten aus Nacht empor zur Macht!", "tokens": ["Ihr", "Un\u00b7ters\u00b7ten", "aus", "Nacht", "em\u00b7por", "zur", "Macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Noch nicht genug vom wilden Klassenhasse", "tokens": ["Noch", "nicht", "ge\u00b7nug", "vom", "wil\u00b7den", "Klas\u00b7sen\u00b7has\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist in den dunklen Seelen euch entfacht!", "tokens": ["Ist", "in", "den", "dunk\u00b7len", "See\u00b7len", "euch", "ent\u00b7facht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Eh nicht die letzten an den Galgen h\u00e4ngen,", "tokens": ["Eh", "nicht", "die", "letz\u00b7ten", "an", "den", "Gal\u00b7gen", "h\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "ADJA", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die euer Blut in M\u00fcnze umgepr\u00e4gt,", "tokens": ["Die", "eu\u00b7er", "Blut", "in", "M\u00fcn\u00b7ze", "um\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Eh nicht der Freiheit Adler in den F\u00e4ngen", "tokens": ["Eh", "nicht", "der", "Frei\u00b7heit", "Ad\u00b7ler", "in", "den", "F\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "ART", "NN", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der alten Knechtschaft Pestkadaver tr\u00e4gt,", "tokens": ["Der", "al\u00b7ten", "Knecht\u00b7schaft", "Pest\u00b7ka\u00b7da\u00b7ver", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Eh wird nicht Friede werden hier auf Erden.", "tokens": ["Eh", "wird", "nicht", "Frie\u00b7de", "wer\u00b7den", "hier", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "NN", "VAFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Stern ergl\u00e4nzt. Es spricht der neue Christ! \u2013", "tokens": ["Ein", "Stern", "er\u00b7gl\u00e4nzt", ".", "Es", "spricht", "der", "neu\u00b7e", "Christ", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Echo wie von Polizistenpferden,", "tokens": ["Ein", "E\u00b7cho", "wie", "von", "Po\u00b7li\u00b7zis\u00b7ten\u00b7pfer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und jauchzend bricht ins Knie der Rotgardist.", "tokens": ["Und", "jauch\u00b7zend", "bricht", "ins", "Knie", "der", "Rot\u00b7gar\u00b7dist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}