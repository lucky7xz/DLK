{"textgrid.poem.41383": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Die B\u00e4renhaut", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zween Helden, die der Douze-Strand", "tokens": ["Zween", "Hel\u00b7den", ",", "die", "der", "Dou\u00b7ze\u00b7Strand"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Jugend auf, in fr\u00fchen Wechselch\u00f6ren,", "tokens": ["Von", "Ju\u00b7gend", "auf", ",", "in", "fr\u00fc\u00b7hen", "Wech\u00b7selc\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nach tapfern Fl\u00fcchen singen h\u00f6ren,", "tokens": ["Nach", "tap\u00b7fern", "Fl\u00fc\u00b7chen", "sin\u00b7gen", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verlie\u00dfen, um die Zahl der Reisenden zu mehren,", "tokens": ["Ver\u00b7lie\u00b7\u00dfen", ",", "um", "die", "Zahl", "der", "Rei\u00b7sen\u00b7den", "zu", "meh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUI", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr liederreiches Vaterland.", "tokens": ["Ihr", "lie\u00b7der\u00b7rei\u00b7ches", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Mehr Lust, als F\u00e4higkeit zu ungemeinen Werken,", "tokens": ["Mehr", "Lust", ",", "als", "F\u00e4\u00b7hig\u00b7keit", "zu", "un\u00b7ge\u00b7mei\u00b7nen", "Wer\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Noth und etwas Eigensinn", "tokens": ["Die", "Noth", "und", "et\u00b7was", "Ei\u00b7gen\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Trieb sie zuletzt nach Polen hin,", "tokens": ["Trieb", "sie", "zu\u00b7letzt", "nach", "Po\u00b7len", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "NE", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Die Mi\u00dfvergn\u00fcgten zu verst\u00e4rken.", "tokens": ["Die", "Mi\u00df\u00b7ver\u00b7gn\u00fcg\u00b7ten", "zu", "ver\u00b7st\u00e4r\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Gesang und Gold und Muth nahm bald und merklich ab,", "tokens": ["Ge\u00b7sang", "und", "Gold", "und", "Muth", "nahm", "bald", "und", "merk\u00b7lich", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "VVFIN", "ADV", "KON", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als diesen sonst galanten Leuten", "tokens": ["Als", "die\u00b7sen", "sonst", "ga\u00b7lan\u00b7ten", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein K\u00fcrschner Tisch und Stube gab;", "tokens": ["Ein", "K\u00fcrschner", "Tisch", "und", "Stu\u00b7be", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vielleicht aus Hoffnung bess'rer Zeiten.", "tokens": ["Viel\u00b7leicht", "aus", "Hoff\u00b7nung", "bess'\u00b7rer", "Zei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Zu diesem sagten sie: Ein gro\u00dfer W\u00fctherich,", "tokens": ["Zu", "die\u00b7sem", "sag\u00b7ten", "sie", ":", "Ein", "gro\u00b7\u00dfer", "W\u00fct\u00b7he\u00b7rich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein ungeheurer B\u00e4r l\u00e4\u00dft sich im Walde sehen;", "tokens": ["Ein", "un\u00b7ge\u00b7heu\u00b7rer", "B\u00e4r", "l\u00e4\u00dft", "sich", "im", "Wal\u00b7de", "se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Euch soll, an Zahlungsstatt, die Haut zu Dienste stehen.", "tokens": ["Euch", "soll", ",", "an", "Zah\u00b7lungs\u00b7statt", ",", "die", "Haut", "zu", "Diens\u00b7te", "ste\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Herr Wirth! das Fell ist sch\u00f6n, der Anschlag ritterlich.", "tokens": ["Herr", "Wirth", "!", "das", "Fell", "ist", "sch\u00f6n", ",", "der", "An\u00b7schlag", "rit\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir s\u00e4hen auch nicht gern, um unsers Landes Ehre,", "tokens": ["Wir", "s\u00e4\u00b7hen", "auch", "nicht", "gern", ",", "um", "un\u00b7sers", "Lan\u00b7des", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "$,", "KOUI", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df ein Gascogner schuldig w\u00e4re.", "tokens": ["Da\u00df", "ein", "Gas\u00b7cog\u00b7ner", "schul\u00b7dig", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Bestie wird euch und uns erfreun.", "tokens": ["Die", "Be\u00b7stie", "wird", "euch", "und", "uns", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "KON", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Beim Element! wir wollen uns erg\u00f6tzen;", "tokens": ["Beim", "E\u00b7le\u00b7ment", "!", "wir", "wol\u00b7len", "uns", "er\u00b7g\u00f6t\u00b7zen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Den B\u00e4ren soll gewi\u00df kein Teufel besser hetzen.", "tokens": ["Den", "B\u00e4\u00b7ren", "soll", "ge\u00b7wi\u00df", "kein", "Teu\u00b7fel", "bes\u00b7ser", "het\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PIAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der K\u00fcrschner l\u00e4chelt zwar, doch geht er alles ein;", "tokens": ["Der", "K\u00fcrschner", "l\u00e4\u00b7chelt", "zwar", ",", "doch", "geht", "er", "al\u00b7les", "ein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "ADV", "VVFIN", "PPER", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.11": {"text": "Sie aber s\u00e4umen nicht, den Streich ins Werk zu setzen.", "tokens": ["Sie", "a\u00b7ber", "s\u00e4u\u00b7men", "nicht", ",", "den", "Streich", "ins", "Werk", "zu", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "$,", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der K\u00fchnheit Ungeduld verdoppelt ihren Lauf;", "tokens": ["Der", "K\u00fchn\u00b7heit", "Un\u00b7ge\u00b7duld", "ver\u00b7dop\u00b7pelt", "ih\u00b7ren", "Lauf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Wald wird schnell erreicht; ihr Gegner zeigt sich wieder.", "tokens": ["Der", "Wald", "wird", "schnell", "er\u00b7reicht", ";", "ihr", "Geg\u00b7ner", "zeigt", "sich", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$.", "PPOSAT", "NN", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Sogleich trifft Furcht und Frost der beiden J\u00e4ger Glieder.", "tokens": ["Sog\u00b7leich", "trifft", "Furcht", "und", "Frost", "der", "bei\u00b7den", "J\u00e4\u00b7ger", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "ART", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der eine springt verzagt den n\u00e4chsten Baum hinauf;", "tokens": ["Der", "ei\u00b7ne", "springt", "ver\u00b7zagt", "den", "n\u00e4chs\u00b7ten", "Baum", "hin\u00b7auf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den andern wirft Gefahr und Angst und Klugheit nieder.", "tokens": ["Den", "an\u00b7dern", "wirft", "Ge\u00b7fahr", "und", "Angst", "und", "Klug\u00b7heit", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "NN", "KON", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er streckt sich starrend aus, h\u00e4lt seinen Athem an,", "tokens": ["Er", "streckt", "sich", "star\u00b7rend", "aus", ",", "h\u00e4lt", "sei\u00b7nen", "A\u00b7them", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und stellt sich mausetodt, so gut er immer kann;", "tokens": ["Und", "stellt", "sich", "mau\u00b7se\u00b7todt", ",", "so", "gut", "er", "im\u00b7mer", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "$,", "ADV", "ADJD", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Denn, was er sonst geh\u00f6rt, ist ihm noch unvergessen,", "tokens": ["Denn", ",", "was", "er", "sonst", "ge\u00b7h\u00f6rt", ",", "ist", "ihm", "noch", "un\u00b7ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Da\u00df B\u00e4ren selten Todte fressen.", "tokens": ["Da\u00df", "B\u00e4\u00b7ren", "sel\u00b7ten", "Tod\u00b7te", "fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Das Thier betrachtet ihn, beriecht ihn, kehrt ihn um,", "tokens": ["Das", "Thier", "be\u00b7trach\u00b7tet", "ihn", ",", "be\u00b7riecht", "ihn", ",", "kehrt", "ihn", "um", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und l\u00e4\u00dft sich durch den Schein betr\u00fcgen,", "tokens": ["Und", "l\u00e4\u00dft", "sich", "durch", "den", "Schein", "be\u00b7tr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Pfui! brummt es, welch ein Aas! wir B\u00e4ren sind nicht dumm;", "tokens": ["Pfui", "!", "brummt", "es", ",", "welch", "ein", "Aas", "!", "wir", "B\u00e4\u00b7ren", "sind", "nicht", "dumm", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "PWAT", "ART", "NN", "$.", "PPER", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns mu\u00df was frischeres vergn\u00fcgen.", "tokens": ["Uns", "mu\u00df", "was", "fri\u00b7sche\u00b7res", "ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PWS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er geht hierauf zur\u00fcck. Der Held verl\u00e4\u00dft den Baum,", "tokens": ["Er", "geht", "hier\u00b7auf", "zu\u00b7r\u00fcck", ".", "Der", "Held", "ver\u00b7l\u00e4\u00dft", "den", "Baum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "$.", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und eilt dem Freunde zu. Ich sehe dich am Leben,", "tokens": ["Und", "eilt", "dem", "Freun\u00b7de", "zu", ".", "Ich", "se\u00b7he", "dich", "am", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ruft er bewundernd aus, und dennoch glaub' ich's kaum,", "tokens": ["Ruft", "er", "be\u00b7wun\u00b7dernd", "aus", ",", "und", "den\u00b7noch", "glaub'", "ich's", "kaum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "ADV", "VVFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kein kleiner Heiliger hat dir jetzt Schutz gegeben.", "tokens": ["Kein", "klei\u00b7ner", "Hei\u00b7li\u00b7ger", "hat", "dir", "jetzt", "Schutz", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPER", "ADV", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Allein, wie h\u00e4lt es nun mit unsers Feindes Haut?", "tokens": ["Al\u00b7lein", ",", "wie", "h\u00e4lt", "es", "nun", "mit", "un\u00b7sers", "Fein\u00b7des", "Haut", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er war, wie ich mit Schrecken sahe,", "tokens": ["Er", "war", ",", "wie", "ich", "mit", "Schre\u00b7cken", "sa\u00b7he", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Hier deinen Ohren ziemlich nahe;", "tokens": ["Hier", "dei\u00b7nen", "Oh\u00b7ren", "ziem\u00b7lich", "na\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Was hat er dir doch anvertraut?", "tokens": ["Was", "hat", "er", "dir", "doch", "an\u00b7ver\u00b7traut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nicht viel, versetzt sein Freund; doch glaub' ich diesem Scythen:", "tokens": ["Nicht", "viel", ",", "ver\u00b7setzt", "sein", "Freund", ";", "doch", "glaub'", "ich", "die\u00b7sem", "Scyt\u00b7hen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er gab mir insgeheim den Rath,", "tokens": ["Er", "gab", "mir", "ins\u00b7ge\u00b7heim", "den", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Haut nicht eher feil zu bieten,", "tokens": ["Die", "Haut", "nicht", "e\u00b7her", "feil", "zu", "bie\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als bis man schon den B\u00e4ren hat.", "tokens": ["Als", "bis", "man", "schon", "den", "B\u00e4\u00b7ren", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PIS", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}