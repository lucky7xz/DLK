{"textgrid.poem.24311": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "3.", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vier adlige Freundinnen nenne ich mein,", "tokens": ["Vier", "ad\u00b7li\u00b7ge", "Freun\u00b7din\u00b7nen", "nen\u00b7ne", "ich", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVFIN", "PPER", "PPOSAT", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Obwohl ich selbst nicht adelig bin.", "tokens": ["Ob\u00b7wohl", "ich", "selbst", "nicht", "a\u00b7de\u00b7lig", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADJD", "VAFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sie sind von edelster Abkunft, rein", "tokens": ["Sie", "sind", "von", "e\u00b7dels\u00b7ter", "Ab\u00b7kunft", ",", "rein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "$,", "ADJD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Durchaus von Gebl\u00fcte,", "tokens": ["Durc\u00b7haus", "von", "Ge\u00b7bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Voller Treue und G\u00fcte,", "tokens": ["Vol\u00b7ler", "Treu\u00b7e", "und", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Und gehen mit Grazie durchs Leben hin.", "tokens": ["Und", "ge\u00b7hen", "mit", "Gra\u00b7zie", "durchs", "Le\u00b7ben", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.2": {"line.1": {"text": "Sie lieben die Jagd, sie lieben das Spiel", "tokens": ["Sie", "lie\u00b7ben", "die", "Jagd", ",", "sie", "lie\u00b7ben", "das", "Spiel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und sind zuweilen sehr verliebt.", "tokens": ["Und", "sind", "zu\u00b7wei\u00b7len", "sehr", "ver\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Arbeit halten sie nicht viel.", "tokens": ["Von", "Ar\u00b7beit", "hal\u00b7ten", "sie", "nicht", "viel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zumal es f\u00fcr Damen", "tokens": ["Zu\u00b7mal", "es", "f\u00fcr", "Da\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Aus edlem Samen", "tokens": ["Aus", "ed\u00b7lem", "Sa\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Keine standesgem\u00e4\u00dfe Arbeit gibt.", "tokens": ["Kei\u00b7ne", "stan\u00b7des\u00b7ge\u00b7m\u00e4\u00b7\u00dfe", "Ar\u00b7beit", "gibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Gef\u00e4llts mir, zu wandern, gleich sind sie dabei,", "tokens": ["Ge\u00b7f\u00e4llts", "mir", ",", "zu", "wan\u00b7dern", ",", "gleich", "sind", "sie", "da\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PTKZU", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "PAV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und, allem Anschein nach, sehr gern.", "tokens": ["Und", ",", "al\u00b7lem", "An\u00b7schein", "nach", ",", "sehr", "gern", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "PIS", "NN", "PTKVZ", "$,", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch legen sie Wert darauf, da\u00df frei", "tokens": ["Doch", "le\u00b7gen", "sie", "Wert", "da\u00b7rauf", ",", "da\u00df", "frei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VVFIN", "PAV", "$,", "KOUS", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ihr Promenieren,", "tokens": ["Ihr", "Pro\u00b7me\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Da\u00df kein Genieren", "tokens": ["Da\u00df", "kein", "Ge\u00b7nie\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIAT", "NN"], "meter": "++-+-", "measure": "iambic.di"}, "line.6": {"text": "Beim Wandern sie st\u00f6rt mit ihrem Herrn.", "tokens": ["Beim", "Wan\u00b7dern", "sie", "st\u00f6rt", "mit", "ih\u00b7rem", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Denn, sonderbar, wirklich, ich bin ihr Herr,", "tokens": ["Denn", ",", "son\u00b7der\u00b7bar", ",", "wirk\u00b7lich", ",", "ich", "bin", "ihr", "Herr", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "$,", "ADJD", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Obwohl sie edler sind als ich,", "tokens": ["Ob\u00b7wohl", "sie", "ed\u00b7ler", "sind", "als", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "VAFIN", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel sch\u00f6ner und wohlgeborener.", "tokens": ["Viel", "sch\u00f6\u00b7ner", "und", "wohl\u00b7ge\u00b7bo\u00b7re\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "KON", "ADJD", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So ist das Leben:", "tokens": ["So", "ist", "das", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Die Bessern geben", "tokens": ["Die", "Bes\u00b7sern", "ge\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Zuweilen den Schlechtern als Diener sich.", "tokens": ["Zu\u00b7wei\u00b7len", "den", "Schlech\u00b7tern", "als", "Die\u00b7ner", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KOUS", "NN", "PRF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Drei Schwestern sind es und ihre Mama.", "tokens": ["Drei", "Schwes\u00b7tern", "sind", "es", "und", "ih\u00b7re", "Ma\u00b7ma", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die ist Respektsperson und so", "tokens": ["Die", "ist", "Res\u00b7pekts\u00b7per\u00b7son", "und", "so"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NN", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vollkommen, wie ich keine sah.", "tokens": ["Voll\u00b7kom\u00b7men", ",", "wie", "ich", "kei\u00b7ne", "sah", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "PIAT", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz \u00e9l\u00e9gance,", "tokens": ["Ganz", "\u00e9l\u00e9\u00b7gan\u00b7ce", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Stets contenance,", "tokens": ["Stets", "con\u00b7ten\u00b7an\u00b7ce", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "NE", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Madame Wiwwi ist comme il faut.", "tokens": ["Ma\u00b7da\u00b7me", "Wiw\u00b7wi", "ist", "com\u00b7me", "il", "faut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Den Fr\u00e4uleins fehlt wohl die W\u00fcrde noch", "tokens": ["Den", "Fr\u00e4u\u00b7leins", "fehlt", "wohl", "die", "W\u00fcr\u00b7de", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie sind auch noch zu jung dazu.", "tokens": ["Sie", "sind", "auch", "noch", "zu", "jung", "da\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Luna kriecht in jedes Loch,", "tokens": ["Die", "Lu\u00b7na", "kriecht", "in", "je\u00b7des", "Loch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die schlanke Brille", "tokens": ["Die", "schlan\u00b7ke", "Bril\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "H\u00e4lt niemals stille,", "tokens": ["H\u00e4lt", "nie\u00b7mals", "stil\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und Thisbe l\u00e4\u00dft keine Katze in Ruh.", "tokens": ["Und", "This\u00b7be", "l\u00e4\u00dft", "kei\u00b7ne", "Kat\u00b7ze", "in", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIAT", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Was schadets, wenn man so sch\u00f6n ist wie sie,", "tokens": ["Was", "scha\u00b7dets", ",", "wenn", "man", "so", "sch\u00f6n", "ist", "wie", "sie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PIS", "ADV", "ADJD", "VAFIN", "KOKOM", "PPER", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So liebensw\u00fcrdig, lustig, fein.", "tokens": ["So", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", ",", "lus\u00b7tig", ",", "fein", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich wei\u00df gewi\u00df, ich treffe nie", "tokens": ["Ich", "wei\u00df", "ge\u00b7wi\u00df", ",", "ich", "tref\u00b7fe", "nie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nochmal so viere,", "tokens": ["Noch\u00b7mal", "so", "vie\u00b7re", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Es m\u00f6gen nun Tiere,", "tokens": ["Es", "m\u00f6\u00b7gen", "nun", "Tie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJA", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Oder, salva venia, Menschen sein.", "tokens": ["O\u00b7der", ",", "sal\u00b7va", "ve\u00b7nia", ",", "Men\u00b7schen", "sein", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "FM.la", "FM.la", "$,", "NN", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}