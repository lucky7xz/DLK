{"textgrid.poem.53571": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Strafgericht?", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie sprachen Tage, lange, lange Tage \u2013", "tokens": ["Sie", "spra\u00b7chen", "Ta\u00b7ge", ",", "lan\u00b7ge", ",", "lan\u00b7ge", "Ta\u00b7ge", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "ADV", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und klagten an in bitterb\u00f6ser Klage.", "tokens": ["und", "klag\u00b7ten", "an", "in", "bit\u00b7ter\u00b7b\u00f6\u00b7ser", "Kla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sie wiesen nach: der Krieg verschluckte brausend", "tokens": ["Sie", "wie\u00b7sen", "nach", ":", "der", "Krieg", "ver\u00b7schluck\u00b7te", "brau\u00b7send"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und ohne Nutzen Sechsmalhunderttausend.", "tokens": ["und", "oh\u00b7ne", "Nut\u00b7zen", "Sechs\u00b7mal\u00b7hun\u00b7dert\u00b7tau\u00b7send", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sie wiesen nach: der Ludendorff, der gro\u00dfe,", "tokens": ["Sie", "wie\u00b7sen", "nach", ":", "der", "Lu\u00b7den\u00b7dorff", ",", "der", "gro\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ART", "NE", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "stie\u00df Deutschland in die schmutzigrote Sauce.", "tokens": ["stie\u00df", "Deutschland", "in", "die", "schmut\u00b7zi\u00b7gro\u00b7te", "Sau\u00b7ce", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Sie wiesen nach: Herr Tirpitz tats nicht minder.", "tokens": ["Sie", "wie\u00b7sen", "nach", ":", "Herr", "Tir\u00b7pitz", "tats", "nicht", "min\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "NN", "NE", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Industrie besa\u00df recht artige Kinder.", "tokens": ["Die", "In\u00b7dust\u00b7rie", "be\u00b7sa\u00df", "recht", "ar\u00b7ti\u00b7ge", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Sie wiesen nach . . . Und nun? Was wird geschehen?", "tokens": ["Sie", "wie\u00b7sen", "nach", ".", ".", ".", "Und", "nun", "?", "Was", "wird", "ge\u00b7sche\u00b7hen", "?"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "$.", "$.", "KON", "ADV", "$.", "PWS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir werden sie nach Hause schlurchen sehen.", "tokens": ["Wir", "wer\u00b7den", "sie", "nach", "Hau\u00b7se", "schlur\u00b7chen", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und schaut ein General noch so verrucht aus:", "tokens": ["Und", "schaut", "ein", "Ge\u00b7ne\u00b7ral", "noch", "so", "ver\u00b7rucht", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man steckt ihn nie und nimmermehr ins Zuchthaus.", "tokens": ["Man", "steckt", "ihn", "nie", "und", "nim\u00b7mer\u00b7mehr", "ins", "Zucht\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "KON", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Also zum Tode? \u2013 Aber, Kind, mit nichten!", "tokens": ["Al\u00b7so", "zum", "To\u00b7de", "?", "\u2013", "A\u00b7ber", ",", "Kind", ",", "mit", "nich\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$.", "$(", "KON", "$,", "NN", "$,", "APPR", "PIS", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Die Weltgeschichte wird ihn einmal richten \u2013!", "tokens": ["Die", "Welt\u00b7ge\u00b7schich\u00b7te", "wird", "ihn", "ein\u00b7mal", "rich\u00b7ten", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVINF", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Die Weltgeschichte aber richtet keinen.", "tokens": ["Die", "Welt\u00b7ge\u00b7schich\u00b7te", "a\u00b7ber", "rich\u00b7tet", "kei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PIAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Stumpf, unger\u00fchrt h\u00f6rt sie die M\u00fctter weinen.", "tokens": ["Stumpf", ",", "un\u00b7ge\u00b7r\u00fchrt", "h\u00f6rt", "sie", "die", "M\u00fct\u00b7ter", "wei\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Und unterdessen freuen sich die Krieger", "tokens": ["Und", "un\u00b7ter\u00b7des\u00b7sen", "freu\u00b7en", "sich", "die", "Krie\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "des rosigen Lichts \u2013 auch heute noch die Sieger.", "tokens": ["des", "ro\u00b7si\u00b7gen", "Lichts", "\u2013", "auch", "heu\u00b7te", "noch", "die", "Sie\u00b7ger", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Wir sind in Deutschland.", "tokens": ["Wir", "sind", "in", "Deutschland", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Da hat ein Paar Gl\u00fcck:", "tokens": ["Da", "hat", "ein", "Paar", "Gl\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-++", "measure": "unknown.measure.tri"}, "line.3": {"text": "Die Gro\u00dfbank und ein buntes Achselst\u00fcck.", "tokens": ["Die", "Gro\u00df\u00b7bank", "und", "ein", "bun\u00b7tes", "Ach\u00b7sel\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}