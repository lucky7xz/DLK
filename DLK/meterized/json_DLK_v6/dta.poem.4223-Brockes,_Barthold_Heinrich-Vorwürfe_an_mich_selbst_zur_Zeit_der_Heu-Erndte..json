{"dta.poem.4223": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Vorw\u00fcrfe an mich selbst  \n zur  \n  Zeit der Heu-Erndte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich habe, mit vergn\u00fcgter Lust,", "tokens": ["Ich", "ha\u00b7be", ",", "mit", "ver\u00b7gn\u00fcg\u00b7ter", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und innrer Regung meiner Brust,", "tokens": ["Und", "inn\u00b7rer", "Re\u00b7gung", "mei\u00b7ner", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gar oft vor dem die Heu-Erndt\u2019 angesehen.", "tokens": ["Gar", "oft", "vor", "dem", "die", "Heu\u00b7Erndt'", "an\u00b7ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich sah das frische Gras, nicht sonder Anmuht, m\u00e4hen,", "tokens": ["Ich", "sah", "das", "fri\u00b7sche", "Gras", ",", "nicht", "son\u00b7der", "An\u00b7muht", ",", "m\u00e4\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "PTKNEG", "ADJA", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich sah es, mit empfindlichem Vergn\u00fcgen,", "tokens": ["Ich", "sah", "es", ",", "mit", "emp\u00b7find\u00b7li\u00b7chem", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So ordentlich in Schwaden liegen,", "tokens": ["So", "or\u00b7dent\u00b7lich", "in", "Schwa\u00b7den", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich roch, recht inniglich ger\u00fchrt, den s\u00fcssen Duft", "tokens": ["Ich", "roch", ",", "recht", "in\u00b7nig\u00b7lich", "ge\u00b7r\u00fchrt", ",", "den", "s\u00fcs\u00b7sen", "Duft"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADJD", "VVPP", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der, durch das frische Heu recht balsamierten, Luft,", "tokens": ["Der", ",", "durch", "das", "fri\u00b7sche", "Heu", "recht", "bal\u00b7sa\u00b7mier\u00b7ten", ",", "Luft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "ADJA", "NN", "ADJD", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und dankte GOtt, da\u00df, auch im frischen Heu,", "tokens": ["Und", "dank\u00b7te", "Gott", ",", "da\u00df", ",", "auch", "im", "fri\u00b7schen", "Heu", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "KOUS", "$,", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Uns Seine G\u00fcte j\u00e4hrlich neu:", "tokens": ["Uns", "Sei\u00b7ne", "G\u00fc\u00b7te", "j\u00e4hr\u00b7lich", "neu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Obgleich von allem, was mich r\u00fchrte,", "tokens": ["Ob\u00b7gleich", "von", "al\u00b7lem", ",", "was", "mich", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Was ich mit Augen sah, und durch die Nase sp\u00fchrte,", "tokens": ["Was", "ich", "mit", "Au\u00b7gen", "sah", ",", "und", "durch", "die", "Na\u00b7se", "sp\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Gar nichts mein eigen war. Jtzt, da mir so viel Wiesen,", "tokens": ["Gar", "nichts", "mein", "ei\u00b7gen", "war", ".", "Jtzt", ",", "da", "mir", "so", "viel", "Wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPOSAT", "ADJD", "VAFIN", "$.", "ADV", "$,", "KOUS", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Durch GOttes Huld, geschenkt, da\u00df, von denselben, man", "tokens": ["Durch", "Got\u00b7tes", "Huld", ",", "ge\u00b7schenkt", ",", "da\u00df", ",", "von", "den\u00b7sel\u00b7ben", ",", "man"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "NN", "NN", "$,", "VVPP", "$,", "KOUS", "$,", "APPR", "PDAT", "$,", "PIS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "An Fudern mehr, als hundert, machen kann;", "tokens": ["An", "Fu\u00b7dern", "mehr", ",", "als", "hun\u00b7dert", ",", "ma\u00b7chen", "kann", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "$,", "KOUS", "CARD", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Hab ich Jhn lange nicht so br\u00fcnstiglich gepriesen,", "tokens": ["Hab", "ich", "Jhn", "lan\u00b7ge", "nicht", "so", "br\u00fcns\u00b7tig\u00b7lich", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Als ich gesollt, und als ich schuldig w\u00e4r.", "tokens": ["Als", "ich", "ge\u00b7sollt", ",", "und", "als", "ich", "schul\u00b7dig", "w\u00e4r", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,", "KON", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Gewohnheit hat bisher,", "tokens": ["Ge\u00b7wohn\u00b7heit", "hat", "bis\u00b7her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Mit den fast nicht zu widerstehnden Kr\u00e4ften,", "tokens": ["Mit", "den", "fast", "nicht", "zu", "wi\u00b7der\u00b7stehn\u00b7den", "Kr\u00e4f\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PTKNEG", "PTKZU", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Nebst einigen geringen Amts-Gesch\u00e4ften,", "tokens": ["Nebst", "ei\u00b7ni\u00b7gen", "ge\u00b7rin\u00b7gen", "Amts\u00b7Ge\u00b7sch\u00e4f\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Von meiner Schuldigkeit mich abgezogen.", "tokens": ["Von", "mei\u00b7ner", "Schul\u00b7dig\u00b7keit", "mich", "ab\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ach, sch\u00e4me dich, mein Geist, er\u00f6ffne dein Gesicht,", "tokens": ["Ach", ",", "sch\u00e4\u00b7me", "dich", ",", "mein", "Geist", ",", "er\u00b7\u00f6ff\u00b7ne", "dein", "Ge\u00b7sicht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und, durch so grosse Huld dazu bewogen,", "tokens": ["Und", ",", "durch", "so", "gros\u00b7se", "Huld", "da\u00b7zu", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ADV", "ADJA", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vergi\u00df, f\u00fcr so viel Guts, des Dankens ferner nicht.", "tokens": ["Ver\u00b7gi\u00df", ",", "f\u00fcr", "so", "viel", "Guts", ",", "des", "Dan\u00b7kens", "fer\u00b7ner", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "APPR", "ADV", "PIAT", "NN", "$,", "ART", "NN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich sehe, wie mein\u2019 eigne Wagen,", "tokens": ["Ich", "se\u00b7he", ",", "wie", "mein'", "eig\u00b7ne", "Wa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein eigen Heu, in schweren Schobern tragen,", "tokens": ["Mein", "ei\u00b7gen", "Heu", ",", "in", "schwe\u00b7ren", "Scho\u00b7bern", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So, da\u00df des grossen Vorwerks Th\u00fcren", "tokens": ["So", ",", "da\u00df", "des", "gros\u00b7sen", "Vor\u00b7werks", "Th\u00fc\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr sie fast noch zu klein. Mein\u2019 eigne Pferde f\u00fchren", "tokens": ["F\u00fcr", "sie", "fast", "noch", "zu", "klein", ".", "Mein'", "eig\u00b7ne", "Pfer\u00b7de", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ADV", "ADV", "PTKA", "ADJD", "$.", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und ziehn ihr eigne Kost. Hier f\u00e4hrt ein Wagen fort;", "tokens": ["Und", "ziehn", "ihr", "eig\u00b7ne", "Kost", ".", "Hier", "f\u00e4hrt", "ein", "Wa\u00b7gen", "fort", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein andrer kommt zur\u00fcck; der dritte wird beladen;", "tokens": ["Ein", "an\u00b7drer", "kommt", "zu\u00b7r\u00fcck", ";", "der", "drit\u00b7te", "wird", "be\u00b7la\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den vierten macht man leer von seiner B\u00fcrde; dort", "tokens": ["Den", "vier\u00b7ten", "macht", "man", "leer", "von", "sei\u00b7ner", "B\u00fcr\u00b7de", ";", "dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "VVFIN", "PIS", "ADJD", "APPR", "PPOSAT", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und hier liegt noch, voll frischer Schwaden,", "tokens": ["Und", "hier", "liegt", "noch", ",", "voll", "fri\u00b7scher", "Schwa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ein Feld, so weit man sehen kann.", "tokens": ["Ein", "Feld", ",", "so", "weit", "man", "se\u00b7hen", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mir m\u00fcssen, ohne sie zu lohnen,", "tokens": ["Mir", "m\u00fcs\u00b7sen", ",", "oh\u00b7ne", "sie", "zu", "loh\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "So viel ich n\u00f6htig hab\u2019, als Hofe-Dienste, frohnen.", "tokens": ["So", "viel", "ich", "n\u00f6h\u00b7tig", "hab'", ",", "als", "Ho\u00b7fe\u00b7Diens\u00b7te", ",", "froh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "VAFIN", "$,", "KOUS", "NN", "$,", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da m\u00e4ht und dorten wendet man;", "tokens": ["Da", "m\u00e4ht", "und", "dor\u00b7ten", "wen\u00b7det", "man", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADV", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Hier macht man ", "tokens": ["Hier", "macht", "man"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Das Feld, zu meinem Nutz, scheint gleichsam ganz belebt.", "tokens": ["Das", "Feld", ",", "zu", "mei\u00b7nem", "Nutz", ",", "scheint", "gleich\u00b7sam", "ganz", "be\u00b7lebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVFIN", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ach! da\u00df mein Herze sich denn nicht bestrebt,", "tokens": ["Ach", "!", "da\u00df", "mein", "Her\u00b7ze", "sich", "denn", "nicht", "be\u00b7strebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "KOUS", "PPOSAT", "VVFIN", "PRF", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "F\u00fcr so viel Gutes, GOtt zu r\u00fchmen,", "tokens": ["F\u00fcr", "so", "viel", "Gu\u00b7tes", ",", "Gott", "zu", "r\u00fch\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "$,", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Dem Ehre, Preis und Dank geb\u00fchrt,", "tokens": ["Dem", "Eh\u00b7re", ",", "Preis", "und", "Dank", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Der, so zum Nutz, als Schmuck der Welt,", "tokens": ["Der", ",", "so", "zum", "Nutz", ",", "als", "Schmuck", "der", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "APPRART", "NN", "$,", "KOUS", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Ein sonsten d\u00fcrr- und \u00f6des Feld", "tokens": ["Ein", "sons\u00b7ten", "d\u00fcrr", "und", "\u00f6\u00b7des", "Feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Mit sch\u00f6nem Gras und Bluhmen ziert,", "tokens": ["Mit", "sch\u00f6\u00b7nem", "Gras", "und", "Bluh\u00b7men", "ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Der seinem Kraut die Wachsthums-Kraft,", "tokens": ["Der", "sei\u00b7nem", "Kraut", "die", "Wachst\u00b7hums\u00b7Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Auch einer Nahrungs-Eigenschaft,", "tokens": ["Auch", "ei\u00b7ner", "Nah\u00b7rungs\u00b7Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "F\u00fcr Menschen, denen Thieren schenket,", "tokens": ["F\u00fcr", "Men\u00b7schen", ",", "de\u00b7nen", "Thie\u00b7ren", "schen\u00b7ket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und ihm zugleich, da\u00df es, von F\u00e4ulni\u00df frey,", "tokens": ["Und", "ihm", "zu\u00b7gleich", ",", "da\u00df", "es", ",", "von", "F\u00e4ul\u00b7ni\u00df", "frey", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "KOUS", "PPER", "$,", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Was erstlich Gras, hernach als Heu", "tokens": ["Was", "erst\u00b7lich", "Gras", ",", "her\u00b7nach", "als", "Heu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADJD", "NN", "$,", "ADV", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Sich trocknen l\u00e4sset, eingesenket,", "tokens": ["Sich", "trock\u00b7nen", "l\u00e4s\u00b7set", ",", "ein\u00b7ge\u00b7sen\u00b7ket", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "ADJA", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Der gute Witterung, zumahl zur Erndte-Zeit,", "tokens": ["Der", "gu\u00b7te", "Wit\u00b7te\u00b7rung", ",", "zu\u00b7mahl", "zur", "Ernd\u00b7te\u00b7Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "An Wind und Sonnen-Schein verleiht,", "tokens": ["An", "Wind", "und", "Son\u00b7nen\u00b7Schein", "ver\u00b7leiht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Durch Den wir des Verstandes Gaben,", "tokens": ["Durch", "Den", "wir", "des", "Ver\u00b7stan\u00b7des", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Es wirthlich zu verpflegen, haben.", "tokens": ["Es", "wirth\u00b7lich", "zu", "ver\u00b7pfle\u00b7gen", ",", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$,", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Mein GOtt, der Du an uns so viele Wunder \u00fcbst,", "tokens": ["Mein", "Gott", ",", "der", "Du", "an", "uns", "so", "vie\u00b7le", "Wun\u00b7der", "\u00fcbst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "APPR", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Du die Creaturen liebst,", "tokens": ["Der", "Du", "die", "Crea\u00b7tu\u00b7ren", "liebst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mir absonderlich so vieles Gute giebst,", "tokens": ["Und", "mir", "ab\u00b7son\u00b7der\u00b7lich", "so", "vie\u00b7les", "Gu\u00b7te", "giebst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "ADV", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach la\u00df, ich bitte Dich, aus Gnaden,", "tokens": ["Ach", "la\u00df", ",", "ich", "bit\u00b7te", "Dich", ",", "aus", "Gna\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein\u2019 Unempfindlichkeit mir doch nicht schaden!", "tokens": ["Mein'", "Un\u00b7emp\u00b7find\u00b7lich\u00b7keit", "mir", "doch", "nicht", "scha\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ach la\u00df, f\u00fcr so viel sch\u00f6nes Heu,", "tokens": ["Ach", "la\u00df", ",", "f\u00fcr", "so", "viel", "sch\u00f6\u00b7nes", "Heu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$,", "APPR", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Das h\u00f6her, als man glaubt, zu sch\u00e4tzen,", "tokens": ["Das", "h\u00f6\u00b7her", ",", "als", "man", "glaubt", ",", "zu", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "KOUS", "PIS", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mein unterbliebenes Ergetzen", "tokens": ["Mein", "un\u00b7ter\u00b7blie\u00b7be\u00b7nes", "Er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Und Unerkenntlichkeit, so ich bereu,", "tokens": ["Und", "Un\u00b7er\u00b7kennt\u00b7lich\u00b7keit", ",", "so", "ich", "be\u00b7reu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ADV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Mich nicht aus Deiner Gnade setzen!", "tokens": ["Mich", "nicht", "aus", "Dei\u00b7ner", "Gna\u00b7de", "set\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und weil doch, ohne Dich, nichts Guts geschehen kann;", "tokens": ["Und", "weil", "doch", ",", "oh\u00b7ne", "Dich", ",", "nichts", "Guts", "ge\u00b7sche\u00b7hen", "kann", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "$,", "KOUI", "PPER", "$,", "PIS", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So fleh ich Deine Lieb\u2019 in Demuht ferner an!", "tokens": ["So", "fleh", "ich", "Dei\u00b7ne", "Lieb'", "in", "De\u00b7muht", "fer\u00b7ner", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ach schenke mir, Dein\u2019 Allmacht zu besingen,", "tokens": ["Ach", "schen\u00b7ke", "mir", ",", "Dein'", "All\u00b7macht", "zu", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-++-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Zugleich das Wollen und Vollbringen:", "tokens": ["Zu\u00b7gleich", "das", "Wol\u00b7len", "und", "Voll\u00b7brin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "La\u00df, o Sch\u00f6pfer aller Dinge,", "tokens": ["La\u00df", ",", "o", "Sch\u00f6p\u00b7fer", "al\u00b7ler", "Din\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "FM", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Lob nicht zu geringe,", "tokens": ["Un\u00b7ser", "Lob", "nicht", "zu", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "PTKZU", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df es Dir gef\u00e4llig seyn!", "tokens": ["La\u00df", "es", "Dir", "ge\u00b7f\u00e4l\u00b7lig", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemand kann Dich w\u00fcrdig preisen,", "tokens": ["Nie\u00b7mand", "kann", "Dich", "w\u00fcr\u00b7dig", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Niemand Dir gnug Ehr\u2019 erweisen.", "tokens": ["Nie\u00b7mand", "Dir", "gnug", "Ehr'", "er\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dein ist alle Ehr\u2019 allein.", "tokens": ["Dein", "ist", "al\u00b7le", "Ehr'", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Dennoch hoff\u2019 ich, da\u00df auf Erden", "tokens": ["Den\u00b7noch", "hoff'", "ich", ",", "da\u00df", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Unsrer Seelen frohe Triebe", "tokens": ["Uns\u00b7rer", "See\u00b7len", "fro\u00b7he", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Dir, aus Liebe,", "tokens": ["Dir", ",", "aus", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Wenn sie Dich, in Deinen Werken,", "tokens": ["Wenn", "sie", "Dich", ",", "in", "Dei\u00b7nen", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "So mit Lust, als Ehrfurcht merken,", "tokens": ["So", "mit", "Lust", ",", "als", "Ehr\u00b7furcht", "mer\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "KOUS", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "G\u00e4nzlich nicht mi\u00dffallen werden.", "tokens": ["G\u00e4nz\u00b7lich", "nicht", "mi\u00df\u00b7fal\u00b7len", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Wenn wir f\u00fchlen und empfinden,", "tokens": ["Wenn", "wir", "f\u00fch\u00b7len", "und", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Wenn wir fassen und befinden,", "tokens": ["Wenn", "wir", "fas\u00b7sen", "und", "be\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Mit erstaunendem Gem\u00fchte,", "tokens": ["Mit", "er\u00b7stau\u00b7nen\u00b7dem", "Ge\u00b7m\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ein weis\u2019 und m\u00e4chtigs Wesen", "tokens": ["Da\u00df", "ein", "weis'", "und", "m\u00e4ch\u00b7tigs", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns zum Vorwurf Seiner G\u00fcte,", "tokens": ["Uns", "zum", "Vor\u00b7wurf", "Sei\u00b7ner", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Blo\u00df aus Gnaden, auserlesen;", "tokens": ["Blo\u00df", "aus", "Gna\u00b7den", ",", "au\u00b7ser\u00b7le\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df Es nichts (o Liebe!) wolle,", "tokens": ["Da\u00df", "Es", "nichts", "(", "o", "Lie\u00b7be", "!", ")", "wol\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "$(", "FM", "NN", "$.", "$(", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als da\u00df man, durch Jhn vergn\u00fcgt,", "tokens": ["Als", "da\u00df", "man", ",", "durch", "Jhn", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Unser\u2019 eigne Lust Jhm zolle.", "tokens": ["Un\u00b7ser'", "eig\u00b7ne", "Lust", "Jhm", "zol\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df man, aus Erkenntlichkeit,", "tokens": ["Da\u00df", "man", ",", "aus", "Er\u00b7kennt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Das, was Jhm mi\u00dff\u00e4llt, zu fliehen,", "tokens": ["Das", ",", "was", "Jhm", "mi\u00df\u00b7f\u00e4llt", ",", "zu", "flie\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Sich nach M\u00f6glichkeit bem\u00fchen,", "tokens": ["Sich", "nach", "M\u00f6g\u00b7lich\u00b7keit", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Und freywillig meiden solle;", "tokens": ["Und", "frey\u00b7wil\u00b7lig", "mei\u00b7den", "sol\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Da\u00df wir, Jhn recht zu erh\u00f6hn,", "tokens": ["Da\u00df", "wir", ",", "Jhn", "recht", "zu", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Sonst kein Mittel finden k\u00f6nnen,", "tokens": ["Sonst", "kein", "Mit\u00b7tel", "fin\u00b7den", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVINF", "VMINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Als da\u00df, in der Werke Pracht,", "tokens": ["Als", "da\u00df", ",", "in", "der", "Wer\u00b7ke", "Pracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Wir die Weisheit, Lieb\u2019 und Macht", "tokens": ["Wir", "die", "Weis\u00b7heit", ",", "Lieb'", "und", "Macht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Mit Bewunderung erkennen,", "tokens": ["Mit", "Be\u00b7wun\u00b7de\u00b7rung", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Und, zu Seinen Ehren, sehn,", "tokens": ["Und", ",", "zu", "Sei\u00b7nen", "Eh\u00b7ren", ",", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "H\u00f6ren, riechen, f\u00fchlen, schmecken,", "tokens": ["H\u00f6\u00b7ren", ",", "rie\u00b7chen", ",", "f\u00fch\u00b7len", ",", "schme\u00b7cken", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Auch, wie Er so wunderbar,", "tokens": ["Auch", ",", "wie", "Er", "so", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "In den Werken, hell und klar,", "tokens": ["In", "den", "Wer\u00b7ken", ",", "hell", "und", "klar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Mit Bewunderung, entdecken.", "tokens": ["Mit", "Be\u00b7wun\u00b7de\u00b7rung", ",", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Dieses thu ich nun allhier,", "tokens": ["Die\u00b7ses", "thu", "ich", "nun", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.23": {"text": "Grosser Sch\u00f6pfer, la\u00df doch Dir", "tokens": ["Gros\u00b7ser", "Sch\u00f6p\u00b7fer", ",", "la\u00df", "doch", "Dir"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVIMP", "ADV", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Mein durch Dich erregtes Lallen,", "tokens": ["Mein", "durch", "Dich", "er\u00b7reg\u00b7tes", "Lal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "APPR", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "Als ein Opfer-Rauch, gefallen!", "tokens": ["Als", "ein", "Op\u00b7fer\u00b7Rauch", ",", "ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}