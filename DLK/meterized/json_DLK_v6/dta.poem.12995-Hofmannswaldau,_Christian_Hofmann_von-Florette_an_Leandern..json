{"dta.poem.12995": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Florette an Leandern.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Leander schreibt zu viel: er lobt mein niedrig dichten,", "tokens": ["Le\u00b7an\u00b7der", "schreibt", "zu", "viel", ":", "er", "lobt", "mein", "nied\u00b7rig", "dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PIS", "$.", "PPER", "VVFIN", "PPOSAT", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und h\u00e4lt sein lauten-spiel nur einer leyer gleich;", "tokens": ["Und", "h\u00e4lt", "sein", "lau\u00b7ten\u00b7spiel", "nur", "ei\u00b7ner", "le\u00b7yer", "gleich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch sollt\u2019 Apollo hier die gantze sache schlichten,", "tokens": ["Doch", "sollt'", "A\u00b7pol\u00b7lo", "hier", "die", "gant\u00b7ze", "sa\u00b7che", "schlich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NE", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich wei\u00df, mein schwartzer brief w\u00fcrd\u2019 augenblicklich bleich.", "tokens": ["Ich", "wei\u00df", ",", "mein", "schwart\u00b7zer", "brief", "w\u00fcrd'", "au\u00b7gen\u00b7blick\u00b7lich", "bleich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich sag: er sch\u00e4mte sich; denn meine schwache feder", "tokens": ["Ich", "sag", ":", "er", "sch\u00e4m\u00b7te", "sich", ";", "denn", "mei\u00b7ne", "schwa\u00b7che", "fe\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "PRF", "$.", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kennt keinen adler nicht, der sie getragen hat,", "tokens": ["Kennt", "kei\u00b7nen", "ad\u00b7ler", "nicht", ",", "der", "sie", "ge\u00b7tra\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKNEG", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie wuchs vor kurtzer zeit aus schlechtem g\u00e4nse-leder;", "tokens": ["Sie", "wuchs", "vor", "kurt\u00b7zer", "zeit", "aus", "schlech\u00b7tem", "g\u00e4n\u00b7se\u00b7le\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Drum schreibt Florette kahl, es weist es dieses blat.", "tokens": ["Drum", "schreibt", "Flo\u00b7ret\u00b7te", "kahl", ",", "es", "weist", "es", "die\u00b7ses", "blat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gewi\u00df, ich scheue mich die antwort aufzusetzen,", "tokens": ["Ge\u00b7wi\u00df", ",", "ich", "scheu\u00b7e", "mich", "die", "ant\u00b7wort", "auf\u00b7zu\u00b7set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Es f\u00e4llt mir nicht ein wort, nicht eine sylbe bey:", "tokens": ["Es", "f\u00e4llt", "mir", "nicht", "ein", "wort", ",", "nicht", "ei\u00b7ne", "syl\u00b7be", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,", "PTKNEG", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ich wolte sie zwar wol wie gold in marmel \u00e4tzen;", "tokens": ["Ich", "wol\u00b7te", "sie", "zwar", "wol", "wie", "gold", "in", "mar\u00b7mel", "\u00e4t\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "KOKOM", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Allein es heist von mir: sie sagt nur einerley.", "tokens": ["Al\u00b7lein", "es", "heist", "von", "mir", ":", "sie", "sagt", "nur", "ei\u00b7ner\u00b7ley", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Leander k\u00f6ntest du mir hand und feder f\u00fchren,", "tokens": ["Le\u00b7an\u00b7der", "k\u00f6n\u00b7test", "du", "mir", "hand", "und", "fe\u00b7der", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ich wei\u00df, ein iedes wort erweichte stahl und stein.", "tokens": ["Ich", "wei\u00df", ",", "ein", "ie\u00b7des", "wort", "er\u00b7weich\u00b7te", "stahl", "und", "stein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "PIAT", "NN", "VVFIN", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die mauren w\u00fcrden selbst den s\u00fc\u00dfen thon versp\u00fcren,", "tokens": ["Die", "mau\u00b7ren", "w\u00fcr\u00b7den", "selbst", "den", "s\u00fc\u00b7\u00dfen", "thon", "ver\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und Orpheus m\u00fcste mir in demuth dienstbar seyn.", "tokens": ["Und", "Or\u00b7pheus", "m\u00fcs\u00b7te", "mir", "in", "de\u00b7muth", "dienst\u00b7bar", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VMFIN", "PPER", "APPR", "NE", "ADJD", "VAINF", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Jedoch du kanst nicht selbst vor dich die antwort schreiben.", "tokens": ["Je\u00b7doch", "du", "kanst", "nicht", "selbst", "vor", "dich", "die", "ant\u00b7wort", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "PTKNEG", "ADV", "APPR", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Man h\u00f6rt auch offtermals das kleine zeischen an.", "tokens": ["Man", "h\u00f6rt", "auch", "off\u00b7ter\u00b7mals", "das", "klei\u00b7ne", "zei\u00b7schen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die nachtigall kan uns nicht stets die zeit vertreiben,", "tokens": ["Die", "nach\u00b7ti\u00b7gall", "kan", "uns", "nicht", "stets", "die", "zeit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Drum lie\u00df von meiner hand, was ich itzt reimen kan.", "tokens": ["Drum", "lie\u00df", "von", "mei\u00b7ner", "hand", ",", "was", "ich", "itzt", "rei\u00b7men", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "PWS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Soll ich hinf\u00fchro mehr von deinen h\u00e4nden lesen?", "tokens": ["Soll", "ich", "hin\u00b7f\u00fch\u00b7ro", "mehr", "von", "dei\u00b7nen", "h\u00e4n\u00b7den", "le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "So glaube, da\u00df mich di\u00df gantz ungemein vergn\u00fcgt.", "tokens": ["So", "glau\u00b7be", ",", "da\u00df", "mich", "di\u00df", "gantz", "un\u00b7ge\u00b7mein", "ver\u00b7gn\u00fcgt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "PDS", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "In deinen versen zeigt sich ein besonders wesen,", "tokens": ["In", "dei\u00b7nen", "ver\u00b7sen", "zeigt", "sich", "ein", "be\u00b7son\u00b7ders", "we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF", "ART", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Das unsre hertzen mehr als ertz und glantz besiegt.", "tokens": ["Das", "uns\u00b7re", "hert\u00b7zen", "mehr", "als", "ertz", "und", "glantz", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "PIAT", "KOKOM", "ADJD", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Leander schreibt von flut, von flut aus tieffen br\u00fcnnen;", "tokens": ["Le\u00b7an\u00b7der", "schreibt", "von", "flut", ",", "von", "flut", "aus", "tief\u00b7fen", "br\u00fcn\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$,", "APPR", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und spricht, die poesie sey darum bey ihm matt.", "tokens": ["Und", "spricht", ",", "die", "po\u00b7e\u00b7sie", "sey", "da\u00b7rum", "bey", "ihm", "matt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PPER", "VAFIN", "PAV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Was soll ich aber wol in einem hofe sinnen,", "tokens": ["Was", "soll", "ich", "a\u00b7ber", "wol", "in", "ei\u00b7nem", "ho\u00b7fe", "sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Das nicht die eigenschafft der harten steine hat?", "tokens": ["Das", "nicht", "die", "ei\u00b7gen\u00b7schafft", "der", "har\u00b7ten", "stei\u00b7ne", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Jedoch dein h\u00f6flich seyn nimmt gleichwol mit vor willen,", "tokens": ["Je\u00b7doch", "dein", "h\u00f6f\u00b7lich", "seyn", "nimmt", "gleich\u00b7wol", "mit", "vor", "wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJD", "VAINF", "VVFIN", "ADV", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Seind schon die verse nicht galant, beliebt, noch frey.", "tokens": ["Seind", "schon", "die", "ver\u00b7se", "nicht", "ga\u00b7lant", ",", "be\u00b7liebt", ",", "noch", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG", "ADJD", "$,", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-----+-+-+", "measure": "dactylic.init"}, "line.31": {"text": "Ich wolte meine pflicht, so gut ich kan, erf\u00fcllen.", "tokens": ["Ich", "wol\u00b7te", "mei\u00b7ne", "pflicht", ",", "so", "gut", "ich", "kan", ",", "er\u00b7f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "$,", "ADV", "ADJD", "PPER", "VMFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Nur, bitt ich, rei\u00df den brief, als er verdient, entzwey.", "tokens": ["Nur", ",", "bitt", "ich", ",", "rei\u00df", "den", "brief", ",", "als", "er", "ver\u00b7dient", ",", "ent\u00b7zwey", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ART", "VVFIN", "$,", "KOUS", "PPER", "VVPP", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}