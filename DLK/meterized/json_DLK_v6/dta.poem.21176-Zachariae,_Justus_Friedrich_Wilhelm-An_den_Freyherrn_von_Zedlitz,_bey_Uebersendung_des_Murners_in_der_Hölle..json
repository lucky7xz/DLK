{"dta.poem.21176": {"metadata": {"author": {"name": "Zachariae, Justus Friedrich Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "An den Freyherrn von Zedlitz,  \n bey Uebersendung des Murners in der H\u00f6lle.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1764", "urn": "urn:nbn:de:kobv:b4-20676-2", "language": ["de:0.71", "af:0.28"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die Muse, die der Ewigkeit", "tokens": ["Die", "Mu\u00b7se", ",", "die", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der M\u00e4use Schlachten sang,", "tokens": ["Der", "M\u00e4u\u00b7se", "Schlach\u00b7ten", "sang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und zu der Berenice Haar", "tokens": ["Und", "zu", "der", "Be\u00b7re\u00b7ni\u00b7ce", "Haar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Fermor Locke hob;", "tokens": ["Der", "Fer\u00b7mor", "Lo\u00b7cke", "hob", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die sah ich, (Nachwelt, glaub\u2019 es mir!)", "tokens": ["Die", "sah", "ich", ",", "(", "Nach\u00b7welt", ",", "glaub'", "es", "mir", "!", ")"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "$(", "NN", "$,", "VVFIN", "PPER", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jm frischen Lindenhayn.", "tokens": ["Jm", "fri\u00b7schen", "Lin\u00b7den\u00b7hayn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein helles Erz am G\u00f6ttermund", "tokens": ["Ein", "hel\u00b7les", "Erz", "am", "G\u00f6t\u00b7ter\u00b7mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Klang durch Germanien.", "tokens": ["Klang", "durch", "Ger\u00b7ma\u00b7ni\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Jhr freyes Haar flo\u00df in die Luft,", "tokens": ["Ihr", "frey\u00b7es", "Haar", "flo\u00df", "in", "die", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Zephyr schwebte drauf;", "tokens": ["Der", "Ze\u00b7phyr", "schweb\u00b7te", "drauf", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Lachen flog um ihre Stirn,", "tokens": ["Das", "La\u00b7chen", "flog", "um", "ih\u00b7re", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ph\u00f6bus Laub umwand.", "tokens": ["Die", "Ph\u00f6\u00b7bus", "Laub", "um\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die Scherze flatterten um sie,", "tokens": ["Die", "Scher\u00b7ze", "flat\u00b7ter\u00b7ten", "um", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh\u00fcllt in falschen Ernst;", "tokens": ["Ge\u00b7h\u00fcllt", "in", "fal\u00b7schen", "Ernst", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der ziegens\u00fc\u00dfge Satyr sprang", "tokens": ["Der", "zie\u00b7gen\u00b7s\u00fc\u00df\u00b7ge", "Sa\u00b7tyr", "sprang"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Gratien einher.", "tokens": ["Mit", "Gra\u00b7ti\u00b7en", "ein\u00b7her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Jhr folgten in dem frohen Chor,", "tokens": ["Ihr", "folg\u00b7ten", "in", "dem", "fro\u00b7hen", "Chor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit scharfem Hohn im Blick;", "tokens": ["Mit", "schar\u00b7fem", "Hohn", "im", "Blick", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "M\u00e4onides, mit ihm Virgil,", "tokens": ["M\u00e4o\u00b7ni\u00b7des", ",", "mit", "ihm", "Vir\u00b7gil", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der Stolz von Latium.", "tokens": ["Der", "Stolz", "von", "La\u00b7ti\u00b7um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und Despreaux, der voller Salz", "tokens": ["Und", "De\u00b7sprea\u00b7ux", ",", "der", "vol\u00b7ler", "Salz"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des fetten M\u00f6nchs gelacht;", "tokens": ["Des", "fet\u00b7ten", "M\u00f6nchs", "ge\u00b7lacht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und der, durch welchen Albion", "tokens": ["Und", "der", ",", "durch", "wel\u00b7chen", "Al\u00b7bi\u00b7on"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Griechenland sich ma\u00df.", "tokens": ["Mit", "Grie\u00b7chen\u00b7land", "sich", "ma\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PRF", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Der k\u00fchne Deutsche dr\u00e4ngte sich,", "tokens": ["Der", "k\u00fch\u00b7ne", "Deut\u00b7sche", "dr\u00e4ng\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da die Trompet\u2019 erscholl,", "tokens": ["Da", "die", "Trom\u00b7pet'", "er\u00b7scholl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Voll Stolz herzu. Die G\u00f6ttin sprach", "tokens": ["Voll", "Stolz", "her\u00b7zu", ".", "Die", "G\u00f6t\u00b7tin", "sprach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "NN", "PTKVZ", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit heitrer Majest\u00e4t:", "tokens": ["Mit", "hei\u00b7trer", "Ma\u00b7jes\u00b7t\u00e4t", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Jhr S\u00f6hne Theurs, die lange Nacht", "tokens": ["Ihr", "S\u00f6h\u00b7ne", "Theurs", ",", "die", "lan\u00b7ge", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NE", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Barbarey entflieht;", "tokens": ["Der", "Bar\u00b7ba\u00b7rey", "ent\u00b7flieht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Jhr r\u00e4chet durch den feinren Witz", "tokens": ["Ihr", "r\u00e4\u00b7chet", "durch", "den", "fein\u00b7ren", "Witz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des schweren Clima Schuld.", "tokens": ["Des", "schwe\u00b7ren", "Cli\u00b7ma", "Schuld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Doch nehmet die Posaune nicht", "tokens": ["Doch", "neh\u00b7met", "die", "Po\u00b7sau\u00b7ne", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu fr\u00fch! Und wenn ihr singt,", "tokens": ["Zu", "fr\u00fch", "!", "Und", "wenn", "ihr", "singt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$.", "KON", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So bleibt nicht immer Wiederhall,", "tokens": ["So", "bleibt", "nicht", "im\u00b7mer", "Wie\u00b7der\u00b7hall", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und seyd Original!", "tokens": ["Und", "seyd", "O\u00b7rig\u00b7i\u00b7nal", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "$."], "meter": "+-+---", "measure": "unknown.measure.di"}}, "stanza.10": {"line.1": {"text": "Der deutsche Stutzer wird zu oft", "tokens": ["Der", "deut\u00b7sche", "Stut\u00b7zer", "wird", "zu", "oft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKA", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Satyr aufgef\u00fchrt,", "tokens": ["Vom", "Sa\u00b7tyr", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und eure Sch\u00f6nen r\u00fchren nicht,", "tokens": ["Und", "eu\u00b7re", "Sch\u00f6\u00b7nen", "r\u00fch\u00b7ren", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die ihr aus Wolken greift.", "tokens": ["Die", "ihr", "aus", "Wol\u00b7ken", "greift", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Welch eine gro\u00dfe Schilderey", "tokens": ["Welch", "ei\u00b7ne", "gro\u00b7\u00dfe", "Schil\u00b7de\u00b7rey"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Liegt vor euch, die Natur!", "tokens": ["Liegt", "vor", "euch", ",", "die", "Na\u00b7tur", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "$,", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ahmt ihr, nicht schlechten Mustern, nach,", "tokens": ["Ahmt", "ihr", ",", "nicht", "schlech\u00b7ten", "Mus\u00b7tern", ",", "nach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PTKNEG", "ADJA", "NN", "$,", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erfindet, und bleibt neu!", "tokens": ["Er\u00b7fin\u00b7det", ",", "und", "bleibt", "neu", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "So sprach sie, Zedlitz, und ich stieg", "tokens": ["So", "sprach", "sie", ",", "Zed\u00b7litz", ",", "und", "ich", "stieg"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "NE", "$,", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hinab zum Erebus.", "tokens": ["Hin\u00b7ab", "zum", "E\u00b7re\u00b7bus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Ungeheur am H\u00f6llenthor,", "tokens": ["Das", "Un\u00b7ge\u00b7heur", "am", "H\u00f6l\u00b7len\u00b7thor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gez\u00e4hmet durch Gesang.", "tokens": ["Ge\u00b7z\u00e4h\u00b7met", "durch", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Kroch, mit dem f\u00fcrchterlichen Schwanz", "tokens": ["Kroch", ",", "mit", "dem", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Schwanz"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sanftschmeichelnd vor mir hin;", "tokens": ["Sanft\u00b7schmei\u00b7chelnd", "vor", "mir", "hin", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und durch der Muse Gunst sah ich", "tokens": ["Und", "durch", "der", "Mu\u00b7se", "Gunst", "sah", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Thier\u2019 Elysium.", "tokens": ["Der", "Thier'", "E\u00b7ly\u00b7si\u00b7um", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}