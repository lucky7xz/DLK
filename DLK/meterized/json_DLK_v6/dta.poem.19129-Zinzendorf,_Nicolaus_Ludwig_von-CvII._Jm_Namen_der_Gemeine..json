{"dta.poem.19129": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "CvII.  Jm Namen der Gemeine.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Odu H\u00fcter Ephraim, des geringsten Theils der Heerde,", "tokens": ["O\u00b7du", "H\u00fc\u00b7ter", "Eph\u00b7raim", ",", "des", "ge\u00b7rings\u00b7ten", "Theils", "der", "Heer\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "Deiner Erde,", "tokens": ["Dei\u00b7ner", "Er\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Unser Auge sieht mit Schmertz,", "tokens": ["Un\u00b7ser", "Au\u00b7ge", "sieht", "mit", "Schmertz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Niederw\u00e4rts,", "tokens": ["Nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.5": {"text": "Aber unsre Seelen blicken,", "tokens": ["A\u00b7ber", "uns\u00b7re", "See\u00b7len", "bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mitten in dem Niederdr\u00fccken,", "tokens": ["Mit\u00b7ten", "in", "dem", "Nie\u00b7der\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "In dein hoch-erhabnes Hertz.", "tokens": ["In", "dein", "hoch\u00b7er\u00b7hab\u00b7nes", "Hertz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "T\u00f6dten ist dem HErrn erlaubt: denn Er t\u00f6dtet nur (vom B\u00f6sen", "tokens": ["T\u00f6d\u00b7ten", "ist", "dem", "Herrn", "er\u00b7laubt", ":", "denn", "Er", "t\u00f6d\u00b7tet", "nur", "(", "vom", "B\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "VVPP", "$.", "KON", "PPER", "VVFIN", "ADV", "$(", "APPRART", "NN"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Zu erl\u00f6sen)", "tokens": ["Zu", "er\u00b7l\u00f6\u00b7sen", ")"], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Nichts als unheilsame Noth,", "tokens": ["Nichts", "als", "un\u00b7heil\u00b7sa\u00b7me", "Noth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nichts als ", "tokens": ["Nichts", "als"], "token_info": ["word", "word"], "pos": ["PIS", "KOKOM"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Und der L\u00fcste ihr Gehecke,", "tokens": ["Und", "der", "L\u00fcs\u00b7te", "ihr", "Ge\u00b7hec\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und der ", "tokens": ["Und", "der"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Und der ", "tokens": ["Und", "der"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "Ehmahls solts gestorben seyn, und dasselbige zur Strafe,", "tokens": ["Eh\u00b7mahls", "solts", "ge\u00b7stor\u00b7ben", "seyn", ",", "und", "das\u00b7sel\u00b7bi\u00b7ge", "zur", "Stra\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAINF", "$,", "KON", "PDS", "APPRART", "NN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Vor die Schafe,", "tokens": ["Vor", "die", "Scha\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Die sich von der Lebens-Bahn", "tokens": ["Die", "sich", "von", "der", "Le\u00b7bens\u00b7Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Abgethan;", "tokens": ["Ab\u00b7ge\u00b7than", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Doch die unverdiente T\u00f6dtung", "tokens": ["Doch", "die", "un\u00b7ver\u00b7dien\u00b7te", "T\u00f6d\u00b7tung"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ward den Hirten angethan.", "tokens": ["Ward", "den", "Hir\u00b7ten", "an\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Seit der Zeit ist unser Ziel, das die Menschen Sterben nennen,", "tokens": ["Seit", "der", "Zeit", "ist", "un\u00b7ser", "Ziel", ",", "das", "die", "Men\u00b7schen", "Ster\u00b7ben", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PRELS", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Dies nicht kennen,", "tokens": ["Dies", "nicht", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Nur ein seliger Beschlu\u00df,", "tokens": ["Nur", "ein", "se\u00b7li\u00b7ger", "Be\u00b7schlu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vom Verdru\u00df,", "tokens": ["Vom", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Nur der letzte Schritt des Ganges,", "tokens": ["Nur", "der", "letz\u00b7te", "Schritt", "des", "Gan\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Den man durch das Thal des Dranges", "tokens": ["Den", "man", "durch", "das", "Thal", "des", "Dran\u00b7ges"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Hinter Christo gehen mu\u00df.", "tokens": ["Hin\u00b7ter", "Chris\u00b7to", "ge\u00b7hen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Schau auf deine ", "tokens": ["Schau", "auf", "dei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Die dich meynen;", "tokens": ["Die", "dich", "mey\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "(kleinen,", "tokens": ["(", "klei\u00b7nen", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "ADJA", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Jetzt zehn Jahr sprach deine Treu,", "tokens": ["Jetzt", "zehn", "Jahr", "sprach", "dei\u00b7ne", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Pl\u00f6tzlich: ", "tokens": ["Pl\u00f6tz\u00b7lich", ":"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Gnade, drinnen wir uns spiegeln,\nWunder, welche wir versiegeln,", "tokens": ["Gna\u00b7de", ",", "drin\u00b7nen", "wir", "uns", "spie\u00b7geln", ",", "Wun\u00b7der", ",", "wel\u00b7che", "wir", "ver\u00b7sie\u00b7geln", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "PRF", "VVINF", "$,", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Werden alle Morgen neu.", "tokens": ["Wer\u00b7den", "al\u00b7le", "Mor\u00b7gen", "neu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Uber hundert hast du schon, weiser Heyland! aufgehaben,", "tokens": ["U\u00b7ber", "hun\u00b7dert", "hast", "du", "schon", ",", "wei\u00b7ser", "Hey\u00b7land", "!", "auf\u00b7ge\u00b7ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "CARD", "VAFIN", "PPER", "ADV", "$,", "ADJA", "NN", "$.", "VVIZU", "$,"], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Und wir traben", "tokens": ["Und", "wir", "tra\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Noch, so lang es dir gef\u00e4llt,", "tokens": ["Noch", ",", "so", "lang", "es", "dir", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADJD", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die Welt.", "tokens": ["Durch", "die", "Welt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Die Vollendungs-Wolcke tauffet,", "tokens": ["Die", "Voll\u00b7en\u00b7dungs\u00b7Wol\u00b7cke", "tauf\u00b7fet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Seit der eilffte Jahr-Gang lauffet,", "tokens": ["Seit", "der", "eilff\u00b7te", "Jahr\u00b7Gang", "lauf\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Erstlich einen jungen Held.", "tokens": ["Erst\u00b7lich", "ei\u00b7nen", "jun\u00b7gen", "Held", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Heute, HErr, gefiel es dir, ", "tokens": ["Heu\u00b7te", ",", "Herr", ",", "ge\u00b7fiel", "es", "dir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gnaden-Winde,", "tokens": ["Gna\u00b7den\u00b7Win\u00b7de", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Zuzuwehn.", "tokens": ["Zu\u00b7zu\u00b7wehn", "."], "token_info": ["word", "punct"], "pos": ["CARD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Solten wir uns unternehmen,", "tokens": ["Sol\u00b7ten", "wir", "uns", "un\u00b7ter\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deine Liebe zu besch\u00e4men,", "tokens": ["Dei\u00b7ne", "Lie\u00b7be", "zu", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und zu sprechen: ", "tokens": ["Und", "zu", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PTKZU", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Fahre hin ins ", "tokens": ["Fah\u00b7re", "hin", "ins"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "APPRART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Bleibt dein Ruder,", "tokens": ["Bleibt", "dein", "Ru\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Gleich in Einsamleit zur\u00fcck,", "tokens": ["Gleich", "in", "Ein\u00b7sam\u00b7leit", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil das Gl\u00fcck,", "tokens": ["Weil", "das", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Deine Stelle zu bedienen,", "tokens": ["Dei\u00b7ne", "Stel\u00b7le", "zu", "be\u00b7die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unser keinem noch geschienen,", "tokens": ["Un\u00b7ser", "kei\u00b7nem", "noch", "ge\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Der gesegne dir den Schlaff, du gehst fr\u00fch genung zur Ruhe,", "tokens": ["Der", "ge\u00b7seg\u00b7ne", "dir", "den", "Schlaff", ",", "du", "gehst", "fr\u00fch", "ge\u00b7nung", "zur", "Ru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Deine Schuhe", "tokens": ["Dei\u00b7ne", "Schu\u00b7he"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Sind nicht durch den langen Weg,", "tokens": ["Sind", "nicht", "durch", "den", "lan\u00b7gen", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Rauhen Steg,", "tokens": ["Rau\u00b7hen", "Steg", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Noch vom Alter abgerissen,", "tokens": ["Noch", "vom", "Al\u00b7ter", "ab\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Jesus wird die Ursach wissen,", "tokens": ["Je\u00b7sus", "wird", "die", "Ur\u00b7sach", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df er dich zu Bette legt.", "tokens": ["Da\u00df", "er", "dich", "zu", "Bet\u00b7te", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Dancke unserm lieben HErrn, den die heilgen Seelen droben", "tokens": ["Dan\u00b7cke", "un\u00b7serm", "lie\u00b7ben", "Herrn", ",", "den", "die", "heil\u00b7gen", "See\u00b7len", "dro\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Jmmer loben,", "tokens": ["Jm\u00b7mer", "lo\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Was man kan:)", "tokens": ["Was", "man", "kan", ":)"], "token_info": ["word", "word", "word", "emoticon"], "pos": ["PWS", "PIS", "VMFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Dancke Jhm, da\u00df unsre Jugend", "tokens": ["Dan\u00b7cke", "Jhm", ",", "da\u00df", "uns\u00b7re", "Ju\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deinem Glauben, deiner Tugend", "tokens": ["Dei\u00b7nem", "Glau\u00b7ben", ",", "dei\u00b7ner", "Tu\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nachzufolgen lieb gewann.", "tokens": ["Nach\u00b7zu\u00b7fol\u00b7gen", "lieb", "ge\u00b7wann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Nun, du zartes Knaben-Volck, la\u00df dich doch zu Christi Sitten", "tokens": ["Nun", ",", "du", "zar\u00b7tes", "Kna\u00b7ben\u00b7Volck", ",", "la\u00df", "dich", "doch", "zu", "Chris\u00b7ti", "Sit\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "ADJA", "NN", "$,", "VVIMP", "PPER", "ADV", "APPR", "NE", "NN"], "meter": "--+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Fr\u00fch erbitten,", "tokens": ["Fr\u00fch", "er\u00b7bit\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dencke, da\u00df es JEsus Christ", "tokens": ["Den\u00b7cke", ",", "da\u00df", "es", "Je\u00b7sus", "Christ"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fcrdig ist,", "tokens": ["W\u00fcr\u00b7dig", "ist", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Wer, wie unser ", "tokens": ["Wer", ",", "wie", "un\u00b7ser"], "token_info": ["word", "punct", "word", "word"], "pos": ["PWS", "$,", "PWAV", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Wird, wie er, ins Licht erh\u00f6het,", "tokens": ["Wird", ",", "wie", "er", ",", "ins", "Licht", "er\u00b7h\u00f6\u00b7het", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und zum Hochzeit-Fest ger\u00fcst.", "tokens": ["Und", "zum", "Hoch\u00b7zeit\u00b7Fest", "ge\u00b7r\u00fcst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}