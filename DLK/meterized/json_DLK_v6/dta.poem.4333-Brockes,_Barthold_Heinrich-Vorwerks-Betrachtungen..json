{"dta.poem.4333": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Vorwerks-Betrachtungen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wie j\u00fcngst, im sp\u00e4ten Februar,", "tokens": ["Wie", "j\u00fcngst", ",", "im", "sp\u00e4\u00b7ten", "Feb\u00b7ru\u00b7ar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Winde still, das Wetter lieblich war,", "tokens": ["Die", "Win\u00b7de", "still", ",", "das", "Wet\u00b7ter", "lieb\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bing ich, mit aufger\u00e4umtem Sinn,", "tokens": ["Bing", "ich", ",", "mit", "auf\u00b7ge\u00b7r\u00e4um\u00b7tem", "Sinn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach meinem Vorwerk, um zu sehn", "tokens": ["Nach", "mei\u00b7nem", "Vor\u00b7werk", ",", "um", "zu", "sehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUI", "PTKZU", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Dinge, die daselbst, zur Winters-Zeit, geschehn,", "tokens": ["Die", "Din\u00b7ge", ",", "die", "da\u00b7selbst", ",", "zur", "Win\u00b7ter\u00b7sZeit", ",", "ge\u00b7schehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PAV", "$,", "APPRART", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nebst meinen Kindern, hin.", "tokens": ["Nebst", "mei\u00b7nen", "Kin\u00b7dern", ",", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da wir denn unterwegs, und eh wir nahe kamen,", "tokens": ["Da", "wir", "denn", "un\u00b7ter\u00b7wegs", ",", "und", "eh", "wir", "na\u00b7he", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "$,", "KON", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "bereits, mit Lust, in nett getheilter Zeit,", "tokens": ["be\u00b7reits", ",", "mit", "Lust", ",", "in", "nett", "ge\u00b7theil\u00b7ter", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "NN", "$,", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "In unzertrennt- und fester Richtigkeit,", "tokens": ["In", "un\u00b7zer\u00b7trennt", "und", "fes\u00b7ter", "Rich\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Der regen Drescher Tact vernahmen.", "tokens": ["Der", "re\u00b7gen", "Dre\u00b7scher", "Tact", "ver\u00b7nah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Der, ob sich gleich zum Ton kein s\u00fcsser Wechsel f\u00fcgte,", "tokens": ["Der", ",", "ob", "sich", "gleich", "zum", "Ton", "kein", "s\u00fcs\u00b7ser", "Wech\u00b7sel", "f\u00fcg\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PRF", "ADV", "APPRART", "NN", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "uns dennoch ungemein vergn\u00fcgte.", "tokens": ["uns", "den\u00b7noch", "un\u00b7ge\u00b7mein", "ver\u00b7gn\u00fcg\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Zumahl wir unsern Schritt zum Vorwerk selber kehrten,", "tokens": ["Zu\u00b7mahl", "wir", "un\u00b7sern", "Schritt", "zum", "Vor\u00b7werk", "sel\u00b7ber", "kehr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPRART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "da wir sie dreschen sahn und h\u00f6rten.", "tokens": ["da", "wir", "sie", "dre\u00b7schen", "sahn", "und", "h\u00f6r\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich dachte der Music ein wenig weiter nach,", "tokens": ["Ich", "dach\u00b7te", "der", "Mu\u00b7sic", "ein", "we\u00b7nig", "wei\u00b7ter", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "PIS", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und fand, da\u00df, bey dem richtigen Tactiren,", "tokens": ["und", "fand", ",", "da\u00df", ",", "bey", "dem", "rich\u00b7ti\u00b7gen", "Tac\u00b7ti\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und ordentlichen Musiciren,", "tokens": ["und", "or\u00b7dent\u00b7li\u00b7chen", "Mu\u00b7si\u00b7ci\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur blo\u00df der Text gebrach.", "tokens": ["Nur", "blo\u00df", "der", "Text", "ge\u00b7brach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Daher ich, bey dem abgeme\u00dfnen Klang,", "tokens": ["Da\u00b7her", "ich", ",", "bey", "dem", "ab\u00b7ge\u00b7me\u00df\u00b7nen", "Klang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "ihr n\u00fctzlich Werk, wie folgt, besang:", "tokens": ["ihr", "n\u00fctz\u00b7lich", "Werk", ",", "wie", "folgt", ",", "be\u00b7sang", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "PWAV", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u201cbem\u00fcht euch, mit wichtigen, richtigen Schl\u00e4gen", "tokens": ["\u201c", "be\u00b7m\u00fcht", "euch", ",", "mit", "wich\u00b7ti\u00b7gen", ",", "rich\u00b7ti\u00b7gen", "Schl\u00e4\u00b7gen"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "$,", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "\u201edie springende K\u00f6rner, den himmlischen Segen,", "tokens": ["\u201e", "die", "sprin\u00b7gen\u00b7de", "K\u00f6r\u00b7ner", ",", "den", "himm\u00b7li\u00b7schen", "Se\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u201ejhr Drescher, aus ihren Beh\u00e4ltern zu bringen!", "tokens": ["\u201e", "jhr", "Dre\u00b7scher", ",", "aus", "ih\u00b7ren", "Be\u00b7h\u00e4l\u00b7tern", "zu", "brin\u00b7gen", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "\u201ewir wollen den g\u00fctigen Geber besingen!", "tokens": ["\u201e", "wir", "wol\u00b7len", "den", "g\u00fc\u00b7ti\u00b7gen", "Ge\u00b7ber", "be\u00b7sin\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "\u201eauf, la\u00dft uns den trocknen und fruchtbaren Regen,", "tokens": ["\u201e", "auf", ",", "la\u00dft", "uns", "den", "trock\u00b7nen", "und", "frucht\u00b7ba\u00b7ren", "Re\u00b7gen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "VVIMP", "PPER", "ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "+---+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "\u201eden euer Bewegen erreget, erwegen!", "tokens": ["\u201e", "den", "eu\u00b7er", "Be\u00b7we\u00b7gen", "er\u00b7re\u00b7get", ",", "er\u00b7we\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "\u201ees ist von den h\u00fcpfenden Fr\u00fcchten der Aehren", "tokens": ["\u201e", "es", "ist", "von", "den", "h\u00fcp\u00b7fen\u00b7den", "Fr\u00fcch\u00b7ten", "der", "A\u00b7eh\u00b7ren"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "\u201eein zischend- und raschelndes Rauschen zu h\u00f6ren.", "tokens": ["\u201e", "ein", "zi\u00b7schen\u00b7d", "und", "ra\u00b7scheln\u00b7des", "Rau\u00b7schen", "zu", "h\u00f6\u00b7ren", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "TRUNC", "KON", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "\u201ees zeigt uns das hurtige Schwingen und Klopfen", "tokens": ["\u201e", "es", "zeigt", "uns", "das", "hur\u00b7ti\u00b7ge", "Schwin\u00b7gen", "und", "Klop\u00b7fen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "\u201ezu n\u00e4hrenden K\u00f6rnern gewordene Tropfen.", "tokens": ["\u201e", "zu", "n\u00e4h\u00b7ren\u00b7den", "K\u00f6r\u00b7nern", "ge\u00b7wor\u00b7de\u00b7ne", "Trop\u00b7fen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u201edie Tropfen des Regens, an ihnen beklieben,", "tokens": ["\u201e", "die", "Trop\u00b7fen", "des", "Re\u00b7gens", ",", "an", "ih\u00b7nen", "be\u00b7klie\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "$,", "APPR", "PPER", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "\u201edurch W\u00e4rme der Sonnen in Aehren getrieben,", "tokens": ["\u201e", "durch", "W\u00e4r\u00b7me", "der", "Son\u00b7nen", "in", "A\u00b7eh\u00b7ren", "ge\u00b7trie\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "\u201esind, da sie die K\u00f6rner getr\u00e4nkt und ern\u00e4hret,", "tokens": ["\u201e", "sind", ",", "da", "sie", "die", "K\u00f6r\u00b7ner", "ge\u00b7tr\u00e4nkt", "und", "er\u00b7n\u00e4h\u00b7ret", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "KON", "VVFIN", "$,"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u201eo Wunder! in n\u00e4hrende K\u00f6rner verkehret.", "tokens": ["\u201e", "o", "Wun\u00b7der", "!", "in", "n\u00e4h\u00b7ren\u00b7de", "K\u00f6r\u00b7ner", "ver\u00b7keh\u00b7ret", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$.", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "\u201ees liefert uns euer gesch\u00e4ftig Betragen,", "tokens": ["\u201e", "es", "lie\u00b7fert", "uns", "eu\u00b7er", "ge\u00b7sch\u00e4f\u00b7tig", "Be\u00b7tra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "\u201edas hurtige Schwingen, das kr\u00e4ftige Schlagen,", "tokens": ["\u201e", "das", "hur\u00b7ti\u00b7ge", "Schwin\u00b7gen", ",", "das", "kr\u00e4f\u00b7ti\u00b7ge", "Schla\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.9": {"text": "\u201edie Sch\u00e4tze, wornach uns so lange verlanget,", "tokens": ["\u201e", "die", "Sch\u00e4t\u00b7ze", ",", "wor\u00b7nach", "uns", "so", "lan\u00b7ge", "ver\u00b7lan\u00b7get", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "\u201emit welchen bishero die Felder gepranget,", "tokens": ["\u201e", "mit", "wel\u00b7chen", "bis\u00b7he\u00b7ro", "die", "Fel\u00b7der", "ge\u00b7pran\u00b7get", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PWAT", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "\u201edie n\u00f6htigsten, n\u00fctzlichsten, edelsten Gaben,", "tokens": ["\u201e", "die", "n\u00f6h\u00b7tigs\u00b7ten", ",", "n\u00fctz\u00b7lichs\u00b7ten", ",", "e\u00b7dels\u00b7ten", "Ga\u00b7ben", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "$,", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.12": {"text": "\u201ewomit wir uns n\u00e4hren, erhalten und laben.", "tokens": ["\u201e", "wo\u00b7mit", "wir", "uns", "n\u00e4h\u00b7ren", ",", "er\u00b7hal\u00b7ten", "und", "la\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "PRF", "VVINF", "$,", "VVPP", "KON", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.13": {"text": "\u201eauf, la\u00dft uns dem Geber uns dankbar erweisen!", "tokens": ["\u201e", "auf", ",", "la\u00dft", "uns", "dem", "Ge\u00b7ber", "uns", "dank\u00b7bar", "er\u00b7wei\u00b7sen", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "VVIMP", "PPER", "ART", "NN", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "\u201eauf, la\u00dft uns, in unserm Bewundern, Jhn preisen!", "tokens": ["\u201e", "auf", ",", "la\u00dft", "uns", ",", "in", "un\u00b7serm", "Be\u00b7wun\u00b7dern", ",", "Jhn", "prei\u00b7sen", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "VVIMP", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "\u201eauf, lasset Sein liebreich- und weises Regieren,", "tokens": ["\u201e", "auf", ",", "las\u00b7set", "Sein", "lieb\u00b7reich", "und", "wei\u00b7ses", "Re\u00b7gie\u00b7ren", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "VVFIN", "PPOSAT", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.16": {"text": "\u201ejm frohen Geniessen, zur Andacht uns f\u00fchren!", "tokens": ["\u201e", "jm", "fro\u00b7hen", "Ge\u00b7nies\u00b7sen", ",", "zur", "An\u00b7dacht", "uns", "f\u00fch\u00b7ren", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "$,", "APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.17": {"text": "\u201eauf, la\u00dft uns Sein\u2019 Allmacht, als Menschen, ermessen!", "tokens": ["\u201e", "auf", ",", "la\u00dft", "uns", "Sein'", "All\u00b7macht", ",", "als", "Men\u00b7schen", ",", "er\u00b7mes\u00b7sen", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "VVIMP", "PPER", "PPOSAT", "NN", "$,", "KOUS", "NN", "$,", "VVPP", "$."], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.18": {"text": "\u201eso k\u00f6nnen wir hoffen, mit G\u00fchtern der Erden", "tokens": ["\u201e", "so", "k\u00f6n\u00b7nen", "wir", "hof\u00b7fen", ",", "mit", "G\u00fch\u00b7tern", "der", "Er\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVFIN", "$,", "APPR", "NN", "ART", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.19": {"text": "\u201eauch k\u00fcnftig und \u00f6fters gesegnet zu werden.", "tokens": ["\u201e", "auch", "k\u00fcnf\u00b7tig", "und", "\u00f6f\u00b7ters", "ge\u00b7seg\u00b7net", "zu", "wer\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "KON", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.5": {"line.1": {"text": "Nachhero liessen wir ihr ferneres Betragen", "tokens": ["Nach\u00b7he\u00b7ro", "lies\u00b7sen", "wir", "ihr", "fer\u00b7ne\u00b7res", "Be\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Mit dem gedroschnen Korn uns nach der Reihe sagen.", "tokens": ["Mit", "dem", "ge\u00b7drosc\u00b7hnen", "Korn", "uns", "nach", "der", "Rei\u00b7he", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da ich denn fast erschrack, da\u00df so gar vielerley,", "tokens": ["Da", "ich", "denn", "fast", "er\u00b7schrack", ",", "da\u00df", "so", "gar", "vie\u00b7ler\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,", "KOUS", "ADV", "ADV", "PIAT", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An Werkzeug und an M\u00fch, hiezu noch n\u00f6htig sey.", "tokens": ["An", "Werk\u00b7zeug", "und", "an", "M\u00fch", ",", "hie\u00b7zu", "noch", "n\u00f6h\u00b7tig", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,", "PAV", "ADV", "ADJD", "VAFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Denn, ausser ", "tokens": ["Denn", ",", "aus\u00b7ser"], "token_info": ["word", "punct", "word"], "pos": ["KON", "$,", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "fangs anzulegen,", "tokens": ["fangs", "an\u00b7zu\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVIZU", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Und da\u00df, wenn zweymahl zugedroschen, die ", "tokens": ["Und", "da\u00df", ",", "wenn", "zwey\u00b7mahl", "zu\u00b7ge\u00b7dro\u00b7schen", ",", "die"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "KOUS", "$,", "KOUS", "ADV", "VVPP", "$,", "PRELS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "abzureissen pflegen;", "tokens": ["ab\u00b7zu\u00b7reis\u00b7sen", "pfle\u00b7gen", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVIZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Wird es mit ", "tokens": ["Wird", "es", "mit"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "zugeschlagen,", "tokens": ["zu\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "Denn mit den Gaffeln aufgesch\u00fcttelt, wodurch der K\u00f6rner", "tokens": ["Denn", "mit", "den", "Gaf\u00b7feln", "auf\u00b7ge\u00b7sch\u00fct\u00b7telt", ",", "wo\u00b7durch", "der", "K\u00f6r\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Ueberrest", "tokens": ["Ue\u00b7ber\u00b7rest"], "token_info": ["word"], "pos": ["NN"], "meter": "+--", "measure": "dactylic.init"}, "line.13": {"text": "Sich vollend aus den Aehren bringen und zu den andern", "tokens": ["Sich", "vol\u00b7lend", "aus", "den", "A\u00b7eh\u00b7ren", "brin\u00b7gen", "und", "zu", "den", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "VVINF", "KON", "APPR", "ART", "ADJA"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "f\u00fcgen l\u00e4\u00dft.", "tokens": ["f\u00fc\u00b7gen", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Das leere Stroh bleibt f\u00fcr das Vieh, und wird demselben", "tokens": ["Das", "lee\u00b7re", "Stroh", "bleibt", "f\u00fcr", "das", "Vieh", ",", "und", "wird", "dem\u00b7sel\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "vorgetragen.", "tokens": ["vor\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Hierauf ergreifen sie die ", "tokens": ["Hier\u00b7auf", "er\u00b7grei\u00b7fen", "sie", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "zu Hauf,", "tokens": ["zu", "Hauf", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Was auf der Diehl\u2019 gedroschen liegt, und schlagen denn", "tokens": ["Was", "auf", "der", "Diehl'", "ge\u00b7dro\u00b7schen", "liegt", ",", "und", "schla\u00b7gen", "denn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "VVINF", "VVFIN", "$,", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "von neuem drauf,", "tokens": ["von", "neu\u00b7em", "drauf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Beym Gersten nehmlich, um die Spitzen von ihren K\u00f6r-", "tokens": ["Beym", "Gers\u00b7ten", "nehm\u00b7lich", ",", "um", "die", "Spit\u00b7zen", "von", "ih\u00b7ren", "K\u00f6r"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "$,", "KOUI", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "nern abzutrennen,", "tokens": ["nern", "ab\u00b7zu\u00b7tren\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVIZU", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "So denn mit wenig M\u00fch\u2019 geschicht, und welches Werk", "tokens": ["So", "denn", "mit", "we\u00b7nig", "M\u00fch'", "ge\u00b7schicht", ",", "und", "wel\u00b7ches", "Werk"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PIAT", "NN", "VVPP", "$,", "KON", "PWAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "sie Baaken nennen.", "tokens": ["sie", "Baa\u00b7ken", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Denn wird die Harke rechts gekehrt, und umgeharket.", "tokens": ["Denn", "wird", "die", "Har\u00b7ke", "rechts", "ge\u00b7kehrt", ",", "und", "um\u00b7ge\u00b7har\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dann der Besen", "tokens": ["Dann", "der", "Be\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "(der von besonderer Figur, wozu ein lauges Kraut erlesen,", "tokens": ["(", "der", "von", "be\u00b7son\u00b7de\u00b7rer", "Fi\u00b7gur", ",", "wo\u00b7zu", "ein", "lau\u00b7ges", "Kraut", "er\u00b7le\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "APPR", "ADJA", "NN", "$,", "PWAV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.14": {"text": "Und welchen man den ", "tokens": ["Und", "wel\u00b7chen", "man", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWAT", "PIS", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.15": {"text": "und her gedreht,", "tokens": ["und", "her", "ge\u00b7dreht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Dadurch wird die zu grobe Spreu davon gest\u00e4ubet, weg-", "tokens": ["Da\u00b7durch", "wird", "die", "zu", "gro\u00b7be", "Spreu", "da\u00b7von", "ge\u00b7st\u00e4u\u00b7bet", ",", "weg"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PAV", "VAFIN", "ART", "PTKZU", "ADJA", "NN", "PAV", "VVPP", "$,", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.17": {"text": "geweht.", "tokens": ["ge\u00b7weht", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.18": {"text": "Dann schiebt man es auf einen Haufen, und kehrt die ganze", "tokens": ["Dann", "schiebt", "man", "es", "auf", "ei\u00b7nen", "Hau\u00b7fen", ",", "und", "kehrt", "die", "gan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Tenne rein,", "tokens": ["Ten\u00b7ne", "rein", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "Ergreifet eine kleine Schaufel, und worfelt alles, kann", "tokens": ["Er\u00b7grei\u00b7fet", "ei\u00b7ne", "klei\u00b7ne", "Schau\u00b7fel", ",", "und", "wor\u00b7felt", "al\u00b7les", ",", "kann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "KON", "VVFIN", "PIS", "$,", "VMFIN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.21": {"text": "es seyn", "tokens": ["es", "seyn"], "token_info": ["word", "word"], "pos": ["PPER", "VAINF"], "meter": "-+", "measure": "iambic.single"}, "line.22": {"text": "Dahin, woher der Wind entsteht, da alle K\u00f6rner, welche", "tokens": ["Da\u00b7hin", ",", "wo\u00b7her", "der", "Wind", "ent\u00b7steht", ",", "da", "al\u00b7le", "K\u00f6r\u00b7ner", ",", "wel\u00b7che"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PAV", "$,", "PWAV", "ART", "NN", "VVFIN", "$,", "KOUS", "PIAT", "NN", "$,", "PRELS"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.23": {"text": "schwehr,", "tokens": ["schwehr", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.24": {"text": "Durch ihnen eingedr\u00fcckte Kraft des Werfens, denn am", "tokens": ["Durch", "ih\u00b7nen", "ein\u00b7ge\u00b7dr\u00fcck\u00b7te", "Kraft", "des", "Wer\u00b7fens", ",", "denn", "am"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "ADJA", "NN", "ART", "NN", "$,", "KON", "APPRART"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "weitsten fliegen;", "tokens": ["weits\u00b7ten", "flie\u00b7gen", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.26": {"text": "Die leichtern aber, und die Spreu, die von verbundnen", "tokens": ["Die", "leich\u00b7tern", "a\u00b7ber", ",", "und", "die", "Spreu", ",", "die", "von", "ver\u00b7bund\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "$,", "KON", "ART", "NN", "$,", "PRELS", "APPR", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Theilen leer,", "tokens": ["Thei\u00b7len", "leer", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.28": {"text": "Durch ihnen widerstehnde Luft gehindert, bleiben nahe liegen.", "tokens": ["Durch", "ih\u00b7nen", "wi\u00b7der\u00b7stehn\u00b7de", "Luft", "ge\u00b7hin\u00b7dert", ",", "blei\u00b7ben", "na\u00b7he", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJA", "NN", "VVPP", "$,", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.29": {"text": "Wodurch, da ich dies \u00fcberdachte, ich in demselben Au-", "tokens": ["Wo\u00b7durch", ",", "da", "ich", "dies", "\u00fc\u00b7berd\u00b7ach\u00b7te", ",", "ich", "in", "dem\u00b7sel\u00b7ben", "Au"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "PPER", "PDS", "VVFIN", "$,", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.30": {"text": "genblick", "tokens": ["gen\u00b7blick"], "token_info": ["word"], "pos": ["XY"], "meter": "-+", "measure": "iambic.single"}, "line.31": {"text": "Mein forschend Denken weiter triebe, noch mehr zu denken", "tokens": ["Mein", "for\u00b7schend", "Den\u00b7ken", "wei\u00b7ter", "trie\u00b7be", ",", "noch", "mehr", "zu", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "VVPP", "NN", "ADV", "VVFIN", "$,", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.32": {"text": "Anla\u00df nahm,", "tokens": ["An\u00b7la\u00df", "nahm", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Und von der Schwer\u2019 in der Natur auf eine neue Probe", "tokens": ["Und", "von", "der", "Schwer'", "in", "der", "Na\u00b7tur", "auf", "ei\u00b7ne", "neu\u00b7e", "Pro\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "kam,", "tokens": ["kam", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Da\u00df nemlich auf dieselbe Art erweislich, wie aus einem", "tokens": ["Da\u00df", "nem\u00b7lich", "auf", "die\u00b7sel\u00b7be", "Art", "er\u00b7weis\u00b7lich", ",", "wie", "aus", "ei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PDAT", "NN", "ADJD", "$,", "PWAV", "APPR", "ART"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "St\u00fcck", "tokens": ["St\u00fcck"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Ein schwehrer Eisen weiter fliegt, als wie ein anders,", "tokens": ["Ein", "schweh\u00b7rer", "Ei\u00b7sen", "wei\u00b7ter", "fliegt", ",", "als", "wie", "ein", "an\u00b7ders", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "$,", "KOUS", "KOKOM", "ART", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "welches klein.", "tokens": ["wel\u00b7ches", "klein", "."], "token_info": ["word", "word", "punct"], "pos": ["PWS", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Ja da\u00df, nach eben dem Gesetz in der Natur, auch unsre", "tokens": ["Ja", "da\u00df", ",", "nach", "e\u00b7ben", "dem", "Ge\u00b7setz", "in", "der", "Na\u00b7tur", ",", "auch", "uns\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "KOUS", "$,", "APPR", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,", "ADV", "PPOSAT"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.8": {"text": "Erde,", "tokens": ["Er\u00b7de", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Die gr\u00f6sser, als Mercur und Venus, um unsre Sonnen-", "tokens": ["Die", "gr\u00f6s\u00b7ser", ",", "als", "Mer\u00b7cur", "und", "Ve\u00b7nus", ",", "um", "uns\u00b7re", "Son\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "KOUS", "NN", "KON", "NN", "$,", "KOUI", "PPOSAT", "TRUNC"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Gluht und Schein,", "tokens": ["Gluht", "und", "Schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "In einem mehr entfernten Cirkel, gehalten und gedrehet", "tokens": ["In", "ei\u00b7nem", "mehr", "ent\u00b7fern\u00b7ten", "Cir\u00b7kel", ",", "ge\u00b7hal\u00b7ten", "und", "ge\u00b7dre\u00b7het"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "ADJA", "NN", "$,", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "werde.", "tokens": ["wer\u00b7de", "."], "token_info": ["word", "punct"], "pos": ["VAFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.8": {"line.1": {"text": "Nachher wird das Getrayde denn aufs neu auf einen", "tokens": ["Nach\u00b7her", "wird", "das", "Ge\u00b7tray\u00b7de", "denn", "aufs", "neu", "auf", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "APPRART", "ADJD", "APPR", "ART"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Haufen bracht,", "tokens": ["Hau\u00b7fen", "bracht", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und durch ein neues Instrument, die Harpe, die aus", "tokens": ["Und", "durch", "ein", "neu\u00b7es", "Inst\u00b7ru\u00b7ment", ",", "die", "Har\u00b7pe", ",", "die", "aus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "PRELS", "APPR"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Draht gemacht,", "tokens": ["Draht", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "(wor\u00fcber man es laufen l\u00e4\u00dft) von Spreu geschieden und", "tokens": ["(", "wo\u00b7r\u00fc\u00b7ber", "man", "es", "lau\u00b7fen", "l\u00e4\u00dft", ")", "von", "Spreu", "ge\u00b7schie\u00b7den", "und"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PIS", "PPER", "VVINF", "VVFIN", "$(", "APPR", "NN", "VVPP", "KON"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "gesichtet,", "tokens": ["ge\u00b7sich\u00b7tet", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Darauf gemessen, und in S\u00e4cken gegossen. Hiemit ist", "tokens": ["Da\u00b7rauf", "ge\u00b7mes\u00b7sen", ",", "und", "in", "S\u00e4\u00b7cken", "ge\u00b7gos\u00b7sen", ".", "Hie\u00b7mit", "ist"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "VVPP", "$,", "KON", "APPR", "NN", "VVPP", "$.", "ADV", "VAFIN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "verrichtet", "tokens": ["ver\u00b7rich\u00b7tet"], "token_info": ["word"], "pos": ["VVPP"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Das grosse Wunder-volle Werk, wodurch der Sch\u00f6pfer", "tokens": ["Das", "gros\u00b7se", "Wun\u00b7der\u00b7vol\u00b7le", "Werk", ",", "wo\u00b7durch", "der", "Sch\u00f6p\u00b7fer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "auf der Welt", "tokens": ["auf", "der", "Welt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "Das ganze menschliche Geschlecht, ja auch so gar das", "tokens": ["Das", "gan\u00b7ze", "menschli\u00b7che", "Ge\u00b7schlecht", ",", "ja", "auch", "so", "gar", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "ADV", "ADV", "ADV", "ADV", "ART"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Vieh erh\u00e4lt.", "tokens": ["Vieh", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Ist auf der gauzen Welt ein Werk mehr Dankens und", "tokens": ["Ist", "auf", "der", "gau\u00b7zen", "Welt", "ein", "Werk", "mehr", "Dan\u00b7kens", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ART", "NN", "PIAT", "NN", "KON"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Betrachtung wehrt,", "tokens": ["Be\u00b7trach\u00b7tung", "wehrt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Worinn mehr Nutzen und mehr Segen? Sprecht selbst,", "tokens": ["Wo\u00b7rinn", "mehr", "Nut\u00b7zen", "und", "mehr", "Se\u00b7gen", "?", "Sprecht", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "KON", "PIAT", "NN", "$.", "NN", "ADV", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "geliebte Menschen, sprecht!", "tokens": ["ge\u00b7lieb\u00b7te", "Men\u00b7schen", ",", "sprecht", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "H\u00e4ngt euer Leben nicht daran? Thut ihr denn wohl? Ist", "tokens": ["H\u00e4ngt", "eu\u00b7er", "Le\u00b7ben", "nicht", "da\u00b7ran", "?", "Thut", "ihr", "denn", "wohl", "?", "Ist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "PAV", "$.", "NE", "PPER", "ADV", "ADV", "$.", "VAFIN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "es denn recht,", "tokens": ["es", "denn", "recht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Da\u00df man, f\u00fcr solch ein heilsam Wunder des Sch\u00f6pfers, nicht", "tokens": ["Da\u00df", "man", ",", "f\u00fcr", "solch", "ein", "heil\u00b7sam", "Wun\u00b7der", "des", "Sch\u00f6p\u00b7fers", ",", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PIS", "$,", "APPR", "PIAT", "ART", "ADJD", "NN", "ART", "NN", "$,", "PTKNEG"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "den Sch\u00f6pfer ehrt?", "tokens": ["den", "Sch\u00f6p\u00b7fer", "ehrt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Da\u00df, wenn wir den von Seiner Gunst so oft, so oft erbetnen", "tokens": ["Da\u00df", ",", "wenn", "wir", "den", "von", "Sei\u00b7ner", "Gunst", "so", "oft", ",", "so", "oft", "er\u00b7bet\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ART", "APPR", "PPOSAT", "NN", "ADV", "ADV", "$,", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Segen", "tokens": ["Se\u00b7gen"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Nun wirklich auf den Boden sch\u00fctten, wir weiter nichts", "tokens": ["Nun", "wirk\u00b7lich", "auf", "den", "Bo\u00b7den", "sch\u00fct\u00b7ten", ",", "wir", "wei\u00b7ter", "nichts"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,", "PPER", "ADV", "PIS"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "davon erwegen,", "tokens": ["da\u00b7von", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Als nur ein frostiges GOtt-Lob, das gleichsam auf den Lip-", "tokens": ["Als", "nur", "ein", "fros\u00b7ti\u00b7ges", "Got\u00b7tLob", ",", "das", "gleich\u00b7sam", "auf", "den", "Lip"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "pen friert,", "tokens": ["pen", "friert", ","], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Und wobey man noch meistens gar ein bitter Denken heimlich", "tokens": ["Und", "wo\u00b7bey", "man", "noch", "meis\u00b7tens", "gar", "ein", "bit\u00b7ter", "Den\u00b7ken", "heim\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIS", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "ADJD"], "meter": "-++--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "sp\u00fchrt:", "tokens": ["sp\u00fchrt", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}, "line.9": {"text": "Da\u00df, w\u00e4r auch gleich der Boden voll von reinem Korn, ein", "tokens": ["Da\u00df", ",", "w\u00e4r", "auch", "gleich", "der", "Bo\u00b7den", "voll", "von", "rei\u00b7nem", "Korn", ",", "ein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "$,", "VAFIN", "ADV", "ADV", "ART", "NN", "ADJD", "APPR", "ADJA", "NN", "$,", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "wenig mehr", "tokens": ["we\u00b7nig", "mehr"], "token_info": ["word", "word"], "pos": ["ADV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "Von Rocken und zumahl von Weizen dennoch ein wenig", "tokens": ["Von", "Ro\u00b7cken", "und", "zu\u00b7mahl", "von", "Wei\u00b7zen", "den\u00b7noch", "ein", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADV", "APPR", "NN", "ADV", "ART", "PIS"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "besser w\u00e4r.", "tokens": ["bes\u00b7ser", "w\u00e4r", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Wahrhaftig es besch\u00e4men uns in diesem St\u00fccke ja die", "tokens": ["Wahr\u00b7haf\u00b7tig", "es", "be\u00b7sch\u00e4\u00b7men", "uns", "in", "die\u00b7sem", "St\u00fc\u00b7cke", "ja", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "PPER", "VVFIN", "PPER", "APPR", "PDAT", "NN", "ADV", "ART"], "meter": "-+-+-+-+-+-+-++", "measure": "unknown.measure.octa.plus"}, "line.14": {"text": "Heyden", "tokens": ["Hey\u00b7den"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.15": {"text": "Durch ihre, den vermeynten Gebern so sch\u00f6ner Frucht,", "tokens": ["Durch", "ih\u00b7re", ",", "den", "ver\u00b7meyn\u00b7ten", "Ge\u00b7bern", "so", "sch\u00f6\u00b7ner", "Frucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "$,", "ART", "ADJA", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "geweihte Freuden.", "tokens": ["ge\u00b7weih\u00b7te", "Freu\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Vermeynt man denn im Christenthum die Pflicht, zu danken", "tokens": ["Ver\u00b7meynt", "man", "denn", "im", "Chris\u00b7ten\u00b7thum", "die", "Pflicht", ",", "zu", "dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "ART", "NN", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "und zu loben", "tokens": ["und", "zu", "lo\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["KON", "PTKZU", "VVINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.19": {"text": "Den grossen Geber alles Guten, sey durch den Glauben auf-", "tokens": ["Den", "gros\u00b7sen", "Ge\u00b7ber", "al\u00b7les", "Gu\u00b7ten", ",", "sey", "durch", "den", "Glau\u00b7ben", "auf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "$,", "VAFIN", "APPR", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "gehoben.", "tokens": ["ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.11": {"line.1": {"text": "Hierauf besahen wir das Horn-Vieh mit Vergn\u00fcgen,", "tokens": ["Hier\u00b7auf", "be\u00b7sa\u00b7hen", "wir", "das", "Horn\u00b7Vieh", "mit", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das uns zur linken Hand,", "tokens": ["Das", "uns", "zur", "lin\u00b7ken", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In einer langen Reih\u2019, in netter Ordnung stand.", "tokens": ["In", "ei\u00b7ner", "lan\u00b7gen", "Reih'", ",", "in", "net\u00b7ter", "Ord\u00b7nung", "stand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir fanden es theils stehn, theils liegen,", "tokens": ["Wir", "fan\u00b7den", "es", "theils", "stehn", ",", "theils", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Theils k\u00e4u\u2019n, theils wiederk\u00e4u\u2019n. Ein emsiges Bewegen", "tokens": ["Theils", "k\u00e4u'n", ",", "theils", "wie\u00b7der\u00b7k\u00e4u'", "n.", "Ein", "em\u00b7si\u00b7ges", "Be\u00b7we\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "abbreviation", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des glatten Mauls, der Ohren sanftes Regen,", "tokens": ["Des", "glat\u00b7ten", "Mauls", ",", "der", "Oh\u00b7ren", "sanf\u00b7tes", "Re\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wobey sie dann und wann die schlanken Zungen", "tokens": ["Wo\u00b7bey", "sie", "dann", "und", "wann", "die", "schlan\u00b7ken", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "KON", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Zu beyden Seiten schwungen,", "tokens": ["Zu", "bey\u00b7den", "Sei\u00b7ten", "schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "War nur allein, sonst nichts bewegliches an ihnen", "tokens": ["War", "nur", "al\u00b7lein", ",", "sonst", "nichts", "be\u00b7weg\u00b7li\u00b7ches", "an", "ih\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "$,", "ADV", "PIS", "ADJA", "APPR", "PPER"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "(indem sie all\u2019 in recht zufriedner Ruh,", "tokens": ["(", "in\u00b7dem", "sie", "all'", "in", "recht", "zu\u00b7fried\u00b7ner", "Ruh", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PIS", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und einer sanften Stille schienen)", "tokens": ["Und", "ei\u00b7ner", "sanf\u00b7ten", "Stil\u00b7le", "schie\u00b7nen", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Zu sp\u00fchren und zu sehn. Wir sahen ihnen zu,", "tokens": ["Zu", "sp\u00fch\u00b7ren", "und", "zu", "sehn", ".", "Wir", "sa\u00b7hen", "ih\u00b7nen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Durch ihre Stille selbst zur Stille mit bewogen,", "tokens": ["Durch", "ih\u00b7re", "Stil\u00b7le", "selbst", "zur", "Stil\u00b7le", "mit", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "APPRART", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie sie das d\u00fcrre Stroh begierig zu sich zogen.", "tokens": ["Wie", "sie", "das", "d\u00fcr\u00b7re", "Stroh", "be\u00b7gie\u00b7rig", "zu", "sich", "zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "ADJD", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir sahen sie die langen Halmen", "tokens": ["Wir", "sa\u00b7hen", "sie", "die", "lan\u00b7gen", "Hal\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit regen Kiefern sanft zermalmen.", "tokens": ["Mit", "re\u00b7gen", "Kie\u00b7fern", "sanft", "zer\u00b7mal\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Das rauschende Gezisch, das knarschende Get\u00f6n,", "tokens": ["Das", "rau\u00b7schen\u00b7de", "Ge\u00b7zisch", ",", "das", "knar\u00b7schen\u00b7de", "Ge\u00b7t\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+---+-+---+", "measure": "dactylic.init"}, "line.6": {"text": "Mit welchem sie die d\u00fcrre Kost verzehren,", "tokens": ["Mit", "wel\u00b7chem", "sie", "die", "d\u00fcr\u00b7re", "Kost", "ver\u00b7zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "War ja so angenehm zu h\u00f6ren,", "tokens": ["War", "ja", "so", "an\u00b7ge\u00b7nehm", "zu", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als ihre Stellungen zu sehn.", "tokens": ["Als", "ih\u00b7re", "Stel\u00b7lun\u00b7gen", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.9": {"text": "Inzwischen kam, vor andern, mir", "tokens": ["I\u00b7nzwi\u00b7schen", "kam", ",", "vor", "an\u00b7dern", ",", "mir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "APPR", "PIS", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Jhr Futter sehr betr\u00e4chtlich f\u00fcr.", "tokens": ["Ihr", "Fut\u00b7ter", "sehr", "be\u00b7tr\u00e4cht\u00b7lich", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Das leer\u2019 und d\u00fcrre Stroh, dem Schein nach sonder Saft,", "tokens": ["Das", "leer'", "und", "d\u00fcr\u00b7re", "Stroh", ",", "dem", "Schein", "nach", "son\u00b7der", "Saft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hat in den leer- und trocknen R\u00f6hren,", "tokens": ["Hat", "in", "den", "leer", "und", "trock\u00b7nen", "R\u00f6h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "O Wunder! dennoch so viel Kraft,", "tokens": ["O", "Wun\u00b7der", "!", "den\u00b7noch", "so", "viel", "Kraft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.14": {"text": "So grosse Thiere zu ern\u00e4hren,", "tokens": ["So", "gros\u00b7se", "Thie\u00b7re", "zu", "er\u00b7n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ja ihre Frucht zugleich, und \u00fcberdem", "tokens": ["Ja", "ih\u00b7re", "Frucht", "zu\u00b7gleich", ",", "und", "\u00fc\u00b7ber\u00b7dem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "PPOSAT", "NN", "ADV", "$,", "KON", "ADJA"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Die s\u00fcsse Milch, die uns so angenehm,", "tokens": ["Die", "s\u00fcs\u00b7se", "Milch", ",", "die", "uns", "so", "an\u00b7ge\u00b7nehm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "In Ueberflu\u00df uns zu gew\u00e4hren.", "tokens": ["In", "Ue\u00b7berf\u00b7lu\u00df", "uns", "zu", "ge\u00b7w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Noch mehr, es wird ein Theil vom Stroh zu Mist,", "tokens": ["Noch", "mehr", ",", "es", "wird", "ein", "Theil", "vom", "Stroh", "zu", "Mist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Der wiederum zum Feld-Bau n\u00f6htig ist.", "tokens": ["Der", "wie\u00b7de\u00b7rum", "zum", "Feld\u00b7Bau", "n\u00f6h\u00b7tig", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Es kam mir dannenher ein solches Thier", "tokens": ["Es", "kam", "mir", "dan\u00b7nen\u00b7her", "ein", "sol\u00b7ches", "Thier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Als ein lebend\u2019ger Wage f\u00fcr,", "tokens": ["Als", "ein", "le\u00b7ben\u00b7d'\u00b7ger", "Wa\u00b7ge", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Der D\u00fcngung auf die Felder f\u00fchret.", "tokens": ["Der", "D\u00fcn\u00b7gung", "auf", "die", "Fel\u00b7der", "f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Ja, sie sind gleichsam anzusehn,", "tokens": ["Ja", ",", "sie", "sind", "gleich\u00b7sam", "an\u00b7zu\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Als unsre K\u00fcchen, welche gehn,", "tokens": ["Als", "uns\u00b7re", "K\u00fc\u00b7chen", ",", "wel\u00b7che", "gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "PRELS", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Als Kolben, worinn sich die Milch selbst distillirt.", "tokens": ["Als", "Kol\u00b7ben", ",", "wo\u00b7rinn", "sich", "die", "Milch", "selbst", "dis\u00b7til\u00b7lirt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PWAV", "PRF", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ich ward recht inniglich ger\u00fchrt", "tokens": ["Ich", "ward", "recht", "in\u00b7nig\u00b7lich", "ge\u00b7r\u00fchrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch die recht Wunder-volle Weise,", "tokens": ["Durch", "die", "recht", "Wun\u00b7der\u00b7vol\u00b7le", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wodurch, in einem steten Kreise,", "tokens": ["Wo\u00b7durch", ",", "in", "ei\u00b7nem", "ste\u00b7ten", "Krei\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der unsern Unterhalt gebiert,", "tokens": ["Der", "un\u00b7sern", "Un\u00b7ter\u00b7halt", "ge\u00b7biert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich Stroh in Mist, in Stroh, Mist circulirt,", "tokens": ["Sich", "Stroh", "in", "Mist", ",", "in", "Stroh", ",", "Mist", "cir\u00b7cu\u00b7lirt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "NE", "APPR", "NN", "$,", "APPR", "NN", "$,", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und im best\u00e4nd\u2019gen Wechsel ginge.", "tokens": ["Und", "im", "be\u00b7st\u00e4n\u00b7d'\u00b7gen", "Wech\u00b7sel", "gin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Anbehtungsw\u00fcrdiger Regierer aller Dinge!", "tokens": ["An\u00b7beh\u00b7tungs\u00b7w\u00fcr\u00b7di\u00b7ger", "Re\u00b7gie\u00b7rer", "al\u00b7ler", "Din\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie zeigt, da alles die\u00df so ordentlich,", "tokens": ["Wie", "zeigt", ",", "da", "al\u00b7les", "die\u00df", "so", "or\u00b7dent\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "KOUS", "PIS", "PDS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In unverr\u00fccktem Gang und Ordnung, gehet, Dich", "tokens": ["In", "un\u00b7ver\u00b7r\u00fcck\u00b7tem", "Gang", "und", "Ord\u00b7nung", ",", "ge\u00b7het", ",", "Dich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,", "VVFIN", "$,", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Deine weise Macht! fing ich, mit Ehrfurcht, an.", "tokens": ["Und", "Dei\u00b7ne", "wei\u00b7se", "Macht", "!", "fing", "ich", ",", "mit", "Ehr\u00b7furcht", ",", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$.", "VVFIN", "PPER", "$,", "APPR", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer ist, der dieses fassen kann?", "tokens": ["Wer", "ist", ",", "der", "die\u00b7ses", "fas\u00b7sen", "kann", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "PDAT", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jedoch mu\u00df unser Unverm\u00f6gen", "tokens": ["Je\u00b7doch", "mu\u00df", "un\u00b7ser", "Un\u00b7ver\u00b7m\u00f6\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Es zu begreifen uns nicht an dem Vorsatz hindern,", "tokens": ["Es", "zu", "be\u00b7grei\u00b7fen", "uns", "nicht", "an", "dem", "Vor\u00b7satz", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Noch unsre Schuldigkeit vermindern,", "tokens": ["Noch", "uns\u00b7re", "Schul\u00b7dig\u00b7keit", "ver\u00b7min\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Es, GOtt zum Ruhm, zu \u00fcberlegen,", "tokens": ["Es", ",", "Gott", "zum", "Ruhm", ",", "zu", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "APPRART", "NN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Weil wir durch nichts uns selbst in Gott erh\u00f6hn,", "tokens": ["Weil", "wir", "durch", "nichts", "uns", "selbst", "in", "Gott", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIS", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Als wenn wir Seiner Herrlichkeiten", "tokens": ["Als", "wenn", "wir", "Sei\u00b7ner", "Herr\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Nicht zu ergr\u00fcndende Vollkommenheiten", "tokens": ["Nicht", "zu", "er\u00b7gr\u00fcn\u00b7den\u00b7de", "Voll\u00b7kom\u00b7men\u00b7hei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "PTKZU", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "In den, durch seine Macht, gewirkten Werken sehn.", "tokens": ["In", "den", ",", "durch", "sei\u00b7ne", "Macht", ",", "ge\u00b7wirk\u00b7ten", "Wer\u00b7ken", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "APPR", "PPOSAT", "NN", "$,", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was mu\u00df es nicht, wenn man die\u00df \u00fcberdenket,", "tokens": ["Was", "mu\u00df", "es", "nicht", ",", "wenn", "man", "die\u00df", "\u00fc\u00b7ber\u00b7den\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PTKNEG", "$,", "KOUS", "PIS", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "F\u00fcr eine fremd\u2019 und sonderliche Kraft,", "tokens": ["F\u00fcr", "ei\u00b7ne", "fremd'", "und", "son\u00b7der\u00b7li\u00b7che", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "F\u00fcr ein Verm\u00f6gen seyn, und f\u00fcr ein\u2019 Eigenschaft,", "tokens": ["F\u00fcr", "ein", "Ver\u00b7m\u00f6\u00b7gen", "seyn", ",", "und", "f\u00fcr", "ein'", "Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAINF", "$,", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die in der Thiere Leib- und C\u00f6rper eingesenket,", "tokens": ["Die", "in", "der", "Thie\u00b7re", "Leib", "und", "C\u00f6r\u00b7per", "ein\u00b7ge\u00b7sen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "TRUNC", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df aus so trocknem Stoff, als wie das Stroh, sie k\u00f6nnen,", "tokens": ["Da\u00df", "aus", "so", "trock\u00b7nem", "Stoff", ",", "als", "wie", "das", "Stroh", ",", "sie", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADV", "ADJA", "NN", "$,", "KOUS", "KOKOM", "ART", "NN", "$,", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Durch ihres Magens Saft, durch ihrer Dr\u00fcsen Menge,", "tokens": ["Durch", "ih\u00b7res", "Ma\u00b7gens", "Saft", ",", "durch", "ih\u00b7rer", "Dr\u00fc\u00b7sen", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Durch so viel seltsamer geformten D\u00e4rmer G\u00e4nge,", "tokens": ["Durch", "so", "viel", "selt\u00b7sa\u00b7mer", "ge\u00b7form\u00b7ten", "D\u00e4r\u00b7mer", "G\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ADJD", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.21": {"text": "Die Theilgen von einander trennen,", "tokens": ["Die", "Theil\u00b7gen", "von", "ein\u00b7an\u00b7der", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Sie mischen, durch einander schlingen,", "tokens": ["Sie", "mi\u00b7schen", ",", "durch", "ein\u00b7an\u00b7der", "schlin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Und jedes eigentlich an solche Oerter bringen,", "tokens": ["Und", "je\u00b7des", "ei\u00b7gent\u00b7lich", "an", "sol\u00b7che", "O\u00b7er\u00b7ter", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADV", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+--++-+--+-", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Woselbst sie n\u00f6htig sind zu unserem Genu\u00df.", "tokens": ["Wo\u00b7selbst", "sie", "n\u00f6h\u00b7tig", "sind", "zu", "un\u00b7se\u00b7rem", "Ge\u00b7nu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da\u00df sie den unbrauchbar- und groben Ueberflu\u00df", "tokens": ["Da\u00df", "sie", "den", "un\u00b7brauch\u00b7ba\u00b7r", "und", "gro\u00b7ben", "Ue\u00b7berf\u00b7lu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Auf eine Weise von sich treiben,", "tokens": ["Auf", "ei\u00b7ne", "Wei\u00b7se", "von", "sich", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Da\u00df nur die n\u00f6htigen bey ihnen bleiben", "tokens": ["Da\u00df", "nur", "die", "n\u00f6h\u00b7ti\u00b7gen", "bey", "ih\u00b7nen", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Zu ihrem, ihrer Frucht und unserm Nutzen auch.", "tokens": ["Zu", "ih\u00b7rem", ",", "ih\u00b7rer", "Frucht", "und", "un\u00b7serm", "Nut\u00b7zen", "auch", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Da\u00df der verworfne Mist zum n\u00f6htigen Gebrauch,", "tokens": ["Da\u00df", "der", "ver\u00b7worf\u00b7ne", "Mist", "zum", "n\u00f6h\u00b7ti\u00b7gen", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die Aecker wiederum zu n\u00e4hren,", "tokens": ["Die", "A\u00b7e\u00b7cker", "wie\u00b7de\u00b7rum", "zu", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.31": {"text": "Um ihnen neue Kost best\u00e4ndig zu gewehren,", "tokens": ["Um", "ih\u00b7nen", "neu\u00b7e", "Kost", "be\u00b7st\u00e4n\u00b7dig", "zu", "ge\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "So heilsam dienen mu\u00df. Da\u00df uns dazu die Hand,", "tokens": ["So", "heil\u00b7sam", "die\u00b7nen", "mu\u00df", ".", "Da\u00df", "uns", "da\u00b7zu", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN", "$.", "KOUS", "PPER", "PAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Das Werkzeug, welches wohl recht zu bewundern wehrt,", "tokens": ["Das", "Werk\u00b7zeug", ",", "wel\u00b7ches", "wohl", "recht", "zu", "be\u00b7wun\u00b7dern", "wehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja, da\u00df insonderheit noch der Verstand,", "tokens": ["Ja", ",", "da\u00df", "in\u00b7son\u00b7der\u00b7heit", "noch", "der", "Ver\u00b7stand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Der alles \u00fcberlegt und ordnet, uns beschehrt.", "tokens": ["Der", "al\u00b7les", "\u00fc\u00b7ber\u00b7legt", "und", "ord\u00b7net", ",", "uns", "be\u00b7schehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVPP", "KON", "VVFIN", "$,", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Die Weis\u2019, auf welche Art nun alles die\u00df geschicht,", "tokens": ["Die", "Weis'", ",", "auf", "wel\u00b7che", "Art", "nun", "al\u00b7les", "die\u00df", "ge\u00b7schicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PWAT", "NN", "ADV", "PIS", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Begreift gewi\u00df der Geist des Menschen nicht.", "tokens": ["Be\u00b7greift", "ge\u00b7wi\u00df", "der", "Geist", "des", "Men\u00b7schen", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es ist daran auch nichts gelegen:", "tokens": ["Es", "ist", "da\u00b7ran", "auch", "nichts", "ge\u00b7le\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn wir nur so viel thun, und dankbarlich erwegen,", "tokens": ["Wenn", "wir", "nur", "so", "viel", "thun", ",", "und", "dank\u00b7bar\u00b7lich", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "VVINF", "$,", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Da\u00df in der Thiere Reich so wohl f\u00fcr uns ein Segen", "tokens": ["Da\u00df", "in", "der", "Thie\u00b7re", "Reich", "so", "wohl", "f\u00fcr", "uns", "ein", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "ADV", "ADV", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von einem ", "tokens": ["Von", "ei\u00b7nem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Als da\u00df man auch zugleich ein helles ", "tokens": ["Als", "da\u00df", "man", "auch", "zu\u00b7gleich", "ein", "hel\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PIS", "ADV", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So aus dem grossen Werk, mit vollen Strahlen, bricht,", "tokens": ["So", "aus", "dem", "gros\u00b7sen", "Werk", ",", "mit", "vol\u00b7len", "Strah\u00b7len", ",", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zu unsers Sch\u00f6pfers Preis und Ruhm, darinn entdeckt,", "tokens": ["Zu", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Preis", "und", "Ruhm", ",", "da\u00b7rinn", "ent\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN", "$,", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nicht minder eine ", "tokens": ["Nicht", "min\u00b7der", "ei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "In Ehrfurcht-voller Lust bewundert und erh\u00f6ht.", "tokens": ["In", "Ehr\u00b7furcht\u00b7vol\u00b7ler", "Lust", "be\u00b7wun\u00b7dert", "und", "er\u00b7h\u00f6ht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Es mu\u00df Bewunderung, nebst Lust und Dank, allein", "tokens": ["Es", "mu\u00df", "Be\u00b7wun\u00b7de\u00b7rung", ",", "nebst", "Lust", "und", "Dank", ",", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "APPR", "NN", "KON", "NN", "$,", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "F\u00fcr so viel Guts, mit Recht, der Menschen Opfer seyn.", "tokens": ["F\u00fcr", "so", "viel", "Guts", ",", "mit", "Recht", ",", "der", "Men\u00b7schen", "Op\u00b7fer", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "$,", "APPR", "NN", "$,", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ach, so bestrebt euch doch auf Erden", "tokens": ["Ach", ",", "so", "be\u00b7strebt", "euch", "doch", "auf", "Er\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Empfind-erkenntlicher und dankbarer zu werden!", "tokens": ["Emp\u00b7fin\u00b7der\u00b7kennt\u00b7li\u00b7cher", "und", "dank\u00b7ba\u00b7rer", "zu", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Zu diesem n\u00fctzlichen Gesch\u00e4fte", "tokens": ["Zu", "die\u00b7sem", "n\u00fctz\u00b7li\u00b7chen", "Ge\u00b7sch\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gebrauchet eurer Seelen Kr\u00e4fte,", "tokens": ["Ge\u00b7brau\u00b7chet", "eu\u00b7rer", "See\u00b7len", "Kr\u00e4f\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und nicht nur blo\u00df die Gr\u00fcnde zu erfinden,", "tokens": ["Und", "nicht", "nur", "blo\u00df", "die", "Gr\u00fcn\u00b7de", "zu", "er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie alles die\u00df geschicht, nicht alles zu ergr\u00fcnden,", "tokens": ["Wie", "al\u00b7les", "die\u00df", "ge\u00b7schicht", ",", "nicht", "al\u00b7les", "zu", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PDS", "VVPP", "$,", "PTKNEG", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie GOttes Weisheit wirkt,", "tokens": ["Wie", "Got\u00b7tes", "Weis\u00b7heit", "wirkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Weil dieses mehrentheils aus Hochmuht blo\u00df geschicht.", "tokens": ["Weil", "die\u00b7ses", "meh\u00b7ren\u00b7theils", "aus", "Hoch\u00b7muht", "blo\u00df", "ge\u00b7schicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es wird ja unsre Kraft des Geistes und sein Licht", "tokens": ["Es", "wird", "ja", "uns\u00b7re", "Kraft", "des", "Geis\u00b7tes", "und", "sein", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "ART", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Durch seinen Kraft-Kreis so bezirkt,", "tokens": ["Durch", "sei\u00b7nen", "Kraft\u00b7Kreis", "so", "be\u00b7zirkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Da\u00df, wenn er redlich denkt, er \u00fcberzeuglich findet:", "tokens": ["Da\u00df", ",", "wenn", "er", "red\u00b7lich", "denkt", ",", "er", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "fin\u00b7det", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$,", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Gottheit werde nur bewundert, nicht ergr\u00fcndet.", "tokens": ["Die", "Got\u00b7theit", "wer\u00b7de", "nur", "be\u00b7wun\u00b7dert", ",", "nicht", "er\u00b7gr\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}