{"dta.poem.9533": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auff ihre schultern.  \n C. H. v. H.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ist dieses schnee? nein/ nein/ schnee kan nicht flam\u0303en f\u00fchren.", "tokens": ["Ist", "die\u00b7ses", "schnee", "?", "nein", "/", "nein", "/", "schnee", "kan", "nicht", "flam\u0303en", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$.", "PTKANT", "$(", "PTKANT", "$(", "VVFIN", "VMFIN", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ist dieses helffenbein? bein wei\u00df nicht weis zu seyn.", "tokens": ["Ist", "die\u00b7ses", "helf\u00b7fen\u00b7bein", "?", "bein", "wei\u00df", "nicht", "weis", "zu", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$.", "ADV", "VVFIN", "PTKNEG", "PTKVZ", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist hier ein glatter schwan? mehr als der schwanen schein/", "tokens": ["Ist", "hier", "ein", "glat\u00b7ter", "schwan", "?", "mehr", "als", "der", "schwa\u00b7nen", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "PIAT", "KOKOM", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist weiche woll allhier? wie kan sich wolle r\u00fchren?", "tokens": ["Ist", "wei\u00b7che", "woll", "all\u00b7hier", "?", "wie", "kan", "sich", "wol\u00b7le", "r\u00fch\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "ADV", "ADV", "$.", "PWAV", "VMFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ist alabaster hie? er w\u00e4chst nicht bey saphiren/", "tokens": ["Ist", "a\u00b7la\u00b7bas\u00b7ter", "hie", "?", "er", "w\u00e4chst", "nicht", "bey", "sa\u00b7phi\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "$.", "PPER", "VVFIN", "PTKNEG", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist hier ein liljen feld? der acker ist zu rein.", "tokens": ["Ist", "hier", "ein", "lil\u00b7jen", "feld", "?", "der", "ac\u00b7ker", "ist", "zu", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "ART", "ADJA", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was bist du endlich doch? weil schnee und helfenbein/", "tokens": ["Was", "bist", "du", "end\u00b7lich", "doch", "?", "weil", "schnee", "und", "hel\u00b7fen\u00b7bein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ADV", "$.", "KOUS", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Weil alabaster/ schwan/ und liljen sich verlieren.", "tokens": ["Weil", "a\u00b7la\u00b7bas\u00b7ter", "/", "schwan", "/", "und", "lil\u00b7jen", "sich", "ver\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$(", "ADV", "$(", "KON", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du schaust nun Lesbie/ wie mein geringer mund", "tokens": ["Du", "schaust", "nun", "Les\u00b7bie", "/", "wie", "mein", "ge\u00b7rin\u00b7ger", "mund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NE", "$(", "KOKOM", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Vor deine schultern wei\u00df kein rechtes wort zu finden/", "tokens": ["Vor", "dei\u00b7ne", "schul\u00b7tern", "wei\u00df", "kein", "rech\u00b7tes", "wort", "zu", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVFIN", "PIAT", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch da\u00df ich nicht zu sehr darf h\u00e4ufen meine s\u00fcnden/", "tokens": ["Doch", "da\u00df", "ich", "nicht", "zu", "sehr", "darf", "h\u00e4u\u00b7fen", "mei\u00b7ne", "s\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "PTKA", "ADV", "VMFIN", "VVFIN", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So macht ein kurtzer reim dir mein gem\u00fcthe kund:", "tokens": ["So", "macht", "ein", "kurt\u00b7zer", "reim", "dir", "mein", "ge\u00b7m\u00fc\u00b7the", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPER", "PPOSAT", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mu\u00df Atlas und sein hals sich vor dem himmel biegen/", "tokens": ["Mu\u00df", "At\u00b7las", "und", "sein", "hals", "sich", "vor", "dem", "him\u00b7mel", "bie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "KON", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So m\u00fcssen g\u00f6tter nur auf deinen schultern liegen.", "tokens": ["So", "m\u00fcs\u00b7sen", "g\u00f6t\u00b7ter", "nur", "auf", "dei\u00b7nen", "schul\u00b7tern", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADJD", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}