{"textgrid.poem.57901": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Nur ein Hund", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Geht ein Manschettenknopf verloren,", "tokens": ["Geht", "ein", "Man\u00b7schet\u00b7ten\u00b7knopf", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dann wird er sauber registriert,", "tokens": ["Dann", "wird", "er", "sau\u00b7ber", "re\u00b7gist\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Polizeibericht gemeldet,", "tokens": ["Im", "Po\u00b7li\u00b7zei\u00b7be\u00b7richt", "ge\u00b7mel\u00b7det", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und auf ein Jahr dann deponiert.", "tokens": ["Und", "auf", "ein", "Jahr", "dann", "de\u00b7po\u00b7niert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein Portemonnaie mit f\u00fcnfzig Pfennig,", "tokens": ["Ein", "Por\u00b7te\u00b7mon\u00b7nai\u00b7e", "mit", "f\u00fcnf\u00b7zig", "Pfen\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ach, darum macht man ein Geschrei,", "tokens": ["Ach", ",", "da\u00b7rum", "macht", "man", "ein", "Ge\u00b7schrei", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PAV", "VVFIN", "PIS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ob's ein Schatz von gro\u00dfem Werte,", "tokens": ["Als", "ob's", "ein", "Schatz", "von", "gro\u00b7\u00dfem", "Wer\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Diamant wie'n Kohlkopf sei.", "tokens": ["Ein", "Di\u00b7a\u00b7mant", "wie'n", "Kohl\u00b7kopf", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch f\u00e4ngt dir 'mal der Hundef\u00e4nger", "tokens": ["Doch", "f\u00e4ngt", "dir", "'mal", "der", "Hun\u00b7de\u00b7f\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Fort deinen Hund, kein Hahn kr\u00e4ht nach,", "tokens": ["Fort", "dei\u00b7nen", "Hund", ",", "kein", "Hahn", "kr\u00e4ht", "nach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und war er dir auch noch so teuer,", "tokens": ["Und", "war", "er", "dir", "auch", "noch", "so", "teu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man murkst ihn ab am vierten Tag.", "tokens": ["Man", "murkst", "ihn", "ab", "am", "vier\u00b7ten", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "L\u00e4ufst du nicht gleich zum Zoologen,", "tokens": ["L\u00e4ufst", "du", "nicht", "gleich", "zum", "Zoo\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "Dann ist dein Hund, eh' du's gedacht,", "tokens": ["Dann", "ist", "dein", "Hund", ",", "eh'", "du's", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "KOUS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dein armer Putti, Ami, Alli,", "tokens": ["Dein", "ar\u00b7mer", "Put\u00b7ti", ",", "A\u00b7mi", ",", "Al\u00b7li", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu Kunstd\u00fcnger schon l\u00e4ngst gemacht.", "tokens": ["Zu", "Kunst\u00b7d\u00fcn\u00b7ger", "schon", "l\u00e4ngst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}}}}