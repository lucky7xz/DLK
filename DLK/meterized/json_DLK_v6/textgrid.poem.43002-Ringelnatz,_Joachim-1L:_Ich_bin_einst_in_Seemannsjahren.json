{"textgrid.poem.43002": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich bin einst in Seemannsjahren", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin einst in Seemannsjahren", "tokens": ["Ich", "bin", "einst", "in", "See\u00b7manns\u00b7jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Oft elbauf, elbab gefahren.", "tokens": ["Oft", "el\u00b7bauf", ",", "el\u00b7bab", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "ADV", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Auf der Seite, wo wir dann Stadt Altona", "tokens": ["Auf", "der", "Sei\u00b7te", ",", "wo", "wir", "dann", "Stadt", "Al\u00b7to\u00b7na"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "NN", "NE"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sichteten, stand ich an Deck und sah.", "tokens": ["Sich\u00b7te\u00b7ten", ",", "stand", "ich", "an", "Deck", "und", "sah", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "APPR", "NN", "KON", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Sah ein Haus. Vom Schornsteinru\u00df geschminkt,", "tokens": ["Sah", "ein", "Haus", ".", "Vom", "Schorn\u00b7stein\u00b7ru\u00df", "ge\u00b7schminkt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Kiekt es lustig nach der Elbe hin.", "tokens": ["Kiekt", "es", "lus\u00b7tig", "nach", "der", "El\u00b7be", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NE", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und ich wu\u00dfte: Meta wohnt darin.", "tokens": ["Und", "ich", "wu\u00df\u00b7te", ":", "Me\u00b7ta", "wohnt", "da\u00b7rin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "NE", "VVFIN", "PAV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wenn ich dort vorbeigefahren bin,", "tokens": ["Wenn", "ich", "dort", "vor\u00b7bei\u00b7ge\u00b7fah\u00b7ren", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Hat sie mir und hab ich ihr gewinkt,", "tokens": ["Hat", "sie", "mir", "und", "hab", "ich", "ihr", "ge\u00b7winkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "KON", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Ein Signal \u00bbIch liebe dich\u00ab.", "tokens": ["Ein", "Sig\u00b7nal", "\u00bb", "Ich", "lie\u00b7be", "dich", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "PPER", "VVFIN", "PPER", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und ich sah sie, und sie sah auch mich.", "tokens": ["Und", "ich", "sah", "sie", ",", "und", "sie", "sah", "auch", "mich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "KON", "PPER", "VVFIN", "ADV", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Heute flog ich \u00fcber das vertraute", "tokens": ["Heu\u00b7te", "flog", "ich", "\u00fc\u00b7ber", "das", "ver\u00b7trau\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Altona. Hab nicht das Haus entdeckt.", "tokens": ["Al\u00b7to\u00b7na", ".", "Hab", "nicht", "das", "Haus", "ent\u00b7deckt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "PTKNEG", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Doch ich hab die Hand hinausgestreckt,", "tokens": ["Doch", "ich", "hab", "die", "Hand", "hin\u00b7aus\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Hab gewinkt, wie ich es einst getan.", "tokens": ["Hab", "ge\u00b7winkt", ",", "wie", "ich", "es", "einst", "ge\u00b7tan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Und ich wu\u00dfte: Meta schaute,", "tokens": ["Und", "ich", "wu\u00df\u00b7te", ":", "Me\u00b7ta", "schau\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Winkte auf nach meinem Wolkenkahn", "tokens": ["Wink\u00b7te", "auf", "nach", "mei\u00b7nem", "Wol\u00b7ken\u00b7kahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Oder wie sie's nennen, \u00bbAeroplan\u00ab.", "tokens": ["O\u00b7der", "wie", "sie's", "nen\u00b7nen", ",", "\u00bb", "A\u00b7e\u00b7rop\u00b7lan", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["KON", "PWAV", "PIS", "VVINF", "$,", "$(", "NN", "$(", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Wenn man sich auch sonst von nah,", "tokens": ["Wenn", "man", "sich", "auch", "sonst", "von", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "ADV", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Teufel eins, viel lieber sah,", "tokens": ["Teu\u00b7fel", "eins", ",", "viel", "lie\u00b7ber", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dacht ich doch verliebt und bang", "tokens": ["Dacht", "ich", "doch", "ver\u00b7liebt", "und", "bang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "VVPP", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Oben dort im Wolkenhang:", "tokens": ["O\u00b7ben", "dort", "im", "Wol\u00b7ken\u00b7hang", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wenn ich jetzt hinunterst\u00fcrze,", "tokens": ["Wenn", "ich", "jetzt", "hin\u00b7un\u00b7ter\u00b7st\u00fcr\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4ngt mich Meta in der Sch\u00fcrze", "tokens": ["F\u00e4ngt", "mich", "Me\u00b7ta", "in", "der", "Sch\u00fcr\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NE", "APPR", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Auf.", "tokens": ["Auf", "."], "token_info": ["word", "punct"], "pos": ["APPR", "$."], "meter": "+", "measure": "single.up"}}}}}