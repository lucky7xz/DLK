{"textgrid.poem.46156": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Ueber abscheiden", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbach, s\u00fc\u00dfe seel, mu\u00df ich dich dan verlieren,", "tokens": ["\u00bb", "ach", ",", "s\u00fc\u00b7\u00dfe", "seel", ",", "mu\u00df", "ich", "dich", "dan", "ver\u00b7lie\u00b7ren", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NN", "$,", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "jetz, da ich stark zu halten dich gedacht?", "tokens": ["jetz", ",", "da", "ich", "stark", "zu", "hal\u00b7ten", "dich", "ge\u00b7dacht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "PTKZU", "VVINF", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "darf ich dan nu nicht l\u00e4nger triumfieren,", "tokens": ["darf", "ich", "dan", "nu", "nicht", "l\u00e4n\u00b7ger", "tri\u00b7um\u00b7fie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "verringert sich dan meiner sch\u00f6nheit macht?", "tokens": ["ver\u00b7rin\u00b7gert", "sich", "dan", "mei\u00b7ner", "sch\u00f6n\u00b7heit", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "ach nein! vil mehr will deine lieb sich enden,", "tokens": ["ach", "nein", "!", "vil", "mehr", "will", "dei\u00b7ne", "lieb", "sich", "en\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKANT", "$.", "ADV", "ADV", "VMFIN", "PPOSAT", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "dan wahre lieb kan sich von lieb nicht wenden.", "tokens": ["dan", "wah\u00b7re", "lieb", "kan", "sich", "von", "lieb", "nicht", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "ADJD", "VMFIN", "PRF", "APPR", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Was soll ein f\u00fcrst mehr macht und vortheil haben,", "tokens": ["Was", "soll", "ein", "f\u00fcrst", "mehr", "macht", "und", "vor\u00b7theil", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADV", "ADV", "VVFIN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "dan Amor selbs, der gr\u00f6sten g\u00f6tter got?", "tokens": ["dan", "A\u00b7mor", "selbs", ",", "der", "gr\u00f6s\u00b7ten", "g\u00f6t\u00b7ter", "got", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "ADV", "$,", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wird dan der krieg dich mit blut mehr erlaben,", "tokens": ["wird", "dan", "der", "krieg", "dich", "mit", "blut", "mehr", "er\u00b7la\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PRF", "APPR", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "dan diese k\u00fc\u00df, dan mein mund s\u00fc\u00df und rot?", "tokens": ["dan", "die\u00b7se", "k\u00fc\u00df", ",", "dan", "mein", "mund", "s\u00fc\u00df", "und", "rot", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "$,", "ADV", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+--+--++-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "ach nein! mein herz; la\u00df krieg und f\u00fcrsten fahren,", "tokens": ["ach", "nein", "!", "mein", "herz", ";", "la\u00df", "krieg", "und", "f\u00fcrs\u00b7ten", "fah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKANT", "$.", "PPOSAT", "NN", "$.", "VVIMP", "NN", "KON", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ein buhler soll nur seiner lieb willfahren.", "tokens": ["ein", "buh\u00b7ler", "soll", "nur", "sei\u00b7ner", "lieb", "will\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Was hilft es dir, nach ehr und lob zu streben,", "tokens": ["Was", "hilft", "es", "dir", ",", "nach", "ehr", "und", "lob", "zu", "stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$,", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wan ich allein ohn hofnung zagen solt?", "tokens": ["wan", "ich", "al\u00b7lein", "ohn", "hof\u00b7nung", "za\u00b7gen", "solt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "vil besser ist, der seinem freind das leben,", "tokens": ["vil", "bes\u00b7ser", "ist", ",", "der", "sei\u00b7nem", "freind", "das", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dan der dem feind den tod mittheilen wolt.", "tokens": ["dan", "der", "dem", "feind", "den", "tod", "mit\u00b7thei\u00b7len", "wolt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "mein herz ohn dich kan keinen ruhm vermehren,", "tokens": ["mein", "herz", "ohn", "dich", "kan", "kei\u00b7nen", "ruhm", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ohn mich dein herz soll keinen ruhm begehren.\u00ab", "tokens": ["ohn", "mich", "dein", "herz", "soll", "kei\u00b7nen", "ruhm", "be\u00b7geh\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPER", "PPOSAT", "NN", "VMFIN", "PIAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Also th\u00e4t sich die zarte Myrt beklagen,", "tokens": ["Al\u00b7so", "th\u00e4t", "sich", "die", "zar\u00b7te", "Myrt", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "da Filodor, auch seufzend, j\u00e4merlich", "tokens": ["da", "Fi\u00b7lo\u00b7dor", ",", "auch", "seuf\u00b7zend", ",", "j\u00e4\u00b7mer\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "NE", "$,", "ADV", "VVPP", "$,", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sprach: \u00bbla\u00df uns doch der g\u00f6tter zorn ertragen;", "tokens": ["sprach", ":", "\u00bb", "la\u00df", "uns", "doch", "der", "g\u00f6t\u00b7ter", "zorn", "er\u00b7tra\u00b7gen", ";"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "VVIMP", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "du hast mein herz, mein Myrt, dein herz hab ich.", "tokens": ["du", "hast", "mein", "herz", ",", "mein", "Myrt", ",", "dein", "herz", "hab", "ich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und wie sehr uns das scheiden nu verletzet,", "tokens": ["und", "wie", "sehr", "uns", "das", "schei\u00b7den", "nu", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PPER", "ART", "ADJA", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "so sehr und mehr die widerkunft ergetzet.\u00ab", "tokens": ["so", "sehr", "und", "mehr", "die", "wi\u00b7der\u00b7kunft", "er\u00b7get\u00b7zet", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}