{"textgrid.poem.57316": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sie, die den Wunsch gab, sch\u00f6ner sie, als der Gaul", "genre": "verse", "period": "N.A.", "pub_year": 1781, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie, die den Wunsch gab, sch\u00f6ner sie, als der Gaul", "tokens": ["Sie", ",", "die", "den", "Wunsch", "gab", ",", "sch\u00f6\u00b7ner", "sie", ",", "als", "der", "Gaul"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "VVFIN", "$,", "ADJA", "PPER", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von Alsens Eiland, lernte noch mehr. Sie sprang", "tokens": ["Von", "Al\u00b7sens", "Ei\u00b7land", ",", "lern\u00b7te", "noch", "mehr", ".", "Sie", "sprang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "NN", "$,", "VVFIN", "ADV", "ADV", "$.", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sonst rasches Leichtsinns \u00fcber Graben,", "tokens": ["Sonst", "ra\u00b7sches", "Leicht\u00b7sinns", "\u00fc\u00b7ber", "Gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Trockne, wie's kam, und vom Moor getr\u00e4nkte.", "tokens": ["Trock\u00b7ne", ",", "wie's", "kam", ",", "und", "vom", "Moor", "ge\u00b7tr\u00e4nk\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "$,", "KON", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Viel Leichtsinn hat sie, aber hat auch Verstand", "tokens": ["Viel", "Leicht\u00b7sinn", "hat", "sie", ",", "a\u00b7ber", "hat", "auch", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "$,", "ADV", "VAFIN", "ADV", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Und Auge, setzet nun mit Bedachtsamkeit", "tokens": ["Und", "Au\u00b7ge", ",", "set\u00b7zet", "nun", "mit", "Be\u00b7dacht\u00b7sam\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-++-+-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Den Huf vorf\u00fchlend hin, misst alles,", "tokens": ["Den", "Huf", "vor\u00b7f\u00fch\u00b7lend", "hin", ",", "misst", "al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "PTKVZ", "$,", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fehlet die Breite um keinen Halm nicht.", "tokens": ["Feh\u00b7let", "die", "Brei\u00b7te", "um", "kei\u00b7nen", "Halm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "PTKNEG", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Mir, dem das Haar schon grau, und Erinnerer", "tokens": ["Mir", ",", "dem", "das", "Haar", "schon", "grau", ",", "und", "E\u00b7rin\u00b7ne\u00b7rer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "ADV", "ADJD", "$,", "KON", "NN"], "meter": "+--+-+--+--", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der Lebensflucht wird, haben sich J\u00fcnglinge", "tokens": ["Der", "Le\u00b7bens\u00b7flucht", "wird", ",", "ha\u00b7ben", "sich", "J\u00fcng\u00b7lin\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "VAFIN", "PRF", "NN"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Nicht nachgewagt, wenn ich die sch\u00f6nern", "tokens": ["Nicht", "nach\u00b7ge\u00b7wagt", ",", "wenn", "ich", "die", "sch\u00f6\u00b7nern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVPP", "$,", "KOUS", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gegenden \u00fcber dem Kl\u00fcftchen anwies.", "tokens": ["Ge\u00b7gen\u00b7den", "\u00fc\u00b7ber", "dem", "Kl\u00fcft\u00b7chen", "an\u00b7wi\u00b7es", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch warn den k\u00fchnen, k\u00fchner, dass er aus Lust", "tokens": ["Doch", "warn", "den", "k\u00fch\u00b7nen", ",", "k\u00fch\u00b7ner", ",", "dass", "er", "aus", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "$,", "ADJA", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Sich nicht des Weidners Graben zum \u00dcbersatz", "tokens": ["Sich", "nicht", "des", "Weid\u00b7ners", "Gra\u00b7ben", "zum", "\u00dc\u00b7ber\u00b7satz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "PTKNEG", "ART", "NN", "NN", "APPRART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Aufsuche, weil Iduna dann sich", "tokens": ["Auf\u00b7su\u00b7che", ",", "weil", "I\u00b7du\u00b7na", "dann", "sich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "NE", "ADV", "PRF"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Etwa verm\u00e4ss', und das Ziel verfehlte.", "tokens": ["Et\u00b7wa", "ver\u00b7m\u00e4ss'", ",", "und", "das", "Ziel", "ver\u00b7fehl\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KON", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Selbst da, wo zwischen Tiefen der schm\u00e4lere", "tokens": ["Selbst", "da", ",", "wo", "zwi\u00b7schen", "Tie\u00b7fen", "der", "schm\u00e4\u00b7le\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "PWAV", "APPR", "NN", "ART", "ADJA"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Fusssteig sich schl\u00e4ngelt, wandelt sie, ungefolgt,", "tokens": ["Fuss\u00b7steig", "sich", "schl\u00e4n\u00b7gelt", ",", "wan\u00b7delt", "sie", ",", "un\u00b7ge\u00b7folgt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PRF", "VVFIN", "$,", "VVFIN", "PPER", "$,", "ADJD", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "In sichrem Gleichgewicht gehalten,", "tokens": ["In", "sich\u00b7rem", "Gleich\u00b7ge\u00b7wicht", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch den gelinderen Zug der Trense.", "tokens": ["Durch", "den", "ge\u00b7lin\u00b7de\u00b7ren", "Zug", "der", "Tren\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "Du w\u00e4hnst, du wissest alles nun; irrest dich!", "tokens": ["Du", "w\u00e4hnst", ",", "du", "wis\u00b7sest", "al\u00b7les", "nun", ";", "ir\u00b7rest", "dich", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VVFIN", "PIS", "ADV", "$.", "VVFIN", "PPER", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vor nichts entsetzte mehr sie sich, schnob sie so,", "tokens": ["Vor", "nichts", "ent\u00b7setz\u00b7te", "mehr", "sie", "sich", ",", "schnob", "sie", "so", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "ADV", "PPER", "PRF", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Als wenn des frommen M\u00f6nchs Erfindung,", "tokens": ["Als", "wenn", "des", "from\u00b7men", "M\u00f6nchs", "Er\u00b7fin\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch so entfernt, wo her\u00fcber schallte.", "tokens": ["Noch", "so", "ent\u00b7fernt", ",", "wo", "her\u00b7\u00fc\u00b7ber", "schall\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "PWAV", "ADV", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Fluch seiner Unschuld selber! Die K\u00f6nige,", "tokens": ["Fluch", "sei\u00b7ner", "Un\u00b7schuld", "sel\u00b7ber", "!", "Die", "K\u00f6\u00b7ni\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$.", "ART", "NN", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Vom M\u00f6nch bewafnet, haben das M\u00f6rderbley", "tokens": ["Vom", "M\u00f6nch", "be\u00b7waf\u00b7net", ",", "ha\u00b7ben", "das", "M\u00f6r\u00b7der\u00b7bley"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wie Saat ges\u00e4t, und tausendf\u00e4ltig", "tokens": ["Wie", "Saat", "ge\u00b7s\u00e4t", ",", "und", "tau\u00b7send\u00b7f\u00e4l\u00b7tig"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "NN", "VVPP", "$,", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wuchs aus der schrecklichen Saat Verderben!", "tokens": ["Wuchs", "aus", "der", "schreck\u00b7li\u00b7chen", "Saat", "Ver\u00b7der\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Doch weg den Blick! Iduna, gef\u00fchrt von mir,", "tokens": ["Doch", "weg", "den", "Blick", "!", "I\u00b7du\u00b7na", ",", "ge\u00b7f\u00fchrt", "von", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "NE", "$,", "VVPP", "APPR", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Bestraft, gestreichelt, heftiger angeredt,", "tokens": ["Be\u00b7straft", ",", "ge\u00b7strei\u00b7chelt", ",", "hef\u00b7ti\u00b7ger", "an\u00b7ge\u00b7redt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dann leiser, sanfter, steht dem Schusse", "tokens": ["Dann", "lei\u00b7ser", ",", "sanf\u00b7ter", ",", "steht", "dem", "Schus\u00b7se"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADJD", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zwar nicht mit Ruh, doch den Dampf beschnaubt sie.", "tokens": ["Zwar", "nicht", "mit", "Ruh", ",", "doch", "den", "Dampf", "be\u00b7schnaubt", "sie", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Ich kann den Blick nicht wenden! Die K\u00f6nige,", "tokens": ["Ich", "kann", "den", "Blick", "nicht", "wen\u00b7den", "!", "Die", "K\u00f6\u00b7ni\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$.", "ART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Weh ihnen, Weh! zerschmetterten; brachten dir", "tokens": ["Weh", "ih\u00b7nen", ",", "Weh", "!", "zer\u00b7schmet\u00b7ter\u00b7ten", ";", "brach\u00b7ten", "dir"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "PPER", "$,", "NN", "$.", "VVFIN", "$.", "VVFIN", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Zum Opfer, Tod! von heissem Blute", "tokens": ["Zum", "Op\u00b7fer", ",", "Tod", "!", "von", "heis\u00b7sem", "Blu\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sch\u00e4umende Schalen, sie selbst auch Menschen.", "tokens": ["Sch\u00e4u\u00b7men\u00b7de", "Scha\u00b7len", ",", "sie", "selbst", "auch", "Men\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "ADV", "ADV", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}}}}