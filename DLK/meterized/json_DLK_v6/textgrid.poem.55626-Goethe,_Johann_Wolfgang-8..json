{"textgrid.poem.55626": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "8.", "genre": "verse", "period": "N.A.", "pub_year": 1790, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Freund, wer ein Lump ist, bleibt ein Lump,", "tokens": ["Freund", ",", "wer", "ein", "Lump", "ist", ",", "bleibt", "ein", "Lump", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "ART", "NN", "VAFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zu Wagen, Pferd und Fu\u00dfe;", "tokens": ["Zu", "Wa\u00b7gen", ",", "Pferd", "und", "Fu\u00b7\u00dfe", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Drum glaub an keinen Lumpen je,", "tokens": ["Drum", "glaub", "an", "kei\u00b7nen", "Lum\u00b7pen", "je", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An keines Lumpen Bu\u00dfe.", "tokens": ["An", "kei\u00b7nes", "Lum\u00b7pen", "Bu\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Bin ich f\u00fcr 'ne Sache eingenommen,", "tokens": ["Bin", "ich", "f\u00fcr", "'ne", "Sa\u00b7che", "ein\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Die Welt, denk ich, mu\u00df mit mir kommen;", "tokens": ["Die", "Welt", ",", "denk", "ich", ",", "mu\u00df", "mit", "mir", "kom\u00b7men", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "VMFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch welch ein Greuel mu\u00df mir erscheinen,", "tokens": ["Doch", "welch", "ein", "Greu\u00b7el", "mu\u00df", "mir", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn Lumpe sich wollen mit mir vereinen.", "tokens": ["Wenn", "Lum\u00b7pe", "sich", "wol\u00b7len", "mit", "mir", "ver\u00b7ei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "VMFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "F\u00fcr und wider zu dieser Stunde", "tokens": ["F\u00fcr", "und", "wi\u00b7der", "zu", "die\u00b7ser", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KON", "APPR", "APPR", "PDAT", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Quengelt ihr schon seit vielen Jahren:", "tokens": ["Quen\u00b7gelt", "ihr", "schon", "seit", "vie\u00b7len", "Jah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Was ich getan, ihr Lumpenhunde!", "tokens": ["Was", "ich", "ge\u00b7tan", ",", "ihr", "Lum\u00b7pen\u00b7hun\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Werdet ihr nimmermehr erfahren.", "tokens": ["Wer\u00b7det", "ihr", "nim\u00b7mer\u00b7mehr", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbso sei doch h\u00f6flich!\u00ab \u2013 H\u00f6flich mit dem Pack?", "tokens": ["\u00bb", "so", "sei", "doch", "h\u00f6f\u00b7lich", "!", "\u00ab", "\u2013", "H\u00f6f\u00b7lich", "mit", "dem", "Pack", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ADV", "ADJD", "$.", "$(", "$(", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Seide n\u00e4ht man keinen groben Sack.", "tokens": ["Mit", "Sei\u00b7de", "n\u00e4ht", "man", "kei\u00b7nen", "gro\u00b7ben", "Sack", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIS", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wie mancher Mi\u00dfwillige schnuffelt und wittert", "tokens": ["Wie", "man\u00b7cher", "Mi\u00df\u00b7wil\u00b7li\u00b7ge", "schnuf\u00b7felt", "und", "wit\u00b7tert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Um das von der Muse verliehne Gedicht;", "tokens": ["Um", "das", "von", "der", "Mu\u00b7se", "ver\u00b7lieh\u00b7ne", "Ge\u00b7dicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Sie haben ", "tokens": ["Sie", "ha\u00b7ben"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Mir sollen sie's nicht!", "tokens": ["Mir", "sol\u00b7len", "sie's", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "PTKNEG", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Jedem redlichen Bem\u00fchn", "tokens": ["Je\u00b7dem", "red\u00b7li\u00b7chen", "Be\u00b7m\u00fchn"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sei Beharrlichkeit verliehn.", "tokens": ["Sei", "Be\u00b7harr\u00b7lich\u00b7keit", "ver\u00b7liehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Jeder Weg zum rechten Zwecke", "tokens": ["Je\u00b7der", "Weg", "zum", "rech\u00b7ten", "Zwe\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist auch recht in jeder Strecke.", "tokens": ["Ist", "auch", "recht", "in", "je\u00b7der", "Stre\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wer mit dem Leben spielt,", "tokens": ["Wer", "mit", "dem", "Le\u00b7ben", "spielt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Kommt nie zurecht;", "tokens": ["Kommt", "nie", "zu\u00b7recht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wer sich nicht selbst befiehlt,", "tokens": ["Wer", "sich", "nicht", "selbst", "be\u00b7fiehlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Bleibt immer ein Knecht.", "tokens": ["Bleibt", "im\u00b7mer", "ein", "Knecht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.8": {"line.1": {"text": "Mu\u00dft rasch dich besinnen", "tokens": ["Mu\u00dft", "rasch", "dich", "be\u00b7sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "PPER", "VVINF"], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "Und neues gewinnen.", "tokens": ["Und", "neu\u00b7es", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Mu\u00dft Ruhm gewinnen,", "tokens": ["Mu\u00dft", "Ruhm", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Da werden die Leute sich anders besinnen.", "tokens": ["Da", "wer\u00b7den", "die", "Leu\u00b7te", "sich", "an\u00b7ders", "be\u00b7sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PRF", "ADV", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Da w\u00e4r es besser: nicht geboren.", "tokens": ["Da", "w\u00e4r", "es", "bes\u00b7ser", ":", "nicht", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$.", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Willst du dir ein gut Leben zimmern,", "tokens": ["Willst", "du", "dir", "ein", "gut", "Le\u00b7ben", "zim\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00dft ums Vergangne dich nicht bek\u00fcmmern,", "tokens": ["Mu\u00dft", "ums", "Ver\u00b7gang\u00b7ne", "dich", "nicht", "be\u00b7k\u00fcm\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Und w\u00e4re dir auch was verloren,", "tokens": ["Und", "w\u00e4\u00b7re", "dir", "auch", "was", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erweise dich wie neugeboren;", "tokens": ["Er\u00b7wei\u00b7se", "dich", "wie", "neu\u00b7ge\u00b7bo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KOKOM", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was jeder Tag will, sollst du fragen,", "tokens": ["Was", "je\u00b7der", "Tag", "will", ",", "sollst", "du", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "VMFIN", "$,", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was jeder Tag will, wird er sagen;", "tokens": ["Was", "je\u00b7der", "Tag", "will", ",", "wird", "er", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "VMFIN", "$,", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mu\u00dft dich an eigenem Tun erg\u00f6tzen,", "tokens": ["Mu\u00dft", "dich", "an", "ei\u00b7ge\u00b7nem", "Tun", "er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.8": {"text": "Was andre tun, das wirst du sch\u00e4tzen;", "tokens": ["Was", "and\u00b7re", "tun", ",", "das", "wirst", "du", "sch\u00e4t\u00b7zen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVINF", "$,", "PDS", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Besonders keinen Menschen hassen", "tokens": ["Be\u00b7son\u00b7ders", "kei\u00b7nen", "Men\u00b7schen", "has\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und das \u00fcbrige Gott \u00fcberlassen.", "tokens": ["Und", "das", "\u00fcb\u00b7ri\u00b7ge", "Gott", "\u00fc\u00b7ber\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Bekenntnis hei\u00dft nach altem Brauch", "tokens": ["Be\u00b7kennt\u00b7nis", "hei\u00dft", "nach", "al\u00b7tem", "Brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gest\u00e4ndnis, wie man's meint;", "tokens": ["Ge\u00b7st\u00e4nd\u00b7nis", ",", "wie", "man's", "meint", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man rede frei, und wenn man auch", "tokens": ["Man", "re\u00b7de", "frei", ",", "und", "wenn", "man", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJD", "$,", "KON", "KOUS", "PIS", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Nur Zwei und Drei vereint.", "tokens": ["Nur", "Zwei", "und", "Drei", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "KON", "CARD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Das Opfer, das die Liebe bringt,", "tokens": ["Das", "Op\u00b7fer", ",", "das", "die", "Lie\u00b7be", "bringt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist das teuerste von allen;", "tokens": ["Es", "ist", "das", "teu\u00b7ers\u00b7te", "von", "al\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "APPR", "PIAT", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Doch wer sein Eigenstes bezwingt,", "tokens": ["Doch", "wer", "sein", "Ei\u00b7gens\u00b7tes", "be\u00b7zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem ist das sch\u00f6nste Los gefallen.", "tokens": ["Dem", "ist", "das", "sch\u00f6ns\u00b7te", "Los", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Nur wenn das Herz erschlossen,", "tokens": ["Nur", "wenn", "das", "Herz", "er\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dann ist die Erde sch\u00f6n.", "tokens": ["Dann", "ist", "die", "Er\u00b7de", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du standest so verdrossen", "tokens": ["Du", "stan\u00b7dest", "so", "ver\u00b7dros\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wu\u00dftest nicht zu sehn.", "tokens": ["Und", "wu\u00df\u00b7test", "nicht", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Der Zaubrer fordert leidenschaftlich wild", "tokens": ["Der", "Zaub\u00b7rer", "for\u00b7dert", "lei\u00b7den\u00b7schaft\u00b7lich", "wild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Von H\u00f6ll und Himmel sich Helenens Bild;", "tokens": ["Von", "H\u00f6ll", "und", "Him\u00b7mel", "sich", "He\u00b7le\u00b7nens", "Bild", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PRF", "NE", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Tr\u00e4t er zu mir in heitern Morgenstunden,", "tokens": ["Tr\u00e4t", "er", "zu", "mir", "in", "hei\u00b7tern", "Mor\u00b7gen\u00b7stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Liebensw\u00fcrdigste w\u00e4r friedlich ihm gefunden.", "tokens": ["Das", "Lie\u00b7bens\u00b7w\u00fcr\u00b7digs\u00b7te", "w\u00e4r", "fried\u00b7lich", "ihm", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PPER", "VVPP", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.14": {"line.1": {"text": "Zu verschweigen meinen Gewinn,", "tokens": ["Zu", "ver\u00b7schwei\u00b7gen", "mei\u00b7nen", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mu\u00df ich die Menschen vermeiden;", "tokens": ["Mu\u00df", "ich", "die", "Men\u00b7schen", "ver\u00b7mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df ich wisse, woran ich bin,", "tokens": ["Da\u00df", "ich", "wis\u00b7se", ",", "wo\u00b7ran", "ich", "bin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Das wollen die andern nicht leiden.", "tokens": ["Das", "wol\u00b7len", "die", "an\u00b7dern", "nicht", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "ADJA", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.15": {"line.1": {"text": "Der Philosoph, dem ich so gern vertraue,", "tokens": ["Der", "Phi\u00b7lo\u00b7soph", ",", "dem", "ich", "so", "gern", "ver\u00b7trau\u00b7e", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lehrt, wo nicht gegen alle, doch die meisten,", "tokens": ["Lehrt", ",", "wo", "nicht", "ge\u00b7gen", "al\u00b7le", ",", "doch", "die", "meis\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PTKNEG", "APPR", "PIS", "$,", "ADV", "ART", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Da\u00df unbewu\u00dft wir stets das Beste leisten:", "tokens": ["Da\u00df", "un\u00b7be\u00b7wu\u00dft", "wir", "stets", "das", "Bes\u00b7te", "leis\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das glaubt man gern und lebt nun frisch ins Blaue.", "tokens": ["Das", "glaubt", "man", "gern", "und", "lebt", "nun", "frisch", "ins", "Blau\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "KON", "VVFIN", "ADV", "ADJD", "APPRART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Der Dichter schaut in Weltgew\u00fchle,", "tokens": ["Der", "Dich\u00b7ter", "schaut", "in", "Welt\u00b7ge\u00b7w\u00fch\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sieht jeden Menschen mit sich selbst befangen,", "tokens": ["Sieht", "je\u00b7den", "Men\u00b7schen", "mit", "sich", "selbst", "be\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bald heitern Sinns, bald b\u00e4nglicher Gef\u00fchle,", "tokens": ["Bald", "hei\u00b7tern", "Sinns", ",", "bald", "b\u00e4ng\u00b7li\u00b7cher", "Ge\u00b7f\u00fch\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch hat er Zwecke. Da\u00df er die erlange,", "tokens": ["Doch", "hat", "er", "Zwe\u00b7cke", ".", "Da\u00df", "er", "die", "er\u00b7lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NN", "$.", "KOUS", "PPER", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sucht er den eignen Weg zum eignen Ziele.", "tokens": ["Sucht", "er", "den", "eig\u00b7nen", "Weg", "zum", "eig\u00b7nen", "Zie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was das bedeute, merkt er sich und allen,", "tokens": ["Was", "das", "be\u00b7deu\u00b7te", ",", "merkt", "er", "sich", "und", "al\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVFIN", "$,", "VVFIN", "PPER", "PRF", "KON", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und was bedeutet, l\u00e4\u00dft er sich gefallen.", "tokens": ["Und", "was", "be\u00b7deu\u00b7tet", ",", "l\u00e4\u00dft", "er", "sich", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "$,", "VVFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Gar mancher hat sich ernst beflissen", "tokens": ["Gar", "man\u00b7cher", "hat", "sich", "ernst", "be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VAFIN", "PRF", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hatte dennoch schlechten Lohn.", "tokens": ["Und", "hat\u00b7te", "den\u00b7noch", "schlech\u00b7ten", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist ganz eigen: wenn sie wissen,", "tokens": ["Es", "ist", "ganz", "ei\u00b7gen", ":", "wenn", "sie", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$.", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So meinen sie, sie w\u00fc\u00dften schon.", "tokens": ["So", "mei\u00b7nen", "sie", ",", "sie", "w\u00fc\u00df\u00b7ten", "schon", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "In die Welt hinaus!", "tokens": ["In", "die", "Welt", "hin\u00b7aus", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Au\u00dfer dem Haus", "tokens": ["Au\u00b7\u00dfer", "dem", "Haus"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Ist immer das beste Leben;", "tokens": ["Ist", "im\u00b7mer", "das", "bes\u00b7te", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wem's zu Hause gef\u00e4llt,", "tokens": ["Wem's", "zu", "Hau\u00b7se", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "VVPP", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ist nicht f\u00fcr die Welt \u2013", "tokens": ["Ist", "nicht", "f\u00fcr", "die", "Welt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ART", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Mag er leben!", "tokens": ["Mag", "er", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.19": {"line.1": {"text": "Seh ich zum Wagen heraus", "tokens": ["Seh", "ich", "zum", "Wa\u00b7gen", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Mich nach jemand um,", "tokens": ["Mich", "nach", "je\u00b7mand", "um", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "So macht er gleich was draus;", "tokens": ["So", "macht", "er", "gleich", "was", "draus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PWS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Er ", "tokens": ["Er"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Und er hat recht.", "tokens": ["Und", "er", "hat", "recht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}