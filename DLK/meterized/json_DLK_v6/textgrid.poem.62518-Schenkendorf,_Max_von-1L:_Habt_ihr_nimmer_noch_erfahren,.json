{"textgrid.poem.62518": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Habt ihr nimmer noch erfahren,", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Habt ihr nimmer noch erfahren,", "tokens": ["Habt", "ihr", "nim\u00b7mer", "noch", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie er ist so reich und gut?", "tokens": ["Wie", "er", "ist", "so", "reich", "und", "gut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie er seit viel tausend Jahren", "tokens": ["Wie", "er", "seit", "viel", "tau\u00b7send", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Wesen lieben thut?", "tokens": ["Al\u00b7le", "We\u00b7sen", "lie\u00b7ben", "thut", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Liebend hat er ausgesehen", "tokens": ["Lie\u00b7bend", "hat", "er", "aus\u00b7ge\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Manches lange Jahr nach euch,", "tokens": ["Man\u00b7ches", "lan\u00b7ge", "Jahr", "nach", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollet endlich ihn verstehen,", "tokens": ["Wol\u00b7let", "end\u00b7lich", "ihn", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Menschen, kommt in Gottes Reich!", "tokens": ["Men\u00b7schen", ",", "kommt", "in", "Got\u00b7tes", "Reich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Segnend in der Menschen Mitte", "tokens": ["Seg\u00b7nend", "in", "der", "Men\u00b7schen", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist er jeder Seele nah,", "tokens": ["Ist", "er", "je\u00b7der", "See\u00b7le", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zu gew\u00e4hren jede Bitte,", "tokens": ["Zu", "ge\u00b7w\u00e4h\u00b7ren", "je\u00b7de", "Bit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Steht er immer freundlich da.", "tokens": ["Steht", "er", "im\u00b7mer", "freund\u00b7lich", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Soll der Taumel ewig w\u00e4hren?", "tokens": ["Soll", "der", "Tau\u00b7mel", "e\u00b7wig", "w\u00e4h\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprecht, wie lang ihr sucht und irrt?", "tokens": ["Sprecht", ",", "wie", "lang", "ihr", "sucht", "und", "irrt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollt ihr nicht zu Jesu kehren,", "tokens": ["Wollt", "ihr", "nicht", "zu", "Je\u00b7su", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welcher winkt, ein treuer Wirth?", "tokens": ["Wel\u00b7cher", "winkt", ",", "ein", "treu\u00b7er", "Wirth", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAT", "VVFIN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Kommt und la\u00dft uns Herberg' nehmen,", "tokens": ["Kommt", "und", "la\u00dft", "uns", "Her\u00b7ber\u00b7g'", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVIMP", "PPER", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Kehret bei dem Heiland ein;", "tokens": ["Keh\u00b7ret", "bei", "dem", "Hei\u00b7land", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da wird Sehnen bald und Gr\u00e4men,", "tokens": ["Da", "wird", "Seh\u00b7nen", "bald", "und", "Gr\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "ADV", "KON", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Welt und Schmerz vergangen sein.", "tokens": ["Welt", "und", "Schmerz", "ver\u00b7gan\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wie sich alle Blumen wenden", "tokens": ["Wie", "sich", "al\u00b7le", "Blu\u00b7men", "wen\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu dem hellen Sonnenlicht,", "tokens": ["Zu", "dem", "hel\u00b7len", "Son\u00b7nen\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nehm' aus den durchbohrten H\u00e4nden", "tokens": ["Nehm'", "aus", "den", "durch\u00b7bohr\u00b7ten", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "Jeder an, was ihm gebricht!", "tokens": ["Je\u00b7der", "an", ",", "was", "ihm", "ge\u00b7bricht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "PTKVZ", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}