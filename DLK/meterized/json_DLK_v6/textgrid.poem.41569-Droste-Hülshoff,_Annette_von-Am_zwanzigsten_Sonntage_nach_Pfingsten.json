{"textgrid.poem.41569": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Am zwanzigsten Sonntage nach Pfingsten", "genre": "verse", "period": "N.A.", "pub_year": 1822, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn Tau auf reifen \u00c4hren gl\u00e4nzt,", "tokens": ["Wenn", "Tau", "auf", "rei\u00b7fen", "\u00c4h\u00b7ren", "gl\u00e4nzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die satten K\u00f6rner schwellen nicht;", "tokens": ["Die", "sat\u00b7ten", "K\u00f6r\u00b7ner", "schwel\u00b7len", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wenn den Toten man bekr\u00e4nzt,", "tokens": ["Und", "wenn", "den", "To\u00b7ten", "man", "be\u00b7kr\u00e4nzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die starren Pulse zucken nicht;", "tokens": ["Die", "star\u00b7ren", "Pul\u00b7se", "zu\u00b7cken", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn \u00fcber Tr\u00fcmmer geht das Licht,", "tokens": ["Wenn", "\u00fc\u00b7ber", "Tr\u00fcm\u00b7mer", "geht", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht eine S\u00e4ule wird erg\u00e4nzt,", "tokens": ["Nicht", "ei\u00b7ne", "S\u00e4u\u00b7le", "wird", "er\u00b7g\u00e4nzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und dennoch, schau!", "tokens": ["Und", "den\u00b7noch", ",", "schau", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "$,", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "D\u00fcnkt reiche Gabe Licht und Kranz und Tau!", "tokens": ["D\u00fcnkt", "rei\u00b7che", "Ga\u00b7be", "Licht", "und", "Kranz", "und", "Tau", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So nimmer Reue mag erbaun,", "tokens": ["So", "nim\u00b7mer", "Reu\u00b7e", "mag", "er\u00b7baun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was einmal Schuld gebrochen hat,", "tokens": ["Was", "ein\u00b7mal", "Schuld", "ge\u00b7bro\u00b7chen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dennoch Gottes Engel schaun", "tokens": ["Und", "den\u00b7noch", "Got\u00b7tes", "En\u00b7gel", "schaun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "NN", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mitleidig auf die w\u00fcste Statt;", "tokens": ["Mit\u00b7lei\u00b7dig", "auf", "die", "w\u00fcs\u00b7te", "Statt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So ragt auch wohl ein gr\u00fcnes Blatt", "tokens": ["So", "ragt", "auch", "wohl", "ein", "gr\u00fc\u00b7nes", "Blatt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch eines Kerkergitters Graun", "tokens": ["Durch", "ei\u00b7nes", "Ker\u00b7ker\u00b7git\u00b7ters", "Graun"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu dem Gefangnen und", "tokens": ["Zu", "dem", "Ge\u00b7fang\u00b7nen", "und"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Er l\u00e4chelt, seine Seele wird gesund.", "tokens": ["Er", "l\u00e4\u00b7chelt", ",", "sei\u00b7ne", "See\u00b7le", "wird", "ge\u00b7sund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "O k\u00f6nnte alle S\u00fcnde nur", "tokens": ["O", "k\u00f6nn\u00b7te", "al\u00b7le", "S\u00fcn\u00b7de", "nur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie \u00fcberm Ast der Mistel stehn,", "tokens": ["Wie", "\u00fc\u00b7berm", "Ast", "der", "Mis\u00b7tel", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der wurzellos durch die Natur", "tokens": ["Der", "wur\u00b7zel\u00b7los", "durch", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich selber bl\u00fchn darf und vergehn!", "tokens": ["Sich", "sel\u00b7ber", "bl\u00fchn", "darf", "und", "ver\u00b7gehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVINF", "VMFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch wie am d\u00fcrren Baume sehn", "tokens": ["Doch", "wie", "am", "d\u00fcr\u00b7ren", "Bau\u00b7me", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPRART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man wird des Schlinggew\u00e4chses Spur,", "tokens": ["Man", "wird", "des", "Schling\u00b7ge\u00b7w\u00e4ch\u00b7ses", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So ein Vampyr", "tokens": ["So", "ein", "Vam\u00b7pyr"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Dorrt sie die Seele und den K\u00f6rper dir.", "tokens": ["Dorrt", "sie", "die", "See\u00b7le", "und", "den", "K\u00f6r\u00b7per", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "KON", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wer frischt dir deinen Glauben auf,", "tokens": ["Wer", "frischt", "dir", "dei\u00b7nen", "Glau\u00b7ben", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Versengt an ihrem Odem hei\u00df?", "tokens": ["Ver\u00b7sengt", "an", "ih\u00b7rem", "O\u00b7dem", "hei\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer bringt dir der Gedanken Lauf", "tokens": ["Wer", "bringt", "dir", "der", "Ge\u00b7dan\u00b7ken", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur\u00fcck ins fromm beschr\u00e4nkte Gleis?", "tokens": ["Zu\u00b7r\u00fcck", "ins", "fromm", "be\u00b7schr\u00e4nk\u00b7te", "Gleis", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und deiner Menschenkenntnis Eis,", "tokens": ["Und", "dei\u00b7ner", "Men\u00b7schen\u00b7kennt\u00b7nis", "Eis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den starren Strom, wer l\u00f6st ihn auf,", "tokens": ["Den", "star\u00b7ren", "Strom", ",", "wer", "l\u00f6st", "ihn", "auf", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWS", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den wahren Flu\u00df,", "tokens": ["Den", "wah\u00b7ren", "Flu\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Der Himmel stets und H\u00f6lle scheiden mu\u00df?", "tokens": ["Der", "Him\u00b7mel", "stets", "und", "H\u00f6l\u00b7le", "schei\u00b7den", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und was dein K\u00f6rper b\u00fc\u00dfte ein", "tokens": ["Und", "was", "dein", "K\u00f6r\u00b7per", "b\u00fc\u00df\u00b7te", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In nagender Gef\u00fchle Joch,", "tokens": ["In", "na\u00b7gen\u00b7der", "Ge\u00b7f\u00fch\u00b7le", "Joch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das bleibt nun f\u00fcr dies Leben dein", "tokens": ["Das", "bleibt", "nun", "f\u00fcr", "dies", "Le\u00b7ben", "dein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PDS", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nach dem Dr\u00fcben greift es noch;", "tokens": ["Und", "nach", "dem", "Dr\u00fc\u00b7ben", "greift", "es", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wie an einem Haare doch", "tokens": ["Und", "wie", "an", "ei\u00b7nem", "Haa\u00b7re", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wirst immer du gehalten sein,", "tokens": ["Wirst", "im\u00b7mer", "du", "ge\u00b7hal\u00b7ten", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn frischer Geist", "tokens": ["Wenn", "fri\u00b7scher", "Geist"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "In frischem K\u00f6rper wie ein Adler kreist.", "tokens": ["In", "fri\u00b7schem", "K\u00f6r\u00b7per", "wie", "ein", "Ad\u00b7ler", "kreist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Sprach doch der allertreuste Mund:", "tokens": ["Sprach", "doch", "der", "al\u00b7ler\u00b7treus\u00b7te", "Mund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbvergeben leicht, und Heilen schwer.\u00ab", "tokens": ["\u00bb", "ver\u00b7ge\u00b7ben", "leicht", ",", "und", "Hei\u00b7len", "schwer", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "ADJD", "$,", "KON", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das ist der S\u00fcnde alter Bund,", "tokens": ["Das", "ist", "der", "S\u00fcn\u00b7de", "al\u00b7ter", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die zehrend wie Gomorrhas Meer", "tokens": ["Die", "zeh\u00b7rend", "wie", "Go\u00b7morr\u00b7has", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KOKOM", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ert\u00f6tet alle Frucht umher.", "tokens": ["Er\u00b7t\u00f6\u00b7tet", "al\u00b7le", "Frucht", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und dennoch kann das Mark gesund", "tokens": ["Und", "den\u00b7noch", "kann", "das", "Mark", "ge\u00b7sund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und himmelw\u00e4rts", "tokens": ["Und", "him\u00b7mel\u00b7w\u00e4rts"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+--", "measure": "dactylic.init"}, "line.8": {"text": "Kann treiben seinen Zweig des Baumes Herz.", "tokens": ["Kann", "trei\u00b7ben", "sei\u00b7nen", "Zweig", "des", "Bau\u00b7mes", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PPOSAT", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "O, nur Ergebung, nur Geduld!", "tokens": ["O", ",", "nur", "Er\u00b7ge\u00b7bung", ",", "nur", "Ge\u00b7duld", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "NN", "$,", "ADV", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zu tragen meiner Narben Schmach,", "tokens": ["Zu", "tra\u00b7gen", "mei\u00b7ner", "Nar\u00b7ben", "Schmach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um was gebrochen meine Schuld,", "tokens": ["Um", "was", "ge\u00b7bro\u00b7chen", "mei\u00b7ne", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PWS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu trauern still und reuig nach:", "tokens": ["Zu", "trau\u00b7ern", "still", "und", "reu\u00b7ig", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch \u00fcber mir steht ja das Dach", "tokens": ["Auch", "\u00fc\u00b7ber", "mir", "steht", "ja", "das", "Dach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Des Himmels und der Sonne Huld", "tokens": ["Des", "Him\u00b7mels", "und", "der", "Son\u00b7ne", "Huld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ach, der Tau,", "tokens": ["Und", "ach", ",", "der", "Tau", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Er f\u00e4llt ja auch auf meine hei\u00dfe Brau'!", "tokens": ["Er", "f\u00e4llt", "ja", "auch", "auf", "mei\u00b7ne", "hei\u00b7\u00dfe", "Brau'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Nicht wirst du Herr mich wandeln gehn,", "tokens": ["Nicht", "wirst", "du", "Herr", "mich", "wan\u00b7deln", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VAFIN", "PPER", "NN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht hei\u00dfen heben mich die Hand,", "tokens": ["Nicht", "hei\u00b7\u00dfen", "he\u00b7ben", "mich", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch eine S\u00e4ule darf ich stehn,", "tokens": ["Doch", "ei\u00b7ne", "S\u00e4u\u00b7le", "darf", "ich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Zeichen an dem \u00f6den Strand,", "tokens": ["Ein", "Zei\u00b7chen", "an", "dem", "\u00f6\u00b7den", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und hoffen, da\u00df wenn Sonnenbrand", "tokens": ["Und", "hof\u00b7fen", ",", "da\u00df", "wenn", "Son\u00b7nen\u00b7brand"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die morschen Tr\u00fcmmer lie\u00df vergehn,", "tokens": ["Die", "mor\u00b7schen", "Tr\u00fcm\u00b7mer", "lie\u00df", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "An jenem Tag", "tokens": ["An", "je\u00b7nem", "Tag"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Dein Strahl die St\u00e4ubchen aufw\u00e4rts ziehen mag.", "tokens": ["Dein", "Strahl", "die", "St\u00e4ub\u00b7chen", "auf\u00b7w\u00e4rts", "zie\u00b7hen", "mag."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPOSAT", "NN", "ART", "NN", "ADV", "VVFIN", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}