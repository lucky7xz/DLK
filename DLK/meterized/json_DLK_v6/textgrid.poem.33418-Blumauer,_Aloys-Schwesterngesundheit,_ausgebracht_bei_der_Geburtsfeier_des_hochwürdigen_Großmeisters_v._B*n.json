{"textgrid.poem.33418": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Schwesterngesundheit, ausgebracht bei der Geburtsfeier des hochw\u00fcrdigen Gro\u00dfmeisters v. B*n", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man spricht, ihr Schwestern, und mit Recht,", "tokens": ["Man", "spricht", ",", "ihr", "Schwes\u00b7tern", ",", "und", "mit", "Recht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPOSAT", "NN", "$,", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von euch und euerem Geschlecht", "tokens": ["Von", "euch", "und", "eu\u00b7e\u00b7rem", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "KON", "PPOSAT", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.3": {"text": "So gar viel b\u00f6se Sachen,", "tokens": ["So", "gar", "viel", "b\u00f6\u00b7se", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df es beinah' unschicklich l\u00e4\u00dft,", "tokens": ["Da\u00df", "es", "bei\u00b7nah'", "un\u00b7schick\u00b7lich", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Euch heut' an diesem grossen Fest", "tokens": ["Euch", "heut'", "an", "die\u00b7sem", "gros\u00b7sen", "Fest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Kompliment zu machen.", "tokens": ["Ein", "Kom\u00b7pli\u00b7ment", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Man will, ", "tokens": ["Man", "will", ","], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Von eu'rer ersten Urmama", "tokens": ["Von", "eu'\u00b7rer", "ers\u00b7ten", "Ur\u00b7ma\u00b7ma"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ganz zuverl\u00e4ssig wissen,", "tokens": ["Ganz", "zu\u00b7ver\u00b7l\u00e4s\u00b7sig", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df wir, weil sie zu einem Bi\u00df", "tokens": ["Da\u00df", "wir", ",", "weil", "sie", "zu", "ei\u00b7nem", "Bi\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Aus F\u00fcrwitz sich verleiten lie\u00df,", "tokens": ["Aus", "F\u00fcr\u00b7witz", "sich", "ver\u00b7lei\u00b7ten", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jetzt Hosen tragen m\u00fcssen.", "tokens": ["Jetzt", "Ho\u00b7sen", "tra\u00b7gen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Denkt dann an eine Dalila,", "tokens": ["Denkt", "dann", "an", "ei\u00b7ne", "Da\u00b7li\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An eu're Schwester Helena,", "tokens": ["An", "eu'\u00b7re", "Schwes\u00b7ter", "He\u00b7le\u00b7na", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und an die griech'schen Phrynen,", "tokens": ["Und", "an", "die", "griech'\u00b7schen", "Phry\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Denkt ferner an die Danaen,", "tokens": ["Denkt", "fer\u00b7ner", "an", "die", "Da\u00b7na\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Die Leden, die Pasiphaen,", "tokens": ["Die", "Le\u00b7den", ",", "die", "Pa\u00b7si\u00b7phaen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und an die Messalinen.", "tokens": ["Und", "an", "die", "Mes\u00b7sa\u00b7li\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Addirt zu dieser grossen Zahl", "tokens": ["Ad\u00b7dirt", "zu", "die\u00b7ser", "gros\u00b7sen", "Zahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "PDAT", "ADJA", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Die Phrynen uns'rer Zeiten all',", "tokens": ["Die", "Phry\u00b7nen", "un\u00b7s'\u00b7rer", "Zei\u00b7ten", "all'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PIS", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu viel, um sie zu nennen;", "tokens": ["Zu", "viel", ",", "um", "sie", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bedenkt die ganze Litaney,", "tokens": ["Be\u00b7denkt", "die", "gan\u00b7ze", "Li\u00b7ta\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sagt, was wir von eu'rer Treu'", "tokens": ["Und", "sagt", ",", "was", "wir", "von", "eu'\u00b7rer", "Treu'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Keuschheit halten k\u00f6nnen.", "tokens": ["Und", "Keuschheit", "hal\u00b7ten", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "VMINF", "$."], "meter": "-++-+-", "measure": "unknown.measure.tri"}}, "stanza.5": {"line.1": {"text": "Allein noch schlimmer ist's, wenn ihr", "tokens": ["Al\u00b7lein", "noch", "schlim\u00b7mer", "ist's", ",", "wenn", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Keuschen spielt; dann werdet ihr", "tokens": ["Die", "Keu\u00b7schen", "spielt", ";", "dann", "wer\u00b7det", "ihr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ADV", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Xantippen und Junonen,", "tokens": ["Xan\u00b7tip\u00b7pen", "und", "Ju\u00b7no\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ermordet eu're Buben dann,", "tokens": ["Er\u00b7mor\u00b7det", "eu'\u00b7re", "Bu\u00b7ben", "dann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zieht eu'rer M\u00e4nner Hosen an,", "tokens": ["Zieht", "eu'\u00b7rer", "M\u00e4n\u00b7ner", "Ho\u00b7sen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und werdet Amazonen.", "tokens": ["Und", "wer\u00b7det", "A\u00b7maz\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ihr Schwestern seid es, deren Hand", "tokens": ["Ihr", "Schwes\u00b7tern", "seid", "es", ",", "de\u00b7ren", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Persepolis und Trojens Brand", "tokens": ["Per\u00b7se\u00b7po\u00b7lis", "und", "Tro\u00b7jens", "Brand"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "In helle Flammen fachte:", "tokens": ["In", "hel\u00b7le", "Flam\u00b7men", "fach\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr seid es, die in einer Nacht", "tokens": ["Ihr", "seid", "es", ",", "die", "in", "ei\u00b7ner", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Fast so viel M\u00e4nner umgebracht,", "tokens": ["Fast", "so", "viel", "M\u00e4n\u00b7ner", "um\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als Herkules einst machte.", "tokens": ["Als", "Her\u00b7ku\u00b7les", "einst", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "VVFIN", "$."], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Es ist kein Argus in der Welt,", "tokens": ["Es", "ist", "kein", "Ar\u00b7gus", "in", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den ihr nicht um sein Auge prellt,", "tokens": ["Den", "ihr", "nicht", "um", "sein", "Au\u00b7ge", "prellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Und obend'rein noch h\u00f6hnet;", "tokens": ["Und", "o\u00b7ben\u00b7d'\u00b7rein", "noch", "h\u00f6h\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Selbst Maurer f\u00fchrt ihr hinter's Licht:", "tokens": ["Selbst", "Mau\u00b7rer", "f\u00fchrt", "ihr", "hin\u00b7ter's", "Licht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch ist kein K\u00f6nig, den ihr nicht", "tokens": ["Auch", "ist", "kein", "K\u00f6\u00b7nig", ",", "den", "ihr", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "PRELS", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum zweitenmale kr\u00f6net.", "tokens": ["Zum", "zwei\u00b7ten\u00b7ma\u00b7le", "kr\u00f6\u00b7net", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Doch, Schwestern, all' das Herzeleid,", "tokens": ["Doch", ",", "Schwes\u00b7tern", ",", "all'", "das", "Her\u00b7ze\u00b7leid", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "PIS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was \u00fcber uns zu jeder Zeit", "tokens": ["Was", "\u00fc\u00b7ber", "uns", "zu", "je\u00b7der", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch euch verh\u00e4nget worden,", "tokens": ["Durch", "euch", "ver\u00b7h\u00e4n\u00b7get", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "VAPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Und was ihr noch uns zugedacht,", "tokens": ["Und", "was", "ihr", "noch", "uns", "zu\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hat Eine wieder gut gemacht,", "tokens": ["Hat", "Ei\u00b7ne", "wie\u00b7der", "gut", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus eu'rem Schwesterorden.", "tokens": ["Aus", "eu'\u00b7rem", "Schwes\u00b7ter\u00b7or\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und diese theure Schwester war", "tokens": ["Und", "die\u00b7se", "theu\u00b7re", "Schwes\u00b7ter", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Frau, die uns den Mann gebar,", "tokens": ["Die", "Frau", ",", "die", "uns", "den", "Mann", "ge\u00b7bar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den wir zum Meister w\u00e4hlten;", "tokens": ["Den", "wir", "zum", "Meis\u00b7ter", "w\u00e4hl\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "D'rum auf, ihr Br\u00fcder, seid bereit!", "tokens": ["D'\u00b7rum", "auf", ",", "ihr", "Br\u00fc\u00b7der", ",", "seid", "be\u00b7reit", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "PTKVZ", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Ihr soll allein das Feuer heut'", "tokens": ["Ihr", "soll", "al\u00b7lein", "das", "Feu\u00b7er", "heut'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus unsern M\u00f6rsern gelten.", "tokens": ["Aus", "un\u00b7sern", "M\u00f6r\u00b7sern", "gel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}