{"dta.poem.4188": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Unsterblichkeit der Seele.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nachdem sich j\u00fcngst ein Sturm geleget,", "tokens": ["Nach\u00b7dem", "sich", "j\u00fcngst", "ein", "Sturm", "ge\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ich, von der noch regen See,", "tokens": ["Und", "ich", ",", "von", "der", "noch", "re\u00b7gen", "See", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da ich an ihrem Ufer steh,", "tokens": ["Da", "ich", "an", "ih\u00b7rem", "U\u00b7fer", "steh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Wanken ihrer Fl\u00e4che seh,", "tokens": ["Das", "Wan\u00b7ken", "ih\u00b7rer", "Fl\u00e4\u00b7che", "seh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die unaufh\u00f6rlich sich beweget;", "tokens": ["Die", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", "sich", "be\u00b7we\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Beweget mich ihr w\u00fchlend Wallen,", "tokens": ["Be\u00b7we\u00b7get", "mich", "ihr", "w\u00fch\u00b7lend", "Wal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ich auf ihrer Wellen Heer,", "tokens": ["Da\u00df", "ich", "auf", "ih\u00b7rer", "Wel\u00b7len", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und ihr best\u00e4ndigs Steigen, Fallen,", "tokens": ["Und", "ihr", "be\u00b7st\u00e4n\u00b7digs", "Stei\u00b7gen", ",", "Fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die angestrengte Blicke kehr.", "tokens": ["Die", "an\u00b7ge\u00b7streng\u00b7te", "Bli\u00b7cke", "kehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ich seh dieselben schnell entstehn,", "tokens": ["Ich", "seh", "die\u00b7sel\u00b7ben", "schnell", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sich sch\u00e4umend b\u00e4umen und erh\u00f6hn,", "tokens": ["Sich", "sch\u00e4u\u00b7mend", "b\u00e4u\u00b7men", "und", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Sich pl\u00f6tzlich senken und vergehn.", "tokens": ["Sich", "pl\u00f6tz\u00b7lich", "sen\u00b7ken", "und", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ich hatte dieses Fluhten-Spiel,", "tokens": ["Ich", "hat\u00b7te", "die\u00b7ses", "Fluh\u00b7ten\u00b7Spiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und ihr ver\u00e4nderlichs Gew\u00fchl,", "tokens": ["Und", "ihr", "ver\u00b7\u00e4n\u00b7der\u00b7lichs", "Ge\u00b7w\u00fchl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Kaum eine Zeitlang angesehn;", "tokens": ["Kaum", "ei\u00b7ne", "Zeit\u00b7lang", "an\u00b7ge\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "So brachte mich der Wellen Wanken,", "tokens": ["So", "brach\u00b7te", "mich", "der", "Wel\u00b7len", "Wan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Derselben rege Fl\u00fcchtigkeit,", "tokens": ["Der\u00b7sel\u00b7ben", "re\u00b7ge", "Fl\u00fcch\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Die kurze Dauer ihrer Zeit,", "tokens": ["Die", "kur\u00b7ze", "Dau\u00b7er", "ih\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Zu diesen ernstlichen Gedanken:", "tokens": ["Zu", "die\u00b7sen", "ernst\u00b7li\u00b7chen", "Ge\u00b7dan\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Mich deucht, es scheinen schnelle Wellen", "tokens": ["Mich", "deucht", ",", "es", "schei\u00b7nen", "schnel\u00b7le", "Wel\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Bild des Lebens vorzustellen,", "tokens": ["Ein", "Bild", "des", "Le\u00b7bens", "vor\u00b7zu\u00b7stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da wir auch schnell, wie sie, vergehn.", "tokens": ["Da", "wir", "auch", "schnell", ",", "wie", "sie", ",", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "PWAV", "PPER", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie kommen, zeigen sich, sie schwellen,", "tokens": ["Sie", "kom\u00b7men", ",", "zei\u00b7gen", "sich", ",", "sie", "schwel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PRF", "$,", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie bersten, da sie kaum entstehn,", "tokens": ["Sie", "bers\u00b7ten", ",", "da", "sie", "kaum", "ent\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie st\u00fcrzen pl\u00f6tzlich sich hernieder,", "tokens": ["Sie", "st\u00fcr\u00b7zen", "pl\u00f6tz\u00b7lich", "sich", "her\u00b7nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und mischen, mit der Fluht, sich wieder.", "tokens": ["Und", "mi\u00b7schen", ",", "mit", "der", "Fluht", ",", "sich", "wie\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "ART", "NN", "$,", "PRF", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So scheint es auch mit uns zu gehn:", "tokens": ["So", "scheint", "es", "auch", "mit", "uns", "zu", "gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wir kommen. Kaum, da\u00df wir uns zeigen;", "tokens": ["Wir", "kom\u00b7men", ".", "Kaum", ",", "da\u00df", "wir", "uns", "zei\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADV", "$,", "KOUS", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So br\u00fcsten wir uns schon im Steigen,", "tokens": ["So", "br\u00fcs\u00b7ten", "wir", "uns", "schon", "im", "Stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Bald sinken wir von unsern H\u00f6h\u2019n,", "tokens": ["Bald", "sin\u00b7ken", "wir", "von", "un\u00b7sern", "H\u00f6h'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wir dann wiederum zur Erden,", "tokens": ["Da", "wir", "dann", "wie\u00b7de\u00b7rum", "zur", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(auch wie sie) was wir waren, werden.", "tokens": ["(", "auch", "wie", "sie", ")", "was", "wir", "wa\u00b7ren", ",", "wer\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "KOKOM", "PPER", "$(", "PWS", "PPER", "VAFIN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die\u00df Gleichni\u00df mu\u00dft\u2019 ich \u00e4hnlich sch\u00e4tzen,", "tokens": ["Die\u00df", "Gleich\u00b7ni\u00df", "mu\u00dft'", "ich", "\u00e4hn\u00b7lich", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wie ich mich darauf besann;", "tokens": ["Und", "wie", "ich", "mich", "da\u00b7rauf", "be\u00b7sann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gerieht ich fast in ein Entsetzen,", "tokens": ["Ge\u00b7rieht", "ich", "fast", "in", "ein", "Ent\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df es mit uns so bald gethan.", "tokens": ["Da\u00df", "es", "mit", "uns", "so", "bald", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Allein, es gab der Wahrheit Licht,", "tokens": ["Al\u00b7lein", ",", "es", "gab", "der", "Wahr\u00b7heit", "Licht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mir diesen tr\u00f6stlichen Bericht:", "tokens": ["Mir", "die\u00b7sen", "tr\u00f6st\u00b7li\u00b7chen", "Be\u00b7richt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "\u201cdie\u00df gehet blo\u00df den Leib nur an;", "tokens": ["\u201c", "die\u00df", "ge\u00b7het", "blo\u00df", "den", "Leib", "nur", "an", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "ADV", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und fuhr sie fort, mir zu erkl\u00e4ren:", "tokens": ["Und", "fuhr", "sie", "fort", ",", "mir", "zu", "er\u00b7kl\u00e4\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "\u201cmein Wesen m\u00fcsse ewig w\u00e4hren.", "tokens": ["\u201c", "mein", "We\u00b7sen", "m\u00fcs\u00b7se", "e\u00b7wig", "w\u00e4h\u00b7ren", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Gedenke nicht, da\u00df dieser Schlu\u00df", "tokens": ["Ge\u00b7den\u00b7ke", "nicht", ",", "da\u00df", "die\u00b7ser", "Schlu\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Der Hoffnung, die in dir sich findet,", "tokens": ["Der", "Hoff\u00b7nung", ",", "die", "in", "dir", "sich", "fin\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Sich blo\u00df auf deinen Nutzen gr\u00fcndet;", "tokens": ["Sich", "blo\u00df", "auf", "dei\u00b7nen", "Nut\u00b7zen", "gr\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Da\u00df man ihn desfalls glauben mu\u00df.", "tokens": ["Da\u00df", "man", "ihn", "des\u00b7falls", "glau\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "O nein, du hast ihn anzusehn", "tokens": ["O", "nein", ",", "du", "hast", "ihn", "an\u00b7zu\u00b7sehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKANT", "$,", "PPER", "VAFIN", "PPER", "VVIZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Als einen unbewegten Grund, den Sch\u00f6pfer Selber zu", "tokens": ["Als", "ei\u00b7nen", "un\u00b7be\u00b7weg\u00b7ten", "Grund", ",", "den", "Sch\u00f6p\u00b7fer", "Sel\u00b7ber", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "PTKZU"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.19": {"text": "erh\u00f6hn.", "tokens": ["er\u00b7h\u00f6hn", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.20": {"text": "Sollt\u2019 ein, mit solcher Meng\u2019 Jdeen,", "tokens": ["Sollt'", "ein", ",", "mit", "sol\u00b7cher", "Meng'", "Jdeen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "$,", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.21": {"text": "(wodurch wir einen Sch\u00f6pfer sehen)", "tokens": ["(", "wo\u00b7durch", "wir", "ei\u00b7nen", "Sch\u00f6p\u00b7fer", "se\u00b7hen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "So wunderbar- begabtes Wesen,", "tokens": ["So", "wun\u00b7der\u00b7ba\u00b7r", "be\u00b7gab\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Zu solcher kurzen Daur erlesen,", "tokens": ["Zu", "sol\u00b7cher", "kur\u00b7zen", "Daur", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und f\u00fcr den Augenblick allein,", "tokens": ["Und", "f\u00fcr", "den", "Au\u00b7gen\u00b7blick", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Den wir hier sind, bestimmet seyn?", "tokens": ["Den", "wir", "hier", "sind", ",", "be\u00b7stim\u00b7met", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "$,", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Wie stimmte die\u00df mit einer Liebe,", "tokens": ["Wie", "stimm\u00b7te", "die\u00df", "mit", "ei\u00b7ner", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PDS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Von einer Gottheit, \u00fcberein,", "tokens": ["Von", "ei\u00b7ner", "Got\u00b7theit", ",", "\u00fc\u00b7be\u00b7re\u00b7in", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.28": {"text": "Die Selbst in unsre Seelen schriebe:", "tokens": ["Die", "Selbst", "in", "uns\u00b7re", "See\u00b7len", "schrie\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Da\u00df solche kaum entstandne Triebe,", "tokens": ["Da\u00df", "sol\u00b7che", "kaum", "ent\u00b7stand\u00b7ne", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "F\u00fcr ein unendlichs, ewigs Seyn,", "tokens": ["F\u00fcr", "ein", "un\u00b7end\u00b7lichs", ",", "e\u00b7wigs", "Seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Zu niedertr\u00e4chtig und zu klein.", "tokens": ["Zu", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "und", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "KON", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die richtige Verg\u00e4nglichkeit der c\u00f6rperlichen Creatu-", "tokens": ["Die", "rich\u00b7ti\u00b7ge", "Ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "der", "c\u00f6r\u00b7per\u00b7li\u00b7chen", "Crea\u00b7tu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "ren", "tokens": ["ren"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Zeigt eines Sch\u00f6pfers weise Macht. Der Seelen Daur", "tokens": ["Zeigt", "ei\u00b7nes", "Sch\u00f6p\u00b7fers", "wei\u00b7se", "Macht", ".", "Der", "See\u00b7len", "Daur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN", "$.", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "allein giebt Spuren", "tokens": ["al\u00b7lein", "giebt", "Spu\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Von GOttes weis- und ew\u2019gen Liebe. Wenn wir derselben", "tokens": ["Von", "Got\u00b7tes", "weis", "und", "ew'\u00b7gen", "Lie\u00b7be", ".", "Wenn", "wir", "der\u00b7sel\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "TRUNC", "KON", "ADJA", "NN", "$.", "KOUS", "PPER", "PDAT"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Daur nicht glauben,", "tokens": ["Daur", "nicht", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Was thun wir sonst, als da\u00df wir GOtt der besten Eigenschaft", "tokens": ["Was", "thun", "wir", "sonst", ",", "als", "da\u00df", "wir", "Gott", "der", "bes\u00b7ten", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "KOKOM", "KOUS", "PPER", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "berauben,", "tokens": ["be\u00b7rau\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Und, statt wir hier, nach allen Kr\u00e4ften, die Gottheit schuldig", "tokens": ["Und", ",", "statt", "wir", "hier", ",", "nach", "al\u00b7len", "Kr\u00e4f\u00b7ten", ",", "die", "Got\u00b7theit", "schul\u00b7dig"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "KOUI", "PPER", "ADV", "$,", "APPR", "PIAT", "NN", "$,", "ART", "NN", "ADJD"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "seyn zu ehren,", "tokens": ["seyn", "zu", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAINF", "PTKZU", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "Selbst GOtt so viel an uns verkleinern, uns gleichsam wider", "tokens": ["Selbst", "Gott", "so", "viel", "an", "uns", "ver\u00b7klei\u00b7nern", ",", "uns", "gleich\u00b7sam", "wi\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "ADV", "ADV", "APPR", "PPER", "VVINF", "$,", "PPER", "ADJD", "PTKVZ"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Gott erkl\u00e4ren.", "tokens": ["Gott", "er\u00b7kl\u00e4\u00b7ren", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Ja wie, wenn kein Gesch\u00f6pfe w\u00e4re, wir nichts vom Sch\u00f6pfer", "tokens": ["Ja", "wie", ",", "wenn", "kein", "Ge\u00b7sch\u00f6p\u00b7fe", "w\u00e4\u00b7re", ",", "wir", "nichts", "vom", "Sch\u00f6p\u00b7fer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "PWAV", "$,", "KOUS", "PIAT", "NN", "VAFIN", "$,", "PPER", "PIS", "APPRART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "wissen k\u00f6nnten;", "tokens": ["wis\u00b7sen", "k\u00f6nn\u00b7ten", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VMFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.15": {"text": "So w\u00fcrden, wenn wir von der Seele derselben stete Dauer", "tokens": ["So", "w\u00fcr\u00b7den", ",", "wenn", "wir", "von", "der", "See\u00b7le", "der\u00b7sel\u00b7ben", "ste\u00b7te", "Dau\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "PDAT", "ADJA", "NN"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.16": {"text": "trennten,", "tokens": ["trenn\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.17": {"text": "Wir den gefundnen GOtt verlieren. Denn, h\u00f6rte mit dem", "tokens": ["Wir", "den", "ge\u00b7fund\u00b7nen", "Gott", "ver\u00b7lie\u00b7ren", ".", "Denn", ",", "h\u00f6r\u00b7te", "mit", "dem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN", "VVINF", "$.", "KON", "$,", "VVFIN", "APPR", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Lebens-Lauf,", "tokens": ["Le\u00b7bens\u00b7Lauf", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.19": {"text": "Und wenn des C\u00f6rpers Stoff sich trennet, auch unsrer Seelen", "tokens": ["Und", "wenn", "des", "C\u00f6r\u00b7pers", "Stoff", "sich", "tren\u00b7net", ",", "auch", "uns\u00b7rer", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "PRF", "VVFIN", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Wesen auf;", "tokens": ["We\u00b7sen", "auf", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.21": {"text": "So w\u00e4r, wenn auch die Gottheit bliebe, dennoch f\u00fcr uns kein", "tokens": ["So", "w\u00e4r", ",", "wenn", "auch", "die", "Got\u00b7theit", "blie\u00b7be", ",", "den\u00b7noch", "f\u00fcr", "uns", "kein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "ADV", "ART", "NN", "VVFIN", "$,", "ADV", "APPR", "PPER", "PIAT"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.22": {"text": "Gott vorhanden,", "tokens": ["Gott", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.23": {"text": "Und, w\u00e4ren wir, da auf der Welt,", "tokens": ["Und", ",", "w\u00e4\u00b7ren", "wir", ",", "da", "auf", "der", "Welt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "PPER", "$,", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Die wahre Tugend selten Lohn, das Laster selten Straf\u2019", "tokens": ["Die", "wah\u00b7re", "Tu\u00b7gend", "sel\u00b7ten", "Lohn", ",", "das", "Las\u00b7ter", "sel\u00b7ten", "Straf'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.25": {"text": "erh\u00e4tt,", "tokens": ["er\u00b7h\u00e4tt", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.26": {"text": "So gut als wie von Ungefehr, und sonder einen GOtt,", "tokens": ["So", "gut", "als", "wie", "von", "Un\u00b7ge\u00b7fehr", ",", "und", "son\u00b7der", "ei\u00b7nen", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "KOKOM", "APPR", "NN", "$,", "KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.27": {"text": "entstanden.", "tokens": ["ent\u00b7stan\u00b7den", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.5": {"line.1": {"text": "So zweifle denn, gescheuchte Seele, nicht ferner an der", "tokens": ["So", "zweif\u00b7le", "denn", ",", "ge\u00b7scheuch\u00b7te", "See\u00b7le", ",", "nicht", "fer\u00b7ner", "an", "der"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "$,", "ADJA", "NN", "$,", "PTKNEG", "ADV", "APPR", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "wahren Lehre,", "tokens": ["wah\u00b7ren", "Leh\u00b7re", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Du seyst zum andern Stand ersehen. Es fordert nicht nur", "tokens": ["Du", "seyst", "zum", "an\u00b7dern", "Stand", "er\u00b7se\u00b7hen", ".", "Es", "for\u00b7dert", "nicht", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN", "VVINF", "$.", "PPER", "VVFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "unsre Pflicht,", "tokens": ["uns\u00b7re", "Pflicht", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Es fordert es die Eigenliebe, und unser eigen Nutzen", "tokens": ["Es", "for\u00b7dert", "es", "die", "Ei\u00b7gen\u00b7lie\u00b7be", ",", "und", "un\u00b7ser", "ei\u00b7gen", "Nut\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "nicht,", "tokens": ["nicht", ","], "token_info": ["word", "punct"], "pos": ["PTKNEG", "$,"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Es fordert diesen wahren Glauben selbst unsers ", "tokens": ["Es", "for\u00b7dert", "die\u00b7sen", "wah\u00b7ren", "Glau\u00b7ben", "selbst", "un\u00b7sers"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "ADJA", "NN", "ADV", "PPOSAT"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Sch\u00f6pfers Ehre.", "tokens": ["Sch\u00f6p\u00b7fers", "Eh\u00b7re", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}