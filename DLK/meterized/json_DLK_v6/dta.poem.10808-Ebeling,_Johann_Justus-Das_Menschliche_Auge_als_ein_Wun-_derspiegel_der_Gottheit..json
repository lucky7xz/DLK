{"dta.poem.10808": {"metadata": {"author": {"name": "Ebeling, Johann Justus", "birth": "N.A.", "death": "N.A."}, "title": "Das  \n Menschliche Auge als ein Wun-  \n derspiegel der Gottheit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1747", "urn": "urn:nbn:de:kobv:b4-200905198774", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So wie GOtt, des Lichtes Bronnen,", "tokens": ["So", "wie", "Gott", ",", "des", "Lich\u00b7tes", "Bron\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als hat das Auge dieser Welt,", "tokens": ["Als", "hat", "das", "Au\u00b7ge", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In dem feurgen Rund der Son-", "tokens": ["In", "dem", "feur\u00b7gen", "Rund", "der", "Son"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "TRUNC"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "An das Firmament gestellt:", "tokens": ["An", "das", "Fir\u00b7ma\u00b7ment", "ge\u00b7stellt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So hat er auch an den H\u00f6hen,", "tokens": ["So", "hat", "er", "auch", "an", "den", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Einer kleinen Welt ersehen;", "tokens": ["Ei\u00b7ner", "klei\u00b7nen", "Welt", "er\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "An dem menschlichen Gesicht,", "tokens": ["An", "dem", "menschli\u00b7chen", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Ein recht herrlich Sonnenlicht.", "tokens": ["Ein", "recht", "herr\u00b7lich", "Son\u00b7nen\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Dieses sind die zwo Kristallen,", "tokens": ["Die\u00b7ses", "sind", "die", "zwo", "Kris\u00b7tal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "CARD", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Die in unsern Haupte stehn,", "tokens": ["Die", "in", "un\u00b7sern", "Haup\u00b7te", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dadurch rege Strahlen prallen,", "tokens": ["Da\u00b7durch", "re\u00b7ge", "Strah\u00b7len", "pral\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die bis ins Gehirne gehn:", "tokens": ["Die", "bis", "ins", "Ge\u00b7hir\u00b7ne", "gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dadurch wird der Leib erhellet,", "tokens": ["Da\u00b7durch", "wird", "der", "Leib", "er\u00b7hel\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Und der Seelen dargestellet,", "tokens": ["Und", "der", "See\u00b7len", "dar\u00b7ge\u00b7stel\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was der Erd und Himmelsbau,", "tokens": ["Was", "der", "Erd", "und", "Him\u00b7mels\u00b7bau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Uns vor Sch\u00f6nheit legt zum Schau.", "tokens": ["Uns", "vor", "Sch\u00f6n\u00b7heit", "legt", "zum", "Schau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Sieht man in den weiten Grenzen,", "tokens": ["Sieht", "man", "in", "den", "wei\u00b7ten", "Gren\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsers Sch\u00f6pfers Herrligkeit,", "tokens": ["Un\u00b7sers", "Sch\u00f6p\u00b7fers", "Herr\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus der Sonnen Spiegel gl\u00e4nzen,", "tokens": ["Aus", "der", "Son\u00b7nen", "Spie\u00b7gel", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deren Anblik uns erfreut;", "tokens": ["De\u00b7ren", "An\u00b7blik", "uns", "er\u00b7freut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So strahlt auch aus dem Gesichte", "tokens": ["So", "strahlt", "auch", "aus", "dem", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Aus dem hellen Augenlichte", "tokens": ["Aus", "dem", "hel\u00b7len", "Au\u00b7gen\u00b7lich\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Unsers grossen Sch\u00f6pfers Zier,", "tokens": ["Un\u00b7sers", "gros\u00b7sen", "Sch\u00f6p\u00b7fers", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Dessen weise Macht herf\u00fcr.", "tokens": ["Des\u00b7sen", "wei\u00b7se", "Macht", "her\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Dieses kl\u00e4rlich zu beweisen", "tokens": ["Die\u00b7ses", "kl\u00e4r\u00b7lich", "zu", "be\u00b7wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJD", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So bedenket und erwegt,", "tokens": ["So", "be\u00b7den\u00b7ket", "und", "er\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was in zwey so kleinen Kreisen,", "tokens": ["Was", "in", "zwey", "so", "klei\u00b7nen", "Krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "CARD", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was in aller Welt zu finden,", "tokens": ["Was", "in", "al\u00b7ler", "Welt", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mu\u00df sich hier gleichsam verbinden;", "tokens": ["Mu\u00df", "sich", "hier", "gleich\u00b7sam", "ver\u00b7bin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Dadurch blikt die Seele an,", "tokens": ["Da\u00b7durch", "blikt", "die", "See\u00b7le", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.7": {"text": "Alles was man finden kan.", "tokens": ["Al\u00b7les", "was", "man", "fin\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PWS", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was sehr gros, sich weit ausbreitet,", "tokens": ["Was", "sehr", "gros", ",", "sich", "weit", "aus\u00b7brei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "$,", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Selbst das breite Firmament,", "tokens": ["Selbst", "das", "brei\u00b7te", "Fir\u00b7ma\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird ins Auge eingeleitet;", "tokens": ["Wird", "ins", "Au\u00b7ge", "ein\u00b7ge\u00b7lei\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Sonne die dran brennt,", "tokens": ["Und", "die", "Son\u00b7ne", "die", "dran", "brennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "PAV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die ein K\u00f6rper dessen Strahlen,", "tokens": ["Die", "ein", "K\u00f6r\u00b7per", "des\u00b7sen", "Strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PRELAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ungeheure Zirkel mahlen;", "tokens": ["Un\u00b7ge\u00b7heu\u00b7re", "Zir\u00b7kel", "mah\u00b7len", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Nichts kann so vergr\u00f6ssert seyn,", "tokens": ["Nichts", "kann", "so", "ver\u00b7gr\u00f6s\u00b7sert", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Unser Auge schlie\u00dft es ein.", "tokens": ["Un\u00b7ser", "Au\u00b7ge", "schlie\u00dft", "es", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Dieses Fernglas unsrer Seele,", "tokens": ["Die\u00b7ses", "Fern\u00b7glas", "uns\u00b7rer", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsrer Augen doppelt Rund,", "tokens": ["Uns\u00b7rer", "Au\u00b7gen", "dop\u00b7pelt", "Rund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lieget in zwiefacher H\u00f6le,", "tokens": ["Lie\u00b7get", "in", "zwie\u00b7fac\u00b7her", "H\u00f6\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Stekt in einem tieffen Grund,", "tokens": ["Stekt", "in", "ei\u00b7nem", "tief\u00b7fen", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lenkt sich zu der Nerven Quelle", "tokens": ["Lenkt", "sich", "zu", "der", "Ner\u00b7ven", "Quel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zum Gehirn, alwo die Stelle", "tokens": ["Zum", "Ge\u00b7hirn", ",", "al\u00b7wo", "die", "Stel\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PWAV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da es seinen Ursprung nimt,", "tokens": ["Da", "es", "sei\u00b7nen", "Ur\u00b7sprung", "nimt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weil es f\u00fcr dem Geist bestimmt.", "tokens": ["Weil", "es", "f\u00fcr", "dem", "Geist", "be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Man kann an dem innren Wesen,", "tokens": ["Man", "kann", "an", "dem", "inn\u00b7ren", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "An der \u00e4usren Einrichtung,", "tokens": ["An", "der", "\u00e4us\u00b7ren", "Ein\u00b7rich\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Weil wir mit Bewunderung", "tokens": ["Weil", "wir", "mit", "Be\u00b7wun\u00b7de\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein recht k\u00fcnstliches Verbinden,", "tokens": ["Ein", "recht", "k\u00fcnst\u00b7li\u00b7ches", "Ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vieler kleinen Theile finden,", "tokens": ["Vie\u00b7ler", "klei\u00b7nen", "Thei\u00b7le", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Woraus sichtbarlich erhellt,", "tokens": ["Wo\u00b7raus", "sicht\u00b7bar\u00b7lich", "er\u00b7hellt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wer dies Kunstwerk so gestellt.", "tokens": ["Wer", "dies", "Kunst\u00b7werk", "so", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Jedes Aug in seinem Fache,", "tokens": ["Je\u00b7des", "Aug", "in", "sei\u00b7nem", "Fa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist mit Knochen woll versezt,", "tokens": ["Ist", "mit", "Kno\u00b7chen", "woll", "ver\u00b7sezt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liegt als unter einem Dache,", "tokens": ["Liegt", "als", "un\u00b7ter", "ei\u00b7nem", "Da\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df es bleibe unverlezt;", "tokens": ["Da\u00df", "es", "blei\u00b7be", "un\u00b7ver\u00b7lezt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Es liegt unter einem Bogen,", "tokens": ["Es", "liegt", "un\u00b7ter", "ei\u00b7nem", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Der mit Haaren \u00fcberzogen,", "tokens": ["Der", "mit", "Haa\u00b7ren", "\u00fc\u00b7berz\u00b7o\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Daran noch ein Vorhang h\u00e4ngt,", "tokens": ["Da\u00b7ran", "noch", "ein", "Vor\u00b7hang", "h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Der sich auf und abwerts lenkt.", "tokens": ["Der", "sich", "auf", "und", "ab\u00b7werts", "lenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PTKVZ", "KON", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wie gar leicht verderben Glieder,", "tokens": ["Wie", "gar", "leicht", "ver\u00b7der\u00b7ben", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die so k\u00fcnstlich, klein und zart;", "tokens": ["Die", "so", "k\u00fcnst\u00b7lich", ",", "klein", "und", "zart", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Darum sind sie hin und wieder,", "tokens": ["Da\u00b7rum", "sind", "sie", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PTKVZ", "KON", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Oben, unten woll verwahrt.", "tokens": ["O\u00b7ben", ",", "un\u00b7ten", "woll", "ver\u00b7wahrt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese Fenster haben Laden,", "tokens": ["Die\u00b7se", "Fens\u00b7ter", "ha\u00b7ben", "La\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df kein Zufal k\u00f6nne schaden;", "tokens": ["Da\u00df", "kein", "Zu\u00b7fal", "k\u00f6n\u00b7ne", "scha\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Diese ziehn in einem Nu,", "tokens": ["Die\u00b7se", "ziehn", "in", "ei\u00b7nem", "Nu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sich wies Noth ist, auf und zu.", "tokens": ["Sich", "wies", "Noth", "ist", ",", "auf", "und", "zu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "NN", "VAFIN", "$,", "APPR", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Diese zarten Augenlieder,", "tokens": ["Die\u00b7se", "zar\u00b7ten", "Au\u00b7gen\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die stat der Gardienen seyn,", "tokens": ["Die", "stat", "der", "Gar\u00b7die\u00b7nen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAINF", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.3": {"text": "Fallen wie ein Vorhang nieder,", "tokens": ["Fal\u00b7len", "wie", "ein", "Vor\u00b7hang", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn des Lichtes heller Schein,", "tokens": ["Wenn", "des", "Lich\u00b7tes", "hel\u00b7ler", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gar zu stark ins Auge blendet;", "tokens": ["Gar", "zu", "stark", "ins", "Au\u00b7ge", "blen\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dadurch wird auch abgewendet,", "tokens": ["Da\u00b7durch", "wird", "auch", "ab\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Mancher Zufal der entsteht,", "tokens": ["Man\u00b7cher", "Zu\u00b7fal", "der", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "VVFIN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.8": {"text": "Und sich nach dem Augen dreht.", "tokens": ["Und", "sich", "nach", "dem", "Au\u00b7gen", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Sie sind gleichsam in der Mitten,", "tokens": ["Sie", "sind", "gleich\u00b7sam", "in", "der", "Mit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von einander abgetheilt,", "tokens": ["Von", "ein\u00b7an\u00b7der", "ab\u00b7ge\u00b7theilt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein Vorhang der zerschnitten,", "tokens": ["Und", "ein", "Vor\u00b7hang", "der", "zer\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Abwerts und auch aufwerts eilt;", "tokens": ["Ab\u00b7werts", "und", "auch", "auf\u00b7werts", "eilt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oben, unten angeschlossen:", "tokens": ["O\u00b7ben", ",", "un\u00b7ten", "an\u00b7ge\u00b7schlos\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn sie beide losgeschossen:", "tokens": ["Wenn", "sie", "bei\u00b7de", "los\u00b7ge\u00b7schos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "So ist jedes Aug verdekt,", "tokens": ["So", "ist", "je\u00b7des", "Aug", "ver\u00b7dekt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und ins Futteral verstekt.", "tokens": ["Und", "ins", "Fut\u00b7te\u00b7ral", "vers\u00b7tekt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Da\u00df sie nicht verschrumpfet liegen,", "tokens": ["Da\u00df", "sie", "nicht", "ver\u00b7schrump\u00b7fet", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und sich nicht zu langsam drehn,", "tokens": ["Und", "sich", "nicht", "zu", "lang\u00b7sam", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PTKNEG", "PTKA", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn sie auf und abwerts fliegen;", "tokens": ["Wenn", "sie", "auf", "und", "ab\u00b7werts", "flie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKVZ", "KON", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So hat ", "tokens": ["So", "hat"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Da\u00df sie an den runden Bogen,", "tokens": ["Da\u00df", "sie", "an", "den", "run\u00b7den", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der sehr kn\u00f6rplich, aufgezogen,", "tokens": ["Der", "sehr", "kn\u00f6r\u00b7plich", ",", "auf\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "$,", "VVPP", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Und durch zarter Muskeln Band,", "tokens": ["Und", "durch", "zar\u00b7ter", "Mus\u00b7keln", "Band", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "An dem Rande ausgespannt.", "tokens": ["An", "dem", "Ran\u00b7de", "aus\u00b7ge\u00b7spannt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Sie bestehn aus fleischern H\u00e4uten,", "tokens": ["Sie", "be\u00b7stehn", "aus", "flei\u00b7schern", "H\u00e4u\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die von aussen etwas hart;", "tokens": ["Die", "von", "aus\u00b7sen", "et\u00b7was", "hart", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch sehr sanffte sich ausspreiten,", "tokens": ["Doch", "sehr", "sanff\u00b7te", "sich", "aus\u00b7sprei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "VVIZU", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Weil sie innerlich sehr zart;", "tokens": ["Weil", "sie", "in\u00b7ner\u00b7lich", "sehr", "zart", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und das Auge gar nicht dr\u00fckken,", "tokens": ["Und", "das", "Au\u00b7ge", "gar", "nicht", "dr\u00fck\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn sie sich dar\u00fcber r\u00fckken;", "tokens": ["Wenn", "sie", "sich", "da\u00b7r\u00fc\u00b7ber", "r\u00fck\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sie sind wenn man sie erwegt,", "tokens": ["Sie", "sind", "wenn", "man", "sie", "er\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Wie mit Sammt sanfft ausgelegt.", "tokens": ["Wie", "mit", "Sammt", "sanfft", "aus\u00b7ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Diese H\u00e4utgen die versp\u00fcren,", "tokens": ["Die\u00b7se", "H\u00e4ut\u00b7gen", "die", "ver\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leicht wenn was in Augen stekt,", "tokens": ["Leicht", "wenn", "was", "in", "Au\u00b7gen", "stekt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOUS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn sie nur etwas ber\u00fchren,", "tokens": ["Wenn", "sie", "nur", "et\u00b7was", "be\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df als unrein sie beflekt:", "tokens": ["Da\u00df", "als", "un\u00b7rein", "sie", "be\u00b7flekt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und das kan uns dazu n\u00fczzen,", "tokens": ["Und", "das", "kan", "uns", "da\u00b7zu", "n\u00fcz\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "PRF", "PAV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df wir es nicht lassen sizzen:", "tokens": ["Da\u00df", "wir", "es", "nicht", "las\u00b7sen", "siz\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sondern uns so gleich bem\u00fchn,", "tokens": ["Son\u00b7dern", "uns", "so", "gleich", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weg zu wischen, weg zu ziehn.", "tokens": ["Weg", "zu", "wi\u00b7schen", ",", "weg", "zu", "ziehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "An der Lieder \u00e4usren Spizzen", "tokens": ["An", "der", "Lie\u00b7der", "\u00e4us\u00b7ren", "Spiz\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Allwo sie zusammen gehn,", "tokens": ["All\u00b7wo", "sie", "zu\u00b7sam\u00b7men", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Find man steiffe Haare sizzen,", "tokens": ["Find", "man", "steif\u00b7fe", "Haa\u00b7re", "siz\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich oben aufwerts drehn:", "tokens": ["Die", "sich", "o\u00b7ben", "auf\u00b7werts", "drehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber an dem Untern beugen,", "tokens": ["A\u00b7ber", "an", "dem", "Un\u00b7tern", "beu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Niederwerts sich k\u00fcnstlich neigen:", "tokens": ["Nie\u00b7der\u00b7werts", "sich", "k\u00fcnst\u00b7lich", "nei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df sie nicht durch das Ber\u00fchrn,", "tokens": ["Da\u00df", "sie", "nicht", "durch", "das", "Be\u00b7r\u00fchrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sich verwikkeln und verliehrn.", "tokens": ["Sich", "ver\u00b7wik\u00b7keln", "und", "ver\u00b7liehrn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Diese Haare die steif hangen,", "tokens": ["Die\u00b7se", "Haa\u00b7re", "die", "steif", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ART", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind in vielen F\u00e4llen nuz;", "tokens": ["Sind", "in", "vie\u00b7len", "F\u00e4l\u00b7len", "nuz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sie gleich den Staub auffangen;", "tokens": ["Da\u00df", "sie", "gleich", "den", "Staub", "auf\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dienen unsern Aug zum Schuz,", "tokens": ["Die\u00b7nen", "un\u00b7sern", "Aug", "zum", "Schuz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wider die Unreinigkeiten,", "tokens": ["Wi\u00b7der", "die", "Un\u00b7rei\u00b7nig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Die sie gleich vor\u00fcber leiten:", "tokens": ["Die", "sie", "gleich", "vor\u00b7\u00fc\u00b7ber", "lei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Damit sie desselben Schein,", "tokens": ["Da\u00b7mit", "sie", "des\u00b7sel\u00b7ben", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nicht, wie sonsten sch\u00e4dlich seyn.", "tokens": ["Nicht", ",", "wie", "sons\u00b7ten", "sch\u00e4d\u00b7lich", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ebenfals mu\u00df man gestehen,", "tokens": ["E\u00b7ben\u00b7fals", "mu\u00df", "man", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df es weislich eingericht,", "tokens": ["Da\u00df", "es", "weis\u00b7lich", "ein\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df die Haare, als wir sehen,", "tokens": ["Da\u00df", "die", "Haa\u00b7re", ",", "als", "wir", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie es an dem Haupt geschicht,", "tokens": ["Wie", "es", "an", "dem", "Haupt", "ge\u00b7schicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht sich in die L\u00e4nge treiben.", "tokens": ["Nicht", "sich", "in", "die", "L\u00e4n\u00b7ge", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sondern ohne Wachsthum bleiben,", "tokens": ["Son\u00b7dern", "oh\u00b7ne", "Wach\u00b7sthum", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn sie ihre L\u00e4ng erreicht,", "tokens": ["Wenn", "sie", "ih\u00b7re", "L\u00e4ng", "er\u00b7reicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wie uns die Erfahrung zeigt.", "tokens": ["Wie", "uns", "die", "Er\u00b7fah\u00b7rung", "zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Dieses scheinen Kleinigkeiten,", "tokens": ["Die\u00b7ses", "schei\u00b7nen", "Klei\u00b7nig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und sind dennoch wunderbahr,", "tokens": ["Und", "sind", "den\u00b7noch", "wun\u00b7der\u00b7bahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ", "tokens": ["Weil"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Schon gesehn auf die Gefahr,", "tokens": ["Schon", "ge\u00b7sehn", "auf", "die", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die da k\u00f6nnte die Kristallen", "tokens": ["Die", "da", "k\u00f6nn\u00b7te", "die", "Kris\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VMFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsrer Augen leicht befallen:", "tokens": ["Uns\u00b7rer", "Au\u00b7gen", "leicht", "be\u00b7fal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Daf\u00fcr sind sie nun besch\u00fczt,", "tokens": ["Da\u00b7f\u00fcr", "sind", "sie", "nun", "be\u00b7sch\u00fczt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weil davor die Schutzwehr sizt.", "tokens": ["Weil", "da\u00b7vor", "die", "Schutz\u00b7wehr", "sizt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "ART", "NN", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.19": {"line.1": {"text": "Wenn wir ihren Bau betrachten,", "tokens": ["Wenn", "wir", "ih\u00b7ren", "Bau", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehen alle Theile an,", "tokens": ["Se\u00b7hen", "al\u00b7le", "Thei\u00b7le", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die bewundernd hoch zu achten", "tokens": ["Die", "be\u00b7wun\u00b7dernd", "hoch", "zu", "ach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJD", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und kein K\u00fcnstler k\u00fcnsteln kan:", "tokens": ["Und", "kein", "K\u00fcnst\u00b7ler", "k\u00fcns\u00b7teln", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So mu\u00df jederman erkennen,", "tokens": ["So", "mu\u00df", "je\u00b7der\u00b7man", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df das Aug ein Werk zu nennen,", "tokens": ["Da\u00df", "das", "Aug", "ein", "Werk", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das die Weisheit ausgedacht,", "tokens": ["Das", "die", "Weis\u00b7heit", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wunderbahr zu Stand gebracht.", "tokens": ["Wun\u00b7der\u00b7bahr", "zu", "Stand", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Weislich ist schon an den Augen", "tokens": ["Weis\u00b7lich", "ist", "schon", "an", "den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die rundl\u00e4nglichte Figur,", "tokens": ["Die", "rund\u00b7l\u00e4ng\u00b7lich\u00b7te", "Fi\u00b7gur", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weil die flachen nicht recht taugen", "tokens": ["Weil", "die", "fla\u00b7chen", "nicht", "recht", "tau\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "PTKNEG", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Bilder der Natur,", "tokens": ["Al\u00b7le", "Bil\u00b7der", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die den Mittelpunet bestrahlen,", "tokens": ["Die", "den", "Mit\u00b7tel\u00b7pu\u00b7net", "be\u00b7strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Deutlich in sich abzumahlen,", "tokens": ["Deut\u00b7lich", "in", "sich", "ab\u00b7zu\u00b7mah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als das, was rund ausgeh\u00f6hlt,", "tokens": ["Als", "das", ",", "was", "rund", "aus\u00b7ge\u00b7h\u00f6hlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "ADJD", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Wie die Sehekunst erz\u00e4hlt.", "tokens": ["Wie", "die", "Se\u00b7he\u00b7kunst", "er\u00b7z\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Da die Augen rund gebildet,", "tokens": ["Da", "die", "Au\u00b7gen", "rund", "ge\u00b7bil\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird darin der Gegenstand,", "tokens": ["Wird", "da\u00b7rin", "der", "Ge\u00b7gen\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohn Verwirrung abgeschildet,", "tokens": ["Ohn", "Ver\u00b7wir\u00b7rung", "ab\u00b7ge\u00b7schil\u00b7det", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und viel leichter, wie bekandt,", "tokens": ["Und", "viel", "leich\u00b7ter", ",", "wie", "be\u00b7kandt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$,", "PWAV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "K\u00f6nnen sie sich nunmehr wenden,", "tokens": ["K\u00f6n\u00b7nen", "sie", "sich", "nun\u00b7mehr", "wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als wenn an den \u00e4usren Enden,", "tokens": ["Als", "wenn", "an", "den", "\u00e4us\u00b7ren", "En\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ekken w\u00e4ren, die im Drehn,", "tokens": ["Ek\u00b7ken", "w\u00e4\u00b7ren", ",", "die", "im", "Drehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PRELS", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nicht so leicht beweglich gehn.", "tokens": ["Nicht", "so", "leicht", "be\u00b7weg\u00b7lich", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Jedes Aug besteht aus H\u00e4uten, Unter diesen dreien H\u00e4uten ist die \u00e4userste sehr hart,\nvorne aber in einen ziemlichen Umsange durchsichtig,\nund wird daher tunica cornea oder die durchsichti-\nge Horn-Haut genennet. Sie umgiebet das ganze\nAuge, und machet rund herum das Weisse in densel-\nben. Unter dieser lieget die andre, die man tunica\nuvea oder die Traubenf\u00f6rmige nennet. Diese ist\nhinterwerts im Auge ganz schwarz, kleidet die inwen-\ndige H\u00f6hle aus, und hindert sonderlich da\u00df das Licht\nvon den Seiten des Auges nicht zur\u00fck nach den Bo-\nden prallen und die AbbildnngAbbildung der Strahlen an dem-\nselben hindern k\u00f6nne. Die dritte Haut bedekket den\nBoden des Auges, wie ein seiner weisser Flor und\nwird daher die Nezf\u00f6rmige Haut oder Tunica re-\ntina genennet. Daran geschehen alle Abbildungen im\nAuge, und werden alle Bilder dem Sehnerven, der\ndichte hinter ihr lieget, zugef\u00fchret.", "tokens": ["Je\u00b7des", "Aug", "be\u00b7steht", "aus", "H\u00e4u\u00b7ten", ",", "Un\u00b7ter", "die\u00b7sen", "drei\u00b7en", "H\u00e4u\u00b7ten", "ist", "die", "\u00e4u\u00b7sers\u00b7te", "sehr", "hart", ",", "vor\u00b7ne", "a\u00b7ber", "in", "ei\u00b7nen", "ziem\u00b7li\u00b7chen", "Um\u00b7san\u00b7ge", "durch\u00b7sich\u00b7tig", ",", "und", "wird", "da\u00b7her", "tu\u00b7ni\u00b7ca", "cor\u00b7nea", "o\u00b7der", "die", "durch\u00b7sich\u00b7ti", "ge", "Horn\u00b7Haut", "ge\u00b7nen\u00b7net", ".", "Sie", "um\u00b7gie\u00b7bet", "das", "gan\u00b7ze", "Au\u00b7ge", ",", "und", "ma\u00b7chet", "rund", "he\u00b7rum", "das", "Weis\u00b7se", "in", "den\u00b7sel", "ben", ".", "Un\u00b7ter", "die\u00b7ser", "lie\u00b7get", "die", "and\u00b7re", ",", "die", "man", "tu\u00b7ni\u00b7ca", "uv\u00b7ea", "o\u00b7der", "die", "Trau\u00b7ben\u00b7f\u00f6r\u00b7mi\u00b7ge", "nen\u00b7net", ".", "Die\u00b7se", "ist", "hin\u00b7ter\u00b7werts", "im", "Au\u00b7ge", "ganz", "schwarz", ",", "klei\u00b7det", "die", "in\u00b7wen", "di\u00b7ge", "H\u00f6h\u00b7le", "aus", ",", "und", "hin\u00b7dert", "son\u00b7der\u00b7lich", "da\u00df", "das", "Licht", "von", "den", "Sei\u00b7ten", "des", "Au\u00b7ges", "nicht", "zu\u00b7r\u00fck", "nach", "den", "Bo", "den", "pral\u00b7len", "und", "die", "Ab\u00b7bildnng", "Ab\u00b7bil\u00b7dung", "der", "Strah\u00b7len", "an", "dem", "sel\u00b7ben", "hin\u00b7dern", "k\u00f6n\u00b7ne", ".", "Die", "drit\u00b7te", "Haut", "be\u00b7dek\u00b7ket", "den", "Bo\u00b7den", "des", "Au\u00b7ges", ",", "wie", "ein", "sei\u00b7ner", "weis\u00b7ser", "Flor", "und", "wird", "da\u00b7her", "die", "Nez\u00b7f\u00f6r\u00b7mi\u00b7ge", "Haut", "o\u00b7der", "Tu\u00b7ni\u00b7ca", "re", "ti\u00b7na", "ge\u00b7nen\u00b7net", ".", "Da\u00b7ran", "ge\u00b7sche\u00b7hen", "al\u00b7le", "Ab\u00b7bil\u00b7dun\u00b7gen", "im", "Au\u00b7ge", ",", "und", "wer\u00b7den", "al\u00b7le", "Bil\u00b7der", "dem", "Seh\u00b7ner\u00b7ven", ",", "der", "dich\u00b7te", "hin\u00b7ter", "ihr", "lie\u00b7get", ",", "zu\u00b7ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "$,", "APPR", "PDAT", "CARD", "NN", "VAFIN", "ART", "ADJA", "ADV", "ADJD", "$,", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "ADJD", "$,", "KON", "VAFIN", "PAV", "FM", "FM", "KON", "ART", "TRUNC", "NN", "NE", "VVPP", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "VVFIN", "ADJD", "ADV", "ART", "NN", "APPR", "TRUNC", "VVINF", "$.", "APPR", "PDAT", "VVFIN", "ART", "ADJA", "$,", "PRELS", "PIS", "FM", "FM", "KON", "ART", "NN", "VVFIN", "$.", "PDS", "VAFIN", "ADV", "APPRART", "NN", "ADV", "ADJD", "$,", "VVFIN", "ART", "TRUNC", "ADJA", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "KOUS", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "PTKNEG", "ADV", "APPR", "ART", "TRUNC", "ART", "ADJA", "KON", "ART", "NN", "NN", "ART", "NN", "APPR", "TRUNC", "VVINF", "VVINF", "VMFIN", "$.", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$,", "PWAV", "ART", "PPOSAT", "ADJA", "NN", "KON", "VAFIN", "PAV", "ART", "ADJA", "NN", "KON", "FM", "FM", "FM", "VVPP", "$.", "PAV", "VVPP", "PIAT", "NN", "APPRART", "NN", "$,", "KON", "VAFIN", "PIAT", "NN", "ART", "NN", "$,", "ART", "ADJA", "APPR", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-+-+--+-+-+--+-+---+--+--+-+-+-+---+-+--++---+-+--+-+--+-+-+-+-+-+-+-+-+--+-+-+-+-+-+-+-+-+--+--+-+-+--++-+-+--+-+-+-+-+--+--+--+-+-+--+-+-+-+-+---+-+-+-+-+--+-+-+--+--+-+-+-+-+-+-+--+--+--+--+-+--+-+-+-+-+-+--+--+-+-+--+-+-+-+--+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Die dreifach sind an der Zahl,", "tokens": ["Die", "drei\u00b7fach", "sind", "an", "der", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und aus so viel Feuchtigkeiten ", "tokens": ["Und", "aus", "so", "viel", "Feuch\u00b7tig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Darin sich des Lichtes Strahl,", "tokens": ["Da\u00b7rin", "sich", "des", "Lich\u00b7tes", "Strahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Als in einem Spiegel dr\u00fckket,", "tokens": ["Als", "in", "ei\u00b7nem", "Spie\u00b7gel", "dr\u00fck\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und zum Mittelpuncte schikket,", "tokens": ["Und", "zum", "Mit\u00b7tel\u00b7punc\u00b7te", "schik\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Dran man eine schwarze Wand,", "tokens": ["Dran", "man", "ei\u00b7ne", "schwar\u00b7ze", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Findet gleichsam ausgespannt.", "tokens": ["Fin\u00b7det", "gleich\u00b7sam", "aus\u00b7ge\u00b7spannt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Wenn durch w\u00e4ssrichte Kristallen", "tokens": ["Wenn", "durch", "w\u00e4ss\u00b7rich\u00b7te", "Kris\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die das \u00e4usre Licht ber\u00fchrt,", "tokens": ["Die", "das", "\u00e4us\u00b7re", "Licht", "be\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mancherlei Gestalten fallen;", "tokens": ["Man\u00b7cher\u00b7lei", "Ge\u00b7stal\u00b7ten", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Werden sie dahin gef\u00fchrt,", "tokens": ["Wer\u00b7den", "sie", "da\u00b7hin", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wo sie diese Wand bestrahlen,", "tokens": ["Wo", "sie", "die\u00b7se", "Wand", "be\u00b7strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und sich gleichsam dran abmahlen,", "tokens": ["Und", "sich", "gleich\u00b7sam", "dran", "ab\u00b7mah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADJD", "PAV", "VVINF", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.7": {"text": "Da hernach der Geist erblikt,", "tokens": ["Da", "her\u00b7nach", "der", "Geist", "er\u00b7blikt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Was daran ist abgedr\u00fckt.", "tokens": ["Was", "da\u00b7ran", "ist", "ab\u00b7ge\u00b7dr\u00fckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PAV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Was noch sonsten ist zufinden,", "tokens": ["Was", "noch", "sons\u00b7ten", "ist", "zu\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den Nerven, Muskeln, Haut,", "tokens": ["Von", "den", "Ner\u00b7ven", ",", "Mus\u00b7keln", ",", "Haut", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Woraus in den hohlen Gr\u00fcnden,", "tokens": ["Wo\u00b7raus", "in", "den", "hoh\u00b7len", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist das runde Aug erbaut,", "tokens": ["Ist", "das", "run\u00b7de", "Aug", "er\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wollen wir nicht weiter zeigen,", "tokens": ["Wol\u00b7len", "wir", "nicht", "wei\u00b7ter", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sondern diesmahl nur verschweigen,", "tokens": ["Son\u00b7dern", "dies\u00b7mahl", "nur", "ver\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Weil wir schon genug gesehn,", "tokens": ["Weil", "wir", "schon", "ge\u00b7nug", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Unsern Sch\u00f6pfer zu erh\u00f6hn.", "tokens": ["Un\u00b7sern", "Sch\u00f6p\u00b7fer", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Kein Theil ist daran so kleine,", "tokens": ["Kein", "Theil", "ist", "da\u00b7ran", "so", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PAV", "ADV", "ADJA", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Es hat seinen grossen Nuz,", "tokens": ["Es", "hat", "sei\u00b7nen", "gros\u00b7sen", "Nuz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und kein H\u00e4utgen ist so feine,", "tokens": ["Und", "kein", "H\u00e4ut\u00b7gen", "ist", "so", "fei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Es dient dem Kristall zum Schuz;", "tokens": ["Es", "dient", "dem", "Kris\u00b7tall", "zum", "Schuz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Oder mu\u00df auf andre Weise,", "tokens": ["O\u00b7der", "mu\u00df", "auf", "and\u00b7re", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dieses Wundervoll Geh\u00e4use,", "tokens": ["Die\u00b7ses", "Wun\u00b7der\u00b7voll", "Ge\u00b7h\u00e4u\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zu dem Zwek, zu seinem Schein,", "tokens": ["Zu", "dem", "Zwek", ",", "zu", "sei\u00b7nem", "Schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Vortheilhafft und n\u00fczlich seyn.", "tokens": ["Vor\u00b7theil\u00b7hafft", "und", "n\u00fcz\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Wer die Augen braucht zum Sehen,", "tokens": ["Wer", "die", "Au\u00b7gen", "braucht", "zum", "Se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und aufmerksam nur erwegt,", "tokens": ["Und", "auf\u00b7merk\u00b7sam", "nur", "er\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie das pfleget zu geschehen,", "tokens": ["Wie", "das", "pfle\u00b7get", "zu", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df der Lichtstrahl darin schl\u00e4gt;", "tokens": ["Da\u00df", "der", "Licht\u00b7strahl", "da\u00b7rin", "schl\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PAV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie das was die H\u00e4utgen r\u00fchret,", "tokens": ["Wie", "das", "was", "die", "H\u00e4ut\u00b7gen", "r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird zu dem Gehirn gef\u00fchret:", "tokens": ["Wird", "zu", "dem", "Ge\u00b7hirn", "ge\u00b7f\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Der erkennt, nur ", "tokens": ["Der", "er\u00b7kennt", ",", "nur"], "token_info": ["word", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "$,", "ADV"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Mu\u00df derselben Meister seyn.", "tokens": ["Mu\u00df", "der\u00b7sel\u00b7ben", "Meis\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Himmel, Erde, Thal und H\u00fcgel,", "tokens": ["Him\u00b7mel", ",", "Er\u00b7de", ",", "Thal", "und", "H\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sonne, Sterne, Baum und Kraut;", "tokens": ["Son\u00b7ne", ",", "Ster\u00b7ne", ",", "Baum", "und", "Kraut", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles sehn wir durch die Spiegel,", "tokens": ["Al\u00b7les", "sehn", "wir", "durch", "die", "Spie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was der Sch\u00f6pfer hat gebaut.", "tokens": ["Was", "der", "Sch\u00f6p\u00b7fer", "hat", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist er darum nicht zu preisen,", "tokens": ["Ist", "er", "da\u00b7rum", "nicht", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das er in so engen Kreisen", "tokens": ["Das", "er", "in", "so", "en\u00b7gen", "Krei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "APPR", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Alles das zusammen zieht,", "tokens": ["Al\u00b7les", "das", "zu\u00b7sam\u00b7men", "zieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Was nur sch\u00f6nes schimmert, bl\u00fcht?", "tokens": ["Was", "nur", "sch\u00f6\u00b7nes", "schim\u00b7mert", ",", "bl\u00fcht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ADV", "ADJA", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Was die N\u00e4he und die Ferne", "tokens": ["Was", "die", "N\u00e4\u00b7he", "und", "die", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In sich hegt, wird uns bekandt,", "tokens": ["In", "sich", "hegt", ",", "wird", "uns", "be\u00b7kandt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVFIN", "$,", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch dis Paar der lichten Sterne,", "tokens": ["Durch", "dis", "Paar", "der", "lich\u00b7ten", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die des H\u00f6chsten Wunderhand", "tokens": ["Die", "des", "H\u00f6chs\u00b7ten", "Wun\u00b7der\u00b7hand"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Uns in unser Haupt gesenket,", "tokens": ["Uns", "in", "un\u00b7ser", "Haupt", "ge\u00b7sen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und so weislich hat gelenket,", "tokens": ["Und", "so", "weis\u00b7lich", "hat", "ge\u00b7len\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ja! es wird dadurch die Welt,", "tokens": ["Ja", "!", "es", "wird", "da\u00b7durch", "die", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "PAV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Uns recht deutlich vorgestellt.", "tokens": ["Uns", "recht", "deut\u00b7lich", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Unsre Augen bleiben sizzen,", "tokens": ["Uns\u00b7re", "Au\u00b7gen", "blei\u00b7ben", "siz\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In dem angewiesnen Ort,", "tokens": ["In", "dem", "an\u00b7ge\u00b7wi\u00b7es\u00b7nen", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Aber ihre strengen Blizzen,", "tokens": ["A\u00b7ber", "ih\u00b7re", "stren\u00b7gen", "Bliz\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rennen allenthalben fort:", "tokens": ["Ren\u00b7nen", "al\u00b7len\u00b7thal\u00b7ben", "fort", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn sie wieder r\u00fckwerts fliegen,", "tokens": ["Wenn", "sie", "wie\u00b7der", "r\u00fck\u00b7werts", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Bringen sie dem Geist vergn\u00fcgen,", "tokens": ["Brin\u00b7gen", "sie", "dem", "Geist", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Fl\u00f6ssen ihm durch ihrem Schein,", "tokens": ["Fl\u00f6s\u00b7sen", "ihm", "durch", "ih\u00b7rem", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Was sich sch\u00f6nes findet, ein.", "tokens": ["Was", "sich", "sch\u00f6\u00b7nes", "fin\u00b7det", ",", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PRF", "ADJA", "VVFIN", "$,", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Mensch! erkenne diese Gaben,", "tokens": ["Mensch", "!", "er\u00b7ken\u00b7ne", "die\u00b7se", "Ga\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die wir von der G\u00fctigkeit,", "tokens": ["Die", "wir", "von", "der", "G\u00fc\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eines weisen Sch\u00f6pfers haben,", "tokens": ["Ei\u00b7nes", "wei\u00b7sen", "Sch\u00f6p\u00b7fers", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der die Welt mit Glanz bestreut:", "tokens": ["Der", "die", "Welt", "mit", "Glanz", "be\u00b7streut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Brauche deine hellen Augen,", "tokens": ["Brau\u00b7che", "dei\u00b7ne", "hel\u00b7len", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Lust und Freude einzusaugen,", "tokens": ["Lust", "und", "Freu\u00b7de", "ein\u00b7zu\u00b7sau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Aus dem Dingen dieser Welt,", "tokens": ["Aus", "dem", "Din\u00b7gen", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Die dir dadurch vorgestellt.", "tokens": ["Die", "dir", "da\u00b7durch", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Aber m\u00f6chtest du auch lernen,", "tokens": ["A\u00b7ber", "m\u00f6ch\u00b7test", "du", "auch", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In den Tieffen, in den H\u00f6hn,", "tokens": ["In", "den", "Tief\u00b7fen", ",", "in", "den", "H\u00f6hn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In der N\u00e4he, in den Fernen", "tokens": ["In", "der", "N\u00e4\u00b7he", ",", "in", "den", "Fer\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Allenthalben ", "tokens": ["Al\u00b7len\u00b7thal\u00b7ben"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "O! so w\u00fcrde durch das Wunder", "tokens": ["O", "!", "so", "w\u00fcr\u00b7de", "durch", "das", "Wun\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "ADV", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Deiner Augen, auch der Zunder", "tokens": ["Dei\u00b7ner", "Au\u00b7gen", ",", "auch", "der", "Zun\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Reger Andacht angebrandt;", "tokens": ["Re\u00b7ger", "An\u00b7dacht", "an\u00b7ge\u00b7brandt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Wer die Welt nur blos ansiehet,", "tokens": ["Wer", "die", "Welt", "nur", "blos", "an\u00b7sie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie ein unvern\u00fcnfftig Thier,", "tokens": ["Wie", "ein", "un\u00b7ver\u00b7n\u00fcnff\u00b7tig", "Thier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sich nicht im Geist bem\u00fchet,", "tokens": ["Und", "sich", "nicht", "im", "Geist", "be\u00b7m\u00fc\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PTKNEG", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jhre Sch\u00f6nheit, Pracht und Zier,", "tokens": ["Ih\u00b7re", "Sch\u00f6n\u00b7heit", ",", "Pracht", "und", "Zier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aufmerksam zu \u00fcberdenken,", "tokens": ["Auf\u00b7merk\u00b7sam", "zu", "\u00fc\u00b7ber\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und das Herz darauf zu lenken,", "tokens": ["Und", "das", "Herz", "da\u00b7rauf", "zu", "len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PAV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Seinen Sch\u00f6pfer nicht so ehrt,", "tokens": ["Sei\u00b7nen", "Sch\u00f6p\u00b7fer", "nicht", "so", "ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist der Augen nimmer wehrt.", "tokens": ["Ist", "der", "Au\u00b7gen", "nim\u00b7mer", "wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Wische den Gewohnheits Schlummer,", "tokens": ["Wi\u00b7sche", "den", "Ge\u00b7wohn\u00b7heits", "Schlum\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mensch! aus deinem Angesicht,", "tokens": ["Mensch", "!", "aus", "dei\u00b7nem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vertreib den finstern Kummer,", "tokens": ["Und", "ver\u00b7treib", "den", "fins\u00b7tern", "Kum\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da du kanst das Freuden-Licht", "tokens": ["Da", "du", "kanst", "das", "Freu\u00b7den\u00b7Licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Das das Herz erg\u00f6zt, erblikken;", "tokens": ["Das", "das", "Herz", "er\u00b7g\u00f6zt", ",", "er\u00b7blik\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVPP", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sprich im freudigen Entz\u00fckken:", "tokens": ["Sprich", "im", "freu\u00b7di\u00b7gen", "Ent\u00b7z\u00fck\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sol mein steter Vorwurf seyn.", "tokens": ["Sol", "mein", "ste\u00b7ter", "Vor\u00b7wurf", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Wirst du so des Sch\u00f6pfers Wesen,", "tokens": ["Wirst", "du", "so", "des", "Sch\u00f6p\u00b7fers", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In dem Buche der Natur,", "tokens": ["In", "dem", "Bu\u00b7che", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch der Augen Spiegel lesen,", "tokens": ["Durch", "der", "Au\u00b7gen", "Spie\u00b7gel", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An der sch\u00f6nen Kreatur:", "tokens": ["An", "der", "sch\u00f6\u00b7nen", "Kre\u00b7a\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So wirst du in allen Werken,", "tokens": ["So", "wirst", "du", "in", "al\u00b7len", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Seine weise Almacht merken;", "tokens": ["Sei\u00b7ne", "wei\u00b7se", "Al\u00b7macht", "mer\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "So bringt dir ein jeder Blik,", "tokens": ["So", "bringt", "dir", "ein", "je\u00b7der", "Blik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "PIAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Jmmer s\u00fcsse Lust zur\u00fck.", "tokens": ["Jm\u00b7mer", "s\u00fcs\u00b7se", "Lust", "zu\u00b7r\u00fck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Brauche ferner dein Gesichte,", "tokens": ["Brau\u00b7che", "fer\u00b7ner", "dein", "Ge\u00b7sich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und lies flei\u00dfig in der Schrifft,", "tokens": ["Und", "lies", "flei\u00b7\u00dfig", "in", "der", "Schrifft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was dein Auge in dem Lichte", "tokens": ["Was", "dein", "Au\u00b7ge", "in", "dem", "Lich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In des Geistes Wort antrifft:", "tokens": ["In", "des", "Geis\u00b7tes", "Wort", "an\u00b7trifft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da wirst du ger\u00fchrt erkennen,", "tokens": ["Da", "wirst", "du", "ge\u00b7r\u00fchrt", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Der durch seine G\u00fctigkeit,", "tokens": ["Der", "durch", "sei\u00b7ne", "G\u00fc\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Auch des Geistes Aug erfreut.", "tokens": ["Auch", "des", "Geis\u00b7tes", "Aug", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Lies wie er sich da beschrieben,", "tokens": ["Lies", "wie", "er", "sich", "da", "be\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als ein h\u00f6chst volkomner Geist,", "tokens": ["Als", "ein", "h\u00f6chst", "vol\u00b7kom\u00b7ner", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was er denen die ihn lieben,", "tokens": ["Was", "er", "de\u00b7nen", "die", "ihn", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PDS", "PRELS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der k\u00fcnfftgen Welt verheist:", "tokens": ["In", "der", "k\u00fcnfft\u00b7gen", "Welt", "ver\u00b7heist", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Folge denen heilgen Lehren,", "tokens": ["Fol\u00b7ge", "de\u00b7nen", "heil\u00b7gen", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Jhn im Geiste zu verehren:", "tokens": ["Jhn", "im", "Geis\u00b7te", "zu", "ver\u00b7eh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "So wird dreinst dir mehr gew\u00e4hrt,", "tokens": ["So", "wird", "dreinst", "dir", "mehr", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wenn dein Auge ist verkl\u00e4rt.", "tokens": ["Wenn", "dein", "Au\u00b7ge", "ist", "ver\u00b7kl\u00e4rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Deucht dir schon das ein Gel\u00fckke", "tokens": ["Deucht", "dir", "schon", "das", "ein", "Ge\u00b7l\u00fck\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie es auch warhafftig ist,", "tokens": ["Wie", "es", "auch", "war\u00b7haff\u00b7tig", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df dein Auge durch die Blikke,", "tokens": ["Da\u00df", "dein", "Au\u00b7ge", "durch", "die", "Blik\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Allenthalben Wunder liest:", "tokens": ["Al\u00b7len\u00b7thal\u00b7ben", "Wun\u00b7der", "liest", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was vor grosse Seeligkeiten,", "tokens": ["Was", "vor", "gros\u00b7se", "See\u00b7lig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird dort ", "tokens": ["Wird", "dort"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Da der Vater alles Lichts,", "tokens": ["Da", "der", "Va\u00b7ter", "al\u00b7les", "Lichts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist der Vorwurf des Gesichts.", "tokens": ["Ist", "der", "Vor\u00b7wurf", "des", "Ge\u00b7sichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Wir sehn hier durch einen Spiegel,", "tokens": ["Wir", "sehn", "hier", "durch", "ei\u00b7nen", "Spie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Noch in einem dunklen Wort:", "tokens": ["Noch", "in", "ei\u00b7nem", "dunk\u00b7len", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber dort auf Salems H\u00fcgel,", "tokens": ["A\u00b7ber", "dort", "auf", "Sa\u00b7lems", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist der vollenkommne Ort,", "tokens": ["Ist", "der", "vol\u00b7len\u00b7komm\u00b7ne", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo wir in des Himmels Lichte,", "tokens": ["Wo", "wir", "in", "des", "Him\u00b7mels", "Lich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.6": {"text": "Unsern ", "tokens": ["Un\u00b7sern"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Was wir hie noch nicht verstehn,", "tokens": ["Was", "wir", "hie", "noch", "nicht", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "In volkomner Klarheit sehn.", "tokens": ["In", "vol\u00b7kom\u00b7ner", "Klar\u00b7heit", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.39": {"line.1": {"text": "K\u00f6nnen wir auf denen Auen", "tokens": ["K\u00f6n\u00b7nen", "wir", "auf", "de\u00b7nen", "Au\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "PRELS", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Der bestrahlten Eitelkeit;", "tokens": ["Der", "be\u00b7strahl\u00b7ten", "Ei\u00b7tel\u00b7keit", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So viel sch\u00f6ne Wunder schauen,", "tokens": ["So", "viel", "sch\u00f6\u00b7ne", "Wun\u00b7der", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da noch viele Dunkelheit;", "tokens": ["Da", "noch", "vie\u00b7le", "Dun\u00b7kel\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da noch viele finstre Schatten,", "tokens": ["Da", "noch", "vie\u00b7le", "finst\u00b7re", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich mit Licht und Klarheit gatten,", "tokens": ["Sich", "mit", "Licht", "und", "Klar\u00b7heit", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was wird denn zu hoffen seyn,", "tokens": ["Was", "wird", "denn", "zu", "hof\u00b7fen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "PTKZU", "VVINF", "VAINF", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Beim verkl\u00e4rten Augenschein?", "tokens": ["Beim", "ver\u00b7kl\u00e4r\u00b7ten", "Au\u00b7gen\u00b7schein", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Doch mein Geist der fa\u00dft das nimmer,", "tokens": ["Doch", "mein", "Geist", "der", "fa\u00dft", "das", "nim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "VVFIN", "ART", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das Auge sieht es nicht,", "tokens": ["Und", "das", "Au\u00b7ge", "sieht", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was vor ein gestrahlter Schimmer", "tokens": ["Was", "vor", "ein", "ge\u00b7strahl\u00b7ter", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Aus dem Licht der Gottheit bricht.", "tokens": ["Aus", "dem", "Licht", "der", "Got\u00b7theit", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich bin noch im finstren Lande,", "tokens": ["Ich", "bin", "noch", "im", "finst\u00b7ren", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Da ich vom verkl\u00e4rten Stande", "tokens": ["Da", "ich", "vom", "ver\u00b7kl\u00e4r\u00b7ten", "Stan\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Noch nicht alles kan verstehn,", "tokens": ["Noch", "nicht", "al\u00b7les", "kan", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Was des Glaubens Aug gesehn.", "tokens": ["Was", "des", "Glau\u00b7bens", "Aug", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Dieses weis ich, und den Glauben,", "tokens": ["Die\u00b7ses", "weis", "ich", ",", "und", "den", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PTKVZ", "PPER", "$,", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sol mir weder H\u00f6ll, noch Welt,", "tokens": ["Sol", "mir", "we\u00b7der", "H\u00f6ll", ",", "noch", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KON", "NN", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und kein teuflisch Sp\u00f6tter rauben:", "tokens": ["Und", "kein", "teuf\u00b7lisch", "Sp\u00f6t\u00b7ter", "rau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dort in dem bestirnten Zelt,", "tokens": ["Dort", "in", "dem", "bes\u00b7tirn\u00b7ten", "Zelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Werd ich JEsum dreinst erblikken,", "tokens": ["Werd", "ich", "Je\u00b7sum", "dreinst", "er\u00b7blik\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da wird sich mein Aug erquikken,", "tokens": ["Da", "wird", "sich", "mein", "Aug", "er\u00b7quik\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "An den Wundern mancher Art,", "tokens": ["An", "den", "Wun\u00b7dern", "man\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Die der Himmel offenbahrt.", "tokens": ["Die", "der", "Him\u00b7mel", "of\u00b7fen\u00b7bahrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}