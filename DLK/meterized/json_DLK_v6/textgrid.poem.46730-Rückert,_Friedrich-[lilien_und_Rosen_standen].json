{"textgrid.poem.46730": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[lilien und Rosen standen]", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lilien und Rosen standen", "tokens": ["Li\u00b7li\u00b7en", "und", "Ro\u00b7sen", "stan\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df und roth,", "tokens": ["Wei\u00df", "und", "roth", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und wir kn\u00fcpften Rosenbanden", "tokens": ["Und", "wir", "kn\u00fcpf\u00b7ten", "Ro\u00b7sen\u00b7ban\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df und roth.", "tokens": ["Wei\u00df", "und", "roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Fr\u00fchling f\u00e4rbte Flur und L\u00fcste", "tokens": ["Fr\u00fch\u00b7ling", "f\u00e4rb\u00b7te", "Flur", "und", "L\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gr\u00fcn und blau,", "tokens": ["Gr\u00fcn", "und", "blau", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wo wir euch als Rosen fanden", "tokens": ["Wo", "wir", "euch", "als", "Ro\u00b7sen", "fan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "KOUS", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df und roth.", "tokens": ["Wei\u00df", "und", "roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Goldner Schmelz war eure Wiege,", "tokens": ["Gold\u00b7ner", "Schmelz", "war", "eu\u00b7re", "Wie\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo sich rings", "tokens": ["Wo", "sich", "rings"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PRF", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Lilien und Rosen wanden", "tokens": ["Li\u00b7li\u00b7en", "und", "Ro\u00b7sen", "wan\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df und roth.", "tokens": ["Wei\u00df", "und", "roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Als die Wiege ward zum Sarge,", "tokens": ["Als", "die", "Wie\u00b7ge", "ward", "zum", "Sar\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Starb in Grau", "tokens": ["Starb", "in", "Grau"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Fr\u00fchlingsgr\u00fcn, und Rosen schwanden", "tokens": ["Fr\u00fch\u00b7lings\u00b7gr\u00fcn", ",", "und", "Ro\u00b7sen", "schwan\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df und roth.", "tokens": ["Wei\u00df", "und", "roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Rosen, aus dem Land der Dornen", "tokens": ["Ro\u00b7sen", ",", "aus", "dem", "Land", "der", "Dor\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hier versetzt,", "tokens": ["Hier", "ver\u00b7setzt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Bl\u00fcht ihr dort in Rosenlanden", "tokens": ["Bl\u00fcht", "ihr", "dort", "in", "Ro\u00b7sen\u00b7lan\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df und roth.", "tokens": ["Wei\u00df", "und", "roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "L\u00e4chelnd streut ihr \u00fcber uns und", "tokens": ["L\u00e4\u00b7chelnd", "streut", "ihr", "\u00fc\u00b7ber", "uns", "und"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "PPER", "KON"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euer Grab", "tokens": ["Eu\u00b7er", "Grab"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Lilien aus Rosenhanden", "tokens": ["Li\u00b7li\u00b7en", "aus", "Ro\u00b7sen\u00b7han\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df und roth.", "tokens": ["Wei\u00df", "und", "roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}