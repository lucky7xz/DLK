{"dta.poem.18918": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "An Herren Han\u00df Jacob Grob   &c.  \n  Meinen alten werthen vnd gelehrten  \n Freind.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Odessen wehrte werck vnd wei\u00dfheit wol bezeugen/", "tokens": ["O\u00b7des\u00b7sen", "wehr\u00b7te", "werck", "vnd", "wei\u00df\u00b7heit", "wol", "be\u00b7zeu\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "KON", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df nichts dan nur dein Nam an dir zu nen\u0303en", "tokens": ["Da\u00df", "nichts", "dan", "nur", "dein", "Nam", "an", "dir", "zu", "ne\u00f1en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "ADV", "PPOSAT", "NN", "APPR", "PPER", "PTKZU", "VVINF"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Grob/", "tokens": ["Grob", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Grob w\u00e4r ich selbs vnd b\u00f6\u00df/ lang vor der welt", "tokens": ["Grob", "w\u00e4r", "ich", "selbs", "vnd", "b\u00f6\u00df", "/", "lang", "vor", "der", "welt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "KON", "ADJD", "$(", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "dein lob/", "tokens": ["dein", "lob", "/"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Welches der Musen zunfft vermeldet/ zu ver-", "tokens": ["Wel\u00b7ches", "der", "Mu\u00b7sen", "zunfft", "ver\u00b7mel\u00b7det", "/", "zu", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "ART", "NN", "ADV", "VVPP", "$(", "APPR", "TRUNC"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "schweigen.", "tokens": ["schwei\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.2": {"line.1": {"text": "Zwar dein verdienst bedarff nu weitter keine zeugen/", "tokens": ["Zwar", "dein", "ver\u00b7dienst", "be\u00b7darff", "nu", "weit\u00b7ter", "kei\u00b7ne", "zeu\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ADV", "ADJA", "PIAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil Landgraff Moritz schon (den zwar/ wie ich", "tokens": ["Weil", "Land\u00b7graff", "Mo\u00b7ritz", "schon", "(", "den", "zwar", "/", "wie", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "NE", "NE", "ADV", "$(", "ART", "ADV", "$(", "PWAV", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "dich lob", "tokens": ["dich", "lob"], "token_info": ["word", "word"], "pos": ["PPER", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Durch jhn/ ich mit dir ehr) auff vnfehlbare prob", "tokens": ["Durch", "jhn", "/", "ich", "mit", "dir", "ehr", ")", "auff", "vn\u00b7fehl\u00b7ba\u00b7re", "prob"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "$(", "PPER", "APPR", "PPER", "NN", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein haupt gekr\u00f6net hat mit seine\u0304 gnaden-zweige\u0304.", "tokens": ["Dein", "haupt", "ge\u00b7kr\u00f6\u00b7net", "hat", "mit", "sein\u0113", "gna\u00b7den\u00b7zweig\u0113", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Darumb sehr ", "tokens": ["Da\u00b7rumb", "sehr"], "token_info": ["word", "word"], "pos": ["PAV", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Die au\u00df deines beruffs (dir noch vngleichen) ehren", "tokens": ["Die", "au\u00df", "dei\u00b7nes", "be\u00b7ruffs", "(", "dir", "noch", "vn\u00b7glei\u00b7chen", ")", "eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "$(", "PPER", "ADV", "ADJA", "$(", "VVINF"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Nicht abnemen den schmuck/ den dir gab Gottes", "tokens": ["Nicht", "ab\u00b7ne\u00b7men", "den", "schmuck", "/", "den", "dir", "gab", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "ART", "NN", "$(", "ART", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "hand;", "tokens": ["hand", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Noch ", "tokens": ["Noch"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Vnd ", "tokens": ["Vnd"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Teutschland/", "tokens": ["Teutschland", "/"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Da\u00df deines lebens trumb m\u00f6g/ zart vnd starck/", "tokens": ["Da\u00df", "dei\u00b7nes", "le\u00b7bens", "trumb", "m\u00f6g", "/", "zart", "vnd", "starck", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "FM", "FM", "FM", "$(", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "lang wehren.", "tokens": ["lang", "weh\u00b7ren", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}