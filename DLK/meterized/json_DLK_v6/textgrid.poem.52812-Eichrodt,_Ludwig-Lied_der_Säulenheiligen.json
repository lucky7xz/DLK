{"textgrid.poem.52812": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Lied der S\u00e4ulenheiligen", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dreihundert Jahre wollen wir", "tokens": ["Drei\u00b7hun\u00b7dert", "Jah\u00b7re", "wol\u00b7len", "wir"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns Gott, so Gott will, weihen,", "tokens": ["Uns", "Gott", ",", "so", "Gott", "will", ",", "wei\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADV", "NN", "VMFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schon siebzig Jahre steh'n wir hier", "tokens": ["Schon", "sieb\u00b7zig", "Jah\u00b7re", "steh'n", "wir", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf S\u00e4ulen hoch im Freien.", "tokens": ["Auf", "S\u00e4u\u00b7len", "hoch", "im", "Frei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wenn er uns Regenwetter schickt,", "tokens": ["Wenn", "er", "uns", "Re\u00b7gen\u00b7wet\u00b7ter", "schickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wir durchn\u00e4sset triefen,", "tokens": ["Da\u00df", "wir", "durch\u00b7n\u00e4s\u00b7set", "trie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir stehen heiter, unverr\u00fcckt,", "tokens": ["Wir", "ste\u00b7hen", "hei\u00b7ter", ",", "un\u00b7ver\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Herr will uns nur pr\u00fcfen.", "tokens": ["Der", "Herr", "will", "uns", "nur", "pr\u00fc\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wenn er im Blitz und Schlo\u00dfen k\u00f6mmt,", "tokens": ["Wenn", "er", "im", "Blitz", "und", "Schlo\u00b7\u00dfen", "k\u00f6mmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns donnert um die Ohren,", "tokens": ["Uns", "don\u00b7nert", "um", "die", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir werden doch nicht weggeschwemmt,", "tokens": ["Wir", "wer\u00b7den", "doch", "nicht", "weg\u00b7ge\u00b7schwemmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir haben keine Moren.", "tokens": ["Wir", "ha\u00b7ben", "kei\u00b7ne", "Mo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wir essen nicht, wir trinken nicht,", "tokens": ["Wir", "es\u00b7sen", "nicht", ",", "wir", "trin\u00b7ken", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PPER", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sammeln nicht in Scheunen,", "tokens": ["Wir", "sam\u00b7meln", "nicht", "in", "Scheu\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir schlafen wie der G\u00e4nsericht", "tokens": ["Wir", "schla\u00b7fen", "wie", "der", "G\u00e4n\u00b7se\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf ", "tokens": ["Auf"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}}, "stanza.5": {"line.1": {"text": "Wir b\u00fc\u00dfen f\u00fcr die b\u00f6se Welt", "tokens": ["Wir", "b\u00fc\u00b7\u00dfen", "f\u00fcr", "die", "b\u00f6\u00b7se", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die eigenen Vergehen,", "tokens": ["Die", "ei\u00b7ge\u00b7nen", "Ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und ob auch Katzenhagel f\u00e4llt,", "tokens": ["Und", "ob", "auch", "Kat\u00b7zen\u00b7ha\u00b7gel", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir lassen's halt geschehen.", "tokens": ["Wir", "las\u00b7sen's", "halt", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "O Herr, du ", "tokens": ["O", "Herr", ",", "du"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "NN", "$,", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Im Jenseits unser Ringen,", "tokens": ["Im", "Jen\u00b7seits", "un\u00b7ser", "Rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo wir entr\u00fcckt der Erdenqual", "tokens": ["Wo", "wir", "ent\u00b7r\u00fcckt", "der", "Er\u00b7den\u00b7qual"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Loblied endlos singen.", "tokens": ["Dein", "Lob\u00b7lied", "end\u00b7los", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wir bitten dich, o schlaf nicht ein", "tokens": ["Wir", "bit\u00b7ten", "dich", ",", "o", "schlaf", "nicht", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "FM", "VVFIN", "PTKNEG", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei unsern langen Ch\u00f6ren,", "tokens": ["Bei", "un\u00b7sern", "lan\u00b7gen", "Ch\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und lohne unsrer jetz'gen Pein", "tokens": ["Und", "loh\u00b7ne", "uns\u00b7rer", "jetz'\u00b7gen", "Pein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch gn\u00e4diges Anh\u00f6ren.", "tokens": ["Durch", "gn\u00e4\u00b7di\u00b7ges", "An\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Was haben Ander's angestrebt", "tokens": ["Was", "ha\u00b7ben", "An\u00b7der's", "an\u00b7ge\u00b7strebt"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PIS", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kr\u00f6ten ohne Nahrung,", "tokens": ["Die", "Kr\u00f6\u00b7ten", "oh\u00b7ne", "Nah\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die \u00fcber tausend Jahr' erlebt", "tokens": ["Die", "\u00fc\u00b7ber", "tau\u00b7send", "Jahr'", "er\u00b7lebt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "CARD", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In steinerner Verwahrung?", "tokens": ["In", "stei\u00b7ner\u00b7ner", "Ver\u00b7wah\u00b7rung", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}}, "stanza.9": {"line.1": {"text": "Und Menschen, sollten sie nicht schon", "tokens": ["Und", "Men\u00b7schen", ",", "soll\u00b7ten", "sie", "nicht", "schon"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "VMFIN", "PPER", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Soviel als ", "tokens": ["So\u00b7viel", "als"], "token_info": ["word", "word"], "pos": ["PIS", "KOKOM"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Das sagen nur, die uns den Lohn", "tokens": ["Das", "sa\u00b7gen", "nur", ",", "die", "uns", "den", "Lohn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "$,", "PRELS", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sch\u00e4ndlicherweis mi\u00dfg\u00f6nnen!", "tokens": ["Sch\u00e4nd\u00b7li\u00b7cher\u00b7weis", "mi\u00df\u00b7g\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}