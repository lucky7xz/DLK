{"textgrid.poem.39924": {"metadata": {"author": {"name": "Schwab, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "Schlo\u00df Lichtenstein", "genre": "verse", "period": "N.A.", "pub_year": 1821, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In einem tiefen gr\u00fcnen Thal", "tokens": ["In", "ei\u00b7nem", "tie\u00b7fen", "gr\u00fc\u00b7nen", "Thal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Steigt auf ein Fels, als wie ein Stral,", "tokens": ["Steigt", "auf", "ein", "Fels", ",", "als", "wie", "ein", "Stral", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Drauf schaut das Schl\u00f6\u00dflein Lichtenstein", "tokens": ["Drauf", "schaut", "das", "Schl\u00f6\u00df\u00b7lein", "Lich\u00b7ten\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vergn\u00fcglich in die Welt hinein.", "tokens": ["Ver\u00b7gn\u00fcg\u00b7lich", "in", "die", "Welt", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "In dieser abgeschiednen Au',", "tokens": ["In", "die\u00b7ser", "ab\u00b7ge\u00b7schied\u00b7nen", "Au'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da baut' es eine Ritterfrau,", "tokens": ["Da", "baut'", "es", "ei\u00b7ne", "Rit\u00b7ter\u00b7frau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie war der Welt und Menschen satt,", "tokens": ["Sie", "war", "der", "Welt", "und", "Men\u00b7schen", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf den Bergen sucht sie eine Statt.", "tokens": ["Auf", "den", "Ber\u00b7gen", "sucht", "sie", "ei\u00b7ne", "Statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Den Fels umklammert des Schlosses Grund,", "tokens": ["Den", "Fels", "um\u00b7klam\u00b7mert", "des", "Schlos\u00b7ses", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu jeder Seiten g\u00e4hnt ein Schlund,", "tokens": ["Zu", "je\u00b7der", "Sei\u00b7ten", "g\u00e4hnt", "ein", "Schlund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Treppen m\u00fcssen, die W\u00e4nde von Stein,", "tokens": ["Die", "Trep\u00b7pen", "m\u00fcs\u00b7sen", ",", "die", "W\u00e4n\u00b7de", "von", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die B\u00f6den ausgegossen sein.", "tokens": ["Die", "B\u00f6\u00b7den", "aus\u00b7ge\u00b7gos\u00b7sen", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "So kann es trotzen Wetter und Sturm,", "tokens": ["So", "kann", "es", "trot\u00b7zen", "Wet\u00b7ter", "und", "Sturm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die Frau wohnt sicher auf ihrem Thurm,", "tokens": ["Die", "Frau", "wohnt", "si\u00b7cher", "auf", "ih\u00b7rem", "Thurm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie schauet tief in's Thal hinab,", "tokens": ["Sie", "schau\u00b7et", "tief", "in's", "Thal", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf die D\u00f6rfer und Felder, wie in's Grab.", "tokens": ["Auf", "die", "D\u00f6r\u00b7fer", "und", "Fel\u00b7der", ",", "wie", "in's", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$,", "PWAV", "APPRART", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "\u00bbdie blaue Luft, der Sonnenschein,\u00ab", "tokens": ["\u00bb", "die", "blau\u00b7e", "Luft", ",", "der", "Son\u00b7nen\u00b7schein", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spricht sie, \u00bbder W\u00e4lder Klang ist mein,", "tokens": ["Spricht", "sie", ",", "\u00bb", "der", "W\u00e4l\u00b7der", "Klang", "ist", "mein", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "ART", "NN", "NN", "VAFIN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eine Feindin bin ich aller Welt,", "tokens": ["Ei\u00b7ne", "Fein\u00b7din", "bin", "ich", "al\u00b7ler", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Zu Gottes Freundin doch bestellt.\u00ab", "tokens": ["Zu", "Got\u00b7tes", "Freun\u00b7din", "doch", "be\u00b7stellt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "NN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Mit diesem Spruch sie lebt' und starb,", "tokens": ["Mit", "die\u00b7sem", "Spruch", "sie", "lebt'", "und", "starb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Davon das Schlo\u00df sich Ruhm erwarb,", "tokens": ["Da\u00b7von", "das", "Schlo\u00df", "sich", "Ruhm", "er\u00b7warb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PRF", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Seit wohnte drauf manch ein Menschenfeind,", "tokens": ["Seit", "wohn\u00b7te", "drauf", "manch", "ein", "Men\u00b7schen\u00b7feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "PIAT", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und ward in der H\u00f6he Gottes Freund.", "tokens": ["Und", "ward", "in", "der", "H\u00f6\u00b7he", "Got\u00b7tes", "Freund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "NN", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Und als vergangen hundert Jahr,", "tokens": ["Und", "als", "ver\u00b7gan\u00b7gen", "hun\u00b7dert", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VVPP", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Menschenfeind auch droben war,", "tokens": ["Ein", "Men\u00b7schen\u00b7feind", "auch", "dro\u00b7ben", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lang hatt' er an keinen Menschen gedacht,", "tokens": ["Lang", "hatt'", "er", "an", "kei\u00b7nen", "Men\u00b7schen", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da pocht' es einsmals an zu Nacht.", "tokens": ["Da", "pocht'", "es", "eins\u00b7mals", "an", "zu", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbes ist ein einz'ger vertriebner Mann,", "tokens": ["\u00bb", "es", "ist", "ein", "einz'\u00b7ger", "ver\u00b7trieb\u00b7ner", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Welt Feind wohl er sich nennen kann,", "tokens": ["Der", "Welt", "Feind", "wohl", "er", "sich", "nen\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Herr Ulrich ist's von Wirtemberg,", "tokens": ["Herr", "Ul\u00b7rich", "ist's", "von", "Wir\u00b7tem\u00b7berg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "APPR", "NN", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.4": {"text": "Zu Gaste will er auf diesen Berg.\u00ab", "tokens": ["Zu", "Gas\u00b7te", "will", "er", "auf", "die\u00b7sen", "Berg", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "APPR", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Der Andre hat ihm aufgemacht,", "tokens": ["Der", "And\u00b7re", "hat", "ihm", "auf\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er nimmt des F\u00fcrsten wohl in Acht;", "tokens": ["Er", "nimmt", "des", "F\u00fcrs\u00b7ten", "wohl", "in", "Acht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "APPR", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er zeiget ihm das finstre Thal,", "tokens": ["Er", "zei\u00b7get", "ihm", "das", "finst\u00b7re", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das weit sich dehnt im Mondenstral.", "tokens": ["Das", "weit", "sich", "dehnt", "im", "Mon\u00b7dens\u00b7tral", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "PRF", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Herzog schaut hinunter lang,", "tokens": ["Der", "Her\u00b7zog", "schaut", "hin\u00b7un\u00b7ter", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er spricht mit einem Seufzer bang:", "tokens": ["Er", "spricht", "mit", "ei\u00b7nem", "Seuf\u00b7zer", "bang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwie fern, ach! von mir abgewandt,", "tokens": ["\u00bb", "wie", "fern", ",", "ach", "!", "von", "mir", "ab\u00b7ge\u00b7wandt", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "$,", "ITJ", "$.", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie tief, wie tief liegst du, mein Land!\u00ab", "tokens": ["Wie", "tief", ",", "wie", "tief", "liegst", "du", ",", "mein", "Land", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADJD", "$,", "PWAV", "ADJD", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "\u00bbauf meiner Burg, Herr Herzog, ja!", "tokens": ["\u00bb", "auf", "mei\u00b7ner", "Burg", ",", "Herr", "Her\u00b7zog", ",", "ja", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "$,", "NN", "NE", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist Erde fern, doch Himmel nah;", "tokens": ["Ist", "Er\u00b7de", "fern", ",", "doch", "Him\u00b7mel", "nah", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PTKVZ", "$,", "ADV", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer schaut hinauf, und wohnt nicht gern", "tokens": ["Wer", "schaut", "hin\u00b7auf", ",", "und", "wohnt", "nicht", "gern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Himmelreich von Mond und Stern?\u00ab", "tokens": ["Im", "Him\u00b7mel\u00b7reich", "von", "Mond", "und", "Stern", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Da hebt der Herzog seinen Blick,", "tokens": ["Da", "hebt", "der", "Her\u00b7zog", "sei\u00b7nen", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sieht nicht wieder auf's Land zur\u00fcck;", "tokens": ["Und", "sieht", "nicht", "wie\u00b7der", "auf's", "Land", "zu\u00b7r\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Von Nacht zu Nacht wird er nicht satt,", "tokens": ["Von", "Nacht", "zu", "Nacht", "wird", "er", "nicht", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis er es wohl verstanden hat.", "tokens": ["Bis", "er", "es", "wohl", "ver\u00b7stan\u00b7den", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und als nach manchem schweren Jahr", "tokens": ["Und", "als", "nach", "man\u00b7chem", "schwe\u00b7ren", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er wieder Herr vom Lande war,", "tokens": ["Er", "wie\u00b7der", "Herr", "vom", "Lan\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da hat er alles wohl bestellt,", "tokens": ["Da", "hat", "er", "al\u00b7les", "wohl", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hie\u00df ein Freund von Gott und Welt.", "tokens": ["Und", "hie\u00df", "ein", "Freund", "von", "Gott", "und", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie hat er erworben solche Gunst?", "tokens": ["Wie", "hat", "er", "er\u00b7wor\u00b7ben", "sol\u00b7che", "Gunst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VVPP", "PIAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wo hat er erlernet solche Kunst?", "tokens": ["Wo", "hat", "er", "er\u00b7ler\u00b7net", "sol\u00b7che", "Kunst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In des Himmels Buch, auf Lichtenstein,", "tokens": ["In", "des", "Him\u00b7mels", "Buch", ",", "auf", "Lich\u00b7ten\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Da hat er's gelesen im Sternenschein.", "tokens": ["Da", "hat", "er's", "ge\u00b7le\u00b7sen", "im", "Ster\u00b7nen\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.15": {"line.1": {"text": "Das Schlo\u00df zerfiel, es ward daraus", "tokens": ["Das", "Schlo\u00df", "zer\u00b7fiel", ",", "es", "ward", "da\u00b7raus"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein leichtgezimmert F\u00f6rsterhaus;", "tokens": ["Ein", "leicht\u00b7ge\u00b7zim\u00b7mert", "F\u00f6rs\u00b7ter\u00b7haus", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch schonet sein der Winde Sto\u00df,", "tokens": ["Doch", "scho\u00b7net", "sein", "der", "Win\u00b7de", "Sto\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meint, es sei noch das alte Schlo\u00df.", "tokens": ["Meint", ",", "es", "sei", "noch", "das", "al\u00b7te", "Schlo\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.16": {"line.1": {"text": "Und einsam ist es jetzt nicht mehr,", "tokens": ["Und", "ein\u00b7sam", "ist", "es", "jetzt", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es kommt der G\u00e4ste fr\u00f6hlich Heer,", "tokens": ["Es", "kommt", "der", "G\u00e4s\u00b7te", "fr\u00f6h\u00b7lich", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus einer ", "tokens": ["Aus", "ei\u00b7ner"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Doch Menschenfeinde sind es nie.", "tokens": ["Doch", "Men\u00b7schen\u00b7fein\u00b7de", "sind", "es", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Manch holdes M\u00e4dchenangesicht", "tokens": ["Manch", "hol\u00b7des", "M\u00e4d\u00b7chen\u00b7an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4\u00dft leuchten seiner Augen Licht,", "tokens": ["L\u00e4\u00dft", "leuch\u00b7ten", "sei\u00b7ner", "Au\u00b7gen", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da f\u00fchrt mit Recht in solchem Schein", "tokens": ["Da", "f\u00fchrt", "mit", "Recht", "in", "sol\u00b7chem", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Schlo\u00df den Namen Lichtenstein.", "tokens": ["Das", "Schlo\u00df", "den", "Na\u00b7men", "Lich\u00b7ten\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Die M\u00e4nner stolz, die M\u00e4gdlein frisch,", "tokens": ["Die", "M\u00e4n\u00b7ner", "stolz", ",", "die", "M\u00e4gd\u00b7lein", "frisch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sitzen alle um Einen Tisch,", "tokens": ["Sie", "sit\u00b7zen", "al\u00b7le", "um", "Ei\u00b7nen", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Erde l\u00e4chelt herauf so hold,", "tokens": ["Die", "Er\u00b7de", "l\u00e4\u00b7chelt", "her\u00b7auf", "so", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es stralt am Himmel der Sonne Gold.", "tokens": ["Es", "stralt", "am", "Him\u00b7mel", "der", "Son\u00b7ne", "Gold", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Sie spenden von des Weines Thau", "tokens": ["Sie", "spen\u00b7den", "von", "des", "Wei\u00b7nes", "Thau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Herzog und der Edelfrau,", "tokens": ["Dem", "Her\u00b7zog", "und", "der", "E\u00b7del\u00b7frau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie bitten sie, dies Schl\u00f6\u00dflein gut", "tokens": ["Sie", "bit\u00b7ten", "sie", ",", "dies", "Schl\u00f6\u00df\u00b7lein", "gut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PDS", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu nehmen in ihre fromme Hut.", "tokens": ["Zu", "neh\u00b7men", "in", "ih\u00b7re", "from\u00b7me", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "Und ziehn sie ab, mit einer Brust", "tokens": ["Und", "ziehn", "sie", "ab", ",", "mit", "ei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Voll Gotteslieb' und Menschenlust,", "tokens": ["Voll", "Got\u00b7tes\u00b7lieb'", "und", "Men\u00b7schen\u00b7lust", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann steht im sp\u00e4ten Sternenschein", "tokens": ["Dann", "steht", "im", "sp\u00e4\u00b7ten", "Ster\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Einsam und selig der Lichtenstein.", "tokens": ["Ein\u00b7sam", "und", "se\u00b7lig", "der", "Lich\u00b7ten\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}}}}