{"textgrid.poem.42211": {"metadata": {"author": {"name": "Wedekind, Frank", "birth": "N.A.", "death": "N.A."}, "title": "Die sieben Heller", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gro\u00dfer Gott im Himmel, sieben", "tokens": ["Gro\u00b7\u00dfer", "Gott", "im", "Him\u00b7mel", ",", "sie\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADJA", "NN", "APPRART", "NN", "$,", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heller sind mir noch geblieben!", "tokens": ["Hel\u00b7ler", "sind", "mir", "noch", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was nur fang ich armer Mann", "tokens": ["Was", "nur", "fang", "ich", "ar\u00b7mer", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den sieben Hellern an.", "tokens": ["Mit", "den", "sie\u00b7ben", "Hel\u00b7lern", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Tod und Teufel, w\u00e4ren's zwanzig,", "tokens": ["Tod", "und", "Teu\u00b7fel", ",", "w\u00e4\u00b7ren's", "zwan\u00b7zig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "VAFIN", "CARD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tanzte gleich noch einen Tanz ich", "tokens": ["Tanz\u00b7te", "gleich", "noch", "ei\u00b7nen", "Tanz", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf der B\u00fchne buntbemalt,", "tokens": ["Auf", "der", "B\u00fch\u00b7ne", "bunt\u00b7be\u00b7malt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo man zwanzig Heller zahlt!", "tokens": ["Wo", "man", "zwan\u00b7zig", "Hel\u00b7ler", "zahlt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "CARD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "W\u00e4ren's f\u00fcnfzehn! \u2013 Einen Teller", "tokens": ["W\u00e4\u00b7ren's", "f\u00fcnf\u00b7zehn", "!", "\u2013", "Ei\u00b7nen", "Tel\u00b7ler"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["VAFIN", "VVINF", "$.", "$(", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wurst kauft man f\u00fcr f\u00fcnfzehn Heller.", "tokens": ["Wurst", "kauft", "man", "f\u00fcr", "f\u00fcnf\u00b7zehn", "Hel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "CARD", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hungrig bin ich sowieso;", "tokens": ["Hung\u00b7rig", "bin", "ich", "so\u00b7wi\u00b7e\u00b7so", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Eine Wurst macht lebensfroh.", "tokens": ["Ei\u00b7ne", "Wurst", "macht", "le\u00b7bens\u00b7froh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ach, und w\u00e4ren's auch nur zehne!", "tokens": ["Ach", ",", "und", "w\u00e4\u00b7ren's", "auch", "nur", "zeh\u00b7ne", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KON", "VAFIN", "ADV", "ADV", "CARD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Schluck Bier, den ich ersehne,", "tokens": ["Ein", "Schluck", "Bier", ",", "den", "ich", "er\u00b7seh\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist er gleich ein wenig klein,", "tokens": ["Ist", "er", "gleich", "ein", "we\u00b7nig", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mu\u00df f\u00fcr zehne k\u00e4uflich sein.", "tokens": ["Mu\u00df", "f\u00fcr", "zeh\u00b7ne", "k\u00e4uf\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "CARD", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Aber sieben, sieben ganze", "tokens": ["A\u00b7ber", "sie\u00b7ben", ",", "sie\u00b7ben", "gan\u00b7ze"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "VVINF", "$,", "CARD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rote Heller, nicht zu Tanze,", "tokens": ["Ro\u00b7te", "Hel\u00b7ler", ",", "nicht", "zu", "Tan\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu Wurst und nicht zu Bier,", "tokens": ["Nicht", "zu", "Wurst", "und", "nicht", "zu", "Bier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gar zu nichts verwendbar mir \u2013!", "tokens": ["Gar", "zu", "nichts", "ver\u00b7wend\u00b7bar", "mir", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PTKA", "PIS", "ADJD", "PPER", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Lehr mich du, o F\u00fcrst der H\u00f6lle,", "tokens": ["Lehr", "mich", "du", ",", "o", "F\u00fcrst", "der", "H\u00f6l\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "$,", "FM", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was t\u00e4tst du an meiner Stelle,", "tokens": ["Was", "t\u00e4tst", "du", "an", "mei\u00b7ner", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Wenn im Beutel du zuletzt", "tokens": ["Wenn", "im", "Beu\u00b7tel", "du", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur noch sieben Heller h\u00e4ttst? \u2013", "tokens": ["Nur", "noch", "sie\u00b7ben", "Hel\u00b7ler", "h\u00e4ttst", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "CARD", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Alsbald zieht der gro\u00dfe Weise", "tokens": ["Als\u00b7bald", "zieht", "der", "gro\u00b7\u00dfe", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seine d\u00fcstren Zauberkreise,", "tokens": ["Sei\u00b7ne", "d\u00fcst\u00b7ren", "Zau\u00b7ber\u00b7krei\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spuckt nach rechts und links und spricht:", "tokens": ["Spuckt", "nach", "rechts", "und", "links", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "KON", "ADV", "KON", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "H\u00f6r mich an, du armer Wicht!", "tokens": ["H\u00f6r", "mich", "an", ",", "du", "ar\u00b7mer", "Wicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PTKVZ", "$,", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Kommt bei Wettersturm und Regen", "tokens": ["Kommt", "bei", "Wet\u00b7ter\u00b7sturm", "und", "Re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dir ein Bettelkind entgegen,", "tokens": ["Dir", "ein", "Bet\u00b7tel\u00b7kind", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarz von Auge, schwarz von Haar,", "tokens": ["Schwarz", "von", "Au\u00b7ge", ",", "schwarz", "von", "Haar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Busen im Entwicklungsjahr,", "tokens": ["Bu\u00b7sen", "im", "Ent\u00b7wick\u00b7lungs\u00b7jahr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wirf ihr deine sieben Heller", "tokens": ["Wirf", "ihr", "dei\u00b7ne", "sie\u00b7ben", "Hel\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPOSAT", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In des Hemdes losen G\u00f6ller,", "tokens": ["In", "des", "Hem\u00b7des", "lo\u00b7sen", "G\u00f6l\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sag ihr, sie sei engelsch\u00f6n,", "tokens": ["Sag", "ihr", ",", "sie", "sei", "en\u00b7gel\u00b7sch\u00f6n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Schweig und hei\u00df sie weitergehn!", "tokens": ["Schweig", "und", "hei\u00df", "sie", "wei\u00b7ter\u00b7gehn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Du hast Freude, sie hat Freude,", "tokens": ["Du", "hast", "Freu\u00b7de", ",", "sie", "hat", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "PPER", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Freuen werdet ihr euch beide;", "tokens": ["Freu\u00b7en", "wer\u00b7det", "ihr", "euch", "bei\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPER", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine Freude hab auch ich,", "tokens": ["Mei\u00b7ne", "Freu\u00b7de", "hab", "auch", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Segne und belohne dich!", "tokens": ["Seg\u00b7ne", "und", "be\u00b7loh\u00b7ne", "dich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}