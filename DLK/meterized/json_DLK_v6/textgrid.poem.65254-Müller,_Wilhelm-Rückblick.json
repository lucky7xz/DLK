{"textgrid.poem.65254": {"metadata": {"author": {"name": "M\u00fcller, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "R\u00fcckblick", "genre": "verse", "period": "N.A.", "pub_year": 1810, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es brennt mir unter beiden Sohlen,", "tokens": ["Es", "brennt", "mir", "un\u00b7ter", "bei\u00b7den", "Soh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Tret' ich auch schon auf Eis und Schnee.", "tokens": ["Tret'", "ich", "auch", "schon", "auf", "Eis", "und", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich m\u00f6cht' nicht wieder Athem holen,", "tokens": ["Ich", "m\u00f6cht'", "nicht", "wie\u00b7der", "A\u00b7them", "ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bis ich nicht mehr die Th\u00fcrme seh'.", "tokens": ["Bis", "ich", "nicht", "mehr", "die", "Th\u00fcr\u00b7me", "seh'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Hab' mich an jedem Stein gesto\u00dfen,", "tokens": ["Hab'", "mich", "an", "je\u00b7dem", "Stein", "ge\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So eilt' ich zu der Stadt hinaus;", "tokens": ["So", "eilt'", "ich", "zu", "der", "Stadt", "hin\u00b7aus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Kr\u00e4hen warfen B\u00e4ll' und Schlo\u00dfen", "tokens": ["Die", "Kr\u00e4\u00b7hen", "war\u00b7fen", "B\u00e4ll'", "und", "Schlo\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auf meinen Hut von jedem Haus.", "tokens": ["Auf", "mei\u00b7nen", "Hut", "von", "je\u00b7dem", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie anders hast du mich empfangen,", "tokens": ["Wie", "an\u00b7ders", "hast", "du", "mich", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du Stadt der Unbest\u00e4ndigkeit!", "tokens": ["Du", "Stadt", "der", "Un\u00b7be\u00b7st\u00e4n\u00b7dig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An deinen blanken Fenstern sangen", "tokens": ["An", "dei\u00b7nen", "blan\u00b7ken", "Fens\u00b7tern", "san\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Lerch' und Nachtigall im Streit.", "tokens": ["Die", "Ler\u00b7ch'", "und", "Nach\u00b7ti\u00b7gall", "im", "Streit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Die runden Lindenb\u00e4ume bl\u00fchten,", "tokens": ["Die", "run\u00b7den", "Lin\u00b7den\u00b7b\u00e4u\u00b7me", "bl\u00fch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die klaren Rinnen rauschten hell,", "tokens": ["Die", "kla\u00b7ren", "Rin\u00b7nen", "rauschten", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und ach, zwei M\u00e4dchenaugen gl\u00fchten! \u2013", "tokens": ["Und", "ach", ",", "zwei", "M\u00e4d\u00b7chen\u00b7au\u00b7gen", "gl\u00fch\u00b7ten", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "XY", "$,", "CARD", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da war's geschehn um dich, Gesell!", "tokens": ["Da", "wa\u00b7r's", "ge\u00b7schehn", "um", "dich", ",", "Ge\u00b7sell", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "APPR", "PPER", "$,", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "K\u00f6mmt mir der Tag in die Gedanken,", "tokens": ["K\u00f6mmt", "mir", "der", "Tag", "in", "die", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "M\u00f6cht' ich noch einmal r\u00fcckw\u00e4rts sehn,", "tokens": ["M\u00f6cht'", "ich", "noch", "ein\u00b7mal", "r\u00fcck\u00b7w\u00e4rts", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "M\u00f6cht' ich zur\u00fccke wieder wanken,", "tokens": ["M\u00f6cht'", "ich", "zu\u00b7r\u00fc\u00b7cke", "wie\u00b7der", "wan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vor ", "tokens": ["Vor"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}}}}}