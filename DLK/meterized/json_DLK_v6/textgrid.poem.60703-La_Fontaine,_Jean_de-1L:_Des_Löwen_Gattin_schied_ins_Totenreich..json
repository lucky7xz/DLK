{"textgrid.poem.60703": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Des L\u00f6wen Gattin schied ins Totenreich.", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des L\u00f6wen Gattin schied ins Totenreich.", "tokens": ["Des", "L\u00f6\u00b7wen", "Gat\u00b7tin", "schied", "ins", "To\u00b7ten\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein jeder lief sogleich,", "tokens": ["Ein", "je\u00b7der", "lief", "sog\u00b7leich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dem Herrn Beileid zu sagen", "tokens": ["Dem", "Herrn", "Bei\u00b7leid", "zu", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In Trostesreden, die von K\u00fcmmernis getragen.", "tokens": ["In", "Tros\u00b7tes\u00b7re\u00b7den", ",", "die", "von", "K\u00fcm\u00b7mer\u00b7nis", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kund und zu wissen tat der L\u00f6we allen Tieren,", "tokens": ["Kund", "und", "zu", "wis\u00b7sen", "tat", "der", "L\u00f6\u00b7we", "al\u00b7len", "Tie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKZU", "VVINF", "VVFIN", "ART", "NE", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "An welchem Tag und Ort", "tokens": ["An", "wel\u00b7chem", "Tag", "und", "Ort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Bestattung sei; es w\u00fcrden die Beamten dort", "tokens": ["Be\u00b7stat\u00b7tung", "sei", ";", "es", "w\u00fcr\u00b7den", "die", "Be\u00b7am\u00b7ten", "dort"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$.", "PPER", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Leute f\u00fcr den Leichenzug gruppieren.", "tokens": ["Die", "Leu\u00b7te", "f\u00fcr", "den", "Lei\u00b7chen\u00b7zug", "grup\u00b7pie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nun fragt euch selbst, ob nicht ein jeder kam.", "tokens": ["Nun", "fragt", "euch", "selbst", ",", "ob", "nicht", "ein", "je\u00b7der", "kam", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PTKNEG", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Der L\u00f6we \u00fcberlie\u00df sich seinem Gram,", "tokens": ["Der", "L\u00f6\u00b7we", "\u00fc\u00b7ber\u00b7lie\u00df", "sich", "sei\u00b7nem", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PRF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Da\u00df seine H\u00f6hle davon widerhallte;", "tokens": ["Da\u00df", "sei\u00b7ne", "H\u00f6h\u00b7le", "da\u00b7von", "wi\u00b7der\u00b7hall\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Denn keinen andern Tempel hat das Leugeschlecht.", "tokens": ["Denn", "kei\u00b7nen", "an\u00b7dern", "Tem\u00b7pel", "hat", "das", "Leu\u00b7ge\u00b7schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und seinem Beispiel folgend schallte", "tokens": ["Und", "sei\u00b7nem", "Bei\u00b7spiel", "fol\u00b7gend", "schall\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Das Wehgeschrei von H\u00f6fling und von Knecht", "tokens": ["Das", "Weh\u00b7ge\u00b7schrei", "von", "H\u00f6f\u00b7ling", "und", "von", "Knecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Am Hof, den ich f\u00fcr eine St\u00e4tte halte,", "tokens": ["Am", "Hof", ",", "den", "ich", "f\u00fcr", "ei\u00b7ne", "St\u00e4t\u00b7te", "hal\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Wo man betr\u00fcbt, vergn\u00fcgt, entflammt, verg\u00e4llt,", "tokens": ["Wo", "man", "be\u00b7tr\u00fcbt", ",", "ver\u00b7gn\u00fcgt", ",", "ent\u00b7flammt", ",", "ver\u00b7g\u00e4llt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "VVPP", "$,", "VVPP", "$,", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Kurz alles ist, was nur dem Herrn gef\u00e4llt,", "tokens": ["Kurz", "al\u00b7les", "ist", ",", "was", "nur", "dem", "Herrn", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "VAFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Zum mindsten aber solchen Schein erweckt,", "tokens": ["Zum", "minds\u00b7ten", "a\u00b7ber", "sol\u00b7chen", "Schein", "er\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "So man's nicht sein kann in der Tat.", "tokens": ["So", "man's", "nicht", "sein", "kann", "in", "der", "Tat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PTKNEG", "VAINF", "VMFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Cham\u00e4leons, Affen sind es, deren Tun bezweckt,", "tokens": ["Cha\u00b7m\u00e4\u00b7le\u00b7ons", ",", "Af\u00b7fen", "sind", "es", ",", "de\u00b7ren", "Tun", "be\u00b7zweckt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "VAFIN", "PPER", "$,", "PRELAT", "NN", "VVPP", "$,"], "meter": "----+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.21": {"text": "Sich anzupassen ihrem Potentat.", "tokens": ["Sich", "an\u00b7zu\u00b7pas\u00b7sen", "ih\u00b7rem", "Po\u00b7ten\u00b7tat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVIZU", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Man k\u00f6nnte sagen, da\u00df ein Geist", "tokens": ["Man", "k\u00f6nn\u00b7te", "sa\u00b7gen", ",", "da\u00df", "ein", "Geist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VMFIN", "VVINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Mit Leben tausend K\u00f6rper speist:", "tokens": ["Mit", "Le\u00b7ben", "tau\u00b7send", "K\u00f6r\u00b7per", "speist", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "So vielverzweigt auch der Verwaltungsapparat,", "tokens": ["So", "viel\u00b7ver\u00b7zweigt", "auch", "der", "Ver\u00b7wal\u00b7tungs\u00b7ap\u00b7pa\u00b7rat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Kein Zweig hat einen eignen Geist.", "tokens": ["Kein", "Zweig", "hat", "ei\u00b7nen", "eig\u00b7nen", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Zur\u00fcck zu der Geschichte nun.", "tokens": ["Zu\u00b7r\u00fcck", "zu", "der", "Ge\u00b7schich\u00b7te", "nun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Der Hirsch hat nicht geweint. Wie sollte er es tun?", "tokens": ["Der", "Hirsch", "hat", "nicht", "ge\u00b7weint", ".", "Wie", "soll\u00b7te", "er", "es", "tun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$.", "PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ihm schien der L\u00f6win Tod gerechte Rache:", "tokens": ["Ihm", "schien", "der", "L\u00f6\u00b7win", "Tod", "ge\u00b7rech\u00b7te", "Ra\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Sie war es, die ihm Weib und Sohn geraubt.", "tokens": ["Sie", "war", "es", ",", "die", "ihm", "Weib", "und", "Sohn", "ge\u00b7raubt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Und schwor bei seinem Haupt,", "tokens": ["Und", "schwor", "bei", "sei\u00b7nem", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.31": {"text": "Zu lachen habe dieser Hirsch gewagt.", "tokens": ["Zu", "la\u00b7chen", "ha\u00b7be", "die\u00b7ser", "Hirsch", "ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Der Zorn des K\u00f6nigs, hat schon Salomo gesagt,", "tokens": ["Der", "Zorn", "des", "K\u00f6\u00b7nigs", ",", "hat", "schon", "Sa\u00b7lo\u00b7mo", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "VAFIN", "ADV", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ist schrecklich! (Doch kein Hirsch versteht zu lesen.)", "tokens": ["Ist", "schreck\u00b7lich", "!", "(", "Doch", "kein", "Hirsch", "ver\u00b7steht", "zu", "le\u00b7sen", ".", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "$.", "$(", "KON", "PIAT", "NN", "VVFIN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Besonders schrecklich ist des L\u00f6wen Zorn gewesen.", "tokens": ["Be\u00b7son\u00b7ders", "schreck\u00b7lich", "ist", "des", "L\u00f6\u00b7wen", "Zorn", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Er rief: \u00bbDerweil ein jeder klagt,", "tokens": ["Er", "rief", ":", "\u00bb", "Der\u00b7weil", "ein", "je\u00b7der", "klagt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "KOUS", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Ist dir, du Wicht, zu lachen beigefallen?", "tokens": ["Ist", "dir", ",", "du", "Wicht", ",", "zu", "la\u00b7chen", "bei\u00b7ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "PPER", "NN", "$,", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Wir werden nicht die k\u00f6niglichen Krallen", "tokens": ["Wir", "wer\u00b7den", "nicht", "die", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Kral\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.38": {"text": "An dir besudeln. Kommt, ihr Untertanen,", "tokens": ["An", "dir", "be\u00b7su\u00b7deln", ".", "Kommt", ",", "ihr", "Un\u00b7ter\u00b7ta\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "$.", "VVFIN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "Ihr W\u00f6lfe, r\u00e4cht die K\u00f6nigin", "tokens": ["Ihr", "W\u00f6l\u00b7fe", ",", "r\u00e4cht", "die", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Und richtet diesen Frevler hin", "tokens": ["Und", "rich\u00b7tet", "die\u00b7sen", "Frev\u00b7ler", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Als Opfer f\u00fcr die heiligen Manen!\u00ab", "tokens": ["Als", "Op\u00b7fer", "f\u00fcr", "die", "hei\u00b7li\u00b7gen", "Ma\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.42": {"text": "\u00bbherr,\u00ab sprach der Hirsch, \u00bbvorbei die Zeit zum Weinen!", "tokens": ["\u00bb", "herr", ",", "\u00ab", "sprach", "der", "Hirsch", ",", "\u00bb", "vor\u00b7bei", "die", "Zeit", "zum", "Wei\u00b7nen", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "$(", "VVFIN", "ART", "NN", "$,", "$(", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Das Jammern will mir \u00fcberfl\u00fcssig scheinen.", "tokens": ["Das", "Jam\u00b7mern", "will", "mir", "\u00fc\u00b7berf\u00b7l\u00fcs\u00b7sig", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "O da\u00df Ihr's doch gleich mir gesehen h\u00e4ttet!", "tokens": ["O", "da\u00df", "Ih\u00b7r's", "doch", "gleich", "mir", "ge\u00b7se\u00b7hen", "h\u00e4t\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PIS", "ADV", "ADV", "PPER", "VVPP", "VAFIN", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.45": {"text": "Denkt, Euer wertes Weib ist mir erschienen,", "tokens": ["Denkt", ",", "Eu\u00b7er", "wer\u00b7tes", "Weib", "ist", "mir", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.46": {"text": "In Blumen sanft gebettet,", "tokens": ["In", "Blu\u00b7men", "sanft", "ge\u00b7bet\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.47": {"text": "Und ich erkannte sie sogleich.", "tokens": ["Und", "ich", "er\u00b7kann\u00b7te", "sie", "sog\u00b7leich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Freund, sprach sie mit verkl\u00e4rten Mienen,", "tokens": ["Freund", ",", "sprach", "sie", "mit", "ver\u00b7kl\u00e4r\u00b7ten", "Mie\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Ich schwebe in der G\u00f6tter Reich.", "tokens": ["Ich", "schwe\u00b7be", "in", "der", "G\u00f6t\u00b7ter", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "La\u00df ab, mit Trauer mir zu dienen.", "tokens": ["La\u00df", "ab", ",", "mit", "Trau\u00b7er", "mir", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "Mit jenen plaudernd, die in Seligkeit mir gleich,", "tokens": ["Mit", "je\u00b7nen", "plau\u00b7dernd", ",", "die", "in", "Se\u00b7lig\u00b7keit", "mir", "gleich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVPP", "$,", "PRELS", "APPR", "NN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Darf im Elysium tausend Wonnen ich genie\u00dfen.", "tokens": ["Darf", "im", "E\u00b7ly\u00b7si\u00b7um", "tau\u00b7send", "Won\u00b7nen", "ich", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "CARD", "NN", "PPER", "VVINF", "$."], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.53": {"text": "Doch m\u00f6gen noch f\u00fcr einige Zeit", "tokens": ["Doch", "m\u00f6\u00b7gen", "noch", "f\u00fcr", "ei\u00b7ni\u00b7ge", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.54": {"text": "Des K\u00f6nigs Tr\u00e4nen um mich flie\u00dfen,", "tokens": ["Des", "K\u00f6\u00b7nigs", "Tr\u00e4\u00b7nen", "um", "mich", "flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.55": {"text": "Denn wohl tut mir sein edles Leid.\u00ab", "tokens": ["Denn", "wohl", "tut", "mir", "sein", "ed\u00b7les", "Leid", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.56": {"text": "Kaum da\u00df man dies vernommen,", "tokens": ["Kaum", "da\u00df", "man", "dies", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "PDS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.57": {"text": "Da rief man: \u00bbWunder! \u2013 Himmelsgl\u00fcck!\u00ab", "tokens": ["Da", "rief", "man", ":", "\u00bb", "Wun\u00b7der", "!", "\u2013", "Him\u00b7mels\u00b7gl\u00fcck", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$.", "$(", "NN", "$.", "$(", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Der L\u00f6we zog sein Urteil schnell zur\u00fcck,", "tokens": ["Der", "L\u00f6\u00b7we", "zog", "sein", "Ur\u00b7teil", "schnell", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPOSAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "Statt Strafe hat der Hirsch ein Dankgeschenk bekommen.", "tokens": ["Statt", "Stra\u00b7fe", "hat", "der", "Hirsch", "ein", "Dank\u00b7ge\u00b7schenk", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Mit Schmeichell\u00fcgen m\u00fc\u00dft ihr sie bedienen!", "tokens": ["Mit", "Schmei\u00b7chel\u00b7l\u00fc\u00b7gen", "m\u00fc\u00dft", "ihr", "sie", "be\u00b7die\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Wie tief gekr\u00e4nkt ihr Herz auch war,", "tokens": ["Wie", "tief", "ge\u00b7kr\u00e4nkt", "ihr", "Herz", "auch", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVPP", "PPOSAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Sie bei\u00dfen an, und Freunde seid ihr ihnen.", "tokens": ["Sie", "bei\u00b7\u00dfen", "an", ",", "und", "Freun\u00b7de", "seid", "ihr", "ih\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KON", "NN", "VAFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}