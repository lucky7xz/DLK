{"textgrid.poem.41432": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der ruhmredige Hase", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Rammler, den zu fr\u00fch der D\u00fcnkel aufgeblasen,", "tokens": ["Ein", "Ramm\u00b7ler", ",", "den", "zu", "fr\u00fch", "der", "D\u00fcn\u00b7kel", "auf\u00b7ge\u00b7bla\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PTKA", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hielt sich f\u00fcr einen hohen Geist.", "tokens": ["Hielt", "sich", "f\u00fcr", "ei\u00b7nen", "ho\u00b7hen", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum? Das N\u00e4rrchen war gereist,", "tokens": ["Wa\u00b7rum", "?", "Das", "N\u00e4rr\u00b7chen", "war", "ge\u00b7reist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und konnte freilich mehr als grasen.", "tokens": ["Und", "konn\u00b7te", "frei\u00b7lich", "mehr", "als", "gra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PIAT", "KOKOM", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm sollte kaum ein Fuchs an Einsicht \u00e4hnlich sein,", "tokens": ["Ihm", "soll\u00b7te", "kaum", "ein", "Fuchs", "an", "Ein\u00b7sicht", "\u00e4hn\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NE", "APPR", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und darum will er sich auch nur dem Hofe weihn.", "tokens": ["Und", "da\u00b7rum", "will", "er", "sich", "auch", "nur", "dem", "Ho\u00b7fe", "weihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PPER", "PRF", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er wartet bald mit zierlichen Manieren", "tokens": ["Er", "war\u00b7tet", "bald", "mit", "zier\u00b7li\u00b7chen", "Ma\u00b7nie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Dem L\u00f6wen auf, macht M\u00e4nnchen, h\u00fcpft und spricht:", "tokens": ["Dem", "L\u00f6\u00b7wen", "auf", ",", "macht", "M\u00e4nn\u00b7chen", ",", "h\u00fcpft", "und", "spricht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "VVFIN", "NN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Un\u00fcberwindlicher, von ungez\u00e4hlten Thieren,", "tokens": ["Un\u00b7\u00fc\u00b7berw\u00b7ind\u00b7li\u00b7cher", ",", "von", "un\u00b7ge\u00b7z\u00e4hl\u00b7ten", "Thie\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Sie so k\u00f6niglich regieren,", "tokens": ["Die", "Sie", "so", "k\u00f6\u00b7nig\u00b7lich", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Kennt keines, so wie ich, der Unterthanen Pflicht,", "tokens": ["Kennt", "kei\u00b7nes", ",", "so", "wie", "ich", ",", "der", "Un\u00b7ter\u00b7tha\u00b7nen", "Pflicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "ADV", "KOKOM", "PPER", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und der Monarchen Recht. In manchem fernen Lande", "tokens": ["Und", "der", "Mon\u00b7ar\u00b7chen", "Recht", ".", "In", "man\u00b7chem", "fer\u00b7nen", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN", "$.", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Verband ich Artigkeit mit gr\u00fcndlichem Verstande.", "tokens": ["Ver\u00b7band", "ich", "Ar\u00b7tig\u00b7keit", "mit", "gr\u00fcnd\u00b7li\u00b7chem", "Ver\u00b7stan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Sie werden es schon sehn, weil Eurer Majest\u00e4t", "tokens": ["Sie", "wer\u00b7den", "es", "schon", "sehn", ",", "weil", "Eu\u00b7rer", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVINF", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Erhabner Weisheit nichts entgeht,", "tokens": ["Er\u00b7hab\u00b7ner", "Weis\u00b7heit", "nichts", "ent\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wenn andre Staaten nicht mich diesem Hofe g\u00f6nnen,", "tokens": ["Wenn", "and\u00b7re", "Staa\u00b7ten", "nicht", "mich", "die\u00b7sem", "Ho\u00b7fe", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "PTKNEG", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ach! so beklag' ich sie. Verdien' ich ihren Neid,", "tokens": ["Ach", "!", "so", "be\u00b7klag'", "ich", "sie", ".", "Ver\u00b7dien'", "ich", "ih\u00b7ren", "Neid", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "PPER", "PPER", "$.", "NN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So soll, Gro\u00dfm\u00e4chtigster, doch meine F\u00e4higkeit", "tokens": ["So", "soll", ",", "Gro\u00df\u00b7m\u00e4ch\u00b7tigs\u00b7ter", ",", "doch", "mei\u00b7ne", "F\u00e4\u00b7hig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "$,", "NN", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Nur Dero Winke sich stets unterth\u00e4nig nennen.", "tokens": ["Nur", "De\u00b7ro", "Win\u00b7ke", "sich", "stets", "un\u00b7ter\u00b7th\u00e4\u00b7nig", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ich bin zu jedem Dienst bereit,", "tokens": ["Ich", "bin", "zu", "je\u00b7dem", "Dienst", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Und werd' auch jedes Amt mit Ruhm bekleiden k\u00f6nnen.", "tokens": ["Und", "werd'", "auch", "je\u00b7des", "Amt", "mit", "Ruhm", "be\u00b7klei\u00b7den", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "APPR", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der L\u00f6we sprach: Der Herr ist klug,", "tokens": ["Der", "L\u00f6\u00b7we", "sprach", ":", "Der", "Herr", "ist", "klug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Und zum Versuche gut genug.", "tokens": ["Und", "zum", "Ver\u00b7su\u00b7che", "gut", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Wir machen ihn zum Rath. Uns soll er stets begleiten", "tokens": ["Wir", "ma\u00b7chen", "ihn", "zum", "Rath", ".", "Uns", "soll", "er", "stets", "be\u00b7glei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Mit allen seinen F\u00e4higkeiten.", "tokens": ["Mit", "al\u00b7len", "sei\u00b7nen", "F\u00e4\u00b7hig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Wir ziehen morgen aus, den Tieger zu bestreiten.", "tokens": ["Wir", "zie\u00b7hen", "mor\u00b7gen", "aus", ",", "den", "Tie\u00b7ger", "zu", "be\u00b7strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie? sagt der junge Herr. Den Tieger? den Barbar?", "tokens": ["Wie", "?", "sagt", "der", "jun\u00b7ge", "Herr", ".", "Den", "Tie\u00b7ger", "?", "den", "Bar\u00b7bar", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "ART", "ADJA", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Den Fresser? Ach! das bringt Gefahr.", "tokens": ["Den", "Fres\u00b7ser", "?", "Ach", "!", "das", "bringt", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ITJ", "$.", "PDS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Mich d\u00e4ucht, man sollt' ihn noch sondiren.", "tokens": ["Mich", "d\u00e4ucht", ",", "man", "sollt'", "ihn", "noch", "son\u00b7di\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PIS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Ist er uns wirklich feind? Befindet das sich wahr:", "tokens": ["Ist", "er", "uns", "wirk\u00b7lich", "feind", "?", "Be\u00b7fin\u00b7det", "das", "sich", "wahr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "NN", "$.", "VVFIN", "ART", "PRF", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So sende man, statt ihn zu attaquiren,", "tokens": ["So", "sen\u00b7de", "man", ",", "statt", "ihn", "zu", "at\u00b7ta\u00b7qui\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.32": {"text": "Die Affen ab, ihn zu civilisiren.", "tokens": ["Die", "Af\u00b7fen", "ab", ",", "ihn", "zu", "ci\u00b7vi\u00b7li\u00b7si\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Gl\u00fcckt dieses nicht, und will er Kriege f\u00fchren,", "tokens": ["Gl\u00fcckt", "die\u00b7ses", "nicht", ",", "und", "will", "er", "Krie\u00b7ge", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PTKNEG", "$,", "KON", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "So macht sich meine Kunst alsdann recht offenbar:", "tokens": ["So", "macht", "sich", "mei\u00b7ne", "Kunst", "als\u00b7dann", "recht", "of\u00b7fen\u00b7bar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So will ich schon capituliren.", "tokens": ["So", "will", "ich", "schon", "ca\u00b7pi\u00b7tu\u00b7li\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.36": {"text": "Der L\u00f6we br\u00fcllt erz\u00fcrnt: Ein solcher Rath entehrt", "tokens": ["Der", "L\u00f6\u00b7we", "br\u00fcllt", "er\u00b7z\u00fcrnt", ":", "Ein", "sol\u00b7cher", "Rath", "ent\u00b7ehrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "VVPP", "$.", "ART", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Mich und mein Heldenreich, und ist bestrafenswerth.", "tokens": ["Mich", "und", "mein", "Hel\u00b7den\u00b7reich", ",", "und", "ist", "be\u00b7stra\u00b7fens\u00b7werth", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$,", "KON", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Der Hase legt es nun aufs Flehen.", "tokens": ["Der", "Ha\u00b7se", "legt", "es", "nun", "aufs", "Fle\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Ich, \u00e4chzt er, kann zwar fechten sehen,", "tokens": ["Ich", ",", "\u00e4chzt", "er", ",", "kann", "zwar", "fech\u00b7ten", "se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "$,", "VMFIN", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Und lob' auch jede Heldenthat;", "tokens": ["Und", "lob'", "auch", "je\u00b7de", "Hel\u00b7den\u00b7that", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Allein, die Wahrheit zu gestehen,", "tokens": ["Al\u00b7lein", ",", "die", "Wahr\u00b7heit", "zu", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "So dien' ich nur zum Friedensrath.", "tokens": ["So", "dien'", "ich", "nur", "zum", "Frie\u00b7dens\u00b7rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}