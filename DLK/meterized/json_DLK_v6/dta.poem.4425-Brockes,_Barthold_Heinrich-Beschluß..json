{"dta.poem.4425": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Beschlu\u00df.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1727", "urn": "urn:nbn:de:kobv:b4-200905198599", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Dieses ist's, was von den Sinnen", "tokens": ["Die\u00b7ses", "ist's", ",", "was", "von", "den", "Sin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsern Sinnen ist bekannt.", "tokens": ["Un\u00b7sern", "Sin\u00b7nen", "ist", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat man aber gleich hierinnen", "tokens": ["Hat", "man", "a\u00b7ber", "gleich", "hie\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "PAV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles Sinnen angewandt;", "tokens": ["Al\u00b7les", "Sin\u00b7nen", "an\u00b7ge\u00b7wandt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bleibt das Wesen doch verborgen,", "tokens": ["Bleibt", "das", "We\u00b7sen", "doch", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ungeachtet aller Sorgen.", "tokens": ["Un\u00b7ge\u00b7ach\u00b7tet", "al\u00b7ler", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Mu\u00df der Kl\u00fcg\u2019ste doch gestehn,", "tokens": ["Mu\u00df", "der", "Kl\u00fcg'\u00b7ste", "doch", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df wir kaum den Schatten sehn.", "tokens": ["Da\u00df", "wir", "kaum", "den", "Schat\u00b7ten", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Da\u00df wir aber die\u00df nicht fassen,", "tokens": ["Da\u00df", "wir", "a\u00b7ber", "die\u00df", "nicht", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PDS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "D\u00fcrfen wir uns warlich nicht", "tokens": ["D\u00fcr\u00b7fen", "wir", "uns", "war\u00b7lich", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gar zu sehr befremden lassen.", "tokens": ["Gar", "zu", "sehr", "be\u00b7frem\u00b7den", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADV", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00e4tten wir nur vier gekriegt,", "tokens": ["H\u00e4t\u00b7ten", "wir", "nur", "vier", "ge\u00b7kriegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "CARD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sag\u2019t, wer w\u00fcrde dann wol k\u00f6nnen", "tokens": ["Sag't", ",", "wer", "w\u00fcr\u00b7de", "dann", "wol", "k\u00f6n\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "VAFIN", "ADV", "ADV", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch des f\u00fcnften Kraft nur nennen?", "tokens": ["Auch", "des", "f\u00fcnf\u00b7ten", "Kraft", "nur", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df uns also viel verhel\u2019t,", "tokens": ["Da\u00df", "uns", "al\u00b7so", "viel", "ver\u00b7hel't", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Kommt, weil uns der sechste fel\u2019t.", "tokens": ["Kommt", ",", "weil", "uns", "der", "sechs\u00b7te", "fel'", "t."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ART", "ADJA", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Welchen, nebst viel andern Gaben", "tokens": ["Wel\u00b7chen", ",", "nebst", "viel", "an\u00b7dern", "Ga\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kr\u00e4ft- und Sinnen, gar vielleicht", "tokens": ["Kr\u00e4ft", "und", "Sin\u00b7nen", ",", "gar", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["TRUNC", "KON", "NN", "$,", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "And\u2019rer Erden B\u00fcrger haben,", "tokens": ["An\u00b7d'\u00b7rer", "Er\u00b7den", "B\u00fcr\u00b7ger", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die GOTT ihnen dargereicht,", "tokens": ["Die", "GoTT", "ih\u00b7nen", "dar\u00b7ge\u00b7reicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df auf mancher Ahrt und Weise", "tokens": ["Da\u00df", "auf", "man\u00b7cher", "Ahrt", "und", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die verschied\u2019nen Himmels-Kreise", "tokens": ["Die", "ver\u00b7schie\u00b7d'\u00b7nen", "Him\u00b7mels\u00b7Krei\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Seine Gr\u00f6sse sollten sehn,", "tokens": ["Sei\u00b7ne", "Gr\u00f6s\u00b7se", "soll\u00b7ten", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und Sein\u2019 Allmachts-Kraft erh\u00f6hn.", "tokens": ["Und", "Sein'", "All\u00b7machts\u00b7Kraft", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.4": {"line.1": {"text": "Ja wer wei\u00df, wann wir verkl\u00e4ret", "tokens": ["Ja", "wer", "wei\u00df", ",", "wann", "wir", "ver\u00b7kl\u00e4\u00b7ret"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "PWS", "VVFIN", "$,", "PWAV", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch den Tod ins Leben gehn,", "tokens": ["Durch", "den", "Tod", "ins", "Le\u00b7ben", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was alsdann uns wiederf\u00e4hret,", "tokens": ["Was", "als\u00b7dann", "uns", "wie\u00b7der\u00b7f\u00e4h\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPER", "VVFIN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "Ob uns GOTT nicht ausersehn,", "tokens": ["Ob", "uns", "GoTT", "nicht", "au\u00b7ser\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Uns in jenem sel\u2019gen Leben", "tokens": ["Uns", "in", "je\u00b7nem", "sel'\u00b7gen", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "And\u2019re Sinne noch zu geben,", "tokens": ["An\u00b7d'\u00b7re", "Sin\u00b7ne", "noch", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und zwar immer mehr und mehr", "tokens": ["Und", "zwar", "im\u00b7mer", "mehr", "und", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADV", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zur Vermehrung seiner Ehr.", "tokens": ["Zur", "Ver\u00b7meh\u00b7rung", "sei\u00b7ner", "Ehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Warum will man denn ergr\u00fcnden,", "tokens": ["Wa\u00b7rum", "will", "man", "denn", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was nicht zu ergr\u00fcnden steht?", "tokens": ["Was", "nicht", "zu", "er\u00b7gr\u00fcn\u00b7den", "steht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Lass\u2019t so saure M\u00fche schwinden,", "tokens": ["Lass't", "so", "sau\u00b7re", "M\u00fc\u00b7he", "schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Drin die Zeit umsonst vergeht!", "tokens": ["Drin", "die", "Zeit", "um\u00b7sonst", "ver\u00b7geht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "GoTT hat uns in diesem Leben", "tokens": ["GoTT", "hat", "uns", "in", "die\u00b7sem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die f\u00fcnf Sinne blo\u00df gegeben,", "tokens": ["Die", "f\u00fcnf", "Sin\u00b7ne", "blo\u00df", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Um in Jhm vergn\u00fcg\u2019t zu seyn,", "tokens": ["Um", "in", "Jhm", "ver\u00b7gn\u00fcg't", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "PPER", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und sich Seiner zu erfreu\u2019n.", "tokens": ["Und", "sich", "Sei\u00b7ner", "zu", "er\u00b7freu'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "PRF", "PPOSAT", "APPR", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Lasset uns doch \u00fcberlegen,", "tokens": ["Las\u00b7set", "uns", "doch", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df fast alles auf der Welt", "tokens": ["Da\u00df", "fast", "al\u00b7les", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIS", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Blo\u00df um uns\u2019rer Sinne wegen,", "tokens": ["Blo\u00df", "um", "un\u00b7s'\u00b7rer", "Sin\u00b7ne", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "APPR", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sey gemacht und vorgestellt;", "tokens": ["Sey", "ge\u00b7macht", "und", "vor\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df die Luft, das Licht, die Erde", "tokens": ["Da\u00df", "die", "Luft", ",", "das", "Licht", ",", "die", "Er\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns\u2019rer Sinne Werkzeug werde;", "tokens": ["Un\u00b7s'\u00b7rer", "Sin\u00b7ne", "Werk\u00b7zeug", "wer\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df so viel so vielerley", "tokens": ["Da\u00df", "so", "viel", "so", "vie\u00b7ler\u00b7ley"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ADV", "PIAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zu den Sinnen n\u00f6tig sey;", "tokens": ["Zu", "den", "Sin\u00b7nen", "n\u00f6\u00b7tig", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Da\u00df der Pflanzen, da\u00df der Tiere", "tokens": ["Da\u00df", "der", "Pflan\u00b7zen", ",", "da\u00df", "der", "Tie\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Absicht, Nutz und Zweck allein,", "tokens": ["Ab\u00b7sicht", ",", "Nutz", "und", "Zweck", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Blo\u00df damit man sehe, sp\u00fcre,", "tokens": ["Blo\u00df", "da\u00b7mit", "man", "se\u00b7he", ",", "sp\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schmecke, h\u00f6r\u2019 und f\u00fcle, seyn;", "tokens": ["Schme\u00b7cke", ",", "h\u00f6r'", "und", "f\u00fc\u00b7le", ",", "seyn", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df selbst unser Leib von innen", "tokens": ["Da\u00df", "selbst", "un\u00b7ser", "Leib", "von", "in\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "APPR", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und von aussen blo\u00df den Sinnen", "tokens": ["Und", "von", "aus\u00b7sen", "blo\u00df", "den", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Mit so mancherley Bem\u00fchn", "tokens": ["Mit", "so", "man\u00b7cher\u00b7ley", "Be\u00b7m\u00fchn"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Kr\u00e4ft- und Eigenschaften dien.", "tokens": ["Kr\u00e4ft", "und", "Ei\u00b7gen\u00b7schaf\u00b7ten", "di\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wenn wir unsern Leib von innen", "tokens": ["Wenn", "wir", "un\u00b7sern", "Leib", "von", "in\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit Aufmerksamkeit besehn;", "tokens": ["Mit", "Auf\u00b7merk\u00b7sam\u00b7keit", "be\u00b7sehn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sp\u00fcren wir, da\u00df f\u00fcr die Sinnen", "tokens": ["Sp\u00fc\u00b7ren", "wir", ",", "da\u00df", "f\u00fcr", "die", "Sin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Wirkungen geschehn;", "tokens": ["Al\u00b7le", "Wir\u00b7kun\u00b7gen", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Da\u00df sich unser Herze reget,", "tokens": ["Da\u00df", "sich", "un\u00b7ser", "Her\u00b7ze", "re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df sich unser Blut beweget,", "tokens": ["Da\u00df", "sich", "un\u00b7ser", "Blut", "be\u00b7we\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df es wie ein Brunnen springt,", "tokens": ["Da\u00df", "es", "wie", "ein", "Brun\u00b7nen", "springt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und durch tausend Adern dringt;", "tokens": ["Und", "durch", "tau\u00b7send", "A\u00b7dern", "dringt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Die besond\u2019re Kraft der Nieren,", "tokens": ["Die", "be\u00b7son\u00b7d'\u00b7re", "Kraft", "der", "Nie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Da\u00df die Leber das Gebl\u00fct,", "tokens": ["Da\u00df", "die", "Le\u00b7ber", "das", "Ge\u00b7bl\u00fct", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nebst der Milz, wei\u00df zu formiren,", "tokens": ["Nebst", "der", "Milz", ",", "wei\u00df", "zu", "for\u00b7mi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df die Lung\u2019 uns Atem zieht;", "tokens": ["Da\u00df", "die", "Lung'", "uns", "A\u00b7tem", "zieht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Uns\u2019rer Nerven zarte G\u00e4nge,", "tokens": ["Un\u00b7s'\u00b7rer", "Ner\u00b7ven", "zar\u00b7te", "G\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Der Ged\u00e4rme L\u00e4ng\u2019 und Menge,", "tokens": ["Der", "Ge\u00b7d\u00e4r\u00b7me", "L\u00e4ng'", "und", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df des Magens rege Kraft", "tokens": ["Da\u00df", "des", "Ma\u00b7gens", "re\u00b7ge", "Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.8": {"text": "Allen Teilen Narung schafft.", "tokens": ["Al\u00b7len", "Tei\u00b7len", "Na\u00b7rung", "schafft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Aller dieser Eingeweide", "tokens": ["Al\u00b7ler", "die\u00b7ser", "Ein\u00b7ge\u00b7wei\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unerforschliche Natur", "tokens": ["Un\u00b7er\u00b7for\u00b7schli\u00b7che", "Na\u00b7tur"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Zielet auf des C\u00f6rpers Freude,", "tokens": ["Zie\u00b7let", "auf", "des", "C\u00f6r\u00b7pers", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dienet den f\u00fcnf Sinnen nur.", "tokens": ["Die\u00b7net", "den", "f\u00fcnf", "Sin\u00b7nen", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "CARD", "NN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Denn die uns verborg\u2019nen S\u00e4fte", "tokens": ["Denn", "die", "uns", "ver\u00b7bor\u00b7g'\u00b7nen", "S\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPER", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Geben unsern Sinnen Kr\u00e4fte,", "tokens": ["Ge\u00b7ben", "un\u00b7sern", "Sin\u00b7nen", "Kr\u00e4f\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und ihr Endzweck ist allein,", "tokens": ["Und", "ihr", "End\u00b7zweck", "ist", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df die Sinne sinnlich seyn.", "tokens": ["Da\u00df", "die", "Sin\u00b7ne", "sinn\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Zeigen solche Wunderwerke,", "tokens": ["Zei\u00b7gen", "sol\u00b7che", "Wun\u00b7der\u00b7wer\u00b7ke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die kein Mensch begreifen kann,", "tokens": ["Die", "kein", "Mensch", "be\u00b7grei\u00b7fen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keine Weisheit, Liebe, St\u00e4rke,", "tokens": ["Kei\u00b7ne", "Weis\u00b7heit", ",", "Lie\u00b7be", ",", "St\u00e4r\u00b7ke", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch den Wehrt der Sinnen an?", "tokens": ["Noch", "den", "Wehrt", "der", "Sin\u00b7nen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich erschrecke, wenn ich denke,", "tokens": ["Ich", "er\u00b7schre\u00b7cke", ",", "wenn", "ich", "den\u00b7ke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie so wenig die\u00df Geschenke", "tokens": ["Wie", "so", "we\u00b7nig", "die\u00df", "Ge\u00b7schen\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIAT", "PDS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und des grossen Gebers Macht", "tokens": ["Und", "des", "gros\u00b7sen", "Ge\u00b7bers", "Macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "In denselben wird geacht\u2019t.", "tokens": ["In", "den\u00b7sel\u00b7ben", "wird", "ge\u00b7acht'", "t."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "PDS", "VAFIN", "VVPP", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Sprich, verstockter Atheiste,", "tokens": ["Sprich", ",", "ver\u00b7stock\u00b7ter", "A\u00b7theis\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$,", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Wenn ein Mensch auf Erden w\u00e4r,", "tokens": ["Wenn", "ein", "Mensch", "auf", "Er\u00b7den", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welcher solche K\u00fcnste w\u00fcste,", "tokens": ["Wel\u00b7cher", "sol\u00b7che", "K\u00fcns\u00b7te", "w\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er Augen, das Geh\u00f6r,", "tokens": ["Da\u00df", "er", "Au\u00b7gen", ",", "das", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Riechen, F\u00fclen, Schmecken, Denken", "tokens": ["Rie\u00b7chen", ",", "F\u00fc\u00b7len", ",", "Schme\u00b7cken", ",", "Den\u00b7ken"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dir verm\u00f6gend w\u00e4r zu schenken,", "tokens": ["Dir", "ver\u00b7m\u00f6\u00b7gend", "w\u00e4r", "zu", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und er schenkte sie denn dir,", "tokens": ["Und", "er", "schenk\u00b7te", "sie", "denn", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Danktest du ihm nicht daf\u00fcr?", "tokens": ["Dank\u00b7test", "du", "ihm", "nicht", "da\u00b7f\u00fcr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Solltest du wol sagen k\u00f6nnen:", "tokens": ["Soll\u00b7test", "du", "wol", "sa\u00b7gen", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles die\u00df ist keine Kunst,", "tokens": ["Al\u00b7les", "die\u00df", "ist", "kei\u00b7ne", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDS", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was er mir wollen g\u00f6nnen,", "tokens": ["Und", "was", "er", "mir", "wol\u00b7len", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Rechne ich f\u00fcr keine Gunst?", "tokens": ["Rech\u00b7ne", "ich", "f\u00fcr", "kei\u00b7ne", "Gunst", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, unm\u00f6glich wird auf Erden", "tokens": ["Nein", ",", "un\u00b7m\u00f6g\u00b7lich", "wird", "auf", "Er\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADJD", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Solch ein Vieh gefunden werden.", "tokens": ["Solch", "ein", "Vieh", "ge\u00b7fun\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da es aber GOTT gemacht,", "tokens": ["Da", "es", "a\u00b7ber", "GoTT", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NE", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Schl\u00e4g\u2019t man\u2019s leider aus der Acht.", "tokens": ["Schl\u00e4g't", "man's", "lei\u00b7der", "aus", "der", "Acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPR", "ART", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Lasst uns doch den Sch\u00f6pfer ehren,", "tokens": ["Lasst", "uns", "doch", "den", "Sch\u00f6p\u00b7fer", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn wir recht was sch\u00f6nes sehn!", "tokens": ["Wenn", "wir", "recht", "was", "sch\u00f6\u00b7nes", "sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PWS", "ADJA", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn wir etwas lieblichs h\u00f6ren,", "tokens": ["Wenn", "wir", "et\u00b7was", "lieb\u00b7lichs", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lasst uns Seinen Ruhm erh\u00f6hn!", "tokens": ["Lasst", "uns", "Sei\u00b7nen", "Ruhm", "er\u00b7h\u00f6hn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn uns Riechen, F\u00fclen, Schmecken", "tokens": ["Wenn", "uns", "Rie\u00b7chen", ",", "F\u00fc\u00b7len", ",", "Schme\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Anmut, Lust und Freud\u2019 erwecken;", "tokens": ["An\u00b7mut", ",", "Lust", "und", "Freud'", "er\u00b7we\u00b7cken", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Lasst uns in Zufriedenheit", "tokens": ["Lasst", "uns", "in", "Zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zeigen uns\u2019re Dankbarkeit!", "tokens": ["Zei\u00b7gen", "un\u00b7s'\u00b7re", "Dank\u00b7bar\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.15": {"line.1": {"text": "Solch ein Dank-erf\u00fclltes Lallen,", "tokens": ["Solch", "ein", "Dank\u00b7er\u00b7f\u00fcll\u00b7tes", "Lal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn\u2019s auch denkend nur geschicht,", "tokens": ["Wenn's", "auch", "den\u00b7kend", "nur", "ge\u00b7schicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df dem Sch\u00f6pfer wolgefallen.", "tokens": ["Mu\u00df", "dem", "Sch\u00f6p\u00b7fer", "wol\u00b7ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die\u00df ist aller Menschen Pflicht;", "tokens": ["Die\u00df", "ist", "al\u00b7ler", "Men\u00b7schen", "Pflicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn wenn man es nicht erkennet,", "tokens": ["Denn", "wenn", "man", "es", "nicht", "er\u00b7ken\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wie viel Gutes GOtt uns g\u00f6nnet,", "tokens": ["Wie", "viel", "Gu\u00b7tes", "Gott", "uns", "g\u00f6n\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und es nicht einmal bedenkt;", "tokens": ["Und", "es", "nicht", "ein\u00b7mal", "be\u00b7denkt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist\u2019s, als w\u00e4r\u2019 uns nichts geschenkt.", "tokens": ["Ist's", ",", "als", "w\u00e4r'", "uns", "nichts", "ge\u00b7schenkt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOKOM", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Nach der Menschen Ahrt zu sprechen,", "tokens": ["Nach", "der", "Men\u00b7schen", "Ahrt", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Scheint zwar dieses Laster klein;", "tokens": ["Scheint", "zwar", "die\u00b7ses", "Las\u00b7ter", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PDAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber warlich kein Verbrechen", "tokens": ["A\u00b7ber", "war\u00b7lich", "kein", "Ver\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kann GOTT mehr zuwider seyn.", "tokens": ["Kann", "GoTT", "mehr", "zu\u00b7wi\u00b7der", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Solche Wunder nicht betrachten,", "tokens": ["Sol\u00b7che", "Wun\u00b7der", "nicht", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Heisst ja, selbige verachten,", "tokens": ["Heisst", "ja", ",", "sel\u00b7bi\u00b7ge", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ADJA", "VVFIN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.7": {"text": "Und aus diesem Undanks-Meer", "tokens": ["Und", "aus", "die\u00b7sem", "Un\u00b7danks\u00b7Meer"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Fliessen alle S\u00fcnden her.", "tokens": ["Flies\u00b7sen", "al\u00b7le", "S\u00fcn\u00b7den", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wir sind Sinn-reich, uns zu qv\u00e4len,", "tokens": ["Wir", "sind", "Sinn\u00b7reich", ",", "uns", "zu", "qv\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und vergr\u00f6ssern uns\u2019re Pein;", "tokens": ["Und", "ver\u00b7gr\u00f6s\u00b7sern", "un\u00b7s'\u00b7re", "Pein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Dennoch w\u00fcnschen uns\u2019re Selen,", "tokens": ["Den\u00b7noch", "w\u00fcn\u00b7schen", "un\u00b7s'\u00b7re", "Se\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Allezeit vergn\u00fcg\u2019t zu seyn.", "tokens": ["Al\u00b7le\u00b7zeit", "ver\u00b7gn\u00fcg't", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nun, zu diesem Zweck zu kommen,", "tokens": ["Nun", ",", "zu", "die\u00b7sem", "Zweck", "zu", "kom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Thut, was ihr anitzt vernommen!", "tokens": ["Thut", ",", "was", "ihr", "a\u00b7nitzt", "ver\u00b7nom\u00b7men", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zur Vergn\u00fcgung eurer Brust,", "tokens": ["Zur", "Ver\u00b7gn\u00fc\u00b7gung", "eu\u00b7rer", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ehret GOTT in eurer Lust!", "tokens": ["Eh\u00b7ret", "GoTT", "in", "eu\u00b7rer", "Lust", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Sollten uns\u2019re Sinne taugen,", "tokens": ["Soll\u00b7ten", "un\u00b7s'\u00b7re", "Sin\u00b7ne", "tau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Tiefer, als sie thun, zu gehn,", "tokens": ["Tie\u00b7fer", ",", "als", "sie", "thun", ",", "zu", "gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nnten wir durch unser\u2019 Augen", "tokens": ["K\u00f6nn\u00b7ten", "wir", "durch", "un\u00b7ser'", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als durch ein Vergr\u00f6ss-Glas sehn;", "tokens": ["Als", "durch", "ein", "Ver\u00b7gr\u00f6ss\u00b7Glas", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrd\u2019 uns f\u00fcr uns selber grauen,", "tokens": ["W\u00fcrd'", "uns", "f\u00fcr", "uns", "sel\u00b7ber", "grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sollten wir die Haut beschauen,", "tokens": ["Soll\u00b7ten", "wir", "die", "Haut", "be\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die ja dann, als wie ein B\u00e4r,", "tokens": ["Die", "ja", "dann", ",", "als", "wie", "ein", "B\u00e4r", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "$,", "KOUS", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Rauch und recht abscheulich w\u00e4r.", "tokens": ["Rauch", "und", "recht", "ab\u00b7scheu\u00b7lich", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Zwar man w\u00fcrd\u2019 auf solche Weise", "tokens": ["Zwar", "man", "w\u00fcrd'", "auf", "sol\u00b7che", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VAFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Viele Kleinigkeiten sehn;", "tokens": ["Vie\u00b7le", "Klei\u00b7nig\u00b7kei\u00b7ten", "sehn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch wie d\u00fcrft\u2019 es um die Kreise", "tokens": ["Doch", "wie", "d\u00fcrft'", "es", "um", "die", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "VMFIN", "PPER", "APPR", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Jener grossen C\u00f6rper stehn?", "tokens": ["Je\u00b7ner", "gros\u00b7sen", "C\u00f6r\u00b7per", "stehn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Von den sch\u00f6nen Himmels-Lichtern", "tokens": ["Von", "den", "sch\u00f6\u00b7nen", "Him\u00b7mels\u00b7Lich\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00fcrde menschlichen Gesichtern", "tokens": ["W\u00fcr\u00b7de", "menschli\u00b7chen", "Ge\u00b7sich\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADJA", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Nichts, bey allem Glanz\u2019 und Schein,", "tokens": ["Nichts", ",", "bey", "al\u00b7lem", "Glanz'", "und", "Schein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "APPR", "PIS", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Jm geringsten sichtbar seyn.", "tokens": ["Jm", "ge\u00b7rings\u00b7ten", "sicht\u00b7bar", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "W\u00e4r\u2019 ein Auge so gebeuget,", "tokens": ["W\u00e4r'", "ein", "Au\u00b7ge", "so", "ge\u00b7beu\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie ein Fern-Glas, das allein", "tokens": ["Wie", "ein", "Fern\u00b7Glas", ",", "das", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "ADV"], "meter": "+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Diese Ding\u2019 uns deutlich zeiget,", "tokens": ["Die\u00b7se", "Ding'", "uns", "deut\u00b7lich", "zei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die von uns entfernet seyn;", "tokens": ["Die", "von", "uns", "ent\u00b7fer\u00b7net", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrden dann die nahen Sachen", "tokens": ["W\u00fcr\u00b7den", "dann", "die", "na\u00b7hen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns nicht ganz verwirret machen?", "tokens": ["Uns", "nicht", "ganz", "ver\u00b7wir\u00b7ret", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Also geht\u2019s mit dem Gebrauch", "tokens": ["Al\u00b7so", "geht's", "mit", "dem", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Uns\u2019rer andern Sinnen auch.", "tokens": ["Un\u00b7s'\u00b7rer", "an\u00b7dern", "Sin\u00b7nen", "auch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "K\u00f6nnten wir viel sch\u00e4rfer h\u00f6ren,", "tokens": ["K\u00f6nn\u00b7ten", "wir", "viel", "sch\u00e4r\u00b7fer", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So, wie oftermals geschicht,", "tokens": ["So", ",", "wie", "of\u00b7ter\u00b7mals", "ge\u00b7schicht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADV", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Wenn man durch die Ohren-R\u00f6ren", "tokens": ["Wenn", "man", "durch", "die", "Oh\u00b7ren\u00b7R\u00b7\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder Sprach-Trompeten spricht;", "tokens": ["O\u00b7der", "Sprach\u00b7Trom\u00b7pe\u00b7ten", "spricht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welch verworr\u2019nes lautes Schallen", "tokens": ["Welch", "ver\u00b7worr'\u00b7nes", "lau\u00b7tes", "Schal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00fcrd\u2019 uns in die Ohren fallen?", "tokens": ["W\u00fcrd'", "uns", "in", "die", "Oh\u00b7ren", "fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ein so wild Ger\u00e4usch allein", "tokens": ["Ein", "so", "wild", "Ge\u00b7r\u00e4usch", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJD", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "W\u00fcrd\u2019 uns unertr\u00e4glich seyn.", "tokens": ["W\u00fcrd'", "uns", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "W\u00e4r\u2019 auch des Gef\u00fcles Wesen", "tokens": ["W\u00e4r'", "auch", "des", "Ge\u00b7f\u00fc\u00b7les", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00e4rfer, und von solcher Ahrt,", "tokens": ["Sch\u00e4r\u00b7fer", ",", "und", "von", "sol\u00b7cher", "Ahrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie uns GOTT zum Aug\u2019 erlesen;", "tokens": ["Wie", "uns", "GoTT", "zum", "Aug'", "er\u00b7le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vieler C\u00f6rper Gegenwart", "tokens": ["Vie\u00b7ler", "C\u00f6r\u00b7per", "Ge\u00b7gen\u00b7wart"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4r\u2019 uns schmerzlich und verdrie\u00dflich.", "tokens": ["W\u00e4r'", "uns", "schmerz\u00b7lich", "und", "ver\u00b7drie\u00df\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gleichfalls w\u00e4r\u2019 es nicht ersprie\u00dflich,", "tokens": ["Gleich\u00b7falls", "w\u00e4r'", "es", "nicht", "er\u00b7sprie\u00df\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn der Zungen Kraft, die schmeckt,", "tokens": ["Wenn", "der", "Zun\u00b7gen", "Kraft", ",", "die", "schmeckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weiter sich, als itzt, erstreckt.", "tokens": ["Wei\u00b7ter", "sich", ",", "als", "itzt", ",", "er\u00b7streckt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PRF", "$,", "KOUS", "ADV", "$,", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Wenn auch der Geruch sich sch\u00e4rste,", "tokens": ["Wenn", "auch", "der", "Ge\u00b7ruch", "sich", "sch\u00e4rs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "So da\u00df man, den Hunden gleich,", "tokens": ["So", "da\u00df", "man", ",", "den", "Hun\u00b7den", "gleich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "$,", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Alle Dinge riechen d\u00f6rfte;", "tokens": ["Al\u00b7le", "Din\u00b7ge", "rie\u00b7chen", "d\u00f6rf\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie verdrie\u00dflich w\u00fcrden euch", "tokens": ["Wie", "ver\u00b7drie\u00df\u00b7lich", "w\u00fcr\u00b7den", "euch"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Allerley Geruch der Erden,", "tokens": ["Al\u00b7ler\u00b7ley", "Ge\u00b7ruch", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ja der meisten Dinge, werden?", "tokens": ["Ja", "der", "meis\u00b7ten", "Din\u00b7ge", ",", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "ART", "PIAT", "NN", "$,", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wir empf\u00fcnden jederzeit", "tokens": ["Wir", "emp\u00b7f\u00fcn\u00b7den", "je\u00b7der\u00b7zeit"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ekel, Abscheu, Widrigkeit.", "tokens": ["E\u00b7kel", ",", "Ab\u00b7scheu", ",", "Wid\u00b7rig\u00b7keit", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Wer kann GOttes Lieb\u2019 ergr\u00fcnden?", "tokens": ["Wer", "kann", "Got\u00b7tes", "Lieb'", "er\u00b7gr\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer kann Seine Macht versteh\u2019n?", "tokens": ["Wer", "kann", "Sei\u00b7ne", "Macht", "ver\u00b7steh'n", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir ohne M\u00fch\u2019 empfinden,", "tokens": ["Da\u00df", "wir", "oh\u00b7ne", "M\u00fch'", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00f6ren, riechen, schmecken, seh\u2019n", "tokens": ["H\u00f6\u00b7ren", ",", "rie\u00b7chen", ",", "schme\u00b7cken", ",", "seh'n"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sonder Arbeit und Studiren,", "tokens": ["Son\u00b7der", "Ar\u00b7beit", "und", "Stu\u00b7di\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "+-+--++-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Kann man durch die Sinne sp\u00fcren.", "tokens": ["Kann", "man", "durch", "die", "Sin\u00b7ne", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Diese Gab\u2019 allein ist wehrt,", "tokens": ["Die\u00b7se", "Gab'", "al\u00b7lein", "ist", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "VAFIN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df man GOTT allein verehrt.", "tokens": ["Da\u00df", "man", "GoTT", "al\u00b7lein", "ver\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NE", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Wie der Sonnen Geist die H\u00f6len", "tokens": ["Wie", "der", "Son\u00b7nen", "Geist", "die", "H\u00f6\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Uns\u2019rer Luft im Stral durchbricht;", "tokens": ["Un\u00b7s'\u00b7rer", "Luft", "im", "Stral", "durch\u00b7bricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Also stral\u2019t aus unsern Selen", "tokens": ["Al\u00b7so", "stral't", "aus", "un\u00b7sern", "Se\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein best\u00e4ndig sinnlich Licht,", "tokens": ["Ein", "be\u00b7st\u00e4n\u00b7dig", "sinn\u00b7lich", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wodurch aller Menschen Sinnen", "tokens": ["Wo\u00b7durch", "al\u00b7ler", "Men\u00b7schen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Empfindungs-Kraft gewinnen.", "tokens": ["Die", "Emp\u00b7fin\u00b7dungs\u00b7Kraft", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Alles, was man sinnt und thut,", "tokens": ["Al\u00b7les", ",", "was", "man", "sinnt", "und", "thut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Stammt aus dieser innern Gluht.", "tokens": ["Stammt", "aus", "die\u00b7ser", "in\u00b7nern", "Gluht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Diesen wiederhol\u2019ten Lehren", "tokens": ["Die\u00b7sen", "wie\u00b7der\u00b7hol'\u00b7ten", "Leh\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Folge denn doch jedermann!", "tokens": ["Fol\u00b7ge", "denn", "doch", "je\u00b7der\u00b7mann", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Braucht die\u00df Licht zu GOttes Ehren!", "tokens": ["Braucht", "die\u00df", "Licht", "zu", "Got\u00b7tes", "Eh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "NN", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seht die Welt mit Andacht an!", "tokens": ["Seht", "die", "Welt", "mit", "An\u00b7dacht", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Such\u2019t mit GOttes Werk die Selen", "tokens": ["Such't", "mit", "Got\u00b7tes", "Werk", "die", "Se\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch die Sinne zu verm\u00e4len,", "tokens": ["Durch", "die", "Sin\u00b7ne", "zu", "ver\u00b7m\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und erzielt, wenn ihr euch freu\u2019t,", "tokens": ["Und", "er\u00b7zielt", ",", "wenn", "ihr", "euch", "freu't", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Kinder br\u00fcnst\u2019ger Dankbarkeit!", "tokens": ["Kin\u00b7der", "br\u00fcnst'\u00b7ger", "Dank\u00b7bar\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "M\u00fcsst ihr nicht auch, wider Willen,", "tokens": ["M\u00fcsst", "ihr", "nicht", "auch", ",", "wi\u00b7der", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu des H\u00f6chsten Preis\u2019 und Ehr\u2019", "tokens": ["Zu", "des", "H\u00f6chs\u00b7ten", "Preis'", "und", "Ehr'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles, was er will, erf\u00fcllen?", "tokens": ["Al\u00b7les", ",", "was", "er", "will", ",", "er\u00b7f\u00fcl\u00b7len", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "$,", "PWS", "PPER", "VMFIN", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wollet ihr denn nicht vielmehr", "tokens": ["Wol\u00b7let", "ihr", "denn", "nicht", "viel\u00b7mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jhm von selbst zu Dienste leben,", "tokens": ["Jhm", "von", "selbst", "zu", "Diens\u00b7te", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "GoTT in eurer Freud\u2019 erheben,", "tokens": ["GoTT", "in", "eu\u00b7rer", "Freud'", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Seines Namens Ehr\u2019 erh\u00f6hn,", "tokens": ["Sei\u00b7nes", "Na\u00b7mens", "Ehr'", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und mit Lust Sein Werk besehn?", "tokens": ["Und", "mit", "Lust", "Sein", "Werk", "be\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Wenn der Sch\u00f6pfer nichts, als Schmerzen,", "tokens": ["Wenn", "der", "Sch\u00f6p\u00b7fer", "nichts", ",", "als", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIS", "$,", "KOUS", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Statt der Lust uns eingepr\u00e4g\u2019t,", "tokens": ["Statt", "der", "Lust", "uns", "ein\u00b7ge\u00b7pr\u00e4g't", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nur blo\u00df f\u00fcr Pein im Herzen", "tokens": ["Und", "nur", "blo\u00df", "f\u00fcr", "Pein", "im", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPR", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein\u2019 Empfindlichkeit geleg\u2019t;", "tokens": ["Ein'", "Emp\u00b7find\u00b7lich\u00b7keit", "ge\u00b7leg't", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4r\u2019 uns unser Leben t\u00e4glich", "tokens": ["W\u00e4r'", "uns", "un\u00b7ser", "Le\u00b7ben", "t\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur ein Scheusal, unertr\u00e4glich,", "tokens": ["Nur", "ein", "Scheu\u00b7sal", ",", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ein\u2019 abscheulich schwere Last,", "tokens": ["Ein'", "ab\u00b7scheu\u00b7lich", "schwe\u00b7re", "Last", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Ja mehr, als der Tod, verhasst.", "tokens": ["Ja", "mehr", ",", "als", "der", "Tod", ",", "ver\u00b7hasst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "ADV", "$,", "KOUS", "ART", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Sey denn, grosser GOTT, gepriesen!", "tokens": ["Sey", "denn", ",", "gros\u00b7ser", "GoTT", ",", "ge\u00b7prie\u00b7sen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df aus lauter Gnaden nur", "tokens": ["Da\u00df", "aus", "lau\u00b7ter", "Gna\u00b7den", "nur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du uns so viel Gnad\u2019 erwiesen,", "tokens": ["Du", "uns", "so", "viel", "Gnad'", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und der menschlichen Natur", "tokens": ["Und", "der", "menschli\u00b7chen", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "So viel Freud\u2019 und Anmut schenkest,", "tokens": ["So", "viel", "Freud'", "und", "An\u00b7mut", "schen\u00b7kest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Sie mit Lust und Wonne tr\u00e4nkest,", "tokens": ["Sie", "mit", "Lust", "und", "Won\u00b7ne", "tr\u00e4n\u00b7kest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da uns jedes Sinnes Kraft", "tokens": ["Da", "uns", "je\u00b7des", "Sin\u00b7nes", "Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Tausendfach Vergn\u00fcgen schafft.", "tokens": ["Tau\u00b7send\u00b7fach", "Ver\u00b7gn\u00fc\u00b7gen", "schafft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}