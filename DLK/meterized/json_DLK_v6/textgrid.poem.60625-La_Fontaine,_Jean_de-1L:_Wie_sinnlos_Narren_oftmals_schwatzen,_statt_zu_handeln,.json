{"textgrid.poem.60625": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie sinnlos Narren oftmals schwatzen, statt zu handeln,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie sinnlos Narren oftmals schwatzen, statt zu handeln,", "tokens": ["Wie", "sinn\u00b7los", "Nar\u00b7ren", "oft\u00b7mals", "schwat\u00b7zen", ",", "statt", "zu", "han\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "NN", "ADV", "VVINF", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das zeigt uns diese Fabel gut.", "tokens": ["Das", "zeigt", "uns", "die\u00b7se", "Fa\u00b7bel", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein Junge, dem's gefiel, am Uferrand zu wandeln,", "tokens": ["Ein", "Jun\u00b7ge", ",", "dem's", "ge\u00b7fiel", ",", "am", "Uf\u00b7er\u00b7rand", "zu", "wan\u00b7deln", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NE", "VVFIN", "$,", "APPRART", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Glitt in des Stromes tiefe Flut.", "tokens": ["Glitt", "in", "des", "Stro\u00b7mes", "tie\u00b7fe", "Flut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Der Himmel wollte, da\u00df dort eine Weide stand,", "tokens": ["Der", "Him\u00b7mel", "woll\u00b7te", ",", "da\u00df", "dort", "ei\u00b7ne", "Wei\u00b7de", "stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "$,", "KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An deren Ruten sich das Kind mit schneller Hand", "tokens": ["An", "de\u00b7ren", "Ru\u00b7ten", "sich", "das", "Kind", "mit", "schnel\u00b7ler", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "PRF", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Festklammerte; es schwebte zwischen Tod und Leben.", "tokens": ["Fest\u00b7klam\u00b7mer\u00b7te", ";", "es", "schweb\u00b7te", "zwi\u00b7schen", "Tod", "und", "Le\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Unschuld Engel wollte weiter, da\u00df soeben", "tokens": ["Der", "Un\u00b7schuld", "En\u00b7gel", "woll\u00b7te", "wei\u00b7ter", ",", "da\u00df", "soe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NE", "VMFIN", "ADV", "$,", "KOUS", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Ein Mensch, ein Schulmeister, des n\u00e4chsten Weges kam", "tokens": ["Ein", "Mensch", ",", "ein", "Schul\u00b7meis\u00b7ter", ",", "des", "n\u00e4chs\u00b7ten", "We\u00b7ges", "kam"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Und unsres Knaben lauten Hilferuf vernahm.", "tokens": ["Und", "uns\u00b7res", "Kna\u00b7ben", "lau\u00b7ten", "Hil\u00b7fe\u00b7ruf", "ver\u00b7nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er blickte hin und sah das Kind im Wasser schweben", "tokens": ["Er", "blick\u00b7te", "hin", "und", "sah", "das", "Kind", "im", "Was\u00b7ser", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und fing sogleich mit ernstem Ton zu schelten an:", "tokens": ["Und", "fing", "sog\u00b7leich", "mit", "erns\u00b7tem", "Ton", "zu", "schel\u00b7ten", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "PTKZU", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u00bbdu kleiner Affenpinscher, was hast du getan!", "tokens": ["\u00bb", "du", "klei\u00b7ner", "Af\u00b7fen\u00b7pin\u00b7scher", ",", "was", "hast", "du", "ge\u00b7tan", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "$,", "PWS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da siehst du nun, wohin dich deine Dummheit f\u00fchrt.", "tokens": ["Da", "siehst", "du", "nun", ",", "wo\u00b7hin", "dich", "dei\u00b7ne", "Dumm\u00b7heit", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mehr Pr\u00fcgel h\u00e4tten dir, du Schlingel, wohl geb\u00fchrt.", "tokens": ["Mehr", "Pr\u00fc\u00b7gel", "h\u00e4t\u00b7ten", "dir", ",", "du", "Schlin\u00b7gel", ",", "wohl", "ge\u00b7b\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "$,", "PPER", "NN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Bedauernswerte Eltern solcher schlimmen Knaben,", "tokens": ["Be\u00b7dau\u00b7erns\u00b7wer\u00b7te", "El\u00b7tern", "sol\u00b7cher", "schlim\u00b7men", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Was m\u00fcssen sie mit ihnen doch f\u00fcr Sorgen haben!", "tokens": ["Was", "m\u00fcs\u00b7sen", "sie", "mit", "ih\u00b7nen", "doch", "f\u00fcr", "Sor\u00b7gen", "ha\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "PPER", "ADV", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mein Gott, wie sind sie hart geplagt", "tokens": ["Mein", "Gott", ",", "wie", "sind", "sie", "hart", "ge\u00b7plagt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Durch solcher Bengel Unverstand!\u00ab", "tokens": ["Durch", "sol\u00b7cher", "Ben\u00b7gel", "Un\u00b7ver\u00b7stand", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Nachdem er dies und mehr gesagt,", "tokens": ["Nach\u00b7dem", "er", "dies", "und", "mehr", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Zog endlich er das Kind ans Land.", "tokens": ["Zog", "end\u00b7lich", "er", "das", "Kind", "ans", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Den Schulmeister k\u00f6nnt ich mit vielen Namen nennen.", "tokens": ["Den", "Schul\u00b7meis\u00b7ter", "k\u00f6nnt", "ich", "mit", "vie\u00b7len", "Na\u00b7men", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+--+--+--", "measure": "amphibrach.tetra.plus"}, "line.2": {"text": "Der Schw\u00e4tzer, N\u00f6rgler und Pedant \u2013", "tokens": ["Der", "Schw\u00e4t\u00b7zer", ",", "N\u00f6rg\u00b7ler", "und", "Pe\u00b7dant", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie alle m\u00f6gen sich in seinem Bild erkennen,", "tokens": ["Sie", "al\u00b7le", "m\u00f6\u00b7gen", "sich", "in", "sei\u00b7nem", "Bild", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VMFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und riesengro\u00df ist ihr Bestand,", "tokens": ["Und", "rie\u00b7sen\u00b7gro\u00df", "ist", "ihr", "Be\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So zahlreich wie der Ufersand.", "tokens": ["So", "zahl\u00b7reich", "wie", "der", "U\u00b7fer\u00b7sand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns ihre Zunge gr\u00fcndlich auszusch\u00fctteln.", "tokens": ["Uns", "ih\u00b7re", "Zun\u00b7ge", "gr\u00fcnd\u00b7lich", "aus\u00b7zu\u00b7sch\u00fct\u00b7teln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Erst, Freundchen, ziehe mich aus der Gefahr \u2013", "tokens": ["Erst", ",", "Freund\u00b7chen", ",", "zie\u00b7he", "mich", "aus", "der", "Ge\u00b7fahr", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "PRF", "APPR", "ART", "NN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und, bitte, sp\u00e4ter dann den Kommentar!", "tokens": ["Und", ",", "bit\u00b7te", ",", "sp\u00e4\u00b7ter", "dann", "den", "Kom\u00b7men\u00b7tar", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PTKANT", "$,", "ADJD", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}