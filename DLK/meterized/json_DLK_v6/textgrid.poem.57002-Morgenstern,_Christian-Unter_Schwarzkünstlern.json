{"textgrid.poem.57002": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Unter Schwarzk\u00fcnstlern", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eines Mittags las man:", "tokens": ["Ei\u00b7nes", "Mit\u00b7tags", "las", "man", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "\u00bbpfiffe zu mieten gesucht!", "tokens": ["\u00bb", "pfif\u00b7fe", "zu", "mie\u00b7ten", "ge\u00b7sucht", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "ADJA", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Hundertweis, zu jedem Preis!", "tokens": ["Hun\u00b7dert\u00b7weis", ",", "zu", "je\u00b7dem", "Preis", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Victor Emanuel Wasmann!\u00ab", "tokens": ["Vic\u00b7tor", "E\u00b7ma\u00b7nu\u00b7el", "Was\u00b7mann", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Um sechs Uhr kam der erste Pfiff", "tokens": ["Um", "sechs", "Uhr", "kam", "der", "ers\u00b7te", "Pfiff"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "von einem alten Kohlenschiff.", "tokens": ["von", "ei\u00b7nem", "al\u00b7ten", "Koh\u00b7len\u00b7schiff", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um acht Uhr waren's tausend schon.", "tokens": ["Um", "acht", "Uhr", "wa\u00b7ren's", "tau\u00b7send", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "CARD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um neun Uhr eine halbe Million.", "tokens": ["Um", "neun", "Uhr", "ei\u00b7ne", "hal\u00b7be", "Mil\u00b7li\u00b7on", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Victor Emanuel Wasmann schlug", "tokens": ["Vic\u00b7tor", "E\u00b7ma\u00b7nu\u00b7el", "Was\u00b7mann", "schlug"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "NE", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "die T\u00fcre zu: \u00bbNun ist's genug!", "tokens": ["die", "T\u00fc\u00b7re", "zu", ":", "\u00bb", "Nun", "ist's", "ge\u00b7nug", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "$(", "ADV", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00f6rt zu, ihr Pfiffe!", "tokens": ["H\u00f6rt", "zu", ",", "ihr", "Pfif\u00b7fe", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PPOSAT", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Ich habe einen Feind (h\u00f6rt! h\u00f6rt!),", "tokens": ["Ich", "ha\u00b7be", "ei\u00b7nen", "Feind", "(", "h\u00f6rt", "!", "h\u00f6rt", "!", ")", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "VVFIN", "$.", "VVFIN", "$.", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der mir des nachts die Ruhe st\u00f6rt \u2013", "tokens": ["der", "mir", "des", "nachts", "die", "Ru\u00b7he", "st\u00f6rt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "auf den sollt ihr marschieren!", "tokens": ["auf", "den", "sollt", "ihr", "mar\u00b7schie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "Er hat Gel\u00e4chter angestellt,", "tokens": ["Er", "hat", "Ge\u00b7l\u00e4ch\u00b7ter", "an\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die schickt er nachts mir an mein Bett,", "tokens": ["die", "schickt", "er", "nachts", "mir", "an", "mein", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "APPR", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da hocken sie auf der Decke,", "tokens": ["da", "ho\u00b7cken", "sie", "auf", "der", "De\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "mit Fl\u00fcgeln wei\u00df und Fl\u00fcgeln rot,", "tokens": ["mit", "Fl\u00fc\u00b7geln", "wei\u00df", "und", "Fl\u00fc\u00b7geln", "rot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und kr\u00e4hn und flattern mich zu Tod. \u2013", "tokens": ["und", "kr\u00e4hn", "und", "flat\u00b7tern", "mich", "zu", "Tod", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVINF", "KON", "VVFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch alles hat sein Ende.\u00ab", "tokens": ["Doch", "al\u00b7les", "hat", "sein", "En\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die Pfiffe pfiffen wie ", "tokens": ["Die", "Pfif\u00b7fe", "pfif\u00b7fen", "wie"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOKOM"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "empfingen ihren Sold sodann.", "tokens": ["emp\u00b7fin\u00b7gen", "ih\u00b7ren", "Sold", "so\u00b7dann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "(ein Schusterjungenpfiff sogar", "tokens": ["(", "ein", "Schus\u00b7ter\u00b7jun\u00b7gen\u00b7pfiff", "so\u00b7gar"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bot Wasmann sich als Bravo dar.)", "tokens": ["bot", "Was\u00b7mann", "sich", "als", "Bra\u00b7vo", "dar", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NN", "PRF", "KOUS", "NE", "PTKVZ", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Drauf lie\u00df er sie durchs Ofenloch ...", "tokens": ["Drauf", "lie\u00df", "er", "sie", "durchs", "O\u00b7fen\u00b7loch", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch lange stand er br\u00fctend noch,", "tokens": ["Doch", "lan\u00b7ge", "stand", "er", "br\u00fc\u00b7tend", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "schrieb Zeichen, hob die Hand und schwur,", "tokens": ["schrieb", "Zei\u00b7chen", ",", "hob", "die", "Hand", "und", "schwur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "VVFIN", "ART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein schwarzer Meister der Natur ...", "tokens": ["ein", "schwar\u00b7zer", "Meis\u00b7ter", "der", "Na\u00b7tur", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Bald nach diesem ging", "tokens": ["Bald", "nach", "die\u00b7sem", "ging"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PDAT", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "ein Herr Axel Ring", "tokens": ["ein", "Herr", "A\u00b7xel", "Ring"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "kurzerhand", "tokens": ["kur\u00b7zer\u00b7hand"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "au\u00dfer Land. \u2013", "tokens": ["au\u00b7\u00dfer", "Land", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Wasmann hatte gesiegt.", "tokens": ["Was\u00b7mann", "hat\u00b7te", "ge\u00b7siegt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "VVPP", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}}}}