{"textgrid.poem.44462": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "9. Trennung", "genre": "verse", "period": "N.A.", "pub_year": 1831, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So la\u00df uns scheiden denn, tuts not zu scheiden,", "tokens": ["So", "la\u00df", "uns", "schei\u00b7den", "denn", ",", "tuts", "not", "zu", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "ADV", "$,", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Allein als Freunde, ohne Groll und Ha\u00df.", "tokens": ["Al\u00b7lein", "als", "Freun\u00b7de", ",", "oh\u00b7ne", "Groll", "und", "Ha\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "$,", "KOUI", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein unerkl\u00e4rtes Etwas zwischen beiden", "tokens": ["Ein", "un\u00b7er\u00b7kl\u00e4r\u00b7tes", "Et\u00b7was", "zwi\u00b7schen", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "St\u00f6rt den Ergu\u00df und hemmt ohn Unterla\u00df.", "tokens": ["St\u00f6rt", "den", "Er\u00b7gu\u00df", "und", "hemmt", "ohn", "Un\u00b7ter\u00b7la\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Ob ich dies Etwas, ewig st\u00f6rend, kenne?", "tokens": ["Ob", "ich", "dies", "Et\u00b7was", ",", "e\u00b7wig", "st\u00f6\u00b7rend", ",", "ken\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "ADV", "$,", "ADJD", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "O gebe Gott, da\u00df ich es nicht erkannt!", "tokens": ["O", "ge\u00b7be", "Gott", ",", "da\u00df", "ich", "es", "nicht", "er\u00b7kannt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$,", "KOUS", "PPER", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Denn ist es, was ich denk, obgleich nicht nenne,", "tokens": ["Denn", "ist", "es", ",", "was", "ich", "denk", ",", "ob\u00b7gleich", "nicht", "nen\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,", "KOUS", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So bist du, Weib, in einer furchtbarn Hand.", "tokens": ["So", "bist", "du", ",", "Weib", ",", "in", "ei\u00b7ner", "furcht\u00b7barn", "Hand", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "In einer Hand, die einmal schon die Klauen", "tokens": ["In", "ei\u00b7ner", "Hand", ",", "die", "ein\u00b7mal", "schon", "die", "Klau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nach deiner Jugend Bl\u00fcten ausgestreckt,", "tokens": ["Nach", "dei\u00b7ner", "Ju\u00b7gend", "Bl\u00fc\u00b7ten", "aus\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und die, zum zweitenmal genaht in Grauen,", "tokens": ["Und", "die", ",", "zum", "zwei\u00b7ten\u00b7mal", "ge\u00b7naht", "in", "Grau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "APPRART", "ADV", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihr Opfer h\u00e4lt, bis es die Erde deckt.", "tokens": ["Ihr", "Op\u00b7fer", "h\u00e4lt", ",", "bis", "es", "die", "Er\u00b7de", "deckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Doch ob es ist? Ich wei\u00df nicht, mags nicht wissen!", "tokens": ["Doch", "ob", "es", "ist", "?", "Ich", "wei\u00df", "nicht", ",", "mags", "nicht", "wis\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "$.", "PPER", "VVFIN", "PTKNEG", "$,", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und so, beim Scheiden, das, wie schwer! verletzt,", "tokens": ["Und", "so", ",", "beim", "Schei\u00b7den", ",", "das", ",", "wie", "schwer", "!", "ver\u00b7letzt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "$,", "APPRART", "NN", "$,", "PDS", "$,", "PWAV", "ADJD", "$.", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nimm das Gest\u00e4ndnis, mir zuletzt entrissen:", "tokens": ["Nimm", "das", "Ge\u00b7st\u00e4nd\u00b7nis", ",", "mir", "zu\u00b7letzt", "ent\u00b7ris\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "PPER", "ADV", "VVPP", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Nie kannt ich dich, noch kenn ich selbst dich jetzt.", "tokens": ["Nie", "kannt", "ich", "dich", ",", "noch", "kenn", "ich", "selbst", "dich", "jetzt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "ADV", "VVFIN", "PPER", "ADV", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ein R\u00e4tsel warst du mir, wie man beim Spiele,", "tokens": ["Ein", "R\u00e4t\u00b7sel", "warst", "du", "mir", ",", "wie", "man", "beim", "Spie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPER", "$,", "PWAV", "PIS", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den Nachbar neckend, wohl zusammenflicht,", "tokens": ["Den", "Nach\u00b7bar", "ne\u00b7ckend", ",", "wohl", "zu\u00b7sam\u00b7men\u00b7flicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Jetzt los und leicht, leichtfertig selbst, wie viele,", "tokens": ["Jetzt", "los", "und", "leicht", ",", "leicht\u00b7fer\u00b7tig", "selbst", ",", "wie", "vie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "ADJD", "$,", "ADJD", "ADV", "$,", "PWAV", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Drauf wieder ernst und streng, wie viele nicht.", "tokens": ["Drauf", "wie\u00b7der", "ernst", "und", "streng", ",", "wie", "vie\u00b7le", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADJD", "KON", "VVFIN", "$,", "PWAV", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Bald sah ich Hohn durch deine Z\u00fcge schweifen,", "tokens": ["Bald", "sah", "ich", "Hohn", "durch", "dei\u00b7ne", "Z\u00fc\u00b7ge", "schwei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Drauf sie verkl\u00e4rt von warmer Tr\u00e4nen Hauch,", "tokens": ["Drauf", "sie", "ver\u00b7kl\u00e4rt", "von", "war\u00b7mer", "Tr\u00e4\u00b7nen", "Hauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVPP", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nun m\u00fchsam dich das Leichtste nicht begreifen,", "tokens": ["Nun", "m\u00fch\u00b7sam", "dich", "das", "Leichts\u00b7te", "nicht", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dann selbst das Tiefste wieder fassen auch.", "tokens": ["Dann", "selbst", "das", "Tiefs\u00b7te", "wie\u00b7der", "fas\u00b7sen", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Was offen mir auch stand, dein innres Wesen,", "tokens": ["Was", "of\u00b7fen", "mir", "auch", "stand", ",", "dein", "inn\u00b7res", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es blieb verschlossen mir bis diesen Tag,", "tokens": ["Es", "blieb", "ver\u00b7schlos\u00b7sen", "mir", "bis", "die\u00b7sen", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und so geb ich, ein R\u00e4tsel, noch zu l\u00f6sen,", "tokens": ["Und", "so", "geb", "ich", ",", "ein", "R\u00e4t\u00b7sel", ",", "noch", "zu", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "ART", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Dem Weisern dich, ders l\u00f6sen darf und mag.", "tokens": ["Dem", "Wei\u00b7sern", "dich", ",", "ders", "l\u00f6\u00b7sen", "darf", "und", "mag."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "NN", "PPER", "$,", "ADV", "VVINF", "VMFIN", "KON", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "War mirs verg\u00f6nnt, in ungest\u00f6rter F\u00fclle", "tokens": ["War", "mirs", "ver\u00b7g\u00f6nnt", ",", "in", "un\u00b7ge\u00b7st\u00f6r\u00b7ter", "F\u00fcl\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NE", "VVPP", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dir nah zu sein, vielleicht tat es sich auf,", "tokens": ["Dir", "nah", "zu", "sein", ",", "viel\u00b7leicht", "tat", "es", "sich", "auf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VAINF", "$,", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch wars, ob unser, nicht des Schicksals Wille,", "tokens": ["Doch", "wars", ",", "ob", "un\u00b7ser", ",", "nicht", "des", "Schick\u00b7sals", "Wil\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "KOUS", "PPOSAT", "$,", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So habe denn, was not tut, seinen Lauf.", "tokens": ["So", "ha\u00b7be", "denn", ",", "was", "not", "tut", ",", "sei\u00b7nen", "Lauf", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "PWS", "NN", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Du bist nun frei und doch nicht ungebunden,", "tokens": ["Du", "bist", "nun", "frei", "und", "doch", "nicht", "un\u00b7ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn eines ist, was nimmer dich entl\u00e4\u00dft:", "tokens": ["Denn", "ei\u00b7nes", "ist", ",", "was", "nim\u00b7mer", "dich", "ent\u00b7l\u00e4\u00dft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "$,", "PRELS", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erinnerung der letztverflo\u00dfnen Stunden,", "tokens": ["E\u00b7rin\u00b7ne\u00b7rung", "der", "letzt\u00b7ver\u00b7flo\u00df\u00b7nen", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und halt sie immer nur im Herzen fest!", "tokens": ["Und", "halt", "sie", "im\u00b7mer", "nur", "im", "Her\u00b7zen", "fest", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Denn wie du jetzt bem\u00fchst dich, halb vergebens,", "tokens": ["Denn", "wie", "du", "jetzt", "be\u00b7m\u00fchst", "dich", ",", "halb", "ver\u00b7ge\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVFIN", "PPER", "$,", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu malen dir dies Band als schwere Last,", "tokens": ["Zu", "ma\u00b7len", "dir", "dies", "Band", "als", "schwe\u00b7re", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "PDS", "NN", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es bleibt denn doch die Krone deines Lebens,", "tokens": ["Es", "bleibt", "denn", "doch", "die", "Kro\u00b7ne", "dei\u00b7nes", "Le\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fcr alle Zeit das beste, was du hast.", "tokens": ["F\u00fcr", "al\u00b7le", "Zeit", "das", "bes\u00b7te", ",", "was", "du", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "ADJA", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Du wirst dein Herz zu dem, zu jenem neigen,", "tokens": ["Du", "wirst", "dein", "Herz", "zu", "dem", ",", "zu", "je\u00b7nem", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "ART", "$,", "APPR", "PDAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch wie er f\u00fchlt und was er sich vermi\u00dft,", "tokens": ["Doch", "wie", "er", "f\u00fchlt", "und", "was", "er", "sich", "ver\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "KON", "PWS", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wird er dir doch zuletzt den Abstand zeigen,", "tokens": ["Wird", "er", "dir", "doch", "zu\u00b7letzt", "den", "Ab\u00b7stand", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der zwischen ihm und mir befestigt ist.", "tokens": ["Der", "zwi\u00b7schen", "ihm", "und", "mir", "be\u00b7fes\u00b7tigt", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "KON", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Und immer wirds dich wieder \u00fcbereilen,", "tokens": ["Und", "im\u00b7mer", "wirds", "dich", "wie\u00b7der", "\u00fc\u00b7be\u00b7rei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sooft Zerstreuung der Besinnung weicht,", "tokens": ["Sooft", "Zer\u00b7streu\u00b7ung", "der", "Be\u00b7sin\u00b7nung", "weicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Wenn man mich nennt, bei jeder meiner Zeilen,", "tokens": ["Wenn", "man", "mich", "nennt", ",", "bei", "je\u00b7der", "mei\u00b7ner", "Zei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$,", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denkst du: er wars! Verlor ich ihn so leicht?", "tokens": ["Denkst", "du", ":", "er", "wars", "!", "Ver\u00b7lor", "ich", "ihn", "so", "leicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "$.", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Und sollt es einst dir ganz vergessen scheinen,", "tokens": ["Und", "sollt", "es", "einst", "dir", "ganz", "ver\u00b7ges\u00b7sen", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "PPER", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dann ists das Zeichen einer furchtbarn Zeit:", "tokens": ["Dann", "ists", "das", "Zei\u00b7chen", "ei\u00b7ner", "furcht\u00b7barn", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du bist umstellt vom Niedern und Gemeinen,", "tokens": ["Du", "bist", "um\u00b7stellt", "vom", "Nie\u00b7dern", "und", "Ge\u00b7mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dann hat es dich, dann bist du ihm geweiht.", "tokens": ["Dann", "hat", "es", "dich", ",", "dann", "bist", "du", "ihm", "ge\u00b7weiht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "$,", "ADV", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und selber dann noch, suchend, sp\u00e4t im Schranke,", "tokens": ["Und", "sel\u00b7ber", "dann", "noch", ",", "su\u00b7chend", ",", "sp\u00e4t", "im", "Schran\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "$,", "VVPP", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Halb achtlos, m\u00fc\u00dfig, f\u00e4ndest du dies Blatt,", "tokens": ["Halb", "acht\u00b7los", ",", "m\u00fc\u00b7\u00dfig", ",", "f\u00e4n\u00b7dest", "du", "dies", "Blatt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "ADJD", "$,", "VVFIN", "PPER", "PDS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und pl\u00f6tzlich st\u00fcnd er vor dir, der Gedanke", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "st\u00fcnd", "er", "vor", "dir", ",", "der", "Ge\u00b7dan\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "PPER", "$,", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "An das, was war und ist an seiner Statt.", "tokens": ["An", "das", ",", "was", "war", "und", "ist", "an", "sei\u00b7ner", "Statt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "$,", "PWS", "VAFIN", "KON", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Weit ob dem Zwischenraum der dunkeln Jahre", "tokens": ["Weit", "ob", "dem", "Zwi\u00b7schen\u00b7raum", "der", "dun\u00b7keln", "Jah\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Tr\u00fcg es dich hin ins fr\u00fchre Blumenreich,", "tokens": ["Tr\u00fcg", "es", "dich", "hin", "ins", "fr\u00fch\u00b7re", "Blu\u00b7men\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Die Hand gedr\u00fcckt in deine sch\u00f6nen Haare,", "tokens": ["Die", "Hand", "ge\u00b7dr\u00fcckt", "in", "dei\u00b7ne", "sch\u00f6\u00b7nen", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "St\u00fcndst du, ein Marmorbild, erstarrend, bleich.", "tokens": ["St\u00fcndst", "du", ",", "ein", "Mar\u00b7mor\u00b7bild", ",", "er\u00b7star\u00b7rend", ",", "bleich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "$,", "VVPP", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Und wie aus Wolken, lauten St\u00fcrmen weichend,", "tokens": ["Und", "wie", "aus", "Wol\u00b7ken", ",", "lau\u00b7ten", "St\u00fcr\u00b7men", "wei\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "NN", "$,", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Mond hervortritt in verkl\u00e4rter Pracht,", "tokens": ["Der", "Mond", "her\u00b7vor\u00b7tritt", "in", "ver\u00b7kl\u00e4r\u00b7ter", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So k\u00e4me bla\u00df dein Bild, nun nicht mehr gleichend,", "tokens": ["So", "k\u00e4\u00b7me", "bla\u00df", "dein", "Bild", ",", "nun", "nicht", "mehr", "glei\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PPOSAT", "NN", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Entgegen dir aus des Vergangnen Nacht.", "tokens": ["Ent\u00b7ge\u00b7gen", "dir", "aus", "des", "Ver\u00b7gang\u00b7nen", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Der stille Reiz der unschuldsvollen Z\u00fcge,", "tokens": ["Der", "stil\u00b7le", "Reiz", "der", "un\u00b7schulds\u00b7vol\u00b7len", "Z\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die klare Stirn, von keiner Schuld gedr\u00fcckt,", "tokens": ["Die", "kla\u00b7re", "Stirn", ",", "von", "kei\u00b7ner", "Schuld", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Mund, noch wahr bei halb bewu\u00dfter L\u00fcge,", "tokens": ["Der", "Mund", ",", "noch", "wahr", "bei", "halb", "be\u00b7wu\u00df\u00b7ter", "L\u00fc\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Aug ein Adler, der zur Sonne blickt,", "tokens": ["Das", "Aug", "ein", "Ad\u00b7ler", ",", "der", "zur", "Son\u00b7ne", "blickt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Und weinend \u2013 doch wozu uns jetzt erweichen?", "tokens": ["Und", "wei\u00b7nend", "\u2013", "doch", "wo\u00b7zu", "uns", "jetzt", "er\u00b7wei\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$(", "KON", "PWAV", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Augenblick scheint viel, die Zukunft hohl.", "tokens": ["Der", "Au\u00b7gen\u00b7blick", "scheint", "viel", ",", "die", "Zu\u00b7kunft", "hohl", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "La\u00df uns die Hand zum letzten Abschied reichen,", "tokens": ["La\u00df", "uns", "die", "Hand", "zum", "letz\u00b7ten", "Ab\u00b7schied", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und so, f\u00fcr alle Zukunft, lebe wohl.", "tokens": ["Und", "so", ",", "f\u00fcr", "al\u00b7le", "Zu\u00b7kunft", ",", "le\u00b7be", "wohl", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "APPR", "PIAT", "NN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}