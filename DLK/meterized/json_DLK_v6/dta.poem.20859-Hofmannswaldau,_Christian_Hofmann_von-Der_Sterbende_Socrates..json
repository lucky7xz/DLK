{"dta.poem.20859": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der  \n Sterbende  \n  Socrates.", "genre": "Lyrik; Prosa; Drama", "period": "N.A.", "pub_year": "1679", "urn": "urn:nbn:de:kobv:b4-20289-1", "language": ["de:0.99"], "booktitle": "Hofmann von Hofmannswaldau, Christian: Deutsche Ubersetzungen und Gedichte. Breslau, 1679."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr dencket/ da\u00df ein kleiner Wind", "tokens": ["Ihr", "den\u00b7cket", "/", "da\u00df", "ein", "klei\u00b7ner", "Wind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich nahe bey den Lippen find/", "tokens": ["Sich", "na\u00b7he", "bey", "den", "Lip\u00b7pen", "find", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und diese Flamme mit sich treibet/", "tokens": ["Und", "die\u00b7se", "Flam\u00b7me", "mit", "sich", "trei\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So gantz erschrocken zeucht heraus/", "tokens": ["So", "gantz", "er\u00b7schro\u00b7cken", "zeucht", "he\u00b7raus", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja da\u00df die Seele todt verbleibet/", "tokens": ["Ja", "da\u00df", "die", "See\u00b7le", "todt", "ver\u00b7blei\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nichts anders als der Seelen Hau\u00df.", "tokens": ["Nichts", "an\u00b7ders", "als", "der", "See\u00b7len", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "KOKOM", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie auch/ wann sich herzu gefunden/", "tokens": ["Wie", "auch", "/", "wann", "sich", "her\u00b7zu", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$(", "PWAV", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Strich der s\u00fcssen Westen Lufft/", "tokens": ["Ein", "Strich", "der", "s\u00fcs\u00b7sen", "Wes\u00b7ten", "Lufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So unsern letzten Athen rufft/", "tokens": ["So", "un\u00b7sern", "letz\u00b7ten", "A\u00b7then", "rufft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NE", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So sey die Seele leicht entbunden/", "tokens": ["So", "sey", "die", "See\u00b7le", "leicht", "ent\u00b7bun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und da\u00df des kleinen Feuers Schein/", "tokens": ["Und", "da\u00df", "des", "klei\u00b7nen", "Feu\u00b7ers", "Schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Nicht balde k\u00f6nt erstecket seyn.", "tokens": ["Nicht", "bal\u00b7de", "k\u00f6nt", "er\u00b7ste\u00b7cket", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So aber sich der Zufall f\u00fcget/", "tokens": ["So", "a\u00b7ber", "sich", "der", "Zu\u00b7fall", "f\u00fc\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Da\u00df dieser Geist den Sand erreicht/", "tokens": ["Da\u00df", "die\u00b7ser", "Geist", "den", "Sand", "er\u00b7reicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der um das H\u00f6llenfuer lieget/", "tokens": ["Der", "um", "das", "H\u00f6l\u00b7len\u00b7fu\u00b7er", "lie\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und ihm der Nord entgegen streicht/", "tokens": ["Und", "ihm", "der", "Nord", "ent\u00b7ge\u00b7gen", "streicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "PTKVZ", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "So wird er hin und her getrieben/", "tokens": ["So", "wird", "er", "hin", "und", "her", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKVZ", "KON", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Und findet gantz kein festes Land/", "tokens": ["Und", "fin\u00b7det", "gantz", "kein", "fes\u00b7tes", "Land", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Wird so veracht/ und mu\u00df verstieben/", "tokens": ["Wird", "so", "ver\u00b7acht", "/", "und", "mu\u00df", "ver\u00b7stie\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVFIN", "$(", "KON", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Wird d\u00fcnner Rauch und leichter Sand.", "tokens": ["Wird", "d\u00fcn\u00b7ner", "Rauch", "und", "leich\u00b7ter", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}