{"textgrid.poem.33329": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "An die deutschen M\u00e4dchen", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Deutsche M\u00e4dchen h\u00f6ret mich!", "tokens": ["Deut\u00b7sche", "M\u00e4d\u00b7chen", "h\u00f6\u00b7ret", "mich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eu'rer M\u00fctter Art will ich", "tokens": ["Eu'\u00b7rer", "M\u00fct\u00b7ter", "Art", "will", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "VMFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlecht und recht im Sang euch lehren,", "tokens": ["Schlecht", "und", "recht", "im", "Sang", "euch", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPRART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wunderdinge sollt ihr h\u00f6ren:", "tokens": ["Wun\u00b7der\u00b7din\u00b7ge", "sollt", "ihr", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00e4dchensitte, alt und neu,", "tokens": ["M\u00e4d\u00b7chen\u00b7sit\u00b7te", ",", "alt", "und", "neu", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Will ich singen, frank und frei. \u2013", "tokens": ["Will", "ich", "sin\u00b7gen", ",", "frank", "und", "frei", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "VVFIN", "KON", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Arbeitlieb' und flinke Hand", "tokens": ["Ar\u00b7beit\u00b7lieb'", "und", "flin\u00b7ke", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Geilte nie nach Stutzertand;", "tokens": ["Geil\u00b7te", "nie", "nach", "Stut\u00b7zer\u00b7tand", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stutzer m\u00fcssen M\u00e4dchen zollen,", "tokens": ["Stut\u00b7zer", "m\u00fcs\u00b7sen", "M\u00e4d\u00b7chen", "zol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die geb\u00fcfft sich br\u00fcsten wollen;", "tokens": ["Die", "ge\u00b7b\u00fcfft", "sich", "br\u00fcs\u00b7ten", "wol\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Arbeitlieb' und flinke Hand", "tokens": ["Ar\u00b7beit\u00b7lieb'", "und", "flin\u00b7ke", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zollt wohl mehr als Stutzertand.", "tokens": ["Zollt", "wohl", "mehr", "als", "Stut\u00b7zer\u00b7tand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "KOUS", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ba\u00df gedieh einst deutsches Blut", "tokens": ["Ba\u00df", "ge\u00b7dieh", "einst", "deut\u00b7sches", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ohne Schirm und Sonnenhut;", "tokens": ["Oh\u00b7ne", "Schirm", "und", "Son\u00b7nen\u00b7hut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor der Sonne Strahlen beben,", "tokens": ["Vor", "der", "Son\u00b7ne", "Strah\u00b7len", "be\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hei\u00dft ja nur f\u00fcr's Auge leben:", "tokens": ["Hei\u00dft", "ja", "nur", "f\u00fcr's", "Au\u00b7ge", "le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Reines, unverdorb'nes Blut", "tokens": ["Rei\u00b7nes", ",", "un\u00b7ver\u00b7dor\u00b7b'\u00b7nes", "Blut"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Gibt nicht Schirm und Sonnenhut.", "tokens": ["Gibt", "nicht", "Schirm", "und", "Son\u00b7nen\u00b7hut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und der Jungfername war,", "tokens": ["Und", "der", "Jung\u00b7fer\u00b7na\u00b7me", "war", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie die Jungfrau, sonst nicht rar:", "tokens": ["Wie", "die", "Jung\u00b7frau", ",", "sonst", "nicht", "rar", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns're lockern Junggesellen", "tokens": ["Un\u00b7s'\u00b7re", "lo\u00b7ckern", "Jung\u00b7ge\u00b7sel\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Machten Jungfern \u2013 zu Mamsellen,", "tokens": ["Mach\u00b7ten", "Jung\u00b7fern", "\u2013", "zu", "Mam\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und sie gaben Jungfernsinn", "tokens": ["Und", "sie", "ga\u00b7ben", "Jung\u00b7fern\u00b7sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fcr Mamsellentitel hin.", "tokens": ["F\u00fcr", "Mam\u00b7sel\u00b7len\u00b7ti\u00b7tel", "hin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Trautes Nicken, Gr\u00fc\u00df euch Gott:", "tokens": ["Trau\u00b7tes", "Ni\u00b7cken", ",", "Gr\u00fc\u00df", "euch", "Gott", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War der M\u00e4dchen Gru\u00dfgebot;", "tokens": ["War", "der", "M\u00e4d\u00b7chen", "Gru\u00df\u00b7ge\u00b7bot", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Statt den deutschen Herzensgr\u00fcssen,", "tokens": ["Statt", "den", "deut\u00b7schen", "Her\u00b7zens\u00b7gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gr\u00fc\u00dft man jetzo mit den F\u00fcssen,", "tokens": ["Gr\u00fc\u00dft", "man", "jet\u00b7zo", "mit", "den", "F\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Besser war einst M\u00e4dchengru\u00df", "tokens": ["Bes\u00b7ser", "war", "einst", "M\u00e4d\u00b7chen\u00b7gru\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit dem Mund, als mit dem Fu\u00df.", "tokens": ["Mit", "dem", "Mund", ",", "als", "mit", "dem", "Fu\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Was man liebte, hie\u00df im Nu", "tokens": ["Was", "man", "lieb\u00b7te", ",", "hie\u00df", "im", "Nu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PIS", "VVFIN", "$,", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach der deutschen Weise du;", "tokens": ["Nach", "der", "deut\u00b7schen", "Wei\u00b7se", "du", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gnadentitel, Excellenzen,", "tokens": ["Gna\u00b7den\u00b7ti\u00b7tel", ",", "Ex\u00b7cel\u00b7len\u00b7zen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Feile Zungenreverenzen", "tokens": ["Fei\u00b7le", "Zun\u00b7gen\u00b7re\u00b7ve\u00b7ren\u00b7zen"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wurden deutsches Sprachgebot:", "tokens": ["Wur\u00b7den", "deut\u00b7sches", "Sprach\u00b7ge\u00b7bot", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dutzen darf man jetzt \u2013 nur Gott.", "tokens": ["Dut\u00b7zen", "darf", "man", "jetzt", "\u2013", "nur", "Gott", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ADV", "$(", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Unschuld, holde Sch\u00fcchternheit", "tokens": ["Un\u00b7schuld", ",", "hol\u00b7de", "Sch\u00fcch\u00b7tern\u00b7heit"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADJD", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Galt sonst mehr als Artigkeit;", "tokens": ["Galt", "sonst", "mehr", "als", "Ar\u00b7tig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "KOUS", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jungen mit den Blicken t\u00f6dten,", "tokens": ["Jun\u00b7gen", "mit", "den", "Bli\u00b7cken", "t\u00f6d\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vor Zotten nicht err\u00f6then,", "tokens": ["Und", "vor", "Zot\u00b7ten", "nicht", "er\u00b7r\u00f6\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hei\u00dft jetzt artig; sch\u00fcchtern thun", "tokens": ["Hei\u00dft", "jetzt", "ar\u00b7tig", ";", "sch\u00fcch\u00b7tern", "thun"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "$.", "VVINF", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nennt man Bauerneinfalt nun.", "tokens": ["Nennt", "man", "Bau\u00b7er\u00b7nein\u00b7falt", "nun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Schamerr\u00f6then durft' allein", "tokens": ["Scha\u00b7mer\u00b7r\u00f6\u00b7then", "durft'", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["NN", "VMFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Deutscher M\u00e4dchen Liebreiz sein.", "tokens": ["Deut\u00b7scher", "M\u00e4d\u00b7chen", "Lieb\u00b7reiz", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NE", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dirnen, die mit Schande prangen,", "tokens": ["Dir\u00b7nen", ",", "die", "mit", "Schan\u00b7de", "pran\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Malen Scham sich auf die Wangen,", "tokens": ["Ma\u00b7len", "Scham", "sich", "auf", "die", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Malet, Dirnen, das Gesicht,", "tokens": ["Ma\u00b7let", ",", "Dir\u00b7nen", ",", "das", "Ge\u00b7sicht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sparet das Err\u00f6then nicht!", "tokens": ["Spa\u00b7ret", "das", "Er\u00b7r\u00f6\u00b7then", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.9": {"line.1": {"text": "Deutschem Herzen, deutschem Blut", "tokens": ["Deut\u00b7schem", "Her\u00b7zen", ",", "deut\u00b7schem", "Blut"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Waren deutsche M\u00e4dchen gut;", "tokens": ["Wa\u00b7ren", "deut\u00b7sche", "M\u00e4d\u00b7chen", "gut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwitterarten, Modelaffen,", "tokens": ["Zwit\u00b7ter\u00b7ar\u00b7ten", ",", "Mo\u00b7de\u00b7laf\u00b7fen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die nach allen Dirnen gaffen,", "tokens": ["Die", "nach", "al\u00b7len", "Dir\u00b7nen", "gaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Frech vom Auge, frech von Hand,", "tokens": ["Frech", "vom", "Au\u00b7ge", ",", "frech", "von", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sch\u00e4nden M\u00e4dchen und ihr Land.", "tokens": ["Sch\u00e4n\u00b7den", "M\u00e4d\u00b7chen", "und", "ihr", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Deutsche Liebe, warm und rein,", "tokens": ["Deut\u00b7sche", "Lie\u00b7be", ",", "warm", "und", "rein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nahm ein deutsches M\u00e4dchen ein;", "tokens": ["Nahm", "ein", "deut\u00b7sches", "M\u00e4d\u00b7chen", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Honigw\u00f6rtchen, H\u00e4ndelecken", "tokens": ["Ho\u00b7nig\u00b7w\u00f6rt\u00b7chen", ",", "H\u00e4n\u00b7de\u00b7le\u00b7cken"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind der Angel s\u00fcsser Gecken,", "tokens": ["Sind", "der", "An\u00b7gel", "s\u00fcs\u00b7ser", "Ge\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So ein s\u00fc\u00dfkandirter Wicht", "tokens": ["So", "ein", "s\u00fc\u00df\u00b7kan\u00b7dir\u00b7ter", "Wicht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Freit' ein deutsches M\u00e4dchen nicht.", "tokens": ["Freit'", "ein", "deut\u00b7sches", "M\u00e4d\u00b7chen", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Heilig war der Ritterschaft", "tokens": ["Hei\u00b7lig", "war", "der", "Rit\u00b7ter\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Deutscher M\u00e4dchen Jungfrauschaft;", "tokens": ["Deut\u00b7scher", "M\u00e4d\u00b7chen", "Jung\u00b7frausc\u00b7haft", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwache, geile Lotterb\u00fcbchen:", "tokens": ["Schwa\u00b7che", ",", "gei\u00b7le", "Lot\u00b7ter\u00b7b\u00fcb\u00b7chen", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Naschen nun bei jedem Liebchen:", "tokens": ["Na\u00b7schen", "nun", "bei", "je\u00b7dem", "Lieb\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lotterb\u00fcbchen, wei\u00df und roth,", "tokens": ["Lot\u00b7ter\u00b7b\u00fcb\u00b7chen", ",", "wei\u00df", "und", "roth", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind der M\u00e4dchenunschuld Tod.", "tokens": ["Sind", "der", "M\u00e4d\u00b7chen\u00b7un\u00b7schuld", "Tod", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Gutem Leumund, rein wie Gold,", "tokens": ["Gu\u00b7tem", "Leu\u00b7mund", ",", "rein", "wie", "Gold", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "KOKOM", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Waren deutsche M\u00e4dchen hold;", "tokens": ["Wa\u00b7ren", "deut\u00b7sche", "M\u00e4d\u00b7chen", "hold", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle Welt kennt jetzt die Schw\u00e4ger", "tokens": ["Al\u00b7le", "Welt", "kennt", "jetzt", "die", "Schw\u00e4\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Von des Liebchens H\u00f6rnertr\u00e4ger;", "tokens": ["Von", "des", "Lieb\u00b7chens", "H\u00f6r\u00b7ner\u00b7tr\u00e4\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "B\u00f6se Sage, Spott und Schmach", "tokens": ["B\u00f6\u00b7se", "Sa\u00b7ge", ",", "Spott", "und", "Schmach"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Folgt der Braut in's Ehbett nach.", "tokens": ["Folgt", "der", "Braut", "in's", "Eh\u00b7bett", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Vaterhaus und Vaterfeld", "tokens": ["Va\u00b7ter\u00b7haus", "und", "Va\u00b7ter\u00b7feld"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War der deutschen M\u00e4dchen Welt,", "tokens": ["War", "der", "deut\u00b7schen", "M\u00e4d\u00b7chen", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Assembleen, Promenaden,", "tokens": ["As\u00b7sem\u00b7bleen", ",", "Pro\u00b7me\u00b7na\u00b7den", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "St\u00e4ndchenlust und Serenaden,", "tokens": ["St\u00e4nd\u00b7chen\u00b7lust", "und", "Se\u00b7re\u00b7na\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Neuer Zeiten loser Tand,", "tokens": ["Neu\u00b7er", "Zei\u00b7ten", "lo\u00b7ser", "Tand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Fremd im deutschen Vaterland.", "tokens": ["Fremd", "im", "deut\u00b7schen", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Hausger\u00e4th und Wirthschaft war", "tokens": ["Haus\u00b7ge\u00b7r\u00e4\u00b7th", "und", "Wirth\u00b7schaft", "war"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VAFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "M\u00e4dchenarbeit Jahr f\u00fcr Jahr;", "tokens": ["M\u00e4d\u00b7chen\u00b7ar\u00b7beit", "Jahr", "f\u00fcr", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit der Mode Putzgeb\u00fchren", "tokens": ["Mit", "der", "Mo\u00b7de", "Putz\u00b7ge\u00b7b\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hausprofit und Zeit verlieren,", "tokens": ["Haus\u00b7pro\u00b7fit", "und", "Zeit", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "War Verbrechen \u2013 Wohlstand heut:", "tokens": ["War", "Ver\u00b7bre\u00b7chen", "\u2013", "Wohl\u00b7stand", "heut", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$(", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kehre wieder alte Zeit!", "tokens": ["Keh\u00b7re", "wie\u00b7der", "al\u00b7te", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Bibel und Gesangbuch las", "tokens": ["Bi\u00b7bel", "und", "Ge\u00b7sang\u00b7buch", "las"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jedes deutsche M\u00e4dchen ba\u00df;", "tokens": ["Je\u00b7des", "deut\u00b7sche", "M\u00e4d\u00b7chen", "ba\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sang- und Bibelbuch verdrangen", "tokens": ["Sang", "und", "Bi\u00b7bel\u00b7buch", "ver\u00b7dran\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["TRUNC", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fratzenb\u00fcchlein \u2013 Sittenschlangen!", "tokens": ["Frat\u00b7zen\u00b7b\u00fcch\u00b7lein", "\u2013", "Sit\u00b7ten\u00b7schlan\u00b7gen", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "S\u00fc\u00dfer Witz und Tugendspott", "tokens": ["S\u00fc\u00b7\u00dfer", "Witz", "und", "Tu\u00b7gends\u00b7pott"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kitzeln M\u00e4dchenunschuld todt.", "tokens": ["Kit\u00b7zeln", "M\u00e4d\u00b7chen\u00b7un\u00b7schuld", "todt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Armen Kindern gab in Noth", "tokens": ["Ar\u00b7men", "Kin\u00b7dern", "gab", "in", "Noth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jedes gute M\u00e4dchen Brod;", "tokens": ["Je\u00b7des", "gu\u00b7te", "M\u00e4d\u00b7chen", "Brod", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Daf\u00fcr m\u00e4sten ihre Petzchen", "tokens": ["Da\u00b7f\u00fcr", "m\u00e4s\u00b7ten", "ih\u00b7re", "Petz\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00e4dchen nun mit Zuckerpl\u00e4tzchen", "tokens": ["M\u00e4d\u00b7chen", "nun", "mit", "Zu\u00b7cker\u00b7pl\u00e4tz\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hunde fressen Zuckerbrod,", "tokens": ["Hun\u00b7de", "fres\u00b7sen", "Zu\u00b7cker\u00b7brod", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Arme Kinder leiden Noth.", "tokens": ["Ar\u00b7me", "Kin\u00b7der", "lei\u00b7den", "Noth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ritterlieder, keusch und rein,", "tokens": ["Rit\u00b7ter\u00b7lie\u00b7der", ",", "keusch", "und", "rein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schauerlich bei'm Mondenschein,", "tokens": ["Schau\u00b7er\u00b7lich", "bei'm", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flossen sanft aus M\u00e4dchenkehlen;", "tokens": ["Flos\u00b7sen", "sanft", "aus", "M\u00e4d\u00b7chen\u00b7keh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00e4nglich ward's den lieben Seelen,", "tokens": ["B\u00e4ng\u00b7lich", "ward's", "den", "lie\u00b7ben", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und manch' s\u00fcsser Seufzer drang", "tokens": ["Und", "man\u00b7ch'", "s\u00fcs\u00b7ser", "Seuf\u00b7zer", "drang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich herauf in ihren Sang.", "tokens": ["Sich", "her\u00b7auf", "in", "ih\u00b7ren", "Sang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Nun ist M\u00e4dchen Melodei", "tokens": ["Nun", "ist", "M\u00e4d\u00b7chen", "Me\u00b7lo\u00b7dei"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Papageienkunstgeschrei,", "tokens": ["Pa\u00b7pa\u00b7gei\u00b7en\u00b7kunst\u00b7ge\u00b7schrei", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn Kanariengurgeleien", "tokens": ["Wenn", "Ka\u00b7na\u00b7ri\u00b7en\u00b7gur\u00b7ge\u00b7lei\u00b7en"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie dem Werklein nachlalleien:", "tokens": ["Sie", "dem", "Wer\u00b7klein", "nach\u00b7lal\u00b7lei\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVIZU", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Lieblicher und s\u00fc\u00dfer klang", "tokens": ["Lieb\u00b7li\u00b7cher", "und", "s\u00fc\u00b7\u00dfer", "klang"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJD", "VVFIN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Freier M\u00e4dchen Waldgesang!", "tokens": ["Frei\u00b7er", "M\u00e4d\u00b7chen", "Wald\u00b7ge\u00b7sang", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Deutsche M\u00e4dchen, wie gef\u00e4llt", "tokens": ["Deut\u00b7sche", "M\u00e4d\u00b7chen", ",", "wie", "ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PWAV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Euch die alt' und neue Welt?", "tokens": ["Euch", "die", "alt'", "und", "neu\u00b7e", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "M\u00f6gt ihr noch die Nase r\u00fcmpfen,", "tokens": ["M\u00f6gt", "ihr", "noch", "die", "Na\u00b7se", "r\u00fcmp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und auf alte Sitte schimpfen.", "tokens": ["Und", "auf", "al\u00b7te", "Sit\u00b7te", "schimp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alt und neu, nun, was gef\u00e4llt?", "tokens": ["Alt", "und", "neu", ",", "nun", ",", "was", "ge\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,", "ADV", "$,", "PRELS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Doch ihr habt ja schon gew\u00e4hlt!", "tokens": ["Doch", "ihr", "habt", "ja", "schon", "ge\u00b7w\u00e4hlt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}