{"textgrid.poem.48365": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Robin Hood", "genre": "verse", "period": "N.A.", "pub_year": 1852, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Liebe Herrn, horcht auf und habt mal Geduld,", "tokens": ["Lie\u00b7be", "Herrn", ",", "horcht", "auf", "und", "habt", "mal", "Ge\u00b7duld", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PTKVZ", "KON", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Und lauf mir keiner davon \u2013", "tokens": ["Und", "lauf", "mir", "kei\u00b7ner", "da\u00b7von", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PIS", "PAV", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich will euch erz\u00e4hlen von Robin Hood,", "tokens": ["Ich", "will", "euch", "er\u00b7z\u00e4h\u00b7len", "von", "Ro\u00b7bin", "Hood", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "NE", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und vielleicht auch von Little John.", "tokens": ["Und", "viel\u00b7leicht", "auch", "von", "Litt\u00b7le", "John", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Zu Locksly, im lustigen Nottinghamshire,", "tokens": ["Zu", "Locks\u00b7ly", ",", "im", "lus\u00b7ti\u00b7gen", "Not\u00b7ting\u00b7hams\u00b7hi\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Beginn' ich mit meiner Geschicht',", "tokens": ["Be\u00b7ginn'", "ich", "mit", "mei\u00b7ner", "Ge\u00b7schicht'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Da bracht' Robins Mutter den Robin zur Welt,", "tokens": ["Da", "bracht'", "Ro\u00b7bins", "Mut\u00b7ter", "den", "Ro\u00b7bin", "zur", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NN", "ART", "NE", "APPRART", "NN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und das andre \u2013 das wei\u00df ich nicht.", "tokens": ["Und", "das", "and\u00b7re", "\u2013", "das", "wei\u00df", "ich", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "$(", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "Das aber wei\u00df ich und h\u00f6rt' es oft:", "tokens": ["Das", "a\u00b7ber", "wei\u00df", "ich", "und", "h\u00f6rt'", "es", "oft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sein Vater war F\u00f6rster allda,", "tokens": ["Sein", "Va\u00b7ter", "war", "F\u00f6rs\u00b7ter", "all\u00b7da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "PAV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er traf ins Schwarze, auf tausend Schritt,", "tokens": ["Er", "traf", "ins", "Schwar\u00b7ze", ",", "auf", "tau\u00b7send", "Schritt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "APPR", "CARD", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und das ist just nicht nah.", "tokens": ["Und", "das", "ist", "just", "nicht", "nah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Mit Adam Bell und Will Cloudesly", "tokens": ["Mit", "A\u00b7dam", "Bell", "und", "Will", "Clou\u00b7des\u00b7ly"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "NE", "KON", "NE", "NE"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Scho\u00df er oftmals um die Wett',", "tokens": ["Scho\u00df", "er", "oft\u00b7mals", "um", "die", "Wett'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die mu\u00dften ihm zahlen vierzig Mark", "tokens": ["Die", "mu\u00df\u00b7ten", "ihm", "zah\u00b7len", "vier\u00b7zig", "Mark"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "CARD", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In Gold und auf ein Brett.", "tokens": ["In", "Gold", "und", "auf", "ein", "Brett", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Robins Mutter, die war John Gamwels Kind,", "tokens": ["Ro\u00b7bins", "Mut\u00b7ter", ",", "die", "war", "John", "Gam\u00b7wels", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "VAFIN", "NE", "NE", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Der 'nen Wolf mit der Hand erw\u00fcrgt", "tokens": ["Der", "'nen", "Wolf", "mit", "der", "Hand", "er\u00b7w\u00fcrgt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "APPR", "ART", "NN", "VVPP"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "(zu Coventry der Ochsenwirt", "tokens": ["(", "zu", "Co\u00b7ven\u00b7try", "der", "Och\u00b7sen\u00b7wirt"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "APPR", "NE", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat mir's hundertmal verb\u00fcrgt).", "tokens": ["Hat", "mir's", "hun\u00b7dert\u00b7mal", "ver\u00b7b\u00fcrgt", ")", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "ADV", "VVPP", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und ihr Bruder hie\u00df Gamwel von Gamwel-Hall,", "tokens": ["Und", "ihr", "Bru\u00b7der", "hie\u00df", "Gam\u00b7wel", "von", "Gam\u00b7wel\u00b7Hall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und sein altes Herz war frisch-", "tokens": ["Und", "sein", "al\u00b7tes", "Herz", "war", "frisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "TRUNC"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das wei\u00dfeste Brot in Nottinghamshire,", "tokens": ["Das", "wei\u00b7\u00dfes\u00b7te", "Brot", "in", "Not\u00b7ting\u00b7hams\u00b7hi\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das kam auf seinen Tisch. \u2013", "tokens": ["Das", "kam", "auf", "sei\u00b7nen", "Tisch", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und sieh, Jung-Robin wuchs heran,", "tokens": ["Und", "sieh", ",", "Jung\u00b7Ro\u00b7bin", "wuchs", "he\u00b7ran", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Z\u00e4hlte zwanzig Jahre bald,", "tokens": ["Z\u00e4hl\u00b7te", "zwan\u00b7zig", "Jah\u00b7re", "bald", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Er hatte Vater und Mutter lieb,", "tokens": ["Er", "hat\u00b7te", "Va\u00b7ter", "und", "Mut\u00b7ter", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch noch lieber den Sherwood-Wald.", "tokens": ["Doch", "noch", "lie\u00b7ber", "den", "Sher\u00b7woo\u00b7dWald", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Robins Mutter aber zum Vater sprach:", "tokens": ["Ro\u00b7bins", "Mut\u00b7ter", "a\u00b7ber", "zum", "Va\u00b7ter", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "\u00bbmein Liebster, der du bist,", "tokens": ["\u00bb", "mein", "Liebs\u00b7ter", ",", "der", "du", "bist", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Gern ritt' ich heute gen Gamwel-Hall", "tokens": ["Gern", "ritt'", "ich", "heu\u00b7te", "gen", "Gam\u00b7wel\u00b7Hall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und feierte heiligen Christ;", "tokens": ["Und", "fei\u00b7er\u00b7te", "hei\u00b7li\u00b7gen", "Christ", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.9": {"line.1": {"text": "Ich hab' eine Lust, in Keller und K\u00fcch'", "tokens": ["Ich", "hab'", "ei\u00b7ne", "Lust", ",", "in", "Kel\u00b7ler", "und", "K\u00fc\u00b7ch'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So recht zur Hand zu gehn;", "tokens": ["So", "recht", "zur", "Hand", "zu", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auch hab' ich den lieben Bruder mein", "tokens": ["Auch", "hab'", "ich", "den", "lie\u00b7ben", "Bru\u00b7der", "mein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "PPOSAT"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Seit Pfingsten nicht gesehn.\u00ab", "tokens": ["Seit", "Pfings\u00b7ten", "nicht", "ge\u00b7sehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Vater Robin drauf: \u00bbLieb' Hanna, gewi\u00df,", "tokens": ["Va\u00b7ter", "Ro\u00b7bin", "drauf", ":", "\u00bb", "Lieb'", "Han\u00b7na", ",", "ge\u00b7wi\u00df", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "NE", "PTKVZ", "$.", "$(", "NN", "NE", "$,", "ADV", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Meinen Braunen geb' ich gern,", "tokens": ["Mei\u00b7nen", "Brau\u00b7nen", "geb'", "ich", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur nimm mir unsren Robin mit", "tokens": ["Nur", "nimm", "mir", "un\u00b7sren", "Ro\u00b7bin", "mit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zeig' ihn dem alten Herrn;", "tokens": ["Und", "zeig'", "ihn", "dem", "al\u00b7ten", "Herrn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Und gr\u00fc\u00df den Alten und k\u00fcsse dazu", "tokens": ["Und", "gr\u00fc\u00df", "den", "Al\u00b7ten", "und", "k\u00fcs\u00b7se", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "VVFIN", "PAV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Kinder gro\u00df und klein,", "tokens": ["Die", "Kin\u00b7der", "gro\u00df", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wenn ihr alle recht lustig seid,", "tokens": ["Und", "wenn", "ihr", "al\u00b7le", "recht", "lus\u00b7tig", "seid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Lieb' Hanna, so denke mein.\u00ab", "tokens": ["Lieb'", "Han\u00b7na", ",", "so", "den\u00b7ke", "mein", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NE", "$,", "ADV", "VVFIN", "PPOSAT", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Er sprach's. Alsbald der Braune kam,", "tokens": ["Er", "sprach'", "s.", "Als\u00b7bald", "der", "Brau\u00b7ne", "kam", ","], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVIMP", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gestriegelt und aufgestutzt!", "tokens": ["Ge\u00b7strie\u00b7gelt", "und", "auf\u00b7ge\u00b7stutzt", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nur Robins Mutter und Robin selbst,", "tokens": ["Nur", "Ro\u00b7bins", "Mut\u00b7ter", "und", "Ro\u00b7bin", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NE", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die waren noch mehr geputzt.", "tokens": ["Die", "wa\u00b7ren", "noch", "mehr", "ge\u00b7putzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Jung-Robin trug eine blaue Kapp'", "tokens": ["Jung\u00b7Ro\u00b7bin", "trug", "ei\u00b7ne", "blau\u00b7e", "Kapp'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und ein Schwert an seiner Seit',", "tokens": ["Und", "ein", "Schwert", "an", "sei\u00b7ner", "Seit'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Mutter gar, die bauschte daher", "tokens": ["Und", "die", "Mut\u00b7ter", "gar", ",", "die", "bauschte", "da\u00b7her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "$,", "PRELS", "VVFIN", "PAV"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Im Vierzigfaltenkleid.", "tokens": ["Im", "Vier\u00b7zig\u00b7fal\u00b7ten\u00b7kleid", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Es war ein selbstgesponnenes St\u00fcck,", "tokens": ["Es", "war", "ein", "selbst\u00b7ge\u00b7spon\u00b7ne\u00b7nes", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und sie wu\u00dfte sich was darin,", "tokens": ["Und", "sie", "wu\u00df\u00b7te", "sich", "was", "da\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "PWS", "PAV", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und sie sah beinah so stattlich aus", "tokens": ["Und", "sie", "sah", "bei\u00b7nah", "so", "statt\u00b7lich", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADV", "ADJD", "PTKVZ"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wie zu London die K\u00f6nigin.", "tokens": ["Wie", "zu", "Lon\u00b7don", "die", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Jung-Robin schwang in den Sattel sich,", "tokens": ["Jung\u00b7Ro\u00b7bin", "schwang", "in", "den", "Sat\u00b7tel", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "PRF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Seine Mutter kletterte nach,", "tokens": ["Sei\u00b7ne", "Mut\u00b7ter", "klet\u00b7ter\u00b7te", "nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sie sah den Braunen \u00e4ngstlich an,", "tokens": ["Sie", "sah", "den", "Brau\u00b7nen", "\u00e4ngst\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vater Robin aber sprach:", "tokens": ["Va\u00b7ter", "Ro\u00b7bin", "a\u00b7ber", "sprach", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bblieb' Hanna, la\u00df, ich kenne sein Kreuz,", "tokens": ["\u00bb", "lieb'", "Han\u00b7na", ",", "la\u00df", ",", "ich", "ken\u00b7ne", "sein", "Kreuz", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "$,", "VVIMP", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Zwei Reiter ist ihm Spiel,", "tokens": ["Zwei", "Rei\u00b7ter", "ist", "ihm", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er trug schon sieben Scheffel Korn,", "tokens": ["Er", "trug", "schon", "sie\u00b7ben", "Schef\u00b7fel", "Korn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "CARD", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und die wiegen doppelt so viel.\u00ab", "tokens": ["Und", "die", "wie\u00b7gen", "dop\u00b7pelt", "so", "viel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "VVFIN", "ADJD", "ADV", "ADV", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.17": {"line.1": {"text": "Er sprach's. Jung-Robin ritt im Schritt", "tokens": ["Er", "sprach'", "s.", "Jung\u00b7Ro\u00b7bin", "ritt", "im", "Schritt"], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "NE", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis dicht an das Stadttor hin \u2013", "tokens": ["Bis", "dicht", "an", "das", "Stadt\u00b7tor", "hin", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das H\u00e4ndesch\u00fctteln nahm kein End'", "tokens": ["Das", "H\u00e4n\u00b7de\u00b7sch\u00fct\u00b7teln", "nahm", "kein", "End'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Nachbar und Nachbarin.", "tokens": ["Von", "Nach\u00b7bar", "und", "Nach\u00b7ba\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.18": {"line.1": {"text": "Nun aber ging's auf den Braunen los", "tokens": ["Nun", "a\u00b7ber", "ging's", "auf", "den", "Brau\u00b7nen", "los"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zugleich mit Peitsch' und Sporn,", "tokens": ["Zu\u00b7gleich", "mit", "Peit\u00b7sch'", "und", "Sporn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und Robin rief: \u00bbHe, lauf einmal", "tokens": ["Und", "Ro\u00b7bin", "rief", ":", "\u00bb", "He", ",", "lauf", "ein\u00b7mal"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["KON", "NE", "VVFIN", "$.", "$(", "ITJ", "$,", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und verdiene dein Weihnachtskorn.\u00ab", "tokens": ["Und", "ver\u00b7die\u00b7ne", "dein", "Weih\u00b7nachts\u00b7korn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.19": {"line.1": {"text": "Sie kamen an. Das ganze Haus", "tokens": ["Sie", "ka\u00b7men", "an", ".", "Das", "gan\u00b7ze", "Haus"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geriet wie au\u00dfer sich,", "tokens": ["Ge\u00b7riet", "wie", "au\u00b7\u00dfer", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "APPR", "PRF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Alte rief in einem fort:", "tokens": ["Der", "Al\u00b7te", "rief", "in", "ei\u00b7nem", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bblieb' Schwester, wie freue ich mich!\u00ab", "tokens": ["\u00bb", "lieb'", "Schwes\u00b7ter", ",", "wie", "freu\u00b7e", "ich", "mich", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "NN", "$,", "PWAV", "VVFIN", "PPER", "PRF", "$.", "$("], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}}, "stanza.20": {"line.1": {"text": "Am andern Morgen ging's zur Mess',", "tokens": ["Am", "an\u00b7dern", "Mor\u00b7gen", "ging's", "zur", "Mess'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann aber ging's wieder nach Haus,", "tokens": ["Dann", "a\u00b7ber", "ging's", "wie\u00b7der", "nach", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sechs Tische standen da, wohlgedeckt,", "tokens": ["Sechs", "Ti\u00b7sche", "stan\u00b7den", "da", ",", "wohl\u00b7ge\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ADV", "$,", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Drauf dampfte der Weihnachtsschmaus.", "tokens": ["Drauf", "dampf\u00b7te", "der", "Weih\u00b7nachts\u00b7schmaus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Jede Tafel trug eine braune Gans,", "tokens": ["Je\u00b7de", "Ta\u00b7fel", "trug", "ei\u00b7ne", "brau\u00b7ne", "Gans", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Mit saftigen \u00c4pfeln gef\u00fcllt,", "tokens": ["Mit", "saf\u00b7ti\u00b7gen", "\u00c4p\u00b7feln", "ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Daneben Wildpret mit Schinken zumal,", "tokens": ["Da\u00b7ne\u00b7ben", "Wild\u00b7pret", "mit", "Schin\u00b7ken", "zu\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "NN", "ADV", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "In Eierteig geh\u00fcllt.", "tokens": ["In", "Ei\u00b7er\u00b7teig", "ge\u00b7h\u00fcllt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Sechs Lichter brannten; der Pfarrer vom Dorf", "tokens": ["Sechs", "Lich\u00b7ter", "brann\u00b7ten", ";", "der", "Pfar\u00b7rer", "vom", "Dorf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "$.", "ART", "NN", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sprach den Segen kurz und fromm-", "tokens": ["Sprach", "den", "Se\u00b7gen", "kurz", "und", "from\u00b7m"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ADJD", "KON", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann aber rief Squire Gamwel selbst:", "tokens": ["Dann", "a\u00b7ber", "rief", "Squi\u00b7re", "Gam\u00b7wel", "selbst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "NE", "NE", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u00bblieben G\u00e4ste, Gott willkomm!", "tokens": ["\u00bb", "lie\u00b7ben", "G\u00e4s\u00b7te", ",", "Gott", "will\u00b7komm", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Willkommen mir all in Gamwel-Hall,", "tokens": ["Will\u00b7kom\u00b7men", "mir", "all", "in", "Gam\u00b7wel\u00b7Hall", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und nun seht, was die K\u00fcche briet,", "tokens": ["Und", "nun", "seht", ",", "was", "die", "K\u00fc\u00b7che", "briet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wer aber mein M\u00e4rzbier trinken will,", "tokens": ["Wer", "a\u00b7ber", "mein", "M\u00e4rz\u00b7bier", "trin\u00b7ken", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der singe zuvor ein Lied.\u00ab", "tokens": ["Der", "sin\u00b7ge", "zu\u00b7vor", "ein", "Lied", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "Da sangen sie all (denn das Bier war gut)", "tokens": ["Da", "san\u00b7gen", "sie", "all", "(", "denn", "das", "Bier", "war", "gut", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "$(", "KON", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Aus voller Kehl' und Brust \u2013", "tokens": ["Aus", "vol\u00b7ler", "Kehl'", "und", "Brust", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Squire Gamwel schlug den Takt dazu", "tokens": ["Squi\u00b7re", "Gam\u00b7wel", "schlug", "den", "Takt", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "PAV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und weinte beinah vor Lust.", "tokens": ["Und", "wein\u00b7te", "bei\u00b7nah", "vor", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.25": {"line.1": {"text": "Er rief: \u00bbH\u00f6rt nur, wie drau\u00dfen der Wind", "tokens": ["Er", "rief", ":", "\u00bb", "H\u00f6rt", "nur", ",", "wie", "drau\u00b7\u00dfen", "der", "Wind"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "VVIMP", "ADV", "$,", "PWAV", "ADV", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Den Regen ans Fenster schl\u00e4gt,", "tokens": ["Den", "Re\u00b7gen", "ans", "Fens\u00b7ter", "schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das ist die Zeit, wo das Menschengem\u00fct", "tokens": ["Das", "ist", "die", "Zeit", ",", "wo", "das", "Men\u00b7schen\u00b7ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einen Humpen mehr vertr\u00e4gt.", "tokens": ["Ei\u00b7nen", "Hum\u00b7pen", "mehr", "ver\u00b7tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Lieb' Hanna, hol uns den Stachelbeerwein,", "tokens": ["Lieb'", "Han\u00b7na", ",", "hol", "uns", "den", "Sta\u00b7chel\u00b7beer\u00b7wein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Er z\u00e4hlt schon manchen Tag,", "tokens": ["Er", "z\u00e4hlt", "schon", "man\u00b7chen", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wirf mehr Holz noch in den Kamin,", "tokens": ["Und", "wirf", "mehr", "Holz", "noch", "in", "den", "Ka\u00b7min", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Da\u00df es lustiger knistern mag.\u00ab", "tokens": ["Da\u00df", "es", "lus\u00b7ti\u00b7ger", "knis\u00b7tern", "mag.", "\u00ab"], "token_info": ["word", "word", "word", "word", "abbreviation", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "NE", "$("], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.27": {"line.1": {"text": "Und sie brachte das Holz und sie brachte den Wein,", "tokens": ["Und", "sie", "brach\u00b7te", "das", "Holz", "und", "sie", "brach\u00b7te", "den", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Und sie tranken wacker davon,", "tokens": ["Und", "sie", "tran\u00b7ken", "wa\u00b7cker", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PAV", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und der Alte rief: \u00bbNun kommt das Best',", "tokens": ["Und", "der", "Al\u00b7te", "rief", ":", "\u00bb", "Nun", "kommt", "das", "Best'", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "$(", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Nun hol' ich den Little John;", "tokens": ["Nun", "hol'", "ich", "den", "Litt\u00b7le", "John", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.28": {"line.1": {"text": "Little John, das ist der flinkste Bursch", "tokens": ["Litt\u00b7le", "John", ",", "das", "ist", "der", "flinks\u00b7te", "Bursch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Zehn Meilen in der Rund':", "tokens": ["Zehn", "Mei\u00b7len", "in", "der", "Rund'", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kopfstehn, Radschlagen und Gliederverdrehn,", "tokens": ["Kopf\u00b7stehn", ",", "Rad\u00b7schla\u00b7gen", "und", "Glie\u00b7der\u00b7ver\u00b7drehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das versteht er aus dem Grund.\u00ab", "tokens": ["Das", "ver\u00b7steht", "er", "aus", "dem", "Grund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Little John trat ein; Jung-Robin rief:", "tokens": ["Litt\u00b7le", "John", "trat", "ein", ";", "Jung\u00b7Ro\u00b7bin", "rief", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PTKVZ", "$.", "NE", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbnun flinkester Bursch, komm her!", "tokens": ["\u00bb", "nun", "flin\u00b7kes\u00b7ter", "Bursch", ",", "komm", "her", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und springst du sieben Ellen weit,", "tokens": ["Und", "springst", "du", "sie\u00b7ben", "El\u00b7len", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So spring' ich noch eine mehr.\u00ab", "tokens": ["So", "spring'", "ich", "noch", "ei\u00b7ne", "mehr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADV", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.30": {"line.1": {"text": "Little John sprang sieben, Jung-Robin sprang acht,", "tokens": ["Litt\u00b7le", "John", "sprang", "sie\u00b7ben", ",", "Jung\u00b7Ro\u00b7bin", "sprang", "acht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "CARD", "$,", "NE", "VVFIN", "CARD", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Auf Zollbreit hielt er Wort,", "tokens": ["Auf", "Zoll\u00b7breit", "hielt", "er", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da rief der Alte: \u00bbSo wahr ich leb',", "tokens": ["Da", "rief", "der", "Al\u00b7te", ":", "\u00bb", "So", "wahr", "ich", "leb'", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich lasse dich nicht mehr fort.", "tokens": ["Ich", "las\u00b7se", "dich", "nicht", "mehr", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.31": {"line.1": {"text": "Sei mir ein Sohn: wir haben hier auch", "tokens": ["Sei", "mir", "ein", "Sohn", ":", "wir", "ha\u00b7ben", "hier", "auch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "$.", "PPER", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Fangmesser, Bogen und Pfeil,", "tokens": ["Fang\u00b7mes\u00b7ser", ",", "Bo\u00b7gen", "und", "Pfeil", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Und mach' ich mal die Augen zu,", "tokens": ["Und", "mach'", "ich", "mal", "die", "Au\u00b7gen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So erbst du Kindesteil.\u00ab", "tokens": ["So", "erbst", "du", "Kin\u00b7des\u00b7teil", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}