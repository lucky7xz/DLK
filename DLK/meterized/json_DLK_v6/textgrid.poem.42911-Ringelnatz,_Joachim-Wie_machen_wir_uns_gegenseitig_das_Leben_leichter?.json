{"textgrid.poem.42911": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Wie machen wir uns gegenseitig das Leben leichter?", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir haben zu gro\u00dfen Respekt vor dem,", "tokens": ["Wir", "ha\u00b7ben", "zu", "gro\u00b7\u00dfen", "Res\u00b7pekt", "vor", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "APPR", "ART", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Was menschlich \u00fcber uns himmelt.", "tokens": ["Was", "menschlich", "\u00fc\u00b7ber", "uns", "him\u00b7melt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wir sind zu feig oder sind zu bequem,", "tokens": ["Wir", "sind", "zu", "feig", "o\u00b7der", "sind", "zu", "be\u00b7quem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "KON", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zu schauen, was unter uns wimmelt.", "tokens": ["Zu", "schau\u00b7en", ",", "was", "un\u00b7ter", "uns", "wim\u00b7melt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Wir trauen zu wenig dem Nebenuns.", "tokens": ["Wir", "trau\u00b7en", "zu", "we\u00b7nig", "dem", "Ne\u00b7be\u00b7nuns", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wir tr\u00e4umen zu wenig im Wachen.", "tokens": ["Wir", "tr\u00e4u\u00b7men", "zu", "we\u00b7nig", "im", "Wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und k\u00f6nnten so leicht das Leben uns", "tokens": ["Und", "k\u00f6nn\u00b7ten", "so", "leicht", "das", "Le\u00b7ben", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "ART", "NN", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einander leichter machen.", "tokens": ["Ein\u00b7an\u00b7der", "leich\u00b7ter", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wir d\u00fcrften viel egoistischer sein", "tokens": ["Wir", "d\u00fcrf\u00b7ten", "viel", "e\u00b7gois\u00b7ti\u00b7scher", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "VAINF"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Aus tierisch frommem Gem\u00fcte. \u2013", "tokens": ["Aus", "tie\u00b7risch", "from\u00b7mem", "Ge\u00b7m\u00fc\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In dem pomp\u00f6sesten Leichenstein", "tokens": ["In", "dem", "pom\u00b7p\u00f6\u00b7ses\u00b7ten", "Lei\u00b7chen\u00b7stein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Liegt soviel dauernde G\u00fcte.", "tokens": ["Liegt", "so\u00b7viel", "dau\u00b7ern\u00b7de", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Ich habe nicht die geringste Lust,", "tokens": ["Ich", "ha\u00b7be", "nicht", "die", "ge\u00b7rings\u00b7te", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dies Thema weiter zu breiten.", "tokens": ["Dies", "The\u00b7ma", "wei\u00b7ter", "zu", "brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wir tragen alle in unsrer Brust", "tokens": ["Wir", "tra\u00b7gen", "al\u00b7le", "in", "uns\u00b7rer", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "L\u00f6sung und Schwierigkeiten.", "tokens": ["L\u00f6\u00b7sung", "und", "Schwie\u00b7rig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}