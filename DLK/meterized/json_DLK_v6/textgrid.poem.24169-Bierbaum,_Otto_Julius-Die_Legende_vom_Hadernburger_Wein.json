{"textgrid.poem.24169": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Die Legende vom Hadernburger Wein", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Christoph Patzeber ein Bauer war,", "tokens": ["Chris\u00b7toph", "Pat\u00b7ze\u00b7ber", "ein", "Bau\u00b7er", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Der hat getrunken wunderbar", "tokens": ["Der", "hat", "ge\u00b7trun\u00b7ken", "wun\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "VVPP", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von ururalten Weinen;", "tokens": ["Von", "u\u00b7rur\u00b7al\u00b7ten", "Wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die waren gelb wie Oel und klar,", "tokens": ["Die", "wa\u00b7ren", "gelb", "wie", "O\u00b7el", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "KOKOM", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Er hat getrunken \u00fcber ein Jahr,", "tokens": ["Er", "hat", "ge\u00b7trun\u00b7ken", "\u00fc\u00b7ber", "ein", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Mit ihm sein Weib und die Seinen.", "tokens": ["Mit", "ihm", "sein", "Weib", "und", "die", "Sei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPOSAT", "NN", "KON", "ART", "PPOSS", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "Er kam dazu, wu\u00dfte selbst nicht wie,", "tokens": ["Er", "kam", "da\u00b7zu", ",", "wu\u00df\u00b7te", "selbst", "nicht", "wie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "$,", "VVFIN", "ADV", "PTKNEG", "KOKOM", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und eure ganze Philosophie,", "tokens": ["Und", "eu\u00b7re", "gan\u00b7ze", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die wirds auch nicht erkl\u00e4ren.", "tokens": ["Die", "wirds", "auch", "nicht", "er\u00b7kl\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schaut nur und h\u00f6rt wies ihm geschah:", "tokens": ["Schaut", "nur", "und", "h\u00f6rt", "wies", "ihm", "ge\u00b7schah", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er ging halt hin, und der Wein war da;", "tokens": ["Er", "ging", "halt", "hin", ",", "und", "der", "Wein", "war", "da", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "PTKVZ", "$,", "KON", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So sind die alten M\u00e4ren.", "tokens": ["So", "sind", "die", "al\u00b7ten", "M\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Christoph Patzeber in einer Nacht", "tokens": ["Chris\u00b7toph", "Pat\u00b7ze\u00b7ber", "in", "ei\u00b7ner", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "ART", "NN"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Hat sich mal auf den Weg gemacht,", "tokens": ["Hat", "sich", "mal", "auf", "den", "Weg", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wollte nach W\u00e4lschmichel gehen.", "tokens": ["Woll\u00b7te", "nach", "W\u00e4lsc\u00b7hmi\u00b7chel", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da f\u00fchrte was ihn in die Quer,", "tokens": ["Da", "f\u00fchr\u00b7te", "was", "ihn", "in", "die", "Quer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PWS", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach W\u00e4lschmichel kam er nicht mehr,", "tokens": ["Nach", "W\u00e4lsc\u00b7hmi\u00b7chel", "kam", "er", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Denn er hat Wein gesehen.", "tokens": ["Denn", "er", "hat", "Wein", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wein! Achtzehn Fa\u00df mit Hahn und Krahn", "tokens": ["Wein", "!", "Acht\u00b7zehn", "Fa\u00df", "mit", "Hahn", "und", "Krahn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "CARD", "NN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sahn ihn wie achtzehn Augen an", "tokens": ["Sahn", "ihn", "wie", "acht\u00b7zehn", "Au\u00b7gen", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KOKOM", "CARD", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Recht freundlich und mit Winken.", "tokens": ["Recht", "freund\u00b7lich", "und", "mit", "Win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie lagen in einem Keller tief,", "tokens": ["Sie", "la\u00b7gen", "in", "ei\u00b7nem", "Kel\u00b7ler", "tief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "In den hell eine Treppe lief;", "tokens": ["In", "den", "hell", "ei\u00b7ne", "Trep\u00b7pe", "lief", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Patzeber, der th\u00e4t trinken.", "tokens": ["Pat\u00b7ze\u00b7ber", ",", "der", "th\u00e4t", "trin\u00b7ken", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.5": {"line.1": {"text": "Sakra! das schmeckt! Doch aus der Hand", "tokens": ["Sa\u00b7kra", "!", "das", "schmeckt", "!", "Doch", "aus", "der", "Hand"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "PDS", "VVFIN", "$.", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Wein zu trinken ist S\u00fcnd und Schand.", "tokens": ["Den", "Wein", "zu", "trin\u00b7ken", "ist", "S\u00fcnd", "und", "Schand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Was giebts da zu besinnen!", "tokens": ["Was", "giebts", "da", "zu", "be\u00b7sin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Christoph holt sich zwei Flaschen gro\u00df,", "tokens": ["Chris\u00b7toph", "holt", "sich", "zwei", "Fla\u00b7schen", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Steigt wiederum in das alte G'schlo\u00df", "tokens": ["Steigt", "wie\u00b7de\u00b7rum", "in", "das", "al\u00b7te", "G'\u00b7schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.6": {"text": "Und l\u00e4\u00dft voll Wein sie rinnen.", "tokens": ["Und", "l\u00e4\u00dft", "voll", "Wein", "sie", "rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Gem\u00e4chlich will er wieder gehn,", "tokens": ["Ge\u00b7m\u00e4ch\u00b7lich", "will", "er", "wie\u00b7der", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sieht Wei\u00dfb\u00e4rte drei er stehn,", "tokens": ["Da", "sieht", "Wei\u00df\u00b7b\u00e4r\u00b7te", "drei", "er", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "CARD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die haben nichts in H\u00e4nden", "tokens": ["Die", "ha\u00b7ben", "nichts", "in", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PIS", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als eine Tafel und Kreide wei\u00df,", "tokens": ["Als", "ei\u00b7ne", "Ta\u00b7fel", "und", "Krei\u00b7de", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es wird ihm eisig bald, bald hei\u00df:", "tokens": ["Es", "wird", "ihm", "ei\u00b7sig", "bald", ",", "bald", "hei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "ADV", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jesus! wie wird das enden!", "tokens": ["Je\u00b7sus", "!", "wie", "wird", "das", "en\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "VAFIN", "PDS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Hebt drum zu vaterunsern an;", "tokens": ["Hebt", "drum", "zu", "va\u00b7ter\u00b7un\u00b7sern", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da tr\u00f6stet ihn der \u00e4lste Mann:", "tokens": ["Da", "tr\u00f6s\u00b7tet", "ihn", "der", "\u00e4ls\u00b7te", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir thun dir nichts zu leide!", "tokens": ["Wir", "thun", "dir", "nichts", "zu", "lei\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hol Wein dir nur, so oft du willst,", "tokens": ["Hol", "Wein", "dir", "nur", ",", "so", "oft", "du", "willst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPER", "ADV", "$,", "ADV", "ADV", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es schreibt nicht auf, wie oft du f\u00fcllst", "tokens": ["Es", "schreibt", "nicht", "auf", ",", "wie", "oft", "du", "f\u00fcllst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,", "PWAV", "ADV", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Flaschenpaar, die Kreide.", "tokens": ["Das", "Fla\u00b7schen\u00b7paar", ",", "die", "Krei\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Patzebern d\u00fcnkt das wunderbar,", "tokens": ["Pat\u00b7ze\u00b7bern", "d\u00fcnkt", "das", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Doch angenehm. Ein ganzes Jahr", "tokens": ["Doch", "an\u00b7ge\u00b7nehm", ".", "Ein", "gan\u00b7zes", "Jahr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat er mit allen Seinen", "tokens": ["Hat", "er", "mit", "al\u00b7len", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Tagt\u00e4glich sich gef\u00fcllt aufs neu", "tokens": ["Tag\u00b7t\u00e4g\u00b7lich", "sich", "ge\u00b7f\u00fcllt", "aufs", "neu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "PRF", "VVPP", "APPRART", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Flaschen ohne Reu und Scheu", "tokens": ["Die", "Fla\u00b7schen", "oh\u00b7ne", "Reu", "und", "Scheu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Hadernburger Weinen.", "tokens": ["Mit", "Ha\u00b7dern\u00b7bur\u00b7ger", "Wei\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "(denn in der Hadernburg geschah", "tokens": ["(", "denn", "in", "der", "Ha\u00b7dern\u00b7burg", "ge\u00b7schah"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die seltsame Historia.", "tokens": ["Die", "selt\u00b7sa\u00b7me", "His\u00b7to\u00b7ria", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ist bei Salurn gelegen;", "tokens": ["Ist", "bei", "Sa\u00b7lurn", "ge\u00b7le\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dietrich von Bern hielt Hochzeit drin", "tokens": ["Diet\u00b7rich", "von", "Bern", "hielt", "Hoch\u00b7zeit", "drin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "NE", "VVFIN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit einer sch\u00f6nen Kurtaatscherin,", "tokens": ["Mit", "ei\u00b7ner", "sch\u00f6\u00b7nen", "Kur\u00b7taat\u00b7sche\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der alte Niblungdegen.)", "tokens": ["Der", "al\u00b7te", "Nib\u00b7lung\u00b7de\u00b7gen", ".", ")"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "So trank er voller Freudigkeit,", "tokens": ["So", "trank", "er", "vol\u00b7ler", "Freu\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis da\u00df ein' hohe Obrigkeit", "tokens": ["Bis", "da\u00df", "ein'", "ho\u00b7he", "Ob\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dahinter ist gekommen.", "tokens": ["Da\u00b7hin\u00b7ter", "ist", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erbarmte sich der Seele sein", "tokens": ["Er\u00b7barm\u00b7te", "sich", "der", "See\u00b7le", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und hat: woher, von wem der Wein,", "tokens": ["Und", "hat", ":", "wo\u00b7her", ",", "von", "wem", "der", "Wein", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$.", "PWAV", "$,", "APPR", "PWS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn ins Gebet genommen.", "tokens": ["Ihn", "ins", "Ge\u00b7bet", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.11": {"line.1": {"text": "Ob er nicht gar vom Teufel w\u00e4r?", "tokens": ["Ob", "er", "nicht", "gar", "vom", "Teu\u00b7fel", "w\u00e4r", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Patzeber bracht die Flaschen her.", "tokens": ["Pat\u00b7ze\u00b7ber", "bracht", "die", "Fla\u00b7schen", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie kosteten gar schnelle:", "tokens": ["Sie", "kos\u00b7te\u00b7ten", "gar", "schnel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht aus Salurn ist dieser Wein,", "tokens": ["Nicht", "aus", "Sa\u00b7lurn", "ist", "die\u00b7ser", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NE", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Drum kann er nicht gestohlen sein,", "tokens": ["Drum", "kann", "er", "nicht", "ge\u00b7stoh\u00b7len", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PTKNEG", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und schmeckt auch nicht nach H\u00f6lle.", "tokens": ["Und", "schmeckt", "auch", "nicht", "nach", "H\u00f6l\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Patzeber! Wo flie\u00dft dieser Quell?", "tokens": ["Pat\u00b7ze\u00b7ber", "!", "Wo", "flie\u00dft", "die\u00b7ser", "Quell", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWAV", "VVFIN", "PDAT", "NN", "$."], "meter": "+--+---+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Christoph bekannte auf der Stell,", "tokens": ["Chris\u00b7toph", "be\u00b7kann\u00b7te", "auf", "der", "Stell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo er den Wein th\u00e4t finden.", "tokens": ["Wo", "er", "den", "Wein", "th\u00e4t", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "So gehe hin und hol aufs neu,", "tokens": ["So", "ge\u00b7he", "hin", "und", "hol", "aufs", "neu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "KON", "ADJD", "APPRART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df nochmals wir nach Pflicht und Treu", "tokens": ["Da\u00df", "noch\u00b7mals", "wir", "nach", "Pflicht", "und", "Treu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Beh\u00f6rdlich ihn ergr\u00fcnden!", "tokens": ["Be\u00b7h\u00f6rd\u00b7lich", "ihn", "er\u00b7gr\u00fcn\u00b7den", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Patzeber lief. Doch sonderbar:", "tokens": ["Pat\u00b7ze\u00b7ber", "lief", ".", "Doch", "son\u00b7der\u00b7bar", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "KON", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wo gestern Trepp und Keller war,", "tokens": ["Wo", "ge\u00b7stern", "Trepp", "und", "Kel\u00b7ler", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Da g\u00e4hnte schwarze Leere,", "tokens": ["Da", "g\u00e4hn\u00b7te", "schwar\u00b7ze", "Lee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und Schl\u00e4ge sausten hageldicht,", "tokens": ["Und", "Schl\u00e4\u00b7ge", "saus\u00b7ten", "ha\u00b7gel\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Patzeber fiel aufs Angesicht", "tokens": ["Pat\u00b7ze\u00b7ber", "fiel", "aufs", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPRART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und f\u00fcrchtete sich sehre.", "tokens": ["Und", "f\u00fcrch\u00b7te\u00b7te", "sich", "seh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Dann sah er tief, tief unter sich", "tokens": ["Dann", "sah", "er", "tief", ",", "tief", "un\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "ADJD", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den lieben Keller; schauerlich", "tokens": ["Den", "lie\u00b7ben", "Kel\u00b7ler", ";", "schau\u00b7er\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sa\u00dfen darin die dreie", "tokens": ["Sa\u00b7\u00dfen", "da\u00b7rin", "die", "drei\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PAV", "ART", "CARD"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Und murmelten in ihren Bart", "tokens": ["Und", "mur\u00b7mel\u00b7ten", "in", "ih\u00b7ren", "Bart"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und kritzelten nach Kaufmannsart", "tokens": ["Und", "krit\u00b7zel\u00b7ten", "nach", "Kauf\u00b7mann\u00b7sart"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Viel Ziffern Reih an Reihe.", "tokens": ["Viel", "Zif\u00b7fern", "Reih", "an", "Rei\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Sprach dumpf der Aelteste: es stimmt!", "tokens": ["Sprach", "dumpf", "der", "A\u00b7el\u00b7tes\u00b7te", ":", "es", "stimmt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sein Nachbar ein St\u00fcck Kreide nimmt,", "tokens": ["Sein", "Nach\u00b7bar", "ein", "St\u00fcck", "Krei\u00b7de", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Durchstreicht die Ziffernreihen,", "tokens": ["Durch\u00b7streicht", "die", "Zif\u00b7fern\u00b7rei\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df es wie eine r\u00f6msche Zehn", "tokens": ["Da\u00df", "es", "wie", "ei\u00b7ne", "r\u00f6m\u00b7sche", "Zehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Oder ein Andreaskreuz zu sehn,", "tokens": ["O\u00b7der", "ein", "A\u00b7ndre\u00b7as\u00b7kreuz", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Mit dicken Strichen zweien.", "tokens": ["Mit", "di\u00b7cken", "Stri\u00b7chen", "zwei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Dann, als dies stumm geschehen war,", "tokens": ["Dann", ",", "als", "dies", "stumm", "ge\u00b7sche\u00b7hen", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PDS", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Z\u00e4hlte auf in Silberm\u00fcnze bar", "tokens": ["Z\u00e4hl\u00b7te", "auf", "in", "Sil\u00b7ber\u00b7m\u00fcn\u00b7ze", "bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "APPR", "NN", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Der dritte drei\u00dfig Thaler,", "tokens": ["Der", "drit\u00b7te", "drei\u00b7\u00dfig", "Tha\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dr\u00fcckt sie Patzebern in die Hand,", "tokens": ["Dr\u00fcckt", "sie", "Pat\u00b7ze\u00b7bern", "in", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Wimmert ein bi\u00dfchen und verschwand.", "tokens": ["Wim\u00b7mert", "ein", "bi\u00df\u00b7chen", "und", "ver\u00b7schwand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "KON", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Aufd\u00e4mmerte ein fahler", "tokens": ["Auf\u00b7d\u00e4m\u00b7mer\u00b7te", "ein", "fah\u00b7ler"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Lichtschein, und durch die graue Luft", "tokens": ["Licht\u00b7schein", ",", "und", "durch", "die", "grau\u00b7e", "Luft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zog hin und her ein Moderduft;", "tokens": ["Zog", "hin", "und", "her", "ein", "Mo\u00b7der\u00b7duft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Patzebern wollt es scheinen,", "tokens": ["Pat\u00b7ze\u00b7bern", "wollt", "es", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Als ging ein Leichenzug vorbei;", "tokens": ["Als", "ging", "ein", "Lei\u00b7chen\u00b7zug", "vor\u00b7bei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Fackeln sah er noch die drei", "tokens": ["Mit", "Fa\u00b7ckeln", "sah", "er", "noch", "die", "drei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "ART", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und h\u00f6rte leise weinen.", "tokens": ["Und", "h\u00f6r\u00b7te", "lei\u00b7se", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Wei\u00df Gott, ihm war nicht wohlgemut,", "tokens": ["Wei\u00df", "Gott", ",", "ihm", "war", "nicht", "wohl\u00b7ge\u00b7mut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Obwohl in seinem alten Hut", "tokens": ["Ob\u00b7wohl", "in", "sei\u00b7nem", "al\u00b7ten", "Hut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die drei\u00dfig Thaler klangen.", "tokens": ["Die", "drei\u00b7\u00dfig", "Tha\u00b7ler", "klan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er lief davon wie hundsgejagt,", "tokens": ["Er", "lief", "da\u00b7von", "wie", "hunds\u00b7ge\u00b7jagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "KOKOM", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Stottern hat er ausgesagt,", "tokens": ["Mit", "Stot\u00b7tern", "hat", "er", "aus\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was Grauens ihm ergangen.", "tokens": ["Was", "Grau\u00b7ens", "ihm", "er\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Die Thaler gingen rundherum", "tokens": ["Die", "Tha\u00b7ler", "gin\u00b7gen", "rund\u00b7he\u00b7rum"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im hohen Ratskollegium,", "tokens": ["Im", "ho\u00b7hen", "Rats\u00b7kol\u00b7le\u00b7gi\u00b7um", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Ob sie nach Schwefel r\u00f6chen?", "tokens": ["Ob", "sie", "nach", "Schwe\u00b7fel", "r\u00f6\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nein, nein: sie waren blinkeblank", "tokens": ["Nein", ",", "nein", ":", "sie", "wa\u00b7ren", "blin\u00b7ke\u00b7blank"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PTKANT", "$.", "PPER", "VAFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und hatten keinerlei Gestank", "tokens": ["Und", "hat\u00b7ten", "kei\u00b7ner\u00b7lei", "Ge\u00b7stank"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und klangen nicht nach Blechen.", "tokens": ["Und", "klan\u00b7gen", "nicht", "nach", "Ble\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Christliche Thaler! Gut und recht!", "tokens": ["Christ\u00b7li\u00b7che", "Tha\u00b7ler", "!", "Gut", "und", "recht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Doch Christoph hatte ausgezecht,", "tokens": ["Doch", "Chris\u00b7toph", "hat\u00b7te", "aus\u00b7ge\u00b7zecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er starb nach zehen Tagen;", "tokens": ["Er", "starb", "nach", "ze\u00b7hen", "Ta\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das hatte wohl die r\u00f6mische Zehn,", "tokens": ["Das", "hat\u00b7te", "wohl", "die", "r\u00f6\u00b7mi\u00b7sche", "Zehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Die er in jener Nacht gesehn,", "tokens": ["Die", "er", "in", "je\u00b7ner", "Nacht", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vork\u00fcndend wollen sagen.", "tokens": ["Vor\u00b7k\u00fcn\u00b7dend", "wol\u00b7len", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Nach Christoph hat in mancher Nacht", "tokens": ["Nach", "Chris\u00b7toph", "hat", "in", "man\u00b7cher", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VAFIN", "APPR", "PIAT", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Manch Bauer sich noch aufgemacht,", "tokens": ["Manch", "Bau\u00b7er", "sich", "noch", "auf\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu trinken alte Weine", "tokens": ["Zu", "trin\u00b7ken", "al\u00b7te", "Wei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Im Keller Dieterichs von Bern;", "tokens": ["Im", "Kel\u00b7ler", "Die\u00b7te\u00b7richs", "von", "Bern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich selber th\u00e4t es herzlich gern:", "tokens": ["Ich", "sel\u00b7ber", "th\u00e4t", "es", "herz\u00b7lich", "gern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Indes, es flie\u00dfen keine.", "tokens": ["In\u00b7des", ",", "es", "flie\u00b7\u00dfen", "kei\u00b7ne", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Die Obrigkeit ist schuld daran!", "tokens": ["Die", "Ob\u00b7rig\u00b7keit", "ist", "schuld", "da\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PAV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Ich klage die Salurner an,", "tokens": ["Ich", "kla\u00b7ge", "die", "Sa\u00b7lur\u00b7ner", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df sie den Wein vertrieben.", "tokens": ["Da\u00df", "sie", "den", "Wein", "ver\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nun ist f\u00fcr jenen Malvasier", "tokens": ["Nun", "ist", "f\u00fcr", "je\u00b7nen", "Mal\u00b7va\u00b7sier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zur Strafe ein recht saurer ihr,", "tokens": ["Zur", "Stra\u00b7fe", "ein", "recht", "sau\u00b7rer", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJD", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr eigner Wein verblieben.", "tokens": ["Ihr", "eig\u00b7ner", "Wein", "ver\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Oh heilige Bureaukratie,", "tokens": ["Oh", "hei\u00b7li\u00b7ge", "Bu\u00b7re\u00b7au\u00b7kra\u00b7tie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vergi\u00df der M\u00e4re Lehre nie:", "tokens": ["Ver\u00b7gi\u00df", "der", "M\u00e4\u00b7re", "Leh\u00b7re", "nie", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df ferne deine H\u00e4nde", "tokens": ["La\u00df", "fer\u00b7ne", "dei\u00b7ne", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von Dingen wunderbarer Art!", "tokens": ["Von", "Din\u00b7gen", "wun\u00b7der\u00b7ba\u00b7rer", "Art", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sonst seng dir saurer Wein den Bart!", "tokens": ["Sonst", "seng", "dir", "sau\u00b7rer", "Wein", "den", "Bart", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der M\u00e4re Ende.", "tokens": ["Das", "ist", "der", "M\u00e4\u00b7re", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}