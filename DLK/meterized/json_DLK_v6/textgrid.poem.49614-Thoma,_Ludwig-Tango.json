{"textgrid.poem.49614": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Tango", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die alte Zeit, ihr guten Leute", "tokens": ["Die", "al\u00b7te", "Zeit", ",", "ihr", "gu\u00b7ten", "Leu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die ist nun leider auch vorbei.", "tokens": ["Die", "ist", "nun", "lei\u00b7der", "auch", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da la\u00dft uns fragen, ob es heute", "tokens": ["Da", "la\u00dft", "uns", "fra\u00b7gen", ",", "ob", "es", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVINF", "$,", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In irgend etwas besser sei.", "tokens": ["In", "ir\u00b7gend", "et\u00b7was", "bes\u00b7ser", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nein, nein, und nein, das mu\u00df ich sagen,", "tokens": ["Nein", ",", "nein", ",", "und", "nein", ",", "das", "mu\u00df", "ich", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "KON", "PTKANT", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das ist mir ohne Zweifel klar,", "tokens": ["Das", "ist", "mir", "oh\u00b7ne", "Zwei\u00b7fel", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df es in unsren jungen Tagen", "tokens": ["Da\u00df", "es", "in", "un\u00b7sren", "jun\u00b7gen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In puncto puncti besser war.", "tokens": ["In", "punc\u00b7to", "punc\u00b7ti", "bes\u00b7ser", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich meine nicht, da\u00df unsre Triebe", "tokens": ["Ich", "mei\u00b7ne", "nicht", ",", "da\u00df", "uns\u00b7re", "Trie\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht mehr so st\u00fcrmisch \u2013 nu \u2013 hem \u2013 hem,", "tokens": ["Nicht", "mehr", "so", "st\u00fcr\u00b7misch", "\u2013", "nu", "\u2013", "hem", "\u2013", "hem", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADJD", "$(", "ADV", "$(", "ADJA", "$(", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nein, allgemein, das Weib \u2013 die Liebe,", "tokens": ["Nein", ",", "all\u00b7ge\u00b7mein", ",", "das", "Weib", "\u2013", "die", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "$,", "ART", "NN", "$(", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die waren netter ehedem,", "tokens": ["Die", "wa\u00b7ren", "net\u00b7ter", "e\u00b7he\u00b7dem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein M\u00e4dchen damals konnte allen", "tokens": ["Ein", "M\u00e4d\u00b7chen", "da\u00b7mals", "konn\u00b7te", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VMFIN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nur wenn es wirklich was besa\u00df,", "tokens": ["Nur", "wenn", "es", "wirk\u00b7lich", "was", "be\u00b7sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur durch reellen Wert gefallen.", "tokens": ["Nur", "durch", "re\u00b7el\u00b7len", "Wert", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir hatten noch ein Augenma\u00df!", "tokens": ["Wir", "hat\u00b7ten", "noch", "ein", "Au\u00b7gen\u00b7ma\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wir Kenner pr\u00fcften noch die B\u00fcste", "tokens": ["Wir", "Ken\u00b7ner", "pr\u00fcf\u00b7ten", "noch", "die", "B\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sch\u00e4tzten noch ein festes Bein,", "tokens": ["Und", "sch\u00e4tz\u00b7ten", "noch", "ein", "fes\u00b7tes", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und r\u00fcckw\u00e4rts durft', da\u00df ich nicht w\u00fc\u00dfte,", "tokens": ["Und", "r\u00fcck\u00b7w\u00e4rts", "durft'", ",", "da\u00df", "ich", "nicht", "w\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch keine glatte Fl\u00e4che sein.", "tokens": ["Auch", "kei\u00b7ne", "glat\u00b7te", "Fl\u00e4\u00b7che", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wir sprachen damals von Potenzen,", "tokens": ["Wir", "spra\u00b7chen", "da\u00b7mals", "von", "Po\u00b7ten\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was so ein M\u00e4dchen uns gezeigt,", "tokens": ["Was", "so", "ein", "M\u00e4d\u00b7chen", "uns", "ge\u00b7zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u00fcberschritt es auch die Grenzen,", "tokens": ["Und", "\u00fc\u00b7bersc\u00b7hritt", "es", "auch", "die", "Gren\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir waren ihm doch zugeneigt.", "tokens": ["Wir", "wa\u00b7ren", "ihm", "doch", "zu\u00b7gen\u00b7eigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Jetzt aber \u2013 ach du gro\u00dfe G\u00fcte! \u2013", "tokens": ["Jetzt", "a\u00b7ber", "\u2013", "ach", "du", "gro\u00b7\u00dfe", "G\u00fc\u00b7te", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$(", "XY", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Weibervolk ist blo\u00df mehr schlank,", "tokens": ["Das", "Wei\u00b7ber\u00b7volk", "ist", "blo\u00df", "mehr", "schlank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist nicht mehr Saft und Kraft und Bl\u00fcte,", "tokens": ["Ist", "nicht", "mehr", "Saft", "und", "Kraft", "und", "Bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "PIAT", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Blo\u00df B\u00fcgelbrett und Hobelbank.", "tokens": ["Blo\u00df", "B\u00fc\u00b7gel\u00b7brett", "und", "Ho\u00b7bel\u00b7bank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die Rundung fehlt, und in der L\u00e4nge", "tokens": ["Die", "Run\u00b7dung", "fehlt", ",", "und", "in", "der", "L\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Liegt heute aller Anmut Sinn,", "tokens": ["Liegt", "heu\u00b7te", "al\u00b7ler", "An\u00b7mut", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und strafft das Kleid sich am Gest\u00e4nge,", "tokens": ["Und", "strafft", "das", "Kleid", "sich", "am", "Ge\u00b7st\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So ist's erreicht, und man ist hin.", "tokens": ["So", "ist's", "er\u00b7reicht", ",", "und", "man", "ist", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$,", "KON", "PIS", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ja, Weiber, die es fr\u00fcher hatten,", "tokens": ["Ja", ",", "Wei\u00b7ber", ",", "die", "es", "fr\u00fc\u00b7her", "hat\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Entfernen ihrer F\u00fclle Reiz", "tokens": ["Ent\u00b7fer\u00b7nen", "ih\u00b7rer", "F\u00fcl\u00b7le", "Reiz"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ganz ohne R\u00fccksicht auf den Gatten", "tokens": ["Ganz", "oh\u00b7ne", "R\u00fcck\u00b7sicht", "auf", "den", "Gat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und aller W\u00fcnsche seinerseits.", "tokens": ["Und", "al\u00b7ler", "W\u00fcn\u00b7sche", "sei\u00b7ner\u00b7seits", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Dies neue Wesen, ich vermute,", "tokens": ["Dies", "neu\u00b7e", "We\u00b7sen", ",", "ich", "ver\u00b7mu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df es auch Amor recht verdrie\u00dft,", "tokens": ["Da\u00df", "es", "auch", "A\u00b7mor", "recht", "ver\u00b7drie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NE", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ich bin froh, da\u00df dieser Gute", "tokens": ["Und", "ich", "bin", "froh", ",", "da\u00df", "die\u00b7ser", "Gu\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$,", "KOUS", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auf mich nicht mehr so h\u00e4ufig schie\u00dft.", "tokens": ["Auf", "mich", "nicht", "mehr", "so", "h\u00e4u\u00b7fig", "schie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und wollte man auch kunstbeflissen", "tokens": ["Und", "woll\u00b7te", "man", "auch", "kunst\u00b7be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PIS", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Versuchen, was die neue Zeit", "tokens": ["Ver\u00b7su\u00b7chen", ",", "was", "die", "neu\u00b7e", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Uns gibt. Man ist hinausgeschmissen", "tokens": ["Uns", "gibt", ".", "Man", "ist", "hin\u00b7aus\u00b7ge\u00b7schmis\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "PIS", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus jeglicher Gelegenheit.", "tokens": ["Aus", "jeg\u00b7li\u00b7cher", "Ge\u00b7le\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Denn Eva will nur Tango tanzen,", "tokens": ["Denn", "E\u00b7va", "will", "nur", "Tan\u00b7go", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und der Schlawiner, der es kann,", "tokens": ["Und", "der", "Schla\u00b7wi\u00b7ner", ",", "der", "es", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist heute \u2013 ja, das pa\u00dft zum Ganzen \u2013", "tokens": ["Ist", "heu\u00b7te", "\u2013", "ja", ",", "das", "pa\u00dft", "zum", "Gan\u00b7zen", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$(", "PTKANT", "$,", "PDS", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Allein der int'ressante Mann.", "tokens": ["Al\u00b7lein", "der", "i\u00b7nt'res\u00b7san\u00b7te", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Kreuz Teufel, wenn man beispielsweise", "tokens": ["Kreuz", "Teu\u00b7fel", ",", "wenn", "man", "bei\u00b7spiels\u00b7wei\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "KOUS", "PIS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An gute, alte Zeiten denkt!", "tokens": ["An", "gu\u00b7te", ",", "al\u00b7te", "Zei\u00b7ten", "denkt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hat fidel ein Bursch im Kreise", "tokens": ["Wie", "hat", "fi\u00b7del", "ein", "Bursch", "im", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "NE", "ART", "NN", "APPRART", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Sein M\u00e4del hin und her geschwenkt!", "tokens": ["Sein", "M\u00e4\u00b7del", "hin", "und", "her", "ge\u00b7schwenkt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Bald lie\u00df man sich zusammenpressen", "tokens": ["Bald", "lie\u00df", "man", "sich", "zu\u00b7sam\u00b7men\u00b7pres\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In einem fr\u00f6hlichen Gew\u00fchl;", "tokens": ["In", "ei\u00b7nem", "fr\u00f6h\u00b7li\u00b7chen", "Ge\u00b7w\u00fchl", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man fand und suchte selbstvergessen", "tokens": ["Man", "fand", "und", "such\u00b7te", "selbst\u00b7ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Anhaltspunkte f\u00fcrs Gef\u00fchl.", "tokens": ["Die", "An\u00b7halts\u00b7punk\u00b7te", "f\u00fcrs", "Ge\u00b7f\u00fchl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Bald legte man im Walzerschleifen", "tokens": ["Bald", "leg\u00b7te", "man", "im", "Wal\u00b7zer\u00b7schlei\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Sinn f\u00fcr sch\u00f6nen Rhythmus dar,", "tokens": ["Den", "Sinn", "f\u00fcr", "sch\u00f6\u00b7nen", "Rhyth\u00b7mus", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann konnte sie es ganz begreifen,", "tokens": ["Dann", "konn\u00b7te", "sie", "es", "ganz", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie da\u00df man stark und z\u00e4rtlich war.", "tokens": ["Wie", "da\u00df", "man", "stark", "und", "z\u00e4rt\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PIS", "ADJD", "KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Was wir gewollt, was wir empfunden,", "tokens": ["Was", "wir", "ge\u00b7wollt", ",", "was", "wir", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMPP", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vor allem: es war innerlich.", "tokens": ["Vor", "al\u00b7lem", ":", "es", "war", "in\u00b7ner\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$.", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob sch\u00fcchtern oder ungebunden,", "tokens": ["Ob", "sch\u00fcch\u00b7tern", "o\u00b7der", "un\u00b7ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man war noch eine Welt f\u00fcr sich.", "tokens": ["Man", "war", "noch", "ei\u00b7ne", "Welt", "f\u00fcr", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ART", "NN", "APPR", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Man war nur mit sich selbst besch\u00e4ftigt", "tokens": ["Man", "war", "nur", "mit", "sich", "selbst", "be\u00b7sch\u00e4f\u00b7tigt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "APPR", "PRF", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fchlte sich dem Ziele nah,", "tokens": ["Und", "f\u00fchl\u00b7te", "sich", "dem", "Zie\u00b7le", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn ein Versprechen es bekr\u00e4ftigt.", "tokens": ["Wenn", "ein", "Ver\u00b7spre\u00b7chen", "es", "be\u00b7kr\u00e4f\u00b7tigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie war man froh, wenn's niemand sah!", "tokens": ["Wie", "war", "man", "froh", ",", "wenn's", "nie\u00b7mand", "sah", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIS", "ADJD", "$,", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Und heute? Heute sitzt die Runde", "tokens": ["Und", "heu\u00b7te", "?", "Heu\u00b7te", "sitzt", "die", "Run\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Modeaffen da und gafft,", "tokens": ["Von", "Mo\u00b7de\u00b7af\u00b7fen", "da", "und", "gafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ein Schlawiner zeigt 'ne Stunde", "tokens": ["Und", "ein", "Schla\u00b7wi\u00b7ner", "zeigt", "'ne", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Die Tanzschlawinermeisterschaft.", "tokens": ["Die", "Tanz\u00b7schla\u00b7wi\u00b7ner\u00b7meis\u00b7ter\u00b7schaft", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Der Biedermann braucht nicht mehr stehlen.", "tokens": ["Der", "Bie\u00b7der\u00b7mann", "braucht", "nicht", "mehr", "steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Tangokunst, die ihn empfahl", "tokens": ["Die", "Tan\u00b7go\u00b7kunst", ",", "die", "ihn", "emp\u00b7fahl"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei den mond\u00e4nen Weiberseelen,", "tokens": ["Bei", "den", "mon\u00b7d\u00e4\u00b7nen", "Wei\u00b7ber\u00b7see\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Tr\u00e4gt mehr, als was er fr\u00fcher stahl.", "tokens": ["Tr\u00e4gt", "mehr", ",", "als", "was", "er", "fr\u00fc\u00b7her", "stahl", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Am Arme eines Taschendiebes", "tokens": ["Am", "Ar\u00b7me", "ei\u00b7nes", "Ta\u00b7schen\u00b7die\u00b7bes"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zeigt uns ein Kl\u00e4rchen als Gespann,", "tokens": ["Zeigt", "uns", "ein", "Kl\u00e4r\u00b7chen", "als", "Ge\u00b7spann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NE", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie es die Kunst des Kniegeschiebes", "tokens": ["Wie", "es", "die", "Kunst", "des", "Knie\u00b7ge\u00b7schie\u00b7bes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nach vorw\u00e4rts und nach r\u00fcckw\u00e4rts kann.", "tokens": ["Nach", "vor\u00b7w\u00e4rts", "und", "nach", "r\u00fcck\u00b7w\u00e4rts", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "KON", "APPR", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und Sara will gleich einer Ente", "tokens": ["Und", "Sa\u00b7ra", "will", "gleich", "ei\u00b7ner", "En\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VMFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den P\u00fcrzel hin und wider drehn.", "tokens": ["Den", "P\u00fcr\u00b7zel", "hin", "und", "wi\u00b7der", "drehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "APPR", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie w\u00fcnscht nur eins: mit dem Talente", "tokens": ["Sie", "w\u00fcnscht", "nur", "eins", ":", "mit", "dem", "Ta\u00b7len\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "$.", "APPR", "ART", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Bemerkt zu werden und geseh'n.", "tokens": ["Be\u00b7merkt", "zu", "wer\u00b7den", "und", "ge\u00b7seh'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVPP", "PTKZU", "VAINF", "KON", "XY", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Das ist das Gl\u00fcck: gesehen werden,", "tokens": ["Das", "ist", "das", "Gl\u00fcck", ":", "ge\u00b7se\u00b7hen", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und jede hofft und jede denkt,", "tokens": ["Und", "je\u00b7de", "hofft", "und", "je\u00b7de", "denkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "PIAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df mit erotischen Geb\u00e4rden", "tokens": ["Da\u00df", "mit", "e\u00b7ro\u00b7ti\u00b7schen", "Ge\u00b7b\u00e4r\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie aller Blicke auf sich lenkt.", "tokens": ["Sie", "al\u00b7ler", "Bli\u00b7cke", "auf", "sich", "lenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Nichts mehr von Leidenschaft und Liebe,", "tokens": ["Nichts", "mehr", "von", "Lei\u00b7den\u00b7schaft", "und", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von sich vergessen und Natur.", "tokens": ["Von", "sich", "ver\u00b7ges\u00b7sen", "und", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVPP", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hier ist von keinem hei\u00dfen Triebe", "tokens": ["Hier", "ist", "von", "kei\u00b7nem", "hei\u00b7\u00dfen", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch nur die Ahnung und die Spur.", "tokens": ["Auch", "nur", "die", "Ah\u00b7nung", "und", "die", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Man setzt den Hintern nur in Szene,", "tokens": ["Man", "setzt", "den", "Hin\u00b7tern", "nur", "in", "Sze\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auch m\u00f6glichst viel von seinem Bein,", "tokens": ["Auch", "m\u00f6g\u00b7lichst", "viel", "von", "sei\u00b7nem", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und zwar \u2013 so will es die Mond\u00e4ne \u2013", "tokens": ["Und", "zwar", "\u2013", "so", "will", "es", "die", "Mon\u00b7d\u00e4\u00b7ne", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ADV", "VMFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Soll es f\u00fcr alle Schauspiel sein.", "tokens": ["Soll", "es", "f\u00fcr", "al\u00b7le", "Schau\u00b7spiel", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Nicht Herz und Sinne zu bewegen", "tokens": ["Nicht", "Herz", "und", "Sin\u00b7ne", "zu", "be\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und froh zu sein in heitrem Spiel,", "tokens": ["Und", "froh", "zu", "sein", "in", "heit\u00b7rem", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VAINF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nein, eine Menge aufzuregen", "tokens": ["Nein", ",", "ei\u00b7ne", "Men\u00b7ge", "auf\u00b7zu\u00b7re\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist heute das erstrebte Ziel.", "tokens": ["Ist", "heu\u00b7te", "das", "er\u00b7streb\u00b7te", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Nat\u00fcrlich kam die sch\u00f6ne Mode,", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "kam", "die", "sch\u00f6\u00b7ne", "Mo\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie jede noch, von ausw\u00e4rts her.", "tokens": ["Wie", "je\u00b7de", "noch", ",", "von", "aus\u00b7w\u00e4rts", "her", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "$,", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir Deutschen hetzen sie zu Tode", "tokens": ["Wir", "Deut\u00b7schen", "het\u00b7zen", "sie", "zu", "To\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und \u00fcberwinden sie nicht mehr.", "tokens": ["Und", "\u00fc\u00b7berw\u00b7in\u00b7den", "sie", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Auch M\u00fcnchen mit den netten M\u00e4deln,", "tokens": ["Auch", "M\u00fcn\u00b7chen", "mit", "den", "net\u00b7ten", "M\u00e4\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das doch einmal so fr\u00f6hlich war,", "tokens": ["Das", "doch", "ein\u00b7mal", "so", "fr\u00f6h\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df nach dem Muster sich veredeln", "tokens": ["Mu\u00df", "nach", "dem", "Mus\u00b7ter", "sich", "ver\u00b7e\u00b7deln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "PRF", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und zeigt sich heute wandelbar.", "tokens": ["Und", "zeigt", "sich", "heu\u00b7te", "wan\u00b7del\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Wenn sie wo eine Dummheit haben,", "tokens": ["Wenn", "sie", "wo", "ei\u00b7ne", "Dumm\u00b7heit", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PWAV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So ist Gesetz: Wir kriegen sie,", "tokens": ["So", "ist", "Ge\u00b7setz", ":", "Wir", "krie\u00b7gen", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$.", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und die nat\u00fcrlichste der Gaben", "tokens": ["Und", "die", "na\u00b7t\u00fcr\u00b7lichs\u00b7te", "der", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "War drum f\u00fcr uns der Tangotea.", "tokens": ["War", "drum", "f\u00fcr", "uns", "der", "Tan\u00b7go\u00b7tea", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Das trippelt nun auf St\u00f6ckelschuhen", "tokens": ["Das", "trip\u00b7pelt", "nun", "auf", "St\u00f6\u00b7ckel\u00b7schu\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im engen Tangor\u00f6ckchen her,", "tokens": ["Im", "en\u00b7gen", "Tan\u00b7go\u00b7r\u00f6\u00b7ck\u00b7chen", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Das ist ein Lernen und Bem\u00fchen,", "tokens": ["Das", "ist", "ein", "Ler\u00b7nen", "und", "Be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und fiele es auch noch so schwer.", "tokens": ["Und", "fie\u00b7le", "es", "auch", "noch", "so", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Wo heute zwei zusammenkommen,", "tokens": ["Wo", "heu\u00b7te", "zwei", "zu\u00b7sam\u00b7men\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "CARD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da fr\u00e4gt die eine: \u00bbKannst du ihn?\u00ab", "tokens": ["Da", "fr\u00e4gt", "die", "ei\u00b7ne", ":", "\u00bb", "Kannst", "du", "ihn", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ART", "$.", "$(", "VMFIN", "PPER", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbich hab' f\u00fcnf Stunden erst genommen", "tokens": ["\u00bb", "ich", "hab'", "f\u00fcnf", "Stun\u00b7den", "erst", "ge\u00b7nom\u00b7men"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "CARD", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und gehe jetzt noch viermal hin.\u00ab", "tokens": ["Und", "ge\u00b7he", "jetzt", "noch", "vier\u00b7mal", "hin", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Die Damenwelt voll Flei\u00df und Eifer", "tokens": ["Die", "Da\u00b7men\u00b7welt", "voll", "Flei\u00df", "und", "Ei\u00b7fer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kennt nur die eine hohe Pflicht", "tokens": ["Kennt", "nur", "die", "ei\u00b7ne", "ho\u00b7he", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Stunde bei dem Tangoschleifer,", "tokens": ["Der", "Stun\u00b7de", "bei", "dem", "Tan\u00b7go\u00b7schlei\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und keine andre kennt sie nicht.", "tokens": ["Und", "kei\u00b7ne", "and\u00b7re", "kennt", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PIS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Sie machen ihre Hausaufgaben", "tokens": ["Sie", "ma\u00b7chen", "ih\u00b7re", "Haus\u00b7auf\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und kennen keine Ruh und Rast,", "tokens": ["Und", "ken\u00b7nen", "kei\u00b7ne", "Ruh", "und", "Rast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis da\u00df sie es herau\u00dfen haben", "tokens": ["Bis", "da\u00df", "sie", "es", "her\u00b7au\u00b7\u00dfen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "PPER", "ADV", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Entweder ganz, entweder fast.", "tokens": ["Ent\u00b7we\u00b7der", "ganz", ",", "ent\u00b7we\u00b7der", "fast", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Und Tochter, Braut und Frau und Schwester,", "tokens": ["Und", "Toch\u00b7ter", ",", "Braut", "und", "Frau", "und", "Schwes\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie alle \u00fcben Tangoschritt,", "tokens": ["Sie", "al\u00b7le", "\u00fc\u00b7ben", "Tan\u00b7go\u00b7schritt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sogar die \u00e4lteren Semester", "tokens": ["So\u00b7gar", "die", "\u00e4l\u00b7te\u00b7ren", "Se\u00b7mes\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind angesteckt und \u00fcben mit.", "tokens": ["Sind", "an\u00b7ge\u00b7steckt", "und", "\u00fc\u00b7ben", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Die Kellnerin h\u00fcpft beim Servieren,", "tokens": ["Die", "Kell\u00b7ne\u00b7rin", "h\u00fcpft", "beim", "Ser\u00b7vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die Ladnerin ist auch so frei,", "tokens": ["Die", "Lad\u00b7ne\u00b7rin", "ist", "auch", "so", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Damit sie keine Zeit verlieren", "tokens": ["Da\u00b7mit", "sie", "kei\u00b7ne", "Zeit", "ver\u00b7lie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihre \u00dcbung st\u00e4ndig sei.", "tokens": ["Und", "ih\u00b7re", "\u00dc\u00b7bung", "st\u00e4n\u00b7dig", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Die alte Freude am Vergn\u00fcgen,", "tokens": ["Die", "al\u00b7te", "Freu\u00b7de", "am", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Leichtsinn und die Fr\u00f6hlichkeit,", "tokens": ["Der", "Leicht\u00b7sinn", "und", "die", "Fr\u00f6h\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie liegen in den letzten Z\u00fcgen;", "tokens": ["Sie", "lie\u00b7gen", "in", "den", "letz\u00b7ten", "Z\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Tango will blo\u00df Emsigkeit.", "tokens": ["Der", "Tan\u00b7go", "will", "blo\u00df", "Em\u00b7sig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Drum ist es Zeit, ein Wort zu sprechen,", "tokens": ["Drum", "ist", "es", "Zeit", ",", "ein", "Wort", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist nicht mehr zu fr\u00fch gewarnt.", "tokens": ["Es", "ist", "nicht", "mehr", "zu", "fr\u00fch", "ge\u00b7warnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit dieser Mode soll man brechen,", "tokens": ["Mit", "die\u00b7ser", "Mo\u00b7de", "soll", "man", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die unsre Weiblichkeit umgarnt.", "tokens": ["Die", "uns\u00b7re", "Weib\u00b7lich\u00b7keit", "um\u00b7garnt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Wenn das so fortgeht, mu\u00df verschwinden", "tokens": ["Wenn", "das", "so", "fort\u00b7geht", ",", "mu\u00df", "ver\u00b7schwin\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PDS", "ADV", "VVFIN", "$,", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der eigentliche Zweck beim Tanz,", "tokens": ["Der", "ei\u00b7gent\u00b7li\u00b7che", "Zweck", "beim", "Tanz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Da\u00df erstens sich zusammenfinden", "tokens": ["Da\u00df", "ers\u00b7tens", "sich", "zu\u00b7sam\u00b7men\u00b7fin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich jede Grete, jeder Hans.", "tokens": ["Sich", "je\u00b7de", "Gre\u00b7te", ",", "je\u00b7der", "Hans", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Da\u00df zweitens durch die W\u00e4rmestrahlen", "tokens": ["Da\u00df", "zwei\u00b7tens", "durch", "die", "W\u00e4r\u00b7mes\u00b7trah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In beiden ein Gef\u00fchl sich regt,", "tokens": ["In", "bei\u00b7den", "ein", "Ge\u00b7f\u00fchl", "sich", "regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das dann bei wiederholten Malen", "tokens": ["Das", "dann", "bei", "wie\u00b7der\u00b7hol\u00b7ten", "Ma\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich etwas steigernd fortbewegt,", "tokens": ["Sich", "et\u00b7was", "stei\u00b7gernd", "fort\u00b7be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Bis es dann drittens durch der Triebe", "tokens": ["Bis", "es", "dann", "drit\u00b7tens", "durch", "der", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Natur- und sachgem\u00e4\u00dfe Kraft", "tokens": ["Na\u00b7tur", "und", "sach\u00b7ge\u00b7m\u00e4\u00b7\u00dfe", "Kraft"], "token_info": ["word", "word", "word", "word"], "pos": ["TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich fortentwickelt bis zur Liebe", "tokens": ["Sich", "for\u00b7tent\u00b7wi\u00b7ckelt", "bis", "zur", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wunscherf\u00fcllten Leidenschaft.", "tokens": ["Und", "wun\u00b7scher\u00b7f\u00fcll\u00b7ten", "Lei\u00b7den\u00b7schaft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Auch viertens das im Wirbel Drehen", "tokens": ["Auch", "vier\u00b7tens", "das", "im", "Wir\u00b7bel", "Dre\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "APPRART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War vom Erfinder klug erdacht.", "tokens": ["War", "vom", "Er\u00b7fin\u00b7der", "klug", "er\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Denkpartie, wie wir verstehen,", "tokens": ["Die", "Denk\u00b7par\u00b7tie", ",", "wie", "wir", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ward so aus ihrer Bahn gebracht,", "tokens": ["Ward", "so", "aus", "ih\u00b7rer", "Bahn", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Wodurch sich f\u00fcnftens mehr verst\u00e4rkte", "tokens": ["Wo\u00b7durch", "sich", "f\u00fcnf\u00b7tens", "mehr", "ver\u00b7st\u00e4rk\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Heirats- und Verbindungsdrang,", "tokens": ["Der", "Hei\u00b7rats", "und", "Ver\u00b7bin\u00b7dungs\u00b7drang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der schlie\u00dflich, wie ich schon bemerkte,", "tokens": ["Der", "schlie\u00df\u00b7lich", ",", "wie", "ich", "schon", "be\u00b7merk\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die beiden zur Vereinung zwang.", "tokens": ["Die", "bei\u00b7den", "zur", "Ver\u00b7ei\u00b7nung", "zwang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Und alles dies wird k\u00fcnftig fehlen,", "tokens": ["Und", "al\u00b7les", "dies", "wird", "k\u00fcnf\u00b7tig", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PDS", "VAFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr M\u00e4dchen, wenn ihr Tango treibt;", "tokens": ["Ihr", "M\u00e4d\u00b7chen", ",", "wenn", "ihr", "Tan\u00b7go", "treibt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr d\u00fcrft euch keineswegs verhehlen,", "tokens": ["Ihr", "d\u00fcrft", "euch", "kei\u00b7nes\u00b7wegs", "ver\u00b7heh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ihr dann einfach sitzenbleibt.", "tokens": ["Da\u00df", "ihr", "dann", "ein\u00b7fach", "sit\u00b7zen\u00b7bleibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Wenn eine als dressierte Puppe", "tokens": ["Wenn", "ei\u00b7ne", "als", "dres\u00b7sier\u00b7te", "Pup\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nur stets mit dem Schlawiner schleift,", "tokens": ["Nur", "stets", "mit", "dem", "Schla\u00b7wi\u00b7ner", "schleift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Bleibt sie den braven M\u00e4nnern schnuppe.", "tokens": ["Bleibt", "sie", "den", "bra\u00b7ven", "M\u00e4n\u00b7nern", "schnup\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ich hoffe, da\u00df ihr dies begreift.", "tokens": ["Ich", "hof\u00b7fe", ",", "da\u00df", "ihr", "dies", "be\u00b7greift", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}