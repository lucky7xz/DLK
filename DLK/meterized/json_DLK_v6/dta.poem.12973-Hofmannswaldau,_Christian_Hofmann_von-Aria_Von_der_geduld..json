{"dta.poem.12973": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Aria  \n Von der geduld.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Getrost, mein geist! wenn sturm und donner dr\u00e4uen.", "tokens": ["Ge\u00b7trost", ",", "mein", "geist", "!", "wenn", "sturm", "und", "don\u00b7ner", "dr\u00e4u\u00b7en", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$.", "KOUS", "ADJD", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die ungeduld h\u00e4lt keinen ab.", "tokens": ["Die", "un\u00b7ge\u00b7duld", "h\u00e4lt", "kei\u00b7nen", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "PIAT", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein gleicher sinn kan sich best\u00e4ndig freuen.", "tokens": ["Ein", "glei\u00b7cher", "sinn", "kan", "sich", "be\u00b7st\u00e4n\u00b7dig", "freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die angst ist ein lebendig grab.", "tokens": ["Die", "angst", "ist", "ein", "le\u00b7ben\u00b7dig", "grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Und ein allzuharter mund", "tokens": ["Und", "ein", "all\u00b7zu\u00b7har\u00b7ter", "mund"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird endlich auch von einem kusse wund.", "tokens": ["Wird", "end\u00b7lich", "auch", "von", "ei\u00b7nem", "kus\u00b7se", "wund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "La\u00df ha\u00df und neid, la\u00df die verleumbdung blitzeu;", "tokens": ["La\u00df", "ha\u00df", "und", "neid", ",", "la\u00df", "die", "ver\u00b7leumb\u00b7dung", "blit\u00b7zeu", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "KON", "NN", "$,", "VVIMP", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die unschuld bleidet unverletzt.", "tokens": ["Die", "un\u00b7schuld", "blei\u00b7det", "un\u00b7ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So lange sie geduld und tugend sch\u00fctzen,", "tokens": ["So", "lan\u00b7ge", "sie", "ge\u00b7duld", "und", "tu\u00b7gend", "sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So wird der pfeil umsonst gewetzt.", "tokens": ["So", "wird", "der", "pfeil", "um\u00b7sonst", "ge\u00b7wetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn der wahrheit klarer schein", "tokens": ["Denn", "der", "wahr\u00b7heit", "kla\u00b7rer", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird doch einmal der falschheit dampff zerstrean.", "tokens": ["Wird", "doch", "ein\u00b7mal", "der", "falschheit", "dampff", "zer\u00b7stre\u00b7an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "PAV", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Aus ungeduld sein eigen hertze fressen;", "tokens": ["Aus", "un\u00b7ge\u00b7duld", "sein", "ei\u00b7gen", "hert\u00b7ze", "fres\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Heist wider sich zu felde gehn.", "tokens": ["Heist", "wi\u00b7der", "sich", "zu", "fel\u00b7de", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es mu\u00df der mensch nicht seiner selbst vergessen,", "tokens": ["Es", "mu\u00df", "der", "mensch", "nicht", "sei\u00b7ner", "selbst", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "PPOSAT", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und auf des feindes seite stehn.", "tokens": ["Und", "auf", "des", "fein\u00b7des", "sei\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn welch schiffer f\u00fchrt den kahn", "tokens": ["Denn", "welch", "schif\u00b7fer", "f\u00fchrt", "den", "kahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "ADJA", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit eignem flei\u00df auf sand und klippen an?", "tokens": ["Mit", "eig\u00b7nem", "flei\u00df", "auf", "sand", "und", "klip\u00b7pen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "VVFIN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Verzweifflung d\u00e4mpfft ohndem kein ungel\u00fccke:", "tokens": ["Ver\u00b7zweif\u00b7flung", "d\u00e4mpfft", "ohn\u00b7dem", "kein", "un\u00b7ge\u00b7l\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie sieht durch ein vergr\u00f6\u00dfrungs-glas:", "tokens": ["Sie", "sieht", "durch", "ein", "ver\u00b7gr\u00f6\u00df\u00b7rungs\u00b7glas", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie macht ein haar zu einem henckers-stricke,", "tokens": ["Sie", "macht", "ein", "haar", "zu", "ei\u00b7nem", "hen\u00b7cker\u00b7sstri\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und kennet weder ziel noch maa\u00df.", "tokens": ["Und", "ken\u00b7net", "we\u00b7der", "ziel", "noch", "maa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die geduld mu\u00df hier allein", "tokens": ["Die", "ge\u00b7duld", "mu\u00df", "hier", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Der seele lust und unsre zuslucht seyn.", "tokens": ["Der", "see\u00b7le", "lust", "und", "uns\u00b7re", "zus\u00b7lucht", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "PPOSAT", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ich will den geist nur in geduld erhalten:", "tokens": ["Ich", "will", "den", "geist", "nur", "in", "ge\u00b7duld", "er\u00b7hal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die wetter m\u00fcssen doch vergehn,", "tokens": ["Die", "wet\u00b7ter", "m\u00fcs\u00b7sen", "doch", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und solten sich auch erd\u2019 und abgrund spalten;", "tokens": ["Und", "sol\u00b7ten", "sich", "auch", "erd'", "und", "ab\u00b7grund", "spal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So bleibt gleichwol der himmel stehn.", "tokens": ["So", "bleibt", "gleich\u00b7wol", "der", "him\u00b7mel", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist der himmel nun noch da,", "tokens": ["Ist", "der", "him\u00b7mel", "nun", "noch", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "So seh\u2019 ich mich noch keinem falle nah.", "tokens": ["So", "seh'", "ich", "mich", "noch", "kei\u00b7nem", "fal\u00b7le", "nah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PIS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Was will ich mich nun in der angst verliehren?", "tokens": ["Was", "will", "ich", "mich", "nun", "in", "der", "angst", "ver\u00b7lieh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PRF", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein feind verdient die ehre nicht:", "tokens": ["Mein", "feind", "ver\u00b7dient", "die", "eh\u00b7re", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es kan sein gifft nicht an mein hertze r\u00fchren,", "tokens": ["Es", "kan", "sein", "gifft", "nicht", "an", "mein", "hert\u00b7ze", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil mir der himmel schutz verspricht.", "tokens": ["Weil", "mir", "der", "him\u00b7mel", "schutz", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Leid\u2019 ich gleich ohn alle schuld;", "tokens": ["Leid'", "ich", "gleich", "ohn", "al\u00b7le", "schuld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PIS", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "So leid\u2019 ich doch mit ruhiger geduld.", "tokens": ["So", "leid'", "ich", "doch", "mit", "ru\u00b7hi\u00b7ger", "ge\u00b7duld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}}}}