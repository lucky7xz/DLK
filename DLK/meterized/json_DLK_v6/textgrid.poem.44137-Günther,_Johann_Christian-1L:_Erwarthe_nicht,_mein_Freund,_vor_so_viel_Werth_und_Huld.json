{"textgrid.poem.44137": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Erwarthe nicht, mein Freund, vor so viel Werth und Huld", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Erwarthe nicht, mein Freund, vor so viel Werth und Huld", "tokens": ["Er\u00b7wart\u00b7he", "nicht", ",", "mein", "Freund", ",", "vor", "so", "viel", "Werth", "und", "Huld"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$,", "PPOSAT", "NN", "$,", "APPR", "ADV", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein lang und nett Geschw\u00e4z. Ich bin in deiner Schuld,", "tokens": ["Ein", "lang", "und", "nett", "Ge\u00b7schw\u00e4z", ".", "Ich", "bin", "in", "dei\u00b7ner", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "NN", "$.", "PPER", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch lieb ich dich dabey. Dies sind die reichsten Zinsen;", "tokens": ["Doch", "lieb", "ich", "dich", "da\u00b7bey", ".", "Dies", "sind", "die", "reichs\u00b7ten", "Zin\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "PRF", "PAV", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der sch\u00f6ne W\u00f6rterkram bezahlt kein Maas voll Linsen,", "tokens": ["Der", "sch\u00f6\u00b7ne", "W\u00f6r\u00b7ter\u00b7kram", "be\u00b7zahlt", "kein", "Maas", "voll", "Lin\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu schweigen Trost und Rath und allzeit gleiche Treu.", "tokens": ["Zu", "schwei\u00b7gen", "Trost", "und", "Rath", "und", "all\u00b7zeit", "glei\u00b7che", "Treu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mein Zustand ist, du weist's, das Leben; nichts dabey", "tokens": ["Mein", "Zu\u00b7stand", "ist", ",", "du", "weist's", ",", "das", "Le\u00b7ben", ";", "nichts", "da\u00b7bey"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "PPER", "VVFIN", "$,", "ART", "NN", "$.", "PIS", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als W\u00fcntsche voll Gedult, ist ja so leicht zu tragen", "tokens": ["Als", "W\u00fcnt\u00b7sche", "voll", "Ge\u00b7dult", ",", "ist", "ja", "so", "leicht", "zu", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADJD", "NN", "$,", "VAFIN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als Thraso, wenn er schwazt, und alter Leute Klagen.", "tokens": ["Als", "Thra\u00b7so", ",", "wenn", "er", "schwazt", ",", "und", "al\u00b7ter", "Leu\u00b7te", "Kla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "KOUS", "PPER", "VVFIN", "$,", "KON", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Das wi\u00dfen leider wir, ich und der Praetendent,", "tokens": ["Das", "wi\u00b7\u00dfen", "lei\u00b7der", "wir", ",", "ich", "und", "der", "Prae\u00b7ten\u00b7dent", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "$,", "PPER", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mit dem mir Gottes Zorn viel Gleichheitsehre g\u00f6nnt.", "tokens": ["Mit", "dem", "mir", "Got\u00b7tes", "Zorn", "viel", "Gleich\u00b7hei\u00b7tseh\u00b7re", "g\u00f6nnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "NN", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wir hofen beide falsch und beides in die L\u00e4nge;", "tokens": ["Wir", "ho\u00b7fen", "bei\u00b7de", "falsch", "und", "bei\u00b7des", "in", "die", "L\u00e4n\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "KON", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wir bringen nach und nach die Wirthschaft in die Enge;", "tokens": ["Wir", "brin\u00b7gen", "nach", "und", "nach", "die", "Wirth\u00b7schaft", "in", "die", "En\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "KON", "APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er soll wie ich kein Sohn des eignen Vaters seyn,", "tokens": ["Er", "soll", "wie", "ich", "kein", "Sohn", "des", "eig\u00b7nen", "Va\u00b7ters", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KOKOM", "PPER", "PIAT", "NN", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und keiner weis gewis, doch glauben wir gemein.", "tokens": ["Und", "kei\u00b7ner", "weis", "ge\u00b7wis", ",", "doch", "glau\u00b7ben", "wir", "ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PTKVZ", "VAPP", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er sucht ein gro\u00dfes Reich, ich m\u00f6cht es auch wohl haben.", "tokens": ["Er", "sucht", "ein", "gro\u00b7\u00dfes", "Reich", ",", "ich", "m\u00f6cht", "es", "auch", "wohl", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "PPER", "VMFIN", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Sehnsucht cr\u00f6nt ihn schon und mich des Phoebus Gaben.", "tokens": ["Die", "Sehn\u00b7sucht", "cr\u00f6nt", "ihn", "schon", "und", "mich", "des", "Phoe\u00b7bus", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "KON", "PRF", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er speiset Gnadenbrodt und solches auf der Flucht,", "tokens": ["Er", "spei\u00b7set", "Gna\u00b7den\u00b7brodt", "und", "sol\u00b7ches", "auf", "der", "Flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie etwan auch mein Tisch verschiedne Wirthe sucht.", "tokens": ["Wie", "et\u00b7wan", "auch", "mein", "Tisch", "ver\u00b7schied\u00b7ne", "Wirt\u00b7he", "sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Jezt n\u00e4hrt ihn Kirchengut; nechst hatt ich noch von Jauer", "tokens": ["Jezt", "n\u00e4hrt", "ihn", "Kir\u00b7chen\u00b7gut", ";", "nechst", "hatt", "ich", "noch", "von", "Jau\u00b7er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$.", "ADV", "VAFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Zw\u00f6lf S\u00e4ckel auf den Weg, es war nur wenig Dauer.", "tokens": ["Zw\u00f6lf", "S\u00e4\u00b7ckel", "auf", "den", "Weg", ",", "es", "war", "nur", "we\u00b7nig", "Dau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$,", "PPER", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Man trennt ihn von der Braut, sie mu\u00df nun in der Still", "tokens": ["Man", "trennt", "ihn", "von", "der", "Braut", ",", "sie", "mu\u00df", "nun", "in", "der", "Still"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PPER", "VMFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+++-+", "measure": "unknown.measure.septa"}, "line.22": {"text": "Den Klostermauren zu; mein M\u00e4gdgen aber will.", "tokens": ["Den", "Klos\u00b7ter\u00b7mau\u00b7ren", "zu", ";", "mein", "M\u00e4gd\u00b7gen", "a\u00b7ber", "will", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "PPOSAT", "NN", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Nur etwas l\u00e4st mich ihm nicht ganz und gar vergleichen:", "tokens": ["Nur", "et\u00b7was", "l\u00e4st", "mich", "ihm", "nicht", "ganz", "und", "gar", "ver\u00b7glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "PPER", "PTKNEG", "ADV", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der Wind verschlug sein Schif, mir will es be\u00dfer streichen;", "tokens": ["Der", "Wind", "ver\u00b7schlug", "sein", "Schif", ",", "mir", "will", "es", "be\u00b7\u00dfer", "strei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Dein Bre\u00dfler richt es wohl. Ach, w\u00e4r er jezt so gro\u00df", "tokens": ["Dein", "Bre\u00df\u00b7ler", "richt", "es", "wohl", ".", "Ach", ",", "w\u00e4r", "er", "jezt", "so", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$.", "ITJ", "$,", "VAFIN", "PPER", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und ri\u00df er noch einmahl den Rock von Pathen los,", "tokens": ["Und", "ri\u00df", "er", "noch", "ein\u00b7mahl", "den", "Rock", "von", "Pa\u00b7then", "los", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ich wollte statt des Dancks ihn nimmermehr beschweren", "tokens": ["Ich", "woll\u00b7te", "statt", "des", "Dancks", "ihn", "nim\u00b7mer\u00b7mehr", "be\u00b7schwe\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und zu so gro\u00dfer Noth den Rath nicht mehr begehren.", "tokens": ["Und", "zu", "so", "gro\u00b7\u00dfer", "Noth", "den", "Rath", "nicht", "mehr", "be\u00b7geh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "ADJA", "NN", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ja, lieber Hahn, so geht's, Wind wird auch hier zu Wind", "tokens": ["Ja", ",", "lie\u00b7ber", "Hahn", ",", "so", "geht's", ",", "Wind", "wird", "auch", "hier", "zu", "Wind"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "NE", "$,", "ADV", "VVFIN", "$,", "NN", "VAFIN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und dient nicht wie vorhin. Mein kurzes Unschlit rinnt,", "tokens": ["Und", "dient", "nicht", "wie", "vor\u00b7hin", ".", "Mein", "kur\u00b7zes", "Un\u00b7schlit", "rinnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "KOKOM", "ADV", "$.", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Als wollt es mir sogar die Freude nicht mehr g\u00f6nnen,", "tokens": ["Als", "wollt", "es", "mir", "so\u00b7gar", "die", "Freu\u00b7de", "nicht", "mehr", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "PPER", "ADV", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die stille Finstern\u00fc\u00df dir schriftlich weihn zu k\u00f6nnen.", "tokens": ["Die", "stil\u00b7le", "Fins\u00b7ter\u00b7n\u00fc\u00df", "dir", "schrift\u00b7lich", "weihn", "zu", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "ADJD", "VVINF", "PTKZU", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die Nahrung in der Welt ist oft wohl wunderlich.", "tokens": ["Die", "Nah\u00b7rung", "in", "der", "Welt", "ist", "oft", "wohl", "wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Zum Helfen w\u00fcntsch ich Gott, zum Ansehn aber dich.", "tokens": ["Zum", "Hel\u00b7fen", "w\u00fcnt\u00b7sch", "ich", "Gott", ",", "zum", "An\u00b7sehn", "a\u00b7ber", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "$,", "APPRART", "NN", "KON", "PPER", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Kein H\u00e4rchen meint es treu, sie wollen alle fliegen,", "tokens": ["Kein", "H\u00e4r\u00b7chen", "meint", "es", "treu", ",", "sie", "wol\u00b7len", "al\u00b7le", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADJD", "$,", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Nur die nicht, welche mir in Brey und Butter liegen.", "tokens": ["Nur", "die", "nicht", ",", "wel\u00b7che", "mir", "in", "Brey", "und", "But\u00b7ter", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PTKNEG", "$,", "PRELS", "PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Vom Morgen in die Nacht und durch die Nacht bis fr\u00fch", "tokens": ["Vom", "Mor\u00b7gen", "in", "die", "Nacht", "und", "durch", "die", "Nacht", "bis", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "APPR", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Schreibt Phoebus neben mir auf Bettbret, Holz und Knie.", "tokens": ["Schreibt", "Phoe\u00b7bus", "ne\u00b7ben", "mir", "auf", "Bett\u00b7bret", ",", "Holz", "und", "Knie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-----+-+-+", "measure": "dactylic.init"}, "line.39": {"text": "Sonst, glaube, wird von uns wohl wenig vorgenommen", "tokens": ["Sonst", ",", "glau\u00b7be", ",", "wird", "von", "uns", "wohl", "we\u00b7nig", "vor\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "$,", "VAFIN", "APPR", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Als leiden, hungrig seyn und t\u00e4glich gehn und kommen.", "tokens": ["Als", "lei\u00b7den", ",", "hung\u00b7rig", "seyn", "und", "t\u00e4g\u00b7lich", "gehn", "und", "kom\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "$,", "ADJD", "VAINF", "KON", "ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Wie soll ich das verstehn? Gleich, gleich, gedulde dich!", "tokens": ["Wie", "soll", "ich", "das", "ver\u00b7stehn", "?", "Gleich", ",", "gleich", ",", "ge\u00b7dul\u00b7de", "dich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PDS", "VVINF", "$.", "ADV", "$,", "ADV", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "(der Feder fehlt das Na\u00df; doch Wa\u00dfer tr\u00f6stet mich.)", "tokens": ["(", "der", "Fe\u00b7der", "fehlt", "das", "Na\u00df", ";", "doch", "Wa\u00b7\u00dfer", "tr\u00f6s\u00b7tet", "mich", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "$.", "ADV", "NN", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Drey Wochen sind es schon, seitdem ich Lauben dr\u00fccke", "tokens": ["Drey", "Wo\u00b7chen", "sind", "es", "schon", ",", "seit\u00b7dem", "ich", "Lau\u00b7ben", "dr\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VAFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und hier wohl weiter nichts als eine Ga\u00df erblicke,", "tokens": ["Und", "hier", "wohl", "wei\u00b7ter", "nichts", "als", "ei\u00b7ne", "Ga\u00df", "er\u00b7bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "PIS", "KOKOM", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Sonst komm ich nirgends hin. Ich hab ein doppelt Haus,", "tokens": ["Sonst", "komm", "ich", "nir\u00b7gends", "hin", ".", "Ich", "hab", "ein", "dop\u00b7pelt", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Zum Betteln mein ich nur; des Abends zieh ich aus", "tokens": ["Zum", "Bet\u00b7teln", "mein", "ich", "nur", ";", "des", "A\u00b7bends", "zieh", "ich", "aus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "PPOSAT", "PPER", "ADV", "$.", "ART", "NN", "VVFIN", "PPER", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Und schlafe dort bey dem. Das heist wohl recht geschoren,", "tokens": ["Und", "schla\u00b7fe", "dort", "bey", "dem", ".", "Das", "heist", "wohl", "recht", "ge\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "$.", "PDS", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.48": {"text": "Der das mit Tuchen thut, was Kutscher mit den Ohren", "tokens": ["Der", "das", "mit", "Tu\u00b7chen", "thut", ",", "was", "Kut\u00b7scher", "mit", "den", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "APPR", "NN", "VVFIN", "$,", "PWS", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Und ich der ganzen Welt und mir das Gl\u00fccke thut.", "tokens": ["Und", "ich", "der", "gan\u00b7zen", "Welt", "und", "mir", "das", "Gl\u00fc\u00b7cke", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "KON", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Nun h\u00f6re ja mit Flei\u00df: Es ist noch eine Ruth,", "tokens": ["Nun", "h\u00f6\u00b7re", "ja", "mit", "Flei\u00df", ":", "Es", "ist", "noch", "ei\u00b7ne", "Ruth", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "NN", "$.", "PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Die, seit der Corporal, ihr Mann, nicht mehr genesen,", "tokens": ["Die", ",", "seit", "der", "Cor\u00b7po\u00b7ral", ",", "ihr", "Mann", ",", "nicht", "mehr", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "$,", "PPOSAT", "NN", "$,", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Auch \u00c4hren um das Feld des Schwagers aufgelesen.", "tokens": ["Auch", "\u00c4h\u00b7ren", "um", "das", "Feld", "des", "Schwa\u00b7gers", "auf\u00b7ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Die lehnet, da\u00df ich nicht den Schlafrock schleppen darf,", "tokens": ["Die", "leh\u00b7net", ",", "da\u00df", "ich", "nicht", "den", "Schla\u00b7frock", "schlep\u00b7pen", "darf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Den Mantel, den ihr Mann bey Posen um sich warf", "tokens": ["Den", "Man\u00b7tel", ",", "den", "ihr", "Mann", "bey", "Po\u00b7sen", "um", "sich", "warf"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "APPR", "NN", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Und Schlacht und Feind verlies. So mu\u00df, um mich zu zieren,", "tokens": ["Und", "Schlacht", "und", "Feind", "ver\u00b7lies", ".", "So", "mu\u00df", ",", "um", "mich", "zu", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "$.", "ADV", "VMFIN", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "So lange Zeit vorher ein ganzes Volck verlieren.", "tokens": ["So", "lan\u00b7ge", "Zeit", "vor\u00b7her", "ein", "gan\u00b7zes", "Volck", "ver\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Bey Tage bin ich hier. Wo ist das Hier? Nicht dort.", "tokens": ["Bey", "Ta\u00b7ge", "bin", "ich", "hier", ".", "Wo", "ist", "das", "Hier", "?", "Nicht", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "$.", "PWAV", "VAFIN", "PDS", "ADV", "$.", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Da mercke, liebster Hahn, hier h\u00f6r ich fast kein Wort", "tokens": ["Da", "mer\u00b7cke", ",", "liebs\u00b7ter", "Hahn", ",", "hier", "h\u00f6r", "ich", "fast", "kein", "Wort"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Als Klagen, Leichgesang, Fluch, Elend und Bereden", "tokens": ["Als", "Kla\u00b7gen", ",", "Leich\u00b7ge\u00b7sang", ",", "Fluch", ",", "E\u00b7lend", "und", "Be\u00b7re\u00b7den"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Und, wenn es k\u00f6stlich ist, von Leinwand, Flachs und F\u00e4den.", "tokens": ["Und", ",", "wenn", "es", "k\u00f6st\u00b7lich", "ist", ",", "von", "Lein\u00b7wand", ",", "Flachs", "und", "F\u00e4\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Auch tr\u00f6stet mich kein Buch, wenn nicht von ohngefehr", "tokens": ["Auch", "tr\u00f6s\u00b7tet", "mich", "kein", "Buch", ",", "wenn", "nicht", "von", "ohn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$,", "KOUS", "PTKNEG", "APPR", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Ein Blat vom Cicero die lezte Wollust w\u00e4r.", "tokens": ["Ein", "Blat", "vom", "Ci\u00b7ce\u00b7ro", "die", "lez\u00b7te", "Wol\u00b7lust", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Es riecht nach K\u00e4sefett, mit dem es vor drey Tagen", "tokens": ["Es", "riecht", "nach", "K\u00e4\u00b7se\u00b7fett", ",", "mit", "dem", "es", "vor", "drey", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "APPR", "PRELS", "PPER", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Herr Schubarth, unser Wirth, vom Tr\u00f6del heimgetragen.", "tokens": ["Herr", "Schu\u00b7barth", ",", "un\u00b7ser", "Wirth", ",", "vom", "Tr\u00f6\u00b7del", "heim\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PPOSAT", "NN", "$,", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Du glaubst wohl nimmermehr, wie br\u00fcnstig sich mein Geist", "tokens": ["Du", "glaubst", "wohl", "nim\u00b7mer\u00b7mehr", ",", "wie", "br\u00fcns\u00b7tig", "sich", "mein", "Geist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "PWAV", "ADJD", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Durch solchen kleinen Rest des gro\u00dfen Mannes speist.", "tokens": ["Durch", "sol\u00b7chen", "klei\u00b7nen", "Rest", "des", "gro\u00b7\u00dfen", "Man\u00b7nes", "speist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Ich les es zehnmahl durch und kan doch hoch betheuren:", "tokens": ["Ich", "les", "es", "zehn\u00b7mahl", "durch", "und", "kan", "doch", "hoch", "be\u00b7theu\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "KON", "VMFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die wiederholte Lust hebt zehnmahl an zu feuren.", "tokens": ["Die", "wie\u00b7der\u00b7hol\u00b7te", "Lust", "hebt", "zehn\u00b7mahl", "an", "zu", "feu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ich lese mehr als steht, und weil ich eifrig thu,", "tokens": ["Ich", "le\u00b7se", "mehr", "als", "steht", ",", "und", "weil", "ich", "eif\u00b7rig", "thu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "KOKOM", "VVFIN", "$,", "KON", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "So bring ich aus mir selbst manch sinnreich Wort dazu", "tokens": ["So", "bring", "ich", "aus", "mir", "selbst", "manch", "sinn\u00b7reich", "Wort", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "ADV", "PIAT", "ADJD", "NN", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Und mein, ich find es da. Dies artige Betriegen", "tokens": ["Und", "mein", ",", "ich", "find", "es", "da", ".", "Dies", "ar\u00b7ti\u00b7ge", "Be\u00b7trie\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "$,", "PPER", "VVFIN", "PPER", "ADV", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Gebiehrt mir innerlich ein herzliches Vergn\u00fcgen.", "tokens": ["Ge\u00b7biehrt", "mir", "in\u00b7ner\u00b7lich", "ein", "herz\u00b7li\u00b7ches", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Hier kan ich nicht vorbey, mit Umschweif und Bem\u00fchn", "tokens": ["Hier", "kan", "ich", "nicht", "vor\u00b7bey", ",", "mit", "Um\u00b7schweif", "und", "Be\u00b7m\u00fchn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.74": {"text": "Ein Laster, dem du gram, mit Unmuth durchzuziehn.", "tokens": ["Ein", "Las\u00b7ter", ",", "dem", "du", "gram", ",", "mit", "Un\u00b7muth", "durch\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "NE", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Bey so viel Noth und Nord, die Herz und Finger schneiden,", "tokens": ["Bey", "so", "viel", "Noth", "und", "Nord", ",", "die", "Herz", "und", "Fin\u00b7ger", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "KON", "NE", "$,", "ART", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.76": {"text": "Ist, glaub ich, neben mir ein unertr\u00e4glich Leiden,", "tokens": ["Ist", ",", "glaub", "ich", ",", "ne\u00b7ben", "mir", "ein", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", "Lei\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "$,", "APPR", "PPER", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Ein rechtes Satanskind, ein ungezogen Weib,", "tokens": ["Ein", "rech\u00b7tes", "Sa\u00b7tans\u00b7kind", ",", "ein", "un\u00b7ge\u00b7zo\u00b7gen", "Weib", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Ein Bild der Gelbensucht und mehr Geripp als Leib.", "tokens": ["Ein", "Bild", "der", "Gel\u00b7ben\u00b7sucht", "und", "mehr", "Ge\u00b7ripp", "als", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "ADV", "NE", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Sie trieft von lauter Fett. Wo aber? In den Augen,", "tokens": ["Sie", "trieft", "von", "lau\u00b7ter", "Fett", ".", "Wo", "a\u00b7ber", "?", "In", "den", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$.", "PWAV", "ADV", "$.", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Die Purpurmuscheln sind und vor die Hexen taugen.", "tokens": ["Die", "Pur\u00b7pur\u00b7mu\u00b7scheln", "sind", "und", "vor", "die", "He\u00b7xen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Vor dies kan sie zwar nicht; doch weil ihr Eigensinn", "tokens": ["Vor", "dies", "kan", "sie", "zwar", "nicht", ";", "doch", "weil", "ihr", "Ei\u00b7gen\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDS", "VMFIN", "PPER", "ADV", "PTKNEG", "$.", "ADV", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Den K\u00f6rper mit beschimpft, so geht auch dies nicht hin.", "tokens": ["Den", "K\u00f6r\u00b7per", "mit", "be\u00b7schimpft", ",", "so", "geht", "auch", "dies", "nicht", "hin", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "VVPP", "$,", "ADV", "VVFIN", "ADV", "PDS", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Ich z\u00fcrne nicht vor mich, nein, wegen andrer Leute.", "tokens": ["Ich", "z\u00fcr\u00b7ne", "nicht", "vor", "mich", ",", "nein", ",", "we\u00b7gen", "an\u00b7drer", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "$,", "PTKANT", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Sie g\u00f6nnt dem Nechsten nichts, begeifert Kranz und Br\u00e4ute,", "tokens": ["Sie", "g\u00f6nnt", "dem", "Nechs\u00b7ten", "nichts", ",", "be\u00b7gei\u00b7fert", "Kranz", "und", "Br\u00e4u\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PIS", "$,", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Flucht heimlich, wenn ein Mensch ein kleines Gl\u00fcck erzehlt", "tokens": ["Flucht", "heim\u00b7lich", ",", "wenn", "ein", "Mensch", "ein", "klei\u00b7nes", "Gl\u00fcck", "er\u00b7zehlt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "$,", "KOUS", "ART", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Und wird von fremder Lust mit Bitterkeit gequ\u00e4lt.", "tokens": ["Und", "wird", "von", "frem\u00b7der", "Lust", "mit", "Bit\u00b7ter\u00b7keit", "ge\u00b7qu\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Sie knirscht, zerbei\u00dft die Hand, zeigt Rachgier \u00fcber Schaden", "tokens": ["Sie", "knirscht", ",", "zer\u00b7bei\u00dft", "die", "Hand", ",", "zeigt", "Rach\u00b7gier", "\u00fc\u00b7ber", "Scha\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,", "VVFIN", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und richtet, wer nur kommt, vom Kopfe bis zur Waden.", "tokens": ["Und", "rich\u00b7tet", ",", "wer", "nur", "kommt", ",", "vom", "Kop\u00b7fe", "bis", "zur", "Wa\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "ADV", "VVFIN", "$,", "APPRART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Bald mu\u00df der K\u00f6nig durch. Warum? Die Zeit ist schwer.", "tokens": ["Bald", "mu\u00df", "der", "K\u00f6\u00b7nig", "durch", ".", "Wa\u00b7rum", "?", "Die", "Zeit", "ist", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PTKVZ", "$.", "PWAV", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Bald heist der M\u00fcller Dieb, bald mu\u00df der B\u00e4cker her,", "tokens": ["Bald", "heist", "der", "M\u00fcl\u00b7ler", "Dieb", ",", "bald", "mu\u00df", "der", "B\u00e4\u00b7cker", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "NN", "$,", "ADV", "VMFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Bald wettern Maul und Bliz auf die, so mehr gewinnen", "tokens": ["Bald", "wet\u00b7tern", "Maul", "und", "Bliz", "auf", "die", ",", "so", "mehr", "ge\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "APPR", "ART", "$,", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Als sie mit fauler Hand und niemahls rechtem Spinnen.", "tokens": ["Als", "sie", "mit", "fau\u00b7ler", "Hand", "und", "nie\u00b7mahls", "rech\u00b7tem", "Spin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Ihr fromm-, ihr ehrlicher und wohlge\u00fcbter Mann,", "tokens": ["Ihr", "from\u00b7m", ",", "ihr", "ehr\u00b7li\u00b7cher", "und", "wohl\u00b7ge\u00b7\u00fcb\u00b7ter", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "TRUNC", "$,", "PPER", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.94": {"text": "Der allerwegen kaum mehr sehn und h\u00f6ren kan,", "tokens": ["Der", "al\u00b7ler\u00b7we\u00b7gen", "kaum", "mehr", "sehn", "und", "h\u00f6\u00b7ren", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "VVINF", "KON", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Mu\u00df, wie er gerne thut, von einer Zeit zur andern", "tokens": ["Mu\u00df", ",", "wie", "er", "ger\u00b7ne", "thut", ",", "von", "ei\u00b7ner", "Zeit", "zur", "an\u00b7dern"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,", "APPR", "ART", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "(wie oft erbarmt es mich!) nach Holz und Nahrung wandern.", "tokens": ["(", "wie", "oft", "er\u00b7barmt", "es", "mich", "!", ")", "nach", "Holz", "und", "Nah\u00b7rung", "wan\u00b7dern", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ADV", "VVFIN", "PPER", "PRF", "$.", "$(", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Sie faulenzt unterdes bey Herd und M\u00fc\u00dfiggang", "tokens": ["Sie", "fau\u00b7lenzt", "un\u00b7ter\u00b7des", "bey", "Herd", "und", "M\u00fc\u00b7\u00dfig\u00b7gang"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Und giebt ihm, kommt er sp\u00e4t, mit losen Worten Danck", "tokens": ["Und", "giebt", "ihm", ",", "kommt", "er", "sp\u00e4t", ",", "mit", "lo\u00b7sen", "Wor\u00b7ten", "Danck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Und kan doch, kostet's auch ihr hungervolles Leben,", "tokens": ["Und", "kan", "doch", ",", "kos\u00b7tet's", "auch", "ihr", "hun\u00b7ger\u00b7vol\u00b7les", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "$,", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Von selbsterworbner M\u00fch nicht einen Dreyer heben.", "tokens": ["Von", "selbs\u00b7ter\u00b7worb\u00b7ner", "M\u00fch", "nicht", "ei\u00b7nen", "Drey\u00b7er", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "ART", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Wahrhaftig, edler Hahn, der gr\u00f6ste Heldenmuth", "tokens": ["Wahr\u00b7haf\u00b7tig", ",", "ed\u00b7ler", "Hahn", ",", "der", "gr\u00f6s\u00b7te", "Hel\u00b7den\u00b7muth"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Vergeht bey solcher Angst. Nur lecken kan sie gut", "tokens": ["Ver\u00b7geht", "bey", "sol\u00b7cher", "Angst", ".", "Nur", "le\u00b7cken", "kan", "sie", "gut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$.", "ADV", "VVINF", "VMFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Und wehlen noch viel mehr und schmazen zehnmahl be\u00dfer.", "tokens": ["Und", "weh\u00b7len", "noch", "viel", "mehr", "und", "schma\u00b7zen", "zehn\u00b7mahl", "be\u00b7\u00dfer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.104": {"text": "R\u00fchrt jemand nur den Mund, so ruft sie schon: Das Me\u00dfer!", "tokens": ["R\u00fchrt", "je\u00b7mand", "nur", "den", "Mund", ",", "so", "ruft", "sie", "schon", ":", "Das", "Me\u00b7\u00dfer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Und schielt begierig hin. Ja, was der Woche soll,", "tokens": ["Und", "schielt", "be\u00b7gie\u00b7rig", "hin", ".", "Ja", ",", "was", "der", "Wo\u00b7che", "soll", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$.", "PTKANT", "$,", "PRELS", "ART", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Zehrt oft ein Abend auf. Sie ist noch wohl so toll", "tokens": ["Zehrt", "oft", "ein", "A\u00b7bend", "auf", ".", "Sie", "ist", "noch", "wohl", "so", "toll"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Und wird, so arm sie ist, viel Ehr und Furcht begehren.", "tokens": ["Und", "wird", ",", "so", "arm", "sie", "ist", ",", "viel", "Ehr", "und", "Furcht", "be\u00b7geh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,", "PIAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Bestraft sie denn ihr Mann, so f\u00e4ngt sie an zu schw\u00f6ren,", "tokens": ["Be\u00b7straft", "sie", "denn", "ihr", "Mann", ",", "so", "f\u00e4ngt", "sie", "an", "zu", "schw\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Verw\u00fcntscht den Hochzeittag und heult und \u00e4chzt und ruft", "tokens": ["Ver\u00b7w\u00fcnt\u00b7scht", "den", "Hoch\u00b7zeit\u00b7tag", "und", "heult", "und", "\u00e4chzt", "und", "ruft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.110": {"text": "Zum Zeugen b\u00f6ser Eh die Mutter aus der Gruft,", "tokens": ["Zum", "Zeu\u00b7gen", "b\u00f6\u00b7ser", "Eh", "die", "Mut\u00b7ter", "aus", "der", "Gruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Die etwan auch wie sie des Vaters Ruhm beflecket", "tokens": ["Die", "et\u00b7wan", "auch", "wie", "sie", "des", "Va\u00b7ters", "Ruhm", "be\u00b7fle\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "KOKOM", "PPER", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und also mit der Milch die Tochter angestecket.", "tokens": ["Und", "al\u00b7so", "mit", "der", "Milch", "die", "Toch\u00b7ter", "an\u00b7ge\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Ein Beyspiel ist genung: Den nechsten Ostertag", "tokens": ["Ein", "Bey\u00b7spiel", "ist", "ge\u00b7nung", ":", "Den", "nechs\u00b7ten", "Os\u00b7ter\u00b7tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Gew\u00e4hrt uns K\u00fcch und Tisch, was Hausmannskost vermag;", "tokens": ["Ge\u00b7w\u00e4hrt", "uns", "K\u00fcch", "und", "Tisch", ",", "was", "Haus\u00b7manns\u00b7kost", "ver\u00b7mag", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "NN", "KON", "NN", "$,", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Es war gering und gut, den Magen auszuf\u00fcllen.", "tokens": ["Es", "war", "ge\u00b7ring", "und", "gut", ",", "den", "Ma\u00b7gen", "aus\u00b7zu\u00b7f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Ich a\u00df mit viel Geschmack; sie sprach mit Widerwillen:", "tokens": ["Ich", "a\u00df", "mit", "viel", "Ge\u00b7schmack", ";", "sie", "sprach", "mit", "Wi\u00b7der\u00b7wil\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$.", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Ein Festtag und kein Kalb, das ist mir nie geschehn;", "tokens": ["Ein", "Fest\u00b7tag", "und", "kein", "Kalb", ",", "das", "ist", "mir", "nie", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PIAT", "NN", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Kein Fladen, lieber Gott, du lebst und kanst es sehn.", "tokens": ["Kein", "Fla\u00b7den", ",", "lie\u00b7ber", "Gott", ",", "du", "lebst", "und", "kanst", "es", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "ADV", "NN", "$,", "PPER", "VVFIN", "KON", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "O da\u00df der Teufel doch (ja, denck ich, dich zur Zinse)", "tokens": ["O", "da\u00df", "der", "Teu\u00b7fel", "doch", "(", "ja", ",", "denck", "ich", ",", "dich", "zur", "Zin\u00b7se", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ART", "NN", "ADV", "$(", "PTKANT", "$,", "PRELS", "PPER", "$,", "PRF", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Den fre\u00dfenden Accis, o schwimm, verdammte Linse!", "tokens": ["Den", "fre\u00b7\u00dfen\u00b7den", "Ac\u00b7cis", ",", "o", "schwimm", ",", "ver\u00b7damm\u00b7te", "Lin\u00b7se", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "FM", "ADJD", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Was h\u00e4tt ich wohl begehrt und solche Bettelbr\u00fch", "tokens": ["Was", "h\u00e4tt", "ich", "wohl", "be\u00b7gehrt", "und", "sol\u00b7che", "Bet\u00b7tel\u00b7br\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Vor diesem eingeschluckt? So rast und donnert sie,", "tokens": ["Vor", "die\u00b7sem", "ein\u00b7ge\u00b7schluckt", "?", "So", "rast", "und", "don\u00b7nert", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVPP", "$.", "ADV", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Das ungeheure Thier. Sollt ich es nur nicht h\u00f6ren", "tokens": ["Das", "un\u00b7ge\u00b7heu\u00b7re", "Thier", ".", "Sollt", "ich", "es", "nur", "nicht", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "VMFIN", "PPER", "PPER", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Und durch solch \u00c4rgern\u00fc\u00df mein fromm Gem\u00fcthe st\u00f6ren!", "tokens": ["Und", "durch", "solch", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "mein", "fromm", "Ge\u00b7m\u00fc\u00b7the", "st\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Ich schw\u00f6r auf ihren Gott (den Geiz, mit dem sie weint).", "tokens": ["Ich", "schw\u00f6r", "auf", "ih\u00b7ren", "Gott", "(", "den", "Geiz", ",", "mit", "dem", "sie", "weint", ")", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "W\u00e4r jemand nicht ihr Sohn und Schubarth nicht mein Freund,", "tokens": ["W\u00e4r", "je\u00b7mand", "nicht", "ihr", "Sohn", "und", "Schu\u00b7barth", "nicht", "mein", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PTKNEG", "PPOSAT", "NN", "KON", "NN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Die Feder w\u00fcrde sich vorwahr nicht halten k\u00f6nnen,", "tokens": ["Die", "Fe\u00b7der", "w\u00fcr\u00b7de", "sich", "vor\u00b7wahr", "nicht", "hal\u00b7ten", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "PTKNEG", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Sie \u00f6fentlich und frey mit Schimpf und Spott zu nennen.", "tokens": ["Sie", "\u00f6\u00b7fent\u00b7lich", "und", "frey", "mit", "Schimpf", "und", "Spott", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "ADJD", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Die Bo\u00dfheit und der Fluch verlezter Majest\u00e4t,", "tokens": ["Die", "Bo\u00df\u00b7heit", "und", "der", "Fluch", "ver\u00b7lez\u00b7ter", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Die Ehrsucht, welche sonst nach Unschuldsblute steht,", "tokens": ["Die", "Ehr\u00b7sucht", ",", "wel\u00b7che", "sonst", "nach", "Un\u00b7schulds\u00b7blu\u00b7te", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Mord, Raub und Schwelgerey sind gro\u00df- und grobe S\u00fcnden,", "tokens": ["Mord", ",", "Raub", "und", "Schwel\u00b7ge\u00b7rey", "sind", "gro\u00df", "und", "gro\u00b7be", "S\u00fcn\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VAFIN", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Doch alle sollten mich viel eher g\u00fctig finden;", "tokens": ["Doch", "al\u00b7le", "soll\u00b7ten", "mich", "viel", "e\u00b7her", "g\u00fc\u00b7tig", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Der Geiz, der Geiz allein macht den, worein er f\u00e4hrt,", "tokens": ["Der", "Geiz", ",", "der", "Geiz", "al\u00b7lein", "macht", "den", ",", "wo\u00b7rein", "er", "f\u00e4hrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "ART", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.134": {"text": "Zum Greuel aller Welt. Ich halt ihn niemahls werth,", "tokens": ["Zum", "Greu\u00b7el", "al\u00b7ler", "Welt", ".", "Ich", "halt", "ihn", "nie\u00b7mahls", "werth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PIAT", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Ich, der ich f\u00e4hig bin, auch Feinden zu vergeben,", "tokens": ["Ich", ",", "der", "ich", "f\u00e4\u00b7hig", "bin", ",", "auch", "Fein\u00b7den", "zu", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$,", "ADV", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Mit Menschen solcher Art getreu und wohl zu leben.", "tokens": ["Mit", "Men\u00b7schen", "sol\u00b7cher", "Art", "ge\u00b7treu", "und", "wohl", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "ADJD", "KON", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Ich sprizle, schelt und flieh, wo so ein Unding sizt,", "tokens": ["Ich", "spriz\u00b7le", ",", "schelt", "und", "flieh", ",", "wo", "so", "ein", "Un\u00b7ding", "sizt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Mit gr\u00f6\u00dfrem Schauder fort, als wo ein Drache blizt,", "tokens": ["Mit", "gr\u00f6\u00df\u00b7rem", "Schau\u00b7der", "fort", ",", "als", "wo", "ein", "Dra\u00b7che", "blizt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,", "KOUS", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Und will mich lieber selbst auf Maul und Antliz schlagen", "tokens": ["Und", "will", "mich", "lie\u00b7ber", "selbst", "auf", "Maul", "und", "Ant\u00b7liz", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Als, kennst du \u2013 \u2013 \u2013 \u2013? und seines gleichen, tragen.", "tokens": ["Als", ",", "kennst", "du", "\u2013", "\u2013", "\u2013", "\u2013", "?", "und", "sei\u00b7nes", "glei\u00b7chen", ",", "tra\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "$,", "VVFIN", "PPER", "$(", "$(", "$(", "$(", "$.", "KON", "PPOSAT", "ADJA", "$,", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.141": {"text": "Da hastu meine Qual, du Schwester armer Kunst,", "tokens": ["Da", "has\u00b7tu", "mei\u00b7ne", "Qual", ",", "du", "Schwes\u00b7ter", "ar\u00b7mer", "Kunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "PPER", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Und forderstu Bericht nach angebohrner Gunst,", "tokens": ["Und", "for\u00b7ders\u00b7tu", "Be\u00b7richt", "nach", "an\u00b7ge\u00b7bohr\u00b7ner", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Was ich doch wohl dabey noch vor Kalender mache?", "tokens": ["Was", "ich", "doch", "wohl", "da\u00b7bey", "noch", "vor", "Ka\u00b7len\u00b7der", "ma\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "PAV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.144": {"text": "Wer bin ich? G\u00fcnther. Gut, was fragst du viel? Ich lache", "tokens": ["Wer", "bin", "ich", "?", "G\u00fcn\u00b7ther", ".", "Gut", ",", "was", "fragst", "du", "viel", "?", "Ich", "la\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "$.", "NE", "$.", "ADJD", "$,", "PWS", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Und seh die ganze Welt, auch mich, vor th\u00f6richt an,", "tokens": ["Und", "seh", "die", "gan\u00b7ze", "Welt", ",", "auch", "mich", ",", "vor", "th\u00f6\u00b7richt", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "PPER", "$,", "APPR", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Sie, weil sie nicht genung und richtig w\u00fcntschen kan,", "tokens": ["Sie", ",", "weil", "sie", "nicht", "ge\u00b7nung", "und", "rich\u00b7tig", "w\u00fcnt\u00b7schen", "kan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "KON", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Mich, weil ich nicht vermag, die Narren scharf zu kr\u00e4ncken.", "tokens": ["Mich", ",", "weil", "ich", "nicht", "ver\u00b7mag", ",", "die", "Nar\u00b7ren", "scharf", "zu", "kr\u00e4n\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Sie sch\u00e4umen, das ist nichts, sie sollten sich erhencken,", "tokens": ["Sie", "sch\u00e4u\u00b7men", ",", "das", "ist", "nichts", ",", "sie", "soll\u00b7ten", "sich", "er\u00b7hen\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PDS", "VAFIN", "PIS", "$,", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Das zierte meinen Reim. Wer weis, was noch geschieht!", "tokens": ["Das", "zier\u00b7te", "mei\u00b7nen", "Reim", ".", "Wer", "weis", ",", "was", "noch", "ge\u00b7schieht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$.", "PWS", "PTKVZ", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Du kennst den \u2013 \u2013 \u2013, der Stockfisch ist gebr\u00fcht,", "tokens": ["Du", "kennst", "den", "\u2013", "\u2013", "\u2013", ",", "der", "Stock\u00b7fisch", "ist", "ge\u00b7br\u00fcht", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "$(", "$(", "$(", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.151": {"text": "Die W\u00fcrze fehlt mir noch, ihn vollends gar zu kochen,", "tokens": ["Die", "W\u00fcr\u00b7ze", "fehlt", "mir", "noch", ",", "ihn", "vol\u00b7lends", "gar", "zu", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Und darauf schenck ich ihn Lucinden in die Wochen,", "tokens": ["Und", "da\u00b7rauf", "schenck", "ich", "ihn", "Lu\u00b7cin\u00b7den", "in", "die", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PPER", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Vor die sein Midas ficht. Die Sachen sind schon alt.", "tokens": ["Vor", "die", "sein", "Mi\u00b7das", "ficht", ".", "Die", "Sa\u00b7chen", "sind", "schon", "alt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Me\u00fci Freund, gieb neuen Stof, sieh, h\u00f6re, schreib, und bald", "tokens": ["Me\u00b7\u00fci", "Freund", ",", "gieb", "neu\u00b7en", "Stof", ",", "sieh", ",", "h\u00f6\u00b7re", ",", "schreib", ",", "und", "bald"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "VVIMP", "ADJA", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "KON", "ADV"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.155": {"text": "Und viel und oft und gern, erforsche viel Gem\u00fcther,", "tokens": ["Und", "viel", "und", "oft", "und", "gern", ",", "er\u00b7for\u00b7sche", "viel", "Ge\u00b7m\u00fc\u00b7ther", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "KON", "ADV", "$,", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Der Testamente List, die Pracht erlogner G\u00fcter,", "tokens": ["Der", "Tes\u00b7ta\u00b7men\u00b7te", "List", ",", "die", "Pracht", "er\u00b7log\u00b7ner", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Der Menschen Heucheley, der M\u00e4gdgen Flehn und Pein,", "tokens": ["Der", "Men\u00b7schen", "Heu\u00b7che\u00b7ley", ",", "der", "M\u00e4gd\u00b7gen", "Flehn", "und", "Pein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "VVINF", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Der Weiber Heimligkeit, der Narren Zeterschreyn,", "tokens": ["Der", "Wei\u00b7ber", "Heim\u00b7lig\u00b7keit", ",", "der", "Nar\u00b7ren", "Ze\u00b7ter\u00b7schreyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Der \u00c4rzte g\u00fcldne Kunst, der Richter schlimme R\u00e4ncke,", "tokens": ["Der", "\u00c4rz\u00b7te", "g\u00fcld\u00b7ne", "Kunst", ",", "der", "Rich\u00b7ter", "schlim\u00b7me", "R\u00e4n\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Gespr\u00e4che, kalten Scherz und tausend andre Schw\u00e4ncke,", "tokens": ["Ge\u00b7spr\u00e4\u00b7che", ",", "kal\u00b7ten", "Scherz", "und", "tau\u00b7send", "and\u00b7re", "Schw\u00e4n\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "KON", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Dies alles schreib genau; denn wenn ich m\u00fcde bin,", "tokens": ["Dies", "al\u00b7les", "schreib", "ge\u00b7nau", ";", "denn", "wenn", "ich", "m\u00fc\u00b7de", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "ADJD", "$.", "KON", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Der Helden ihren Ruhm in Versen hochzuziehn,", "tokens": ["Der", "Hel\u00b7den", "ih\u00b7ren", "Ruhm", "in", "Ver\u00b7sen", "hoch\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "So zeigt mein Satyr gern dem Auge sp\u00e4ter Zeiten,", "tokens": ["So", "zeigt", "mein", "Sa\u00b7tyr", "gern", "dem", "Au\u00b7ge", "sp\u00e4\u00b7ter", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Giebt Phoebus Zeit und Lust, geheime Kleinigkeiten,", "tokens": ["Giebt", "Phoe\u00b7bus", "Zeit", "und", "Lust", ",", "ge\u00b7hei\u00b7me", "Klei\u00b7nig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "KON", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Den Lauf, die Lebensart und Laster unsrer Welt,", "tokens": ["Den", "Lauf", ",", "die", "Le\u00b7ben\u00b7sart", "und", "Las\u00b7ter", "uns\u00b7rer", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Die, wer Geschichte schreibt, nicht eben w\u00fcrdig h\u00e4lt,", "tokens": ["Die", ",", "wer", "Ge\u00b7schich\u00b7te", "schreibt", ",", "nicht", "e\u00b7ben", "w\u00fcr\u00b7dig", "h\u00e4lt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWS", "NN", "VVFIN", "$,", "PTKNEG", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Und die gleichwohl einmahl (ein Kluger mag sie sch\u00e4zen)", "tokens": ["Und", "die", "gleich\u00b7wohl", "ein\u00b7mahl", "(", "ein", "Klu\u00b7ger", "mag", "sie", "sch\u00e4\u00b7zen", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADV", "$(", "ART", "NN", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Noch manchen Kopf vielleicht so be\u00dfern als erg\u00f6zen.", "tokens": ["Noch", "man\u00b7chen", "Kopf", "viel\u00b7leicht", "so", "be\u00b7\u00dfern", "als", "er\u00b7g\u00f6\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADV", "ADV", "ADJD", "KOKOM", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}