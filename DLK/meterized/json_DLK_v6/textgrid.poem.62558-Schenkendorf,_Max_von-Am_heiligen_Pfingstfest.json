{"textgrid.poem.62558": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "Am heiligen Pfingstfest", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du bist nicht ganz von uns geschieden,", "tokens": ["Du", "bist", "nicht", "ganz", "von", "uns", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du nimmst dich unser ewig an,", "tokens": ["Du", "nimmst", "dich", "un\u00b7ser", "e\u00b7wig", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dein gro\u00dfes Herz ist nicht zufrieden", "tokens": ["Dein", "gro\u00b7\u00dfes", "Herz", "ist", "nicht", "zu\u00b7frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit allem, was es schon gethan.", "tokens": ["Mit", "al\u00b7lem", ",", "was", "es", "schon", "ge\u00b7than", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Du hast den Tr\u00f6ster uns gesendet,", "tokens": ["Du", "hast", "den", "Tr\u00f6s\u00b7ter", "uns", "ge\u00b7sen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den scharfen, reinen, klaren Geist,", "tokens": ["Den", "schar\u00b7fen", ",", "rei\u00b7nen", ",", "kla\u00b7ren", "Geist", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Licht und Trost und Wahrheit spendet,", "tokens": ["Der", "Licht", "und", "Trost", "und", "Wahr\u00b7heit", "spen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und deine Zukunft uns verhei\u00dft.", "tokens": ["Und", "dei\u00b7ne", "Zu\u00b7kunft", "uns", "ver\u00b7hei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "O, jede Seele sei ihm offen,", "tokens": ["O", ",", "je\u00b7de", "See\u00b7le", "sei", "ihm", "of\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PIAT", "NN", "VAFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem werthen, gottgesandten Freund,", "tokens": ["Dem", "wert\u00b7hen", ",", "gott\u00b7ge\u00b7sand\u00b7ten", "Freund", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er st\u00e4rke unser liebend Hoffen,", "tokens": ["Er", "st\u00e4r\u00b7ke", "un\u00b7ser", "lie\u00b7bend", "Hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bis der Geliebte selbst erscheint.", "tokens": ["Bis", "der", "Ge\u00b7lieb\u00b7te", "selbst", "er\u00b7scheint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}