{"textgrid.poem.53007": {"metadata": {"author": {"name": "Seume, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du wagsts, in Bedlam noch, dich mit Vernunft zu br\u00fcsten,", "genre": "verse", "period": "N.A.", "pub_year": 1786, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du wagsts, in Bedlam noch, dich mit Vernunft zu br\u00fcsten,", "tokens": ["Du", "wagsts", ",", "in", "Be\u00b7dlam", "noch", ",", "dich", "mit", "Ver\u00b7nunft", "zu", "br\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "NN", "ADV", "$,", "PRF", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Tief tief verworfenes Geschlecht?", "tokens": ["Tief", "tief", "ver\u00b7wor\u00b7fe\u00b7nes", "Ge\u00b7schlecht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Pygm\u00e4isch stehst du da auf deinen Schauger\u00fcsten,", "tokens": ["Pyg\u00b7m\u00e4\u00b7isch", "stehst", "du", "da", "auf", "dei\u00b7nen", "Schau\u00b7ge\u00b7r\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur als Tyrann und Knecht.", "tokens": ["Nur", "als", "Ty\u00b7rann", "und", "Knecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der Unsinn g\u00e4ngelt dich am Zaum der Vorurtheile,", "tokens": ["Der", "Un\u00b7sinn", "g\u00e4n\u00b7gelt", "dich", "am", "Zaum", "der", "Vor\u00b7urt\u00b7hei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An dem du hemionisch gehst,", "tokens": ["An", "dem", "du", "he\u00b7mi\u00b7o\u00b7nisch", "gehst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df nicht die schwere Hand des Gei\u00dflers dich ereile,", "tokens": ["Da\u00df", "nicht", "die", "schwe\u00b7re", "Hand", "des", "Gei\u00df\u00b7lers", "dich", "er\u00b7ei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn du den Schedel drehst.", "tokens": ["Wenn", "du", "den", "Sche\u00b7del", "drehst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Du kniest, vor Angst verstummt, vor jedem Nebelg\u00f6tzen,", "tokens": ["Du", "kniest", ",", "vor", "Angst", "ver\u00b7stummt", ",", "vor", "je\u00b7dem", "Ne\u00b7bel\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "NN", "VVFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den dir Dalai Lama gab,", "tokens": ["Den", "dir", "Da\u00b7lai", "La\u00b7ma", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NE", "NE", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und folgest allem blind, was deine Gaukler setzen,", "tokens": ["Und", "fol\u00b7gest", "al\u00b7lem", "blind", ",", "was", "dei\u00b7ne", "Gauk\u00b7ler", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADJD", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zur Unvernunft hinab.", "tokens": ["Zur", "Un\u00b7ver\u00b7nunft", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Du irrst, Insecten gleich, um eine Feuerflamme,", "tokens": ["Du", "irrst", ",", "In\u00b7sec\u00b7ten", "gleich", ",", "um", "ei\u00b7ne", "Feu\u00b7er\u00b7flam\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "ADV", "$,", "KOUI", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verbrennst die Schwingen, f\u00e4llst und fluchst", "tokens": ["Ver\u00b7brennst", "die", "Schwin\u00b7gen", ",", "f\u00e4llst", "und", "fluchst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem g\u00f6ttlichen Geschenk in deines Unwerths Schlamme,", "tokens": ["Dem", "g\u00f6tt\u00b7li\u00b7chen", "Ge\u00b7schenk", "in", "dei\u00b7nes", "Un\u00b7werths", "Schlam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In dem du Rettung suchst.", "tokens": ["In", "dem", "du", "Ret\u00b7tung", "suchst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Vom \u00e4ltsten Nimrod an bis auf die neuste Krone", "tokens": ["Vom", "\u00e4lts\u00b7ten", "Nim\u00b7rod", "an", "bis", "auf", "die", "neus\u00b7te", "Kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bestimmt der Dolch was Recht soll seyn,", "tokens": ["Be\u00b7stimmt", "der", "Dolch", "was", "Recht", "soll", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PWS", "NN", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schreibet es in Blut; und Weh dem Ungl\u00fcckssohne,", "tokens": ["Und", "schrei\u00b7bet", "es", "in", "Blut", ";", "und", "Weh", "dem", "Un\u00b7gl\u00fccks\u00b7soh\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$.", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "F\u00e4llt ihm ein Zweifel ein.", "tokens": ["F\u00e4llt", "ihm", "ein", "Zwei\u00b7fel", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der eine zieht am Joch, damit der andre schwelge", "tokens": ["Der", "ei\u00b7ne", "zieht", "am", "Joch", ",", "da\u00b7mit", "der", "and\u00b7re", "schwel\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "APPRART", "NN", "$,", "KOUS", "ART", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wagts der Sclav und blickt empor", "tokens": ["Und", "wagts", "der", "Sclav", "und", "blickt", "em\u00b7por"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um Trost und Licht, zerbricht des Herrschers Eisenfelge", "tokens": ["Um", "Trost", "und", "Licht", ",", "zer\u00b7bricht", "des", "Herr\u00b7schers", "Ei\u00b7sen\u00b7fel\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "KON", "NN", "$,", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihn, wie der Hagel Rohr.", "tokens": ["Ihn", ",", "wie", "der", "Ha\u00b7gel", "Rohr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWAV", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wo lebten je bey euch des Himmels Lieblingskinder,", "tokens": ["Wo", "leb\u00b7ten", "je", "bey", "euch", "des", "Him\u00b7mels", "Lieb\u00b7lings\u00b7kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "APPR", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie, Freyheit und Gerechtigkeit?", "tokens": ["Sie", ",", "Frey\u00b7heit", "und", "Ge\u00b7rech\u00b7tig\u00b7keit", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie blickten nur herab auf eine Welt voll S\u00fcnder,", "tokens": ["Sie", "blick\u00b7ten", "nur", "her\u00b7ab", "auf", "ei\u00b7ne", "Welt", "voll", "S\u00fcn\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und flohn mit Traurigkeit.", "tokens": ["Und", "flohn", "mit", "Trau\u00b7rig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Kaum blieb ihr Bild zur\u00fcck in diesen Regionen,", "tokens": ["Kaum", "blieb", "ihr", "Bild", "zu\u00b7r\u00fcck", "in", "die\u00b7sen", "Re\u00b7gi\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das man nur selten ehrt und liebt.", "tokens": ["Das", "man", "nur", "sel\u00b7ten", "ehrt", "und", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "ADV", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Selbst Aristides mu\u00df die B\u00f6sewichter schonen,", "tokens": ["Selbst", "A\u00b7ris\u00b7ti\u00b7des", "mu\u00df", "die", "B\u00f6\u00b7se\u00b7wich\u00b7ter", "scho\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Damit man ihm vergibt.", "tokens": ["Da\u00b7mit", "man", "ihm", "ver\u00b7gibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und endlich treibt das Volk, Emblem der Weltgeschichte,", "tokens": ["Und", "end\u00b7lich", "treibt", "das", "Volk", ",", "Em\u00b7blem", "der", "Welt\u00b7ge\u00b7schich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$,", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Aus seinem Kreis den reinen Mann;", "tokens": ["Aus", "sei\u00b7nem", "Kreis", "den", "rei\u00b7nen", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil es das Strafgericht von seinem Angesichte", "tokens": ["Weil", "es", "das", "Straf\u00b7ge\u00b7richt", "von", "sei\u00b7nem", "An\u00b7ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht mehr ertragen kann.", "tokens": ["Nicht", "mehr", "er\u00b7tra\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Man stellt mit feilem Hohn in der Zerst\u00f6rer Ehre", "tokens": ["Man", "stellt", "mit", "fei\u00b7lem", "Hohn", "in", "der", "Zer\u00b7st\u00f6\u00b7rer", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ADJA", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Menschensinnes Brandmark auf;", "tokens": ["Des", "Men\u00b7schen\u00b7sin\u00b7nes", "Brand\u00b7mark", "auf", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und eilt verr\u00fcckt, als ob der Frevel Wohlthat w\u00e4re,", "tokens": ["Und", "eilt", "ver\u00b7r\u00fcckt", ",", "als", "ob", "der", "Fre\u00b7vel", "Wohlt\u00b7hat", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "KOKOM", "KOUS", "ART", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu dem Idol hinauf.", "tokens": ["Zu", "dem", "I\u00b7dol", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.11": {"line.1": {"text": "Die Zwingherrnkunst und Herrschbegier gewannen", "tokens": ["Die", "Zwing\u00b7herrn\u00b7kunst", "und", "Herrschbe\u00b7gier", "ge\u00b7wan\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nur durch der Andern Sch\u00e4ndlichkeit:", "tokens": ["Nur", "durch", "der", "An\u00b7dern", "Sch\u00e4nd\u00b7lich\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sclaven werden erst, dann werden die Tyrannen;", "tokens": ["Die", "Scla\u00b7ven", "wer\u00b7den", "erst", ",", "dann", "wer\u00b7den", "die", "Ty\u00b7ran\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und schnell zu gleicher Zeit.", "tokens": ["Und", "schnell", "zu", "glei\u00b7cher", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Despoten spotten hoch, und dann Oligokraten,", "tokens": ["Des\u00b7po\u00b7ten", "spot\u00b7ten", "hoch", ",", "und", "dann", "O\u00b7li\u00b7go\u00b7kra\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,", "KON", "ADV", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und dann des P\u00f6bels Hefensatz:", "tokens": ["Und", "dann", "des", "P\u00f6\u00b7bels", "He\u00b7fen\u00b7satz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann kommt ein Demagog und setzt mit Frevelthaten", "tokens": ["Dann", "kommt", "ein", "De\u00b7ma\u00b7gog", "und", "setzt", "mit", "Fre\u00b7vel\u00b7tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich auf den alten Platz.", "tokens": ["Sich", "auf", "den", "al\u00b7ten", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Viel Gr\u00e4uel hatte schon mit seines Lictors Beilen", "tokens": ["Viel", "Gr\u00e4u\u00b7el", "hat\u00b7te", "schon", "mit", "sei\u00b7nes", "Lic\u00b7tors", "Bei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Sulla W\u00fcrgerblick gethan;", "tokens": ["Des", "Sul\u00b7la", "W\u00fcr\u00b7ger\u00b7blick", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch schmeichelnd giftiger schlug Wunden, die nicht heilen,", "tokens": ["Doch", "schmei\u00b7chelnd", "gif\u00b7ti\u00b7ger", "schlug", "Wun\u00b7den", ",", "die", "nicht", "hei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "VVFIN", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Knab' Octavian.", "tokens": ["Der", "Knab'", "Oc\u00b7ta\u00b7vi\u00b7an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Der Bonzen Gaunerey erzwang das Austernleben,", "tokens": ["Der", "Bon\u00b7zen", "Gau\u00b7ne\u00b7rey", "er\u00b7zwang", "das", "Aus\u00b7tern\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und st\u00e4mpelte den Mann zum Schaf,", "tokens": ["Und", "st\u00e4m\u00b7pel\u00b7te", "den", "Mann", "zum", "Schaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schuf oft S\u00fcnde, nur um S\u00fcnde zu vergeben,", "tokens": ["Und", "schuf", "oft", "S\u00fcn\u00b7de", ",", "nur", "um", "S\u00fcn\u00b7de", "zu", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NN", "$,", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Ruh zu Todesschlaf.", "tokens": ["Und", "Ruh", "zu", "To\u00b7des\u00b7schlaf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Ihr waret stolz und k\u00fchn mit euern Meteoren,", "tokens": ["Ihr", "wa\u00b7ret", "stolz", "und", "k\u00fchn", "mit", "eu\u00b7ern", "Me\u00b7te\u00b7o\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und prunktet mit Philosophie:", "tokens": ["Und", "prunk\u00b7tet", "mit", "Phi\u00b7lo\u00b7so\u00b7phie", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hat das neue Licht sich wieder schnell verloren", "tokens": ["Wie", "hat", "das", "neu\u00b7e", "Licht", "sich", "wie\u00b7der", "schnell", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "PRF", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In alte Phrenesie!", "tokens": ["In", "al\u00b7te", "Phre\u00b7ne\u00b7sie", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Man k\u00f6derte die Welt mit reinen Freyheit Golde,", "tokens": ["Man", "k\u00f6\u00b7der\u00b7te", "die", "Welt", "mit", "rei\u00b7nen", "Frey\u00b7heit", "Gol\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dolchte sie in Sclaverey;", "tokens": ["Und", "dolch\u00b7te", "sie", "in", "Scla\u00b7ve\u00b7rey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hier h\u00e4lt Despotie des Helfers Faust im Solde,", "tokens": ["Und", "hier", "h\u00e4lt", "Des\u00b7po\u00b7tie", "des", "Hel\u00b7fers", "Faust", "im", "Sol\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ART", "NN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hier die Klerisey.", "tokens": ["Und", "hier", "die", "Kle\u00b7ri\u00b7sey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Wir k\u00f6nnen also nicht das Tagelicht ertragen,", "tokens": ["Wir", "k\u00f6n\u00b7nen", "al\u00b7so", "nicht", "das", "Ta\u00b7ge\u00b7licht", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da man uns in die Nacht verst\u00f6\u00dft;", "tokens": ["Da", "man", "uns", "in", "die", "Nacht", "ver\u00b7st\u00f6\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ewig m\u00fcssen wir das gro\u00dfe R\u00e4thsel wagen,", "tokens": ["Und", "e\u00b7wig", "m\u00fcs\u00b7sen", "wir", "das", "gro\u00b7\u00dfe", "R\u00e4th\u00b7sel", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das ewig sich nicht l\u00f6st!", "tokens": ["Das", "e\u00b7wig", "sich", "nicht", "l\u00f6st", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Vom Erdengott herab bis zu dem Dorftyrannen", "tokens": ["Vom", "Er\u00b7den\u00b7gott", "her\u00b7ab", "bis", "zu", "dem", "Dorf\u00b7ty\u00b7ran\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Spricht Willk\u00fchr ungleich nur nach Gunst,", "tokens": ["Spricht", "Will\u00b7k\u00fchr", "un\u00b7gleich", "nur", "nach", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADJD", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und webt das feine Garn, das ihre S\u00f6ldner spannen,", "tokens": ["Und", "webt", "das", "fei\u00b7ne", "Garn", ",", "das", "ih\u00b7re", "S\u00f6ld\u00b7ner", "span\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit tief gelegter Kunst.", "tokens": ["Mit", "tief", "ge\u00b7leg\u00b7ter", "Kunst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Die gro\u00dfe Schickung lag in eines Mannes H\u00e4nden:", "tokens": ["Die", "gro\u00b7\u00dfe", "Schi\u00b7ckung", "lag", "in", "ei\u00b7nes", "Man\u00b7nes", "H\u00e4n\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der sollte wie ein Heiland seyn.", "tokens": ["Der", "soll\u00b7te", "wie", "ein", "Hei\u00b7land", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "KOKOM", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er fing es g\u00f6ttlich an; doch g\u00f6ttlich zu vollenden", "tokens": ["Er", "fing", "es", "g\u00f6tt\u00b7lich", "an", ";", "doch", "g\u00f6tt\u00b7lich", "zu", "voll\u00b7en\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "ADV", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "War noch sein Geist zu klein.", "tokens": ["War", "noch", "sein", "Geist", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Noch nie schien das Geschlecht, von seinem Werthe trunken,", "tokens": ["Noch", "nie", "schien", "das", "Ge\u00b7schlecht", ",", "von", "sei\u00b7nem", "Wert\u00b7he", "trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So hoch im Strahlenkreis zu stehn:", "tokens": ["So", "hoch", "im", "Strah\u00b7len\u00b7kreis", "zu", "stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nie ist es so tief in Kriechsucht hingesunken,", "tokens": ["Und", "nie", "ist", "es", "so", "tief", "in", "Kriech\u00b7sucht", "hin\u00b7ge\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Um tiefer noch zu gehn.", "tokens": ["Um", "tie\u00b7fer", "noch", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Des Menschen Leidenschaft ist, hat sie nur erst Nahrung,", "tokens": ["Des", "Men\u00b7schen", "Lei\u00b7den\u00b7schaft", "ist", ",", "hat", "sie", "nur", "erst", "Nah\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "VAFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Krebsgeschw\u00fcres Prototyp.", "tokens": ["Des", "Krebs\u00b7ge\u00b7schw\u00fc\u00b7res", "Pro\u00b7to\u00b7typ", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was sich dem Arme naht, das lehret die Erfahrung,", "tokens": ["Was", "sich", "dem", "Ar\u00b7me", "naht", ",", "das", "leh\u00b7ret", "die", "Er\u00b7fah\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ART", "NN", "VVFIN", "$,", "PDS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verzehret der Polyp.", "tokens": ["Ver\u00b7zeh\u00b7ret", "der", "Po\u00b7lyp", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Les't die Annalen durch von Cyrus bis auf gestern,", "tokens": ["Les't", "die", "An\u00b7na\u00b7len", "durch", "von", "Cy\u00b7rus", "bis", "auf", "ge\u00b7stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "APPR", "NE", "ADV", "APPR", "ADJA", "$,"], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Und sprecht dann von Gerechtigkeit.", "tokens": ["Und", "sprecht", "dann", "von", "Ge\u00b7rech\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man stellt ihr Bildni\u00df auf; und eilet es zu l\u00e4stern,", "tokens": ["Man", "stellt", "ihr", "Bild\u00b7ni\u00df", "auf", ";", "und", "ei\u00b7let", "es", "zu", "l\u00e4s\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "KON", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo man es eingeweiht.", "tokens": ["Wo", "man", "es", "ein\u00b7ge\u00b7weiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Man ehrt die G\u00f6ttinn laut, und h\u00f6hnt sie dann mit Thaten,", "tokens": ["Man", "ehrt", "die", "G\u00f6t\u00b7tinn", "laut", ",", "und", "h\u00f6hnt", "sie", "dann", "mit", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADJD", "$,", "KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Ariman nicht schw\u00e4rzer sinnt:", "tokens": ["Die", "A\u00b7ri\u00b7man", "nicht", "schw\u00e4r\u00b7zer", "sinnt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man spricht von Menschenrecht, und hat es schon verrathen,", "tokens": ["Man", "spricht", "von", "Men\u00b7schen\u00b7recht", ",", "und", "hat", "es", "schon", "ver\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "$,", "KON", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Eh noch der Ton zerrinnt.", "tokens": ["Eh", "noch", "der", "Ton", "zer\u00b7rinnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.24": {"line.1": {"text": "Mit M\u00e4klergeiste schrey'n die Afterpatrioten,", "tokens": ["Mit", "M\u00e4k\u00b7ler\u00b7geis\u00b7te", "schrey'n", "die", "Af\u00b7ter\u00b7pat\u00b7ri\u00b7o\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als bauten sie des Welttheils Gl\u00fcck,", "tokens": ["Als", "bau\u00b7ten", "sie", "des", "Welt\u00b7theils", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sinken in den Staub, ver\u00e4chtliche Heloten,", "tokens": ["Und", "sin\u00b7ken", "in", "den", "Staub", ",", "ver\u00b7\u00e4cht\u00b7li\u00b7che", "He\u00b7lo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Um einen Gnadenblick.", "tokens": ["Um", "ei\u00b7nen", "Gna\u00b7den\u00b7blick", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Wer in dem Knechtsgef\u00fchl des Jammers seiner S\u00fcnde", "tokens": ["Wer", "in", "dem", "Knechts\u00b7ge\u00b7f\u00fchl", "des", "Jam\u00b7mers", "sei\u00b7ner", "S\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zuerst ans Licht die Gnade trug,", "tokens": ["Zu\u00b7erst", "ans", "Licht", "die", "Gna\u00b7de", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verdient, da\u00df ihm der Geist das Schrecklichste verk\u00fcnde,", "tokens": ["Ver\u00b7di\u00b7ent", ",", "da\u00df", "ihm", "der", "Geist", "das", "Schreck\u00b7lichs\u00b7te", "ver\u00b7k\u00fcn\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wenn seine Stunde schlug.", "tokens": ["Wenn", "sei\u00b7ne", "Stun\u00b7de", "schlug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Hier w\u00fcrgte man am Flu\u00df mit einer Freyheitsfahne;", "tokens": ["Hier", "w\u00fcrg\u00b7te", "man", "am", "Flu\u00df", "mit", "ei\u00b7ner", "Frey\u00b7he\u00b7its\u00b7fah\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und focht ergrimmt um gleiches Recht,", "tokens": ["Und", "focht", "er\u00b7grimmt", "um", "glei\u00b7ches", "Recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schleppt, mit Schande schwer, dort durch die Oceane", "tokens": ["Und", "schleppt", ",", "mit", "Schan\u00b7de", "schwer", ",", "dort", "durch", "die", "O\u00b7cea\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "APPR", "NN", "ADJD", "$,", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Das Negervolk als Knecht.", "tokens": ["Das", "Ne\u00b7ger\u00b7volk", "als", "Knecht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Wenn uns ein Funke blickt von Gottes Flammensonne,", "tokens": ["Wenn", "uns", "ein", "Fun\u00b7ke", "blickt", "von", "Got\u00b7tes", "Flam\u00b7men\u00b7son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erstickt ihn pl\u00f6tzlich eine Zunft;", "tokens": ["Er\u00b7stickt", "ihn", "pl\u00f6tz\u00b7lich", "ei\u00b7ne", "Zunft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wem kein Heerszug folgt mit Waffen von Bayonne,", "tokens": ["Und", "wem", "kein", "Heers\u00b7zug", "folgt", "mit", "Waf\u00b7fen", "von", "Ba\u00b7yon\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIAT", "NN", "VVFIN", "APPR", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der spricht umsonst Vernunft.", "tokens": ["Der", "spricht", "um\u00b7sonst", "Ver\u00b7nunft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Was bleibet uns zum Trost? Nur noch die holde Sch\u00f6ne,", "tokens": ["Was", "blei\u00b7bet", "uns", "zum", "Trost", "?", "Nur", "noch", "die", "hol\u00b7de", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPRART", "NN", "$.", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die uns der alte Mythus zeigt:", "tokens": ["Die", "uns", "der", "al\u00b7te", "My\u00b7thus", "zeigt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vielleicht da\u00df Harmonie noch aus dem Mi\u00dfget\u00f6ne", "tokens": ["Viel\u00b7leicht", "da\u00df", "Har\u00b7mo\u00b7nie", "noch", "aus", "dem", "Mi\u00df\u00b7ge\u00b7t\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des gro\u00dfen Chaos steigt.", "tokens": ["Des", "gro\u00b7\u00dfen", "Chaos", "steigt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.29": {"line.1": {"text": "Ich geh; wer wei\u00df, wohin? Gewi\u00df zu meinen V\u00e4tern.", "tokens": ["Ich", "geh", ";", "wer", "wei\u00df", ",", "wo\u00b7hin", "?", "Ge\u00b7wi\u00df", "zu", "mei\u00b7nen", "V\u00e4\u00b7tern", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "VVFIN", "$,", "PWAV", "$.", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vielleicht da\u00df ein Centraljahr kommt,", "tokens": ["Viel\u00b7leicht", "da\u00df", "ein", "Cent\u00b7ral\u00b7jahr", "kommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wo noch der Kampf zuletzt mit Narrn und Misseth\u00e4tern", "tokens": ["Wo", "noch", "der", "Kampf", "zu\u00b7letzt", "mit", "Narrn", "und", "Mis\u00b7set\u00b7h\u00e4\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Guten besser frommt.", "tokens": ["Den", "Gu\u00b7ten", "bes\u00b7ser", "frommt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}