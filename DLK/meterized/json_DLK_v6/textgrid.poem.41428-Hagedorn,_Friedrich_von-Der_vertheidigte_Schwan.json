{"textgrid.poem.41428": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der vertheidigte Schwan", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man tadelt' einen Schwan, der Wasserv\u00f6gel K\u00f6nig;", "tokens": ["Man", "ta\u00b7delt'", "ei\u00b7nen", "Schwan", ",", "der", "Was\u00b7ser\u00b7v\u00f6\u00b7gel", "K\u00f6\u00b7nig", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da nimmt sich seines Ruhms ein schlauer Vogel an.", "tokens": ["Da", "nimmt", "sich", "sei\u00b7nes", "Ruhms", "ein", "schlau\u00b7er", "Vo\u00b7gel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "H\u00f6rt, singt er, wie ich euch gleich widerlegen kann:", "tokens": ["H\u00f6rt", ",", "singt", "er", ",", "wie", "ich", "euch", "gleich", "wi\u00b7der\u00b7le\u00b7gen", "kann", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$,", "PWAV", "PPER", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wahr ist es, dieser Schwan fliegt wenig;", "tokens": ["Wahr", "ist", "es", ",", "die\u00b7ser", "Schwan", "fliegt", "we\u00b7nig", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PDAT", "NN", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch er verfliegt sich nicht. Er taumelt, wann er geht;", "tokens": ["Doch", "er", "ver\u00b7fliegt", "sich", "nicht", ".", "Er", "tau\u00b7melt", ",", "wann", "er", "geht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "PTKNEG", "$.", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein er schwimmt mit Majest\u00e4t.", "tokens": ["Al\u00b7lein", "er", "schwimmt", "mit", "Ma\u00b7jes\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jung war er weder wei\u00df, noch sch\u00f6n, noch stark zu nennen;", "tokens": ["Jung", "war", "er", "we\u00b7der", "wei\u00df", ",", "noch", "sch\u00f6n", ",", "noch", "stark", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "KON", "VVFIN", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jetzt mu\u00df man ihn daf\u00fcr erkennen.", "tokens": ["Jetzt", "mu\u00df", "man", "ihn", "da\u00b7f\u00fcr", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PPER", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Ernst ist gar zu stumm; allein er denket nach:", "tokens": ["Sein", "Ernst", "ist", "gar", "zu", "stumm", ";", "al\u00b7lein", "er", "den\u00b7ket", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$.", "ADV", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn eh' er stirbt, wird seine Stimme wach.", "tokens": ["Denn", "eh'", "er", "stirbt", ",", "wird", "sei\u00b7ne", "Stim\u00b7me", "wach", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VAFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Den G\u00e4nsen mag er freilich gleichen;", "tokens": ["Den", "G\u00e4n\u00b7sen", "mag", "er", "frei\u00b7lich", "glei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Doch wird er keinen G\u00e4nsen weichen.", "tokens": ["Doch", "wird", "er", "kei\u00b7nen", "G\u00e4n\u00b7sen", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zwar fischt der Fresser sich manch' niedliches Gericht;", "tokens": ["Zwar", "fischt", "der", "Fres\u00b7ser", "sich", "man\u00b7ch'", "nied\u00b7li\u00b7ches", "Ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Doch wi\u00dft ihr, uns verschlingt er nicht.", "tokens": ["Doch", "wi\u00dft", "ihr", ",", "uns", "ver\u00b7schlingt", "er", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein Dienst von solcher Art beleidigt.", "tokens": ["Ein", "Dienst", "von", "sol\u00b7cher", "Art", "be\u00b7lei\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Horaz, ach h\u00e4tte man dich j\u00fcngst nicht so vertheidigt!", "tokens": ["Ho\u00b7raz", ",", "ach", "h\u00e4t\u00b7te", "man", "dich", "j\u00fcngst", "nicht", "so", "ver\u00b7thei\u00b7digt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VAFIN", "PIS", "PRF", "ADV", "PTKNEG", "ADV", "VVPP", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}}}}