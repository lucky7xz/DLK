{"textgrid.poem.33866": {"metadata": {"author": {"name": "Hebbel, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Spanierin", "genre": "verse", "period": "N.A.", "pub_year": 1841, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbflasche, wunderbar versiegelt,", "tokens": ["\u00bb", "fla\u00b7sche", ",", "wun\u00b7der\u00b7bar", "ver\u00b7sie\u00b7gelt", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deinen Glutwein trink' ich jetzt,", "tokens": ["Dei\u00b7nen", "Glut\u00b7wein", "trink'", "ich", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er meinen Geist, befl\u00fcgelt,", "tokens": ["Da\u00df", "er", "mei\u00b7nen", "Geist", ",", "be\u00b7fl\u00fc\u00b7gelt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach Hispania versetzt!", "tokens": ["Nach", "His\u00b7pa\u00b7nia", "ver\u00b7setzt", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Da\u00df ich jenen H\u00fcgel schaue,", "tokens": ["Da\u00df", "ich", "je\u00b7nen", "H\u00fc\u00b7gel", "schau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "D'rauf er wuchs und Feuer sog,", "tokens": ["D'\u00b7rauf", "er", "wuchs", "und", "Feu\u00b7er", "sog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und das Felsenhaupt, das graue,", "tokens": ["Und", "das", "Fel\u00b7sen\u00b7haupt", ",", "das", "grau\u00b7e", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das sich auf ihn niederbog.", "tokens": ["Das", "sich", "auf", "ihn", "nie\u00b7der\u00b7bog", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und das M\u00e4dchen, das ihn streifte", "tokens": ["Und", "das", "M\u00e4d\u00b7chen", ",", "das", "ihn", "streif\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit des Flammenauges Stral,", "tokens": ["Mit", "des", "Flam\u00b7men\u00b7au\u00b7ges", "Stral", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er doppelt schneller reifte,", "tokens": ["Da\u00df", "er", "dop\u00b7pelt", "schnel\u00b7ler", "reif\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn sie kam aus ihrem Thal.", "tokens": ["Wenn", "sie", "kam", "aus", "ih\u00b7rem", "Thal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Das sich oft in seinem Schatten", "tokens": ["Das", "sich", "oft", "in", "sei\u00b7nem", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRF", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An den Reben still entz\u00fcckt,", "tokens": ["An", "den", "Re\u00b7ben", "still", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zuletzt die feuersatten", "tokens": ["Und", "zu\u00b7letzt", "die", "feu\u00b7er\u00b7sat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr ein Festmahl ausgedr\u00fcckt.\u00ab", "tokens": ["F\u00fcr", "ein", "Fest\u00b7mahl", "aus\u00b7ge\u00b7dr\u00fcckt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie aus einer Ader, sch\u00e4umend", "tokens": ["Wie", "aus", "ei\u00b7ner", "A\u00b7der", ",", "sch\u00e4u\u00b7mend"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "$,", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In den Becher rinnt der Wein,", "tokens": ["In", "den", "Be\u00b7cher", "rinnt", "der", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hastig trinkt der J\u00fcngling, tr\u00e4umend", "tokens": ["Has\u00b7tig", "trinkt", "der", "J\u00fcng\u00b7ling", ",", "tr\u00e4u\u00b7mend"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Blickt er dann in's Glas hinein.", "tokens": ["Blickt", "er", "dann", "in's", "Glas", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Eine dunkle Rebenlaube", "tokens": ["Ei\u00b7ne", "dunk\u00b7le", "Re\u00b7ben\u00b7lau\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sieht er vor sich, heimlich, dicht,", "tokens": ["Sieht", "er", "vor", "sich", ",", "heim\u00b7lich", ",", "dicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PRF", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Traube dr\u00e4ngt sich d'rin an Traube,", "tokens": ["Trau\u00b7be", "dr\u00e4ngt", "sich", "d'\u00b7rin", "an", "Trau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Doch das M\u00e4dchen sieht er nicht.", "tokens": ["Doch", "das", "M\u00e4d\u00b7chen", "sieht", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbtrinke mehr!\u00ab Er ruft's beklommen,", "tokens": ["\u00bb", "trin\u00b7ke", "mehr", "!", "\u00ab", "Er", "ruft's", "be\u00b7klom\u00b7men", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$.", "$(", "PPER", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In die Wangen tritt sein Blut,", "tokens": ["In", "die", "Wan\u00b7gen", "tritt", "sein", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbtrinke Alles! Sie soll kommen,", "tokens": ["\u00bb", "trin\u00b7ke", "Al\u00b7les", "!", "Sie", "soll", "kom\u00b7men", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "$.", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ob sie auch im Grabe ruht!\u00ab", "tokens": ["Ob", "sie", "auch", "im", "Gra\u00b7be", "ruht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Eben schl\u00e4gt die zw\u00f6lfte Stunde,", "tokens": ["E\u00b7ben", "schl\u00e4gt", "die", "zw\u00f6lf\u00b7te", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und er leert das letzte Glas.", "tokens": ["Und", "er", "leert", "das", "letz\u00b7te", "Glas", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Da, wie aus des Bechers Grunde,", "tokens": ["Da", ",", "wie", "aus", "des", "Be\u00b7chers", "Grun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Steigt ein M\u00e4dchen, ernst und bla\u00df.", "tokens": ["Steigt", "ein", "M\u00e4d\u00b7chen", ",", "ernst", "und", "bla\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbk\u00f6nnt' ich weinen \u2013 spricht sie \u2013 Armer,", "tokens": ["\u00bb", "k\u00f6nnt'", "ich", "wei\u00b7nen", "\u2013", "spricht", "sie", "\u2013", "Ar\u00b7mer", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "VVINF", "$(", "VVFIN", "PPER", "$(", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch als Geist beweint' ich dich,", "tokens": ["Noch", "als", "Geist", "be\u00b7weint'", "ich", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "VVFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn du Bl\u00fchend-Lebenswarmer", "tokens": ["Denn", "du", "Bl\u00fc\u00b7hen\u00b7dLe\u00b7bens\u00b7war\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bist nun bald so kalt, wie ich.", "tokens": ["Bist", "nun", "bald", "so", "kalt", ",", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,", "PWAV", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Diese Laube, diese Reben", "tokens": ["Die\u00b7se", "Lau\u00b7be", ",", "die\u00b7se", "Re\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Siehst du, auch den kleinsten Spro\u00df,", "tokens": ["Siehst", "du", ",", "auch", "den", "kleins\u00b7ten", "Spro\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber nicht das s\u00fc\u00dfe Leben,", "tokens": ["A\u00b7ber", "nicht", "das", "s\u00fc\u00b7\u00dfe", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das sie d\u00e4mmernd einst umschlo\u00df.", "tokens": ["Das", "sie", "d\u00e4m\u00b7mernd", "einst", "um\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Nicht, wie ich mich schlafend stellte,", "tokens": ["Nicht", ",", "wie", "ich", "mich", "schla\u00b7fend", "stell\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "PPER", "PRF", "ADJD", "VVFIN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Als ich ihn von fern geseh'n,", "tokens": ["Als", "ich", "ihn", "von", "fern", "ge\u00b7seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht, wie es das Herz mir schwellte,", "tokens": ["Nicht", ",", "wie", "es", "das", "Herz", "mir", "schwell\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "PPER", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Als er sprach: Hier bleib' ich steh'n!", "tokens": ["Als", "er", "sprach", ":", "Hier", "bleib'", "ich", "steh'n", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Nicht, wie bald ich seinem Sehnen", "tokens": ["Nicht", ",", "wie", "bald", "ich", "sei\u00b7nem", "Seh\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "$,", "PWAV", "ADV", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine h\u00f6chste Huld erwies,", "tokens": ["Mei\u00b7ne", "h\u00f6chs\u00b7te", "Huld", "er\u00b7wies", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch nicht meine starren Thr\u00e4nen,", "tokens": ["Auch", "nicht", "mei\u00b7ne", "star\u00b7ren", "Thr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als er endlich mich verlie\u00df.", "tokens": ["Als", "er", "end\u00b7lich", "mich", "ver\u00b7lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Alle diese Reben bl\u00fchten,", "tokens": ["Al\u00b7le", "die\u00b7se", "Re\u00b7ben", "bl\u00fch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als er mich zuerst umfing,", "tokens": ["Als", "er", "mich", "zu\u00b7erst", "um\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die reifen Trauben gl\u00fchten,", "tokens": ["Und", "die", "rei\u00b7fen", "Trau\u00b7ben", "gl\u00fch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als er treulos von mir ging.", "tokens": ["Als", "er", "treu\u00b7los", "von", "mir", "ging", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Da, im rachedurst'gen Muthe,", "tokens": ["Da", ",", "im", "ra\u00b7che\u00b7dur\u00b7st'\u00b7gen", "Mu\u00b7the", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Pre\u00df't ich sie, den Zauberspruch", "tokens": ["Pre\u00df't", "ich", "sie", ",", "den", "Zau\u00b7ber\u00b7spruch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "PPER", "PPER", "$,", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Murmelnd, und von meinem Blute", "tokens": ["Mur\u00b7melnd", ",", "und", "von", "mei\u00b7nem", "Blu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mischt' ich d'rein und sprach den Fluch.", "tokens": ["Mischt'", "ich", "d'\u00b7rein", "und", "sprach", "den", "Fluch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Nun, ein letztes Angebinde,", "tokens": ["Nun", ",", "ein", "letz\u00b7tes", "An\u00b7ge\u00b7bin\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schickt' ich ihm den dunklen Trank,", "tokens": ["Schickt'", "ich", "ihm", "den", "dunk\u00b7len", "Trank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann, da\u00df er mich nie mehr finde,", "tokens": ["Dann", ",", "da\u00df", "er", "mich", "nie", "mehr", "fin\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stach ich mich in's Herz und sank.", "tokens": ["Stach", "ich", "mich", "in's", "Herz", "und", "sank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPRART", "NN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Doch, mein Werk blieb unvollendet,", "tokens": ["Doch", ",", "mein", "Werk", "blieb", "un\u00b7voll\u00b7en\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinen Wein, der ihn bedr\u00e4ut,", "tokens": ["Mei\u00b7nen", "Wein", ",", "der", "ihn", "be\u00b7dr\u00e4ut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat er \u00fcber's Meer gesendet,", "tokens": ["Hat", "er", "\u00fc\u00b7ber's", "Meer", "ge\u00b7sen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und du Armer trankst ihn heut'.", "tokens": ["Und", "du", "Ar\u00b7mer", "trankst", "ihn", "heut'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Weh', nun wirst du dich verzehren,", "tokens": ["Weh'", ",", "nun", "wirst", "du", "dich", "ver\u00b7zeh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie es ihm beschieden war,", "tokens": ["Wie", "es", "ihm", "be\u00b7schie\u00b7den", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wirst des M\u00e4dchens noch begehren,", "tokens": ["Wirst", "des", "M\u00e4d\u00b7chens", "noch", "be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das schon Staub seit manchem Jahr;", "tokens": ["Das", "schon", "Staub", "seit", "man\u00b7chem", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Wirst auf Erden Nichts erwerben,", "tokens": ["Wirst", "auf", "Er\u00b7den", "Nichts", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als die Glut, d'rin du erstickst,", "tokens": ["Als", "die", "Glut", ",", "d'\u00b7rin", "du", "er\u00b7stickst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wirst, ach wirst nicht einmal sterben,", "tokens": ["Wirst", ",", "ach", "wirst", "nicht", "ein\u00b7mal", "ster\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "XY", "VAFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ehe du mein Grab erblickst!", "tokens": ["E\u00b7he", "du", "mein", "Grab", "er\u00b7blickst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Willst du mir zur Seite schlafen?", "tokens": ["Willst", "du", "mir", "zur", "Sei\u00b7te", "schla\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In Sevilla!\u00ab \u2013 Sie entschwebt,", "tokens": ["In", "Se\u00b7vil\u00b7la", "!", "\u00ab", "\u2013", "Sie", "ent\u00b7schwebt", ","], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$.", "$(", "$(", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und der J\u00fcngling geht zum Hafen,", "tokens": ["Und", "der", "J\u00fcng\u00b7ling", "geht", "zum", "Ha\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ob ein Schiff den Anker hebt.", "tokens": ["Ob", "ein", "Schiff", "den", "An\u00b7ker", "hebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}