{"textgrid.poem.44276": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[verm\u00f6chten \u00dcbung, Wiz, Erfahrung, Flei\u00df und Wi\u00dfen]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Verm\u00f6chten \u00dcbung, Wiz, Erfahrung, Flei\u00df und Wi\u00dfen", "tokens": ["Ver\u00b7m\u00f6ch\u00b7ten", "\u00dc\u00b7bung", ",", "Wiz", ",", "Er\u00b7fah\u00b7rung", ",", "Flei\u00df", "und", "Wi\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Macht der Sterbligkeit in Gr\u00e4nzen einzuschlie\u00dfen,", "tokens": ["Die", "Macht", "der", "Ster\u00b7blig\u00b7keit", "in", "Gr\u00e4n\u00b7zen", "ein\u00b7zu\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und k\u00f6nte Theophrast der Schickung wiederstehn,", "tokens": ["Und", "k\u00f6n\u00b7te", "Theo\u00b7ph\u00b7rast", "der", "Schi\u00b7ckung", "wie\u00b7ders\u00b7tehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So d\u00fcrften diesen Tag so viel getreue Thr\u00e4nen,", "tokens": ["So", "d\u00fcrf\u00b7ten", "die\u00b7sen", "Tag", "so", "viel", "ge\u00b7treu\u00b7e", "Thr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDAT", "NN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So manches Krancken Trost, so vieler Freunde Sehnen", "tokens": ["So", "man\u00b7ches", "Kran\u00b7cken", "Trost", ",", "so", "vie\u00b7ler", "Freun\u00b7de", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "NN", "$,", "ADV", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nebst unsrer Schuldigkeit nicht mit zur Leiche gehn.", "tokens": ["Nebst", "uns\u00b7rer", "Schul\u00b7dig\u00b7keit", "nicht", "mit", "zur", "Lei\u00b7che", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "APPR", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "So aber stellt uns jezt das kl\u00e4gliche Gedr\u00e4nge,", "tokens": ["So", "a\u00b7ber", "stellt", "uns", "jezt", "das", "kl\u00e4g\u00b7li\u00b7che", "Ge\u00b7dr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Kleider finstre Nacht, der Seufzer Ernst und Menge", "tokens": ["Der", "Klei\u00b7der", "finst\u00b7re", "Nacht", ",", "der", "Seuf\u00b7zer", "Ernst", "und", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN", "$,", "ART", "NN", "NE", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vom neuen den Beweis der alten Warheit vor:", "tokens": ["Vom", "neu\u00b7en", "den", "Be\u00b7weis", "der", "al\u00b7ten", "War\u00b7heit", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df noch kein Lullius den Schaz aus Tiegeln zwinge,", "tokens": ["Da\u00df", "noch", "kein", "Lul\u00b7li\u00b7us", "den", "Schaz", "aus", "Tie\u00b7geln", "zwin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NE", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der unserm Leben hier die Dauer wiederbringe,", "tokens": ["Der", "un\u00b7serm", "Le\u00b7ben", "hier", "die", "Dau\u00b7er", "wie\u00b7der\u00b7brin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die mit der Unschuld sich bald aus der Welt verlor.", "tokens": ["Die", "mit", "der", "Un\u00b7schuld", "sich", "bald", "aus", "der", "Welt", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PRF", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dies macht nun, Seeligster, da\u00df wir mit na\u00dfen Klagen", "tokens": ["Dies", "macht", "nun", ",", "See\u00b7ligs\u00b7ter", ",", "da\u00df", "wir", "mit", "na\u00b7\u00dfen", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "$,", "NN", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Pfand betr\u00fcbter Pflicht zum Leichenopfer tragen", "tokens": ["Das", "Pfand", "be\u00b7tr\u00fcb\u00b7ter", "Pflicht", "zum", "Lei\u00b7chen\u00b7op\u00b7fer", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und dein best\u00fcrztes Haus voll stummes Jammers sehn:", "tokens": ["Und", "dein", "be\u00b7st\u00fcrz\u00b7tes", "Haus", "voll", "stum\u00b7mes", "Jam\u00b7mers", "sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O war denn hier kein Weg, der Schickung auszuweichen?", "tokens": ["O", "war", "denn", "hier", "kein", "Weg", ",", "der", "Schi\u00b7ckung", "aus\u00b7zu\u00b7wei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "PIAT", "NN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O war denn hier kein Rath in drey so gro\u00dfen Reichen,", "tokens": ["O", "war", "denn", "hier", "kein", "Rath", "in", "drey", "so", "gro\u00b7\u00dfen", "Rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "PIAT", "NN", "APPR", "CARD", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Parzen g\u00fcldnen Draht dir weiter auszudrehn?", "tokens": ["Der", "Par\u00b7zen", "g\u00fcld\u00b7nen", "Draht", "dir", "wei\u00b7ter", "aus\u00b7zu\u00b7drehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Umsonst; Gold, Bezoar und alle theure Sachen,", "tokens": ["Um\u00b7sonst", ";", "Gold", ",", "Be\u00b7zoar", "und", "al\u00b7le", "theu\u00b7re", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NN", "$,", "NN", "KON", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Die Sch\u00fcler des Galens zu Wundercuren machen,", "tokens": ["Die", "Sch\u00fc\u00b7ler", "des", "Ga\u00b7lens", "zu", "Wun\u00b7der\u00b7cu\u00b7ren", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sind Mittel, deren Kraft nur Wind und Ohnmacht heist.", "tokens": ["Sind", "Mit\u00b7tel", ",", "de\u00b7ren", "Kraft", "nur", "Wind", "und", "Ohn\u00b7macht", "heist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "PRELAT", "NN", "ADV", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein zehnfach Recipe h\u00e4lt Streich und Tod zur\u00fccke;", "tokens": ["Kein", "zehn\u00b7fach", "Re\u00b7ci\u00b7pe", "h\u00e4lt", "Streich", "und", "Tod", "zu\u00b7r\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "NN", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn bricht die Vorsicht schon das Stundenglas in St\u00fccke,", "tokens": ["Denn", "bricht", "die", "Vor\u00b7sicht", "schon", "das", "Stun\u00b7den\u00b7glas", "in", "St\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So l\u00e4st die Kunst den Arzt so wie der Leib den Geist.", "tokens": ["So", "l\u00e4st", "die", "Kunst", "den", "Arzt", "so", "wie", "der", "Leib", "den", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADV", "KOKOM", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ist dieses nun der Lohn vor so viel sch\u00f6ne Proben,", "tokens": ["Ist", "die\u00b7ses", "nun", "der", "Lohn", "vor", "so", "viel", "sch\u00f6\u00b7ne", "Pro\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ART", "NN", "APPR", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die deine Wi\u00dfenschaft und deine Sorgfalt loben,", "tokens": ["Die", "dei\u00b7ne", "Wi\u00b7\u00dfen\u00b7schaft", "und", "dei\u00b7ne", "Sorg\u00b7falt", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die manchem Podalir die Cur vergn\u00fcgt gemacht?", "tokens": ["Die", "man\u00b7chem", "Po\u00b7da\u00b7lir", "die", "Cur", "ver\u00b7gn\u00fcgt", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist dies die Danckbarkeit der gro\u00dfen Meditrine,", "tokens": ["Ist", "dies", "die", "Dan\u00b7ck\u00b7bar\u00b7keit", "der", "gro\u00b7\u00dfen", "Me\u00b7di\u00b7tri\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Zu deren Dienst und Ruhm dein Flei\u00df nach Art der Biene", "tokens": ["Zu", "de\u00b7ren", "Dienst", "und", "Ruhm", "dein", "Flei\u00df", "nach", "Art", "der", "Bie\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "KON", "NN", "PPOSAT", "NN", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gesammlet und geschwizt und bey der Glut gewacht?", "tokens": ["Ge\u00b7samm\u00b7let", "und", "ge\u00b7schwizt", "und", "bey", "der", "Glut", "ge\u00b7wacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ist dieses nun der Danck, da\u00df sie in ihren Kr\u00e4ften", "tokens": ["Ist", "die\u00b7ses", "nun", "der", "Danck", ",", "da\u00df", "sie", "in", "ih\u00b7ren", "Kr\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu deinen durch den Schmerz verflognen Lebenss\u00e4ften", "tokens": ["Zu", "dei\u00b7nen", "durch", "den", "Schmerz", "ver\u00b7flog\u00b7nen", "Le\u00b7bens\u00b7s\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Im Lager, das dich dr\u00fcckt, kein Nahrungsmittel sieht?", "tokens": ["Im", "La\u00b7ger", ",", "das", "dich", "dr\u00fcckt", ",", "kein", "Nah\u00b7rungs\u00b7mit\u00b7tel", "sieht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was hilfts nun, da\u00df du sonst so klug vor sie gewesen?", "tokens": ["Was", "hilfts", "nun", ",", "da\u00df", "du", "sonst", "so", "klug", "vor", "sie", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "APPR", "PPER", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jedoch wir irren uns, jezt bistu recht genesen,", "tokens": ["Je\u00b7doch", "wir", "ir\u00b7ren", "uns", ",", "jezt", "bis\u00b7tu", "recht", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "$,", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da dich des H\u00f6chsten Hand dem Lazareth entzieht.", "tokens": ["Da", "dich", "des", "H\u00f6chs\u00b7ten", "Hand", "dem", "La\u00b7za\u00b7reth", "ent\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wir meinen, Seeligster, das Lazareth der Erden;", "tokens": ["Wir", "mei\u00b7nen", ",", "See\u00b7ligs\u00b7ter", ",", "das", "La\u00b7za\u00b7reth", "der", "Er\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In dieses kommen wir, so bald wir Menschen werden,", "tokens": ["In", "die\u00b7ses", "kom\u00b7men", "wir", ",", "so", "bald", "wir", "Men\u00b7schen", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "$,", "ADV", "ADV", "PPER", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und dieses macht das Gift von Evens N\u00e4scherey.", "tokens": ["Und", "die\u00b7ses", "macht", "das", "Gift", "von", "E\u00b7vens", "N\u00e4\u00b7sche\u00b7rey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Seitdem der Apfelbi\u00df uns Fleisch und Blut verdorben", "tokens": ["Seit\u00b7dem", "der", "Ap\u00b7fel\u00b7bi\u00df", "uns", "Fleisch", "und", "Blut", "ver\u00b7dor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "PPER", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und wir in Adams Fall der Freyheit abgestorben,", "tokens": ["Und", "wir", "in", "A\u00b7dams", "Fall", "der", "Frey\u00b7heit", "ab\u00b7ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NE", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist unser Leben hier und Kranckseyn einerley.", "tokens": ["Ist", "un\u00b7ser", "Le\u00b7ben", "hier", "und", "Kranc\u00b7kseyn", "ei\u00b7ner\u00b7ley", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Wir tragen, ists nicht wahr, den Aussaz grober S\u00fcnden,", "tokens": ["Wir", "tra\u00b7gen", ",", "ists", "nicht", "wahr", ",", "den", "Aus\u00b7saz", "gro\u00b7ber", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VAFIN", "PTKNEG", "ADJD", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Schlafsucht l\u00e4st sich oft im Christenthume finden,", "tokens": ["Die", "Schlaf\u00b7sucht", "l\u00e4st", "sich", "oft", "im", "Chris\u00b7ten\u00b7thu\u00b7me", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des \u00c4rgern\u00fc\u00dfes Pest steckt allenthalben an;", "tokens": ["Des", "\u00c4r\u00b7ger\u00b7n\u00fc\u00b7\u00dfes", "Pest", "steckt", "al\u00b7len\u00b7thal\u00b7ben", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Ehrgeiz f\u00fchlt und liebt die Windsucht im Gem\u00fcthe,", "tokens": ["Der", "Ehr\u00b7geiz", "f\u00fchlt", "und", "liebt", "die", "Wind\u00b7sucht", "im", "Ge\u00b7m\u00fc\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Wollust hei\u00dfer Brand entz\u00fcndet das Gebl\u00fcte,", "tokens": ["Der", "Wol\u00b7lust", "hei\u00b7\u00dfer", "Brand", "ent\u00b7z\u00fcn\u00b7det", "das", "Ge\u00b7bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von dem der d\u00fcrre Geiz sich kaum mehr n\u00e4hren kan.", "tokens": ["Von", "dem", "der", "d\u00fcr\u00b7re", "Geiz", "sich", "kaum", "mehr", "n\u00e4h\u00b7ren", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "PRF", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Dich also, Seeligster, mit Wehmuth zu beweinen,", "tokens": ["Dich", "al\u00b7so", ",", "See\u00b7ligs\u00b7ter", ",", "mit", "Weh\u00b7muth", "zu", "be\u00b7wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NN", "$,", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "K\u00f6nt etwan eher Neid als Pflicht und Liebe scheinen;", "tokens": ["K\u00f6nt", "et\u00b7wan", "e\u00b7her", "Neid", "als", "Pflicht", "und", "Lie\u00b7be", "schei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "NN", "KOUS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du bist nun recht gesund und in ein Land versezt,", "tokens": ["Du", "bist", "nun", "recht", "ge\u00b7sund", "und", "in", "ein", "Land", "ver\u00b7sezt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In welchem nun nicht mehr Pest, Brand und andre Seuchen", "tokens": ["In", "wel\u00b7chem", "nun", "nicht", "mehr", "Pest", ",", "Brand", "und", "and\u00b7re", "Seu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ADV", "PTKNEG", "PIAT", "NN", "$,", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie hier in Mesechs Kluft noch oft im Finstern schleichen", "tokens": ["Wie", "hier", "in", "Me\u00b7sechs", "Kluft", "noch", "oft", "im", "Fins\u00b7tern", "schlei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "NE", "NN", "ADV", "ADV", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wo kein eitler Dunst dein Auge mehr verlezt.", "tokens": ["Und", "wo", "kein", "eit\u00b7ler", "Dunst", "dein", "Au\u00b7ge", "mehr", "ver\u00b7lezt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "ADJA", "NN", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Geh\u00f6rt auch, wie man meint, der Nachruhm zu dem Leben,", "tokens": ["Ge\u00b7h\u00f6rt", "auch", ",", "wie", "man", "meint", ",", "der", "Nach\u00b7ruhm", "zu", "dem", "Le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "PIS", "VVFIN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So wird auch dieser dir ein frisch Ged\u00e4chtn\u00fc\u00df geben,", "tokens": ["So", "wird", "auch", "die\u00b7ser", "dir", "ein", "frisch", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDAT", "PPER", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil doch noch unter uns vielleicht ein Celsus ist,", "tokens": ["Weil", "doch", "noch", "un\u00b7ter", "uns", "viel\u00b7leicht", "ein", "Cel\u00b7sus", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "APPR", "PPER", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der deine Scheidekunst zur rechten Hand gebrauchet", "tokens": ["Der", "dei\u00b7ne", "Schei\u00b7de\u00b7kunst", "zur", "rech\u00b7ten", "Hand", "ge\u00b7brau\u00b7chet"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und, wenn ihm k\u00fcnftighin Capell und Ofen rauchet,", "tokens": ["Und", ",", "wenn", "ihm", "k\u00fcnf\u00b7tig\u00b7hin", "Ca\u00b7pell", "und", "O\u00b7fen", "rau\u00b7chet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADJA", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bey seiner Arbeit dich mit Sehnsucht starck vermi\u00dft.", "tokens": ["Bey", "sei\u00b7ner", "Ar\u00b7beit", "dich", "mit", "Sehn\u00b7sucht", "starck", "ver\u00b7mi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "APPR", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Nur die, nur die allein verdient gerechte Z\u00e4hren,", "tokens": ["Nur", "die", ",", "nur", "die", "al\u00b7lein", "ver\u00b7dient", "ge\u00b7rech\u00b7te", "Z\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "ADV", "ART", "ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die, deren Lieb und Schmerz sich jezo stumm erkl\u00e4ren", "tokens": ["Die", ",", "de\u00b7ren", "Lieb", "und", "Schmerz", "sich", "je\u00b7zo", "stumm", "er\u00b7kl\u00e4\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "PRELAT", "NN", "KON", "NN", "PRF", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und an der Heftigkeit in gleichem Grade gehn;", "tokens": ["Und", "an", "der", "Hef\u00b7tig\u00b7keit", "in", "glei\u00b7chem", "Gra\u00b7de", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie sizt in Einsamkeit bey ihres Gatten Raube", "tokens": ["Sie", "sizt", "in", "Ein\u00b7sam\u00b7keit", "bey", "ih\u00b7res", "Gat\u00b7ten", "Rau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Und seufzt und weint und girrt nach Art der Turteltaube", "tokens": ["Und", "seufzt", "und", "weint", "und", "girrt", "nach", "Art", "der", "Tur\u00b7tel\u00b7tau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ist sich selbst zu schwach, den Kummer auszustehn.", "tokens": ["Und", "ist", "sich", "selbst", "zu", "schwach", ",", "den", "Kum\u00b7mer", "aus\u00b7zu\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "ADV", "PTKA", "ADJD", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Kein Balsam Gileads, kein Pflaster hilft den Wunden,", "tokens": ["Kein", "Bal\u00b7sam", "Gi\u00b7le\u00b7ads", ",", "kein", "Pflas\u00b7ter", "hilft", "den", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NE", "$,", "PIAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sie in ihrer Brust so starck und tief empfunden;", "tokens": ["Die", "sie", "in", "ih\u00b7rer", "Brust", "so", "starck", "und", "tief", "emp\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum prahlen wir auch nicht mit viel Beredsamkeit,", "tokens": ["Drum", "prah\u00b7len", "wir", "auch", "nicht", "mit", "viel", "Be\u00b7red\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bedauren aber nur den Wuntsch der Patienten,", "tokens": ["Be\u00b7dau\u00b7ren", "a\u00b7ber", "nur", "den", "Wunt\u00b7sch", "der", "Pa\u00b7ti\u00b7en\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Die noch durch unsern Vogt mehr Hofnung sch\u00f6pfen k\u00f6nten,", "tokens": ["Die", "noch", "durch", "un\u00b7sern", "Vogt", "mehr", "Hof\u00b7nung", "sch\u00f6p\u00b7fen", "k\u00f6n\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "PIAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und \u00fcberla\u00dfen ihr den besten Trost: die Zeit.", "tokens": ["Und", "\u00fc\u00b7berl\u00b7a\u00b7\u00dfen", "ihr", "den", "bes\u00b7ten", "Trost", ":", "die", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}