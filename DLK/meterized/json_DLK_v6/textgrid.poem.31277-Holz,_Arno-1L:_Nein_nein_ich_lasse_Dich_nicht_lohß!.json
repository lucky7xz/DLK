{"textgrid.poem.31277": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nein/ nein/ ich lasse Dich nicht loh\u00df!", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nein/ nein/ ich lasse Dich nicht loh\u00df!", "tokens": ["Nein", "/", "nein", "/", "ich", "las\u00b7se", "Dich", "nicht", "loh\u00df", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PTKANT", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich gl\u00e4ube ja/ ich gl\u00e4ube!", "tokens": ["Ich", "gl\u00e4u\u00b7be", "ja", "/", "ich", "gl\u00e4u\u00b7be", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Errette mich in Deine Schoo\u00df/", "tokens": ["Er\u00b7ret\u00b7te", "mich", "in", "Dei\u00b7ne", "Schoo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "darmitt ich nicht verst\u00e4ube!", "tokens": ["dar\u00b7mitt", "ich", "nicht", "ver\u00b7st\u00e4u\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Au\u00df des Satans ekkler Schule", "tokens": ["Au\u00df", "des", "Sa\u00b7tans", "ek\u00b7kler", "Schu\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sih mich hihr f\u00fcr Deinem Stule/", "tokens": ["sih", "mich", "hihr", "f\u00fcr", "Dei\u00b7nem", "Stu\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ohnerh\u00f6hrt ist meine Noht/", "tokens": ["oh\u00b7ner\u00b7h\u00f6hrt", "ist", "mei\u00b7ne", "Noht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "h\u00fclff es/ schl\u00e4ng ich Gassen-Koht!", "tokens": ["h\u00fclff", "es", "/", "schl\u00e4ng", "ich", "Gas\u00b7sen\u00b7Koht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Fast ward ich schon wie blind und taub/", "tokens": ["Fast", "ward", "ich", "schon", "wie", "blind", "und", "taub", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "KOKOM", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "la\u00df/ la\u00df Dich dr\u00fcmb vers\u00fchnen", "tokens": ["la\u00df", "/", "la\u00df", "Dich", "dr\u00fcmb", "ver\u00b7s\u00fch\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "$(", "VVIMP", "PPER", "PAV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und g\u00f6nn mir Deinen Sternen-Staub/", "tokens": ["und", "g\u00f6nn", "mir", "Dei\u00b7nen", "Ster\u00b7nen\u00b7Staub", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "drau\u00df keine Gr\u00e4ber gr\u00fcnen!", "tokens": ["drau\u00df", "kei\u00b7ne", "Gr\u00e4\u00b7ber", "gr\u00fc\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Motten/ Modder/ Wuhst und Schimmel", "tokens": ["Mot\u00b7ten", "/", "Mod\u00b7der", "/", "Wuhst", "und", "Schim\u00b7mel"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "dausch mir gn\u00e4dig for den Himmel/", "tokens": ["dausch", "mir", "gn\u00e4\u00b7dig", "for", "den", "Him\u00b7mel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADJD", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da\u00df mich nicht nach kortzer Frist", "tokens": ["da\u00df", "mich", "nicht", "nach", "kort\u00b7zer", "Frist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "nichts al\u00df bloh\u00df die F\u00e4ulung fri\u00dft!", "tokens": ["nichts", "al\u00df", "bloh\u00df", "die", "F\u00e4u\u00b7lung", "fri\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Vor warst Du mir ein Spihl/ ein Spott/", "tokens": ["Vor", "warst", "Du", "mir", "ein", "Spihl", "/", "ein", "Spott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "VAFIN", "PPER", "PPER", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Wort stund mir auff Schrauben/", "tokens": ["Dein", "Wort", "stund", "mir", "auff", "Schrau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "kein ", "tokens": ["kein"], "token_info": ["word"], "pos": ["PIAT"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "kein ", "tokens": ["kein"], "token_info": ["word"], "pos": ["PIAT"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Ohn auch nur auff Dich zu h\u00f6hren/", "tokens": ["Ohn", "auch", "nur", "auff", "Dich", "zu", "h\u00f6h\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "lih\u00df ich mich durchs Fleisch beth\u00f6ren/", "tokens": ["lih\u00df", "ich", "mich", "durchs", "Fleisch", "be\u00b7th\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPRART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "l\u00fcderlich war ich gesinnt/", "tokens": ["l\u00fc\u00b7der\u00b7lich", "war", "ich", "ge\u00b7sinnt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "VVPP", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.8": {"text": "durch und durch ein ", "tokens": ["durch", "und", "durch", "ein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KON", "APPR", "ART"], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "Verruchter war ich wie kein Thier/", "tokens": ["Ver\u00b7ruch\u00b7ter", "war", "ich", "wie", "kein", "Thier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KOKOM", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "for Lieder pfiff ich Zoten", "tokens": ["for", "Lie\u00b7der", "pfiff", "ich", "Zo\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "in meiner br\u00e4nnenden Begihr/", "tokens": ["in", "mei\u00b7ner", "br\u00e4n\u00b7nen\u00b7den", "Be\u00b7gihr", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dreyn alle L\u00fcste lohten!", "tokens": ["dreyn", "al\u00b7le", "L\u00fcs\u00b7te", "loh\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dem ", "tokens": ["Dem"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "hieb ich qwer durch die Gesichter/", "tokens": ["hieb", "ich", "qwer", "durch", "die", "Ge\u00b7sich\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "jeglicher Enthaltungs-stand", "tokens": ["jeg\u00b7li\u00b7cher", "Ent\u00b7hal\u00b7tungs\u00b7stand"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "war mir g\u00e4ntzlich unbekand!", "tokens": ["war", "mir", "g\u00e4ntz\u00b7lich", "un\u00b7be\u00b7kand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Itzt b\u00fcn ich bloh\u00df noch Haut und Bein/", "tokens": ["Itzt", "b\u00fcn", "ich", "bloh\u00df", "noch", "Haut", "und", "Bein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mein Hertz kan kaum mehr schlagen/", "tokens": ["mein", "Hertz", "kan", "kaum", "mehr", "schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "mein schwartzer allerletzter Schreyn", "tokens": ["mein", "schwart\u00b7zer", "al\u00b7ler\u00b7letz\u00b7ter", "Schreyn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "steht schon auff seinem Schragen.", "tokens": ["steht", "schon", "auff", "sei\u00b7nem", "Schra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nacht for Nacht au\u00df meinen Kissen", "tokens": ["Nacht", "for", "Nacht", "au\u00df", "mei\u00b7nen", "Kis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "schrekkt mich zittrend mein Gewissen/", "tokens": ["schrekkt", "mich", "zitt\u00b7rend", "mein", "Ge\u00b7wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Grauen wirfft mich/ Angst und Schwei\u00df/", "tokens": ["Grau\u00b7en", "wirfft", "mich", "/", "Angst", "und", "Schwei\u00df", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "gihb mich nicht den W\u00fcrmern prei\u00df!", "tokens": ["gihb", "mich", "nicht", "den", "W\u00fcr\u00b7mern", "prei\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Seit zwey mahl dausend Jahren schon", "tokens": ["Seit", "zwey", "mahl", "dau\u00b7send", "Jah\u00b7ren", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "ADV", "ADJD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "lobsingen Dir Diorben;", "tokens": ["lob\u00b7sin\u00b7gen", "Dir", "Di\u00b7or\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "sey nicht \u00fcmbsonst durch Deinen Sohn", "tokens": ["sey", "nicht", "\u00fcm\u00b7bsonst", "durch", "Dei\u00b7nen", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "am Creutz for mir gestorben!", "tokens": ["am", "Creutz", "for", "mir", "ge\u00b7stor\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mach/ da\u00df ich nach dihser Erde", "tokens": ["Mach", "/", "da\u00df", "ich", "nach", "dih\u00b7ser", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "KOUS", "PPER", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gantz mit Dir vereinigt werde/", "tokens": ["gantz", "mit", "Dir", "ver\u00b7ei\u00b7nigt", "wer\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVPP", "VAFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "d\u00e4kkt mich gleich der Leichen-Stein/", "tokens": ["d\u00e4kkt", "mich", "gleich", "der", "Lei\u00b7chen\u00b7Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "la\u00df es nicht for ewig seyn!", "tokens": ["la\u00df", "es", "nicht", "for", "e\u00b7wig", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Au\u00df Gold und P\u00e4rlen blizzt die Stadt/", "tokens": ["Au\u00df", "Gold", "und", "P\u00e4r\u00b7len", "blizzt", "die", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gepflastert mit Tublonen/", "tokens": ["ge\u00b7pflas\u00b7tert", "mit", "Tub\u00b7lo\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "kaum sehn sich an ihr s\u00e4lbsten satt", "tokens": ["kaum", "sehn", "sich", "an", "ihr", "s\u00e4lbs\u00b7ten", "satt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die englische Sqwadronen!", "tokens": ["die", "eng\u00b7li\u00b7sche", "Sqwad\u00b7ro\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Jedem/ der durch Deine Gnade", "tokens": ["Je\u00b7dem", "/", "der", "durch", "Dei\u00b7ne", "Gna\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "$(", "ART", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Jesum fand im Wasser-Bade/", "tokens": ["Je\u00b7sum", "fand", "im", "Was\u00b7ser\u00b7Ba\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wird dort einstmahls seine Haut", "tokens": ["wird", "dort", "einst\u00b7mahls", "sei\u00b7ne", "Haut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "wihder\u00fcmb neu anverdraut!", "tokens": ["wih\u00b7de\u00b7r\u00fcmb", "neu", "an\u00b7ver\u00b7draut", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie freudig werd ich im Verein/", "tokens": ["Wie", "freu\u00b7dig", "werd", "ich", "im", "Ver\u00b7ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sorbald ich dort gelendet/", "tokens": ["sor\u00b7bald", "ich", "dort", "ge\u00b7len\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "mit ", "tokens": ["mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "weil alles sich gewendet!", "tokens": ["weil", "al\u00b7les", "sich", "ge\u00b7wen\u00b7det", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nichts bleibt unterm Leichlach ligen/", "tokens": ["Nichts", "bleibt", "un\u00b7term", "Leich\u00b7lach", "li\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.6": {"text": "alles werd ich wihder krigen:", "tokens": ["al\u00b7les", "werd", "ich", "wih\u00b7der", "kri\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ohr und Nase/ Mund und Kinn/", "tokens": ["Ohr", "und", "Na\u00b7se", "/", "Mund", "und", "Kinn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "jedes kleinste Kn\u00f6chelchin!", "tokens": ["je\u00b7des", "kleins\u00b7te", "Kn\u00f6\u00b7chel\u00b7chin", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Das steht gantz durchau\u00df und gewi\u00df", "tokens": ["Das", "steht", "gantz", "durch\u00b7au\u00df", "und", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PTKVZ", "KON", "ADV"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "durch Deine Schrifft verheissen/", "tokens": ["durch", "Dei\u00b7ne", "Schrifft", "ver\u00b7heis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du wirst \u00fcmb einen Apffel-Bi\u00df", "tokens": ["Du", "wirst", "\u00fcmb", "ei\u00b7nen", "Apf\u00b7fel\u00b7Bi\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mich nicht ins Feuer schmeissen!", "tokens": ["mich", "nicht", "ins", "Feu\u00b7er", "schmeis\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dodt/ du Teuffel/ deinem Drachen", "tokens": ["Dodt", "/", "du", "Teuf\u00b7fel", "/", "dei\u00b7nem", "Dra\u00b7chen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "$(", "NE", "NE", "$(", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "spey ich mitten in den Rachen:", "tokens": ["spey", "ich", "mit\u00b7ten", "in", "den", "Ra\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "bald b\u00fcn ich dahin gelangt/", "tokens": ["bald", "b\u00fcn", "ich", "da\u00b7hin", "ge\u00b7langt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "VVPP", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "wo mein Haupt mit Krohnen prangt!", "tokens": ["wo", "mein", "Haupt", "mit", "Kroh\u00b7nen", "prangt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Dan jauchtz ich wihder frisch und roht/", "tokens": ["Dan", "jauchtz", "ich", "wih\u00b7der", "frisch", "und", "roht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "o Freuden-volle Pfr\u00fcnde!", "tokens": ["o", "Freu\u00b7den\u00b7vol\u00b7le", "Pfr\u00fcn\u00b7de", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["FM", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wa\u00df w\u00e4re dihser Leib au\u00df Koht/", "tokens": ["Wa\u00df", "w\u00e4\u00b7re", "dih\u00b7ser", "Leib", "au\u00df", "Koht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PDAT", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wenn ich nicht aufferst\u00fcnde?", "tokens": ["wenn", "ich", "nicht", "auf\u00b7fer\u00b7st\u00fcn\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Erst zwar drifft mich noch Verwesung/", "tokens": ["Erst", "zwar", "drifft", "mich", "noch", "Ver\u00b7we\u00b7sung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "doch sordan folgt die Genesung/", "tokens": ["doch", "sor\u00b7dan", "folgt", "die", "Ge\u00b7ne\u00b7sung", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.7": {"text": "denn ich wei\u00df es itzt al\u00df Christ/", "tokens": ["denn", "ich", "wei\u00df", "es", "itzt", "al\u00df", "Christ", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "KOUS", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "da\u00df der Dodt mein Leben ist!", "tokens": ["da\u00df", "der", "Dodt", "mein", "Le\u00b7ben", "ist", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}