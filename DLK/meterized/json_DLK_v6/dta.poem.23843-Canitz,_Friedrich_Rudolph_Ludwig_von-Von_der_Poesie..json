{"dta.poem.23843": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Von der Poesie.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Auf! s\u00e4ume nicht mein Sinn ein gutes Werck zu wa-\ngen/", "tokens": ["Auf", "!", "s\u00e4u\u00b7me", "nicht", "mein", "Sinn", "ein", "gu\u00b7tes", "Werck", "zu", "wa", "gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PTKNEG", "PPOSAT", "NN", "ART", "ADJA", "NN", "APPR", "TRUNC", "APPR", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und aller Tichterey auf ewig abzusagen;", "tokens": ["Und", "al\u00b7ler", "Tich\u00b7te\u00b7rey", "auf", "e\u00b7wig", "ab\u00b7zu\u00b7sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gib weiter kein Geh\u00f6r/ wenn die Syrene singt/", "tokens": ["Gib", "wei\u00b7ter", "kein", "Ge\u00b7h\u00f6r", "/", "wenn", "die", "Sy\u00b7re\u00b7ne", "singt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PIAT", "NN", "$(", "KOUS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und such ein ander Spiel/ das bessern Nutzen bringt.", "tokens": ["Und", "such", "ein", "an\u00b7der", "Spiel", "/", "das", "bes\u00b7sern", "Nut\u00b7zen", "bringt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie? sprichst du/ soll ich schon ein Zeitvertreib verschwe-", "tokens": ["Wie", "?", "sprichst", "du", "/", "soll", "ich", "schon", "ein", "Zeit\u00b7ver\u00b7treib", "ver\u00b7schwe"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VVFIN", "PPER", "$(", "VMFIN", "PPER", "ADV", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dadurch ich bin gewohnt die Grillen abzukehren/", "tokens": ["Da\u00b7durch", "ich", "bin", "ge\u00b7wohnt", "die", "Gril\u00b7len", "ab\u00b7zu\u00b7keh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VAFIN", "ADJD", "ART", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das mir in Sicherheit bi\u00dfher die Stunden k\u00fcrtzt/", "tokens": ["Das", "mir", "in", "Si\u00b7cher\u00b7heit", "bi\u00df\u00b7her", "die", "Stun\u00b7den", "k\u00fcrtzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "An statt da\u00df mancher sich aus Lust in Unlust st\u00fcrtzt/", "tokens": ["An", "statt", "da\u00df", "man\u00b7cher", "sich", "aus", "Lust", "in", "Un\u00b7lust", "st\u00fcrtzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "KOUS", "PIS", "PRF", "APPR", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der/ weil ein schwartzer Punct im W\u00fcrffeln aus geblie-", "tokens": ["Der", "/", "weil", "ein", "schwart\u00b7zer", "Punct", "im", "W\u00fcrf\u00b7feln", "aus", "ge\u00b7blie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$(", "KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zuletzt aus dem Besitz der G\u00fcter wir getrieben.", "tokens": ["Zu\u00b7letzt", "aus", "dem", "Be\u00b7sitz", "der", "G\u00fc\u00b7ter", "wir", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ich thu mir schon Gewalt/ wenn ich viel Thorheit seh/", "tokens": ["Ich", "thu", "mir", "schon", "Ge\u00b7walt", "/", "wenn", "ich", "viel", "Thor\u00b7heit", "seh", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "$(", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die ich bescheidentlich mit schweigen \u00fcbergeh;", "tokens": ["Die", "ich", "be\u00b7schei\u00b7dent\u00b7lich", "mit", "schwei\u00b7gen", "\u00fc\u00b7ber\u00b7geh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das aber ding\u2019 ich aus/ nicht zu des Nechsten Schaden/", "tokens": ["Das", "a\u00b7ber", "ding'", "ich", "aus", "/", "nicht", "zu", "des", "Nechs\u00b7ten", "Scha\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "PTKVZ", "$(", "PTKNEG", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nein; sondern nur mein Hertz der B\u00fcrde zu entladen/", "tokens": ["Nein", ";", "son\u00b7dern", "nur", "mein", "Hertz", "der", "B\u00fcr\u00b7de", "zu", "ent\u00b7la\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "KON", "ADV", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da\u00df ich durch einen Reim/ was ich den gantzen Tag/", "tokens": ["Da\u00df", "ich", "durch", "ei\u00b7nen", "Reim", "/", "was", "ich", "den", "gant\u00b7zen", "Tag", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "$(", "PWS", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Geduldig angemerckt/ mir selbst vertrauen mag.", "tokens": ["Ge\u00b7dul\u00b7dig", "an\u00b7ge\u00b7merckt", "/", "mir", "selbst", "ver\u00b7trau\u00b7en", "mag."], "token_info": ["word", "word", "punct", "word", "word", "word", "abbreviation"], "pos": ["ADJD", "VVPP", "$(", "PPER", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Den\u0303 schenck\u2019 ichs keinem nicht/ kein Ort ist den ich schone/", "tokens": ["De\u00f1", "schenck", "ichs", "kei\u00b7nem", "nicht", "/", "kein", "Ort", "ist", "den", "ich", "scho\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "PIS", "PTKNEG", "$(", "PIAT", "NN", "VAFIN", "ART", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von schlechten H\u00fctten an/ bi\u00df zu des K\u00f6nigs Throne.", "tokens": ["Von", "schlech\u00b7ten", "H\u00fct\u00b7ten", "an", "/", "bi\u00df", "zu", "des", "K\u00f6\u00b7nigs", "Thro\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$(", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ein b\u00e4rtiger Heyduck/ der wie ein Cherubim/", "tokens": ["Ein", "b\u00e4r\u00b7ti\u00b7ger", "Hey\u00b7duck", "/", "der", "wie", "ein", "Che\u00b7ru\u00b7bim", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "KOKOM", "ART", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die Streit-Axt in der Hand/ die Augen voller Grimm/", "tokens": ["Die", "Streit\u00b7Axt", "in", "der", "Hand", "/", "die", "Au\u00b7gen", "vol\u00b7ler", "Grimm", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$(", "ART", "NN", "APPR", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der Au\u00dferw\u00e4hlten Sitz verschleu\u00dft f\u00fcr meines gleichen/", "tokens": ["Der", "Au\u00b7\u00dfer\u00b7w\u00e4hl\u00b7ten", "Sitz", "ver\u00b7schleu\u00dft", "f\u00fcr", "mei\u00b7nes", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Mu\u00df wie ein sch\u00fcchtern Reh von seiner Wacht entwei-", "tokens": ["Mu\u00df", "wie", "ein", "sch\u00fcch\u00b7tern", "Reh", "von", "sei\u00b7ner", "Wacht", "ent\u00b7wei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "KOKOM", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wenn mein gerechter Zorn erst anzubrenne", "tokens": ["Wenn", "mein", "ge\u00b7rech\u00b7ter", "Zorn", "erst", "an\u00b7zu\u00b7bren\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Und sich bi\u00df in den Schoo\u00df des blinden Gl\u00fcckes drengt/", "tokens": ["Und", "sich", "bi\u00df", "in", "den", "Schoo\u00df", "des", "blin\u00b7den", "Gl\u00fc\u00b7ckes", "drengt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.25": {"text": "Die Larve vom Gesicht des Lasters weg zu reissen;", "tokens": ["Die", "Lar\u00b7ve", "vom", "Ge\u00b7sicht", "des", "Las\u00b7ters", "weg", "zu", "reis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Weh dem der th\u00f6richt ist/ und dennoch klug wil heissen!", "tokens": ["Weh", "dem", "der", "th\u00f6\u00b7richt", "ist", "/", "und", "den\u00b7noch", "klug", "wil", "heis\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ART", "ADJD", "VAFIN", "$(", "KON", "ADV", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Denn wo sein Name nur sich in die Verse schickt/", "tokens": ["Denn", "wo", "sein", "Na\u00b7me", "nur", "sich", "in", "die", "Ver\u00b7se", "schickt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "NN", "ADV", "PRF", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So wird er alsofort dem - - - - be", "tokens": ["So", "wird", "er", "al\u00b7so\u00b7fort", "dem", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "$(", "$(", "$(", "$(", "VVFIN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.29": {"text": "In meinem Sch\u00fcler-stand/ auf den bestaubten B\u00e4ncken/", "tokens": ["In", "mei\u00b7nem", "Sch\u00fc\u00b7ler\u00b7stand", "/", "auf", "den", "be\u00b7staub\u00b7ten", "B\u00e4n\u00b7cken", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Hub sich die Kurtzweil an; Solt\u2019 ich auf ", "tokens": ["Hub", "sich", "die", "Kurt\u00b7zweil", "an", ";", "Solt'", "ich", "auf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKVZ", "$.", "VMFIN", "PPER", "APPR"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.31": {"text": "(die man gezwungen lernt/ und l\u00e4nger nicht bewahrt/", "tokens": ["(", "die", "man", "ge\u00b7zwun\u00b7gen", "lernt", "/", "und", "l\u00e4n\u00b7ger", "nicht", "be\u00b7wahrt", "/"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PIS", "VVPP", "VVFIN", "$(", "KON", "ADJD", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Als bi\u00df der kluge Sohn/ nach Papageyen Art/", "tokens": ["Als", "bi\u00df", "der", "klu\u00b7ge", "Sohn", "/", "nach", "Pa\u00b7pa\u00b7ge\u00b7yen", "Art", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$(", "APPR", "NN", "NN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.33": {"text": "Sie zu der Eltern Trost/ dem Lehrer nachgesprochen/)", "tokens": ["Sie", "zu", "der", "El\u00b7tern", "Trost", "/", "dem", "Leh\u00b7rer", "nach\u00b7ge\u00b7spro\u00b7chen", "/", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "NN", "$(", "ART", "NN", "VVINF", "$(", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So ward mir aller Flei\u00df durch Reimen unterbrochen/", "tokens": ["So", "ward", "mir", "al\u00b7ler", "Flei\u00df", "durch", "Rei\u00b7men", "un\u00b7ter\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Da mahlt\u2019 ich unge\u00fcbt in meiner Einfalt ab/", "tokens": ["Da", "mahlt'", "ich", "un\u00b7ge\u00b7\u00fcbt", "in", "mei\u00b7ner", "Ein\u00b7falt", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wenn Meister und Gesell/ mir was zu lachen gab;", "tokens": ["Wenn", "Meis\u00b7ter", "und", "Ge\u00b7sell", "/", "mir", "was", "zu", "la\u00b7chen", "gab", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$(", "PPER", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Bi\u00df nach und nach die Zeit den Vorhang weggeschoben/", "tokens": ["Bi\u00df", "nach", "und", "nach", "die", "Zeit", "den", "Vor\u00b7hang", "weg\u00b7ge\u00b7scho\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "KON", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Und mir/ was scheltens werth/ hingegen was zu loben/", "tokens": ["Und", "mir", "/", "was", "schel\u00b7tens", "werth", "/", "hin\u00b7ge\u00b7gen", "was", "zu", "lo\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "PWS", "ADV", "ADJD", "$(", "ADV", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Was Hof und Kirch und Land/ und Stadt f\u00fcr Wunder", "tokens": ["Was", "Hof", "und", "Kirch", "und", "Land", "/", "und", "Stadt", "f\u00fcr", "Wun\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "NN", "KON", "NN", "KON", "NN", "$(", "KON", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Und was mir selber fehlt getreulich ausgelegt.", "tokens": ["Und", "was", "mir", "sel\u00b7ber", "fehlt", "ge\u00b7treu\u00b7lich", "aus\u00b7ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Das mach\u2019 ich mir zu nutz/ und durch des Himmels G\u00fcte", "tokens": ["Das", "mach'", "ich", "mir", "zu", "nutz", "/", "und", "durch", "des", "Him\u00b7mels", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PRF", "APPR", "NN", "$(", "KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Werd\u2019 ich je mehr und mehr best\u00e4rckt/ da\u00df ein Gem\u00fcthe/", "tokens": ["Werd'", "ich", "je", "mehr", "und", "mehr", "be\u00b7st\u00e4rckt", "/", "da\u00df", "ein", "Ge\u00b7m\u00fc\u00b7the", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "KON", "ADV", "VVPP", "$(", "KOUS", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Wenn es der Tyranney des Wahnes obgesiegt/", "tokens": ["Wenn", "es", "der", "Ty\u00b7ran\u00b7ney", "des", "Wah\u00b7nes", "ob\u00b7ge\u00b7siegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und seine Freyheit kennt/ gantz Peru \u00fcberwiegt;", "tokens": ["Und", "sei\u00b7ne", "Frey\u00b7heit", "kennt", "/", "gantz", "Pe\u00b7ru", "\u00fc\u00b7berw\u00b7iegt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$(", "ADV", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Das ists/ was offt mein Kiel schleu\u00dft in gebundnen S\u00e4-", "tokens": ["Das", "ists", "/", "was", "offt", "mein", "Kiel", "schleu\u00dft", "in", "ge\u00b7bund\u00b7nen", "S\u00e4"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$(", "PWS", "ADV", "PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Was mich nun dergestalt in Unschuld kan erg\u00e4tzen/", "tokens": ["Was", "mich", "nun", "der\u00b7ge\u00b7stalt", "in", "Un\u00b7schuld", "kan", "er\u00b7g\u00e4t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wozu mich die Natur - - - - halt ein verf\u00fchrter", "tokens": ["Wo\u00b7zu", "mich", "die", "Na\u00b7tur", "halt", "ein", "ver\u00b7f\u00fchr\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "$(", "$(", "$(", "$(", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.48": {"text": "Drum eben straff\u2019 ich dich/ weil ich besorget bin/", "tokens": ["Drum", "e\u00b7ben", "straff'", "ich", "dich", "/", "weil", "ich", "be\u00b7sor\u00b7get", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "PRF", "$(", "KOUS", "PPER", "VVFIN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Es m\u00f6chte/ was itzund/ noch leicht ist zu verst\u00f6ren/", "tokens": ["Es", "m\u00f6ch\u00b7te", "/", "was", "it\u00b7zund", "/", "noch", "leicht", "ist", "zu", "ver\u00b7st\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$(", "PWS", "ADV", "$(", "ADV", "ADJD", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Sich endlich unvermerckt/ in die Natur verkehren;", "tokens": ["Sich", "end\u00b7lich", "un\u00b7ver\u00b7merckt", "/", "in", "die", "Na\u00b7tur", "ver\u00b7keh\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "$(", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Wo hat Justinian das strenge Recht erdacht/", "tokens": ["Wo", "hat", "Jus\u00b7ti\u00b7ni\u00b7an", "das", "stren\u00b7ge", "Recht", "er\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.52": {"text": "Durch welches ein Phantast wird Vogel-frey ge-", "tokens": ["Durch", "wel\u00b7ches", "ein", "Phan\u00b7tast", "wird", "Vo\u00b7gel\u00b7frey", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ART", "NN", "VAFIN", "NE", "TRUNC"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.53": {"text": "Und da ein weiser Mann dis f\u00fcr was grosses sch\u00e4tzet/", "tokens": ["Und", "da", "ein", "wei\u00b7ser", "Mann", "dis", "f\u00fcr", "was", "gros\u00b7ses", "sch\u00e4t\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "PDS", "APPR", "PRELS", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Da\u00df man noch keinen Zoll auf die Gedancken setzet/", "tokens": ["Da\u00df", "man", "noch", "kei\u00b7nen", "Zoll", "auf", "die", "Ge\u00b7dan\u00b7cken", "set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PIAT", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Ist wol der beste Raht/ man seh\u2019 und schweige still/", "tokens": ["Ist", "wol", "der", "bes\u00b7te", "Raht", "/", "man", "seh'", "und", "schwei\u00b7ge", "still", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$(", "PIS", "VVFIN", "KON", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Und stelle jedem frey/ zu schwermen wie er wil/", "tokens": ["Und", "stel\u00b7le", "je\u00b7dem", "frey", "/", "zu", "schwer\u00b7men", "wie", "er", "wil", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADJD", "$(", "PTKZU", "VVINF", "PWAV", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Indem es fast so schwer die rohe Welt zu zwingen/", "tokens": ["In\u00b7dem", "es", "fast", "so", "schwer", "die", "ro\u00b7he", "Welt", "zu", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Als mancher Priesterschafft das Beicht-Geld abzubrin-", "tokens": ["Als", "man\u00b7cher", "Pries\u00b7ter\u00b7schafft", "das", "Beicht\u00b7Geld", "ab\u00b7zu\u00b7brin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Ein Spiegel weiset uns der Narben He\u00dflichkeit/", "tokens": ["Ein", "Spie\u00b7gel", "wei\u00b7set", "uns", "der", "Nar\u00b7ben", "He\u00df\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Doch wird er offtermahls deswegen angespeyt.", "tokens": ["Doch", "wird", "er", "off\u00b7ter\u00b7mahls", "des\u00b7we\u00b7gen", "an\u00b7ge\u00b7speyt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Du meynst zwar/ was du schreibst/ sol nie das Licht er-", "tokens": ["Du", "meynst", "zwar", "/", "was", "du", "schreibst", "/", "sol", "nie", "das", "Licht", "er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PWS", "PPER", "VVFIN", "$(", "VMFIN", "ADV", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.62": {"text": "Wie bald kan aber dis auch dir eins mi\u00dfgel\u00fccken?", "tokens": ["Wie", "bald", "kan", "a\u00b7ber", "dis", "auch", "dir", "eins", "mi\u00df\u00b7ge\u00b7l\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "ADV", "PDS", "ADV", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Von deinem sch\u00f6nen Zeug/ entdeck ich/ wie mich deucht/", "tokens": ["Von", "dei\u00b7nem", "sch\u00f6\u00b7nen", "Zeug", "/", "ent\u00b7deck", "ich", "/", "wie", "mich", "deucht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "VVIMP", "PPER", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Schon manch geheimes Blat/ das durch die Zechen", "tokens": ["Schon", "manch", "ge\u00b7hei\u00b7mes", "Blat", "/", "das", "durch", "die", "Ze\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$(", "ART", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.65": {"text": "So wirst du ein Poet/ wie sehr du es verneinest;", "tokens": ["So", "wirst", "du", "ein", "Po\u00b7et", "/", "wie", "sehr", "du", "es", "ver\u00b7nei\u00b7nest", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$(", "KOKOM", "ADV", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wer wei\u00df ob du nicht bald in offnem Druck erscheinest;", "tokens": ["Wer", "wei\u00df", "ob", "du", "nicht", "bald", "in", "off\u00b7nem", "Druck", "er\u00b7schei\u00b7nest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KOUS", "PPER", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Vielleicht wird dein Gedicht/ des M\u00fc\u00dfigganges Frucht/", "tokens": ["Viel\u00b7leicht", "wird", "dein", "Ge\u00b7dicht", "/", "des", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ges", "Frucht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Noch bey der sp\u00e4ten Welt einmahl hervor gesucht/", "tokens": ["Noch", "bey", "der", "sp\u00e4\u00b7ten", "Welt", "ein\u00b7mahl", "her\u00b7vor", "ge\u00b7sucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "ADV", "PTKVZ", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Und zwar mit Juvenal in einem Pack gefunden/", "tokens": ["Und", "zwar", "mit", "Ju\u00b7ve\u00b7nal", "in", "ei\u00b7nem", "Pack", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Wenn man ihn ohngefehr in Leschpapier gewunden.", "tokens": ["Wenn", "man", "ihn", "ohn\u00b7ge\u00b7fehr", "in", "Leschpa\u00b7pier", "ge\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADJD", "APPR", "NN", "VAPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.71": {"text": "Schreibt dir dein bester Freund/ der deinen Raht begehrt/", "tokens": ["Schreibt", "dir", "dein", "bes\u00b7ter", "Freund", "/", "der", "dei\u00b7nen", "Raht", "be\u00b7gehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$(", "ART", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "So scheints/ als hieltest du ihn keiner Antwort wehrt/", "tokens": ["So", "scheints", "/", "als", "hiel\u00b7test", "du", "ihn", "kei\u00b7ner", "Ant\u00b7wort", "wehrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOKOM", "VVFIN", "PPER", "PPER", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Bringt jemand ein Gewerb/ das auf dein Wohlerge-", "tokens": ["Bringt", "je\u00b7mand", "ein", "Ge\u00b7werb", "/", "das", "auf", "dein", "Wohl\u00b7er\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ART", "NN", "$(", "PDS", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Auf Ehr und Vortheil zielt; du l\u00e4\u00dft ihn draussen ste-", "tokens": ["Auf", "Ehr", "und", "Vor\u00b7theil", "zielt", ";", "du", "l\u00e4\u00dft", "ihn", "draus\u00b7sen", "ste"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Triffst du Gesellschafft an die ein Gespr\u00e4ch ergetzt/", "tokens": ["Triffst", "du", "Ge\u00b7sell\u00b7schafft", "an", "die", "ein", "Ge\u00b7spr\u00e4ch", "er\u00b7getzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "PRELS", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Wo der Bek\u00fcmmertste sein Leid beyseite setzt/", "tokens": ["Wo", "der", "Be\u00b7k\u00fcm\u00b7merts\u00b7te", "sein", "Leid", "bey\u00b7sei\u00b7te", "setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "So runtzelst du die Stirn in so viel hundert Falten/", "tokens": ["So", "runt\u00b7zelst", "du", "die", "Stirn", "in", "so", "viel", "hun\u00b7dert", "Fal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ADV", "ADV", "CARD", "NN", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.78": {"text": "Da\u00df du offt f\u00fcr ein Bild des Cato wirst gehalten/", "tokens": ["Da\u00df", "du", "offt", "f\u00fcr", "ein", "Bild", "des", "Ca\u00b7to", "wirst", "ge\u00b7hal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ART", "NE", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Ein jeder wolte gern erfahren was dich qu\u00e4lt;", "tokens": ["Ein", "je\u00b7der", "wol\u00b7te", "gern", "er\u00b7fah\u00b7ren", "was", "dich", "qu\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VMFIN", "ADV", "VVINF", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Indessen schleichst du fort/ weist selbst kaum was dir", "tokens": ["In\u00b7des\u00b7sen", "schleichst", "du", "fort", "/", "weist", "selbst", "kaum", "was", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$(", "VVFIN", "ADV", "ADV", "PWS", "PPER"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.81": {"text": "Dein Hau\u00df wird zugesperrt die Schl\u00f6sser abgespannet/", "tokens": ["Dein", "Hau\u00df", "wird", "zu\u00b7ge\u00b7sperrt", "die", "Schl\u00f6s\u00b7ser", "ab\u00b7ge\u00b7span\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "So wie\u2019s ein Zaubrer macht/ wenn er die Geister bannet/", "tokens": ["So", "wie's", "ein", "Zaub\u00b7rer", "macht", "/", "wenn", "er", "die", "Geis\u00b7ter", "ban\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ART", "NN", "VVFIN", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Und da die halbe Welt/ von aller Arbeit ruht/", "tokens": ["Und", "da", "die", "hal\u00b7be", "Welt", "/", "von", "al\u00b7ler", "Ar\u00b7beit", "ruht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "$(", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Weckst du den Nachbar auf/ den des Camines Glut", "tokens": ["Weckst", "du", "den", "Nach\u00b7bar", "auf", "/", "den", "des", "Ca\u00b7mi\u00b7nes", "Glut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$(", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Und sp\u00e4te Lampe schreckt/ die dich im Fenster zeigen/", "tokens": ["Und", "sp\u00e4\u00b7te", "Lam\u00b7pe", "schreckt", "/", "die", "dich", "im", "Fens\u00b7ter", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$(", "PRELS", "PRF", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Als woltst du Thurm und Dach aus Mond-Sucht \u00fc-", "tokens": ["Als", "woltst", "du", "Thurm", "und", "Dach", "aus", "Mon\u00b7dSucht", "\u00fc"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "PPER", "NN", "KON", "NN", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Warum? was ficht dich an? was ists? was macht", "tokens": ["Wa\u00b7rum", "?", "was", "ficht", "dich", "an", "?", "was", "ists", "?", "was", "macht"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VAFIN", "$.", "PWS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.88": {"text": "Ein Wort; was f\u00fcr ein Wort? das hinten reimen sol.", "tokens": ["Ein", "Wort", ";", "was", "f\u00fcr", "ein", "Wort", "?", "das", "hin\u00b7ten", "rei\u00b7men", "sol", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PWS", "APPR", "ART", "NN", "$.", "PDS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Verdammte Poesie! mein Sinn/ la\u00df dich bedeuten/", "tokens": ["Ver\u00b7damm\u00b7te", "Poe\u00b7sie", "!", "mein", "Sinn", "/", "la\u00df", "dich", "be\u00b7deu\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PPOSAT", "NN", "$(", "VVIMP", "PPER", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.90": {"text": "Eh ich dir Niese-Wurtz darff lassen zubereiten;", "tokens": ["Eh", "ich", "dir", "Nie\u00b7se\u00b7Wurtz", "darff", "las\u00b7sen", "zu\u00b7be\u00b7rei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "NN", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Greiff erst die Fehler an/ die du selbst an dir siehst/", "tokens": ["Greiff", "erst", "die", "Feh\u00b7ler", "an", "/", "die", "du", "selbst", "an", "dir", "siehst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "PTKVZ", "$(", "PRELS", "PPER", "ADV", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Eh du der andern Thun/ durch deine Hechel ziehst;", "tokens": ["Eh", "du", "der", "an\u00b7dern", "Thun", "/", "durch", "dei\u00b7ne", "He\u00b7chel", "ziehst", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Doch solt ich hier die M\u00fch/ dich zu erforschen/ nehmen/", "tokens": ["Doch", "solt", "ich", "hier", "die", "M\u00fch", "/", "dich", "zu", "er\u00b7for\u00b7schen", "/", "neh\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "NN", "$(", "PPER", "PTKZU", "VVINF", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Wir m\u00fc\u00dften/ ists nicht wahr? uns f\u00fcr einander", "tokens": ["Wir", "m\u00fc\u00df\u00b7ten", "/", "ists", "nicht", "wahr", "?", "uns", "f\u00fcr", "ein\u00b7an\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$(", "VAFIN", "PTKNEG", "PTKVZ", "$.", "PPER", "APPR", "PRF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.95": {"text": "Kurtz: wer das Richter-Amt auf seinen Schultern", "tokens": ["Kurtz", ":", "wer", "das", "Rich\u00b7ter\u00b7Amt", "auf", "sei\u00b7nen", "Schul\u00b7tern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "PWS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.96": {"text": "Der seh/ da\u00df sein Gesetz mit seinem Wandel stimmt.", "tokens": ["Der", "seh", "/", "da\u00df", "sein", "Ge\u00b7setz", "mit", "sei\u00b7nem", "Wan\u00b7del", "stimmt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "KOUS", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Wird doch die Cantzel roht wenn ein erhitzter - - -", "tokens": ["Wird", "doch", "die", "Cant\u00b7zel", "roht", "wenn", "ein", "er\u00b7hitz\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVFIN", "KOUS", "ART", "ADJA", "$(", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.98": {"text": "Der geilen Heerde schwatzt/ von Sodom Rach und", "tokens": ["Der", "gei\u00b7len", "Heer\u00b7de", "schwatzt", "/", "von", "So\u00b7dom", "Rach", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "APPR", "NE", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.99": {"text": "In Cloris Gegenwarth/ die noch verwichnen Tag", "tokens": ["In", "Clo\u00b7ris", "Ge\u00b7gen\u00b7warth", "/", "die", "noch", "ver\u00b7wich\u00b7nen", "Tag"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "$(", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "In dem verliebten Arm des treuen Hir", "tokens": ["In", "dem", "ver\u00b7lieb\u00b7ten", "Arm", "des", "treu\u00b7en", "Hir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.101": {"text": "Ists m\u00fcglich/ kan dir noch die Tichter-Kunst gefallen?", "tokens": ["Ists", "m\u00fcg\u00b7lich", "/", "kan", "dir", "noch", "die", "Tich\u00b7ter\u00b7Kunst", "ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$(", "VMFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Gib Achtung/ bitt ich dich/ wie unsre Lieder schallen/", "tokens": ["Gib", "Ach\u00b7tung", "/", "bitt", "ich", "dich", "/", "wie", "uns\u00b7re", "Lie\u00b7der", "schal\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$(", "VVFIN", "PPER", "PRF", "$(", "KOKOM", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Und was f\u00fcr eine Bruth/ man allenthalben heckt/", "tokens": ["Und", "was", "f\u00fcr", "ei\u00b7ne", "Bruth", "/", "man", "al\u00b7len\u00b7thal\u00b7ben", "heckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "ART", "NN", "$(", "PIS", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "So weit sich das Gebieth des Teutschen Bodens streckt.", "tokens": ["So", "weit", "sich", "das", "Ge\u00b7bieth", "des", "Teut\u00b7schen", "Bo\u00b7dens", "streckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Durch Opitzs stillen Bach gehn wir mit trocknen F\u00fcssen/", "tokens": ["Durch", "O\u00b7pitzs", "stil\u00b7len", "Bach", "gehn", "wir", "mit", "trock\u00b7nen", "F\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Wo sieht man Hoffmanns Brun\u0303/ und Lohnsteins Str\u00f6h-", "tokens": ["Wo", "sieht", "man", "Hoff\u00b7manns", "Bru\u00f1", "/", "und", "Lohn\u00b7steins", "Str\u00f6h"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PIS", "NN", "NE", "$(", "KON", "NE", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.107": {"text": "Und/ nehm ich Bessern aus/ wem ist wol mehr verg\u00f6nnt/", "tokens": ["Und", "/", "nehm", "ich", "Bes\u00b7sern", "aus", "/", "wem", "ist", "wol", "mehr", "ver\u00b7g\u00f6nnt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "PPER", "NN", "PTKVZ", "$(", "PWS", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Da\u00df er den wahren Quell der Hyppocrene kennt?", "tokens": ["Da\u00df", "er", "den", "wah\u00b7ren", "Quell", "der", "Hyp\u00b7po\u00b7cre\u00b7ne", "kennt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Wer itzt aus Pf\u00fctzen trinckt/ tritt in Poeten Orden/", "tokens": ["Wer", "itzt", "aus", "Pf\u00fct\u00b7zen", "trinckt", "/", "tritt", "in", "Po\u00b7et\u00b7en", "Or\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "VVFIN", "$(", "VVFIN", "APPR", "NN", "NN", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.110": {"text": "So da\u00df der Helicon ein Blocksberg ist geworden/", "tokens": ["So", "da\u00df", "der", "He\u00b7li\u00b7con", "ein", "Blocks\u00b7berg", "ist", "ge\u00b7wor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "ART", "NN", "VAFIN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Auf welchem das Geheul des wilden Pans erth\u00f6nt/", "tokens": ["Auf", "wel\u00b7chem", "das", "Ge\u00b7heul", "des", "wil\u00b7den", "Pans", "er\u00b7th\u00f6nt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Der seine S\u00e4nger-Zunfft mit Hasen-Pappeln kr\u00f6nt.", "tokens": ["Der", "sei\u00b7ne", "S\u00e4n\u00b7ger\u00b7Zunfft", "mit", "Ha\u00b7sen\u00b7Pap\u00b7peln", "kr\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Vor alters/ wo mir recht/ ward nie ein Held besungen/", "tokens": ["Vor", "al\u00b7ters", "/", "wo", "mir", "recht", "/", "ward", "nie", "ein", "Held", "be\u00b7sun\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$(", "PWAV", "PPER", "ADJD", "$(", "VAFIN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Wenn er nicht durch Verdienst sich in die H\u00f6h geschwun-", "tokens": ["Wenn", "er", "nicht", "durch", "Ver\u00b7dienst", "sich", "in", "die", "H\u00f6h", "ge\u00b7schwun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "NN", "PRF", "APPR", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Und eine Redens-Art die g\u00f6ttlich solte seyn/", "tokens": ["Und", "ei\u00b7ne", "Re\u00b7den\u00b7sArt", "die", "g\u00f6tt\u00b7lich", "sol\u00b7te", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADJD", "VMFIN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Die ward zu solcher Zeit den Sclaven nicht gemein.", "tokens": ["Die", "ward", "zu", "sol\u00b7cher", "Zeit", "den", "Scla\u00b7ven", "nicht", "ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Wo lebt itzt der Poet/ der dis Geheimni\u00df schonet?", "tokens": ["Wo", "lebt", "itzt", "der", "Po\u00b7et", "/", "der", "dis", "Ge\u00b7heim\u00b7ni\u00df", "scho\u00b7net", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "So bald er einen merckt/ der ihm die Arbeit lohnet/", "tokens": ["So", "bald", "er", "ei\u00b7nen", "merckt", "/", "der", "ihm", "die", "Ar\u00b7beit", "loh\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PIS", "VVFIN", "$(", "ART", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Wird seinem Pegasus der Sattel aufgelegt/", "tokens": ["Wird", "sei\u00b7nem", "Pe\u00b7ga\u00b7sus", "der", "Sat\u00b7tel", "auf\u00b7ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Der ein erkaufftes Lob bi\u00df an den Himmel tr\u00e4gt;", "tokens": ["Der", "ein", "er\u00b7kauff\u00b7tes", "Lob", "bi\u00df", "an", "den", "Him\u00b7mel", "tr\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Den wir mit solcher Post so offt zum Zorne reitzen/", "tokens": ["Den", "wir", "mit", "sol\u00b7cher", "Post", "so", "offt", "zum", "Zor\u00b7ne", "reit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIAT", "NN", "ADV", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Und \u00f6ffter noch vielleicht/ als sich die Sterne schneutzen.", "tokens": ["Und", "\u00f6ff\u00b7ter", "noch", "viel\u00b7leicht", "/", "als", "sich", "die", "Ster\u00b7ne", "schneut\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ADV", "$(", "KOUS", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Da\u00df grossen theils die Welt in tr\u00e4ger Lust verdirbt/", "tokens": ["Da\u00df", "gros\u00b7sen", "theils", "die", "Welt", "in", "tr\u00e4\u00b7ger", "Lust", "ver\u00b7dirbt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Und sich um wahren Ruhm so selten mehr bewirbt/", "tokens": ["Und", "sich", "um", "wah\u00b7ren", "Ruhm", "so", "sel\u00b7ten", "mehr", "be\u00b7wirbt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ADJA", "NN", "ADV", "ADJD", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Ist der Poeten Schuld: Der Weyrauch wird verschwen-", "tokens": ["Ist", "der", "Po\u00b7et\u00b7en", "Schuld", ":", "Der", "Wey\u00b7rauch", "wird", "ver\u00b7schwen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NN", "$.", "ART", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Und manchem Leib und Seel um die Geb\u00fchr verpf\u00e4ndet/", "tokens": ["Und", "man\u00b7chem", "Leib", "und", "Seel", "um", "die", "Ge\u00b7b\u00fchr", "ver\u00b7pf\u00e4n\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Da\u00df die Unsterblichkeit ihm nimmer fehlen kan/", "tokens": ["Da\u00df", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", "ihm", "nim\u00b7mer", "feh\u00b7len", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.128": {"text": "Der wie ein Erden Schwam sich kaum hervor gethan/", "tokens": ["Der", "wie", "ein", "Er\u00b7den", "Schwam", "sich", "kaum", "her\u00b7vor", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "NN", "NE", "PRF", "ADV", "PTKVZ", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Und den sonst anders nichts vom P\u00f6bel unterscheidet/", "tokens": ["Und", "den", "sonst", "an\u00b7ders", "nichts", "vom", "P\u00f6\u00b7bel", "un\u00b7ter\u00b7schei\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADV", "PIS", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Als da\u00df ein bl\u00f6der F\u00fcrst ihn an der Seite leidet/", "tokens": ["Als", "da\u00df", "ein", "bl\u00f6\u00b7der", "F\u00fcrst", "ihn", "an", "der", "Sei\u00b7te", "lei\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Da er f\u00fcr jedes Loth/ das ihm an Tugend fehlt/", "tokens": ["Da", "er", "f\u00fcr", "je\u00b7des", "Loth", "/", "das", "ihm", "an", "Tu\u00b7gend", "fehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "$(", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Ein Pfund des eitlen Gl\u00fccks und schn\u00f6den Goldes", "tokens": ["Ein", "Pfund", "des", "eit\u00b7len", "Gl\u00fccks", "und", "schn\u00f6\u00b7den", "Gol\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.133": {"text": "Man denckt und schreibt nicht mehr/ was sich zur Sache", "tokens": ["Man", "denckt", "und", "schreibt", "nicht", "mehr", "/", "was", "sich", "zur", "Sa\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PTKNEG", "ADV", "$(", "PWS", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.134": {"text": "schicket/", "tokens": ["schi\u00b7cket", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.135": {"text": "Es wird nach der Vernunfft kein Einfall ausgedr\u00fccket;", "tokens": ["Es", "wird", "nach", "der", "Ver\u00b7nunfft", "kein", "Ein\u00b7fall", "aus\u00b7ge\u00b7dr\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Der Bogen ist gef\u00fcllt/ eh man an sie gedacht;", "tokens": ["Der", "Bo\u00b7gen", "ist", "ge\u00b7f\u00fcllt", "/", "eh", "man", "an", "sie", "ge\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "KOUS", "PIS", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.137": {"text": "Was gro\u00df ist/ das wird klein/ was klein ist/ gro\u00df gemacht;", "tokens": ["Was", "gro\u00df", "ist", "/", "das", "wird", "klein", "/", "was", "klein", "ist", "/", "gro\u00df", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$(", "PDS", "VAFIN", "ADJD", "$(", "PWS", "ADJD", "VAFIN", "$(", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Da doch ein jeder wei\u00df/ da\u00df in den Schildereyen", "tokens": ["Da", "doch", "ein", "je\u00b7der", "wei\u00df", "/", "da\u00df", "in", "den", "Schil\u00b7de\u00b7re\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "PIS", "VVFIN", "$(", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.139": {"text": "Allein die Aehnlichkeit das Auge kan erfreuen/", "tokens": ["Al\u00b7lein", "die", "A\u00b7ehn\u00b7lich\u00b7keit", "das", "Au\u00b7ge", "kan", "er\u00b7freu\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.140": {"text": "Und eines Zwerges Bild die Artigkeit verliert/", "tokens": ["Und", "ei\u00b7nes", "Zwer\u00b7ges", "Bild", "die", "Ar\u00b7tig\u00b7keit", "ver\u00b7liert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Wenn er wird in Gestalt des Riesen aufgef\u00fchrt.", "tokens": ["Wenn", "er", "wird", "in", "Ge\u00b7stalt", "des", "Rie\u00b7sen", "auf\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.142": {"text": "Wir lesen ja mit Lust Aeneas Abentheur/", "tokens": ["Wir", "le\u00b7sen", "ja", "mit", "Lust", "A\u00b7e\u00b7neas", "A\u00b7bent\u00b7heur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Warum? st\u00f6\u00dft ihm zur Hand ein grimmig Ungeheur/", "tokens": ["Wa\u00b7rum", "?", "st\u00f6\u00dft", "ihm", "zur", "Hand", "ein", "grim\u00b7mig", "Un\u00b7ge\u00b7heur", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.144": {"text": "So hat es sein Virgil so gl\u00fccklich vorgestellt/", "tokens": ["So", "hat", "es", "sein", "Vir\u00b7gil", "so", "gl\u00fcck\u00b7lich", "vor\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Da\u00df uns/ ich wei\u00df nicht wie/ ein Schr\u00f6cken \u00fcberf\u00e4llt.", "tokens": ["Da\u00df", "uns", "/", "ich", "wei\u00df", "nicht", "wie", "/", "ein", "Schr\u00f6\u00b7cken", "\u00fc\u00b7berf\u00b7\u00e4llt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$(", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Und h\u00f6r\u2019 ich Dido dort von Lieb und Undanck sprechen/", "tokens": ["Und", "h\u00f6r'", "ich", "Di\u00b7do", "dort", "von", "Lieb", "und", "Un\u00b7danck", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NE", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "So m\u00f6cht ich ihren Hohn an den Trojanern r\u00e4chen;", "tokens": ["So", "m\u00f6cht", "ich", "ih\u00b7ren", "Hohn", "an", "den", "Tro\u00b7ja\u00b7nern", "r\u00e4\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.148": {"text": "So k\u00fcnstlich trifft itzund kein Tichter die Natur/", "tokens": ["So", "k\u00fcnst\u00b7lich", "trifft", "it\u00b7zund", "kein", "Tich\u00b7ter", "die", "Na\u00b7tur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "PIAT", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Sie ist ihm viel zu schlecht/ er sucht ihm neue Spuhr:", "tokens": ["Sie", "ist", "ihm", "viel", "zu", "schlecht", "/", "er", "sucht", "ihm", "neu\u00b7e", "Spuhr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$(", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Geu\u00dft solche Thr\u00e4nen aus die Lachens-w\u00fcrdig scheinen/", "tokens": ["Geu\u00dft", "sol\u00b7che", "Thr\u00e4\u00b7nen", "aus", "die", "La\u00b7chens\u00b7w\u00fcr\u00b7dig", "schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIAT", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Und wenn er lachen wil/ so m\u00f6chten andre weinen.", "tokens": ["Und", "wenn", "er", "la\u00b7chen", "wil", "/", "so", "m\u00f6ch\u00b7ten", "and\u00b7re", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVINF", "VMFIN", "$(", "ADV", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Ein Teutscher ist gelehrt wenn er sein Teutsch versteht/", "tokens": ["Ein", "Teut\u00b7scher", "ist", "ge\u00b7lehrt", "wenn", "er", "sein", "Teutsch", "ver\u00b7steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Kein Wort k\u00f6mmt f\u00fcr den Tag das nicht auf Steltzen", "tokens": ["Kein", "Wort", "k\u00f6mmt", "f\u00fcr", "den", "Tag", "das", "nicht", "auf", "Stelt\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "PDS", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.154": {"text": "F\u00e4llt das geringste vor in diesen Krieges-Zeiten/", "tokens": ["F\u00e4llt", "das", "ge\u00b7rings\u00b7te", "vor", "in", "die\u00b7sen", "Krie\u00b7ge\u00b7sZei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "APPR", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "So d\u00fcnckt mich h\u00f6r ich schon die Wetter-Klocke leuten/", "tokens": ["So", "d\u00fcnckt", "mich", "h\u00f6r", "ich", "schon", "die", "Wet\u00b7ter\u00b7Klo\u00b7cke", "leu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Ein Flammen-schwangrer Dampff beschw\u00e4rtzt das Lufft-", "tokens": ["Ein", "Flam\u00b7men\u00b7schwan\u00b7grer", "Dampff", "be\u00b7schw\u00e4rtzt", "das", "Lufft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.157": {"text": "Der Straal-beschw\u00e4ntzte Blitz bricht \u00fcberall herf\u00fcr/", "tokens": ["Der", "Straa\u00b7lbe\u00b7schw\u00e4ntz\u00b7te", "Blitz", "bricht", "\u00fc\u00b7be\u00b7rall", "her\u00b7f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Der grause Donner br\u00fcllt/ und spielt mit Schwefel-", "tokens": ["Der", "grau\u00b7se", "Don\u00b7ner", "br\u00fcllt", "/", "und", "spielt", "mit", "Schwe\u00b7fel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "KON", "VVFIN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.159": {"text": "Der Leser wird betr\u00fcbt/ beginnet fort zu eylen/", "tokens": ["Der", "Le\u00b7ser", "wird", "be\u00b7tr\u00fcbt", "/", "be\u00b7gin\u00b7net", "fort", "zu", "ey\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Bi\u00df er ins Truckne kom\u0303t/ weil doch ein Wolcken-Gu\u00df/", "tokens": ["Bi\u00df", "er", "ins", "Truck\u00b7ne", "kom\u0303t", "/", "weil", "doch", "ein", "Wol\u00b7cken\u00b7Gu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$(", "KOUS", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Auf solchen starcken Knall/ nothwendig folgen mu\u00df/", "tokens": ["Auf", "sol\u00b7chen", "star\u00b7cken", "Knall", "/", "noth\u00b7wen\u00b7dig", "fol\u00b7gen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$(", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Und l\u00e4\u00dft den armen Tropff der Welt zur Straffe reimen/", "tokens": ["Und", "l\u00e4\u00dft", "den", "ar\u00b7men", "Tropff", "der", "Welt", "zur", "Straf\u00b7fe", "rei\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Wie ein Bese\u00dfner pflegt in seiner Angst zu scheumen/", "tokens": ["Wie", "ein", "Be\u00b7se\u00df\u00b7ner", "pflegt", "in", "sei\u00b7ner", "Angst", "zu", "scheu\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Geht wo ein Schul-Regent in einem Flecken ab/", "tokens": ["Geht", "wo", "ein", "Schul\u00b7Re\u00b7gent", "in", "ei\u00b7nem", "Fle\u00b7cken", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWAV", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Mein GOtt! wie rasen nicht die Tichter um sein Grab;", "tokens": ["Mein", "Gott", "!", "wie", "ra\u00b7sen", "nicht", "die", "Tich\u00b7ter", "um", "sein", "Grab", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PWAV", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Der Tod wird ausgefiltzt/ da\u00df er dem theuren Leben/", "tokens": ["Der", "Tod", "wird", "aus\u00b7ge\u00b7filtzt", "/", "da\u00df", "er", "dem", "theu\u00b7ren", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "KOUS", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Nicht eine l\u00e4ngre Frist/ als achtzig Jahr gegeben;", "tokens": ["Nicht", "ei\u00b7ne", "l\u00e4ng\u00b7re", "Frist", "/", "als", "acht\u00b7zig", "Jahr", "ge\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$(", "KOKOM", "CARD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Die Erde wird bewegt/ im Himmel Lerm gemacht/", "tokens": ["Die", "Er\u00b7de", "wird", "be\u00b7wegt", "/", "im", "Him\u00b7mel", "Lerm", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "APPRART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Minerva wenn sie gleich in ihrem Hertzen lacht/", "tokens": ["Mi\u00b7ner\u00b7va", "wenn", "sie", "gleich", "in", "ih\u00b7rem", "Hert\u00b7zen", "lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.170": {"text": "Auch Ph\u00f6bus und sein Chor/ die m\u00fcssen wider Willen/", "tokens": ["Auch", "Ph\u00f6\u00b7bus", "und", "sein", "Chor", "/", "die", "m\u00fcs\u00b7sen", "wi\u00b7der", "Wil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "KON", "PPOSAT", "NN", "$(", "ART", "VMFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Sich traurig/ ohne Trost/ in Flohr und Boy verh\u00fcllen.", "tokens": ["Sich", "trau\u00b7rig", "/", "oh\u00b7ne", "Trost", "/", "in", "Flohr", "und", "Boy", "ver\u00b7h\u00fcl\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "$(", "APPR", "NN", "$(", "APPR", "NN", "KON", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Mehr G\u00f6tter sieht man offt auf solchem Zettel stehn/", "tokens": ["Mehr", "G\u00f6t\u00b7ter", "sieht", "man", "offt", "auf", "sol\u00b7chem", "Zet\u00b7tel", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Als B\u00fcrger in der That mit zu der Leiche gehn;", "tokens": ["Als", "B\u00fcr\u00b7ger", "in", "der", "That", "mit", "zu", "der", "Lei\u00b7che", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Ein andrer von dem Pfeil des Liebens angeschossen/", "tokens": ["Ein", "an\u00b7drer", "von", "dem", "Pfeil", "des", "Lie\u00b7bens", "an\u00b7ge\u00b7schos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Er\u00f6ffnet seinen Schmertz mit hundert Gauckel-Possen/", "tokens": ["Er\u00b7\u00f6ff\u00b7net", "sei\u00b7nen", "Schmertz", "mit", "hun\u00b7dert", "Gau\u00b7ckel\u00b7Pos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Da\u00df man gesundern Witz bey jenem T\u00e4ntzer sp\u00fchrt/", "tokens": ["Da\u00df", "man", "ge\u00b7sun\u00b7dern", "Witz", "bey", "je\u00b7nem", "T\u00e4nt\u00b7zer", "sp\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJA", "NN", "APPR", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Den die Tarantula mit ihrem Stich ber\u00fchrt;", "tokens": ["Den", "die", "Ta\u00b7ran\u00b7tu\u00b7la", "mit", "ih\u00b7rem", "Stich", "be\u00b7r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NE", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.178": {"text": "Was er von Kindheit an aus B\u00fcchern abgeschrieben/", "tokens": ["Was", "er", "von", "Kind\u00b7heit", "an", "aus", "B\u00fc\u00b7chern", "ab\u00b7ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "APPR", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Das wird mit M\u00fch und Zwang in einen Ver\u00df getrieben;", "tokens": ["Das", "wird", "mit", "M\u00fch", "und", "Zwang", "in", "ei\u00b7nen", "Ver\u00df", "ge\u00b7trie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "KON", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Die Seuffzer/ wie er meynet/ erweichen Kieselstein/", "tokens": ["Die", "Seuff\u00b7zer", "/", "wie", "er", "mey\u00b7net", "/", "er\u00b7wei\u00b7chen", "Kie\u00b7sel\u00b7stein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWAV", "PPER", "VVFIN", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.181": {"text": "Die voll Gelehrsamkeit und wohl belesen seyn.", "tokens": ["Die", "voll", "Ge\u00b7lehr\u00b7sam\u00b7keit", "und", "wohl", "be\u00b7le\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "KON", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Des Aetna Feuer-Klufft mu\u00df seiner Liebe gleichen/", "tokens": ["Des", "A\u00b7et\u00b7na", "Feu\u00b7er\u00b7Klufft", "mu\u00df", "sei\u00b7ner", "Lie\u00b7be", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.183": {"text": "Und aller Alpen Ey\u00df/ der Liebsten K\u00e4lte weichen/", "tokens": ["Und", "al\u00b7ler", "Al\u00b7pen", "Ey\u00df", "/", "der", "Liebs\u00b7ten", "K\u00e4l\u00b7te", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "$(", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Indessen aber wird das arme Kind beth\u00f6rt/", "tokens": ["In\u00b7des\u00b7sen", "a\u00b7ber", "wird", "das", "ar\u00b7me", "Kind", "be\u00b7th\u00f6rt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Und wei\u00df nicht was sie f\u00fchlt/ wenn sie dergleichen", "tokens": ["Und", "wei\u00df", "nicht", "was", "sie", "f\u00fchlt", "/", "wenn", "sie", "derg\u00b7lei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "PWS", "PPER", "VVFIN", "$(", "KOUS", "PPER", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.186": {"text": "Ja wenn ihr Coridon geb\u00fcckt vor ihren F\u00fcssen/", "tokens": ["Ja", "wenn", "ihr", "Co\u00b7ri\u00b7don", "ge\u00b7b\u00fcckt", "vor", "ih\u00b7ren", "F\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPOSAT", "NN", "VVPP", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Der Klage Bitterkeit ein wenig zu vers\u00fcssen/", "tokens": ["Der", "Kla\u00b7ge", "Bit\u00b7ter\u00b7keit", "ein", "we\u00b7nig", "zu", "ver\u00b7s\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ART", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Nichts anders als Zibeth und Ambra von sich haucht/", "tokens": ["Nichts", "an\u00b7ders", "als", "Zi\u00b7beth", "und", "A\u00b7mbra", "von", "sich", "haucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "KOUS", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Und sie kein Biebergeil zum Gegenmittel braucht/", "tokens": ["Und", "sie", "kein", "Bie\u00b7ber\u00b7geil", "zum", "Ge\u00b7gen\u00b7mit\u00b7tel", "braucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIAT", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "So mag des M\u00f6rders Hand was ihm von seinem Tich-", "tokens": ["So", "mag", "des", "M\u00f6r\u00b7ders", "Hand", "was", "ihm", "von", "sei\u00b7nem", "Tich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "NN", "NN", "PWS", "PPER", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Noch etwan \u00fcbrig bleibt/ auf ihre Grabschrifft richten.", "tokens": ["Noch", "et\u00b7wan", "\u00fcb\u00b7rig", "bleibt", "/", "auf", "ih\u00b7re", "Grab\u00b7schrifft", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVFIN", "$(", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}