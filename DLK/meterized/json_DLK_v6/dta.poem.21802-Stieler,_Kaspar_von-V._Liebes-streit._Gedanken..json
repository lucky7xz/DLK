{"dta.poem.21802": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "V.  \n  Liebes-streit. Gedanken.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Ich sach mit einer einen scherzen/", "tokens": ["Ich", "sach", "mit", "ei\u00b7ner", "ei\u00b7nen", "scher\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ART", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da fiel die Rosilis mir ein.", "tokens": ["da", "fiel", "die", "Ro\u00b7si\u00b7lis", "mir", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was? fiel erst Rosilis mir ein/", "tokens": ["Was", "?", "fiel", "erst", "Ro\u00b7si\u00b7lis", "mir", "ein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "VVFIN", "ADV", "NE", "PPER", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als ich die beyde sahe scherzen?", "tokens": ["als", "ich", "die", "bey\u00b7de", "sa\u00b7he", "scher\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PIS", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die Rosilis ist allzeit mein", "tokens": ["die", "Ro\u00b7si\u00b7lis", "ist", "all\u00b7zeit", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VAFIN", "ADV", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und schwebet stets in meinem Herzen.", "tokens": ["und", "schwe\u00b7bet", "stets", "in", "mei\u00b7nem", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Es schmazzten vier Korallen-Lippen/", "tokens": ["Es", "schmazz\u00b7ten", "vier", "Ko\u00b7ral\u00b7len\u00b7\u00b7Lip\u00b7pen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da dacht\u2019 ich auff Rosillen hin.", "tokens": ["da", "dacht'", "ich", "auff", "Ro\u00b7sil\u00b7len", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dacht\u2019 ich auff ihre Lippen hin/", "tokens": ["Dacht'", "ich", "auff", "ih\u00b7re", "Lip\u00b7pen", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als schmazzten vier Korallen Lippen", "tokens": ["als", "schmazz\u00b7ten", "vier", "Ko\u00b7ral\u00b7len", "Lip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "CARD", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nein. Lauter Rosen und Rubin", "tokens": ["Nein", ".", "Lau\u00b7ter", "Ro\u00b7sen", "und", "Ru\u00b7bin"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADJA", "NN", "KON", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Ich sach zwey Liljen-H\u00e4nde dr\u00fckken", "tokens": ["Ich", "sach", "zwey", "Lil\u00b7jen\u00b7H\u00e4n\u00b7de", "dr\u00fck\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "CARD", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist weisser nicht Rosillen Hand/", "tokens": ["Ist", "weis\u00b7ser", "nicht", "Ro\u00b7sil\u00b7len", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wenn sie die meinen pflegt zu dr\u00fckken?", "tokens": ["wenn", "sie", "die", "mei\u00b7nen", "pflegt", "zu", "dr\u00fck\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PPOSAT", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht Schnee noch Wolle h\u00e4lt Bestand", "tokens": ["Nicht", "Schnee", "noch", "Wol\u00b7le", "h\u00e4lt", "Be\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "NN", "ADV", "NE", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "f\u00fcr ihrer H\u00e4nde silber-blikken.", "tokens": ["f\u00fcr", "ih\u00b7rer", "H\u00e4n\u00b7de", "sil\u00b7ber\u00b7blik\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich sach vier Arme sich umfassen/", "tokens": ["Ich", "sach", "vier", "Ar\u00b7me", "sich", "um\u00b7fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie? liebt die Rosilis so mich/", "tokens": ["Wie", "?", "liebt", "die", "Ro\u00b7si\u00b7lis", "so", "mich", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "ART", "NE", "ADV", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "durch ihr bes\u00fc\u00dftes Arm-umfassen?", "tokens": ["durch", "ihr", "be\u00b7s\u00fc\u00df\u00b7tes", "Ar\u00b7mum\u00b7fas\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Tugend hat sie mehr bey sich/", "tokens": ["Die", "Tu\u00b7gend", "hat", "sie", "mehr", "bey", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "APPR", "PRF", "$("], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "was \u00fcbrig/ wil sie zu-mir-lassen.", "tokens": ["was", "\u00fcb\u00b7rig", "/", "wil", "sie", "zu\u00b7mir\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "$(", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Es waren in dem Busen H\u00e4nde:", "tokens": ["Es", "wa\u00b7ren", "in", "dem", "Bu\u00b7sen", "H\u00e4n\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So treib\u2019 ichs mit Rosillen auch.", "tokens": ["So", "treib'", "ichs", "mit", "Ro\u00b7sil\u00b7len", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein! leidet Rosilis di\u00df auch/", "tokens": ["Mein", "!", "lei\u00b7det", "Ro\u00b7si\u00b7lis", "di\u00df", "auch", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "VVFIN", "NE", "PDS", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und l\u00e4\u00dft darinnen deine H\u00e4nde?", "tokens": ["und", "l\u00e4\u00dft", "da\u00b7rin\u00b7nen", "dei\u00b7ne", "H\u00e4n\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Rosill\u2019 hat dieses nicht im Brauch/", "tokens": ["Ro\u00b7sill'", "hat", "die\u00b7ses", "nicht", "im", "Brauch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PDS", "PTKNEG", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sie sahen sich beyd\u2019 an und lachten:", "tokens": ["Sie", "sa\u00b7hen", "sich", "beyd'", "an", "und", "lach\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer sagt was von der Rosilis/", "tokens": ["Wer", "sagt", "was", "von", "der", "Ro\u00b7si\u00b7lis", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "APPR", "ART", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie ich und Sie zusammen lachten?", "tokens": ["wie", "ich", "und", "Sie", "zu\u00b7sam\u00b7men", "lach\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "KON", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja/ wenn ich Koridon schon hie\u00df/", "tokens": ["Ja", "/", "wenn", "ich", "Ko\u00b7ri\u00b7don", "schon", "hie\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "KOUS", "PPER", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es war nur ein Gem\u00fcht in zweyen:", "tokens": ["Es", "war", "nur", "ein", "Ge\u00b7m\u00fcht", "in", "zwe\u00b7yen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ja/ freylich/ ist sie so gesinnt/", "tokens": ["Ja", "/", "frey\u00b7lich", "/", "ist", "sie", "so", "ge\u00b7sinnt", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "$(", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "es lebt nur ein Geist in uns Zweyen.", "tokens": ["es", "lebt", "nur", "ein", "Geist", "in", "uns", "Zwe\u00b7yen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "PPER", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ach", "tokens": ["Ach"], "token_info": ["word"], "pos": ["ITJ"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "dar\u00fcber mich nicht herzlich freuen.", "tokens": ["da\u00b7r\u00fc\u00b7ber", "mich", "nicht", "herz\u00b7lich", "freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "La\u00df andre lachen/ la\u00df sie klagen/", "tokens": ["La\u00df", "and\u00b7re", "la\u00b7chen", "/", "la\u00df", "sie", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "VVINF", "$(", "VVIMP", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "la\u00df herzen/ scherzen und was mehr.", "tokens": ["la\u00df", "her\u00b7zen", "/", "scher\u00b7zen", "und", "was", "mehr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVINF", "$(", "VVINF", "KON", "PWS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich d\u00fcrff kein Zeugn\u00fc\u00df/ Herze/ mehr/", "tokens": ["Ich", "d\u00fcrff", "kein", "Zeug\u00b7n\u00fc\u00df", "/", "Her\u00b7ze", "/", "mehr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "$(", "VVFIN", "$(", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als dein bey meinem hingehn/ klagen.", "tokens": ["als", "dein", "bey", "mei\u00b7nem", "hin\u00b7gehn", "/", "kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "APPR", "PPOSAT", "VVINF", "$(", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Rosille liebt mich noch so sehr/", "tokens": ["Ro\u00b7sil\u00b7le", "liebt", "mich", "noch", "so", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als ich beschreiben kan und sagen.", "tokens": ["als", "ich", "be\u00b7schrei\u00b7ben", "kan", "und", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}