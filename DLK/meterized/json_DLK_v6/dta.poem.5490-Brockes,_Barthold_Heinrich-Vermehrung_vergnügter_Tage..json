{"dta.poem.5490": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Vermehrung vergn\u00fcgter Tage.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Bey aufgekl\u00e4rter Luft, im warmen Sonnen-Strahl,", "tokens": ["Bey", "auf\u00b7ge\u00b7kl\u00e4r\u00b7ter", "Luft", ",", "im", "war\u00b7men", "Son\u00b7nen\u00b7Strahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Spricht mancher Mensch noch wol einmahl:", "tokens": ["Spricht", "man\u00b7cher", "Mensch", "noch", "wol", "ein\u00b7mahl", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Heut ist das Wetter sch\u00f6n!", "tokens": ["Heut", "ist", "das", "Wet\u00b7ter", "sch\u00f6n", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Kaum aber hat er die\u00df gesprochen,", "tokens": ["Kaum", "a\u00b7ber", "hat", "er", "die\u00df", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wird seine Red\u2019 und Lust gleich abgebrochen.", "tokens": ["Wird", "sei\u00b7ne", "Red'", "und", "Lust", "gleich", "ab\u00b7ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Er l\u00e4\u00dft den gantzen Tag vergehn,", "tokens": ["Er", "l\u00e4\u00dft", "den", "gant\u00b7zen", "Tag", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ohn an desselben Pracht und an der Sonnen Sch\u00e4tzen", "tokens": ["Ohn", "an", "des\u00b7sel\u00b7ben", "Pracht", "und", "an", "der", "Son\u00b7nen", "Sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "APPR", "PDAT", "NN", "KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sich im geringsten zu ergetzen,", "tokens": ["Sich", "im", "ge\u00b7rings\u00b7ten", "zu", "er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und sie ger\u00fchret anzusehn;", "tokens": ["Und", "sie", "ge\u00b7r\u00fch\u00b7ret", "an\u00b7zu\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da, wenn wir recht vern\u00fcnftig handeln wollten,", "tokens": ["Da", ",", "wenn", "wir", "recht", "ver\u00b7n\u00fcnf\u00b7tig", "han\u00b7deln", "woll\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wir billig \u00fcberlegen sollten,", "tokens": ["Wir", "bil\u00b7lig", "\u00fc\u00b7berl\u00b7e\u00b7gen", "soll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df ja ein sch\u00f6ner Tag, aus vielen Viertel-Stunden,", "tokens": ["Da\u00df", "ja", "ein", "sch\u00f6\u00b7ner", "Tag", ",", "aus", "vie\u00b7len", "Vier\u00b7tel\u00b7Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Noch mehr Minuten und Secunden,", "tokens": ["Noch", "mehr", "Mi\u00b7nu\u00b7ten", "und", "Se\u00b7cun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "In seiner Pracht besteht,", "tokens": ["In", "sei\u00b7ner", "Pracht", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Da\u00df jeder Augenblick, wenn man es nur bedenckt,", "tokens": ["Da\u00df", "je\u00b7der", "Au\u00b7gen\u00b7blick", ",", "wenn", "man", "es", "nur", "be\u00b7denckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "$,", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Uns eine neue Lust und solche Freude schenckt,", "tokens": ["Uns", "ei\u00b7ne", "neu\u00b7e", "Lust", "und", "sol\u00b7che", "Freu\u00b7de", "schenckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die uns ein gantzer Tag", "tokens": ["Die", "uns", "ein", "gant\u00b7zer", "Tag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Der ungef\u00fchlt verstreicht zu geben nicht vermag.", "tokens": ["Der", "un\u00b7ge\u00b7f\u00fchlt", "ver\u00b7streicht", "zu", "ge\u00b7ben", "nicht", "ver\u00b7mag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVPP", "PTKZU", "VVINF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wir theilen sonst die Zeit", "tokens": ["Wir", "thei\u00b7len", "sonst", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Durch Uhren ein:", "tokens": ["Durch", "Uh\u00b7ren", "ein", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Warum wird doch der Anmuth Fl\u00fcchtigkeit", "tokens": ["Wa\u00b7rum", "wird", "doch", "der", "An\u00b7muth", "Fl\u00fcch\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Durch Theile nicht gehemmt? Ach w\u00fcrde, GOtt zu Ehren,", "tokens": ["Durch", "Thei\u00b7le", "nicht", "ge\u00b7hemmt", "?", "Ach", "w\u00fcr\u00b7de", ",", "Gott", "zu", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVPP", "$.", "NN", "VAFIN", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch unsre Lust zugleich dadurch zu mehren,", "tokens": ["Auch", "uns\u00b7re", "Lust", "zu\u00b7gleich", "da\u00b7durch", "zu", "meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bey sch\u00f6nem Wetter doch zum \u00f6ftern \u00fcberdacht:", "tokens": ["Bey", "sch\u00f6\u00b7nem", "Wet\u00b7ter", "doch", "zum", "\u00f6f\u00b7tern", "\u00fc\u00b7berd\u00b7acht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Aufs neu' hab ich ein Theil von meinem Leben,", "tokens": ["Aufs", "neu'", "hab", "ich", "ein", "Theil", "von", "mei\u00b7nem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VAFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das mir der Sch\u00f6pfer hat gegeben,", "tokens": ["Das", "mir", "der", "Sch\u00f6p\u00b7fer", "hat", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Jm sch\u00f6nen Sonnen-Licht, GOTT Lob! ver-\ngn\u00fcgt verbracht:", "tokens": ["Jm", "sch\u00f6\u00b7nen", "Son\u00b7nen\u00b7Licht", ",", "GoTT", "Lob", "!", "ver", "gn\u00fcgt", "ver\u00b7bracht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "NE", "NN", "$.", "TRUNC", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Hiedurch kann uns ein sch\u00f6ner Tag auf Erden,", "tokens": ["Hie\u00b7durch", "kann", "uns", "ein", "sch\u00f6\u00b7ner", "Tag", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den wir, da man an ihn so kurtze Zeit gedacht,", "tokens": ["Den", "wir", ",", "da", "man", "an", "ihn", "so", "kurt\u00b7ze", "Zeit", "ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "KOUS", "PIS", "APPR", "PPER", "ADV", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fast zur Minute nur bi\u00dfher gemacht,", "tokens": ["Fast", "zur", "Mi\u00b7nu\u00b7te", "nur", "bi\u00df\u00b7her", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Zu vielen sch\u00f6nen Tagen werden.", "tokens": ["Zu", "vie\u00b7len", "sch\u00f6\u00b7nen", "Ta\u00b7gen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil eigentlich durchs Dencken blos allein", "tokens": ["Weil", "ei\u00b7gent\u00b7lich", "durchs", "Den\u00b7cken", "blos", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPRART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wir im Besitz vom Guten seyn.", "tokens": ["Wir", "im", "Be\u00b7sitz", "vom", "Gu\u00b7ten", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}