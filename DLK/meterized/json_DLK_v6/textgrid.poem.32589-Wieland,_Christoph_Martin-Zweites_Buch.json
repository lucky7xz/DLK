{"textgrid.poem.32589": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "Zweites Buch", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was, beim Anubis! konnte das", "tokens": ["Was", ",", "beim", "A\u00b7nu\u00b7bis", "!", "konn\u00b7te", "das"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWS", "$,", "APPRART", "NN", "$.", "VMFIN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr eine Stellung sein, in welcher Phanias", "tokens": ["F\u00fcr", "ei\u00b7ne", "Stel\u00b7lung", "sein", ",", "in", "wel\u00b7cher", "Pha\u00b7ni\u00b7as"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAINF", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die beiden Weisen angetroffen?", "tokens": ["Die", "bei\u00b7den", "Wei\u00b7sen", "an\u00b7ge\u00b7trof\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbsie lagen doch \u2013 wir wollen bessers hoffen! \u2013", "tokens": ["\u00bb", "sie", "la\u00b7gen", "doch", "\u2013", "wir", "wol\u00b7len", "bes\u00b7sers", "hof\u00b7fen", "!", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "$(", "PPER", "VMFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nicht s\u00fc\u00dfen Weines voll im Gras?\u00ab", "tokens": ["Nicht", "s\u00fc\u00b7\u00dfen", "Wei\u00b7nes", "voll", "im", "Gras", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "ADJD", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dies nicht. \u2013 \u00bbSo ritten sie vielleicht auf Steckenpferden?\u00ab", "tokens": ["Dies", "nicht", ".", "\u2013", "\u00bb", "So", "rit\u00b7ten", "sie", "viel\u00b7leicht", "auf", "Ste\u00b7cken\u00b7pfer\u00b7den", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PTKNEG", "$.", "$(", "$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das k\u00f6nnte noch entschuldigt werden;", "tokens": ["Das", "k\u00f6nn\u00b7te", "noch", "ent\u00b7schul\u00b7digt", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Plutarchus r\u00fchmt sogar es an Agesilas.", "tokens": ["Plu\u00b7tar\u00b7chus", "r\u00fchmt", "so\u00b7gar", "es", "an", "A\u00b7ge\u00b7si\u00b7las", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch von so feirlichen Gesichtern, als sie waren,", "tokens": ["Doch", "von", "so", "feir\u00b7li\u00b7chen", "Ge\u00b7sich\u00b7tern", ",", "als", "sie", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "ADJA", "NN", "$,", "KOUS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Vermutet sich nichts weniger als das,", "tokens": ["Ver\u00b7mu\u00b7tet", "sich", "nichts", "we\u00b7ni\u00b7ger", "als", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIS", "PIS", "KOKOM", "PDS", "$,"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Ihr Zeitvertreib war in der Tat kein Spa\u00df;", "tokens": ["Ihr", "Zeit\u00b7ver\u00b7treib", "war", "in", "der", "Tat", "kein", "Spa\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Denn, kurz, sie hatten sich einander bei den Haaren.", "tokens": ["Denn", ",", "kurz", ",", "sie", "hat\u00b7ten", "sich", "ein\u00b7an\u00b7der", "bei", "den", "Haa\u00b7ren", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "$,", "PPER", "VAFIN", "PRF", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der nervige Kleanth war im Begriff, ein Knie", "tokens": ["Der", "ner\u00b7vi\u00b7ge", "Kle\u00b7an\u00b7th", "war", "im", "Be\u00b7griff", ",", "ein", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPRART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "Dem Gegner auf die Brust zu setzen,", "tokens": ["Dem", "Geg\u00b7ner", "auf", "die", "Brust", "zu", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der, unter ihn gekr\u00fcmmt, f\u00fcr die Philosophie,", "tokens": ["Der", ",", "un\u00b7ter", "ihn", "ge\u00b7kr\u00fcmmt", ",", "f\u00fcr", "die", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "PPER", "VVPP", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die keine Bohnen i\u00dft,", "tokens": ["Die", "kei\u00b7ne", "Boh\u00b7nen", "i\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "In ihrem Skythischen Ergetzen", "tokens": ["In", "ih\u00b7rem", "Sky\u00b7thi\u00b7schen", "Er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Des Hausherrn Ankunft st\u00f6rt. Besch\u00e4mt, als h\u00e4tte ihn", "tokens": ["Des", "Haus\u00b7herrn", "An\u00b7kunft", "st\u00f6rt", ".", "Be\u00b7sch\u00e4mt", ",", "als", "h\u00e4t\u00b7te", "ihn"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "VVPP", "$,", "KOKOM", "VAFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein Feind bei einer Tat, die keine fremde Leute", "tokens": ["Sein", "Feind", "bei", "ei\u00b7ner", "Tat", ",", "die", "kei\u00b7ne", "frem\u00b7de", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zu Zeugen nimmt, ertappt, zum Stehn wie zum Entfliehn", "tokens": ["Zu", "Zeu\u00b7gen", "nimmt", ",", "er\u00b7tappt", ",", "zum", "Stehn", "wie", "zum", "Ent\u00b7fliehn"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "$,", "VVPP", "$,", "APPRART", "NN", "KOKOM", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Unschl\u00fcssig, w\u00fcnscht er nur dem Gast an seiner Seite", "tokens": ["Un\u00b7schl\u00fcs\u00b7sig", ",", "w\u00fcnscht", "er", "nur", "dem", "Gast", "an", "sei\u00b7ner", "Sei\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein Schauspiel zu entziehn, das Sie weit mehr erfreute", "tokens": ["Ein", "Schau\u00b7spiel", "zu", "ent\u00b7ziehn", ",", "das", "Sie", "weit", "mehr", "er\u00b7freu\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "PPER", "ADJD", "ADV", "VVFIN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Als von Menandern selbst (dem Attischen Goldon)", "tokens": ["Als", "von", "Me\u00b7nan\u00b7dern", "selbst", "(", "dem", "At\u00b7ti\u00b7schen", "Gol\u00b7don", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ADV", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das beste St\u00fcck. Allein sie waren schon", "tokens": ["Das", "bes\u00b7te", "St\u00fcck", ".", "Al\u00b7lein", "sie", "wa\u00b7ren", "schon"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ADV", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Zu nah, sie sah zu gut, der Schauplatz war zu offen,", "tokens": ["Zu", "nah", ",", "sie", "sah", "zu", "gut", ",", "der", "Schau\u00b7platz", "war", "zu", "of\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "PPER", "VVFIN", "PTKA", "ADJD", "$,", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er konnte nicht sie zu bereden hoffen", "tokens": ["Er", "konn\u00b7te", "nicht", "sie", "zu", "be\u00b7re\u00b7den", "hof\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "PPER", "PTKZU", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Sie habe nichts gesehn. Die K\u00e4mpfer raffen sich", "tokens": ["Sie", "ha\u00b7be", "nichts", "ge\u00b7sehn", ".", "Die", "K\u00e4mp\u00b7fer", "raf\u00b7fen", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "VVPP", "$.", "ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Indessen auf; sie ziehen sittsamlich", "tokens": ["In\u00b7des\u00b7sen", "auf", ";", "sie", "zie\u00b7hen", "sitt\u00b7sam\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PTKVZ", "$.", "PPER", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Die M\u00e4ntel um sich her, und stehen da und sinnen", "tokens": ["Die", "M\u00e4n\u00b7tel", "um", "sich", "her", ",", "und", "ste\u00b7hen", "da", "und", "sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRF", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "KON", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "(weil Phanias, damit sie Zeit gewinnen,", "tokens": ["(", "weil", "Pha\u00b7ni\u00b7as", ",", "da\u00b7mit", "sie", "Zeit", "ge\u00b7win\u00b7nen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NE", "$,", "KOUS", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Die Nymph am Arm, nur schleichend n\u00e4her kam)", "tokens": ["Die", "Nymph", "am", "Arm", ",", "nur", "schlei\u00b7chend", "n\u00e4\u00b7her", "kam", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ADV", "ADJD", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Der Schmach sich selbst bewu\u00dfter Scham", "tokens": ["Der", "Schmach", "sich", "selbst", "be\u00b7wu\u00df\u00b7ter", "Scham"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PRF", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Durch dialektische M\u00e4ander zu entrinnen.", "tokens": ["Durch", "di\u00b7a\u00b7lek\u00b7ti\u00b7sche", "M\u00e4\u00b7an\u00b7der", "zu", "ent\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.22": {"text": "Vergebens, wenn Musarion", "tokens": ["Ver\u00b7ge\u00b7bens", ",", "wenn", "Mu\u00b7sa\u00b7ri\u00b7on"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADV", "$,", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Gro\u00dfm\u00fctig ihnen nicht zuvor gekommen w\u00e4re.", "tokens": ["Gro\u00df\u00b7m\u00fc\u00b7tig", "ih\u00b7nen", "nicht", "zu\u00b7vor", "ge\u00b7kom\u00b7men", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PTKNEG", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u00bbdie Herren \u00fcben sich\u00ab, spricht mit gela\u00dfnem Ton", "tokens": ["\u00bb", "die", "Her\u00b7ren", "\u00fc\u00b7ben", "sich", "\u00ab", ",", "spricht", "mit", "ge\u00b7la\u00df\u00b7nem", "Ton"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VVFIN", "PRF", "$(", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Sp\u00f6tterin, \u00bbvermutlich nach der Lehre,", "tokens": ["Die", "Sp\u00f6t\u00b7te\u00b7rin", ",", "\u00bb", "ver\u00b7mut\u00b7lich", "nach", "der", "Leh\u00b7re", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "$(", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Da\u00df Leibes\u00fcbung auch des Geistes St\u00e4rke n\u00e4hre.", "tokens": ["Da\u00df", "Lei\u00b7bes\u00b7\u00fc\u00b7bung", "auch", "des", "Geis\u00b7tes", "St\u00e4r\u00b7ke", "n\u00e4h\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ein m\u00e4nnlich Spiel f\u00fcrwahr! wovon", "tokens": ["Ein", "m\u00e4nn\u00b7lich", "Spiel", "f\u00fcr\u00b7wahr", "!", "wo\u00b7von"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJD", "NN", "PTKVZ", "$.", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Mit bestem Recht zu w\u00fcnschen w\u00e4re,", "tokens": ["Mit", "bes\u00b7tem", "Recht", "zu", "w\u00fcn\u00b7schen", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Da\u00df unsrer Sitten Weichlichkeit", "tokens": ["Da\u00df", "uns\u00b7rer", "Sit\u00b7ten", "Weich\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Nicht allgemach es aus der Mode br\u00e4chte.\u00ab", "tokens": ["Nicht", "all\u00b7ge\u00b7mach", "es", "aus", "der", "Mo\u00b7de", "br\u00e4ch\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Man sieht, sie gab dem wilden Stiergefechte", "tokens": ["Man", "sieht", ",", "sie", "gab", "dem", "wil\u00b7den", "Stier\u00b7ge\u00b7fech\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Kolorit von Wohlanst\u00e4ndigkeit", "tokens": ["Ein", "Ko\u00b7lo\u00b7rit", "von", "Wohl\u00b7an\u00b7st\u00e4n\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "(nicht ohne Absicht zwar). \u2013 Wer war dabei so freudig", "tokens": ["(", "nicht", "oh\u00b7ne", "Ab\u00b7sicht", "zwar", ")", ".", "\u2013", "Wer", "war", "da\u00b7bei", "so", "freu\u00b7dig"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PTKNEG", "APPR", "NN", "ADV", "$(", "$.", "$(", "PWS", "VAFIN", "PAV", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Phanias! \u2013 Allein der stoische Kleanth", "tokens": ["Als", "Pha\u00b7ni\u00b7as", "!", "\u2013", "Al\u00b7lein", "der", "sto\u00b7i\u00b7sche", "Kle\u00b7an\u00b7th"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "$.", "$(", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "(zu hitzig oder ungeschmeidig", "tokens": ["(", "zu", "hit\u00b7zig", "o\u00b7der", "un\u00b7ge\u00b7schmei\u00b7dig"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "PTKA", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu f\u00fchlen, da\u00df es blo\u00df in seiner Willk\u00fcr stand", "tokens": ["Zu", "f\u00fch\u00b7len", ",", "da\u00df", "es", "blo\u00df", "in", "sei\u00b7ner", "Will\u00b7k\u00fcr", "stand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das Kompliment in vollem Ernst zu nehmen)", "tokens": ["Das", "Kom\u00b7pli\u00b7ment", "in", "vol\u00b7lem", "Ernst", "zu", "neh\u00b7men", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Zwang seinen Sch\u00fcler sich noch mehr f\u00fcr ihn zu sch\u00e4men.", "tokens": ["Zwang", "sei\u00b7nen", "Sch\u00fc\u00b7ler", "sich", "noch", "mehr", "f\u00fcr", "ihn", "zu", "sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PRF", "ADV", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Augenblick, worin Musarion", "tokens": ["Der", "Au\u00b7gen\u00b7blick", ",", "wo\u00b7rin", "Mu\u00b7sa\u00b7ri\u00b7on"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ihn \u00fcberfiel, ihr Blick, der schalkhaft sanfte Ton", "tokens": ["Ihn", "\u00fc\u00b7berf\u00b7iel", ",", "ihr", "Blick", ",", "der", "schalk\u00b7haft", "sanf\u00b7te", "Ton"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PRELS", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Ironie, und (was noch zehnmal schlimmer", "tokens": ["Der", "I\u00b7ro\u00b7nie", ",", "und", "(", "was", "noch", "zehn\u00b7mal", "schlim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "$(", "PWS", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Als alles andre war) ihr ungewohnter Schimmer,", "tokens": ["Als", "al\u00b7les", "and\u00b7re", "war", ")", "ihr", "un\u00b7ge\u00b7wohn\u00b7ter", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "VAFIN", "$(", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Majest\u00e4t der Liebesk\u00f6nigin,", "tokens": ["Die", "Ma\u00b7jes\u00b7t\u00e4t", "der", "Lie\u00b7bes\u00b7k\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Das Wollustatmende, das eine Atmosph\u00e4re", "tokens": ["Das", "Wol\u00b7lus\u00b7tat\u00b7men\u00b7de", ",", "das", "ei\u00b7ne", "At\u00b7mo\u00b7sph\u00e4\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Von Reiz und Lust um sie zu machen schien,", "tokens": ["Von", "Reiz", "und", "Lust", "um", "sie", "zu", "ma\u00b7chen", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Best\u00fcrmt auf einmal, f\u00fcr die Ehre", "tokens": ["Be\u00b7st\u00fcrmt", "auf", "ein\u00b7mal", ",", "f\u00fcr", "die", "Eh\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADV", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.18": {"text": "Er stottert ihr Entschuldigungen,", "tokens": ["Er", "stot\u00b7tert", "ihr", "Ent\u00b7schul\u00b7di\u00b7gun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Zupft sich am Bart, zieht stets den Mantel enger an,", "tokens": ["Zupft", "sich", "am", "Bart", ",", "zieht", "stets", "den", "Man\u00b7tel", "en\u00b7ger", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und unterdes entwischt dem weisen Mann", "tokens": ["Und", "un\u00b7ter\u00b7des", "ent\u00b7wischt", "dem", "wei\u00b7sen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Was niemand wissen will, \u2013 er hab im ", "tokens": ["Was", "nie\u00b7mand", "wis\u00b7sen", "will", ",", "\u2013", "er", "hab", "im"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PWS", "PIS", "VVINF", "VMFIN", "$,", "$(", "PPER", "VAFIN", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Der Streit, versichert er, ging eine Wahrheit an,", "tokens": ["Der", "Streit", ",", "ver\u00b7si\u00b7chert", "er", ",", "ging", "ei\u00b7ne", "Wahr\u00b7heit", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die er so sonnenklar, so scharf beweisen kann,", "tokens": ["Die", "er", "so", "son\u00b7nen\u00b7klar", ",", "so", "scharf", "be\u00b7wei\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Nur ein Arkadisch Tier, ein Strau\u00df, ein Auerhahn \u2013", "tokens": ["Nur", "ein", "Ar\u00b7ka\u00b7disch", "Tier", ",", "ein", "Strau\u00df", ",", "ein", "Au\u00b7er\u00b7hahn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$,", "ART", "NE", "$,", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Hier r\u00f6tet sich sein Kamm, es schwellen Brust und Lungen,", "tokens": ["Hier", "r\u00f6\u00b7tet", "sich", "sein", "Kamm", ",", "es", "schwel\u00b7len", "Brust", "und", "Lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$,", "PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Er schreit \u2013 Mich jammert nur der arme Phanias!", "tokens": ["Er", "schreit", "\u2013", "Mich", "jam\u00b7mert", "nur", "der", "ar\u00b7me", "Pha\u00b7ni\u00b7as", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Bald lauter Glut, bald leichenm\u00e4\u00dfig bla\u00df,", "tokens": ["Bald", "lau\u00b7ter", "Glut", ",", "bald", "lei\u00b7chen\u00b7m\u00e4\u00b7\u00dfig", "bla\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Steht er beiseits und w\u00fcnscht vom Boden sich verschlungen", "tokens": ["Steht", "er", "bei\u00b7seits", "und", "w\u00fcnscht", "vom", "Bo\u00b7den", "sich", "ver\u00b7schlun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "KON", "VVFIN", "APPRART", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Worauf er steht. \u2013 Die Sch\u00f6ne sieht's, und eilt", "tokens": ["Wo\u00b7rauf", "er", "steht", ".", "\u2013", "Die", "Sch\u00f6\u00b7ne", "sieht's", ",", "und", "eilt"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "PPER", "VVFIN", "$.", "$(", "ART", "NN", "NE", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Ihn von der Marter zu erretten.", "tokens": ["Ihn", "von", "der", "Mar\u00b7ter", "zu", "er\u00b7ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Mit einem Blick voll junger Amoretten", "tokens": ["Mit", "ei\u00b7nem", "Blick", "voll", "jun\u00b7ger", "A\u00b7mo\u00b7ret\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Und Grazien, der stracks an unsichtbare Ketten", "tokens": ["Und", "Gra\u00b7zi\u00b7en", ",", "der", "stracks", "an", "un\u00b7sicht\u00b7ba\u00b7re", "Ket\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "PRELS", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.33": {"text": "Kleanthens Tollheit legt, Theophrons Rippen heilt,", "tokens": ["Kle\u00b7an\u00b7thens", "Toll\u00b7heit", "legt", ",", "Theo\u00b7phrons", "Rip\u00b7pen", "heilt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.34": {"text": "Spricht sie: \u00bbWenn's euch beliebt, so machen wir die Fragen,", "tokens": ["Spricht", "sie", ":", "\u00bb", "Wenn's", "euch", "be\u00b7liebt", ",", "so", "ma\u00b7chen", "wir", "die", "Fra\u00b7gen", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "KOUS", "PPER", "ADJD", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Wovon die Rede war, zu unserm Tischkonfekt;", "tokens": ["Wo\u00b7von", "die", "Re\u00b7de", "war", ",", "zu", "un\u00b7serm", "Tischkon\u00b7fekt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Ich z\u00f6g ein solch Gespr\u00e4ch, sogar bei leerem Magen,", "tokens": ["Ich", "z\u00f6g", "ein", "solch", "Ge\u00b7spr\u00e4ch", ",", "so\u00b7gar", "bei", "lee\u00b7rem", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "PIAT", "NN", "$,", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Der Tafel vor, die Ganymedes deckt.", "tokens": ["Der", "Ta\u00b7fel", "vor", ",", "die", "Ga\u00b7ny\u00b7me\u00b7des", "deckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "Wie freu ich mich, da\u00df ich den Weg verloren,", "tokens": ["Wie", "freu", "ich", "mich", ",", "da\u00df", "ich", "den", "Weg", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PRF", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "Da mir das Gl\u00fcck so viel Vergn\u00fcgen zugedacht!", "tokens": ["Da", "mir", "das", "Gl\u00fcck", "so", "viel", "Ver\u00b7gn\u00fc\u00b7gen", "zu\u00b7ge\u00b7dacht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Gl\u00fcckselger Phanias, der Freunde sich erkoren,", "tokens": ["Gl\u00fcck\u00b7sel\u00b7ger", "Pha\u00b7ni\u00b7as", ",", "der", "Freun\u00b7de", "sich", "er\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.41": {"text": "Von denen schon der Anblick weiser macht!", "tokens": ["Von", "de\u00b7nen", "schon", "der", "An\u00b7blick", "wei\u00b7ser", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.42": {"text": "Jetzt wundert mich nicht mehr, wenn er zum Spott der Toren", "tokens": ["Jetzt", "wun\u00b7dert", "mich", "nicht", "mehr", ",", "wenn", "er", "zum", "Spott", "der", "To\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "$,", "KOUS", "PPER", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Mitleidig l\u00e4cheln kann, und, gl\u00fccklich, wie er ist,", "tokens": ["Mit\u00b7lei\u00b7dig", "l\u00e4\u00b7cheln", "kann", ",", "und", ",", "gl\u00fcck\u00b7lich", ",", "wie", "er", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "VMFIN", "$,", "KON", "$,", "ADJD", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Athen und uns und alle Welt vergi\u00dft! \u00ab", "tokens": ["A\u00b7then", "und", "uns", "und", "al\u00b7le", "Welt", "ver\u00b7gi\u00dft", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "KON", "PPER", "KON", "PIAT", "NN", "VVFIN", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.4": {"line.1": {"text": "So sprach sie; und mit Ohren und mit Augen", "tokens": ["So", "sprach", "sie", ";", "und", "mit", "Oh\u00b7ren", "und", "mit", "Au\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "KON", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verschlingt das weise Paar was diese Muse spricht:", "tokens": ["Ver\u00b7schlingt", "das", "wei\u00b7se", "Paar", "was", "die\u00b7se", "Mu\u00b7se", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PWS", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Begierger kann die welke Rose nicht", "tokens": ["Be\u00b7gier\u00b7ger", "kann", "die", "wel\u00b7ke", "Ro\u00b7se", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "ART", "ADJA", "NN", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den Abendtau aus Zephyrs Lippen saugen.", "tokens": ["Den", "A\u00b7bend\u00b7tau", "aus", "Ze\u00b7phyrs", "Lip\u00b7pen", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zusehends schwellen sie von selbst-bewu\u00dftem Wert:", "tokens": ["Zu\u00b7se\u00b7hends", "schwel\u00b7len", "sie", "von", "selbst\u00b7be\u00b7wu\u00df\u00b7tem", "Wert", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Nicht, da\u00df ein fremdes Lob sie dessen erst belehrt;", "tokens": ["Nicht", ",", "da\u00df", "ein", "frem\u00b7des", "Lob", "sie", "des\u00b7sen", "erst", "be\u00b7lehrt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "KOUS", "ART", "ADJA", "NN", "PPER", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nur h\u00f6rt man stets mit Wohlgefallen", "tokens": ["Nur", "h\u00f6rt", "man", "stets", "mit", "Wohl\u00b7ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Aus andrer Mund das Urteil widerhallen,", "tokens": ["Aus", "an\u00b7drer", "Mund", "das", "Ur\u00b7teil", "wi\u00b7der\u00b7hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Womit uns innerlich die Eitelkeit beehrt.", "tokens": ["Wo\u00b7mit", "uns", "in\u00b7ner\u00b7lich", "die", "Ei\u00b7tel\u00b7keit", "be\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein Philosoph bleibt doch uns andern allen", "tokens": ["Ein", "Phi\u00b7lo\u00b7soph", "bleibt", "doch", "uns", "an\u00b7dern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PPER", "PIS", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Im Grunde gleich; w\u00e4r er so stoisch als ein Stein,", "tokens": ["Im", "Grun\u00b7de", "gleich", ";", "w\u00e4r", "er", "so", "sto\u00b7isch", "als", "ein", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$.", "VAFIN", "PPER", "ADV", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und h\u00e4tte nichts die Ehr ihm zu gefallen,", "tokens": ["Und", "h\u00e4t\u00b7te", "nichts", "die", "Ehr", "ihm", "zu", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Er selbst gef\u00e4llt sich doch! Schmaucht ihn mit Weihrauch ein,", "tokens": ["Er", "selbst", "ge\u00b7f\u00e4llt", "sich", "doch", "!", "Schmaucht", "ihn", "mit", "Weih\u00b7rauch", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "ADV", "$.", "NN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Und seid gewi\u00df, er wird erkenntlich sein.", "tokens": ["Und", "seid", "ge\u00b7wi\u00df", ",", "er", "wird", "er\u00b7kennt\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "PPER", "VAFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Es stieg demnach von Grad zu Grade", "tokens": ["Es", "stieg", "dem\u00b7nach", "von", "Grad", "zu", "Gra\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Der Sch\u00f6nen Gunst bei unserm Weisenpaar;", "tokens": ["Der", "Sch\u00f6\u00b7nen", "Gunst", "bei", "un\u00b7serm", "Wei\u00b7sen\u00b7paar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Ihr lachend Auge fand selbst vor der Stoa Gnade,", "tokens": ["Ihr", "la\u00b7chend", "Au\u00b7ge", "fand", "selbst", "vor", "der", "Stoa", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Und man vergab es ihr, da\u00df sie so reizend war.", "tokens": ["Und", "man", "ver\u00b7gab", "es", "ihr", ",", "da\u00df", "sie", "so", "rei\u00b7zend", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "PPER", "$,", "KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ein kleiner Saal, der von des Hauswirts Sch\u00e4tzen", "tokens": ["Ein", "klei\u00b7ner", "Saal", ",", "der", "von", "des", "Haus\u00b7wirts", "Sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "NN"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Kein allzu g\u00fcnstig Zeugnis gab,", "tokens": ["Kein", "all\u00b7zu", "g\u00fcns\u00b7tig", "Zeug\u00b7nis", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PTKA", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nahm die Gesellschaft auf Ein ungek\u00e4mmter Knab", "tokens": ["Nahm", "die", "Ge\u00b7sell\u00b7schaft", "auf", "Ein", "un\u00b7ge\u00b7k\u00e4mm\u00b7ter", "Knab"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Erschien, die Tafel aufzusetzen,", "tokens": ["Er\u00b7schien", ",", "die", "Ta\u00b7fel", "auf\u00b7zu\u00b7set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Lief keuchend hin und her, und hatte viel zu tun", "tokens": ["Lief", "keu\u00b7chend", "hin", "und", "her", ",", "und", "hat\u00b7te", "viel", "zu", "tun"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKVZ", "KON", "PTKVZ", "$,", "KON", "VAFIN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bis er ein Mahl zu Stande brachte,", "tokens": ["Bis", "er", "ein", "Mahl", "zu", "Stan\u00b7de", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wovon ein wohlbetagtes Huhn", "tokens": ["Wo\u00b7von", "ein", "wohl\u00b7be\u00b7tag\u00b7tes", "Huhn"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "(doch nicht, der Regel nach, die Catius erdachte,", "tokens": ["(", "doch", "nicht", ",", "der", "Re\u00b7gel", "nach", ",", "die", "Ca\u00b7ti\u00b7us", "er\u00b7dach\u00b7te", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKNEG", "$,", "ART", "NN", "PTKVZ", "$,", "PRELS", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In Cypernwein erstickt) die beste Sch\u00fcssel machte.", "tokens": ["In", "Cy\u00b7pern\u00b7wein", "er\u00b7stickt", ")", "die", "bes\u00b7te", "Sch\u00fcs\u00b7sel", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$(", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ob die Philosophie des guten Phanias", "tokens": ["Ob", "die", "Phi\u00b7lo\u00b7so\u00b7phie", "des", "gu\u00b7ten", "Pha\u00b7ni\u00b7as"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der sch\u00f6nen Nymphe gegen \u00fcber", "tokens": ["Der", "sch\u00f6\u00b7nen", "Nym\u00b7phe", "ge\u00b7gen", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bei einem solchen Schmaus so gar gem\u00e4chlich sa\u00df,", "tokens": ["Bei", "ei\u00b7nem", "sol\u00b7chen", "Schmaus", "so", "gar", "ge\u00b7m\u00e4ch\u00b7lich", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "L\u00e4\u00dft man dem Leser selbst zu untersuchen \u00fcber.", "tokens": ["L\u00e4\u00dft", "man", "dem", "Le\u00b7ser", "selbst", "zu", "un\u00b7ter\u00b7su\u00b7chen", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ADV", "PTKZU", "VVINF", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein wenig falsche Scham, von der er noch nicht ganz", "tokens": ["Ein", "we\u00b7nig", "fal\u00b7sche", "Scham", ",", "von", "der", "er", "noch", "nicht", "ganz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "ADJA", "NN", "$,", "APPR", "PRELS", "PPER", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sich los gemacht, schien ihn vor einem Zeugen", "tokens": ["Sich", "los", "ge\u00b7macht", ",", "schien", "ihn", "vor", "ei\u00b7nem", "Zeu\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "VVPP", "$,", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Von seines vorgen Wohlstands Glanz", "tokens": ["Von", "sei\u00b7nes", "vor\u00b7gen", "Wohl\u00b7stands", "Glanz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein wenig mehr als n\u00f6tig war zu beugen.", "tokens": ["Ein", "we\u00b7nig", "mehr", "als", "n\u00f6\u00b7tig", "war", "zu", "beu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PIAT", "KOKOM", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Allein der Dame Witz, die freie Munterkeit,", "tokens": ["Al\u00b7lein", "der", "Da\u00b7me", "Witz", ",", "die", "frei\u00b7e", "Mun\u00b7ter\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die was sie spricht und tut mit Grazie bestreut,", "tokens": ["Die", "was", "sie", "spricht", "und", "tut", "mit", "Gra\u00b7zie", "be\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Und dann und wann ein Blick voll Z\u00e4rtlichkeit,", "tokens": ["Und", "dann", "und", "wann", "ein", "Blick", "voll", "Z\u00e4rt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "PWAV", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Den sie, als ob sie sich verg\u00e4\u00df, erst auf ihn heftet,", "tokens": ["Den", "sie", ",", "als", "ob", "sie", "sich", "ver\u00b7g\u00e4\u00df", ",", "erst", "auf", "ihn", "hef\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "KOKOM", "KOUS", "PPER", "PRF", "ADJD", "$,", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dann seitw\u00e4rts glitschen l\u00e4\u00dft, entkr\u00e4ftet", "tokens": ["Dann", "seit\u00b7w\u00e4rts", "glit\u00b7schen", "l\u00e4\u00dft", ",", "ent\u00b7kr\u00e4f\u00b7tet"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "VVINF", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Den Unmut bald, der seine Stirne kr\u00e4ust;", "tokens": ["Den", "Un\u00b7mut", "bald", ",", "der", "sei\u00b7ne", "Stir\u00b7ne", "kr\u00e4ust", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Stets schw\u00e4cher widersteht sein Herz dem s\u00fc\u00dfen Triebe,", "tokens": ["Stets", "schw\u00e4\u00b7cher", "wi\u00b7der\u00b7steht", "sein", "Herz", "dem", "s\u00fc\u00b7\u00dfen", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und, eh er sich's versieht, beweist", "tokens": ["Und", ",", "eh", "er", "sich's", "ver\u00b7sieht", ",", "be\u00b7weist"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Sein ganzes Wesen schon den stillen Sieg der Liebe.", "tokens": ["Sein", "gan\u00b7zes", "We\u00b7sen", "schon", "den", "stil\u00b7len", "Sieg", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Indessen wird, so sichtbar als es war,", "tokens": ["In\u00b7des\u00b7sen", "wird", ",", "so", "sicht\u00b7bar", "als", "es", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den beiden Weisen doch davon nichts offenbar,", "tokens": ["Den", "bei\u00b7den", "Wei\u00b7sen", "doch", "da\u00b7von", "nichts", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "PAV", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob sie die Sch\u00f6ne gleich mit gro\u00dfen Augen messen.", "tokens": ["Ob", "sie", "die", "Sch\u00f6\u00b7ne", "gleich", "mit", "gro\u00b7\u00dfen", "Au\u00b7gen", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Herren dieser Art blendt oft zu vieles Licht;", "tokens": ["Die", "Her\u00b7ren", "die\u00b7ser", "Art", "blendt", "oft", "zu", "vie\u00b7les", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "VVFIN", "ADV", "PTKA", "PIS", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie sehn den Wald vor lauter B\u00e4umen nicht.", "tokens": ["Sie", "sehn", "den", "Wald", "vor", "lau\u00b7ter", "B\u00e4u\u00b7men", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Doch sind die unsrigen entschuldigt; denn indessen", "tokens": ["Doch", "sind", "die", "uns\u00b7ri\u00b7gen", "ent\u00b7schul\u00b7digt", ";", "denn", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "VVPP", "$.", "KON", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df Phanias ein liebliches Vergessen", "tokens": ["Da\u00df", "Pha\u00b7ni\u00b7as", "ein", "lieb\u00b7li\u00b7ches", "Ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Von allem, was sein steifer P\u00e4dagog", "tokens": ["Von", "al\u00b7lem", ",", "was", "sein", "stei\u00b7fer", "P\u00e4d\u00b7a\u00b7gog"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ihm jemals vorgeprahlt, aus sch\u00f6nen Augen sog,", "tokens": ["Ihm", "je\u00b7mals", "vor\u00b7ge\u00b7prahlt", ",", "aus", "sch\u00f6\u00b7nen", "Au\u00b7gen", "sog", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "War auf Musarions Verlangen", "tokens": ["War", "auf", "Mu\u00b7sa\u00b7ri\u00b7ons", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Das akademische Gefecht schon angegangen,", "tokens": ["Das", "a\u00b7kad\u00b7e\u00b7mi\u00b7sche", "Ge\u00b7fecht", "schon", "an\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Womit sie etwas sich zu gut zu tun beschlo\u00df.", "tokens": ["Wo\u00b7mit", "sie", "et\u00b7was", "sich", "zu", "gut", "zu", "tun", "be\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIS", "PRF", "PTKA", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Kleanth bewies bereits: \u00bbDer Weise nur sei gro\u00df", "tokens": ["Kle\u00b7an\u00b7th", "be\u00b7wies", "be\u00b7reits", ":", "\u00bb", "Der", "Wei\u00b7se", "nur", "sei", "gro\u00df"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "$.", "$(", "ART", "NN", "ADV", "VAFIN", "ADJD"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.14": {"text": "Und frei, geringer kaum ein wenig", "tokens": ["Und", "frei", ",", "ge\u00b7rin\u00b7ger", "kaum", "ein", "we\u00b7nig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "ADJD", "ADV", "ART", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Als Jupiter, ein Kr\u00f6sus, ein Adon,", "tokens": ["Als", "Ju\u00b7pi\u00b7ter", ",", "ein", "Kr\u00f6\u00b7sus", ",", "ein", "A\u00b7don", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ART", "NN", "$,", "ART", "NE", "$,"], "meter": "-+-+-+-+++", "measure": "zehnsilber"}, "line.16": {"text": "Ein Herkules, und zehnmal mehr ein K\u00f6nig", "tokens": ["Ein", "Her\u00b7ku\u00b7les", ",", "und", "zehn\u00b7mal", "mehr", "ein", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "ADV", "ADV", "ART", "NN"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Auf m\u00fcrbem Stroh als Xerxes auf dem Thron,", "tokens": ["Auf", "m\u00fcr\u00b7bem", "Stroh", "als", "Xe\u00b7rxes", "auf", "dem", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Des Weisen Eigentum, die Tugend, ganz alleine", "tokens": ["Des", "Wei\u00b7sen", "Ei\u00b7gen\u00b7tum", ",", "die", "Tu\u00b7gend", ",", "ganz", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sei wahres Gut, und nichts von allem dem", "tokens": ["Sei", "wah\u00b7res", "Gut", ",", "und", "nichts", "von", "al\u00b7lem", "dem"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJA", "NN", "$,", "KON", "PIS", "APPR", "PIS", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Was unsern Sinnen reizend scheine", "tokens": ["Was", "un\u00b7sern", "Sin\u00b7nen", "rei\u00b7zend", "schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Sei w\u00fcnschensw\u00fcrdig\u00ab \u2013 Kurz, die Wut f\u00fcr sein System", "tokens": ["Sei", "w\u00fcn\u00b7schens\u00b7w\u00fcr\u00b7dig", "\u00ab", "\u2013", "Kurz", ",", "die", "Wut", "f\u00fcr", "sein", "Sys\u00b7tem"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "$(", "$(", "ADJD", "$,", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Ging weit genug, ganz trotzig, ohne R\u00f6te,", "tokens": ["Ging", "weit", "ge\u00b7nug", ",", "ganz", "trot\u00b7zig", ",", "oh\u00b7ne", "R\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "$,", "ADV", "ADJD", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Zu prahlen: \u00bbWenn in Cypriens Figur", "tokens": ["Zu", "prah\u00b7len", ":", "\u00bb", "Wenn", "in", "Cyp\u00b7riens", "Fi\u00b7gur"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$.", "$(", "KOUS", "APPR", "NE", "NN"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.24": {"text": "Die Wollust selbst leibhaftig vor ihn tr\u00e4te,", "tokens": ["Die", "Wol\u00b7lust", "selbst", "leib\u00b7haf\u00b7tig", "vor", "ihn", "tr\u00e4\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Sch\u00f6n, wie die G\u00f6ttin sich dem Sohn der Myrrha", "tokens": ["Sch\u00f6n", ",", "wie", "die", "G\u00f6t\u00b7tin", "sich", "dem", "Sohn", "der", "Myrr\u00b7ha"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ART", "NN", "PRF", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.26": {"text": "Bei Mondschein sehen lie\u00df, \u2013 und diese Venus b\u00f6te", "tokens": ["Bei", "Mond\u00b7schein", "se\u00b7hen", "lie\u00df", ",", "\u2013", "und", "die\u00b7se", "Ve\u00b7nus", "b\u00f6\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVINF", "VVFIN", "$,", "$(", "KON", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Auf seinem Stroh ihm ihre sch\u00f6ne Brust", "tokens": ["Auf", "sei\u00b7nem", "Stroh", "ihm", "ih\u00b7re", "sch\u00f6\u00b7ne", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Zum Polster an \u2013 ein Mann wie Er verschm\u00e4hte", "tokens": ["Zum", "Pols\u00b7ter", "an", "\u2013", "ein", "Mann", "wie", "Er", "ver\u00b7schm\u00e4h\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "$(", "ART", "NN", "KOKOM", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Den s\u00fc\u00dfen Tausch.\u00ab \u2013", "tokens": ["Den", "s\u00fc\u00b7\u00dfen", "Tausch", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Hier war es, wo die Lust", "tokens": ["Hier", "war", "es", ",", "wo", "die", "Lust"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Des Widerspruchs Theophron sich nicht l\u00e4nger", "tokens": ["Des", "Wi\u00b7der\u00b7spruchs", "Theo\u00b7phron", "sich", "nicht", "l\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "PRF", "PTKNEG", "ADJD"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Versagen kann \u2013 ein Mann von krausem schwarzem Bart", "tokens": ["Ver\u00b7sa\u00b7gen", "kann", "\u2013", "ein", "Mann", "von", "krau\u00b7sem", "schwar\u00b7zem", "Bart"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "$(", "ART", "NN", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Augen voller Glut, kein \u00fcbler S\u00e4nger", "tokens": ["Und", "Au\u00b7gen", "vol\u00b7ler", "Glut", ",", "kein", "\u00fcb\u00b7ler", "S\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und Citharist, dabei ein Grillenf\u00e4nger", "tokens": ["Und", "Cit\u00b7ha\u00b7rist", ",", "da\u00b7bei", "ein", "Gril\u00b7len\u00b7f\u00e4n\u00b7ger"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$,", "PAV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So gut als jener, nur von einer andern Art.", "tokens": ["So", "gut", "als", "je\u00b7ner", ",", "nur", "von", "ei\u00b7ner", "an\u00b7dern", "Art", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PDS", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u00bbdas geht zu weit, (fiel er Kleanthen in die Rede)", "tokens": ["\u00bb", "das", "geht", "zu", "weit", ",", "(", "fiel", "er", "Kle\u00b7an\u00b7then", "in", "die", "Re\u00b7de", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PTKA", "ADJD", "$,", "$(", "VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zum mindsten f\u00fchret es gar leicht zu Mi\u00dfverstand.", "tokens": ["Zum", "minds\u00b7ten", "f\u00fch\u00b7ret", "es", "gar", "leicht", "zu", "Mi\u00df\u00b7ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nicht da\u00df ich hier das Wort der Wollust rede", "tokens": ["Nicht", "da\u00df", "ich", "hier", "das", "Wort", "der", "Wol\u00b7lust", "re\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Im gr\u00f6bern Sinn! Die ist unleugbar eitel Tand", "tokens": ["Im", "gr\u00f6\u00b7bern", "Sinn", "!", "Die", "ist", "un\u00b7leug\u00b7bar", "ei\u00b7tel", "Tand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$.", "PDS", "VAFIN", "ADJD", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und Schaum und Dunst, ein Kinderspiel f\u00fcr bl\u00f6de", "tokens": ["Und", "Schaum", "und", "Dunst", ",", "ein", "Kin\u00b7der\u00b7spiel", "f\u00fcr", "bl\u00f6\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "$,", "ART", "NN", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Unreife Seelen, die mit ihren Fl\u00fcgeln noch", "tokens": ["Un\u00b7rei\u00b7fe", "See\u00b7len", ",", "die", "mit", "ih\u00b7ren", "Fl\u00fc\u00b7geln", "noch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "ADV"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Im Schlamm des tr\u00fcben Stoffes stecken.", "tokens": ["Im", "Schlamm", "des", "tr\u00fc\u00b7ben", "Stof\u00b7fes", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch sollt uns nicht die Nektartraube schmecken,", "tokens": ["Doch", "sollt", "uns", "nicht", "die", "Nekt\u00b7ar\u00b7trau\u00b7be", "schme\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Weil ein Insekt auf ihrem Purpur kroch?", "tokens": ["Weil", "ein", "In\u00b7sekt", "auf", "ih\u00b7rem", "Pur\u00b7pur", "kroch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Der Mi\u00dfbrauch darf nicht unser Urteil leiten:", "tokens": ["Der", "Mi\u00df\u00b7brauch", "darf", "nicht", "un\u00b7ser", "Ur\u00b7teil", "lei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Alt ist der Spruch, zu selten sein Gebrauch!", "tokens": ["Alt", "ist", "der", "Spruch", ",", "zu", "sel\u00b7ten", "sein", "Ge\u00b7brauch", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,", "PTKA", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Saugt nicht auf gleichem Rosenstrauch", "tokens": ["Saugt", "nicht", "auf", "glei\u00b7chem", "Ro\u00b7sen\u00b7strauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Die Raupe Gift, die Biene S\u00fc\u00dfigkeiten?\u00ab", "tokens": ["Die", "Rau\u00b7pe", "Gift", ",", "die", "Bie\u00b7ne", "S\u00fc\u00b7\u00dfig\u00b7kei\u00b7ten", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Begeistert wie ein Korybant,", "tokens": ["Be\u00b7geis\u00b7tert", "wie", "ein", "Ko\u00b7ry\u00b7bant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und von Musarion die Augen unverwandt,", "tokens": ["Und", "von", "Mu\u00b7sa\u00b7ri\u00b7on", "die", "Au\u00b7gen", "un\u00b7ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fing jetzt Theophron an, in dichterischen T\u00f6nen,", "tokens": ["Fing", "jetzt", "Theo\u00b7phron", "an", ",", "in", "dich\u00b7te\u00b7ri\u00b7schen", "T\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NE", "PTKVZ", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Vom Ersten Wesentlichen Sch\u00f6nen", "tokens": ["Vom", "Ers\u00b7ten", "We\u00b7sent\u00b7li\u00b7chen", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Zu schw\u00e4rmen: \u00bbWie das alles, was wir sehn", "tokens": ["Zu", "schw\u00e4r\u00b7men", ":", "\u00bb", "Wie", "das", "al\u00b7les", ",", "was", "wir", "sehn"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$.", "$(", "PWAV", "PDS", "PIS", "$,", "PRELS", "PPER", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und durch der Sinne Dienst mit unsrer Seele gatten,", "tokens": ["Und", "durch", "der", "Sin\u00b7ne", "Dienst", "mit", "uns\u00b7rer", "See\u00b7le", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Von dem, was \u00fcbersinnlich sch\u00f6n", "tokens": ["Von", "dem", ",", "was", "\u00fc\u00b7ber\u00b7sinn\u00b7lich", "sch\u00f6n"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "$,", "PRELS", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und g\u00f6ttlich ist, nur wesenlose Schatten,", "tokens": ["Und", "g\u00f6tt\u00b7lich", "ist", ",", "nur", "we\u00b7sen\u00b7lo\u00b7se", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nur Bilder sind, wie wenn in stiller Flut,", "tokens": ["Nur", "Bil\u00b7der", "sind", ",", "wie", "wenn", "in", "stil\u00b7ler", "Flut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "$,", "KOKOM", "KOUS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Von B\u00fcschen eingefa\u00dft, sich Sommerwolken malen.\u00ab", "tokens": ["Von", "B\u00fc\u00b7schen", "ein\u00b7ge\u00b7fa\u00dft", ",", "sich", "Som\u00b7mer\u00b7wol\u00b7ken", "ma\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "PRF", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Von da erhob er sich, bei immer w\u00e4rmerm Blut,", "tokens": ["Von", "da", "er\u00b7hob", "er", "sich", ",", "bei", "im\u00b7mer", "w\u00e4r\u00b7merm", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PRF", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zu den geheimnisvollen Zahlen,", "tokens": ["Zu", "den", "ge\u00b7heim\u00b7nis\u00b7vol\u00b7len", "Zah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Zur sph\u00e4rischen Musik, zum unsichtbaren Licht,", "tokens": ["Zur", "sph\u00e4\u00b7ri\u00b7schen", "Mu\u00b7sik", ",", "zum", "un\u00b7sicht\u00b7ba\u00b7ren", "Licht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zuletzt zum Quell des Lichts. \u2013 Ekstatischer hat nicht,", "tokens": ["Zu\u00b7letzt", "zum", "Quell", "des", "Lichts", ".", "\u2013", "Eks\u00b7ta\u00b7ti\u00b7scher", "hat", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$.", "$(", "NN", "VAFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie aus der alten Nacht die sch\u00f6ne Welt entsprungen,", "tokens": ["Wie", "aus", "der", "al\u00b7ten", "Nacht", "die", "sch\u00f6\u00b7ne", "Welt", "ent\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und von Deukalion, und von der goldnen Zeit,", "tokens": ["Und", "von", "Deu\u00b7ka\u00b7li\u00b7on", ",", "und", "von", "der", "gold\u00b7nen", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "$,", "KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Virgils Silen den Knaben vorgesungen", "tokens": ["Vir\u00b7gils", "Si\u00b7len", "den", "Kna\u00b7ben", "vor\u00b7ge\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "ART", "NN", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Die ihn im Schlaf erhascht und zum Gesang gezwungen.", "tokens": ["Die", "ihn", "im", "Schlaf", "er\u00b7hascht", "und", "zum", "Ge\u00b7sang", "ge\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "KON", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Dann fuhr er fort, und sprach vom Tod der Sinnlichkeit,", "tokens": ["Dann", "fuhr", "er", "fort", ",", "und", "sprach", "vom", "Tod", "der", "Sinn\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wie durch magische geheime Reinigungen", "tokens": ["Und", "wie", "durch", "ma\u00b7gi\u00b7sche", "ge\u00b7hei\u00b7me", "Rei\u00b7ni\u00b7gun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die See und nach und nach vom Stoffe sich befreit,", "tokens": ["Die", "See", "und", "nach", "und", "nach", "vom", "Stof\u00b7fe", "sich", "be\u00b7freit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "APPR", "KON", "APPR", "APPRART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie sie, durch Enthaltsamkeit", "tokens": ["Und", "wie", "sie", ",", "durch", "Ent\u00b7halt\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "PPER", "$,", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Erdet\u00f6chtern und \u2013 von Bohnen,", "tokens": ["Von", "Er\u00b7de\u00b7t\u00f6ch\u00b7tern", "und", "\u2013", "von", "Boh\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "$(", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zum Umgang t\u00fcchtig wird mit G\u00f6ttern und D\u00e4monen.", "tokens": ["Zum", "Um\u00b7gang", "t\u00fcch\u00b7tig", "wird", "mit", "G\u00f6t\u00b7tern", "und", "D\u00e4\u00b7mo\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VAFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bis sie (dem Wurme gleich, der in die Sommerluft", "tokens": ["Bis", "sie", "(", "dem", "Wur\u00b7me", "gleich", ",", "der", "in", "die", "Som\u00b7mer\u00b7luft"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$(", "ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf neuen Fl\u00fcgeln sich erhebet)", "tokens": ["Auf", "neu\u00b7en", "Fl\u00fc\u00b7geln", "sich", "er\u00b7he\u00b7bet", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Dem Stoff sich ganz entrei\u00dft und ihres K\u00f6rpers Gruft,", "tokens": ["Dem", "Stoff", "sich", "ganz", "ent\u00b7rei\u00dft", "und", "ih\u00b7res", "K\u00f6r\u00b7pers", "Gruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "VVFIN", "KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zur G\u00f6ttin wird und unter G\u00f6ttern lebet.", "tokens": ["Zur", "G\u00f6t\u00b7tin", "wird", "und", "un\u00b7ter", "G\u00f6t\u00b7tern", "le\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Belustigt an dem hohen Schwung,", "tokens": ["Be\u00b7lus\u00b7tigt", "an", "dem", "ho\u00b7hen", "Schwung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den unser Doktor nahm, stellt sich die schlaue Sch\u00f6ne,", "tokens": ["Den", "un\u00b7ser", "Dok\u00b7tor", "nahm", ",", "stellt", "sich", "die", "schlau\u00b7e", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als ob vor H\u00f6renslust und vor Bewunderung", "tokens": ["Als", "ob", "vor", "H\u00f6\u00b7rens\u00b7lust", "und", "vor", "Be\u00b7wun\u00b7de\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr Busen sich in seinen Fesseln dehne.", "tokens": ["Ihr", "Bu\u00b7sen", "sich", "in", "sei\u00b7nen", "Fes\u00b7seln", "deh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zum Ungl\u00fcck f\u00fcr den Mann, der lauter Wunder spricht,", "tokens": ["Zum", "Un\u00b7gl\u00fcck", "f\u00fcr", "den", "Mann", ",", "der", "lau\u00b7ter", "Wun\u00b7der", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Entsteht dadurch (und sie bemerkt es nicht)", "tokens": ["Ent\u00b7steht", "da\u00b7durch", "(", "und", "sie", "be\u00b7merkt", "es", "nicht", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "$(", "KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich wei\u00df nicht welche kleine L\u00fccke,", "tokens": ["Ich", "wei\u00df", "nicht", "wel\u00b7che", "klei\u00b7ne", "L\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die seinen Flug auf einmal unterbricht;", "tokens": ["Die", "sei\u00b7nen", "Flug", "auf", "ein\u00b7mal", "un\u00b7ter\u00b7bricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und wie zuletzt die Richtung seiner Blicke", "tokens": ["Und", "wie", "zu\u00b7letzt", "die", "Rich\u00b7tung", "sei\u00b7ner", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ihr sichtbar macht was ihn zerstreut,", "tokens": ["Ihr", "sicht\u00b7bar", "macht", "was", "ihn", "zer\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und sie besch\u00e4ftigt scheint den Zufall zu verbessern,", "tokens": ["Und", "sie", "be\u00b7sch\u00e4f\u00b7tigt", "scheint", "den", "Zu\u00b7fall", "zu", "ver\u00b7bes\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hat sie die Ungeschicklichkeit,", "tokens": ["Hat", "sie", "die", "Un\u00b7ge\u00b7schick\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "(wofern's nicht Bosheit war) das \u00dcbel zu vergr\u00f6\u00dfern.", "tokens": ["(", "wo\u00b7fern's", "nicht", "Bos\u00b7heit", "war", ")", "das", "\u00dc\u00b7bel", "zu", "ver\u00b7gr\u00f6\u00b7\u00dfern", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PTKNEG", "NN", "VAFIN", "$(", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Der Umstand ist an sich nur eine Kleinigkeit;", "tokens": ["Der", "Um\u00b7stand", "ist", "an", "sich", "nur", "ei\u00b7ne", "Klei\u00b7nig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch wird vielleicht die Folge zeigen", "tokens": ["Doch", "wird", "viel\u00b7leicht", "die", "Fol\u00b7ge", "zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er entscheidend war. Es folgt ein tiefes Schweigen,", "tokens": ["Da\u00df", "er", "ent\u00b7schei\u00b7dend", "war", ".", "Es", "folgt", "ein", "tie\u00b7fes", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wobei Kleanth sogar das volle Glas,", "tokens": ["Wo\u00b7bei", "Kle\u00b7an\u00b7th", "so\u00b7gar", "das", "vol\u00b7le", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Und, was kaum glaublich ist, die Lust zum Zank verga\u00df;", "tokens": ["Und", ",", "was", "kaum", "glaub\u00b7lich", "ist", ",", "die", "Lust", "zum", "Zank", "ver\u00b7ga\u00df", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Indes, vertieft in ", "tokens": ["In\u00b7des", ",", "ver\u00b7tieft", "in"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "VVFIN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Der J\u00fcnger des Pythagoras", "tokens": ["Der", "J\u00fcn\u00b7ger", "des", "Py\u00b7tha\u00b7go\u00b7ras"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NE"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Den wallenden Kontur", "tokens": ["Den", "wal\u00b7len\u00b7den", "Kon\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Woran die Lambert selbst sich \u00fcbermessen k\u00f6nnten;", "tokens": ["Wo\u00b7ran", "die", "Lam\u00b7bert", "selbst", "sich", "\u00fc\u00b7ber\u00b7mes\u00b7sen", "k\u00f6nn\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Vor Amorn unbesorgt, der hier zu lauern pflegt,", "tokens": ["Vor", "A\u00b7morn", "un\u00b7be\u00b7sorgt", ",", "der", "hier", "zu", "lau\u00b7ern", "pflegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und schon den sch\u00e4rfsten Pfeil aus seinen Bogen legt.", "tokens": ["Und", "schon", "den", "sch\u00e4rfs\u00b7ten", "Pfeil", "aus", "sei\u00b7nen", "Bo\u00b7gen", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Mit l\u00e4chelnder Verachtung sieht die Dame", "tokens": ["Mit", "l\u00e4\u00b7cheln\u00b7der", "Ver\u00b7ach\u00b7tung", "sieht", "die", "Da\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das weise Paar, mit seinem Flitterkrame", "tokens": ["Das", "wei\u00b7se", "Paar", ",", "mit", "sei\u00b7nem", "Flit\u00b7ter\u00b7kra\u00b7me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Von falschen Tugenden und gro\u00dfen W\u00f6rtern, an;", "tokens": ["Von", "fal\u00b7schen", "Tu\u00b7gen\u00b7den", "und", "gro\u00b7\u00dfen", "W\u00f6r\u00b7tern", ",", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und eh die Herren sich's versahn,", "tokens": ["Und", "eh", "die", "Her\u00b7ren", "sich's", "ver\u00b7sahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wei\u00df sie mit guter Art den unbescheidnen Blicken,", "tokens": ["Wei\u00df", "sie", "mit", "gu\u00b7ter", "Art", "den", "un\u00b7be\u00b7scheid\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was ihres gleichen zu entz\u00fccken", "tokens": ["Was", "ih\u00b7res", "glei\u00b7chen", "zu", "ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "ADJA", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Chartinnen nicht mit eigner Hand", "tokens": ["Die", "Char\u00b7tin\u00b7nen", "nicht", "mit", "eig\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "So sch\u00f6n gedreht, auf einmal zu entr\u00fccken;", "tokens": ["So", "sch\u00f6n", "ge\u00b7dreht", ",", "auf", "ein\u00b7mal", "zu", "ent\u00b7r\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "APPR", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und alles sinkt sogleich in seinen alten Stand.", "tokens": ["Und", "al\u00b7les", "sinkt", "sog\u00b7leich", "in", "sei\u00b7nen", "al\u00b7ten", "Stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Drauf sprach sie: \u00bbIn der Tat, man kann nichts sch\u00f6ners h\u00f6ren,", "tokens": ["Drauf", "sprach", "sie", ":", "\u00bb", "In", "der", "Tat", ",", "man", "kann", "nichts", "sch\u00f6\u00b7ners", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$.", "$(", "APPR", "ART", "NN", "$,", "PIS", "VMFIN", "PIS", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als was Theophron uns von unsichtbarem Licht,", "tokens": ["Als", "was", "Theo\u00b7phron", "uns", "von", "un\u00b7sicht\u00b7ba\u00b7rem", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Von Eins und Zwei, von musikalschen Sph\u00e4ren,", "tokens": ["Von", "Eins", "und", "Zwei", ",", "von", "mu\u00b7si\u00b7kal\u00b7schen", "Sph\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "CARD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vom Tod der Sinnlichkeit und von Verg\u00f6ttrung spricht.", "tokens": ["Vom", "Tod", "der", "Sinn\u00b7lich\u00b7keit", "und", "von", "Ver\u00b7g\u00f6t\u00b7trung", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie schade, w\u00e4r es nur ein sch\u00f6nes Luftgesicht", "tokens": ["Wie", "scha\u00b7de", ",", "w\u00e4r", "es", "nur", "ein", "sch\u00f6\u00b7nes", "Luft\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wornach er uns die Lippen w\u00e4ssern machte!", "tokens": ["Wor\u00b7nach", "er", "uns", "die", "Lip\u00b7pen", "w\u00e4s\u00b7sern", "mach\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und doch, der Weg zu diesem stolzen Gl\u00fcck", "tokens": ["Und", "doch", ",", "der", "Weg", "zu", "die\u00b7sem", "stol\u00b7zen", "Gl\u00fcck"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "ART", "NN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ist, deucht mir, das, woran er nicht gedachte?\u00ab", "tokens": ["Ist", ",", "deucht", "mir", ",", "das", ",", "wo\u00b7ran", "er", "nicht", "ge\u00b7dach\u00b7te", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "$,", "PDS", "$,", "PWAV", "PPER", "PTKNEG", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Theophron, noch ganz warm von dem was seinem Blick", "tokens": ["Theo\u00b7phron", ",", "noch", "ganz", "warm", "von", "dem", "was", "sei\u00b7nem", "Blick"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "ADV", "ADJD", "APPR", "ART", "PRELS", "PPOSAT", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Entzogen war, und voll von wollustreichen Bildern,", "tokens": ["Ent\u00b7zo\u00b7gen", "war", ",", "und", "voll", "von", "wol\u00b7lust\u00b7rei\u00b7chen", "Bil\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Beginnt den Weg, den Prodikus so schmal", "tokens": ["Be\u00b7ginnt", "den", "Weg", ",", "den", "Pro\u00b7di\u00b7kus", "so", "schmal"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und rauh und dornig malt,", "tokens": ["Und", "rauh", "und", "dor\u00b7nig", "malt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So lachend wie ein Rosental", "tokens": ["So", "la\u00b7chend", "wie", "ein", "Ro\u00b7sen\u00b7tal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu Amathunt, dem Aufenthalt der Freuden.", "tokens": ["Zu", "A\u00b7mat\u00b7hunt", ",", "dem", "Auf\u00b7ent\u00b7halt", "der", "Freu\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein Sybarit, der einen Weg aus beiden", "tokens": ["Ein", "Sy\u00b7ba\u00b7rit", ",", "der", "ei\u00b7nen", "Weg", "aus", "bei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "APPR", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Zu w\u00e4hlen h\u00e4tt, erw\u00e4hlte sonder M\u00fch", "tokens": ["Zu", "w\u00e4h\u00b7len", "h\u00e4tt", ",", "er\u00b7w\u00e4hl\u00b7te", "son\u00b7der", "M\u00fch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VAFIN", "$,", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Den blumigen, den die Philosophie", "tokens": ["Den", "blu\u00b7mi\u00b7gen", ",", "den", "die", "Phi\u00b7lo\u00b7so\u00b7phie"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Theophrons ging, \u2013 durch zauberische Schatten,", "tokens": ["Theo\u00b7phrons", "ging", ",", "\u2013", "durch", "zau\u00b7be\u00b7ri\u00b7sche", "Schat\u00b7ten", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "$(", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Wo Geist und K\u00f6rper sich, bei ungewissem Licht,", "tokens": ["Wo", "Geist", "und", "K\u00f6r\u00b7per", "sich", ",", "bei", "un\u00b7ge\u00b7wis\u00b7sem", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "PRF", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "In sch\u00f6ne Ungeheuer gatten,", "tokens": ["In", "sch\u00f6\u00b7ne", "Un\u00b7ge\u00b7heu\u00b7er", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und Amor, nicht der kleine B\u00f6sewicht", "tokens": ["Und", "A\u00b7mor", ",", "nicht", "der", "klei\u00b7ne", "B\u00f6\u00b7se\u00b7wicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "$,", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Den Coypel malt, ein andrer von Ideen,", "tokens": ["Den", "Coy\u00b7pel", "malt", ",", "ein", "an\u00b7drer", "von", "I\u00b7deen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "ADJA", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Wie der zu Gnid von Grazien, umschwebt,", "tokens": ["Wie", "der", "zu", "Gnid", "von", "Gra\u00b7zi\u00b7en", ",", "um\u00b7schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "NE", "APPR", "NE", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Ein Amor, der vom Haupt bis zu den Zehen", "tokens": ["Ein", "A\u00b7mor", ",", "der", "vom", "Haupt", "bis", "zu", "den", "Ze\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "$,", "PRELS", "APPRART", "NN", "APPR", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Voll Augen ist und nur vom Anschaun lebt,", "tokens": ["Voll", "Au\u00b7gen", "ist", "und", "nur", "vom", "An\u00b7schaun", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "KON", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Der Seele F\u00fchrer wird, sie in die Wolken hebt,", "tokens": ["Der", "See\u00b7le", "F\u00fch\u00b7rer", "wird", ",", "sie", "in", "die", "Wol\u00b7ken", "hebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und, wenn er sie zuvor \u2013 in einem kleinen Bade", "tokens": ["Und", ",", "wenn", "er", "sie", "zu\u00b7vor", "\u2013", "in", "ei\u00b7nem", "klei\u00b7nen", "Ba\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "ADV", "$(", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Von Flammen \u2013 wohl gereinigt und gefegt,", "tokens": ["Von", "Flam\u00b7men", "\u2013", "wohl", "ge\u00b7rei\u00b7nigt", "und", "ge\u00b7fegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Sie stufenweis durch die gestirnten Pfade", "tokens": ["Sie", "stu\u00b7fen\u00b7weis", "durch", "die", "ge\u00b7stirn\u00b7ten", "Pfa\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Bis in den Scho\u00df des h\u00f6chsten Sch\u00f6nen tr\u00e4gt.", "tokens": ["Bis", "in", "den", "Scho\u00df", "des", "h\u00f6chs\u00b7ten", "Sch\u00f6\u00b7nen", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Doch eh zu so erhabner Liebe", "tokens": ["Doch", "eh", "zu", "so", "er\u00b7hab\u00b7ner", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Seele leicht genug sich f\u00fchlt,", "tokens": ["Die", "See\u00b7le", "leicht", "ge\u00b7nug", "sich", "f\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Befreit Theophron sie vorher von jedem Triebe,", "tokens": ["Be\u00b7freit", "Theo\u00b7phron", "sie", "vor\u00b7her", "von", "je\u00b7dem", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der tierisch im Morast des groben Stoffes w\u00fchlt.", "tokens": ["Der", "tie\u00b7risch", "im", "Mo\u00b7rast", "des", "gro\u00b7ben", "Stof\u00b7fes", "w\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbund hier ist's,\u00ab f\u00e4hrt er fort, \u00bbwo unsre Afterweisen", "tokens": ["\u00bb", "und", "hier", "ist's", ",", "\u00ab", "f\u00e4hrt", "er", "fort", ",", "\u00bb", "wo", "uns\u00b7re", "Af\u00b7ter\u00b7wei\u00b7sen"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "KON", "ADV", "VAFIN", "$,", "$(", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "PWAV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein falsches Licht verf\u00fchrt. Die guten Leute preisen", "tokens": ["Ein", "fal\u00b7sches", "Licht", "ver\u00b7f\u00fchrt", ".", "Die", "gu\u00b7ten", "Leu\u00b7te", "prei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Uns ihre ", "tokens": ["Uns", "ih\u00b7re"], "token_info": ["word", "word"], "pos": ["PPER", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Das uns zu mehr als G\u00f6ttern machen kann.", "tokens": ["Das", "uns", "zu", "mehr", "als", "G\u00f6t\u00b7tern", "ma\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "PIAT", "KOKOM", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Nach ihnen soll der Weise alles meiden", "tokens": ["Nach", "ih\u00b7nen", "soll", "der", "Wei\u00b7se", "al\u00b7les", "mei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VMFIN", "ART", "NN", "PIS", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Was Aug und Ohr ergetzt; so kleine Kinderfreuden", "tokens": ["Was", "Aug", "und", "Ohr", "er\u00b7getzt", ";", "so", "klei\u00b7ne", "Kin\u00b7der\u00b7freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NN", "KON", "NN", "VVPP", "$.", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sind ihm zu t\u00e4ndelhaft; stets in sich selbst gekehrt", "tokens": ["Sind", "ihm", "zu", "t\u00e4n\u00b7del\u00b7haft", ";", "stets", "in", "sich", "selbst", "ge\u00b7kehrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKA", "ADJD", "$.", "ADV", "APPR", "PRF", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Beweist er sich ", "tokens": ["Be\u00b7weist", "er", "sich"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Die Gr\u00f6\u00dfe seines Gl\u00fccks, f\u00fchlt nichts, um nichts zu leiden,", "tokens": ["Die", "Gr\u00f6\u00b7\u00dfe", "sei\u00b7nes", "Gl\u00fccks", ",", "f\u00fchlt", "nichts", ",", "um", "nichts", "zu", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "VVFIN", "PIS", "$,", "KOUI", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und \u2013 irret sehr. Das ", "tokens": ["Und", "\u2013", "ir\u00b7ret", "sehr", ".", "Das"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "$(", "VVFIN", "ADV", "$.", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Der Gegenstand von unsrer Liebe sein;", "tokens": ["Der", "Ge\u00b7gen\u00b7stand", "von", "uns\u00b7rer", "Lie\u00b7be", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Die gro\u00dfe Kunst ist nur, vom ", "tokens": ["Die", "gro\u00b7\u00dfe", "Kunst", "ist", "nur", ",", "vom"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "$,", "APPRART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Der Weise ", "tokens": ["Der", "Wei\u00b7se"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.18": {"text": "Mit allen andern Erdens\u00f6hnen:", "tokens": ["Mit", "al\u00b7len", "an\u00b7dern", "Er\u00b7den\u00b7s\u00f6h\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Doch diese st\u00fcrzen sich, vom k\u00f6rperlichen Sch\u00f6nen", "tokens": ["Doch", "die\u00b7se", "st\u00fcr\u00b7zen", "sich", ",", "vom", "k\u00f6r\u00b7per\u00b7li\u00b7chen", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "PRF", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.20": {"text": "Geblendet, in den Schlamm der Sinnlichkeit hinein,", "tokens": ["Ge\u00b7blen\u00b7det", ",", "in", "den", "Schlamm", "der", "Sinn\u00b7lich\u00b7keit", "hin\u00b7ein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPR", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Indessen ", "tokens": ["In\u00b7des\u00b7sen"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.22": {"text": "Ins ", "tokens": ["Ins"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.23": {"text": "Dies ist's, was ein ", "tokens": ["Dies", "ist's", ",", "was", "ein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.24": {"text": "Was in der Sonn ihm strahlt und in der Rose bl\u00fcht.", "tokens": ["Was", "in", "der", "Sonn", "ihm", "strahlt", "und", "in", "der", "Ro\u00b7se", "bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PPER", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Der Sinnensklave klebt, wie V\u00f6gel an der Stange,", "tokens": ["Der", "Sin\u00b7nens\u00b7kla\u00b7ve", "klebt", ",", "wie", "V\u00f6\u00b7gel", "an", "der", "Stan\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "An einem Lilienhals, an einer Rosenwange;", "tokens": ["An", "ei\u00b7nem", "Li\u00b7li\u00b7en\u00b7hals", ",", "an", "ei\u00b7ner", "Ro\u00b7sen\u00b7wan\u00b7ge", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Der Weise sieht und liebt im Sch\u00f6nen der Natur", "tokens": ["Der", "Wei\u00b7se", "sieht", "und", "liebt", "im", "Sch\u00f6\u00b7nen", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Vom Unverg\u00e4nglichen die abgedr\u00fcckte Spur.", "tokens": ["Vom", "Un\u00b7ver\u00b7g\u00e4ng\u00b7li\u00b7chen", "die", "ab\u00b7ge\u00b7dr\u00fcck\u00b7te", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der Seele Fittich w\u00e4chst in diesen geistgen Strahlen,", "tokens": ["Der", "See\u00b7le", "Fit\u00b7tich", "w\u00e4chst", "in", "die\u00b7sen", "geist\u00b7gen", "Strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die, aus dem Ursprungsquell des Lichts", "tokens": ["Die", ",", "aus", "dem", "Ur\u00b7sprungs\u00b7quell", "des", "Lichts"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Ergossen, die Natur bis an den Rand des Nichts", "tokens": ["Er\u00b7gos\u00b7sen", ",", "die", "Na\u00b7tur", "bis", "an", "den", "Rand", "des", "Nichts"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "ART", "NN", "ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Mit fern nachahmenden nicht eignen Farben malen.", "tokens": ["Mit", "fern", "nac\u00b7hah\u00b7men\u00b7den", "nicht", "eig\u00b7nen", "Far\u00b7ben", "ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVIZU", "PTKNEG", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Sie w\u00e4chst, entfaltet sich, wagt immer h\u00f6hern Flug,", "tokens": ["Sie", "w\u00e4chst", ",", "ent\u00b7fal\u00b7tet", "sich", ",", "wagt", "im\u00b7mer", "h\u00f6\u00b7hern", "Flug", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PRF", "$,", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.34": {"text": "Und trinkt aus reinern Wollustb\u00e4chen;", "tokens": ["Und", "trinkt", "aus", "rei\u00b7nern", "Wol\u00b7lust\u00b7b\u00e4\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Ihr tut nichts Sterbliches genug,", "tokens": ["Ihr", "tut", "nichts", "Sterb\u00b7li\u00b7ches", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Ja, G\u00f6tterlust kann einen Durst nicht schw\u00e4chen", "tokens": ["Ja", ",", "G\u00f6t\u00b7ter\u00b7lust", "kann", "ei\u00b7nen", "Durst", "nicht", "schw\u00e4\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "VMFIN", "ART", "NN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Den nur die Quelle stillt. So, meine Freunde, wird,", "tokens": ["Den", "nur", "die", "Quel\u00b7le", "stillt", ".", "So", ",", "mei\u00b7ne", "Freun\u00b7de", ",", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$.", "ADV", "$,", "PPOSAT", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Was andre Sterbliche, aus Mangel", "tokens": ["Was", "and\u00b7re", "Sterb\u00b7li\u00b7che", ",", "aus", "Man\u00b7gel"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "ADJA", "NN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.40": {"text": "Zu s\u00fc\u00dfem Untergange kirrt,", "tokens": ["Zu", "s\u00fc\u00b7\u00dfem", "Un\u00b7ter\u00b7gan\u00b7ge", "kirrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "So wird es f\u00fcr den echten Weisen", "tokens": ["So", "wird", "es", "f\u00fcr", "den", "ech\u00b7ten", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Ein Fl\u00fcgelpferd zu \u00fcberirdschen Reisen.", "tokens": ["Ein", "Fl\u00fc\u00b7gel\u00b7pferd", "zu", "\u00fc\u00b7be\u00b7rird\u00b7schen", "Rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Auch die Musik, so roh und mangelhaft", "tokens": ["Auch", "die", "Mu\u00b7sik", ",", "so", "roh", "und", "man\u00b7gel\u00b7haft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "Sie unterm Monde bleibt \u2013 denn, ihrer Zauberkraft", "tokens": ["Sie", "un\u00b7term", "Mon\u00b7de", "bleibt", "\u2013", "denn", ",", "ih\u00b7rer", "Zau\u00b7ber\u00b7kraft"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "APPRART", "NE", "VVFIN", "$(", "KON", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Sich recht vollkommen zu belehren,", "tokens": ["Sich", "recht", "voll\u00b7kom\u00b7men", "zu", "be\u00b7leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Mu\u00df man, wie Scipio, die Sph\u00e4ren", "tokens": ["Mu\u00df", "man", ",", "wie", "Sci\u00b7pio", ",", "die", "Sph\u00e4\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "PIS", "$,", "PWAV", "NE", "$,", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.47": {"text": "(zum wenigsten im Traume) singen h\u00f6ren", "tokens": ["(", "zum", "we\u00b7nigs\u00b7ten", "im", "Trau\u00b7me", ")", "sin\u00b7gen", "h\u00f6\u00b7ren"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "APPRART", "PIS", "APPRART", "NN", "$(", "VVINF", "VVINF"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.48": {"text": "Auch die Musik bez\u00e4hmt die wilde Leidenschaft,", "tokens": ["Auch", "die", "Mu\u00b7sik", "be\u00b7z\u00e4hmt", "die", "wil\u00b7de", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Verfeinert das Gef\u00fchl, und schwellt die Seelenfl\u00fcgel;", "tokens": ["Ver\u00b7fei\u00b7nert", "das", "Ge\u00b7f\u00fchl", ",", "und", "schwellt", "die", "See\u00b7len\u00b7fl\u00fc\u00b7gel", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Sie stillt den Kummer, heilt die Milzsucht aus dem Grund,", "tokens": ["Sie", "stillt", "den", "Kum\u00b7mer", ",", "heilt", "die", "Milz\u00b7sucht", "aus", "dem", "Grund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Und wirkt (zumal aus einem sch\u00f6nen Mund)", "tokens": ["Und", "wirkt", "(", "zu\u00b7mal", "aus", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Mund", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.52": {"text": "Mehr Wunderding als Salomonis Siegel.\u00ab", "tokens": ["Mehr", "Wun\u00b7der\u00b7ding", "als", "Sa\u00b7lo\u00b7mo\u00b7nis", "Sie\u00b7gel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "KOKOM", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Hier kann Kleanth nicht l\u00e4nger ruhn,", "tokens": ["Hier", "kann", "Kle\u00b7an\u00b7th", "nicht", "l\u00e4n\u00b7ger", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er mu\u00df, vom Wahrheitsdrang gezwungen,", "tokens": ["Er", "mu\u00df", ",", "vom", "Wahr\u00b7heits\u00b7drang", "ge\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Schw\u00e4rmerei des Mannes Einhalt tun;", "tokens": ["Der", "Schw\u00e4r\u00b7me\u00b7rei", "des", "Man\u00b7nes", "Ein\u00b7halt", "tun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn alles was Theophron uns gesungen,", "tokens": ["Denn", "al\u00b7les", "was", "Theo\u00b7phron", "uns", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PWS", "NE", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "War, seinem Urteil nach, vollkommner Aberwitz.", "tokens": ["War", ",", "sei\u00b7nem", "Ur\u00b7teil", "nach", ",", "voll\u00b7komm\u00b7ner", "A\u00b7ber\u00b7witz", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PPOSAT", "NN", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Schon richtet er auf seinem Polstersitz,", "tokens": ["Schon", "rich\u00b7tet", "er", "auf", "sei\u00b7nem", "Pols\u00b7ter\u00b7sitz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Den rechten Arm entbl\u00f6\u00dft, die Stirn in stolzen Falten,", "tokens": ["Den", "rech\u00b7ten", "Arm", "ent\u00b7bl\u00f6\u00dft", ",", "die", "Stirn", "in", "stol\u00b7zen", "Fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sich drohend auf, und hat, noch eh er spricht,", "tokens": ["Sich", "dro\u00b7hend", "auf", ",", "und", "hat", ",", "noch", "eh", "er", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKVZ", "$,", "KON", "VAFIN", "$,", "ADV", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Den leichten Sieg bereits erhalten;", "tokens": ["Den", "leich\u00b7ten", "Sieg", "be\u00b7reits", "er\u00b7hal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Als ihn ein Auftritt unterbricht,", "tokens": ["Als", "ihn", "ein", "Auf\u00b7tritt", "un\u00b7ter\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Auf den das weise Paar sich nicht gefa\u00dft gehalten.", "tokens": ["Auf", "den", "das", "wei\u00b7se", "Paar", "sich", "nicht", "ge\u00b7fa\u00dft", "ge\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "PRF", "PTKNEG", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Der Saal er\u00f6ffnet sich, und eine Nymphe tritt", "tokens": ["Der", "Saal", "er\u00b7\u00f6ff\u00b7net", "sich", ",", "und", "ei\u00b7ne", "Nym\u00b7phe", "tritt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Herein, das Haupt mit einem Korb beladen,", "tokens": ["Her\u00b7ein", ",", "das", "Haupt", "mit", "ei\u00b7nem", "Korb", "be\u00b7la\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den Busen leicht verh\u00fcllt, und gleich den Oreaden", "tokens": ["Den", "Bu\u00b7sen", "leicht", "ver\u00b7h\u00fcllt", ",", "und", "gleich", "den", "O\u00b7rea\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVPP", "$,", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "So hoch gesch\u00fcrzt, da\u00df jeder schnelle Schritt", "tokens": ["So", "hoch", "ge\u00b7sch\u00fcrzt", ",", "da\u00df", "je\u00b7der", "schnel\u00b7le", "Schritt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "$,", "KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Den schlanken Fu\u00df bis an die feinsten Waden,", "tokens": ["Den", "schlan\u00b7ken", "Fu\u00df", "bis", "an", "die", "feins\u00b7ten", "Wa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und oft sogar ein Knie von Wachs entdeckt,", "tokens": ["Und", "oft", "so\u00b7gar", "ein", "Knie", "von", "Wachs", "ent\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Das eilend wieder sich im d\u00fcnnen Flor versteckt.", "tokens": ["Das", "ei\u00b7lend", "wie\u00b7der", "sich", "im", "d\u00fcn\u00b7nen", "Flor", "ver\u00b7steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADV", "PRF", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nicht sch\u00f6ner malt die Heben und Auroren", "tokens": ["Nicht", "sch\u00f6\u00b7ner", "malt", "die", "He\u00b7ben", "und", "Au\u00b7ro\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VVFIN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Alban, der wie ihr wi\u00dft, so gerne Nymphen malt.", "tokens": ["Al\u00b7ban", ",", "der", "wie", "ihr", "wi\u00dft", ",", "so", "ger\u00b7ne", "Nym\u00b7phen", "malt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "KOKOM", "PPER", "VVFIN", "$,", "ADV", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mit Einem Wort, sie war so auserkoren,", "tokens": ["Mit", "Ei\u00b7nem", "Wort", ",", "sie", "war", "so", "au\u00b7ser\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Da\u00df unser Theosoph (beim ersten Blick verloren", "tokens": ["Da\u00df", "un\u00b7ser", "The\u00b7o\u00b7soph", "(", "beim", "ers\u00b7ten", "Blick", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$(", "APPRART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Im ", "tokens": ["Im"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Die D\u00fcfte nicht empfindt, die aus dem Korbe steigen,", "tokens": ["Die", "D\u00fcf\u00b7te", "nicht", "emp\u00b7findt", ",", "die", "aus", "dem", "Kor\u00b7be", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$,", "PRELS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und die Kleanth mit Mund und Nase in sich schl\u00fcrft.", "tokens": ["Und", "die", "Kle\u00b7an\u00b7th", "mit", "Mund", "und", "Na\u00b7se", "in", "sich", "schl\u00fcrft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.15": {"text": "Musarion, die sich den Ausgang schon entwirft,", "tokens": ["Mu\u00b7sa\u00b7ri\u00b7on", ",", "die", "sich", "den", "Aus\u00b7gang", "schon", "ent\u00b7wirft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PRF", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.16": {"text": "Winkt ihrem Freund ein Pythagorsches Schweigen,", "tokens": ["Winkt", "ih\u00b7rem", "Freund", "ein", "Py\u00b7tha\u00b7gor\u00b7sches", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Indes den Korb die sch\u00f6ne Sklavin leert,", "tokens": ["In\u00b7des", "den", "Korb", "die", "sch\u00f6\u00b7ne", "Skla\u00b7vin", "leert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Und mit sechs gro\u00dfen Nektarkr\u00fcgen,", "tokens": ["Und", "mit", "sechs", "gro\u00b7\u00dfen", "Nek\u00b7tar\u00b7kr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "(genug von einem Faun den Weindurst zu besiegen)", "tokens": ["(", "ge\u00b7nug", "von", "ei\u00b7nem", "Faun", "den", "Wein\u00b7durst", "zu", "be\u00b7sie\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mit Fr\u00fcchten und Konfekt den runden Tisch beschwert.", "tokens": ["Mit", "Fr\u00fcch\u00b7ten", "und", "Kon\u00b7fekt", "den", "run\u00b7den", "Tisch", "be\u00b7schwert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "\u00bbdie Herren (spricht hierauf die Sch\u00f6ne) haben beide", "tokens": ["\u00bb", "die", "Her\u00b7ren", "(", "spricht", "hier\u00b7auf", "die", "Sch\u00f6\u00b7ne", ")", "ha\u00b7ben", "bei\u00b7de"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "ART", "NN", "$(", "VVFIN", "PAV", "ART", "NN", "$(", "VAFIN", "PIS"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mich wechselsweise, so wie jeder sprach, bekehrt:", "tokens": ["Mich", "wech\u00b7sels\u00b7wei\u00b7se", ",", "so", "wie", "je\u00b7der", "sprach", ",", "be\u00b7kehrt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "KOKOM", "PIS", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sehr ich auch das Gl\u00fcck der ", "tokens": ["Wie", "sehr", "ich", "auch", "das", "Gl\u00fcck", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPER", "ADV", "ART", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So deucht mich doch die geistge Augenweide,", "tokens": ["So", "deucht", "mich", "doch", "die", "geist\u00b7ge", "Au\u00b7gen\u00b7wei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die uns Theophron zeigt, nicht minder w\u00fcnschenswert.", "tokens": ["Die", "uns", "Theo\u00b7phron", "zeigt", ",", "nicht", "min\u00b7der", "w\u00fcn\u00b7schens\u00b7wert", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVFIN", "$,", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Erlaubet, da\u00df ich mich ein andermal entscheide.", "tokens": ["Er\u00b7lau\u00b7bet", ",", "da\u00df", "ich", "mich", "ein", "an\u00b7der\u00b7mal", "ent\u00b7schei\u00b7de", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PRF", "ART", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es sei der Rest der Nacht, die mich so viel gelehrt,", "tokens": ["Es", "sei", "der", "Rest", "der", "Nacht", ",", "die", "mich", "so", "viel", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Musen heilig und der Freude!", "tokens": ["Den", "Mu\u00b7sen", "hei\u00b7lig", "und", "der", "Freu\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Nimm, Phanias, die Schal, und gie\u00df sie aus", "tokens": ["Nimm", ",", "Pha\u00b7ni\u00b7as", ",", "die", "Schal", ",", "und", "gie\u00df", "sie", "aus"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Der himmlisch l\u00e4chelnden Cytheren;", "tokens": ["Der", "himm\u00b7lisch", "l\u00e4\u00b7cheln\u00b7den", "Cy\u00b7the\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und du, Theophron, gib uns einen Ohrenschmaus,", "tokens": ["Und", "du", ",", "Theo\u00b7phron", ",", "gib", "uns", "ei\u00b7nen", "Oh\u00b7ren\u00b7schmaus", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "NE", "$,", "VVIMP", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "Und la\u00df zum Saitenspiel uns deine Stimme h\u00f6ren.\u00ab", "tokens": ["Und", "la\u00df", "zum", "Sai\u00b7ten\u00b7spiel", "uns", "dei\u00b7ne", "Stim\u00b7me", "h\u00f6\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVIMP", "APPRART", "NN", "PPER", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Das leichte philosophsche Mahl", "tokens": ["Das", "leich\u00b7te", "phi\u00b7lo\u00b7soph\u00b7sche", "Mahl"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verwandelt nun (Dank sei der Oreade,", "tokens": ["Ver\u00b7wan\u00b7delt", "nun", "(", "Dank", "sei", "der", "O\u00b7rea\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Hebens Dienste tut) durch unbemerkte Grade", "tokens": ["Die", "He\u00b7bens", "Diens\u00b7te", "tut", ")", "durch", "un\u00b7be\u00b7merk\u00b7te", "Gra\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich in ein kleines Bacchanal.", "tokens": ["Sich", "in", "ein", "klei\u00b7nes", "Bac\u00b7cha\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zwar l\u00e4\u00dft zum Lob des unsichtbaren Sch\u00f6nen", "tokens": ["Zwar", "l\u00e4\u00dft", "zum", "Lob", "des", "un\u00b7sicht\u00b7ba\u00b7ren", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der b\u00e4rtige Apoll das ganze Haus ert\u00f6nen;", "tokens": ["Der", "b\u00e4r\u00b7ti\u00b7ge", "A\u00b7poll", "das", "gan\u00b7ze", "Haus", "er\u00b7t\u00f6\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Allein sein Blick, der nie von Chloens Busen weicht,", "tokens": ["Al\u00b7lein", "sein", "Blick", ",", "der", "nie", "von", "Chloens", "Bu\u00b7sen", "weicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "NE", "NE", "VVFIN", "$,"], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Beweist, wie wenig was er ", "tokens": ["Be\u00b7weist", ",", "wie", "we\u00b7nig", "was", "er"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PIS", "PWS", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Dem was er ", "tokens": ["Dem", "was", "er"], "token_info": ["word", "word", "word"], "pos": ["ART", "PWS", "PPER"], "meter": "++-", "measure": "unknown.measure.di"}, "line.10": {"text": "Die auch der k\u00fcnstlichste Kom\u00f6diant so leicht", "tokens": ["Die", "auch", "der", "k\u00fcnst\u00b7lichs\u00b7te", "Ko\u00b7m\u00f6\u00b7di\u00b7ant", "so", "leicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und ungezwungen nie, wie seine eigne, spielet.", "tokens": ["Und", "un\u00b7ge\u00b7zwun\u00b7gen", "nie", ",", "wie", "sei\u00b7ne", "eig\u00b7ne", ",", "spie\u00b7let", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "$,", "PWAV", "PPOSAT", "ADJA", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die lose Sklavin hilft des Weisen L\u00fcsternheit", "tokens": ["Die", "lo\u00b7se", "Skla\u00b7vin", "hilft", "des", "Wei\u00b7sen", "L\u00fcs\u00b7tern\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Durch listige Gesch\u00e4ftigkeit", "tokens": ["Durch", "lis\u00b7ti\u00b7ge", "Ge\u00b7sch\u00e4f\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Mit jedem Augenblick lebhafter anzufachen;", "tokens": ["Mit", "je\u00b7dem", "Au\u00b7gen\u00b7blick", "leb\u00b7haf\u00b7ter", "an\u00b7zu\u00b7fa\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Stets ist sie um ihn her, und macht sich tausend Sachen", "tokens": ["Stets", "ist", "sie", "um", "ihn", "her", ",", "und", "macht", "sich", "tau\u00b7send", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PRF", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mit ihm zu tun, in immer hellerm Glanz", "tokens": ["Mit", "ihm", "zu", "tun", ",", "in", "im\u00b7mer", "hel\u00b7lerm", "Glanz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "$,", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Die Reizungen ihm vorzuspiegeln,", "tokens": ["Die", "Rei\u00b7zun\u00b7gen", "ihm", "vor\u00b7zu\u00b7spie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$,"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Die nur zu sehr die Seel in ihm befl\u00fcgeln", "tokens": ["Die", "nur", "zu", "sehr", "die", "Seel", "in", "ihm", "be\u00b7fl\u00fc\u00b7geln"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PTKA", "ADV", "ART", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Die unterm Zwerchfell thront.", "tokens": ["Die", "un\u00b7term", "Zwerch\u00b7fell", "thront", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Womit sie seine Stirne schm\u00fccket,", "tokens": ["Wo\u00b7mit", "sie", "sei\u00b7ne", "Stir\u00b7ne", "schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Vollendet was ihm fehlt, damit wer ihn erblicket,", "tokens": ["Voll\u00b7en\u00b7det", "was", "ihm", "fehlt", ",", "da\u00b7mit", "wer", "ihn", "er\u00b7bli\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "PPER", "VVFIN", "$,", "KOUS", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wie er den Z\u00e4rtlichen und Angenehmen macht,", "tokens": ["Wie", "er", "den", "Z\u00e4rt\u00b7li\u00b7chen", "und", "An\u00b7ge\u00b7neh\u00b7men", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Fast \u00fcberlaut ihm an die Nase lacht.", "tokens": ["Fast", "\u00fc\u00b7berl\u00b7aut", "ihm", "an", "die", "Na\u00b7se", "lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Wie traurig, Phanias, siehst du die sch\u00f6nste Nacht,", "tokens": ["Wie", "trau\u00b7rig", ",", "Pha\u00b7ni\u00b7as", ",", "siehst", "du", "die", "sch\u00f6ns\u00b7te", "Nacht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "NE", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dir ungen\u00fctzt, bei diesem Spiel verstreichen!", "tokens": ["Dir", "un\u00b7ge\u00b7n\u00fctzt", ",", "bei", "die\u00b7sem", "Spiel", "ver\u00b7strei\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er g\u00e4hnt die Freundin kl\u00e4glich an,", "tokens": ["Er", "g\u00e4hnt", "die", "Freun\u00b7din", "kl\u00e4g\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er winkt, er seufzt: umsonst, sie folget ihrem Plan,", "tokens": ["Er", "winkt", ",", "er", "seufzt", ":", "um\u00b7sonst", ",", "sie", "fol\u00b7get", "ih\u00b7rem", "Plan", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "ADV", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und denkt vielleicht nicht weniger daran", "tokens": ["Und", "denkt", "viel\u00b7leicht", "nicht", "we\u00b7ni\u00b7ger", "da\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "ADV", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ihn mit dem seinen zu vergleichen.", "tokens": ["Ihn", "mit", "dem", "sei\u00b7nen", "zu", "ver\u00b7glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Zu ihrer Freude bringt der schlauen Chloe Kunst", "tokens": ["Zu", "ih\u00b7rer", "Freu\u00b7de", "bringt", "der", "schlau\u00b7en", "Chloe", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Den schl\u00fcpfrigen Pythagor\u00e4er", "tokens": ["Den", "schl\u00fcpf\u00b7ri\u00b7gen", "Py\u00b7tha\u00b7go\u00b7r\u00e4\u00b7er"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dem abgeredten Ziel zusehends immer n\u00e4her.", "tokens": ["Dem", "ab\u00b7ge\u00b7red\u00b7ten", "Ziel", "zu\u00b7se\u00b7hends", "im\u00b7mer", "n\u00e4\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er buhlt durch Blicke schon um ihre Gegengunst", "tokens": ["Er", "buhlt", "durch", "Bli\u00b7cke", "schon", "um", "ih\u00b7re", "Ge\u00b7gen\u00b7gunst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So feierlich, antwortet ihren Blicken", "tokens": ["So", "fei\u00b7er\u00b7lich", ",", "ant\u00b7wor\u00b7tet", "ih\u00b7ren", "Bli\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mit so fanatischem, so komischem Entz\u00fccken,", "tokens": ["Mit", "so", "fa\u00b7na\u00b7ti\u00b7schem", ",", "so", "ko\u00b7mi\u00b7schem", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df Hogarths Laune selbst kaum weiter gehen kann.", "tokens": ["Da\u00df", "Ho\u00b7garths", "Lau\u00b7ne", "selbst", "kaum", "wei\u00b7ter", "ge\u00b7hen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "ADV", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wozu, Verf\u00fchrerin, bietst du den Nektarbecher", "tokens": ["Wo\u00b7zu", ",", "Ver\u00b7f\u00fch\u00b7re\u00b7rin", ",", "bietst", "du", "den", "Nekt\u00b7ar\u00b7be\u00b7cher"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "NN", "$,", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-++--", "measure": "unknown.measure.hexa"}, "line.9": {"text": "Dem Lechzenden so zaubrisch l\u00e4chelnd an?", "tokens": ["Dem", "Lech\u00b7zen\u00b7den", "so", "zaub\u00b7risch", "l\u00e4\u00b7chelnd", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sein Brand bedarf kein \u00d6l! Nimm lieber einen F\u00e4cher,", "tokens": ["Sein", "Brand", "be\u00b7darf", "kein", "\u00d6l", "!", "Nimm", "lie\u00b7ber", "ei\u00b7nen", "F\u00e4\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$.", "NE", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und k\u00fchle seinen Mund und seiner Wangen Glut!", "tokens": ["Und", "k\u00fch\u00b7le", "sei\u00b7nen", "Mund", "und", "sei\u00b7ner", "Wan\u00b7gen", "Glut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wohnt so viel Grausamkeit in sanften M\u00e4dchenseelen?", "tokens": ["Wohnt", "so", "viel", "Grau\u00b7sam\u00b7keit", "in", "sanf\u00b7ten", "M\u00e4d\u00b7chen\u00b7see\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Glaubt ihr, ein weiser Mann sei nicht von Fleisch und Blut?", "tokens": ["Glaubt", "ihr", ",", "ein", "wei\u00b7ser", "Mann", "sei", "nicht", "von", "Fleisch", "und", "Blut", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "VAFIN", "PTKNEG", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Doch Chloe wei\u00df vermutlich was sie tut;", "tokens": ["Doch", "Chloe", "wei\u00df", "ver\u00b7mut\u00b7lich", "was", "sie", "tut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADJD", "PWS", "PPER", "VVFIN", "$."], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.15": {"text": "Sie hat die Miene nicht, ihn unbelohnt zu qu\u00e4len.", "tokens": ["Sie", "hat", "die", "Mie\u00b7ne", "nicht", ",", "ihn", "un\u00b7be\u00b7lohnt", "zu", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Nicht wenig stolz auf sein gefrornes Blut,", "tokens": ["Nicht", "we\u00b7nig", "stolz", "auf", "sein", "ge\u00b7fror\u00b7nes", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Beweist indes mit hoch empor geworfner Nase", "tokens": ["Be\u00b7weist", "in\u00b7des", "mit", "hoch", "em\u00b7por", "ge\u00b7worf\u00b7ner", "Na\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ADJD", "PTKVZ", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kleanth, der Stoiker, bei oft gef\u00fclltem Glase,", "tokens": ["Kle\u00b7an\u00b7th", ",", "der", "Stoi\u00b7ker", ",", "bei", "oft", "ge\u00b7f\u00fcll\u00b7tem", "Gla\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Da\u00df Schmerz kein \u00dcbel sei, und Sinnenlust kein Gut.", "tokens": ["Da\u00df", "Schmerz", "kein", "\u00dc\u00b7bel", "sei", ",", "und", "Sin\u00b7nen\u00b7lust", "kein", "Gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PIAT", "NN", "VAFIN", "$,", "KON", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihm h\u00e4ngt, wie dort Horaz, dem tr\u00e4gen", "tokens": ["Ihm", "h\u00e4ngt", ",", "wie", "dort", "Ho\u00b7raz", ",", "dem", "tr\u00e4\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADV", "NE", "$,", "PRELS", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Lastbaren Tiere gleich, sein Lehrling, weil er mu\u00df", "tokens": ["Last\u00b7ba\u00b7ren", "Tie\u00b7re", "gleich", ",", "sein", "Lehr\u00b7ling", ",", "weil", "er", "mu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "VMFIN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Verzweiflungsvoll ein schl\u00e4frig Ohr entgegen,", "tokens": ["Ver\u00b7zwei\u00b7flungs\u00b7voll", "ein", "schl\u00e4f\u00b7rig", "Ohr", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und widerspricht zuletzt aus Langweil und Verdru\u00df.", "tokens": ["Und", "wi\u00b7der\u00b7spricht", "zu\u00b7letzt", "aus", "Lang\u00b7weil", "und", "Ver\u00b7dru\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nat\u00fcrlich reizet dies noch mehr des Weisen Galle;", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "rei\u00b7zet", "dies", "noch", "mehr", "des", "Wei\u00b7sen", "Gal\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDS", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Eifer schenkt er sich nur desto \u00f6fter ein,", "tokens": ["Im", "Ei\u00b7fer", "schenkt", "er", "sich", "nur", "des\u00b7to", "\u00f6f\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PRF", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Glaubt, da\u00df er Wasser trinkt, nicht Wein,", "tokens": ["Glaubt", ",", "da\u00df", "er", "Was\u00b7ser", "trinkt", ",", "nicht", "Wein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,", "PTKNEG", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Und demonstriert den Aristipp, und alle", "tokens": ["Und", "de\u00b7monst\u00b7riert", "den", "A\u00b7ris\u00b7tipp", ",", "und", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NE", "$,", "KON", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Die seiner Gattung sind, in ", "tokens": ["Die", "sei\u00b7ner", "Gat\u00b7tung", "sind", ",", "in"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$,", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.24": {"line.1": {"text": "Sein Eifer f\u00fcr den Lieblingssatz der ", "tokens": ["Sein", "Ei\u00b7fer", "f\u00fcr", "den", "Lieb\u00b7lings\u00b7satz", "der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch jeden Widerspruch und jedes Glas vermehrt,", "tokens": ["Durch", "je\u00b7den", "Wi\u00b7der\u00b7spruch", "und", "je\u00b7des", "Glas", "ver\u00b7mehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat von sechs Flaschen schon die dritte ausgeleert;", "tokens": ["Hat", "von", "sechs", "Fla\u00b7schen", "schon", "die", "drit\u00b7te", "aus\u00b7ge\u00b7leert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "CARD", "NN", "ADV", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als der Planetentanz,", "tokens": ["Als", "der", "Pla\u00b7ne\u00b7ten\u00b7tanz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Die Damen zum Beschlu\u00df ergetzt,", "tokens": ["Die", "Da\u00b7men", "zum", "Be\u00b7schlu\u00df", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn vollends ganz in Flammen setzt.", "tokens": ["Ihn", "vol\u00b7lends", "ganz", "in", "Flam\u00b7men", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nun wird nichts mehr verschont: \u00c4gypter und Chald\u00e4er", "tokens": ["Nun", "wird", "nichts", "mehr", "ver\u00b7schont", ":", "\u00c4\u00b7gyp\u00b7ter", "und", "Chal\u00b7d\u00e4\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "VVPP", "$.", "NN", "KON", "NN"], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Erfahren seine Wut, wie Er des Weingotts Macht;", "tokens": ["Er\u00b7fah\u00b7ren", "sei\u00b7ne", "Wut", ",", "wie", "Er", "des", "Wein\u00b7gotts", "Macht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und eh der T\u00e4nzer noch uns von den Antipoden", "tokens": ["Und", "eh", "der", "T\u00e4n\u00b7zer", "noch", "uns", "von", "den", "An\u00b7ti\u00b7po\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Gott des Lichts zur\u00fcck gebracht,", "tokens": ["Den", "Gott", "des", "Lichts", "zu\u00b7r\u00fcck", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "F\u00e4llt taumelnd sein Rival und liegt besiegt zu Boden.", "tokens": ["F\u00e4llt", "tau\u00b7melnd", "sein", "Ri\u00b7val", "und", "liegt", "be\u00b7siegt", "zu", "Bo\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "NN", "KON", "VVFIN", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Der dritte Akt des Lustspiels schlie\u00dft sich nun,", "tokens": ["Der", "drit\u00b7te", "Akt", "des", "Lust\u00b7spiels", "schlie\u00dft", "sich", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und alles sehnet sich, den Rest der Nacht zu ruhn.", "tokens": ["Und", "al\u00b7les", "seh\u00b7net", "sich", ",", "den", "Rest", "der", "Nacht", "zu", "ruhn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "$,", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kleanth, der, wie er lag, Virgils Silenen", "tokens": ["Kle\u00b7an\u00b7th", ",", "der", ",", "wie", "er", "lag", ",", "Vir\u00b7gils", "Si\u00b7le\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "$,", "PRELS", "$,", "PWAV", "PPER", "VVFIN", "$,", "KOUS", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Nicht \u00fcbel glich, (nur da\u00df er nicht erwacht,", "tokens": ["Nicht", "\u00fc\u00b7bel", "glich", ",", "(", "nur", "da\u00df", "er", "nicht", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVFIN", "$,", "$(", "ADV", "KOUS", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So sehr ihn Chloe zwickt, so laut man um ihn lacht)", "tokens": ["So", "sehr", "ihn", "Chloe", "zwickt", ",", "so", "laut", "man", "um", "ihn", "lacht", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "NE", "VVFIN", "$,", "ADV", "APPR", "PIS", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-++-+-+-+", "measure": "unknown.measure.hexa"}, "line.6": {"text": "Wird standsgem\u00e4\u00df, umtanzt von beiden Sch\u00f6nen,", "tokens": ["Wird", "stands\u00b7ge\u00b7m\u00e4\u00df", ",", "um\u00b7tanzt", "von", "bei\u00b7den", "Sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Mit Bacchischem Triumph in \u2013 einen Stall gebracht,", "tokens": ["Mit", "Bac\u00b7chi\u00b7schem", "Tri\u00b7umph", "in", "\u2013", "ei\u00b7nen", "Stall", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "$(", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und lachend w\u00fcnschet man einander gute Nacht.", "tokens": ["Und", "la\u00b7chend", "w\u00fcn\u00b7schet", "man", "ein\u00b7an\u00b7der", "gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "PRF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}