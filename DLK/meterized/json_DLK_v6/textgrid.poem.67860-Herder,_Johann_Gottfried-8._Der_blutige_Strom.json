{"textgrid.poem.67860": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "8. Der blutige Strom", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gr\u00fcner Strom, du rinnst so traurig,", "tokens": ["Gr\u00fc\u00b7ner", "Strom", ",", "du", "rinnst", "so", "trau\u00b7rig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel Leichen schwimmen in dir,", "tokens": ["So", "viel", "Lei\u00b7chen", "schwim\u00b7men", "in", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Christenleichen, Mohrenleichen,", "tokens": ["Chris\u00b7ten\u00b7lei\u00b7chen", ",", "Moh\u00b7ren\u00b7lei\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die das harte Schwert erlegte.", "tokens": ["Die", "das", "har\u00b7te", "Schwert", "er\u00b7leg\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Deine klare Silberwellen", "tokens": ["Dei\u00b7ne", "kla\u00b7re", "Sil\u00b7ber\u00b7wel\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind mit rothem Blut gef\u00e4rbet,", "tokens": ["Sind", "mit", "ro\u00b7them", "Blut", "ge\u00b7f\u00e4r\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mohrenblute, Christenblute,", "tokens": ["Moh\u00b7ren\u00b7blu\u00b7te", ",", "Chris\u00b7ten\u00b7blu\u00b7te", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die in grosser Schlacht hier fielen.", "tokens": ["Die", "in", "gros\u00b7ser", "Schlacht", "hier", "fie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ritter, Herzoge und Grafen,", "tokens": ["Rit\u00b7ter", ",", "Her\u00b7zo\u00b7ge", "und", "Gra\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Grosse hohen Standes fielen,", "tokens": ["Gros\u00b7se", "ho\u00b7hen", "Stan\u00b7des", "fie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "M\u00e4nner hoher Tugend sanken,", "tokens": ["M\u00e4n\u00b7ner", "ho\u00b7her", "Tu\u00b7gend", "san\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Bl\u00fcthe Span'scher Edlen.", "tokens": ["Und", "die", "Bl\u00fc\u00b7the", "Span'\u00b7scher", "Ed\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "An dir sank hier Don Alonso,", "tokens": ["An", "dir", "sank", "hier", "Don", "A\u00b7lon\u00b7so", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ADV", "NE", "NE", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "Der von Aguilar sich nannte,", "tokens": ["Der", "von", "A\u00b7gui\u00b7lar", "sich", "nann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch der tapfre Urdiales", "tokens": ["Auch", "der", "tapf\u00b7re", "Ur\u00b7di\u00b7a\u00b7les"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sank an dir, mit Don Alonso.", "tokens": ["Sank", "an", "dir", ",", "mit", "Don", "A\u00b7lon\u00b7so", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "$,", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Von der Seite klimmt den Felsen", "tokens": ["Von", "der", "Sei\u00b7te", "klimmt", "den", "Fel\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ab der tapfre Sayavedra,", "tokens": ["Ab", "der", "tapf\u00b7re", "Say\u00b7a\u00b7ve\u00b7dra", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Eingebohrner von Sevilla", "tokens": ["Ein\u00b7ge\u00b7bohr\u00b7ner", "von", "Se\u00b7vil\u00b7la"], "token_info": ["word", "word", "word"], "pos": ["PIS", "APPR", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Aus Granad's (lies: Granadas) \u00e4ltstem Stamme.", "tokens": ["Aus", "Gra\u00b7na\u00b7d's", "(", "lies", ":", "Gra\u00b7na\u00b7das", ")", "\u00e4lts\u00b7tem", "Stam\u00b7me", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$(", "VVFIN", "$.", "NE", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Hinter ihm ein Renegate", "tokens": ["Hin\u00b7ter", "ihm", "ein", "Re\u00b7ne\u00b7ga\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rief ihm nach mit frecher Stimme:", "tokens": ["Rief", "ihm", "nach", "mit", "fre\u00b7cher", "Stim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbgib dich, gib dich, Sayavedra!", "tokens": ["\u00bb", "gib", "dich", ",", "gib", "dich", ",", "Say\u00b7a\u00b7ve\u00b7dra", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "VVIMP", "PPER", "$,", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Fliehe nicht so aus dem Treffen!", "tokens": ["Flie\u00b7he", "nicht", "so", "aus", "dem", "Tref\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wohl erkenn' ich dich, ich war ja", "tokens": ["Wohl", "er\u00b7kenn'", "ich", "dich", ",", "ich", "war", "ja"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PPER", "VAFIN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Lang genug in deinem Hause.", "tokens": ["Lang", "ge\u00b7nug", "in", "dei\u00b7nem", "Hau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf dem Markte von Sevilla", "tokens": ["Auf", "dem", "Mark\u00b7te", "von", "Se\u00b7vil\u00b7la"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sah ich oft dich Lanzen werfen;", "tokens": ["Sah", "ich", "oft", "dich", "Lan\u00b7zen", "wer\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Kenne deine Eltern, kenne", "tokens": ["Ken\u00b7ne", "dei\u00b7ne", "El\u00b7tern", ",", "ken\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dein Gemahl, die Donna Klara,", "tokens": ["Dein", "Ge\u00b7mahl", ",", "die", "Don\u00b7na", "Kla\u00b7ra", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieben Jahre dein Gefangner,", "tokens": ["Sie\u00b7ben", "Jah\u00b7re", "dein", "Ge\u00b7fang\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit dem du sehr hart verfuhrest!", "tokens": ["Mit", "dem", "du", "sehr", "hart", "ver\u00b7fuh\u00b7rest", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Jezt sollt du der Meine werden,", "tokens": ["Jezt", "sollt", "du", "der", "Mei\u00b7ne", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "PPOSAT", "VAINF", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Wenn mir Mahomet nun beisteht,", "tokens": ["Wenn", "mir", "Ma\u00b7ho\u00b7met", "nun", "bei\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dann will ich mit dir umgehn,", "tokens": ["Und", "dann", "will", "ich", "mit", "dir", "um\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie du einst mit mir auch umgingst!\u00ab", "tokens": ["Wie", "du", "einst", "mit", "mir", "auch", "um\u00b7gingst", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sayavedra, der das h\u00f6rte,", "tokens": ["Say\u00b7a\u00b7ve\u00b7dra", ",", "der", "das", "h\u00f6r\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PDS", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Kehrt sein Angesicht zum Mohren,", "tokens": ["Kehrt", "sein", "An\u00b7ge\u00b7sicht", "zum", "Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Mohr schnellt seinen Bogen,", "tokens": ["Und", "der", "Mohr", "schnellt", "sei\u00b7nen", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch der Pfeil kam nicht zum Ziele.", "tokens": ["Doch", "der", "Pfeil", "kam", "nicht", "zum", "Zie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Und da fa\u00dfte Sayavedra,", "tokens": ["Und", "da", "fa\u00df\u00b7te", "Say\u00b7a\u00b7ve\u00b7dra", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NE", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Traf auf ihn mit \u00fcblem Stosse;", "tokens": ["Traf", "auf", "ihn", "mit", "\u00fcb\u00b7lem", "Stos\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nieder st\u00fcrzt der Renegate,", "tokens": ["Nie\u00b7der", "st\u00fcrzt", "der", "Re\u00b7ne\u00b7ga\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ohn' ein Wort noch zu verm\u00f6gen.", "tokens": ["Ohn'", "ein", "Wort", "noch", "zu", "ver\u00b7m\u00f6\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Sayavedra ward umringet", "tokens": ["Say\u00b7a\u00b7ve\u00b7dra", "ward", "um\u00b7rin\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["NE", "VAFIN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem ganzen Mohrenp\u00f6bel,", "tokens": ["Von", "dem", "gan\u00b7zen", "Moh\u00b7ren\u00b7p\u00f6\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und am Ende sank er todt hin,", "tokens": ["Und", "am", "En\u00b7de", "sank", "er", "todt", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Todt von einer b\u00f6sen Lanze.", "tokens": ["Todt", "von", "ei\u00b7ner", "b\u00f6\u00b7sen", "Lan\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Noch stritt Don Alonso tapfer;", "tokens": ["Noch", "stritt", "Don", "A\u00b7lon\u00b7so", "tap\u00b7fer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "ADJD", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Schon war ihm sein Ro\u00df erlegen,", "tokens": ["Schon", "war", "ihm", "sein", "Ro\u00df", "er\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und sein todtes Ro\u00df mu\u00df jezo", "tokens": ["Und", "sein", "tod\u00b7tes", "Ro\u00df", "mu\u00df", "je\u00b7zo"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VMFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fechtend ihm statt Mauer dienen.", "tokens": ["Fech\u00b7tend", "ihm", "statt", "Mau\u00b7er", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Aber Mohren \u00fcber Mohren", "tokens": ["A\u00b7ber", "Moh\u00b7ren", "\u00fc\u00b7ber", "Moh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Drangen auf ihn, fochten, stiessen,", "tokens": ["Dran\u00b7gen", "auf", "ihn", ",", "foch\u00b7ten", ",", "sties\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vom Blut, das er verlohren,", "tokens": ["Und", "vom", "Blut", ",", "das", "er", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sinkt ohnm\u00e4chtig Don Alonso.", "tokens": ["Sinkt", "ohn\u00b7m\u00e4ch\u00b7tig", "Don", "A\u00b7lon\u00b7so", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NE", "NE", "$."], "meter": "+-+-++--", "measure": "unknown.measure.tetra"}}, "stanza.15": {"line.1": {"text": "Endlich, endlich sinkt er nieder", "tokens": ["End\u00b7lich", ",", "end\u00b7lich", "sinkt", "er", "nie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADV", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An dem Fu\u00df des hohen Felsen,", "tokens": ["An", "dem", "Fu\u00df", "des", "ho\u00b7hen", "Fel\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bleibet todt; doch Don Alonso", "tokens": ["Blei\u00b7bet", "todt", ";", "doch", "Don", "A\u00b7lon\u00b7so"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "$.", "ADV", "NE", "NE"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "Lebet noch in ew'gem Ruhme.", "tokens": ["Le\u00b7bet", "noch", "in", "ew'\u00b7gem", "Ruh\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}