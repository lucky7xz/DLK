{"dta.poem.13277": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "E ilftes  B uch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20535-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "\u201esag! was erw\u00e4hntest du von jener V\u00f6gel-Schaar,", "tokens": ["\u201e", "sag", "!", "was", "er\u00b7w\u00e4hn\u00b7test", "du", "von", "je\u00b7ner", "V\u00f6\u00b7gel\u00b7Schaar", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "$.", "PWS", "VVFIN", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201edie unsers ", "tokens": ["\u201e", "die", "un\u00b7sers"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "\u201ewie kann dein weiser Geist den Zufall so verachten?", "tokens": ["\u201e", "wie", "kann", "dein", "wei\u00b7ser", "Geist", "den", "Zu\u00b7fall", "so", "ver\u00b7ach\u00b7ten", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPOSAT", "ADJA", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "580\u201dIst dir dann unbekannt, was sie vor Zeiten brachten?", "tokens": ["\"", "Ist", "dir", "dann", "un\u00b7be\u00b7kannt", ",", "was", "sie", "vor", "Zei\u00b7ten", "brach\u00b7ten", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADV", "ADJD", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eerfolgte nicht darauf ein allgemeiner Fried?", "tokens": ["\u201e", "er\u00b7folg\u00b7te", "nicht", "da\u00b7rauf", "ein", "all\u00b7ge\u00b7mei\u00b7ner", "Fried", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201ewer wei\u00df, ob zwischen jezt und dort ein Unterschied?", "tokens": ["\u201e", "wer", "wei\u00df", ",", "ob", "zwi\u00b7schen", "jezt", "und", "dort", "ein", "Un\u00b7ter\u00b7schied", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "$,", "KOUS", "APPR", "ADV", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201ewar dieses nicht vielleicht schon dazumahl das Zeichen,", "tokens": ["\u201e", "war", "die\u00b7ses", "nicht", "viel\u00b7leicht", "schon", "da\u00b7zu\u00b7mahl", "das", "Zei\u00b7chen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PDS", "PTKNEG", "ADV", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eda\u00df einstens, wie geschah, der Adler w\u00fcrde weichen;", "tokens": ["\u201e", "da\u00df", "eins\u00b7tens", ",", "wie", "ge\u00b7schah", ",", "der", "Ad\u00b7ler", "w\u00fcr\u00b7de", "wei\u00b7chen", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "$,", "PWAV", "VVFIN", "$,", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "585\u201dMithin aus jenem Land, woher der neue Flug", "tokens": ["\"", "Mi\u00b7thin", "aus", "je\u00b7nem", "Land", ",", "wo\u00b7her", "der", "neu\u00b7e", "Flug"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "PDAT", "NN", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ederselben Stahren-Schaar sich zu dem Adler schlug,", "tokens": ["\u201e", "der\u00b7sel\u00b7ben", "Stahren\u00b7Schaar", "sich", "zu", "dem", "Ad\u00b7ler", "schlug", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDAT", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "\u201eein solcher Krieger-Schwarm zum Beystand w\u00fcrde kommen,", "tokens": ["\u201e", "ein", "sol\u00b7cher", "Krie\u00b7ger\u00b7Schwarm", "zum", "Beys\u00b7tand", "w\u00fcr\u00b7de", "kom\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PIAT", "NN", "APPRART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201ebi\u00df dieser wiederum den alten Siz genommen?", "tokens": ["\u201e", "bi\u00df", "die\u00b7ser", "wie\u00b7de\u00b7rum", "den", "al\u00b7ten", "Siz", "ge\u00b7nom\u00b7men", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}