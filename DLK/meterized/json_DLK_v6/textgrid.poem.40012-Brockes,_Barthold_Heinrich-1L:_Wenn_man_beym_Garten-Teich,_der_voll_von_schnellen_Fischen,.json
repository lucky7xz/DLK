{"textgrid.poem.40012": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wenn man beym Garten-Teich, der voll von schnellen Fischen,", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn man beym Garten-Teich, der voll von schnellen Fischen,", "tokens": ["Wenn", "man", "beym", "Gar\u00b7ten\u00b7Teich", ",", "der", "voll", "von", "schnel\u00b7len", "Fi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "$,", "PRELS", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und rings umher umpflantzt mit Taxus-B\u00e4um- und B\u00fcschen,", "tokens": ["Und", "rings", "um\u00b7her", "um\u00b7pflantzt", "mit", "Ta\u00b7xus\u00b7B\u00e4um", "und", "B\u00fc\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "VVFIN", "APPR", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich im geraden Viereck zeiget,", "tokens": ["Sich", "im", "ge\u00b7ra\u00b7den", "Vier\u00b7eck", "zei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die breite Stieg' hinunter steiget;", "tokens": ["Die", "brei\u00b7te", "Stieg'", "hin\u00b7un\u00b7ter", "stei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPO", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Erblickt man einen gr\u00fcnen Gang,", "tokens": ["Er\u00b7blickt", "man", "ei\u00b7nen", "gr\u00fc\u00b7nen", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "De\u00df Seiten Linien so lang,", "tokens": ["De\u00df", "Sei\u00b7ten", "Li\u00b7ni\u00b7en", "so", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df die darob fast m\u00fcden Augen", "tokens": ["Da\u00df", "die", "da\u00b7rob", "fast", "m\u00fc\u00b7den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "PAV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gespitzt, mit M\u00fch', ihr Ziel zu finden taugen.", "tokens": ["Ge\u00b7spitzt", ",", "mit", "M\u00fch'", ",", "ihr", "Ziel", "zu", "fin\u00b7den", "tau\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPR", "NN", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Des gr\u00fcnen Kerckers holde L\u00e4nge", "tokens": ["Des", "gr\u00fc\u00b7nen", "Ker\u00b7ckers", "hol\u00b7de", "L\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Treibt den gefang'nen Blick in eine sch\u00f6ne Enge;", "tokens": ["Treibt", "den", "ge\u00b7fang'\u00b7nen", "Blick", "in", "ei\u00b7ne", "sch\u00f6\u00b7ne", "En\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Er hofft, voll s\u00fcsser Furcht, da\u00df gar kein Ende sey,", "tokens": ["Er", "hofft", ",", "voll", "s\u00fcs\u00b7ser", "Furcht", ",", "da\u00df", "gar", "kein", "En\u00b7de", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "ADJA", "NN", "$,", "KOUS", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und wird, wie matt er gleich, dennoch mit Unmuth frey.", "tokens": ["Und", "wird", ",", "wie", "matt", "er", "gleich", ",", "den\u00b7noch", "mit", "Un\u00b7muth", "frey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "PWAV", "ADJD", "PPER", "ADV", "$,", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "In diesem angenehmen Steige", "tokens": ["In", "die\u00b7sem", "an\u00b7ge\u00b7neh\u00b7men", "Stei\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Gehorcheten nicht nur", "tokens": ["Ge\u00b7hor\u00b7che\u00b7ten", "nicht", "nur"], "token_info": ["word", "word", "word"], "pos": ["NN", "PTKNEG", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Die schlancken B\u00e4ume, St\u00e4mm' und Zweige,", "tokens": ["Die", "schlan\u00b7cken", "B\u00e4u\u00b7me", ",", "St\u00e4mm'", "und", "Zwei\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Nein, gar die Bl\u00e4tter selbst, der gleich gezog'nen Schnur.", "tokens": ["Nein", ",", "gar", "die", "Bl\u00e4t\u00b7ter", "selbst", ",", "der", "gleich", "ge\u00b7zo\u00b7g'\u00b7nen", "Schnur", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ART", "NN", "ADV", "$,", "PRELS", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.17": {"text": "Die Aeste sind durch's Laub verdeckt,", "tokens": ["Die", "A\u00b7es\u00b7te", "sind", "durch's", "Laub", "ver\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Worinnen gar die St\u00e4mme selbst versteckt.", "tokens": ["Wo\u00b7rin\u00b7nen", "gar", "die", "St\u00e4m\u00b7me", "selbst", "ver\u00b7steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Dahero scheint's, als ob das gr\u00fcne Laub", "tokens": ["Da\u00b7he\u00b7ro", "scheint's", ",", "als", "ob", "das", "gr\u00fc\u00b7ne", "Laub"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "$,", "KOKOM", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Sich, ohne Stamm, auf Sand und Staub,", "tokens": ["Sich", ",", "oh\u00b7ne", "Stamm", ",", "auf", "Sand", "und", "Staub", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$,", "KOUI", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Als w\u00e4r' es aufgemauert, gr\u00fcnde.", "tokens": ["Als", "w\u00e4r'", "es", "auf\u00b7ge\u00b7mau\u00b7ert", ",", "gr\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "VVPP", "$,", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Die Bl\u00e4tter schr\u00e4ncken sich so dicht und fest,", "tokens": ["Die", "Bl\u00e4t\u00b7ter", "schr\u00e4n\u00b7cken", "sich", "so", "dicht", "und", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Da\u00df ihre Dunckelheit dem Regen, Licht' und Winde", "tokens": ["Da\u00df", "ih\u00b7re", "Dun\u00b7ckel\u00b7heit", "dem", "Re\u00b7gen", ",", "Licht'", "und", "Win\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Nicht den geringsten Durchgang l\u00e4sst.", "tokens": ["Nicht", "den", "ge\u00b7rings\u00b7ten", "Durch\u00b7gang", "l\u00e4sst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Der Augen sonst so scharfe Blicke", "tokens": ["Der", "Au\u00b7gen", "sonst", "so", "schar\u00b7fe", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Begegneten nur dann und wann", "tokens": ["Be\u00b7ge\u00b7gne\u00b7ten", "nur", "dann", "und", "wann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "KON", "PWAV"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.27": {"text": "Dem, durch die, von der Luft, gemachten selt'nen Ritzen,", "tokens": ["Dem", ",", "durch", "die", ",", "von", "der", "Luft", ",", "ge\u00b7mach\u00b7ten", "selt'\u00b7nen", "Rit\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "APPR", "ART", "$,", "APPR", "ART", "NN", "$,", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Mit angenehmen schnellen Blitzen,", "tokens": ["Mit", "an\u00b7ge\u00b7neh\u00b7men", "schnel\u00b7len", "Blit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Eindringenden, gantz zarten Sonnen-Strahl.", "tokens": ["Ein\u00b7drin\u00b7gen\u00b7den", ",", "gantz", "zar\u00b7ten", "Son\u00b7nen\u00b7Strahl", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Sonst aber war die Wand so dicke,", "tokens": ["Sonst", "a\u00b7ber", "war", "die", "Wand", "so", "di\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Da\u00df, wann die Augen oftermahl", "tokens": ["Da\u00df", ",", "wann", "die", "Au\u00b7gen", "of\u00b7ter\u00b7mahl"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "PWAV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Von Blatt auf Blatt, in Schatten-reichen Tiefen,", "tokens": ["Von", "Blatt", "auf", "Blatt", ",", "in", "Schat\u00b7ten\u00b7rei\u00b7chen", "Tie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Verwirret hin und wieder liefen,", "tokens": ["Ver\u00b7wir\u00b7ret", "hin", "und", "wie\u00b7der", "lie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Sie keine Th\u00fcr zu finden wusten,", "tokens": ["Sie", "kei\u00b7ne", "Th\u00fcr", "zu", "fin\u00b7den", "wus\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Und, angenehm-besch\u00e4m't, zur\u00fccke gehen musten.", "tokens": ["Und", ",", "an\u00b7ge\u00b7nehm\u00b7be\u00b7sch\u00e4m't", ",", "zu\u00b7r\u00fc\u00b7cke", "ge\u00b7hen", "mus\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVPP", "$,", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Ich f\u00fchlt' und sah in diesen B\u00fcschen,", "tokens": ["Ich", "f\u00fchlt'", "und", "sah", "in", "die\u00b7sen", "B\u00fc\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Wie, durch der Bl\u00e4tter gr\u00fcne Pracht,", "tokens": ["Wie", ",", "durch", "der", "Bl\u00e4t\u00b7ter", "gr\u00fc\u00b7ne", "Pracht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Sich Hitz' und K\u00e4lte, Licht und Nacht,", "tokens": ["Sich", "Hitz'", "und", "K\u00e4l\u00b7te", ",", "Licht", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "NE", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Nach langem K\u00e4mpfen, endlich mischen,", "tokens": ["Nach", "lan\u00b7gem", "K\u00e4mp\u00b7fen", ",", "end\u00b7lich", "mi\u00b7schen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Und, unter den belaubten Zweigen,", "tokens": ["Und", ",", "un\u00b7ter", "den", "be\u00b7laub\u00b7ten", "Zwei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Die K\u00fchlung und die D\u00e4mm'rung zeugen.", "tokens": ["Die", "K\u00fch\u00b7lung", "und", "die", "D\u00e4m\u00b7m'\u00b7rung", "zeu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Vergn\u00fcgte Seele, nimm in Acht:", "tokens": ["Ver\u00b7gn\u00fcg\u00b7te", "See\u00b7le", ",", "nimm", "in", "Acht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVIMP", "APPR", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein jedes Blatt dient Hitz' und Wind zu wehren,", "tokens": ["Ein", "je\u00b7des", "Blatt", "dient", "Hitz'", "und", "Wind", "zu", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein jedes Blatt hilft deine Lust vermehren,", "tokens": ["Ein", "je\u00b7des", "Blatt", "hilft", "dei\u00b7ne", "Lust", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein jedes Blatt zeigt Gottes Lieb' und Macht.", "tokens": ["Ein", "je\u00b7des", "Blatt", "zeigt", "Got\u00b7tes", "Lieb'", "und", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ach, so gedencke denn, den Sch\u00f6pfer zu verehren,", "tokens": ["Ach", ",", "so", "ge\u00b7den\u00b7cke", "denn", ",", "den", "Sch\u00f6p\u00b7fer", "zu", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "ADV", "$,", "ART", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und la\u00df, in dem Gebrauch von diesen holden Schatten,", "tokens": ["Und", "la\u00df", ",", "in", "dem", "Ge\u00b7brauch", "von", "die\u00b7sen", "hol\u00b7den", "Schat\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$,", "APPR", "ART", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In deiner sanft ger\u00fchrten Brust,", "tokens": ["In", "dei\u00b7ner", "sanft", "ge\u00b7r\u00fchr\u00b7ten", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich die Betrachtung mit der Lust,", "tokens": ["Sich", "die", "Be\u00b7trach\u00b7tung", "mit", "der", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Vergn\u00fcgung mit der Andacht, gatten!", "tokens": ["Ver\u00b7gn\u00fc\u00b7gung", "mit", "der", "An\u00b7dacht", ",", "gat\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Oft siehet man mit dunckler Bl\u00e4tter Bildern,", "tokens": ["Oft", "sie\u00b7het", "man", "mit", "dunck\u00b7ler", "Bl\u00e4t\u00b7ter", "Bil\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Steige, sich die hellen Stellen schildern,", "tokens": ["Im", "Stei\u00b7ge", ",", "sich", "die", "hel\u00b7len", "Stel\u00b7len", "schil\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRF", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wobey auch oft der duncklen Stellen Nacht", "tokens": ["Wo\u00b7bey", "auch", "oft", "der", "dunck\u00b7len", "Stel\u00b7len", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein schnelles Bl\u00e4tter-f\u00f6rmicht Licht,", "tokens": ["Ein", "schnel\u00b7les", "Bl\u00e4t\u00b7ter\u00b7f\u00f6r\u00b7micht", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das durch der Bl\u00e4tter Oeffnung bricht,", "tokens": ["Das", "durch", "der", "Bl\u00e4t\u00b7ter", "Oeff\u00b7nung", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit gleichsam g\u00fcld'ner Bl\u00e4tter Pracht", "tokens": ["Mit", "gleich\u00b7sam", "g\u00fcld'\u00b7ner", "Bl\u00e4t\u00b7ter", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und regen Circkeln, helle macht.", "tokens": ["Und", "re\u00b7gen", "Cir\u00b7ckeln", ",", "hel\u00b7le", "macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Oft, wenn durch das beweg'te Laub", "tokens": ["Oft", ",", "wenn", "durch", "das", "be\u00b7weg'\u00b7te", "Laub"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Sonnen spitze Strahlen spielen;", "tokens": ["Der", "Son\u00b7nen", "spit\u00b7ze", "Strah\u00b7len", "spie\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So lie\u00df es, als wenn auf den Staub", "tokens": ["So", "lie\u00df", "es", ",", "als", "wenn", "auf", "den", "Staub"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOKOM", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Best\u00e4ndig g\u00fcld'ne Flocken fielen:", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "g\u00fcld'\u00b7ne", "Flo\u00b7cken", "fie\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wenn aber Zephirus die schlancken Zweige", "tokens": ["Wenn", "a\u00b7ber", "Ze\u00b7phi\u00b7rus", "die", "schlan\u00b7cken", "Zwei\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NE", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "In Ruhe l\u00e4sst;", "tokens": ["In", "Ru\u00b7he", "l\u00e4sst", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "Scheint es, als w\u00e4r' im braunen Steige,", "tokens": ["Scheint", "es", ",", "als", "w\u00e4r'", "im", "brau\u00b7nen", "Stei\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOKOM", "VAFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Figuren weis', ein g\u00fcld'ner Sand gestreut.", "tokens": ["Fi\u00b7gu\u00b7ren", "weis'", ",", "ein", "g\u00fcld'\u00b7ner", "Sand", "ge\u00b7streut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Indem ich hier, in stiller Einsamkeit,", "tokens": ["In\u00b7dem", "ich", "hier", ",", "in", "stil\u00b7ler", "Ein\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An dieses Ganges Schmuck und L\u00e4ng', in sanfter Freude,", "tokens": ["An", "die\u00b7ses", "Gan\u00b7ges", "Schmuck", "und", "L\u00e4ng'", ",", "in", "sanf\u00b7ter", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "KON", "NE", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu Gottes Ruhm, mein Auge weide;", "tokens": ["Zu", "Got\u00b7tes", "Ruhm", ",", "mein", "Au\u00b7ge", "wei\u00b7de", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sah ich von ungefehr auf zwantzig Schritte weit,", "tokens": ["Sah", "ich", "von", "un\u00b7ge\u00b7fehr", "auf", "zwant\u00b7zig", "Schrit\u00b7te", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJD", "APPR", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aus einer, von dem Ort, woselbst ich stand,", "tokens": ["Aus", "ei\u00b7ner", ",", "von", "dem", "Ort", ",", "wo\u00b7selbst", "ich", "stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nicht sichtbar'n Th\u00fcr der gr\u00fcnen Wand,", "tokens": ["Nicht", "sicht\u00b7ba\u00b7r'n", "Th\u00fcr", "der", "gr\u00fc\u00b7nen", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Von einer Seite zu der andern,", "tokens": ["Von", "ei\u00b7ner", "Sei\u00b7te", "zu", "der", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das \u00e4lt'ste Paar von meinen Kindern wandern.", "tokens": ["Das", "\u00e4lt'\u00b7ste", "Paar", "von", "mei\u00b7nen", "Kin\u00b7dern", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sie hielten sich einander bey der Hand,", "tokens": ["Sie", "hiel\u00b7ten", "sich", "ein\u00b7an\u00b7der", "bey", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und sag'ten nicht ein Wort.", "tokens": ["Und", "sag'\u00b7ten", "nicht", "ein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Kaum ward ich ihrer recht gewahr,", "tokens": ["Kaum", "ward", "ich", "ih\u00b7rer", "recht", "ge\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Da waren sie schon wieder fort,", "tokens": ["Da", "wa\u00b7ren", "sie", "schon", "wie\u00b7der", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und in der, gleichfalls nicht von mir", "tokens": ["Und", "in", "der", ",", "gleich\u00b7falls", "nicht", "von", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "$,", "ADV", "PTKNEG", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Geseh'nen andern gr\u00fcnen Th\u00fcr,", "tokens": ["Ge\u00b7seh'\u00b7nen", "an\u00b7dern", "gr\u00fc\u00b7nen", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Indem sie gleich quer \u00fcber giengen:", "tokens": ["In\u00b7dem", "sie", "gleich", "quer", "\u00fc\u00b7ber", "gien\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Schnell hatten sie sich eingefunden,", "tokens": ["Schnell", "hat\u00b7ten", "sie", "sich", "ein\u00b7ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Schnell waren sie hinweg, als w\u00e4ren sie verschwunden.", "tokens": ["Schnell", "wa\u00b7ren", "sie", "hin\u00b7weg", ",", "als", "w\u00e4\u00b7ren", "sie", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PTKVZ", "$,", "KOKOM", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Bald sah ich andre Zwey", "tokens": ["Bald", "sah", "ich", "and\u00b7re", "Zwey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Durch eben diesen Weg, in vollen Spr\u00fcngen, springen:", "tokens": ["Durch", "e\u00b7ben", "die\u00b7sen", "Weg", ",", "in", "vol\u00b7len", "Spr\u00fcn\u00b7gen", ",", "sprin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADV", "PDAT", "NN", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die waren auch im Augenblick vorbey.", "tokens": ["Die", "wa\u00b7ren", "auch", "im", "Au\u00b7gen\u00b7blick", "vor\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dem folgete gemach gemach", "tokens": ["Dem", "fol\u00b7ge\u00b7te", "ge\u00b7mach", "ge\u00b7mach"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das dritte Paar, mit kleinen Schritten, nach.", "tokens": ["Das", "drit\u00b7te", "Paar", ",", "mit", "klei\u00b7nen", "Schrit\u00b7ten", ",", "nach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zuletzt erblickt' ich noch auf gleiche Weise,", "tokens": ["Zu\u00b7letzt", "er\u00b7blickt'", "ich", "noch", "auf", "glei\u00b7che", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wie auch das vierte Paar, jedoch gantz leise,", "tokens": ["Wie", "auch", "das", "vier\u00b7te", "Paar", ",", "je\u00b7doch", "gantz", "lei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Aus eben diesem Orte kam,", "tokens": ["Aus", "e\u00b7ben", "die\u00b7sem", "Or\u00b7te", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und, weil die Reise kurtz, schnell wieder Abschied nahm.", "tokens": ["Und", ",", "weil", "die", "Rei\u00b7se", "kurtz", ",", "schnell", "wie\u00b7der", "Ab\u00b7schied", "nahm", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADJD", "$,", "ADJD", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Im Augenblick war also, wie vorher,", "tokens": ["Im", "Au\u00b7gen\u00b7blick", "war", "al\u00b7so", ",", "wie", "vor\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "$,", "PWAV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Steig gantz einsam, still und leer,", "tokens": ["Der", "Steig", "gantz", "ein\u00b7sam", ",", "still", "und", "leer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und war von allem, was darin geschehen,", "tokens": ["Und", "war", "von", "al\u00b7lem", ",", "was", "da\u00b7rin", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIS", "$,", "PRELS", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht die geringste Spur zu sehen.", "tokens": ["Nicht", "die", "ge\u00b7rings\u00b7te", "Spur", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Hier\u00fcber stutzt' ich recht: von ernstlichen Gedancken", "tokens": ["Hier\u00b7\u00fc\u00b7ber", "stutzt'", "ich", "recht", ":", "von", "ernst\u00b7li\u00b7chen", "Ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ward mein Gem\u00fcth erf\u00fcllt,", "tokens": ["Ward", "mein", "Ge\u00b7m\u00fcth", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und fiel mir die Betrachtung ein!", "tokens": ["Und", "fiel", "mir", "die", "Be\u00b7trach\u00b7tung", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbes scheinet die\u00df Gesicht ein Bild", "tokens": ["\u00bb", "es", "schei\u00b7net", "die\u00df", "Ge\u00b7sicht", "ein", "Bild"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PDS", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von unserm Lebens-Lauf zu seyn.", "tokens": ["Von", "un\u00b7serm", "Le\u00b7bens\u00b7Lauf", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir treten in die Welt, und, weil wir immer gehen,", "tokens": ["Wir", "tre\u00b7ten", "in", "die", "Welt", ",", "und", ",", "weil", "wir", "im\u00b7mer", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nie aber stille stehen,", "tokens": ["Nie", "a\u00b7ber", "stil\u00b7le", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So sind wir bald hindruch. Wir treten pl\u00f6tzlich auf,", "tokens": ["So", "sind", "wir", "bald", "hind\u00b7ruch", ".", "Wir", "tre\u00b7ten", "pl\u00f6tz\u00b7lich", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und pl\u00f6tzlich wieder ab.", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "wie\u00b7der", "ab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Es ist das Ziel von unserm Lebens-Lauf", "tokens": ["Es", "ist", "das", "Ziel", "von", "un\u00b7serm", "Le\u00b7bens\u00b7Lauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ein unvermeidlich Grab.", "tokens": ["Ein", "un\u00b7ver\u00b7meid\u00b7lich", "Grab", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ach ja, mehr als zu wahr, was ich, von unserm Wesen,", "tokens": ["Ach", "ja", ",", "mehr", "als", "zu", "wahr", ",", "was", "ich", ",", "von", "un\u00b7serm", "We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$,", "PIAT", "KOKOM", "PTKA", "ADJD", "$,", "PWS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In einer alten Schrift gelesen:", "tokens": ["In", "ei\u00b7ner", "al\u00b7ten", "Schrift", "ge\u00b7le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Hier drohete nun auch das Angedencken", "tokens": ["Hier", "dro\u00b7he\u00b7te", "nun", "auch", "das", "An\u00b7ge\u00b7den\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der gar zu kurtzen Daur des Lebens,", "tokens": ["Der", "gar", "zu", "kurt\u00b7zen", "Daur", "des", "Le\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mich in den finstern Pful der Schwermuth zu versencken:", "tokens": ["Mich", "in", "den", "fins\u00b7tern", "Pful", "der", "Schwer\u00b7muth", "zu", "ver\u00b7sen\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein, Gott Lob! vergebens.", "tokens": ["Al\u00b7lein", ",", "Gott", "Lob", "!", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "NN", "NN", "$.", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn mir fiel dieses ein:", "tokens": ["Denn", "mir", "fiel", "die\u00b7ses", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "-+---+", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "Wann nun der Jahre Quell, der Herr der Zeit,", "tokens": ["Wann", "nun", "der", "Jah\u00b7re", "Quell", ",", "der", "Herr", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Meinigen und mir vielleicht in diesem Leben", "tokens": ["Den", "Mei\u00b7ni\u00b7gen", "und", "mir", "viel\u00b7leicht", "in", "die\u00b7sem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Nur einen kurtzen Gang gegeben,", "tokens": ["Nur", "ei\u00b7nen", "kurt\u00b7zen", "Gang", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und etwa mir insonderheit", "tokens": ["Und", "et\u00b7wa", "mir", "in\u00b7son\u00b7der\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kein langes Wandern mehr beschieden;", "tokens": ["Kein", "lan\u00b7ges", "Wan\u00b7dern", "mehr", "be\u00b7schie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So bin ich hertzlich wohl damit zufrieden,", "tokens": ["So", "bin", "ich", "hertz\u00b7lich", "wohl", "da\u00b7mit", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADV", "PAV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und scheide, sonder Gram, wills Gott, aus dieser Welt,", "tokens": ["Und", "schei\u00b7de", ",", "son\u00b7der", "Gram", ",", "wills", "Gott", ",", "aus", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "NN", "$,", "VMFIN", "NN", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nicht darum, weil ich mu\u00df, nein, weil es Gott gef\u00e4llt.", "tokens": ["Nicht", "da\u00b7rum", ",", "weil", "ich", "mu\u00df", ",", "nein", ",", "weil", "es", "Gott", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PAV", "$,", "KOUS", "PPER", "VMFIN", "$,", "PTKANT", "$,", "KOUS", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}