{"textgrid.poem.53967": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Oller Mann", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein alter Mann ist stets ein fremder Mann.", "tokens": ["Ein", "al\u00b7ter", "Mann", "ist", "stets", "ein", "frem\u00b7der", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er spricht von alten, l\u00e4ngst vergangenen Zeiten,", "tokens": ["Er", "spricht", "von", "al\u00b7ten", ",", "l\u00e4ngst", "ver\u00b7gan\u00b7ge\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "von Toten und verschollenen Begebenheiten . . .", "tokens": ["von", "To\u00b7ten", "und", "ver\u00b7schol\u00b7le\u00b7nen", "Be\u00b7ge\u00b7ben\u00b7hei\u00b7ten", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir denken: \u00bbWas geht uns das an \u2013?\u00ab", "tokens": ["Wir", "den\u00b7ken", ":", "\u00bb", "Was", "geht", "uns", "das", "an", "\u2013", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PWS", "VVFIN", "PPER", "PDS", "PTKVZ", "$(", "$.", "$("], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "In unser Zeitdorf ist er zugereist.", "tokens": ["In", "un\u00b7ser", "Zeit\u00b7dorf", "ist", "er", "zu\u00b7ge\u00b7reist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Stammt aber aus ganz andern Jahresl\u00e4ndern,", "tokens": ["Stammt", "a\u00b7ber", "aus", "ganz", "an\u00b7dern", "Jah\u00b7res\u00b7l\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mit andern Leuten, andern Taggew\u00e4ndern,", "tokens": ["mit", "an\u00b7dern", "Leu\u00b7ten", ",", "an\u00b7dern", "Tag\u00b7ge\u00b7w\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "von denen du nichts wei\u00dft.", "tokens": ["von", "de\u00b7nen", "du", "nichts", "wei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Sein Geist nimmt das f\u00fcr eine ganze Welt,", "tokens": ["Sein", "Geist", "nimmt", "das", "f\u00fcr", "ei\u00b7ne", "gan\u00b7ze", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PDS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "was ihn umgab, als seine S\u00e4fte rannen;", "tokens": ["was", "ihn", "um\u00b7gab", ",", "als", "sei\u00b7ne", "S\u00e4f\u00b7te", "ran\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wenn er an Liebe denkt, denkt er an die, die l\u00e4ngst von dannen.", "tokens": ["wenn", "er", "an", "Lie\u00b7be", "denkt", ",", "denkt", "er", "an", "die", ",", "die", "l\u00e4ngst", "von", "dan\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,", "VVFIN", "PPER", "APPR", "ART", "$,", "PRELS", "ADV", "APPR", "ADV", "$."], "meter": "+--+--+-+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "F\u00fcr uns ist er kein Held.", "tokens": ["F\u00fcr", "uns", "ist", "er", "kein", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Ein alter Held ist nur ein alter Mann.", "tokens": ["Ein", "al\u00b7ter", "Held", "ist", "nur", "ein", "al\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie uns die Jahre trennen \u2013!", "tokens": ["Wie", "uns", "die", "Jah\u00b7re", "tren\u00b7nen", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Erfahrung war umsonst. Die Menschen starten f\u00fcr das Rennen,", "tokens": ["Er\u00b7fah\u00b7rung", "war", "um\u00b7sonst", ".", "Die", "Men\u00b7schen", "star\u00b7ten", "f\u00fcr", "das", "Ren\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "$.", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "und jeder f\u00e4ngt f\u00fcr sich von vorne an.", "tokens": ["und", "je\u00b7der", "f\u00e4ngt", "f\u00fcr", "sich", "von", "vor\u00b7ne", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PRF", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "F\u00fcr uns ist er ein Mann von irgendwo.", "tokens": ["F\u00fcr", "uns", "ist", "er", "ein", "Mann", "von", "ir\u00b7gend\u00b7wo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "ART", "NN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihm fehlt sein Zeitland, wo die Seinen waren,", "tokens": ["Ihm", "fehlt", "sein", "Zeit\u00b7land", ",", "wo", "die", "Sei\u00b7nen", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PWAV", "ART", "PPOSS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "er spricht nicht unsre Sprache, hat ein fremd Gebaren . . .", "tokens": ["er", "spricht", "nicht", "uns\u00b7re", "Spra\u00b7che", ",", "hat", "ein", "fremd", "Ge\u00b7ba\u00b7ren", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,", "VAFIN", "ART", "ADJD", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wenn wir einmal alt sind und bei Jahren \u2013:", "tokens": ["Und", "wenn", "wir", "ein\u00b7mal", "alt", "sind", "und", "bei", "Jah\u00b7ren", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "KON", "APPR", "NN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "dann sind wir grade so.", "tokens": ["dann", "sind", "wir", "gra\u00b7de", "so", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}