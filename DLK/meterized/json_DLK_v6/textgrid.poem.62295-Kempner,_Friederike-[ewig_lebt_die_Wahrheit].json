{"textgrid.poem.62295": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "[ewig lebt die Wahrheit]", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ewig lebt die Wahrheit,", "tokens": ["E\u00b7wig", "lebt", "die", "Wahr\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ewig lebt das Recht,", "tokens": ["E\u00b7wig", "lebt", "das", "Recht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Menschlichkeit ist Klarheit,", "tokens": ["Menschlich\u00b7keit", "ist", "Klar\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Hassen, das ist schlecht!", "tokens": ["Has\u00b7sen", ",", "das", "ist", "schlecht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDS", "VAFIN", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Antisemitismus,", "tokens": ["An\u00b7ti\u00b7se\u00b7mi\u00b7tis\u00b7mus", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Aufgew\u00fchltes Meer,", "tokens": ["Auf\u00b7ge\u00b7w\u00fchl\u00b7tes", "Meer", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Neueste Influenza,", "tokens": ["Neu\u00b7es\u00b7te", "In\u00b7flu\u00b7en\u00b7za", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dauerst mich gar sehr;", "tokens": ["Dau\u00b7erst", "mich", "gar", "sehr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Antisemitismus", "tokens": ["An\u00b7ti\u00b7se\u00b7mi\u00b7tis\u00b7mus"], "token_info": ["word"], "pos": ["NE"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Antibr\u00fcderlich,", "tokens": ["An\u00b7ti\u00b7br\u00fc\u00b7der\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Senk' die morsche Fahne,", "tokens": ["Senk'", "die", "mor\u00b7sche", "Fah\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sie wird l\u00e4cherlich.", "tokens": ["Sie", "wird", "l\u00e4\u00b7cher\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Antisemitismus,", "tokens": ["An\u00b7ti\u00b7se\u00b7mi\u00b7tis\u00b7mus", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wi\u00dft ihr, wie das klingt?", "tokens": ["Wi\u00dft", "ihr", ",", "wie", "das", "klingt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "PDS", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Als wenn unter Psalmen", "tokens": ["Als", "wenn", "un\u00b7ter", "Psal\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einen Fluch man singt;", "tokens": ["Ei\u00b7nen", "Fluch", "man", "singt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Psalmen sind semitisch,", "tokens": ["Psal\u00b7men", "sind", "se\u00b7mi\u00b7tisch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Zehn Gebote auch,", "tokens": ["Zehn", "Ge\u00b7bo\u00b7te", "auch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Sch\u00f6ne Sonntagsfeier", "tokens": ["Sch\u00f6\u00b7ne", "Sonn\u00b7tags\u00b7fei\u00b7er"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ursemitischer Brauch;", "tokens": ["Ur\u00b7se\u00b7mi\u00b7ti\u00b7scher", "Brauch", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Doch die Heuchler t\u00e4uschen", "tokens": ["Doch", "die", "Heuch\u00b7ler", "t\u00e4u\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Absichtlich die Welt,", "tokens": ["Ab\u00b7sicht\u00b7lich", "die", "Welt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Meinen nicht Semiten,", "tokens": ["Mei\u00b7nen", "nicht", "Se\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Meinen nur ihr Geld.", "tokens": ["Mei\u00b7nen", "nur", "ihr", "Geld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Wenn sie vieles h\u00e4tten,", "tokens": ["Wenn", "sie", "vie\u00b7les", "h\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "G\u00e4ben sie's dem Zar,", "tokens": ["G\u00e4\u00b7ben", "sie's", "dem", "Zar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Kauften sich Gatschina", "tokens": ["Kauf\u00b7ten", "sich", "Gat\u00b7schi\u00b7na"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PRF", "NE"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Sch\u00f6n und wunderbar;", "tokens": ["Sch\u00f6n", "und", "wun\u00b7der\u00b7bar", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "S\u00e4ulen gro\u00df und m\u00e4chtig,", "tokens": ["S\u00e4u\u00b7len", "gro\u00df", "und", "m\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lapis Lazuli,", "tokens": ["La\u00b7pis", "La\u00b7zu\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Dunkelblau und pr\u00e4chtig,", "tokens": ["Dun\u00b7kel\u00b7blau", "und", "pr\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sie erkaufen's nie;", "tokens": ["Sie", "er\u00b7kau\u00b7fen's", "nie", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Ihren Reichtum aber,", "tokens": ["Ih\u00b7ren", "Reich\u00b7tum", "a\u00b7ber", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schlauheit ihn erdacht,", "tokens": ["Schlau\u00b7heit", "ihn", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ha\u00df und Zwietracht haben", "tokens": ["Ha\u00df", "und", "Zwiet\u00b7racht", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VAFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wahrheit nie gebracht;", "tokens": ["Wahr\u00b7heit", "nie", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Wen'ge ausgenommen,", "tokens": ["Wen'\u00b7ge", "aus\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Darben sie gar sehr,", "tokens": ["Dar\u00b7ben", "sie", "gar", "sehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Tausende verk\u00fcmmern,", "tokens": ["Tau\u00b7sen\u00b7de", "ver\u00b7k\u00fcm\u00b7mern", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Eilen \u00fcbers Meer.", "tokens": ["Ei\u00b7len", "\u00fc\u00b7bers", "Meer", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Nahrung dort zu suchen,", "tokens": ["Nah\u00b7rung", "dort", "zu", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo noch nichts ges\u00e4et,", "tokens": ["Wo", "noch", "nichts", "ge\u00b7s\u00e4et", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Kehren gern zur\u00fccke,", "tokens": ["Keh\u00b7ren", "gern", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wo die Heimat stehet;", "tokens": ["Wo", "die", "Hei\u00b7mat", "ste\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Heimat leere St\u00e4dte,", "tokens": ["Hei\u00b7mat", "lee\u00b7re", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo der Vater stand,", "tokens": ["Wo", "der", "Va\u00b7ter", "stand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Eh' er Blut und Leben", "tokens": ["Eh'", "er", "Blut", "und", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gab f\u00fcrs Vaterland;", "tokens": ["Gab", "f\u00fcrs", "Va\u00b7ter\u00b7land", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Ewig lebt die Wahrheit,", "tokens": ["E\u00b7wig", "lebt", "die", "Wahr\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ewig lebt das Recht,", "tokens": ["E\u00b7wig", "lebt", "das", "Recht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Menschlichkeit ist Klarheit,", "tokens": ["Menschlich\u00b7keit", "ist", "Klar\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Hassen, das ist schlecht!", "tokens": ["Has\u00b7sen", ",", "das", "ist", "schlecht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDS", "VAFIN", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Anti-ti-semiten,", "tokens": ["An\u00b7ti\u00b7ti\u00b7se\u00b7mi\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00f6ret meinen Rat,", "tokens": ["H\u00f6\u00b7ret", "mei\u00b7nen", "Rat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Heilet eure Leber,", "tokens": ["Hei\u00b7let", "eu\u00b7re", "Le\u00b7ber", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gehet nach Karlsbad!", "tokens": ["Ge\u00b7het", "nach", "Karls\u00b7bad", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.15": {"line.1": {"text": "Bad- und Reisekosten", "tokens": ["Ba\u00b7d", "und", "Rei\u00b7se\u00b7kos\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["TRUNC", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zahlet sicher Der,", "tokens": ["Zah\u00b7let", "si\u00b7cher", "Der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Der Euch sonst bezahlet,", "tokens": ["Der", "Euch", "sonst", "be\u00b7zah\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Doch \u2013 ich wei\u00df nicht Wer! \u2013", "tokens": ["Doch", "\u2013", "ich", "wei\u00df", "nicht", "Wer", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$(", "PPER", "VVFIN", "PTKNEG", "PWS", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}