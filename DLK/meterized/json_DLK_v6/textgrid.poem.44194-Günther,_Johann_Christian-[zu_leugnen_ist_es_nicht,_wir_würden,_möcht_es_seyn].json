{"textgrid.poem.44194": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[zu leugnen ist es nicht, wir w\u00fcrden, m\u00f6cht es seyn]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu leugnen ist es nicht, wir w\u00fcrden, m\u00f6cht es seyn,", "tokens": ["Zu", "leug\u00b7nen", "ist", "es", "nicht", ",", "wir", "w\u00fcr\u00b7den", ",", "m\u00f6cht", "es", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "PPER", "PTKNEG", "$,", "PPER", "VAFIN", "$,", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch ohne Schimpf gesagt, des Arztes gern entbehren;", "tokens": ["Doch", "oh\u00b7ne", "Schimpf", "ge\u00b7sagt", ",", "des", "Arz\u00b7tes", "gern", "ent\u00b7beh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "$,", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch sezen wir voraus, wenn nehmlich Fleisch und Bein", "tokens": ["Doch", "se\u00b7zen", "wir", "vo\u00b7raus", ",", "wenn", "nehm\u00b7lich", "Fleisch", "und", "Bein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein angesteckter Zeug von Adams Ribbe w\u00e4ren.", "tokens": ["Kein", "an\u00b7ge\u00b7steck\u00b7ter", "Zeug", "von", "A\u00b7dams", "Rib\u00b7be", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "NE", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein nachdem das Gift der ungesunden Frucht,", "tokens": ["Al\u00b7lein", "nach\u00b7dem", "das", "Gift", "der", "un\u00b7ge\u00b7sun\u00b7den", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ein vernaschtes Weib und wir durch sie verschlungen,", "tokens": ["Die", "ein", "ver\u00b7naschtes", "Weib", "und", "wir", "durch", "sie", "ver\u00b7schlun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "KON", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.7": {"text": "Noch t\u00e4glich jiehrt und w\u00fcrckt, so bleiben wir gezwungen,", "tokens": ["Noch", "t\u00e4g\u00b7lich", "jiehrt", "und", "w\u00fcrckt", ",", "so", "blei\u00b7ben", "wir", "ge\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "KON", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Finger anzuflehn, der Puls und Hize sucht,", "tokens": ["Den", "Fin\u00b7ger", "an\u00b7zu\u00b7flehn", ",", "der", "Puls", "und", "Hi\u00b7ze", "sucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und m\u00fc\u00dfen, sind wir gleich auch G\u00f6tter dieser Erden,", "tokens": ["Und", "m\u00fc\u00b7\u00dfen", ",", "sind", "wir", "gleich", "auch", "G\u00f6t\u00b7ter", "die\u00b7ser", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "VAFIN", "PPER", "ADV", "ADV", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Reiche des Galens zu Unterthanen werden.", "tokens": ["Im", "Rei\u00b7che", "des", "Ga\u00b7lens", "zu", "Un\u00b7ter\u00b7tha\u00b7nen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "ART", "NN", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der Apfel war verzehrt, der Tod kam in die Welt,", "tokens": ["Der", "Ap\u00b7fel", "war", "ver\u00b7zehrt", ",", "der", "Tod", "kam", "in", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Leute wuchsen schnell, die Seuchen noch geschwinder;", "tokens": ["Die", "Leu\u00b7te", "wuch\u00b7sen", "schnell", ",", "die", "Seu\u00b7chen", "noch", "ge\u00b7schwin\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So weit die Sonne steigt, so weit die Sonne f\u00e4llt,", "tokens": ["So", "weit", "die", "Son\u00b7ne", "steigt", ",", "so", "weit", "die", "Son\u00b7ne", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "VVFIN", "$,", "ADV", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ergrifen Brand und Pest die halbverzagten S\u00fcnder;", "tokens": ["Er\u00b7gri\u00b7fen", "Brand", "und", "Pest", "die", "halb\u00b7ver\u00b7zag\u00b7ten", "S\u00fcn\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dem faulten Lung und Milz, dem schwollen Hals und Leib,", "tokens": ["Dem", "faul\u00b7ten", "Lung", "und", "Milz", ",", "dem", "schwol\u00b7len", "Hals", "und", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,", "ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den warf der blaue Schlag, der schwand an Fu\u00df und H\u00e4nden,", "tokens": ["Den", "warf", "der", "blau\u00b7e", "Schlag", ",", "der", "schwand", "an", "Fu\u00df", "und", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der schnappte nach der Luft, den z\u00fcchtigten die Lenden,", "tokens": ["Der", "schnapp\u00b7te", "nach", "der", "Luft", ",", "den", "z\u00fcch\u00b7tig\u00b7ten", "die", "Len\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "ADJA", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dort w\u00e4lzte sich ein Kind, dort kri\u00df ein m\u00fcdes Weib,", "tokens": ["Dort", "w\u00e4lz\u00b7te", "sich", "ein", "Kind", ",", "dort", "kri\u00df", "ein", "m\u00fc\u00b7des", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und wo man h\u00f6rt und sah, da h\u00f6rt und sah man Heulen,", "tokens": ["Und", "wo", "man", "h\u00f6rt", "und", "sah", ",", "da", "h\u00f6rt", "und", "sah", "man", "Heu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "VVFIN", "KON", "VVFIN", "$,", "ADV", "VVFIN", "KON", "VVFIN", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Blut, Blattern, Geifer, Schaum, Schleim, Eiter, Koth und Beulen.", "tokens": ["Blut", ",", "Blat\u00b7tern", ",", "Gei\u00b7fer", ",", "Schaum", ",", "Schleim", ",", "Ei\u00b7ter", ",", "Koth", "und", "Beu\u00b7len", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Erbarmung aus der H\u00f6h, du sahst das Elend an,", "tokens": ["Er\u00b7bar\u00b7mung", "aus", "der", "H\u00f6h", ",", "du", "sahst", "das", "E\u00b7lend", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du sahst es nicht allein, du nahmst es auch zu Herzen,", "tokens": ["Du", "sahst", "es", "nicht", "al\u00b7lein", ",", "du", "nahmst", "es", "auch", "zu", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$,", "PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Mitleid ward erweckt, der Himmel aufgethan,", "tokens": ["Dein", "Mit\u00b7leid", "ward", "er\u00b7weckt", ",", "der", "Him\u00b7mel", "auf\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sieh, da kam ein Trost der allgemeinen Schmerzen:", "tokens": ["Und", "sieh", ",", "da", "kam", "ein", "Trost", "der", "all\u00b7ge\u00b7mei\u00b7nen", "Schmer\u00b7zen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erfahrung und Vernunft, die Bothen deiner Gunst,", "tokens": ["Er\u00b7fah\u00b7rung", "und", "Ver\u00b7nunft", ",", "die", "Bo\u00b7then", "dei\u00b7ner", "Gunst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Verschworen sich bey dir vor unser Heil zusammen;", "tokens": ["Ver\u00b7schwo\u00b7ren", "sich", "bey", "dir", "vor", "un\u00b7ser", "Heil", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da wich das \u00dcbel aus, da legten sich die Flammen", "tokens": ["Da", "wich", "das", "\u00dc\u00b7bel", "aus", ",", "da", "leg\u00b7ten", "sich", "die", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der k\u00fczelnden Geschwulst; da stieg Hygeens Kunst", "tokens": ["Der", "k\u00fc\u00b7zeln\u00b7den", "Ge\u00b7schwulst", ";", "da", "stieg", "Hy\u00b7ge\u00b7ens", "Kunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ADV", "VVFIN", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Auf ihren Ehrenstuhl und fing uns an zu lehren,", "tokens": ["Auf", "ih\u00b7ren", "Eh\u00b7ren\u00b7stuhl", "und", "fing", "uns", "an", "zu", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wodurch man f\u00e4hig sey, der Feinde Macht zu st\u00f6ren.", "tokens": ["Wo\u00b7durch", "man", "f\u00e4\u00b7hig", "sey", ",", "der", "Fein\u00b7de", "Macht", "zu", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "VAFIN", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie gl\u00fccklich ist der Mann, der hier ein Sch\u00fcler heist", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", "der", "Mann", ",", "der", "hier", "ein", "Sch\u00fc\u00b7ler", "heist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wieder Tod und Gift die Wafen brauchen lernet;", "tokens": ["Und", "wie\u00b7der", "Tod", "und", "Gift", "die", "Wa\u00b7fen", "brau\u00b7chen", "ler\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "KON", "NN", "ART", "NN", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Alter wird sein Lohn, er \u00fcbt den klugen Geist", "tokens": ["Das", "Al\u00b7ter", "wird", "sein", "Lohn", ",", "er", "\u00fcbt", "den", "klu\u00b7gen", "Geist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An Dingen, welchen sich des P\u00f6bels Aug entfernet.", "tokens": ["An", "Din\u00b7gen", ",", "wel\u00b7chen", "sich", "des", "P\u00f6\u00b7bels", "Aug", "ent\u00b7fer\u00b7net", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAT", "PRF", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihm m\u00fc\u00dfen Thier und Kraut getreue Diener seyn,", "tokens": ["Ihm", "m\u00fc\u00b7\u00dfen", "Thier", "und", "Kraut", "ge\u00b7treu\u00b7e", "Die\u00b7ner", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "KON", "NN", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er kennt der Seelen Haus, das k\u00fcnstlichste Geb\u00e4ude,", "tokens": ["Er", "kennt", "der", "See\u00b7len", "Haus", ",", "das", "k\u00fcnst\u00b7lichs\u00b7te", "Ge\u00b7b\u00e4u\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es ist kein Berg so gro\u00df, er sucht sein Eingeweide", "tokens": ["Es", "ist", "kein", "Berg", "so", "gro\u00df", ",", "er", "sucht", "sein", "Ein\u00b7ge\u00b7wei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und steiget der Natur in alle Kammern ein;", "tokens": ["Und", "stei\u00b7get", "der", "Na\u00b7tur", "in", "al\u00b7le", "Kam\u00b7mern", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da kan sie nichts so tief und nichts so hoch verstecken,", "tokens": ["Da", "kan", "sie", "nichts", "so", "tief", "und", "nichts", "so", "hoch", "ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "ADV", "ADJD", "KON", "PIS", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sein Einsehn weis es doch den Sinnen zu entdecken.", "tokens": ["Sein", "Ein\u00b7sehn", "weis", "es", "doch", "den", "Sin\u00b7nen", "zu", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "PPER", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Was schenckt ihm nicht sein Amt vor Vortheil und vor Lust.", "tokens": ["Was", "schenckt", "ihm", "nicht", "sein", "Amt", "vor", "Vor\u00b7theil", "und", "vor", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Krancken hei\u00dfen ihn als ihren Gott willkommen;", "tokens": ["Die", "Kran\u00b7cken", "hei\u00b7\u00dfen", "ihn", "als", "ih\u00b7ren", "Gott", "will\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KOUS", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es bleibt ihm nichts geheim; oft wird er in die Brust,", "tokens": ["Es", "bleibt", "ihm", "nichts", "ge\u00b7heim", ";", "oft", "wird", "er", "in", "die", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADJD", "$.", "ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An der er vor geheilt, zum Liebsten eingenommen.", "tokens": ["An", "der", "er", "vor", "ge\u00b7heilt", ",", "zum", "Liebs\u00b7ten", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "VVPP", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die M\u00fctter traun ihm stets ihr sch\u00f6n- und bla\u00dfes Kind,", "tokens": ["Die", "M\u00fct\u00b7ter", "traun", "ihm", "stets", "ihr", "sch\u00f6n", "und", "bla\u00b7\u00dfes", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "PPOSAT", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Armen bethen ihn zu einem reichen Manne,", "tokens": ["Die", "Ar\u00b7men", "be\u00b7then", "ihn", "zu", "ei\u00b7nem", "rei\u00b7chen", "Man\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bey Reichen strahlt sein Lohn in einer Nectarkanne,", "tokens": ["Bey", "Rei\u00b7chen", "strahlt", "sein", "Lohn", "in", "ei\u00b7ner", "Nec\u00b7tar\u00b7kan\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und F\u00fcrsten sind bey ihm, was andre Menschen sind;", "tokens": ["Und", "F\u00fcrs\u00b7ten", "sind", "bey", "ihm", ",", "was", "and\u00b7re", "Men\u00b7schen", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "APPR", "PPER", "$,", "PWS", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Und schreibt ihn Nabal gleich nicht allemahl zum Erben,", "tokens": ["Und", "schreibt", "ihn", "Na\u00b7bal", "gleich", "nicht", "al\u00b7le\u00b7mahl", "zum", "Er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NE", "ADV", "PTKNEG", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So hat er dies von ihm: Er lernt getroster sterben.", "tokens": ["So", "hat", "er", "dies", "von", "ihm", ":", "Er", "lernt", "ge\u00b7tros\u00b7ter", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "APPR", "PPER", "$.", "PPER", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ha, ha, gedenckt ein Thor, der nichts von Arbeit liebt,", "tokens": ["Ha", ",", "ha", ",", "ge\u00b7denckt", "ein", "Thor", ",", "der", "nichts", "von", "Ar\u00b7beit", "liebt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ITJ", "$,", "VVFIN", "ART", "NN", "$,", "PRELS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ists so ein k\u00f6stlich Ding um Meditrinens Gl\u00fccke?", "tokens": ["Ists", "so", "ein", "k\u00f6st\u00b7lich", "Ding", "um", "Me\u00b7di\u00b7tri\u00b7nens", "Gl\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nun weis ich, was mir Brodt und faule Tage giebt,", "tokens": ["Nun", "weis", "ich", ",", "was", "mir", "Brodt", "und", "fau\u00b7le", "Ta\u00b7ge", "giebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PPER", "$,", "PWS", "PPER", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Worzu ich mich vorwahr am allerbesten schicke.", "tokens": ["Wor\u00b7zu", "ich", "mich", "vor\u00b7wahr", "am", "al\u00b7ler\u00b7bes\u00b7ten", "schi\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADJD", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie bald begreift man nicht die Pillendrechslerey:", "tokens": ["Wie", "bald", "be\u00b7greift", "man", "nicht", "die", "Pil\u00b7len\u00b7drechs\u00b7le\u00b7rey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PIS", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier liegt mein Theophrast, da steht der ganze Plunder,", "tokens": ["Hier", "liegt", "mein", "Theo\u00b7ph\u00b7rast", ",", "da", "steht", "der", "gan\u00b7ze", "Plun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Glas voll Ofenru\u00df, ein L\u00e4pchen Hemdezunder,", "tokens": ["Ein", "Glas", "voll", "O\u00b7fen\u00b7ru\u00df", ",", "ein", "L\u00e4p\u00b7chen", "Hem\u00b7de\u00b7zun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein goldnes Polychrest, ein Perlentranck vom Ey,", "tokens": ["Ein", "gold\u00b7nes", "Po\u00b7ly\u00b7chrest", ",", "ein", "Per\u00b7len\u00b7tranck", "vom", "Ey", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Pfund Verwegenheit, ein glattes Maul voll L\u00fcgen,", "tokens": ["Ein", "Pfund", "Ver\u00b7we\u00b7gen\u00b7heit", ",", "ein", "glat\u00b7tes", "Maul", "voll", "L\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das ist ein gut Recept, die Einfalt zu betriegen.", "tokens": ["Das", "ist", "ein", "gut", "Re\u00b7cept", ",", "die", "Ein\u00b7falt", "zu", "be\u00b7trie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Gekleckt ist nicht gemahlt; du blinder Davus, schweig!", "tokens": ["Ge\u00b7kleckt", "ist", "nicht", "ge\u00b7mahlt", ";", "du", "blin\u00b7der", "Da\u00b7vus", ",", "schweig", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "VAFIN", "PTKNEG", "VVPP", "$.", "PPER", "ADJA", "NE", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Pfuscher haben nichts als Fluch und Schimpf zu hofen,", "tokens": ["Die", "Pfu\u00b7scher", "ha\u00b7ben", "nichts", "als", "Fluch", "und", "Schimpf", "zu", "ho\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "KOKOM", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht einer \u00fcberk\u00f6mmt Hygeens Ehrenzweig,", "tokens": ["Nicht", "ei\u00b7ner", "\u00fc\u00b7ber\u00b7k\u00f6mmt", "Hy\u00b7ge\u00b7ens", "Eh\u00b7ren\u00b7zweig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VVFIN", "NE", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wofern er nicht bereits den rechten Zweck getrofen.", "tokens": ["Wo\u00b7fern", "er", "nicht", "be\u00b7reits", "den", "rech\u00b7ten", "Zweck", "ge\u00b7tro\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was braucht es viel Beweis? Gelehrt- und edler Freund,", "tokens": ["Was", "braucht", "es", "viel", "Be\u00b7weis", "?", "Ge\u00b7lehr\u00b7t", "und", "ed\u00b7ler", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PIAT", "NN", "$.", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Dein Beyspiel unterschreibt und l\u00e4st uns jezt erfahren,", "tokens": ["Dein", "Bey\u00b7spiel", "un\u00b7ter\u00b7schreibt", "und", "l\u00e4st", "uns", "jezt", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df schon Hippocrates vor zweymahl tausend Jahren", "tokens": ["Da\u00df", "schon", "Hip\u00b7po\u00b7cra\u00b7tes", "vor", "zwey\u00b7mahl", "tau\u00b7send", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "APPR", "ADV", "CARD", "NN"], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Dich, den er nicht gesehn, durch diesen Spruch gemeint:", "tokens": ["Dich", ",", "den", "er", "nicht", "ge\u00b7sehn", ",", "durch", "die\u00b7sen", "Spruch", "ge\u00b7meint", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "PTKNEG", "VVPP", "$,", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es k\u00f6nne sich ein Arzt, o las die Misgunst lachen,", "tokens": ["Es", "k\u00f6n\u00b7ne", "sich", "ein", "Arzt", ",", "o", "las", "die", "Mis\u00b7gunst", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ART", "NN", "$,", "FM", "FM", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So bald er Wei\u00dfheit liebt, den G\u00f6ttern \u00e4hnlich machen.", "tokens": ["So", "bald", "er", "Wei\u00df\u00b7heit", "liebt", ",", "den", "G\u00f6t\u00b7tern", "\u00e4hn\u00b7lich", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Dies Lob ist dir genug; denn Warheit schwazt nicht viel.", "tokens": ["Dies", "Lob", "ist", "dir", "ge\u00b7nug", ";", "denn", "War\u00b7heit", "schwazt", "nicht", "viel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PPER", "ADV", "$.", "KON", "NN", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Saal' erkennt es wohl und l\u00e4st dich heute steigen,", "tokens": ["Die", "Saal'", "er\u00b7kennt", "es", "wohl", "und", "l\u00e4st", "dich", "heu\u00b7te", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Morbona steht in Furcht, die Parzen sehn ihr Ziel", "tokens": ["Mor\u00b7bo\u00b7na", "steht", "in", "Furcht", ",", "die", "Par\u00b7zen", "sehn", "ihr", "Ziel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NN", "$,", "ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und halten dich vor starck, ihr altes Recht zu beugen.", "tokens": ["Und", "hal\u00b7ten", "dich", "vor", "starck", ",", "ihr", "al\u00b7tes", "Recht", "zu", "beu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$,", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dies ist, was unter uns ein jeder w\u00fcntscht und glaubt.", "tokens": ["Dies", "ist", ",", "was", "un\u00b7ter", "uns", "ein", "je\u00b7der", "w\u00fcnt\u00b7scht", "und", "glaubt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "APPR", "PPER", "ART", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Besuch und st\u00e4rcke nun der Schmachtenden Verlangen;", "tokens": ["Be\u00b7such", "und", "st\u00e4r\u00b7cke", "nun", "der", "Schmach\u00b7ten\u00b7den", "Ver\u00b7lan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Nuzen schleicht dir nach, die Ehre will dich fangen,", "tokens": ["Der", "Nu\u00b7zen", "schleicht", "dir", "nach", ",", "die", "Eh\u00b7re", "will", "dich", "fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Venus hat dir schon ein sch\u00f6nes Kind geraubt.", "tokens": ["Und", "Ve\u00b7nus", "hat", "dir", "schon", "ein", "sch\u00f6\u00b7nes", "Kind", "ge\u00b7raubt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bey Krancken schone dich, doch mehr bey den Gesunden,", "tokens": ["Bey", "Kran\u00b7cken", "scho\u00b7ne", "dich", ",", "doch", "mehr", "bey", "den", "Ge\u00b7sun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$,", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Bey welchen mancher Arzt sein s\u00fc\u00dfes Grab gefunden.", "tokens": ["Bey", "wel\u00b7chen", "man\u00b7cher", "Arzt", "sein", "s\u00fc\u00b7\u00dfes", "Grab", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PIAT", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}