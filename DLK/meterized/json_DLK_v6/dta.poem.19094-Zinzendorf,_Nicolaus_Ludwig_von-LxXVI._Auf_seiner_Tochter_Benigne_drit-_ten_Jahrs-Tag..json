{"dta.poem.19094": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "LxXVI.   Auf seiner Tochter Benigne drit-  \n ten Jahrs-Tag.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Auf, Benigna, liebes Kind!", "tokens": ["Auf", ",", "Be\u00b7nig\u00b7na", ",", "lie\u00b7bes", "Kind", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "$,", "NE", "$,", "ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "La\u00df dich JEsu nur geschwind:", "tokens": ["La\u00df", "dich", "Je\u00b7su", "nur", "ge\u00b7schwind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NE", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses ist der einge Rath,", "tokens": ["Die\u00b7ses", "ist", "der", "ein\u00b7ge", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df man meine Liebe hat.", "tokens": ["Da\u00df", "man", "mei\u00b7ne", "Lie\u00b7be", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Was mein Sinn gewesen ist,", "tokens": ["Was", "mein", "Sinn", "ge\u00b7we\u00b7sen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als du etwas worden bist,", "tokens": ["Als", "du", "et\u00b7was", "wor\u00b7den", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was deine Mutter trieb,", "tokens": ["Und", "was", "dei\u00b7ne", "Mut\u00b7ter", "trieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das ist uns noch immer lieb.", "tokens": ["Das", "ist", "uns", "noch", "im\u00b7mer", "lieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Jesus, JEsus nur allein", "tokens": ["Je\u00b7sus", ",", "Je\u00b7sus", "nur", "al\u00b7lein"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NE", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Soll und kan uns alles seyn:", "tokens": ["Soll", "und", "kan", "uns", "al\u00b7les", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "VMFIN", "PPER", "PIS", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In ihm liebet man ein Kind,", "tokens": ["In", "ihm", "lie\u00b7bet", "man", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PIS", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das uns ausser ihm verschwindt.", "tokens": ["Das", "uns", "aus\u00b7ser", "ihm", "ver\u00b7schwindt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bliebest du ein St\u00fcckgen Fleisch,", "tokens": ["Blie\u00b7best", "du", "ein", "St\u00fcck\u00b7gen", "Fleisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4ttest noch so viel Ger\u00e4usch,", "tokens": ["H\u00e4t\u00b7test", "noch", "so", "viel", "Ge\u00b7r\u00e4usch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Maul und Gaben, und Verstand,", "tokens": ["Maul", "und", "Ga\u00b7ben", ",", "und", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ohne Kraft; das hie\u00df ich Tand.", "tokens": ["Oh\u00b7ne", "Kraft", ";", "das", "hie\u00df", "ich", "Tand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "PDS", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was solt unvern\u00fcnft\u2019ger seyn;", "tokens": ["Was", "solt", "un\u00b7ver\u00b7n\u00fcnft'\u00b7ger", "seyn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als sich \u00fcber was erfreun,", "tokens": ["Als", "sich", "\u00fc\u00b7ber", "was", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPR", "PIS", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dessen uns in Ewigkeit", "tokens": ["Des\u00b7sen", "uns", "in", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor des Lammes Stuhl gereut?", "tokens": ["Vor", "des", "Lam\u00b7mes", "Stuhl", "ge\u00b7reut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "W\u00e4rst du aber lahm und krum,", "tokens": ["W\u00e4rst", "du", "a\u00b7ber", "lahm", "und", "krum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKVZ", "KON", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ubersichtig, taub und stumm,", "tokens": ["Ub\u00b7er\u00b7sich\u00b7tig", ",", "taub", "und", "stumm", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und giengst nur zum Leben ein;", "tokens": ["Und", "giengst", "nur", "zum", "Le\u00b7ben", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "O wie theur solt\u2019st du mir seyn!", "tokens": ["O", "wie", "theur", "solt'st", "du", "mir", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "ADV", "VMFIN", "PPER", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Nun, mein T\u00f6chtergen, wohlan!", "tokens": ["Nun", ",", "mein", "T\u00f6ch\u00b7ter\u00b7gen", ",", "wo\u00b7hlan", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gott hat viel an dir gethan;", "tokens": ["Gott", "hat", "viel", "an", "dir", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leib und Seele sind gantz fein:", "tokens": ["Leib", "und", "See\u00b7le", "sind", "gantz", "fein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie wirds mit dem Geiste seyn?", "tokens": ["Wie", "wirds", "mit", "dem", "Geis\u00b7te", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Unser Liebe seh' auf dich,", "tokens": ["Un\u00b7ser", "Lie\u00b7be", "seh'", "auf", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie sie pflegt, barmhertziglich,", "tokens": ["Wie", "sie", "pflegt", ",", "barm\u00b7hert\u00b7zig\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und als einen todten Mann", "tokens": ["Und", "als", "ei\u00b7nen", "tod\u00b7ten", "Mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nehm sie dich zur Wartung an!", "tokens": ["Nehm", "sie", "dich", "zur", "War\u00b7tung", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Mein und deiner Mutter Kraft", "tokens": ["Mein", "und", "dei\u00b7ner", "Mut\u00b7ter", "Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "KON", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat dir nichts voraus geschaft:", "tokens": ["Hat", "dir", "nichts", "vo\u00b7raus", "ge\u00b7schaft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Heissen andrer Kinder rein;", "tokens": ["Heis\u00b7sen", "an\u00b7drer", "Kin\u00b7der", "rein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So solst du ein S\u00fcnder seyn.", "tokens": ["So", "solst", "du", "ein", "S\u00fcn\u00b7der", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Jesus solls alleine thun,", "tokens": ["Je\u00b7sus", "solls", "al\u00b7lei\u00b7ne", "thun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jhm soll unsre Hofnung ruhn:", "tokens": ["Jhm", "soll", "uns\u00b7re", "Hof\u00b7nung", "ruhn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Jhm trauts unser Hertze zu,", "tokens": ["Jhm", "trauts", "un\u00b7ser", "Hert\u00b7ze", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er Treue an dir thu.", "tokens": ["Da\u00df", "er", "Treu\u00b7e", "an", "dir", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Di\u00df Jahr m\u00fcssest du verlohrn,", "tokens": ["Di\u00df", "Jahr", "m\u00fcs\u00b7sest", "du", "ver\u00b7lohrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dieses Jahr zur Gnad erkohrn,", "tokens": ["Die\u00b7ses", "Jahr", "zur", "Gnad", "er\u00b7kohrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und durchs Blut des Lammes rein,", "tokens": ["Und", "durchs", "Blut", "des", "Lam\u00b7mes", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und aus Geist gezeuget seyn.", "tokens": ["Und", "aus", "Geist", "ge\u00b7zeu\u00b7get", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}