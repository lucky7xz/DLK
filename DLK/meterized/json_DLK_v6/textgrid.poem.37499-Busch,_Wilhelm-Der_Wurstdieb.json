{"textgrid.poem.37499": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Der Wurstdieb", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hier h\u00e4ngt die Wurst \u2013 dort an der Mauer", "tokens": ["Hier", "h\u00e4ngt", "die", "Wurst", "\u2013", "dort", "an", "der", "Mau\u00b7er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Steht Louis heimlich auf der Lauer.", "tokens": ["Steht", "Lou\u00b7is", "heim\u00b7lich", "auf", "der", "Lau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und schon bemerkt man sein Bestreben,", "tokens": ["Und", "schon", "be\u00b7merkt", "man", "sein", "Be\u00b7stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich eine Wurst herauszuheben.", "tokens": ["Sich", "ei\u00b7ne", "Wurst", "her\u00b7aus\u00b7zu\u00b7he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Jetzt hat er sie und schleicht davon;", "tokens": ["Jetzt", "hat", "er", "sie", "und", "schleicht", "da\u00b7von", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "KON", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch Graps, der Hund, erblickt ihn schon.", "tokens": ["Doch", "Graps", ",", "der", "Hund", ",", "er\u00b7blickt", "ihn", "schon", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "NN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Eh' Louis denkt, da\u00df er ihn packe,", "tokens": ["Eh'", "Lou\u00b7is", "denkt", ",", "da\u00df", "er", "ihn", "pa\u00b7cke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Graps ihn hinten bei der Jacke.", "tokens": ["Hat", "Graps", "ihn", "hin\u00b7ten", "bei", "der", "Ja\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die zwei, die schaun sich ins Gesicht,", "tokens": ["Die", "zwei", ",", "die", "schaun", "sich", "ins", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "$,", "PRELS", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der eine froh, der andre nicht.", "tokens": ["Der", "ei\u00b7ne", "froh", ",", "der", "and\u00b7re", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "$,", "PRELS", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Graps aber tr\u00e4gt mit sanftem Schritte", "tokens": ["Graps", "a\u00b7ber", "tr\u00e4gt", "mit", "sanf\u00b7tem", "Schrit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wurst zu seiner stillen H\u00fctte.", "tokens": ["Die", "Wurst", "zu", "sei\u00b7ner", "stil\u00b7len", "H\u00fct\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Indessen Graps sich so erg\u00f6tzt,", "tokens": ["In\u00b7des\u00b7sen", "Graps", "sich", "so", "er\u00b7g\u00f6tzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Louis aufrecht sich gesetzt", "tokens": ["Hat", "Lou\u00b7is", "auf\u00b7recht", "sich", "ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NE", "VVFIN", "PRF", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und will ganz heimlich sich soeben", "tokens": ["Und", "will", "ganz", "heim\u00b7lich", "sich", "soe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "PRF", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Aus dieser Gegend fortbegeben.", "tokens": ["Aus", "die\u00b7ser", "Ge\u00b7gend", "fort\u00b7be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch Graps, der wachsam, zieht ihn wieder", "tokens": ["Doch", "Graps", ",", "der", "wach\u00b7sam", ",", "zieht", "ihn", "wie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$,", "PRELS", "ADJD", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit k\u00fchnem Griff nach hinten nieder.", "tokens": ["Mit", "k\u00fch\u00b7nem", "Griff", "nach", "hin\u00b7ten", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Er legt sich kl\u00fcglich auf die Spitze", "tokens": ["Er", "legt", "sich", "kl\u00fcg\u00b7lich", "auf", "die", "Spit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Louis seiner Zipfelm\u00fctze.", "tokens": ["Von", "Lou\u00b7is", "sei\u00b7ner", "Zip\u00b7fel\u00b7m\u00fct\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der treue Graps, der denkt sich: Nun", "tokens": ["Der", "treu\u00b7e", "Graps", ",", "der", "denkt", "sich", ":", "Nun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "PRF", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kann ich getrost ein wenig ruhn!", "tokens": ["Kann", "ich", "ge\u00b7trost", "ein", "we\u00b7nig", "ruhn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "ART", "PIS", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch Louis zog ganz in der Stille", "tokens": ["Doch", "Lou\u00b7is", "zog", "ganz", "in", "der", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Kopf aus seiner spitzen H\u00fclle", "tokens": ["Den", "Kopf", "aus", "sei\u00b7ner", "spit\u00b7zen", "H\u00fcl\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und w\u00e4re gl\u00fccklich fast entkommen,", "tokens": ["Und", "w\u00e4\u00b7re", "gl\u00fcck\u00b7lich", "fast", "ent\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4tt' ihn der Graps nicht festgenommen.", "tokens": ["H\u00e4tt'", "ihn", "der", "Graps", "nicht", "fest\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Er steht und darf sich nicht bewegen;", "tokens": ["Er", "steht", "und", "darf", "sich", "nicht", "be\u00b7we\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VMFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von oben str\u00f6mt ein k\u00fchler Regen.", "tokens": ["Von", "o\u00b7ben", "str\u00f6mt", "ein", "k\u00fch\u00b7ler", "Re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Der Regen wird zu kaltem Reif;", "tokens": ["Der", "Re\u00b7gen", "wird", "zu", "kal\u00b7tem", "Reif", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Louis friert ganz starr und steif.", "tokens": ["Der", "Lou\u00b7is", "friert", "ganz", "starr", "und", "steif", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Der gute Nachbar sah ihn stehn", "tokens": ["Der", "gu\u00b7te", "Nach\u00b7bar", "sah", "ihn", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und will mit ihm zum Ofen gehn.", "tokens": ["Und", "will", "mit", "ihm", "zum", "O\u00b7fen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Bauz! Klirr! \u2013 er stolpert an der Schwelle;", "tokens": ["Bauz", "!", "Klirr", "!", "\u2013", "er", "stol\u00b7pert", "an", "der", "Schwel\u00b7le", ";"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "$(", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Louis ist ein Eisger\u00f6lle.", "tokens": ["Der", "Lou\u00b7is", "ist", "ein", "Eis\u00b7ge\u00b7r\u00f6l\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Da nimmt der gute Nachbar schnell den Besen", "tokens": ["Da", "nimmt", "der", "gu\u00b7te", "Nach\u00b7bar", "schnell", "den", "Be\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und fegt hinaus, was Louis einst gewesen.", "tokens": ["Und", "fegt", "hin\u00b7aus", ",", "was", "Lou\u00b7is", "einst", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "PRELS", "NE", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}