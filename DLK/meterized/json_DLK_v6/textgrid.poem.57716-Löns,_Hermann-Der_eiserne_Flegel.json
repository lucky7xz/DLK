{"textgrid.poem.57716": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Der eiserne Flegel", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Damiett, Damiett, du feine Stadt,", "tokens": ["Da\u00b7miett", ",", "Da\u00b7miett", ",", "du", "fei\u00b7ne", "Stadt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der T\u00fcrke h\u00e4lt dich fest;", "tokens": ["Der", "T\u00fcr\u00b7ke", "h\u00e4lt", "dich", "fest", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir wurden m\u00fcde, wurden matt,", "tokens": ["Wir", "wur\u00b7den", "m\u00fc\u00b7de", ",", "wur\u00b7den", "matt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor dem verdammtigen Nest.", "tokens": ["Vor", "dem", "ver\u00b7damm\u00b7ti\u00b7gen", "Nest", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "Es flo\u00df das teure Christenblut", "tokens": ["Es", "flo\u00df", "das", "teu\u00b7re", "Chris\u00b7ten\u00b7blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Zinnen und Tor herab;", "tokens": ["Von", "Zin\u00b7nen", "und", "Tor", "her\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So mancher Christenmensch, treu und gut,", "tokens": ["So", "man\u00b7cher", "Chris\u00b7ten\u00b7mensch", ",", "treu", "und", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Fand vor Damiett sein Grab.", "tokens": ["Fand", "vor", "Da\u00b7miett", "sein", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "So manche Mutter im deutschen Land", "tokens": ["So", "man\u00b7che", "Mut\u00b7ter", "im", "deut\u00b7schen", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Augen unter sich schl\u00e4gt;", "tokens": ["Die", "Au\u00b7gen", "un\u00b7ter", "sich", "schl\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Es fiel der Spiegel von der Wand,", "tokens": ["Es", "fiel", "der", "Spie\u00b7gel", "von", "der", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Wurm in der Lade sich regt.", "tokens": ["Der", "Wurm", "in", "der", "La\u00b7de", "sich", "reg\u00b7t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PRF", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "So manches M\u00e4dchen im deutschen Land,", "tokens": ["So", "man\u00b7ches", "M\u00e4d\u00b7chen", "im", "deut\u00b7schen", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das weint sich die Augen rot;", "tokens": ["Das", "weint", "sich", "die", "Au\u00b7gen", "rot", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Rosmarin in Bl\u00fcte stand,", "tokens": ["Der", "Ros\u00b7ma\u00b7rin", "in", "Bl\u00fc\u00b7te", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und heute ist er tot.", "tokens": ["Und", "heu\u00b7te", "ist", "er", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Herr Hayo, der Friese, der blickte quer,", "tokens": ["Herr", "Ha\u00b7yo", ",", "der", "Frie\u00b7se", ",", "der", "blick\u00b7te", "quer", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Seine Faust zum Tische kracht;", "tokens": ["Sei\u00b7ne", "Faust", "zum", "Ti\u00b7sche", "kracht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbbei Christi Tod, ich leid's nicht mehr,", "tokens": ["\u00bb", "bei", "Chris\u00b7ti", "Tod", ",", "ich", "lei\u00b7d's", "nicht", "mehr", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NE", "NN", "$,", "PPER", "NE", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein Ende wird gemacht!\u00ab", "tokens": ["Ein", "En\u00b7de", "wird", "ge\u00b7macht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Er nahm den Dreschflegel von der Wand,", "tokens": ["Er", "nahm", "den", "Dresc\u00b7hfle\u00b7gel", "von", "der", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von Eisen war der gebaut;", "tokens": ["Von", "Ei\u00b7sen", "war", "der", "ge\u00b7baut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Er stieg bis auf der Mauer Rand,", "tokens": ["Er", "stieg", "bis", "auf", "der", "Mau\u00b7er", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sang so lustig und laut.", "tokens": ["Und", "sang", "so", "lus\u00b7tig", "und", "laut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "Er sang ein friesisches Drescherlied,", "tokens": ["Er", "sang", "ein", "frie\u00b7si\u00b7sches", "Dre\u00b7scher\u00b7lied", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er sang nicht gerade fein;", "tokens": ["Er", "sang", "nicht", "ge\u00b7ra\u00b7de", "fein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er sang den Heiden Furcht ins Gem\u00fct", "tokens": ["Er", "sang", "den", "Hei\u00b7den", "Furcht", "ins", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und Angst in die Hosen hinein.", "tokens": ["Und", "Angst", "in", "die", "Ho\u00b7sen", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.8": {"line.1": {"text": "Es klang sein Flegel die klapp, die klapp,", "tokens": ["Es", "klang", "sein", "Fle\u00b7gel", "die", "klapp", ",", "die", "klapp", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ART", "ADJD", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er drosch nach alter Art;", "tokens": ["Er", "drosch", "nach", "al\u00b7ter", "Art", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er drosch ihnen Arme und Beine ab,", "tokens": ["Er", "drosch", "ih\u00b7nen", "Ar\u00b7me", "und", "Bei\u00b7ne", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Er drosch nicht allzu zart.", "tokens": ["Er", "drosch", "nicht", "all\u00b7zu", "zart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Sie lie\u00dfen die Mauern, sie lie\u00dfen das Tor,", "tokens": ["Sie", "lie\u00b7\u00dfen", "die", "Mau\u00b7ern", ",", "sie", "lie\u00b7\u00dfen", "das", "Tor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sie lie\u00dfen die feine Stadt;", "tokens": ["Sie", "lie\u00b7\u00dfen", "die", "fei\u00b7ne", "Stadt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Es stieg das heilige Kreuz empor,", "tokens": ["Es", "stieg", "das", "hei\u00b7li\u00b7ge", "Kreuz", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wo der Halbmond gestanden hat.", "tokens": ["Wo", "der", "Halb\u00b7mond", "ge\u00b7stan\u00b7den", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "--++-+-+", "measure": "anapaest.init"}}, "stanza.10": {"line.1": {"text": "Herr Hayo lachte in seinen Bart", "tokens": ["Herr", "Ha\u00b7yo", "lach\u00b7te", "in", "sei\u00b7nen", "Bart"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und trank zw\u00f6lf Schoppen Wein,", "tokens": ["Und", "trank", "zw\u00f6lf", "Schop\u00b7pen", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "CARD", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und sprach: \u00bbGeht's nicht auf gute Art,", "tokens": ["Und", "sprach", ":", "\u00bb", "Geht's", "nicht", "auf", "gu\u00b7te", "Art", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NE", "PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So schlagt mit dem Dreschflegel drein.\u00ab", "tokens": ["So", "schlagt", "mit", "dem", "Dresc\u00b7hfle\u00b7gel", "drein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}}}}