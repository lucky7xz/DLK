{"textgrid.poem.34417": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "[ich bin rasiert und trage keine Locke]", "genre": "verse", "period": "N.A.", "pub_year": 1885, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin rasiert und trage keine Locke,", "tokens": ["Ich", "bin", "ra\u00b7siert", "und", "tra\u00b7ge", "kei\u00b7ne", "Lo\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "sogar die B\u00fcrste g\u00f6nn ich meinem Rocke.", "tokens": ["so\u00b7gar", "die", "B\u00fcrs\u00b7te", "g\u00f6nn", "ich", "mei\u00b7nem", "Ro\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich bin durchaus kein lyrischer Tenor,", "tokens": ["Ich", "bin", "durc\u00b7haus", "kein", "ly\u00b7ri\u00b7scher", "Te\u00b7nor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "nur was ich heiss durchlebt, trag ich euch vor.", "tokens": ["nur", "was", "ich", "heiss", "durch\u00b7lebt", ",", "trag", "ich", "euch", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPER", "ADJD", "VVPP", "$,", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Nicht zart allein ins schwelgende Gef\u00fchl", "tokens": ["Nicht", "zart", "al\u00b7lein", "ins", "schwel\u00b7gen\u00b7de", "Ge\u00b7f\u00fchl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "verlier ich mich \u2013 auch in der Welt Gew\u00fchl.", "tokens": ["ver\u00b7lier", "ich", "mich", "\u2013", "auch", "in", "der", "Welt", "Ge\u00b7w\u00fchl", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$(", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und seh das Sch\u00f6ne nicht und Edle nur,", "tokens": ["Und", "seh", "das", "Sch\u00f6\u00b7ne", "nicht", "und", "Ed\u00b7le", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "KON", "ADJA", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ich kenne der Gemeinheit breite Spur.", "tokens": ["ich", "ken\u00b7ne", "der", "Ge\u00b7mein\u00b7heit", "brei\u00b7te", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich seh den Schmutz am Lumpenrock des Sclaven,", "tokens": ["Ich", "seh", "den", "Schmutz", "am", "Lum\u00b7pen\u00b7rock", "des", "Scla\u00b7ven", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ich seh den Schmutz im Herzen manches Braven.", "tokens": ["ich", "seh", "den", "Schmutz", "im", "Her\u00b7zen", "man\u00b7ches", "Bra\u00b7ven", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und sprech es aus, was Kopf und Herz emp\u00f6rt,", "tokens": ["Und", "sprech", "es", "aus", ",", "was", "Kopf", "und", "Herz", "em\u00b7p\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "PWS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und freue mich, wenns euch die Ruhe st\u00f6rt.", "tokens": ["und", "freu\u00b7e", "mich", ",", "wenns", "euch", "die", "Ru\u00b7he", "st\u00f6rt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und ob ihr Klugen auch mein Wollen h\u00f6hnt \u2013", "tokens": ["Und", "ob", "ihr", "Klu\u00b7gen", "auch", "mein", "Wol\u00b7len", "h\u00f6hnt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und ob ihr Frommen mich entsetzt verp\u00f6nt \u2013", "tokens": ["und", "ob", "ihr", "From\u00b7men", "mich", "ent\u00b7setzt", "ver\u00b7p\u00f6nt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PPER", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und ob ihr Zarten meine Worte flieht \u2013", "tokens": ["und", "ob", "ihr", "Zar\u00b7ten", "mei\u00b7ne", "Wor\u00b7te", "flieht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "hart ist das Leben, hart sei auch mein Lied!", "tokens": ["hart", "ist", "das", "Le\u00b7ben", ",", "hart", "sei", "auch", "mein", "Lied", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,", "ADJD", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}