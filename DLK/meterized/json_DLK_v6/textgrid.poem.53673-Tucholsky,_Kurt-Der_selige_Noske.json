{"textgrid.poem.53673": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der selige Noske", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist ja beinah Leichensch\u00e4ndung,", "tokens": ["Es", "ist", "ja", "bei\u00b7nah", "Lei\u00b7chen\u00b7sch\u00e4n\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wenn man dir, Gustav, eine klebt.", "tokens": ["wenn", "man", "dir", ",", "Gus\u00b7tav", ",", "ei\u00b7ne", "klebt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "$,", "NE", "$,", "ART", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du sprichst von deiner neuen Sendung . . .", "tokens": ["Du", "sprichst", "von", "dei\u00b7ner", "neu\u00b7en", "Sen\u00b7dung", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Eisner ist tot.", "tokens": ["Eis\u00b7ner", "ist", "tot", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Und sowas lebt.", "tokens": ["Und", "so\u00b7was", "lebt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Die H\u00e4nde in den Hosentaschen,", "tokens": ["Die", "H\u00e4n\u00b7de", "in", "den", "Ho\u00b7sen\u00b7ta\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "h\u00e4ltst du noch einmal Instruktion.", "tokens": ["h\u00e4ltst", "du", "noch", "ein\u00b7mal", "I\u00b7nstruk\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Hast du die Finger dir gewaschen?", "tokens": ["Hast", "du", "die", "Fin\u00b7ger", "dir", "ge\u00b7wa\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie sind noch rot . . . Du wei\u00dft, wovon.", "tokens": ["Sie", "sind", "noch", "rot", ".", ".", ".", "Du", "wei\u00dft", ",", "wo\u00b7von", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$.", "$.", "$.", "PPER", "VVFIN", "$,", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nochmal? Nach dieser Kapp-Blamage?", "tokens": ["Noch\u00b7mal", "?", "Nach", "die\u00b7ser", "Kapp\u00b7\u00b7Bla\u00b7ma\u00b7ge", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "PDAT", "NN", "$."], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Nochmal? Und wieder mit Hurra?", "tokens": ["Noch\u00b7mal", "?", "Und", "wie\u00b7der", "mit", "Hur\u00b7ra", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Unteroffiziersvisage", "tokens": ["Die", "Un\u00b7ter\u00b7of\u00b7fi\u00b7ziers\u00b7vi\u00b7sa\u00b7ge"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hat jeder dick \u2013 Mensch, bleib blo\u00df da!", "tokens": ["hat", "je\u00b7der", "dick", "\u2013", "Mensch", ",", "bleib", "blo\u00df", "da", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "$(", "NN", "$,", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Blamier nicht die Parteikollegen!", "tokens": ["Bla\u00b7mier", "nicht", "die", "Par\u00b7tei\u00b7kol\u00b7le\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "$."], "meter": "+--+-+-++", "measure": "iambic.penta.invert"}, "line.2": {"text": "Du Bendlerstra\u00dfensozialist!", "tokens": ["Du", "Bend\u00b7ler\u00b7stra\u00b7\u00dfen\u00b7so\u00b7zi\u00b7a\u00b7list", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Geh in Pension mit Gottes Segen!", "tokens": ["Geh", "in", "Pen\u00b7si\u00b7on", "mit", "Got\u00b7tes", "Se\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Wohl dir, da\u00df du Beamter bist!", "tokens": ["Wohl", "dir", ",", "da\u00df", "du", "Be\u00b7am\u00b7ter", "bist", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "KOUS", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Brutal und roh zu den Genossen,", "tokens": ["Bru\u00b7tal", "und", "roh", "zu", "den", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "beschubst von jedem Lieutenant \u2013", "tokens": ["be\u00b7schubst", "von", "je\u00b7dem", "Lie\u00b7u\u00b7ten\u00b7ant", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "so hast du deutsches Blut vergossen.", "tokens": ["so", "hast", "du", "deut\u00b7sches", "Blut", "ver\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Maul: dein Rex. Format: Sergeant.", "tokens": ["Das", "Maul", ":", "dein", "Rex", ".", "For\u00b7mat", ":", "Ser\u00b7ge\u00b7ant", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$.", "PPOSAT", "NN", "$.", "NN", "$.", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Dann wurden die Kadetten t\u00e4tlich.", "tokens": ["Dann", "wur\u00b7den", "die", "Ka\u00b7det\u00b7ten", "t\u00e4t\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Und Gustav fuhr ums Morgenrot . . .", "tokens": ["Und", "Gus\u00b7tav", "fuhr", "ums", "Mor\u00b7gen\u00b7rot", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "NE", "VVFIN", "APPRART", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bleib in Hannover. N\u00e4hr dich redlich.", "tokens": ["Bleib", "in", "Han\u00b7no\u00b7ver", ".", "N\u00e4hr", "dich", "red\u00b7lich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$.", "NN", "PPER", "ADJD", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und i\u00df nur, garantiert unsch\u00e4dlich,", "tokens": ["Und", "i\u00df", "nur", ",", "ga\u00b7ran\u00b7tiert", "un\u00b7sch\u00e4d\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "dein wohlverdientes Gnadenbrot \u2013!", "tokens": ["dein", "wohl\u00b7ver\u00b7dien\u00b7tes", "Gna\u00b7den\u00b7brot", "\u2013", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}