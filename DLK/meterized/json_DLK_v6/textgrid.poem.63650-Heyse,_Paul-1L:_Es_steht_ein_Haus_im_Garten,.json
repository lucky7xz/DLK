{"textgrid.poem.63650": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es steht ein Haus im Garten,", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es steht ein Haus im Garten,", "tokens": ["Es", "steht", "ein", "Haus", "im", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "K\u00fchl an ein W\u00e4ldchen angelehnt.", "tokens": ["K\u00fchl", "an", "ein", "W\u00e4ld\u00b7chen", "an\u00b7ge\u00b7lehnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf allen meinen Fahrten", "tokens": ["Auf", "al\u00b7len", "mei\u00b7nen", "Fahr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hab' ich nach ihm mich heimgesehnt.", "tokens": ["Hab'", "ich", "nach", "ihm", "mich", "heim\u00b7ge\u00b7sehnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie s\u00fc\u00df erklang", "tokens": ["Wie", "s\u00fc\u00df", "er\u00b7klang"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Dort Vogelsang,", "tokens": ["Dort", "Vo\u00b7gel\u00b7sang", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wie lachten Blumen ringsumher!", "tokens": ["Wie", "lach\u00b7ten", "Blu\u00b7men", "rings\u00b7um\u00b7her", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wie ging's im Lauf", "tokens": ["Wie", "ging's", "im", "Lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "APPRART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Die Stieg hinauf \u2013", "tokens": ["Die", "Stieg", "hin\u00b7auf", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Nun graut mir vor der Wiederkehr.", "tokens": ["Nun", "graut", "mir", "vor", "der", "Wie\u00b7der\u00b7kehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Im Haus da ist ein Zimmer,", "tokens": ["Im", "Haus", "da", "ist", "ein", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So luftig hoch, so blank und rein.", "tokens": ["So", "luf\u00b7tig", "hoch", ",", "so", "blank", "und", "rein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was nur an Sonnenschimmer", "tokens": ["Was", "nur", "an", "Son\u00b7nen\u00b7schim\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ums H\u00e4uschen streifte, drang hinein.", "tokens": ["Ums", "H\u00e4usc\u00b7hen", "streif\u00b7te", ",", "drang", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "NN", "VVFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie lustig klang", "tokens": ["Wie", "lus\u00b7tig", "klang"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Dort Kindersang,", "tokens": ["Dort", "Kin\u00b7der\u00b7sang", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Kein Winkel war von Spielen leer;", "tokens": ["Kein", "Win\u00b7kel", "war", "von", "Spie\u00b7len", "leer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dort fand ich Rast", "tokens": ["Dort", "fand", "ich", "Rast"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Nach Tageslast \u2013", "tokens": ["Nach", "Ta\u00b7ges\u00b7last", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Nun \u00f6ffn' ich seine T\u00fcr nicht mehr.", "tokens": ["Nun", "\u00f6ffn'", "ich", "sei\u00b7ne", "T\u00fcr", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Im Haus erklang ein Name", "tokens": ["Im", "Haus", "er\u00b7klang", "ein", "Na\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von allen Lippen fort und fort,", "tokens": ["Von", "al\u00b7len", "Lip\u00b7pen", "fort", "und", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der hatte wundersame", "tokens": ["Der", "hat\u00b7te", "wun\u00b7der\u00b7sa\u00b7me"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gewalt, schier wie ein Zauberwort.", "tokens": ["Ge\u00b7walt", ",", "schier", "wie", "ein", "Zau\u00b7ber\u00b7wort", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auf jedem Mund", "tokens": ["Auf", "je\u00b7dem", "Mund"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ein L\u00e4cheln stund,", "tokens": ["Ein", "L\u00e4\u00b7cheln", "stund", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Als ob's des Fr\u00fchlings Name w\u00e4r' \u2013", "tokens": ["Als", "ob's", "des", "Fr\u00fch\u00b7lings", "Na\u00b7me", "w\u00e4r'", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "NN", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Jetzt geht er stumm", "tokens": ["Jetzt", "geht", "er", "stumm"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Gespenstig um,", "tokens": ["Ge\u00b7spens\u00b7tig", "um", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Und wer ihn ausspricht, lacht nicht mehr.", "tokens": ["Und", "wer", "ihn", "aus\u00b7spricht", ",", "lacht", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "$,", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}