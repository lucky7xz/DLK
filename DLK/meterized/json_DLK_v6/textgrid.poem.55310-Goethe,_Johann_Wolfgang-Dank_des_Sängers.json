{"textgrid.poem.55310": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Dank des S\u00e4ngers", "genre": "verse", "period": "N.A.", "pub_year": 1815, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Von S\u00e4ngern hat man viel erz\u00e4hlt,", "tokens": ["Von", "S\u00e4n\u00b7gern", "hat", "man", "viel", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die in ein Schlo\u00df gekommen,", "tokens": ["Die", "in", "ein", "Schlo\u00df", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo nichts ermangelt, nichts gefehlt,", "tokens": ["Wo", "nichts", "er\u00b7man\u00b7gelt", ",", "nichts", "ge\u00b7fehlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie haben Platz genommen.", "tokens": ["Sie", "ha\u00b7ben", "Platz", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch war wo, irgendwo ein Platz,", "tokens": ["Doch", "war", "wo", ",", "ir\u00b7gend\u00b7wo", "ein", "Platz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PWAV", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vergleichbar diesem Br\u00fcderschatz,", "tokens": ["Ver\u00b7gleich\u00b7bar", "die\u00b7sem", "Br\u00fc\u00b7der\u00b7schatz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo auch ich Platz genommen?", "tokens": ["Wo", "auch", "ich", "Platz", "ge\u00b7nom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ihr fraget nicht, woher ich sei,", "tokens": ["Ihr", "fra\u00b7get", "nicht", ",", "wo\u00b7her", "ich", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir alle sind von oben;", "tokens": ["Wir", "al\u00b7le", "sind", "von", "o\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VAFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch singend wird der Freie frei", "tokens": ["Doch", "sin\u00b7gend", "wird", "der", "Frei\u00b7e", "frei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und darf die Br\u00fcder loben.", "tokens": ["Und", "darf", "die", "Br\u00fc\u00b7der", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Brust entl\u00f6se der Gesang!", "tokens": ["Die", "Brust", "ent\u00b7l\u00f6\u00b7se", "der", "Ge\u00b7sang", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was au\u00dfen eng, was au\u00dfen bang,", "tokens": ["Was", "au\u00b7\u00dfen", "eng", ",", "was", "au\u00b7\u00dfen", "bang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Uns macht es nicht beklommen.", "tokens": ["Uns", "macht", "es", "nicht", "be\u00b7klom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "So hab ich euch denn schon den Dank,", "tokens": ["So", "hab", "ich", "euch", "denn", "schon", "den", "Dank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den ich gedacht, erwiesen", "tokens": ["Den", "ich", "ge\u00b7dacht", ",", "er\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "PPER", "VVPP", "$,", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und euch mit T\u00f6nen rein und schlank", "tokens": ["Und", "euch", "mit", "T\u00f6\u00b7nen", "rein", "und", "schlank"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "NN", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als W\u00fcrdige gepriesen.", "tokens": ["Als", "W\u00fcr\u00b7di\u00b7ge", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Was bleibet \u00fcbrig als der Schall,", "tokens": ["Was", "blei\u00b7bet", "\u00fcb\u00b7rig", "als", "der", "Schall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den wir so gerne h\u00f6ren,", "tokens": ["Den", "wir", "so", "ger\u00b7ne", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn \u00fcberall, all\u00fcberall", "tokens": ["Wenn", "\u00fc\u00b7be\u00b7rall", ",", "al\u00b7l\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "ADV", "$,", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im stillen wir uns vermehren.", "tokens": ["Im", "stil\u00b7len", "wir", "uns", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}