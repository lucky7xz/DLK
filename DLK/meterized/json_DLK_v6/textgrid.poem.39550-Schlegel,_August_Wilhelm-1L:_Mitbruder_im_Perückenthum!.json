{"textgrid.poem.39550": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mitbruder im Per\u00fcckenthum!", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mitbruder im Per\u00fcckenthum!", "tokens": ["Mit\u00b7bru\u00b7der", "im", "Pe\u00b7r\u00fc\u00b7cken\u00b7thum", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du linderst meine Schmerzen", "tokens": ["Du", "lin\u00b7derst", "mei\u00b7ne", "Schmer\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Um der verlornen Locken Ruhm:", "tokens": ["Um", "der", "ver\u00b7lor\u00b7nen", "Lo\u00b7cken", "Ruhm", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Willkommen mir von Herzen!", "tokens": ["Will\u00b7kom\u00b7men", "mir", "von", "Her\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Oft ward mein Haar, so seidenweich,", "tokens": ["Oft", "ward", "mein", "Haar", ",", "so", "sei\u00b7den\u00b7weich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durchw\u00fchlt von sch\u00f6nen H\u00e4nden;", "tokens": ["Durch\u00b7w\u00fchlt", "von", "sch\u00f6\u00b7nen", "H\u00e4n\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich konnt' es, unerme\u00dflich reich,", "tokens": ["Ich", "konnt'", "es", ",", "un\u00b7er\u00b7me\u00df\u00b7lich", "reich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu Ring und Armband spenden.", "tokens": ["Zu", "Ring", "und", "Arm\u00b7band", "spen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Der Liebe Lust, der Liebe Schmerz", "tokens": ["Der", "Lie\u00b7be", "Lust", ",", "der", "Lie\u00b7be", "Schmerz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erfuhr ich hin und wieder,", "tokens": ["Er\u00b7fuhr", "ich", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und gleicherma\u00dfen schlug mein Herz", "tokens": ["Und", "glei\u00b7cher\u00b7ma\u00b7\u00dfen", "schlug", "mein", "Herz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor Schn\u00fcrbrust oder Mieder.", "tokens": ["Vor", "Schn\u00fcr\u00b7brust", "o\u00b7der", "Mie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und da\u00df man alt're, glaubt' ich kaum;", "tokens": ["Und", "da\u00df", "man", "alt'\u00b7re", ",", "glaubt'", "ich", "kaum", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADJA", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich hatt' es nicht erfahren.", "tokens": ["Ich", "hatt'", "es", "nicht", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Allm\u00e4lich schwand der Wonnetraum", "tokens": ["A\u00b7llm\u00e4\u00b7lich", "schwand", "der", "Won\u00b7ne\u00b7traum"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit meinen blonden Haaren.", "tokens": ["Mit", "mei\u00b7nen", "blon\u00b7den", "Haa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Des Lebens Mittag folgte nun", "tokens": ["Des", "Le\u00b7bens", "Mit\u00b7tag", "folg\u00b7te", "nun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf jenen frischen Morgen;", "tokens": ["Auf", "je\u00b7nen", "fri\u00b7schen", "Mor\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Ehrgeiz rief zu anderm Thun,", "tokens": ["Der", "Ehr\u00b7geiz", "rief", "zu", "an\u00b7derm", "Thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Welt zu Kampf und Sorgen.", "tokens": ["Die", "Welt", "zu", "Kampf", "und", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Mein Kopf war innen vollbepackt", "tokens": ["Mein", "Kopf", "war", "in\u00b7nen", "voll\u00b7be\u00b7packt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit hochgelahrtem Wesen:", "tokens": ["Mit", "hoch\u00b7ge\u00b7lahr\u00b7tem", "We\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ach! aber au\u00dfen kahl und nackt", "tokens": ["Ach", "!", "a\u00b7ber", "au\u00b7\u00dfen", "kahl", "und", "nackt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "ADV", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie ein verbrauchter Besen.", "tokens": ["Wie", "ein", "ver\u00b7brauch\u00b7ter", "Be\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Vergebens kr\u00e4uselt' ich noch viel", "tokens": ["Ver\u00b7ge\u00b7bens", "kr\u00e4u\u00b7selt'", "ich", "noch", "viel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An diesen Stoppelfeldern;", "tokens": ["An", "die\u00b7sen", "Stop\u00b7pel\u00b7fel\u00b7dern", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Winde hatten freies Spiel,", "tokens": ["Die", "Win\u00b7de", "hat\u00b7ten", "frei\u00b7es", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie in entlaubten W\u00e4ldern.", "tokens": ["Wie", "in", "ent\u00b7laub\u00b7ten", "W\u00e4l\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Da schalt ich dich, du R\u00e4uberin,", "tokens": ["Da", "schalt", "ich", "dich", ",", "du", "R\u00e4u\u00b7be\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O Zeit! voll falscher T\u00fccke.", "tokens": ["O", "Zeit", "!", "voll", "fal\u00b7scher", "T\u00fc\u00b7cke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich warf im Zorn den Spiegel hin,", "tokens": ["Ich", "warf", "im", "Zorn", "den", "Spie\u00b7gel", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und griff nach der Per\u00fccke.", "tokens": ["Und", "griff", "nach", "der", "Pe\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Zwar solch ein Ding, so leicht gewandt, \u2013", "tokens": ["Zwar", "solch", "ein", "Ding", ",", "so", "leicht", "ge\u00b7wandt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PIAT", "ART", "NN", "$,", "ADV", "ADJD", "VVPP", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Konnt' ich zum Trost mir sagen, \u2013", "tokens": ["Konnt'", "ich", "zum", "Trost", "mir", "sa\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "PPER", "VVINF", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wer h\u00e4tt' es wohl daf\u00fcr erkannt", "tokens": ["Wer", "h\u00e4tt'", "es", "wohl", "da\u00b7f\u00fcr", "er\u00b7kannt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In unsrer V\u00e4ter Tagen?", "tokens": ["In", "uns\u00b7rer", "V\u00e4\u00b7ter", "Ta\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Entfremdet jener Unnatur,", "tokens": ["Ent\u00b7frem\u00b7det", "je\u00b7ner", "Un\u00b7na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die damals man bewundert,", "tokens": ["Die", "da\u00b7mals", "man", "be\u00b7wun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bracht' edlen Stil in die Frisur", "tokens": ["Bracht'", "ed\u00b7len", "Stil", "in", "die", "Fri\u00b7sur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die\u00df schaffende Jahrhundert.", "tokens": ["Die\u00df", "schaf\u00b7fen\u00b7de", "Jahr\u00b7hun\u00b7dert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Im Puderreif, Pomadenthau", "tokens": ["Im", "Pu\u00b7der\u00b7reif", ",", "Po\u00b7ma\u00b7dent\u00b7hau"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPRART", "NN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Pfeifen, Knoten, Zipfeln,", "tokens": ["An", "Pfei\u00b7fen", ",", "Kno\u00b7ten", ",", "Zip\u00b7feln", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Glich des Toupee's geth\u00fcrmter Bau", "tokens": ["Glich", "des", "Tou\u00b7pee's", "ge\u00b7th\u00fcrm\u00b7ter", "Bau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ART", "NN", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Beschneiter Alpen Gipfeln.", "tokens": ["Be\u00b7schnei\u00b7ter", "Al\u00b7pen", "Gip\u00b7feln", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Die spitze Schneppe trat herein", "tokens": ["Die", "spit\u00b7ze", "Schnep\u00b7pe", "trat", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hoch \u00fcber beiden Brauen;", "tokens": ["Hoch", "\u00fc\u00b7ber", "bei\u00b7den", "Brau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Ecken lie\u00dfen, glatt und rein,", "tokens": ["Die", "E\u00b7cken", "lie\u00b7\u00dfen", ",", "glatt", "und", "rein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Rasierte Stirnen schauen.", "tokens": ["Ra\u00b7sier\u00b7te", "Stir\u00b7nen", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.12": {"line.1": {"text": "Und Lovelace spielte, so geschm\u00fcckt,", "tokens": ["Und", "Lo\u00b7ve\u00b7la\u00b7ce", "spiel\u00b7te", ",", "so", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Des Herzensdiebes Rolle,", "tokens": ["Des", "Her\u00b7zens\u00b7die\u00b7bes", "Rol\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie Englands Kanzler, steif per\u00fcckt,", "tokens": ["Wie", "En\u00b7glands", "Kanz\u00b7ler", ",", "steif", "pe\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf seinem Sack von Wolle.", "tokens": ["Auf", "sei\u00b7nem", "Sack", "von", "Wol\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Jetzt wei\u00df die Kunst den Wurf und Schwung", "tokens": ["Jetzt", "wei\u00df", "die", "Kunst", "den", "Wurf", "und", "Schwung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Locken nachzuahmen,", "tokens": ["Der", "Lo\u00b7cken", "nach\u00b7zu\u00b7ah\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und aus der Fern' erscheinen jung", "tokens": ["Und", "aus", "der", "Fern'", "er\u00b7schei\u00b7nen", "jung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel alte Herrn und Damen.", "tokens": ["Viel", "al\u00b7te", "Herrn", "und", "Da\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Dein krauses Haar, sonst sch\u00f6n gebr\u00e4unt,", "tokens": ["Dein", "krau\u00b7ses", "Haar", ",", "sonst", "sch\u00f6n", "ge\u00b7br\u00e4unt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War scheckig j\u00fcngst geworden:", "tokens": ["War", "sche\u00b7ckig", "j\u00fcngst", "ge\u00b7wor\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJD", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da fa\u00dfest du dich m\u00e4nnlich, Freund,", "tokens": ["Da", "fa\u00b7\u00dfest", "du", "dich", "m\u00e4nn\u00b7lich", ",", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und trittst in unsern Orden.", "tokens": ["Und", "trittst", "in", "un\u00b7sern", "Or\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wer uns Per\u00fcckenh\u00e4nse hei\u00dft,", "tokens": ["Wer", "uns", "Pe\u00b7r\u00fc\u00b7cken\u00b7h\u00e4n\u00b7se", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil wir Per\u00fccken tragen,", "tokens": ["Weil", "wir", "Pe\u00b7r\u00fc\u00b7cken", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der wi\u00dfe: stets verj\u00fcngt der Geist,", "tokens": ["Der", "wi\u00b7\u00dfe", ":", "stets", "ver\u00b7j\u00fcngt", "der", "Geist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$.", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Muth, das k\u00fchne Wagen.", "tokens": ["Der", "Muth", ",", "das", "k\u00fch\u00b7ne", "Wa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Die Tr\u00e4gen werden zeitig alt,", "tokens": ["Die", "Tr\u00e4\u00b7gen", "wer\u00b7den", "zei\u00b7tig", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Spotte gar die Thoren;", "tokens": ["Zum", "Spot\u00b7te", "gar", "die", "Tho\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und blieb eu'r Herz dem Sch\u00f6nen kalt,", "tokens": ["Und", "blieb", "eu'r", "Herz", "dem", "Sch\u00f6\u00b7nen", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So war't ihr alt geboren.", "tokens": ["So", "wa\u00b7r't", "ihr", "alt", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Gelbschn\u00e4bel! flattert nur herum", "tokens": ["Gelb\u00b7schn\u00e4\u00b7bel", "!", "flat\u00b7tert", "nur", "he\u00b7rum"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "VVFIN", "ADV", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit eurem bischen Jugend.", "tokens": ["Mit", "eu\u00b7rem", "bi\u00b7schen", "Ju\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Euch bleibt der Mund des Ruhmes stumm,", "tokens": ["Euch", "bleibt", "der", "Mund", "des", "Ruh\u00b7mes", "stumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Euch kr\u00e4nzet nie die Tugend.", "tokens": ["Euch", "kr\u00e4n\u00b7zet", "nie", "die", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Zwar wird wohl kein Per\u00fcckenhans", "tokens": ["Zwar", "wird", "wohl", "kein", "Pe\u00b7r\u00fc\u00b7cken\u00b7hans"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein eitles Weib gewinnen;", "tokens": ["Ein", "eit\u00b7les", "Weib", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch das Verdienst des reifen Manns", "tokens": ["Doch", "das", "Ver\u00b7dienst", "des", "rei\u00b7fen", "Manns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Find't weise Kennerinnen.", "tokens": ["Find't", "wei\u00b7se", "Ken\u00b7ne\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}