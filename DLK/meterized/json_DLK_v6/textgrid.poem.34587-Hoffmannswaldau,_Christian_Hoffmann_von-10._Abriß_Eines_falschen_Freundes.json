{"textgrid.poem.34587": {"metadata": {"author": {"name": "Hoffmannswaldau, Christian Hoffmann von", "birth": "N.A.", "death": "N.A."}, "title": "10. Abri\u00df Eines falschen Freundes", "genre": "verse", "period": "N.A.", "pub_year": 1647, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was ist doch ingemein ein Freund in dieser Welt?", "tokens": ["Was", "ist", "doch", "in\u00b7ge\u00b7mein", "ein", "Freund", "in", "die\u00b7ser", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "ART", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Spiegel, der vergr\u00f6st und f\u00e4lschlich sch\u00f6ner machet,", "tokens": ["Ein", "Spie\u00b7gel", ",", "der", "ver\u00b7gr\u00f6st", "und", "f\u00e4lschlich", "sch\u00f6\u00b7ner", "ma\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "KON", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ein Pfennig, der nicht Strich und nicht Gewichte h\u00e4lt,", "tokens": ["Ein", "Pfen\u00b7nig", ",", "der", "nicht", "Strich", "und", "nicht", "Ge\u00b7wich\u00b7te", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PTKNEG", "NN", "KON", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Wesen, so aus Zorn und bittrer Galle lachet,", "tokens": ["Ein", "We\u00b7sen", ",", "so", "aus", "Zorn", "und", "bit\u00b7trer", "Gal\u00b7le", "la\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Strauchstern dessen Glantz uns Schand und Schaden bringt,", "tokens": ["Ein", "Strauchs\u00b7tern", "des\u00b7sen", "Glantz", "uns", "Schand", "und", "Scha\u00b7den", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRELAT", "NN", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Glas, an Tituln gut, und doch mit Gifft gef\u00fcllet,", "tokens": ["Ein", "Glas", ",", "an", "Ti\u00b7tuln", "gut", ",", "und", "doch", "mit", "Gifft", "ge\u00b7f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "ADJD", "$,", "KON", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Dolch der schreckend ist, und uns zum Hertzen dringt:", "tokens": ["Ein", "Dolch", "der", "schre\u00b7ckend", "ist", ",", "und", "uns", "zum", "Hert\u00b7zen", "dringt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJD", "VAFIN", "$,", "KON", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein Heilbrunn (wie er heist) aus dem Verderben quillet,", "tokens": ["Ein", "Heil\u00b7brunn", "(", "wie", "er", "heist", ")", "aus", "dem", "Ver\u00b7der\u00b7ben", "quil\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWAV", "PPER", "VVFIN", "$(", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Goldgestrickter Strang, der uns die Gurgel bricht,", "tokens": ["Ein", "Gold\u00b7ge\u00b7strick\u00b7ter", "Strang", ",", "der", "uns", "die", "Gur\u00b7gel", "bricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein Freund, der ohngefehr das Hertze hat verlohren,", "tokens": ["Ein", "Freund", ",", "der", "ohn\u00b7ge\u00b7fehr", "das", "Hert\u00b7ze", "hat", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "PDS", "VVFIN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein Honigwurm, der stets mit s\u00fcssem Stachel sticht,", "tokens": ["Ein", "Ho\u00b7nig\u00b7wurm", ",", "der", "stets", "mit", "s\u00fcs\u00b7sem", "Sta\u00b7chel", "sticht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein weisses Hennen-Ey, das Drachen hat gebohren,", "tokens": ["Ein", "weis\u00b7ses", "Hen\u00b7nen\u00b7Ey", ",", "das", "Dra\u00b7chen", "hat", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein falscher Crocodil, der weinend uns zerrei\u00dft,", "tokens": ["Ein", "fal\u00b7scher", "Cro\u00b7co\u00b7dil", ",", "der", "wei\u00b7nend", "uns", "zer\u00b7rei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein recht Sirenen Weib, das singend uns ertr\u00e4ncket,", "tokens": ["Ein", "recht", "Si\u00b7re\u00b7nen", "Weib", ",", "das", "sin\u00b7gend", "uns", "er\u00b7tr\u00e4n\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.15": {"text": "Ein Safft, der lieblich reucht, und doch die Haut durchbeist.", "tokens": ["Ein", "Safft", ",", "der", "lieb\u00b7lich", "reucht", ",", "und", "doch", "die", "Haut", "durch\u00b7beist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,", "KON", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein Mann, der uns umhalst, wenn seine Hand uns hencket,", "tokens": ["Ein", "Mann", ",", "der", "uns", "um\u00b7halst", ",", "wenn", "sei\u00b7ne", "Hand", "uns", "hen\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ein Gifftbaum voller Bluth, ein ", "tokens": ["Ein", "Gifft\u00b7baum", "vol\u00b7ler", "Bluth", ",", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Ein \u00fcbergoldte Perl, ein Lock-Aas zu den N\u00f6then,", "tokens": ["Ein", "\u00fc\u00b7ber\u00b7gold\u00b7te", "Perl", ",", "ein", "Lock\u00b7Aas", "zu", "den", "N\u00f6\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Ein Apffel ", "tokens": ["Ein", "Apf\u00b7fel"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.20": {"text": "Ein \u00fcberzuckert Gifft, ein Irrlicht uns zu t\u00f6dten,", "tokens": ["Ein", "\u00fc\u00b7ber\u00b7zu\u00b7ckert", "Gifft", ",", "ein", "Irr\u00b7licht", "uns", "zu", "t\u00f6d\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein Pfeiffer in den Garn, ein Sp\u00f6tter unser Pein,", "tokens": ["Ein", "Pfeif\u00b7fer", "in", "den", "Garn", ",", "ein", "Sp\u00f6t\u00b7ter", "un\u00b7ser", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ein g\u00f6ldner Urtels Tisch, und eine faule St\u00fctze,", "tokens": ["Ein", "g\u00f6ld\u00b7ner", "Ur\u00b7tels", "Tisch", ",", "und", "ei\u00b7ne", "fau\u00b7le", "St\u00fct\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ein Zeug, der bald verschlei\u00dft, ein ungegr\u00fcndter Schein,", "tokens": ["Ein", "Zeug", ",", "der", "bald", "ver\u00b7schlei\u00dft", ",", "ein", "un\u00b7ge\u00b7gr\u00fcnd\u00b7ter", "Schein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dem Teuffel allzusehr, dem Menschen wenig n\u00fctze.", "tokens": ["Dem", "Teuf\u00b7fel", "all\u00b7zu\u00b7sehr", ",", "dem", "Men\u00b7schen", "we\u00b7nig", "n\u00fct\u00b7ze", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ein mehrers l\u00e4\u00dft mir itzt die Ungedult nicht zu.", "tokens": ["Ein", "meh\u00b7rers", "l\u00e4\u00dft", "mir", "itzt", "die", "Un\u00b7ge\u00b7dult", "nicht", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Mein Leser, fleuch den Krahm von solchen falschen Waaren,", "tokens": ["Mein", "Le\u00b7ser", ",", "fleuch", "den", "Krahm", "von", "sol\u00b7chen", "fal\u00b7schen", "Waa\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Was dieser Eifer-Reim erprest, das meide du.", "tokens": ["Was", "die\u00b7ser", "Ei\u00b7fer\u00b7Reim", "er\u00b7prest", ",", "das", "mei\u00b7de", "du", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "PDS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ach h\u00e4tt ich, was ich schrieb, nicht auch zugleich erfahren!", "tokens": ["Ach", "h\u00e4tt", "ich", ",", "was", "ich", "schrieb", ",", "nicht", "auch", "zu\u00b7gleich", "er\u00b7fah\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VAFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,", "PTKNEG", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}