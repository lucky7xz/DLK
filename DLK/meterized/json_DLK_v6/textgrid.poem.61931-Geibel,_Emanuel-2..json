{"textgrid.poem.61931": {"metadata": {"author": {"name": "Geibel, Emanuel", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1833, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ins Unendliche strebt sich die Bildung der Zeit zu erweitern,", "tokens": ["Ins", "Un\u00b7end\u00b7li\u00b7che", "strebt", "sich", "die", "Bil\u00b7dung", "der", "Zeit", "zu", "er\u00b7wei\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PRF", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Aber dem breiteren Strom droht die Verflachung bereits.", "tokens": ["A\u00b7ber", "dem", "brei\u00b7te\u00b7ren", "Strom", "droht", "die", "Ver\u00b7fla\u00b7chung", "be\u00b7reits", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "F\u00fclle die Jugend mit w\u00fcrdigem Stoff und in froher Begeistrung", "tokens": ["F\u00fcl\u00b7le", "die", "Ju\u00b7gend", "mit", "w\u00fcr\u00b7di\u00b7gem", "Stoff", "und", "in", "fro\u00b7her", "Be\u00b7geis\u00b7trung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "ADJA", "NN", "KON", "APPR", "ADJA", "NN"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Lehre sie gl\u00fchn! Die Kritik kommt mit den Jahren von selbst.", "tokens": ["Leh\u00b7re", "sie", "gl\u00fchn", "!", "Die", "Kri\u00b7tik", "kommt", "mit", "den", "Jah\u00b7ren", "von", "selbst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "$.", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "APPR", "ADV", "$."], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}}, "stanza.3": {"line.1": {"text": "Immer behalte getreu vor Augen das H\u00f6chste, doch heute", "tokens": ["Im\u00b7mer", "be\u00b7hal\u00b7te", "ge\u00b7treu", "vor", "Au\u00b7gen", "das", "H\u00f6chs\u00b7te", ",", "doch", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "APPR", "NN", "ART", "ADJA", "$,", "ADV", "ADV"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Strebe nach dem, was heut du zu erreichen vermagst.", "tokens": ["Stre\u00b7be", "nach", "dem", ",", "was", "heut", "du", "zu", "er\u00b7rei\u00b7chen", "ver\u00b7magst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "$,", "PRELS", "ADV", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}}, "stanza.4": {"line.1": {"text": "Nicht wer Staatstheorien doziert, ein Politiker ist nur,", "tokens": ["Nicht", "wer", "Staats\u00b7the\u00b7o\u00b7ri\u00b7en", "do\u00b7ziert", ",", "ein", "Po\u00b7li\u00b7ti\u00b7ker", "ist", "nur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PWS", "NN", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}, "line.2": {"text": "Wer im gegebenen Fall richtig das M\u00f6gliche schafft.", "tokens": ["Wer", "im", "ge\u00b7ge\u00b7be\u00b7nen", "Fall", "rich\u00b7tig", "das", "M\u00f6g\u00b7li\u00b7che", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "ADJA", "NN", "ADJD", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+--++--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Stets zu Schw\u00e4rmen gesellt sich das Volk der geschw\u00e4tzigen Stare,", "tokens": ["Stets", "zu", "Schw\u00e4r\u00b7men", "ge\u00b7sellt", "sich", "das", "Volk", "der", "ge\u00b7schw\u00e4t\u00b7zi\u00b7gen", "Sta\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PRF", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Einsam sucht sich der Aar \u00fcber den Wolken die Bahn.", "tokens": ["Ein\u00b7sam", "sucht", "sich", "der", "Aar", "\u00fc\u00b7ber", "den", "Wol\u00b7ken", "die", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Bester, du hast ein Gewissen f\u00fcr das, was sittlich und wahr ist,", "tokens": ["Bes\u00b7ter", ",", "du", "hast", "ein", "Ge\u00b7wis\u00b7sen", "f\u00fcr", "das", ",", "was", "sitt\u00b7lich", "und", "wahr", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ART", "NN", "APPR", "PDS", "$,", "PRELS", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "+--++-+----+--+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Warum fehlt es dir, ach, nur f\u00fcr das Sch\u00f6ne so ganz?", "tokens": ["Wa\u00b7rum", "fehlt", "es", "dir", ",", "ach", ",", "nur", "f\u00fcr", "das", "Sch\u00f6\u00b7ne", "so", "ganz", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "$,", "ITJ", "$,", "ADV", "APPR", "ART", "NN", "ADV", "ADV", "$."], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}}, "stanza.7": {"line.1": {"text": "Nicht blo\u00df, wer im Gem\u00fct abstreifte den Z\u00fcgel der Sitte,", "tokens": ["Nicht", "blo\u00df", ",", "wer", "im", "Ge\u00b7m\u00fct", "ab\u00b7streif\u00b7te", "den", "Z\u00fc\u00b7gel", "der", "Sit\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "PWS", "APPRART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+---+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wer sich des H\u00e4\u00dflichen nicht sch\u00e4mt, er ist auch ein Barbar.", "tokens": ["Wer", "sich", "des", "H\u00e4\u00df\u00b7li\u00b7chen", "nicht", "sch\u00e4mt", ",", "er", "ist", "auch", "ein", "Bar\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ART", "NN", "PTKNEG", "ADJD", "$,", "PPER", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.8": {"line.1": {"text": "Eile mit Weile! Den Kahn erst lerne zu steuern im Hafen,", "tokens": ["Ei\u00b7le", "mit", "Wei\u00b7le", "!", "Den", "Kahn", "erst", "ler\u00b7ne", "zu", "steu\u00b7ern", "im", "Ha\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$.", "ART", "NN", "ADV", "VVFIN", "PTKZU", "VVINF", "APPRART", "NN", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Eh' zur Entdeckungsfahrt m\u00e4chtige Segel du spannst.", "tokens": ["Eh'", "zur", "Ent\u00b7de\u00b7ckungs\u00b7fahrt", "m\u00e4ch\u00b7ti\u00b7ge", "Se\u00b7gel", "du", "spannst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Stolz und schweigend enth\u00fcllt sein Werk uns der Meister; im eitlen", "tokens": ["Stolz", "und", "schwei\u00b7gend", "ent\u00b7h\u00fcllt", "sein", "Werk", "uns", "der", "Meis\u00b7ter", ";", "im", "eit\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "ADJD", "VVFIN", "PPOSAT", "NN", "PPER", "ART", "NN", "$.", "APPRART", "ADJA"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Selbstlob birgt ein Gef\u00fchl heimlicher Schw\u00e4che sich nur.", "tokens": ["Selbst\u00b7lob", "birgt", "ein", "Ge\u00b7f\u00fchl", "heim\u00b7li\u00b7cher", "Schw\u00e4\u00b7che", "sich", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "PRF", "ADV", "$."], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Tiefer erscheint tr\u00fcbstr\u00f6mende Flut, durchsichtige flacher,", "tokens": ["Tie\u00b7fer", "er\u00b7scheint", "tr\u00fcbs\u00b7tr\u00f6\u00b7men\u00b7de", "Flut", ",", "durch\u00b7sich\u00b7ti\u00b7ge", "fla\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADJA", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Aber das Senkblei lehrt oft, da\u00df dich beides get\u00e4uscht.", "tokens": ["A\u00b7ber", "das", "Senk\u00b7blei", "lehrt", "oft", ",", "da\u00df", "dich", "bei\u00b7des", "ge\u00b7t\u00e4uscht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PIS", "VVPP", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}}, "stanza.11": {"line.1": {"text": "Ist denn die Blume nur da zum Zergliedern? Weh dem Geschlechte,", "tokens": ["Ist", "denn", "die", "Blu\u00b7me", "nur", "da", "zum", "Zer\u00b7glie\u00b7dern", "?", "Weh", "dem", "Ge\u00b7schlech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "$.", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Das, anstatt sich zu freun, jegliche Freude zerdenkt!", "tokens": ["Das", ",", "an\u00b7statt", "sich", "zu", "freun", ",", "jeg\u00b7li\u00b7che", "Freu\u00b7de", "zer\u00b7denkt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUI", "PRF", "PTKZU", "VVINF", "$,", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+---+--+", "measure": "iambic.penta.chol"}}, "stanza.12": {"line.1": {"text": "Torheit bleibt's, im Gesang um den Preis der Geschichte zu ringen,", "tokens": ["Tor\u00b7heit", "bleibt's", ",", "im", "Ge\u00b7sang", "um", "den", "Preis", "der", "Ge\u00b7schich\u00b7te", "zu", "rin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "APPRART", "NN", "APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Doch der poetische Stoff kann ein historischer sein.", "tokens": ["Doch", "der", "po\u00b7e\u00b7ti\u00b7sche", "Stoff", "kann", "ein", "his\u00b7to\u00b7ri\u00b7scher", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VMFIN", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.13": {"line.1": {"text": "Freilich f\u00fcr ein Gedicht ist Sch\u00f6nheit immer das H\u00f6chste,", "tokens": ["Frei\u00b7lich", "f\u00fcr", "ein", "Ge\u00b7dicht", "ist", "Sch\u00f6n\u00b7heit", "im\u00b7mer", "das", "H\u00f6chs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "NN", "ADV", "ART", "ADJA", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Nur nicht jeglicher Zeit H\u00f6chstes ein sch\u00f6nes Gedicht.", "tokens": ["Nur", "nicht", "jeg\u00b7li\u00b7cher", "Zeit", "H\u00f6chs\u00b7tes", "ein", "sch\u00f6\u00b7nes", "Ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PIAT", "NN", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+---+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.14": {"line.1": {"text": "Ward dir Gro\u00dfes versagt, so \u00fcbe die Kunst an bescheidnen", "tokens": ["Ward", "dir", "Gro\u00b7\u00dfes", "ver\u00b7sagt", ",", "so", "\u00fc\u00b7be", "die", "Kunst", "an", "be\u00b7scheid\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "NN", "VVPP", "$,", "ADV", "VVFIN", "ART", "NN", "APPR", "ADJA"], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Stoffen und strebe mit Ernst, Meister im Kleinen zu sein.", "tokens": ["Stof\u00b7fen", "und", "stre\u00b7be", "mit", "Ernst", ",", "Meis\u00b7ter", "im", "Klei\u00b7nen", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "APPR", "NE", "$,", "NN", "APPRART", "NN", "PTKZU", "VAINF", "$."], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}}, "stanza.15": {"line.1": {"text": "In dem kastalischen Born, dem begeisternden, sprudelt ein Tropfen", "tokens": ["In", "dem", "kas\u00b7ta\u00b7li\u00b7schen", "Born", ",", "dem", "be\u00b7geis\u00b7tern\u00b7den", ",", "spru\u00b7delt", "ein", "Trop\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Lethe; jeglichen Schmerz d\u00e4mpft er, so lange du singst.", "tokens": ["Le\u00b7the", ";", "jeg\u00b7li\u00b7chen", "Schmerz", "d\u00e4mpft", "er", ",", "so", "lan\u00b7ge", "du", "singst", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PIAT", "NN", "VVFIN", "PPER", "$,", "ADV", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}}}}}