{"textgrid.poem.64995": {"metadata": {"author": {"name": "Paoli, Betty", "birth": "N.A.", "death": "N.A."}, "title": "84.", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So weichst auch du von mir? So mu\u00dft auch du erkalten?", "tokens": ["So", "weichst", "auch", "du", "von", "mir", "?", "So", "mu\u00dft", "auch", "du", "er\u00b7kal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPR", "PPER", "$.", "ADV", "VMFIN", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fahr' hin, auf ewig hin! ich werde dich nicht halten.", "tokens": ["Fahr'", "hin", ",", "auf", "e\u00b7wig", "hin", "!", "ich", "wer\u00b7de", "dich", "nicht", "hal\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "APPR", "ADJD", "PTKVZ", "$.", "PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Allein beim Abschied jetzt f\u00fchl' ich noch mehr als Gram,", "tokens": ["Al\u00b7lein", "beim", "Ab\u00b7schied", "jetzt", "f\u00fchl'", "ich", "noch", "mehr", "als", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "VVFIN", "PPER", "ADV", "PIAT", "KOKOM", "NE", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In meiner tiefsten Brust bew\u00e4ltigende Scham.", "tokens": ["In", "mei\u00b7ner", "tiefs\u00b7ten", "Brust", "be\u00b7w\u00e4l\u00b7ti\u00b7gen\u00b7de", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Scham, da\u00df mich ein Gem\u00fcth, da\u00df ich so hoch geehret,", "tokens": ["Scham", ",", "da\u00df", "mich", "ein", "Ge\u00b7m\u00fcth", ",", "da\u00df", "ich", "so", "hoch", "ge\u00b7eh\u00b7ret", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Nun \u00fcber meinen Wahn so schm\u00e4hlich hat belehret.", "tokens": ["Nun", "\u00fc\u00b7ber", "mei\u00b7nen", "Wahn", "so", "schm\u00e4h\u00b7lich", "hat", "be\u00b7leh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}