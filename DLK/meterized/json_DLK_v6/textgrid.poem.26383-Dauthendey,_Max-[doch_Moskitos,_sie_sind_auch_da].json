{"textgrid.poem.26383": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[doch Moskitos, sie sind auch da]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Doch Moskitos, sie sind auch da", "tokens": ["Doch", "Mos\u00b7ki\u00b7tos", ",", "sie", "sind", "auch", "da"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "$,", "PPER", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im angebornen Europa.", "tokens": ["Im", "an\u00b7ge\u00b7bor\u00b7nen", "Eu\u00b7ro\u00b7pa", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Etwas in mir tat heftig bocken,", "tokens": ["Et\u00b7was", "in", "mir", "tat", "hef\u00b7tig", "bo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVFIN", "ADJD", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und blutd\u00fcrstig blieb es nicht hocken.", "tokens": ["Und", "blut\u00b7d\u00fcrs\u00b7tig", "blieb", "es", "nicht", "ho\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Das ideale Heidentum", "tokens": ["Das", "i\u00b7dea\u00b7le", "Hei\u00b7den\u00b7tum"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lag stets um Griechenland herum,", "tokens": ["Lag", "stets", "um", "Grie\u00b7chen\u00b7land", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Dort ging der Mensch einst nackt auf Erden.", "tokens": ["Dort", "ging", "der", "Mensch", "einst", "nackt", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wollt' ein alter Grieche werden.", "tokens": ["Ich", "wollt'", "ein", "al\u00b7ter", "Grie\u00b7che", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "In Griechenland sind Tropen kaum,", "tokens": ["In", "Grie\u00b7chen\u00b7land", "sind", "Tro\u00b7pen", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort steht auch Birk' und Eichenbaum.", "tokens": ["Dort", "steht", "auch", "Birk'", "und", "Ei\u00b7chen\u00b7baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich bau' dort irgendwo ein Haus", "tokens": ["Ich", "bau'", "dort", "ir\u00b7gend\u00b7wo", "ein", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schau' auf Griechenland hinaus.", "tokens": ["Und", "schau'", "auf", "Grie\u00b7chen\u00b7land", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Frau K\u00f6nigin sprach diesmal: \u00bbNein,", "tokens": ["Frau", "K\u00f6\u00b7ni\u00b7gin", "sprach", "dies\u00b7mal", ":", "\u00bb", "Nein", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ADV", "$.", "$(", "PTKANT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bitte, reis' zuerst allein,", "tokens": ["Ich", "bit\u00b7te", ",", "reis'", "zu\u00b7erst", "al\u00b7lein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Such du uns unten Haus und Garten,", "tokens": ["Such", "du", "uns", "un\u00b7ten", "Haus", "und", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PRF", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich werd' bei meiner Mutter warten.\u00ab \u2013", "tokens": ["Ich", "werd'", "bei", "mei\u00b7ner", "Mut\u00b7ter", "war\u00b7ten", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Neumond hing an der Himmelswand,", "tokens": ["Neu\u00b7mond", "hing", "an", "der", "Him\u00b7mels\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ich im Mittelmeer mich fand.", "tokens": ["Als", "ich", "im", "Mit\u00b7tel\u00b7meer", "mich", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Mond ward fein wie eine Ahle", "tokens": ["Der", "Mond", "ward", "fein", "wie", "ei\u00b7ne", "Ah\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und stach mich in die Seelenschale,", "tokens": ["Und", "stach", "mich", "in", "die", "See\u00b7len\u00b7scha\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Er drang mir st\u00fcndlich tiefer ein", "tokens": ["Er", "drang", "mir", "st\u00fcnd\u00b7lich", "tie\u00b7fer", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ADJD", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sagte: \u00bbMensch, du bist allein!\u00ab", "tokens": ["Und", "sag\u00b7te", ":", "\u00bb", "Mensch", ",", "du", "bist", "al\u00b7lein", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NN", "$,", "PPER", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "In zweiter Nacht ward er zur Wiege,", "tokens": ["In", "zwei\u00b7ter", "Nacht", "ward", "er", "zur", "Wie\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mir war's, als ob ein Weib drin liege,", "tokens": ["Mir", "wa\u00b7r's", ",", "als", "ob", "ein", "Weib", "drin", "lie\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.13": {"line.1": {"text": "Ein Weib mit dunkeln kurzen Locken,", "tokens": ["Ein", "Weib", "mit", "dun\u00b7keln", "kur\u00b7zen", "Lo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mund war mir vor Sehnsucht trocken.", "tokens": ["Der", "Mund", "war", "mir", "vor", "Sehn\u00b7sucht", "tro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Endlich der Mond im Meer still stand", "tokens": ["End\u00b7lich", "der", "Mond", "im", "Meer", "still", "stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPRART", "NN", "ADJD", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Als Schaumweinkelch mit flachem Rand.", "tokens": ["Als", "Schaum\u00b7wein\u00b7kelch", "mit", "fla\u00b7chem", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich tat nur wenig an ihm nippen", "tokens": ["Ich", "tat", "nur", "we\u00b7nig", "an", "ihm", "nip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fchlt' ihn brennend in den Rippen,", "tokens": ["Und", "f\u00fchlt'", "ihn", "bren\u00b7nend", "in", "den", "Rip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Er gab mir Heimweh zum Begleiter,", "tokens": ["Er", "gab", "mir", "Heim\u00b7weh", "zum", "Be\u00b7glei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sprach: \u00bbWarum reist man jetzt weiter?", "tokens": ["Und", "sprach", ":", "\u00bb", "Wa\u00b7rum", "reist", "man", "jetzt", "wei\u00b7ter", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PWAV", "VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.17": {"line.1": {"text": "Warum nach Fremdem stets gehetzt?", "tokens": ["Wa\u00b7rum", "nach", "Frem\u00b7dem", "stets", "ge\u00b7hetzt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Komm doch mal in die Heimat jetzt!", "tokens": ["Komm", "doch", "mal", "in", "die", "Hei\u00b7mat", "jetzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Denn wechselst du auch Ort um Ort,", "tokens": ["Denn", "wech\u00b7selst", "du", "auch", "Ort", "um", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch keiner reiste von sich fort.", "tokens": ["Noch", "kei\u00b7ner", "reis\u00b7te", "von", "sich", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Du sollst still in der Heimat stehn", "tokens": ["Du", "sollst", "still", "in", "der", "Hei\u00b7mat", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und deine S\u00fcnden dort begehn.", "tokens": ["Und", "dei\u00b7ne", "S\u00fcn\u00b7den", "dort", "be\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Dein Schicksal hat dir's vorgeschrieben,", "tokens": ["Dein", "Schick\u00b7sal", "hat", "dir's", "vor\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zwei Fraun sollst du vor allem lieben.", "tokens": ["Zwei", "Fraun", "sollst", "du", "vor", "al\u00b7lem", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "PPER", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Entsetzt sah ich das Heimweh an:", "tokens": ["Ent\u00b7setzt", "sah", "ich", "das", "Heim\u00b7weh", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gibt's nichts, was mich noch retten kann?\u00ab", "tokens": ["Gibt's", "nichts", ",", "was", "mich", "noch", "ret\u00b7ten", "kann", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PIS", "$,", "PWS", "PPER", "ADV", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "\u00bbder Tod,\u00ab sprachs Heimweh schnell bereit,", "tokens": ["\u00bb", "der", "Tod", ",", "\u00ab", "sprachs", "Heim\u00b7weh", "schnell", "be\u00b7reit", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "$(", "ADJA", "NN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdoch dazu hast du stets noch Zeit,", "tokens": ["\u00bb", "doch", "da\u00b7zu", "hast", "du", "stets", "noch", "Zeit", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PAV", "VAFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Lebst du, so mu\u00dft du s\u00fcndigen", "tokens": ["Lebst", "du", ",", "so", "mu\u00dft", "du", "s\u00fcn\u00b7di\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Oder dem Leben k\u00fcndigen.\u00ab", "tokens": ["O\u00b7der", "dem", "Le\u00b7ben", "k\u00fcn\u00b7di\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.24": {"line.1": {"text": "O Gott, wer h\u00e4tte das gedacht,", "tokens": ["O", "Gott", ",", "wer", "h\u00e4t\u00b7te", "das", "ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWS", "VAFIN", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Liebe mich zum Zwilling macht!", "tokens": ["Da\u00df", "Lie\u00b7be", "mich", "zum", "Zwil\u00b7ling", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Ich f\u00fcrchte mich vor Schuldgewicht,", "tokens": ["Ich", "f\u00fcrch\u00b7te", "mich", "vor", "Schuld\u00b7ge\u00b7wicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch sterben m\u00f6cht' ich auch noch nicht.", "tokens": ["Doch", "ster\u00b7ben", "m\u00f6cht'", "ich", "auch", "noch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Nun wu\u00dfte ich es wieder klar,", "tokens": ["Nun", "wu\u00df\u00b7te", "ich", "es", "wie\u00b7der", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weshalb ich unterwegs stets war.", "tokens": ["We\u00b7shalb", "ich", "un\u00b7ter\u00b7wegs", "stets", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Sehnsucht ist heimlich wie die Laus,", "tokens": ["Sehn\u00b7sucht", "ist", "heim\u00b7lich", "wie", "die", "Laus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem schwarzen Mohrle wich ich aus.", "tokens": ["Dem", "schwar\u00b7zen", "Mohr\u00b7le", "wich", "ich", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Sie sitzt im Pelz mir wie die Motten", "tokens": ["Sie", "sitzt", "im", "Pelz", "mir", "wie", "die", "Mot\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPER", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ist nicht mehr dort auszurotten.", "tokens": ["Und", "ist", "nicht", "mehr", "dort", "aus\u00b7zu\u00b7rot\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Wie Klimafieber sie mich plagt,", "tokens": ["Wie", "Kli\u00b7ma\u00b7fie\u00b7ber", "sie", "mich", "plagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seit \u00bbgl\u00fccklich bin ich\u00ab ich gesagt.", "tokens": ["Seit", "\u00bb", "gl\u00fcck\u00b7lich", "bin", "ich", "\u00ab", "ich", "ge\u00b7sagt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "$(", "ADJD", "VAFIN", "PPER", "$(", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Gl\u00fcck sollte man nie laut gestehn,", "tokens": ["Gl\u00fcck", "soll\u00b7te", "man", "nie", "laut", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann ist ein Ungl\u00fcck schon geschehn,", "tokens": ["Dann", "ist", "ein", "Un\u00b7gl\u00fcck", "schon", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Ausspucken soll man schnell dabei,", "tokens": ["Aus\u00b7spu\u00b7cken", "soll", "man", "schnell", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil sonst das Gl\u00fcck zum Teufel sei.", "tokens": ["Weil", "sonst", "das", "Gl\u00fcck", "zum", "Teu\u00b7fel", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Zu spucken hatt' ich ganz vergessen,", "tokens": ["Zu", "spu\u00b7cken", "hatt'", "ich", "ganz", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da jene Dame nahgesessen.", "tokens": ["Da", "je\u00b7ne", "Da\u00b7me", "nah\u00b7ge\u00b7ses\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Was fang' mit jener Lieb' ich an,", "tokens": ["Was", "fang'", "mit", "je\u00b7ner", "Lieb'", "ich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PDAT", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sich legitimieren kann?", "tokens": ["Die", "sich", "le\u00b7gi\u00b7ti\u00b7mie\u00b7ren", "kann", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Denn einstmals, als es niemand sah,", "tokens": ["Denn", "einst\u00b7mals", ",", "als", "es", "nie\u00b7mand", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ging ich heimlich zur Gro\u00dfmama,", "tokens": ["Ging", "ich", "heim\u00b7lich", "zur", "Gro\u00df\u00b7ma\u00b7ma", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.35": {"line.1": {"text": "Blitzschnell ich meine Lieb' gestand", "tokens": ["Blitz\u00b7schnell", "ich", "mei\u00b7ne", "Lieb'", "ge\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPOSAT", "NN", "VVFIN"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bat um Mohrles Kinderhand.", "tokens": ["Und", "bat", "um", "Mohr\u00b7les", "Kin\u00b7der\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "War \u00dcbermensch damals noch nicht", "tokens": ["War", "\u00dc\u00b7ber\u00b7mensch", "da\u00b7mals", "noch", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "ADV", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nur symbolisch ein Gesicht,", "tokens": ["Und", "nur", "sym\u00b7bo\u00b7lisch", "ein", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Hatt' sch\u00f6ne Z\u00e4hn' und sonst nichts mehr,", "tokens": ["Hatt'", "sch\u00f6\u00b7ne", "Z\u00e4hn'", "und", "sonst", "nichts", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "KON", "ADV", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ist nicht viel, liebt man auch sehr.", "tokens": ["Das", "ist", "nicht", "viel", ",", "liebt", "man", "auch", "sehr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADV", "$,", "VVFIN", "PIS", "ADV", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.38": {"line.1": {"text": "Gro\u00dfmutter kratzte ihre Warze,", "tokens": ["Gro\u00df\u00b7mut\u00b7ter", "kratz\u00b7te", "ih\u00b7re", "War\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zerschnitt die Lieb' als strenge Parze.", "tokens": ["Zer\u00b7schnitt", "die", "Lieb'", "als", "stren\u00b7ge", "Par\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KOUS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Nie ganz mein Herz vom Mohrle wich,", "tokens": ["Nie", "ganz", "mein", "Herz", "vom", "Mohr\u00b7le", "wich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sahn uns \u00f6fter innerlich,", "tokens": ["Wir", "sahn", "uns", "\u00f6f\u00b7ter", "in\u00b7ner\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Doch hatt' ich sie vergessen schier,", "tokens": ["Doch", "hatt'", "ich", "sie", "ver\u00b7ges\u00b7sen", "schier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "VVPP", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis sie leibhaftig stand vor mir", "tokens": ["Bis", "sie", "leib\u00b7haf\u00b7tig", "stand", "vor", "mir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "APPR", "PPER"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.41": {"line.1": {"text": "Und fragte, ob ich gl\u00fccklich bin.", "tokens": ["Und", "frag\u00b7te", ",", "ob", "ich", "gl\u00fcck\u00b7lich", "bin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wei\u00df jetzt vor Ungl\u00fcck nicht, wohin.", "tokens": ["Wei\u00df", "jetzt", "vor", "Un\u00b7gl\u00fcck", "nicht", ",", "wo\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "PTKNEG", "$,", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Heimat schien mir ein Deckelhaus,", "tokens": ["Hei\u00b7mat", "schien", "mir", "ein", "De\u00b7ckel\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Dr\u00fcckt man daran, sprang's Mohrle 'raus.", "tokens": ["Dr\u00fcckt", "man", "da\u00b7ran", ",", "sprang's", "Mohr\u00b7le", "'raus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PAV", "$,", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "O Mohrle mit dem Mohrenkopf,", "tokens": ["O", "Mohr\u00b7le", "mit", "dem", "Moh\u00b7ren\u00b7kopf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du machst mich noch zum S\u00fcndentropf!", "tokens": ["Du", "machst", "mich", "noch", "zum", "S\u00fcn\u00b7den\u00b7tropf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Seufzend fuhr ich zum Mittelmeer,", "tokens": ["Seuf\u00b7zend", "fuhr", "ich", "zum", "Mit\u00b7tel\u00b7meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Der Mond schwamm feurig nebenher,", "tokens": ["Der", "Mond", "schwamm", "feu\u00b7rig", "ne\u00b7ben\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADV", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.45": {"line.1": {"text": "Ganz afrikanisch roch die Luft,", "tokens": ["Ganz", "af\u00b7ri\u00b7ka\u00b7nisch", "roch", "die", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mond schien eine helle Gruft,", "tokens": ["Der", "Mond", "schien", "ei\u00b7ne", "hel\u00b7le", "Gruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Sah wie der Feuerofen aus", "tokens": ["Sah", "wie", "der", "Feu\u00b7er\u00b7o\u00b7fen", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In einem Krematoriumhaus.", "tokens": ["In", "ei\u00b7nem", "Kre\u00b7ma\u00b7to\u00b7ri\u00b7um\u00b7haus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.47": {"line.1": {"text": "Bald, dacht' ich, schiebt man mich hinein,", "tokens": ["Bald", ",", "dacht'", "ich", ",", "schiebt", "man", "mich", "hin\u00b7ein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PIS", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nein, bat ich, ich will S\u00fcnder sein,", "tokens": ["Nein", ",", "bat", "ich", ",", "ich", "will", "S\u00fcn\u00b7der", "sein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "PPER", "VMFIN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Will mich als S\u00fcnder k\u00fcnftig geben", "tokens": ["Will", "mich", "als", "S\u00fcn\u00b7der", "k\u00fcnf\u00b7tig", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und nicht so jung vom Sterben leben.", "tokens": ["Und", "nicht", "so", "jung", "vom", "Ster\u00b7ben", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Doch fiel manch' Regen noch herab,", "tokens": ["Doch", "fiel", "man\u00b7ch'", "Re\u00b7gen", "noch", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "ADV", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und nicht so schnell ich mich ergab.", "tokens": ["Und", "nicht", "so", "schnell", "ich", "mich", "er\u00b7gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADJD", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Ich suchte noch in Griechenland,", "tokens": ["Ich", "such\u00b7te", "noch", "in", "Grie\u00b7chen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob ich Ruh' vor Frau S\u00fcnde fand.", "tokens": ["Ob", "ich", "Ruh'", "vor", "Frau", "S\u00fcn\u00b7de", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "APPR", "NN", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.51": {"line.1": {"text": "Nah bei Athen am Hymettos,", "tokens": ["Nah", "bei", "A\u00b7then", "am", "Hy\u00b7met\u00b7tos", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Dacht' ich, liegt mir ein Klosterschlo\u00df,", "tokens": ["Dacht'", "ich", ",", "liegt", "mir", "ein", "Klos\u00b7ter\u00b7schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.52": {"line.1": {"text": "Zerschossen sind dort Deck' und Dielen,", "tokens": ["Zer\u00b7schos\u00b7sen", "sind", "dort", "Deck'", "und", "Die\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort nehm' ich R\u00e4uber zu Gespielen.", "tokens": ["Dort", "nehm'", "ich", "R\u00e4u\u00b7ber", "zu", "Ge\u00b7spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Ich hause in dem alten Bau,", "tokens": ["Ich", "hau\u00b7se", "in", "dem", "al\u00b7ten", "Bau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kaffee kocht mir die R\u00e4uberfrau,", "tokens": ["Kaf\u00b7fee", "kocht", "mir", "die", "R\u00e4u\u00b7ber\u00b7frau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.54": {"line.1": {"text": "In Fallen fang' ich Eulen ein,", "tokens": ["In", "Fal\u00b7len", "fang'", "ich", "Eu\u00b7len", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die trag' ich nach Athen hinein.", "tokens": ["Die", "trag'", "ich", "nach", "A\u00b7then", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.55": {"line.1": {"text": "Denn scheinst du dort nichts auszugeben,", "tokens": ["Denn", "scheinst", "du", "dort", "nichts", "aus\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nur dann lassen dich R\u00e4uber leben.", "tokens": ["Nur", "dann", "las\u00b7sen", "dich", "R\u00e4u\u00b7ber", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.56": {"line.1": {"text": "Und nachts, wenn ich nicht schlafen kann,", "tokens": ["Und", "nachts", ",", "wenn", "ich", "nicht", "schla\u00b7fen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00f6r' ich R\u00e4ubergeschichten an.", "tokens": ["H\u00f6r'", "ich", "R\u00e4u\u00b7ber\u00b7ge\u00b7schich\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.57": {"line.1": {"text": "Am Tag schreib' ich Frau K\u00f6nigin,", "tokens": ["Am", "Tag", "schreib'", "ich", "Frau", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ausgemacht ich S\u00fcnder bin,", "tokens": ["Da\u00df", "aus\u00b7ge\u00b7macht", "ich", "S\u00fcn\u00b7der", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVPP", "PPER", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "F\u00fcr sie sei wert ich keinen Zoll,", "tokens": ["F\u00fcr", "sie", "sei", "wert", "ich", "kei\u00b7nen", "Zoll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sie mich nicht ersehnen soll.", "tokens": ["Und", "sie", "mich", "nicht", "er\u00b7seh\u00b7nen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Das Kloster fand ich wie gedacht,", "tokens": ["Das", "Klos\u00b7ter", "fand", "ich", "wie", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch war zu teuer mir die Pacht,", "tokens": ["Doch", "war", "zu", "teu\u00b7er", "mir", "die", "Pacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKA", "ADJD", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Und W\u00e4scherinnen lebten dort,", "tokens": ["Und", "W\u00e4\u00b7sche\u00b7rin\u00b7nen", "leb\u00b7ten", "dort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die schnatterten in einem fort.", "tokens": ["Die", "schnat\u00b7ter\u00b7ten", "in", "ei\u00b7nem", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Ich war gelandet bei Athen,", "tokens": ["Ich", "war", "ge\u00b7lan\u00b7det", "bei", "A\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Drau\u00dfen, wo keine Tempel stehn,", "tokens": ["Drau\u00b7\u00dfen", ",", "wo", "kei\u00b7ne", "Tem\u00b7pel", "stehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PIAT", "NN", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.62": {"line.1": {"text": "Doch feierlich war's mir im Herzen,", "tokens": ["Doch", "fei\u00b7er\u00b7lich", "wa\u00b7r's", "mir", "im", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als st\u00fcnd' das Land voll R\u00e4ucherkerzen.", "tokens": ["Als", "st\u00fcnd'", "das", "Land", "voll", "R\u00e4u\u00b7cher\u00b7ker\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "An Venus\u00e4pfeln war nicht Not,", "tokens": ["An", "Ve\u00b7nus\u00b7\u00e4p\u00b7feln", "war", "nicht", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Hafen lag voll Boot bei Boot.", "tokens": ["Im", "Ha\u00b7fen", "lag", "voll", "Boot", "bei", "Boot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADJD", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Ich mu\u00dfte an den Paris denken,", "tokens": ["Ich", "mu\u00df\u00b7te", "an", "den", "Pa\u00b7ris", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schwer ist's, G\u00f6ttinnen nicht zu kr\u00e4nken.", "tokens": ["Schwer", "ist's", ",", "G\u00f6t\u00b7tin\u00b7nen", "nicht", "zu", "kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.65": {"line.1": {"text": "Prachtvoll wie wei\u00dfe Heidenfrauen,", "tokens": ["Pracht\u00b7voll", "wie", "wei\u00b7\u00dfe", "Hei\u00b7den\u00b7frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Waren die Tempel anzuschauen,", "tokens": ["Wa\u00b7ren", "die", "Tem\u00b7pel", "an\u00b7zu\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVIZU", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.66": {"line.1": {"text": "Doch fremd f\u00fchlt ich auch hier mich wieder:", "tokens": ["Doch", "fremd", "f\u00fchlt", "ich", "auch", "hier", "mich", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "ADV", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hatten keine Heimatglieder.", "tokens": ["Sie", "hat\u00b7ten", "kei\u00b7ne", "Hei\u00b7mat\u00b7glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Sie sind nur edel anzusehen,", "tokens": ["Sie", "sind", "nur", "e\u00b7del", "an\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man kommt zu ihnen auf den Zehen,", "tokens": ["Man", "kommt", "zu", "ih\u00b7nen", "auf", "den", "Ze\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Und auf den Zehen schlich ich weiter,", "tokens": ["Und", "auf", "den", "Ze\u00b7hen", "schlich", "ich", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Heimweh blieb die Himmelsleiter.", "tokens": ["Und", "Heim\u00b7weh", "blieb", "die", "Him\u00b7mels\u00b7lei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Vor den Theatern blieb ich stehn,", "tokens": ["Vor", "den", "The\u00b7a\u00b7tern", "blieb", "ich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ohne Dach zum Himmel sehn;", "tokens": ["Die", "oh\u00b7ne", "Dach", "zum", "Him\u00b7mel", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Einst spielte man bei sch\u00f6nem Wetter", "tokens": ["Einst", "spiel\u00b7te", "man", "bei", "sch\u00f6\u00b7nem", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mehr f\u00fcr den Himmel und die G\u00f6tter.", "tokens": ["Mehr", "f\u00fcr", "den", "Him\u00b7mel", "und", "die", "G\u00f6t\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "In Logen, in kornblumenblauen,", "tokens": ["In", "Lo\u00b7gen", ",", "in", "korn\u00b7blu\u00b7men\u00b7blau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sa\u00df da der Gott mit G\u00f6tterfrauen,", "tokens": ["Sa\u00df", "da", "der", "Gott", "mit", "G\u00f6t\u00b7ter\u00b7frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.72": {"line.1": {"text": "Sah auf die Menschenp\u00fcpplein hin,", "tokens": ["Sah", "auf", "die", "Men\u00b7schen\u00b7p\u00fcpp\u00b7lein", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denen er seinen Geist verliehn.", "tokens": ["De\u00b7nen", "er", "sei\u00b7nen", "Geist", "ver\u00b7liehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.73": {"line.1": {"text": "Und wie der Gott im Blau auch hei\u00dft,", "tokens": ["Und", "wie", "der", "Gott", "im", "Blau", "auch", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPRART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch mir verlieh er seinen Geist,", "tokens": ["Auch", "mir", "ver\u00b7lieh", "er", "sei\u00b7nen", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Er tat auch manche G\u00f6ttin rauben.", "tokens": ["Er", "tat", "auch", "man\u00b7che", "G\u00f6t\u00b7tin", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist Lieb' dabei, tut er's erlauben.", "tokens": ["Ist", "Lieb'", "da\u00b7bei", ",", "tut", "er's", "er\u00b7lau\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PAV", "$,", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.75": {"line.1": {"text": "Und auf den Zehen schlich ich weiter,", "tokens": ["Und", "auf", "den", "Ze\u00b7hen", "schlich", "ich", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stets schleppend an der Himmelsleiter.", "tokens": ["Stets", "schlep\u00b7pend", "an", "der", "Him\u00b7mels\u00b7lei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "Der Marmor der Akropolis", "tokens": ["Der", "Mar\u00b7mor", "der", "Ak\u00b7ro\u00b7po\u00b7lis"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hoch k\u00f6niglich sich sehen lie\u00df,", "tokens": ["Hoch", "k\u00f6\u00b7nig\u00b7lich", "sich", "se\u00b7hen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "PRF", "VVINF", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.77": {"line.1": {"text": "Des Tempels heller Wunderbau,", "tokens": ["Des", "Tem\u00b7pels", "hel\u00b7ler", "Wun\u00b7der\u00b7bau", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gemahnte mich an meine Frau.", "tokens": ["Ge\u00b7mahn\u00b7te", "mich", "an", "mei\u00b7ne", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Vom Berg f\u00e4llt seine Marmorschleppe,", "tokens": ["Vom", "Berg", "f\u00e4llt", "sei\u00b7ne", "Mar\u00b7mor\u00b7schlep\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ehrf\u00fcrchtig trat ich auf die Treppe.", "tokens": ["Ehr\u00b7f\u00fcrch\u00b7tig", "trat", "ich", "auf", "die", "Trep\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Er deutet auf Gebirg und Meer,", "tokens": ["Er", "deu\u00b7tet", "auf", "Ge\u00b7birg", "und", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gibt die Welt verschwendend her,", "tokens": ["Und", "gibt", "die", "Welt", "ver\u00b7schwen\u00b7dend", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Und sinkt man an sein Antlitz nieder,", "tokens": ["Und", "sinkt", "man", "an", "sein", "Ant\u00b7litz", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "M\u00f6chte man nie zur Erde wieder.", "tokens": ["M\u00f6ch\u00b7te", "man", "nie", "zur", "Er\u00b7de", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "APPRART", "NN", "ADV", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.81": {"line.1": {"text": "Ein Schluchzen steckte mir im Hals,", "tokens": ["Ein", "Schluch\u00b7zen", "steck\u00b7te", "mir", "im", "Hals", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tempel schien mir wie aus Salz,", "tokens": ["Der", "Tem\u00b7pel", "schien", "mir", "wie", "aus", "Salz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KOKOM", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "Aus Tr\u00e4nen schien er steif geweint,", "tokens": ["Aus", "Tr\u00e4\u00b7nen", "schien", "er", "steif", "ge\u00b7weint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "All Leid der Welt in ihm vereint.", "tokens": ["All", "Leid", "der", "Welt", "in", "ihm", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Er sah so bitter auf mich nieder,", "tokens": ["Er", "sah", "so", "bit\u00b7ter", "auf", "mich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und heimlich schlich ich weiter wieder", "tokens": ["Und", "heim\u00b7lich", "schlich", "ich", "wei\u00b7ter", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Da festlich bei dem Stadtgedr\u00e4nge", "tokens": ["Da", "fest\u00b7lich", "bei", "dem", "Stadt\u00b7ge\u00b7dr\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Trat froh ein Tempel aus der Enge,", "tokens": ["Trat", "froh", "ein", "Tem\u00b7pel", "aus", "der", "En\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.85": {"line.1": {"text": "Hat wie ein Tanz irdisch erfreut,", "tokens": ["Hat", "wie", "ein", "Tanz", "ir\u00b7disch", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und keinem Gott war er geweiht,", "tokens": ["Und", "kei\u00b7nem", "Gott", "war", "er", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.86": {"line.1": {"text": "Trug einen Helden nur im Sinn:", "tokens": ["Trug", "ei\u00b7nen", "Hel\u00b7den", "nur", "im", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Theseus gab er stets sich hin.", "tokens": ["Dem", "The\u00b7seus", "gab", "er", "stets", "sich", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.87": {"line.1": {"text": "Irdisch vertraulich war er mir,", "tokens": ["Ir\u00b7disch", "ver\u00b7trau\u00b7lich", "war", "er", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "PPER", "PPER", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wie Chopin am Salonklavier.", "tokens": ["Wie", "Cho\u00b7pin", "am", "Sa\u00b7lon\u00b7kla\u00b7vier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Die Marmors\u00e4ulen und die Pforten", "tokens": ["Die", "Mar\u00b7mor\u00b7s\u00e4u\u00b7len", "und", "die", "Pfor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schienen wie Kerzen gelb geworden,", "tokens": ["Schie\u00b7nen", "wie", "Ker\u00b7zen", "gelb", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "NN", "ADJD", "VAPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.89": {"line.1": {"text": "Schon morgens sah das ganze Haus", "tokens": ["Schon", "mor\u00b7gens", "sah", "das", "gan\u00b7ze", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Abendsonne festlich aus.", "tokens": ["Wie", "A\u00b7bend\u00b7son\u00b7ne", "fest\u00b7lich", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.90": {"line.1": {"text": "Der Tempel, dacht' ich, da vor dir", "tokens": ["Der", "Tem\u00b7pel", ",", "dacht'", "ich", ",", "da", "vor", "dir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "KOUS", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Scheint wie des Mohrles Seele schier,", "tokens": ["Scheint", "wie", "des", "Mohr\u00b7les", "See\u00b7le", "schier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.91": {"line.1": {"text": "Voll Spiel steckt sie schlafend und wach", "tokens": ["Voll", "Spiel", "steckt", "sie", "schla\u00b7fend", "und", "wach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "VVFIN", "PPER", "ADJD", "KON", "XY"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Und steckt voll Tanz bis unters Dach.", "tokens": ["Und", "steckt", "voll", "Tanz", "bis", "un\u00b7ters", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.92": {"line.1": {"text": "Wie Amor in dem Heimatschlo\u00df,", "tokens": ["Wie", "A\u00b7mor", "in", "dem", "Hei\u00b7mat\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wuchs sie als Amorette gro\u00df.", "tokens": ["Wuchs", "sie", "als", "A\u00b7mo\u00b7ret\u00b7te", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KOUS", "NE", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.93": {"line.1": {"text": "Das Mohrle l\u00e4\u00dft dir keine Ruh,", "tokens": ["Das", "Mohr\u00b7le", "l\u00e4\u00dft", "dir", "kei\u00b7ne", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kehr' um und klapp den Koffer zu.", "tokens": ["Kehr'", "um", "und", "klapp", "den", "Kof\u00b7fer", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.94": {"line.1": {"text": "Ein Platz jedoch noch zu sich lockte,", "tokens": ["Ein", "Platz", "je\u00b7doch", "noch", "zu", "sich", "lock\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Es war dort, wo die Pythia hockte.", "tokens": ["Es", "war", "dort", ",", "wo", "die", "Py\u00b7thia", "hock\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.95": {"line.1": {"text": "Nach Delphi wollt' ich gl\u00e4ubig noch,", "tokens": ["Nach", "Del\u00b7phi", "wollt'", "ich", "gl\u00e4u\u00b7big", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VMFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Erde Nabel ist das doch,", "tokens": ["Der", "Er\u00b7de", "Na\u00b7bel", "ist", "das", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PDS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.96": {"line.1": {"text": "Dort, wo man seine Zukunft sah", "tokens": ["Dort", ",", "wo", "man", "sei\u00b7ne", "Zu\u00b7kunft", "sah"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PIS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und unerwartet nichts geschah.", "tokens": ["Und", "un\u00b7er\u00b7war\u00b7tet", "nichts", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.97": {"line.1": {"text": "Itea hie\u00df die Schiffstation,", "tokens": ["I\u00b7tea", "hie\u00df", "die", "Schiff\u00b7sta\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Es wartete ein Maultier schon,", "tokens": ["Es", "war\u00b7te\u00b7te", "ein", "Maul\u00b7tier", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Auf heil'ger Stra\u00dfe, jetzt ganz leer,", "tokens": ["Auf", "heil'\u00b7ger", "Stra\u00b7\u00dfe", ",", "jetzt", "ganz", "leer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lief nur des Esels Schatten her.", "tokens": ["Lief", "nur", "des", "E\u00b7sels", "Schat\u00b7ten", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.99": {"line.1": {"text": "Durch \u00d6lwald ging's bergauf, bergab,", "tokens": ["Durch", "\u00d6l\u00b7wald", "ging's", "ber\u00b7gauf", ",", "berg\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PTKVZ", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von oben sieht man dann hinab.", "tokens": ["Von", "o\u00b7ben", "sieht", "man", "dann", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.100": {"line.1": {"text": "Eiskalt kam es aus Felsenspalten,", "tokens": ["Eis\u00b7kalt", "kam", "es", "aus", "Fel\u00b7sen\u00b7spal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Mein Fell zog sich in G\u00e4nsefalten,", "tokens": ["Mein", "Fell", "zog", "sich", "in", "G\u00e4n\u00b7se\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.101": {"line.1": {"text": "Heilige Quellen, stark versumpft,", "tokens": ["Hei\u00b7li\u00b7ge", "Quel\u00b7len", ",", "stark", "ver\u00b7sumpft", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Weinten wie Weiber eingeschrumpft,", "tokens": ["Wein\u00b7ten", "wie", "Wei\u00b7ber", "ein\u00b7ge\u00b7schrumpft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.102": {"line.1": {"text": "Und Wolken stets die Welt verschoben,", "tokens": ["Und", "Wol\u00b7ken", "stets", "die", "Welt", "ver\u00b7scho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man war nicht unten und nicht oben.", "tokens": ["Man", "war", "nicht", "un\u00b7ten", "und", "nicht", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKNEG", "ADV", "KON", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.103": {"line.1": {"text": "In Kl\u00fcften ward das Echo wach,", "tokens": ["In", "Kl\u00fcf\u00b7ten", "ward", "das", "E\u00b7cho", "wach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dachtest du laut nur etwas nach,", "tokens": ["Dach\u00b7test", "du", "laut", "nur", "et\u00b7was", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADV", "PIS", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.104": {"line.1": {"text": "Und Delphi, das einst sch\u00f6n gebaut,", "tokens": ["Und", "Del\u00b7phi", ",", "das", "einst", "sch\u00f6n", "ge\u00b7baut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "PRELS", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lag wild, als ob man Marmor kaut.", "tokens": ["Lag", "wild", ",", "als", "ob", "man", "Mar\u00b7mor", "kaut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "KOKOM", "KOUS", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.105": {"line.1": {"text": "Niemand wohnt mehr auf den Ruinen,", "tokens": ["Nie\u00b7mand", "wohnt", "mehr", "auf", "den", "Ru\u00b7i\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Nur Hirten, die den Schafen dienen.", "tokens": ["Nur", "Hir\u00b7ten", ",", "die", "den", "Scha\u00b7fen", "die\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.106": {"line.1": {"text": "Ich stieg auf S\u00e4ulen wie Skelette", "tokens": ["Ich", "stieg", "auf", "S\u00e4u\u00b7len", "wie", "Ske\u00b7let\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KOKOM", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und lief im Stadion um die Wette,", "tokens": ["Und", "lief", "im", "Sta\u00b7di\u00b7on", "um", "die", "Wet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.107": {"line.1": {"text": "Lief ganz allein dort in der Bahn", "tokens": ["Lief", "ganz", "al\u00b7lein", "dort", "in", "der", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Und kam zuerst als Sieger an.", "tokens": ["Und", "kam", "zu\u00b7erst", "als", "Sie\u00b7ger", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.108": {"line.1": {"text": "Sage: zuerst, denn nebenbei", "tokens": ["Sa\u00b7ge", ":", "zu\u00b7erst", ",", "denn", "ne\u00b7ben\u00b7bei"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$.", "ADV", "$,", "KON", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Liefen pl\u00f6tzlich der Schatten drei,", "tokens": ["Lie\u00b7fen", "pl\u00f6tz\u00b7lich", "der", "Schat\u00b7ten", "drei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "NN", "CARD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.109": {"line.1": {"text": "Und rennt mein Schatten noch mit zwein,", "tokens": ["Und", "rennt", "mein", "Schat\u00b7ten", "noch", "mit", "zwein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "M\u00fcssen bei Schatten Menschen sein.", "tokens": ["M\u00fcs\u00b7sen", "bei", "Schat\u00b7ten", "Men\u00b7schen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "NN", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.110": {"line.1": {"text": "Suchend schaut ich am Ziel mich um,", "tokens": ["Su\u00b7chend", "schaut", "ich", "am", "Ziel", "mich", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPRART", "NN", "PPER", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Doch blieb mein Auge suchend dumm.", "tokens": ["Doch", "blieb", "mein", "Au\u00b7ge", "su\u00b7chend", "dumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.111": {"line.1": {"text": "Nachts erst, wo ich im Bett wach lag,", "tokens": ["Nachts", "erst", ",", "wo", "ich", "im", "Bett", "wach", "lag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "PPER", "APPRART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wurde mir im Mondschein Tag.", "tokens": ["Da", "wur\u00b7de", "mir", "im", "Mond\u00b7schein", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.112": {"line.1": {"text": "Die Fenster standen aufgerissen,", "tokens": ["Die", "Fens\u00b7ter", "stan\u00b7den", "auf\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mond schien wie ein fremd Gewissen,", "tokens": ["Der", "Mond", "schien", "wie", "ein", "fremd", "Ge\u00b7wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ART", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.113": {"line.1": {"text": "Pythia sa\u00df nackt auf dem Mondstein,", "tokens": ["Py\u00b7thia", "sa\u00df", "nackt", "auf", "dem", "Mond\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Sprach laut und deutlich auf mich ein:", "tokens": ["Sprach", "laut", "und", "deut\u00b7lich", "auf", "mich", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.114": {"line.1": {"text": "\u00bbim Herzen tr\u00e4gst du zwei als Beute,", "tokens": ["\u00bb", "im", "Her\u00b7zen", "tr\u00e4gst", "du", "zwei", "als", "Beu\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "VVFIN", "PPER", "CARD", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihre Schatten sahst du heute.\u00ab", "tokens": ["Und", "ih\u00b7re", "Schat\u00b7ten", "sahst", "du", "heu\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.115": {"line.1": {"text": "Ich rief: \u00bbAch, da\u00df ich Ruhe finde!\u00ab", "tokens": ["Ich", "rief", ":", "\u00bb", "Ach", ",", "da\u00df", "ich", "Ru\u00b7he", "fin\u00b7de", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ITJ", "$,", "KOUS", "PPER", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sprach: \u00bbErl\u00f6send wirkt die S\u00fcnde.\u00ab", "tokens": ["Sie", "sprach", ":", "\u00bb", "Er\u00b7l\u00f6\u00b7send", "wirkt", "die", "S\u00fcn\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VVPP", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.116": {"line.1": {"text": "Sie zog verkl\u00e4rt ihr Hemd sich an,", "tokens": ["Sie", "zog", "ver\u00b7kl\u00e4rt", "ihr", "Hemd", "sich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPOSAT", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mond in D\u00e4mpfen dann zerrann.", "tokens": ["Der", "Mond", "in", "D\u00e4mp\u00b7fen", "dann", "zer\u00b7rann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.117": {"line.1": {"text": "Der Erde Nabel grunzte nach:", "tokens": ["Der", "Er\u00b7de", "Na\u00b7bel", "grunz\u00b7te", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbs\u00fcndigen sollst du ohne Ach.\u00ab", "tokens": ["\u00bb", "s\u00fcn\u00b7di\u00b7gen", "sollst", "du", "oh\u00b7ne", "Ach", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVINF", "VMFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.118": {"line.1": {"text": "Ich hab die Fenster zugeschmissen,", "tokens": ["Ich", "hab", "die", "Fens\u00b7ter", "zu\u00b7ge\u00b7schmis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warf mich verr\u00fcckt in meine Kissen.", "tokens": ["Warf", "mich", "ver\u00b7r\u00fcckt", "in", "mei\u00b7ne", "Kis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.119": {"line.1": {"text": "Nun wu\u00dft' ich, niemals halt ich Treu,", "tokens": ["Nun", "wu\u00dft'", "ich", ",", "nie\u00b7mals", "halt", "ich", "Treu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und vor der Tat kam schon die Reu.", "tokens": ["Und", "vor", "der", "Tat", "kam", "schon", "die", "Reu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADV", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.120": {"line.1": {"text": "Wollt' erst recht nicht zur Heimat gehn,", "tokens": ["Wollt'", "erst", "recht", "nicht", "zur", "Hei\u00b7mat", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PTKNEG", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil ich in Delphi hellgesehn.", "tokens": ["Weil", "ich", "in", "Del\u00b7phi", "hell\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.121": {"line.1": {"text": "Ich schlich mich in Arkadien ein,", "tokens": ["Ich", "schlich", "mich", "in", "Ar\u00b7ka\u00b7di\u00b7en", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wollte beim Pan ein Hirte sein.", "tokens": ["Woll\u00b7te", "beim", "Pan", "ein", "Hir\u00b7te", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "ART", "NN", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.122": {"line.1": {"text": "Fr\u00fchling spazierte durch die Au,", "tokens": ["Fr\u00fch\u00b7ling", "spa\u00b7zier\u00b7te", "durch", "die", "Au", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Hinterlie\u00df Blumen rot und blau,", "tokens": ["Hin\u00b7ter\u00b7lie\u00df", "Blu\u00b7men", "rot", "und", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.123": {"line.1": {"text": "Sch\u00f6n sa\u00df sich's bei antiken Quellen,", "tokens": ["Sch\u00f6n", "sa\u00df", "sich's", "bei", "an\u00b7ti\u00b7ken", "Quel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "H\u00f6rte den Pan am Mittag bellen,", "tokens": ["H\u00f6r\u00b7te", "den", "Pan", "am", "Mit\u00b7tag", "bel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.124": {"line.1": {"text": "Und sieht der Pan dich meckernd an,", "tokens": ["Und", "sieht", "der", "Pan", "dich", "me\u00b7ckernd", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wachsen auch H\u00f6rner jedem Mann.", "tokens": ["Wach\u00b7sen", "auch", "H\u00f6r\u00b7ner", "je\u00b7dem", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "PIAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.125": {"line.1": {"text": "So lag ich fauler als die Drohnen", "tokens": ["So", "lag", "ich", "fau\u00b7ler", "als", "die", "Droh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bei rot und blauen Anemonen,", "tokens": ["Bei", "rot", "und", "blau\u00b7en", "A\u00b7ne\u00b7mo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.126": {"line.1": {"text": "Und um mich Hirten wei\u00df in Fellen,", "tokens": ["Und", "um", "mich", "Hir\u00b7ten", "wei\u00df", "in", "Fel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUI", "PRF", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schafe hundert, und hundert Schellen.", "tokens": ["Scha\u00b7fe", "hun\u00b7dert", ",", "und", "hun\u00b7dert", "Schel\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "$,", "KON", "CARD", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.127": {"line.1": {"text": "Nah im gestorbnen Eichenhain", "tokens": ["Nah", "im", "ge\u00b7storb\u00b7nen", "Ei\u00b7chen\u00b7hain"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stand greis ein mager Tempelein.", "tokens": ["Stand", "greis", "ein", "ma\u00b7ger", "Tem\u00b7pe\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.128": {"line.1": {"text": "Pl\u00f6tzlich entfallen mir die Glieder,", "tokens": ["Pl\u00f6tz\u00b7lich", "ent\u00b7fal\u00b7len", "mir", "die", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Im Tempel tanzt ein fremder Widder,", "tokens": ["Im", "Tem\u00b7pel", "tanzt", "ein", "frem\u00b7der", "Wid\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.129": {"line.1": {"text": "Die Hirtenhunde querfeldein", "tokens": ["Die", "Hir\u00b7ten\u00b7hun\u00b7de", "quer\u00b7fel\u00b7dein"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ziehn rennend ihre Schw\u00e4nze ein;", "tokens": ["Ziehn", "ren\u00b7nend", "ih\u00b7re", "Schw\u00e4n\u00b7ze", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.130": {"line.1": {"text": "Die Schafe scheu zur Seite r\u00fccken", "tokens": ["Die", "Scha\u00b7fe", "scheu", "zur", "Sei\u00b7te", "r\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und tuen sich vor Schreck zerdr\u00fccken,", "tokens": ["Und", "tu\u00b7en", "sich", "vor", "Schreck", "zer\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.131": {"line.1": {"text": "Die ganze Landschaft meckert laut,", "tokens": ["Die", "gan\u00b7ze", "Land\u00b7schaft", "me\u00b7ckert", "laut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Haare sind mir fast ergraut,", "tokens": ["Die", "Haa\u00b7re", "sind", "mir", "fast", "er\u00b7graut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.132": {"line.1": {"text": "Mir war, als wenn die H\u00f6lle lachte", "tokens": ["Mir", "war", ",", "als", "wenn", "die", "H\u00f6l\u00b7le", "lach\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Satan schlechte Witze machte.", "tokens": ["Und", "Sa\u00b7tan", "schlech\u00b7te", "Wit\u00b7ze", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.133": {"line.1": {"text": "Sp\u00e4ter man mich ohnm\u00e4chtig fand,", "tokens": ["Sp\u00e4\u00b7ter", "man", "mich", "ohn\u00b7m\u00e4ch\u00b7tig", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "PRF", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Man sprach, es k\u00e4m vom Mittagsbrand.", "tokens": ["Man", "sprach", ",", "es", "k\u00e4m", "vom", "Mit\u00b7tags\u00b7brand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.134": {"line.1": {"text": "Doch Pan, er hatt' mich angesehn,", "tokens": ["Doch", "Pan", ",", "er", "hatt'", "mich", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und H\u00f6rner konnten jetzt entstehn,", "tokens": ["Und", "H\u00f6r\u00b7ner", "konn\u00b7ten", "jetzt", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.135": {"line.1": {"text": "Und warum sollten sie nicht kommen,", "tokens": ["Und", "wa\u00b7rum", "soll\u00b7ten", "sie", "nicht", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da ich mir Untreu vorgenommen.", "tokens": ["Da", "ich", "mir", "Un\u00b7treu", "vor\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.136": {"line.1": {"text": "Denn wo der Mann die Frau betr\u00fcgt,", "tokens": ["Denn", "wo", "der", "Mann", "die", "Frau", "be\u00b7tr\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Teufel leicht mit H\u00f6rnern pfl\u00fcgt.", "tokens": ["Der", "Teu\u00b7fel", "leicht", "mit", "H\u00f6r\u00b7nern", "pfl\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.137": {"line.1": {"text": "O Liebe, gro\u00dfes Fabeltier,", "tokens": ["O", "Lie\u00b7be", ",", "gro\u00b7\u00dfes", "Fa\u00b7bel\u00b7tier", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch deine H\u00f6rner w\u00fcnsch' ich mir,", "tokens": ["Auch", "dei\u00b7ne", "H\u00f6r\u00b7ner", "w\u00fcn\u00b7sch'", "ich", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.138": {"line.1": {"text": "Erleben will ich gr\u00fcndlich dich,", "tokens": ["Er\u00b7le\u00b7ben", "will", "ich", "gr\u00fcnd\u00b7lich", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor Unerlebtem f\u00fcrcht' ich mich!", "tokens": ["Vor", "Un\u00b7er\u00b7leb\u00b7tem", "f\u00fcrcht'", "ich", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.139": {"line.1": {"text": "Und jetzo will ich nicht verschnaufen", "tokens": ["Und", "jet\u00b7zo", "will", "ich", "nicht", "ver\u00b7schnau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und heute noch zum Mohrle laufen.", "tokens": ["Und", "heu\u00b7te", "noch", "zum", "Mohr\u00b7le", "lau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}