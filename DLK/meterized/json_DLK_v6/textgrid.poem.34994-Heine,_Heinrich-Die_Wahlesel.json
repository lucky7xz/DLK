{"textgrid.poem.34994": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Wahlesel", "genre": "verse", "period": "N.A.", "pub_year": 1852, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Freiheit hat man satt am End',", "tokens": ["Die", "Frei\u00b7heit", "hat", "man", "satt", "am", "End'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und die Republik der Tiere", "tokens": ["Und", "die", "Re\u00b7pub\u00b7lik", "der", "Tie\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Begehrte, da\u00df ein einz'ger Regent", "tokens": ["Be\u00b7gehr\u00b7te", ",", "da\u00df", "ein", "einz'\u00b7ger", "Re\u00b7gent"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie absolut regiere.", "tokens": ["Sie", "ab\u00b7so\u00b7lut", "re\u00b7gie\u00b7re", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Jedwede Tiergattung versammelte sich,", "tokens": ["Jed\u00b7we\u00b7de", "Tier\u00b7gat\u00b7tung", "ver\u00b7sam\u00b7mel\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "$,"], "meter": "+--++-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Wahlzettel wurden geschrieben;", "tokens": ["Wahl\u00b7zet\u00b7tel", "wur\u00b7den", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Parteisucht w\u00fctete f\u00fcrchterlich,", "tokens": ["Par\u00b7tei\u00b7sucht", "w\u00fc\u00b7te\u00b7te", "f\u00fcrch\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Intrigen wurden getrieben.", "tokens": ["Int\u00b7ri\u00b7gen", "wur\u00b7den", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.3": {"line.1": {"text": "Das Komitee der Esel ward", "tokens": ["Das", "Ko\u00b7mi\u00b7tee", "der", "E\u00b7sel", "ward"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Alt-Langohren regieret;", "tokens": ["Von", "Al\u00b7tLang\u00b7oh\u00b7ren", "re\u00b7gie\u00b7ret", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie hatten die K\u00f6pfe mit einer Kokard',", "tokens": ["Sie", "hat\u00b7ten", "die", "K\u00f6p\u00b7fe", "mit", "ei\u00b7ner", "Ko\u00b7kard'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Die schwarz-rot-gold, verzieret.", "tokens": ["Die", "schwa\u00b7rz\u00b7rot\u00b7gold", ",", "ver\u00b7zie\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Es gab eine kleine Pferdepartei,", "tokens": ["Es", "gab", "ei\u00b7ne", "klei\u00b7ne", "Pfer\u00b7de\u00b7par\u00b7tei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch wagte sie nicht zu stimmen;", "tokens": ["Doch", "wag\u00b7te", "sie", "nicht", "zu", "stim\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie hatte Angst vor dem Geschrei", "tokens": ["Sie", "hat\u00b7te", "Angst", "vor", "dem", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Alt-Langohren, der grimmen.", "tokens": ["Der", "Al\u00b7tLang\u00b7oh\u00b7ren", ",", "der", "grim\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Als einer jedoch die Kandidatur", "tokens": ["Als", "ei\u00b7ner", "je\u00b7doch", "die", "Kan\u00b7di\u00b7da\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADV", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Des Rosses empfahl, mit Zeter", "tokens": ["Des", "Ros\u00b7ses", "emp\u00b7fahl", ",", "mit", "Ze\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ein Alt-Langohr in die Rede ihm fuhr,", "tokens": ["Ein", "Al\u00b7tLang\u00b7ohr", "in", "die", "Re\u00b7de", "ihm", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Und schrie: \u00bbDu bist ein Verr\u00e4ter!", "tokens": ["Und", "schrie", ":", "\u00bb", "Du", "bist", "ein", "Ver\u00b7r\u00e4\u00b7ter", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Du bist ein Verr\u00e4ter, es flie\u00dft in dir", "tokens": ["Du", "bist", "ein", "Ver\u00b7r\u00e4\u00b7ter", ",", "es", "flie\u00dft", "in", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Kein Tropfen vom Eselsblute;", "tokens": ["Kein", "Trop\u00b7fen", "vom", "E\u00b7sels\u00b7blu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du bist kein Esel, ich glaube schier,", "tokens": ["Du", "bist", "kein", "E\u00b7sel", ",", "ich", "glau\u00b7be", "schier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Dich warf eine welsche Stute.", "tokens": ["Dich", "warf", "ei\u00b7ne", "wel\u00b7sche", "Stu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Du stammst vom Zebra vielleicht, die Haut,", "tokens": ["Du", "stammst", "vom", "Zeb\u00b7ra", "viel\u00b7leicht", ",", "die", "Haut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie ist gestreift zebr\u00e4isch;", "tokens": ["Sie", "ist", "ge\u00b7streift", "zeb\u00b7r\u00e4\u00b7isch", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auch deiner Stimme n\u00e4selnder Laut", "tokens": ["Auch", "dei\u00b7ner", "Stim\u00b7me", "n\u00e4\u00b7seln\u00b7der", "Laut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Klingt ziemlich \u00e4gyptisch-hebr\u00e4isch.", "tokens": ["Klingt", "ziem\u00b7lich", "\u00e4\u00b7gyp\u00b7tischhe\u00b7br\u00e4\u00b7isch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und w\u00e4rst du kein Fremdling, so bist du doch nur", "tokens": ["Und", "w\u00e4rst", "du", "kein", "Fremd\u00b7ling", ",", "so", "bist", "du", "doch", "nur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Verstandesesel, ein kalter;", "tokens": ["Ver\u00b7stan\u00b7de\u00b7se\u00b7sel", ",", "ein", "kal\u00b7ter", ";"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du kennst nicht die Tiefen der Eselsnatur,", "tokens": ["Du", "kennst", "nicht", "die", "Tie\u00b7fen", "der", "E\u00b7sels\u00b7na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dir klingt nicht ihr mystischer Psalter.", "tokens": ["Dir", "klingt", "nicht", "ihr", "mys\u00b7ti\u00b7scher", "Psal\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.9": {"line.1": {"text": "Ich aber versenkte die Seele ganz", "tokens": ["Ich", "a\u00b7ber", "ver\u00b7senk\u00b7te", "die", "See\u00b7le", "ganz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In jenes s\u00fc\u00dfe Ged\u00f6sel;", "tokens": ["In", "je\u00b7nes", "s\u00fc\u00b7\u00dfe", "Ge\u00b7d\u00f6\u00b7sel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich bin ein Esel, in meinem Schwanz", "tokens": ["Ich", "bin", "ein", "E\u00b7sel", ",", "in", "mei\u00b7nem", "Schwanz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist jedes Haar ein Esel.", "tokens": ["Ist", "je\u00b7des", "Haar", "ein", "E\u00b7sel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Ich bin kein R\u00f6mling, ich bin kein Slaw';", "tokens": ["Ich", "bin", "kein", "R\u00f6m\u00b7ling", ",", "ich", "bin", "kein", "Sla\u00b7w'", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein deutscher Esel bin ich,", "tokens": ["Ein", "deut\u00b7scher", "E\u00b7sel", "bin", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Gleich meinen V\u00e4tern. Sie waren so brav,", "tokens": ["Gleich", "mei\u00b7nen", "V\u00e4\u00b7tern", ".", "Sie", "wa\u00b7ren", "so", "brav", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So pflanzenw\u00fcchsig, so sinnig.", "tokens": ["So", "pflan\u00b7zen\u00b7w\u00fcch\u00b7sig", ",", "so", "sin\u00b7nig", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Sie spielten nicht mit Galanterei", "tokens": ["Sie", "spiel\u00b7ten", "nicht", "mit", "Ga\u00b7lan\u00b7te\u00b7rei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "NN"], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Frivole Lasterspiele;", "tokens": ["Fri\u00b7vo\u00b7le", "Las\u00b7ter\u00b7spie\u00b7le", ";"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie trabten t\u00e4glich, frisch-fromm-fr\u00f6hlich-frei,", "tokens": ["Sie", "trab\u00b7ten", "t\u00e4g\u00b7lich", ",", "frischfrom\u00b7mfr\u00f6h\u00b7lich\u00b7frei", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit ihren S\u00e4cken zur M\u00fchle.", "tokens": ["Mit", "ih\u00b7ren", "S\u00e4\u00b7cken", "zur", "M\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Die V\u00e4ter sind nicht tot! Im Grab", "tokens": ["Die", "V\u00e4\u00b7ter", "sind", "nicht", "tot", "!", "Im", "Grab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$.", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur ihre H\u00e4ute liegen,", "tokens": ["Nur", "ih\u00b7re", "H\u00e4u\u00b7te", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die sterblichen H\u00fcllen. Vom Himmel herab", "tokens": ["Die", "sterb\u00b7li\u00b7chen", "H\u00fcl\u00b7len", ".", "Vom", "Him\u00b7mel", "her\u00b7ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "APPRART", "NN", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Schaun sie auf uns mit Vergn\u00fcgen.", "tokens": ["Schaun", "sie", "auf", "uns", "mit", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Verkl\u00e4rte Esel im Glorialicht!", "tokens": ["Ver\u00b7kl\u00e4r\u00b7te", "E\u00b7sel", "im", "Glo\u00b7ri\u00b7a\u00b7licht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir wollen euch immer gleichen", "tokens": ["Wir", "wol\u00b7len", "euch", "im\u00b7mer", "glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und niemals von dem Pfad der Pflicht", "tokens": ["Und", "nie\u00b7mals", "von", "dem", "Pfad", "der", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur einen Fingerbreit weichen.", "tokens": ["Nur", "ei\u00b7nen", "Fin\u00b7ger\u00b7breit", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "O welche Wonne, ein Esel zu sein!", "tokens": ["O", "wel\u00b7che", "Won\u00b7ne", ",", "ein", "E\u00b7sel", "zu", "sein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAT", "NN", "$,", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Enkel von solchen Langohren!", "tokens": ["Ein", "En\u00b7kel", "von", "sol\u00b7chen", "Lan\u00b7goh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ich m\u00f6cht es von allen D\u00e4chern schrein:", "tokens": ["Ich", "m\u00f6cht", "es", "von", "al\u00b7len", "D\u00e4\u00b7chern", "schrein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich bin als ein Esel geboren.", "tokens": ["Ich", "bin", "als", "ein", "E\u00b7sel", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Der gro\u00dfe Esel, der mich erzeugt,", "tokens": ["Der", "gro\u00b7\u00dfe", "E\u00b7sel", ",", "der", "mich", "er\u00b7zeugt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er war von deutschem Stamme;", "tokens": ["Er", "war", "von", "deut\u00b7schem", "Stam\u00b7me", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit deutscher Eselsmilch ges\u00e4ugt", "tokens": ["Mit", "deut\u00b7scher", "E\u00b7sels\u00b7milch", "ge\u00b7s\u00e4ugt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat mich die Mutter, die Mamme.", "tokens": ["Hat", "mich", "die", "Mut\u00b7ter", ",", "die", "Mam\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Ich bin ein Esel, und will getreu,", "tokens": ["Ich", "bin", "ein", "E\u00b7sel", ",", "und", "will", "ge\u00b7treu", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KON", "VMFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie meine V\u00e4ter, die Alten,", "tokens": ["Wie", "mei\u00b7ne", "V\u00e4\u00b7ter", ",", "die", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "An der alten, lieben Eselei,", "tokens": ["An", "der", "al\u00b7ten", ",", "lie\u00b7ben", "E\u00b7se\u00b7lei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Am Eseltume halten.", "tokens": ["Am", "E\u00b7sel\u00b7tu\u00b7me", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Und weil ich ein Esel, so rat ich euch,", "tokens": ["Und", "weil", "ich", "ein", "E\u00b7sel", ",", "so", "rat", "ich", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Esel zum K\u00f6nig zu w\u00e4hlen;", "tokens": ["Den", "E\u00b7sel", "zum", "K\u00f6\u00b7nig", "zu", "w\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Wir stiften das gro\u00dfe Eselreich,", "tokens": ["Wir", "stif\u00b7ten", "das", "gro\u00b7\u00dfe", "E\u00b7sel\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wo nur die Esel befehlen.", "tokens": ["Wo", "nur", "die", "E\u00b7sel", "be\u00b7feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Wir alle sind Esel! I-A! I-A!", "tokens": ["Wir", "al\u00b7le", "sind", "E\u00b7sel", "!", "I\u00b7A", "!", "I\u00b7A", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "PIS", "VAFIN", "NN", "$.", "NE", "$.", "NE", "$."], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Wir sind keine Pferdeknechte.", "tokens": ["Wir", "sind", "kei\u00b7ne", "Pfer\u00b7de\u00b7knech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Fort mit den Rossen! Es lebe, hurra!", "tokens": ["Fort", "mit", "den", "Ros\u00b7sen", "!", "Es", "le\u00b7be", ",", "hur\u00b7ra", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "$,", "ITJ", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Der K\u00f6nig vom Eselsgeschlechte!\u00ab", "tokens": ["Der", "K\u00f6\u00b7nig", "vom", "E\u00b7sels\u00b7ge\u00b7schlech\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "So sprach der Patriot. Im Saal", "tokens": ["So", "sprach", "der", "Pat\u00b7ri\u00b7ot", ".", "Im", "Saal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Esel Beifall rufen.", "tokens": ["Die", "E\u00b7sel", "Bei\u00b7fall", "ru\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie waren alle national,", "tokens": ["Sie", "wa\u00b7ren", "al\u00b7le", "na\u00b7ti\u00b7o\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und stampften mit den Hufen.", "tokens": ["Und", "stampf\u00b7ten", "mit", "den", "Hu\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Sie haben des Redners Haupt geschm\u00fcckt", "tokens": ["Sie", "ha\u00b7ben", "des", "Red\u00b7ners", "Haupt", "ge\u00b7schm\u00fcckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "VVPP"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit einem Eichenkranze.", "tokens": ["Mit", "ei\u00b7nem", "Ei\u00b7chen\u00b7kran\u00b7ze", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er dankte stumm, und hochbegl\u00fcckt", "tokens": ["Er", "dank\u00b7te", "stumm", ",", "und", "hoch\u00b7be\u00b7gl\u00fcckt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wedelt' er mit dem Schwanze.", "tokens": ["We\u00b7delt'", "er", "mit", "dem", "Schwan\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}