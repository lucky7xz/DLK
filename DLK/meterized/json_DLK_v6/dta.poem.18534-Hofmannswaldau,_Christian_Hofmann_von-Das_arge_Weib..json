{"dta.poem.18534": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Das arge Weib.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1703", "urn": "urn:nbn:de:kobv:b4-200905199360", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nichts bessers al\u00df ein weib ist/ wie mich deucht/ auf erden/", "tokens": ["Nichts", "bes\u00b7sers", "al\u00df", "ein", "weib", "ist", "/", "wie", "mich", "deucht", "/", "auf", "er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "ADV", "KOUS", "ART", "NN", "VAFIN", "$(", "PWAV", "PPER", "VVFIN", "$(", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch kan nichts \u00e4rgers/ al\u00df ein weib gefunden werden/", "tokens": ["Auch", "kan", "nichts", "\u00e4r\u00b7gers", "/", "al\u00df", "ein", "weib", "ge\u00b7fun\u00b7den", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "$(", "KOUS", "ART", "NN", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie tr\u00e4get beyderley creutz/ ungl\u00fcck/ gl\u00fcck und heyl/", "tokens": ["Sie", "tr\u00e4\u00b7get", "bey\u00b7der\u00b7ley", "creutz", "/", "un\u00b7gl\u00fcck", "/", "gl\u00fcck", "und", "heyl", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$(", "ADJD", "$(", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Milch/ honig/ gall und gifft/ in ihren busen feil.", "tokens": ["Milch", "/", "ho\u00b7nig", "/", "gall", "und", "gifft", "/", "in", "ih\u00b7ren", "bu\u00b7sen", "feil", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "$(", "NE", "KON", "NN", "$(", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Und hat in einer hand/ gleich wie die kinder pflegen/", "tokens": ["Und", "hat", "in", "ei\u00b7ner", "hand", "/", "gleich", "wie", "die", "kin\u00b7der", "pfle\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "$(", "ADV", "KOKOM", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu spielen pincke panck/ lust/ leben/ friede/ segen/", "tokens": ["Zu", "spie\u00b7len", "pin\u00b7cke", "pan\u00b7ck", "/", "lust", "/", "le\u00b7ben", "/", "frie\u00b7de", "/", "se\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "NN", "$(", "VVFIN", "$(", "VVINF", "$(", "NN", "$(", "VVINF", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Und in der andern hand zorn/ tod/ fluch/ ha\u00df und zanck/", "tokens": ["Und", "in", "der", "an\u00b7dern", "hand", "zorn", "/", "tod", "/", "fluch", "/", "ha\u00df", "und", "zanck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN", "$(", "NN", "$(", "VVIMP", "$(", "VVIMP", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ach wie gef\u00e4hrlich ist ein solches pinckepanck:", "tokens": ["Ach", "wie", "ge\u00b7f\u00e4hr\u00b7lich", "ist", "ein", "sol\u00b7ches", "pin\u00b7cke\u00b7panck", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADJD", "VAFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wer diese hand ergreift/ der kriget nicht nur h\u00e4nde/", "tokens": ["Wer", "die\u00b7se", "hand", "er\u00b7greift", "/", "der", "kri\u00b7get", "nicht", "nur", "h\u00e4n\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$(", "ART", "VVFIN", "PTKNEG", "ADV", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ja vielmehr hau\u00df und hoff voll angst/ qual und elende/", "tokens": ["Ja", "viel\u00b7mehr", "hau\u00df", "und", "hoff", "voll", "angst", "/", "qual", "und", "e\u00b7len\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "NN", "KON", "VVFIN", "ADJD", "VVPP", "$(", "NN", "KON", "ADJA", "$("], "meter": "-+-+-+-++-+--", "measure": "unknown.measure.hexa"}, "line.11": {"text": "Was sag ich hau\u00df und hoff/ es mu\u00df was gr\u00f6ssers seyn/", "tokens": ["Was", "sag", "ich", "hau\u00df", "und", "hoff", "/", "es", "mu\u00df", "was", "gr\u00f6s\u00b7sers", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "NN", "KON", "VVFIN", "$(", "PPER", "VMFIN", "PWS", "ADJA", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ist doch der weiber zorn die gantze welt zu klein.", "tokens": ["Ist", "doch", "der", "wei\u00b7ber", "zorn", "die", "gant\u00b7ze", "welt", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wenn der/ wie offt geschicht/ hat \u00fcber hand genommen/", "tokens": ["Wenn", "der", "/", "wie", "offt", "ge\u00b7schicht", "/", "hat", "\u00fc\u00b7ber", "hand", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "KOKOM", "ADV", "VVPP", "$(", "VAFIN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So soll der teufel selbst aus seiner h\u00f6lle kommen/", "tokens": ["So", "soll", "der", "teu\u00b7fel", "selbst", "aus", "sei\u00b7ner", "h\u00f6l\u00b7le", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und holen iederman/ auf den sie b\u00f6se sind/", "tokens": ["Und", "ho\u00b7len", "ie\u00b7der\u00b7man", "/", "auf", "den", "sie", "b\u00f6\u00b7se", "sind", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "$(", "APPR", "PRELS", "PPER", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Hund/ katze/ kuh und kalb/ knecht/ magd/ mann/ weib und", "tokens": ["Hund", "/", "kat\u00b7ze", "/", "kuh", "und", "kalb", "/", "knecht", "/", "magd", "/", "mann", "/", "weib", "und"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$(", "VVFIN", "$(", "NN", "KON", "ADJD", "$(", "VVFIN", "$(", "NN", "$(", "NN", "$(", "VVFIN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "kind.", "tokens": ["kind", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.18": {"text": "Du hebt das gantze hau\u00df von keifen an zu sausen/", "tokens": ["Du", "hebt", "das", "gant\u00b7ze", "hau\u00df", "von", "kei\u00b7fen", "an", "zu", "sau\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Gleich wie die starcken wind im w\u00fcsten meere brausen/", "tokens": ["Gleich", "wie", "die", "star\u00b7cken", "wind", "im", "w\u00fcs\u00b7ten", "mee\u00b7re", "brau\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "APPRART", "VVFIN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Jhr rachen thut sich auf/ wirft feuer aus und gischt/", "tokens": ["Ihr", "ra\u00b7chen", "thut", "sich", "auf", "/", "wirft", "feu\u00b7er", "aus", "und", "gischt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "$(", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die z\u00e4hne beissen sich/ die braune zunge zischt/", "tokens": ["Die", "z\u00e4h\u00b7ne", "beis\u00b7sen", "sich", "/", "die", "brau\u00b7ne", "zun\u00b7ge", "zischt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die augen finckeln beyd als einem wilden schweine/", "tokens": ["Die", "au\u00b7gen", "fin\u00b7ckeln", "beyd", "als", "ei\u00b7nem", "wil\u00b7den", "schwei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "KOKOM", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Das \u00fcber berg und thal und \u00fcber stock und steine/", "tokens": ["Das", "\u00fc\u00b7ber", "berg", "und", "thal", "und", "\u00fc\u00b7ber", "stock", "und", "stei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NE", "KON", "NN", "KON", "APPR", "NE", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Von hunden wird gejagt/ die arme schwingen sich;", "tokens": ["Von", "hun\u00b7den", "wird", "ge\u00b7jagt", "/", "die", "ar\u00b7me", "schwin\u00b7gen", "sich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VAFIN", "VVPP", "$(", "ART", "ADJA", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Lincks/ rechts/ nach fechter-art/ auf streich/ schlag/ hieb", "tokens": ["Lincks", "/", "rechts", "/", "nach", "fech\u00b7ter\u00b7art", "/", "auf", "streich", "/", "schlag", "/", "hieb"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["NE", "$(", "ADV", "$(", "APPR", "NE", "$(", "APPR", "ADJD", "$(", "VVFIN", "$(", "VVFIN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.26": {"text": "und stich.", "tokens": ["und", "stich", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$."], "meter": "-+", "measure": "iambic.single"}, "line.27": {"text": "Es mu\u00df gescholten seyn/ giebts auch gleich nichts zu schelten/", "tokens": ["Es", "mu\u00df", "ge\u00b7schol\u00b7ten", "seyn", "/", "giebts", "auch", "gleich", "nichts", "zu", "schel\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$(", "VVFIN", "ADV", "ADV", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "So schilt/ so schilt sie doch potz hundert tausend velten/", "tokens": ["So", "schilt", "/", "so", "schilt", "sie", "doch", "potz", "hun\u00b7dert", "tau\u00b7send", "vel\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "CARD", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Sie springt/ sie h\u00fcpfft/ sie tantzt wie ein verliebtes pferd/", "tokens": ["Sie", "springt", "/", "sie", "h\u00fcpfft", "/", "sie", "tantzt", "wie", "ein", "ver\u00b7lieb\u00b7tes", "pferd", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "KOKOM", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ist gleich die sach offtmahl nicht wohl drey heller werth.", "tokens": ["Ist", "gleich", "die", "sach", "offt\u00b7mahl", "nicht", "wohl", "drey", "hel\u00b7ler", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "ADV", "PTKNEG", "ADV", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wenns hoch k\u00f6mmt/ ist etwa die katz in topf gekrochen/", "tokens": ["Wenns", "hoch", "k\u00f6mmt", "/", "ist", "et\u00b7wa", "die", "katz", "in", "topf", "ge\u00b7kro\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "VVFIN", "$(", "VAFIN", "ADV", "ART", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und hat den alten topf geleckt/ darnach zerbrochen/", "tokens": ["Und", "hat", "den", "al\u00b7ten", "topf", "ge\u00b7leckt", "/", "dar\u00b7nach", "zer\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$(", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die k\u00f6chin hat das fleisch versaltzen und verw\u00fcrtzt/", "tokens": ["Die", "k\u00f6\u00b7chin", "hat", "das", "fleisch", "ver\u00b7salt\u00b7zen", "und", "ver\u00b7w\u00fcrtzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVINF", "KON", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Auch ist der essig-krug beym ofen \u00fcmbgest\u00fcrtzt.", "tokens": ["Auch", "ist", "der", "es\u00b7sig\u00b7krug", "beym", "o\u00b7fen", "\u00fcmb\u00b7ge\u00b7st\u00fcrtzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ist sonst nichts mehr; so f\u00e4lt der zorn auf fl\u00f6h und l\u00e4use/", "tokens": ["Ist", "sonst", "nichts", "mehr", ";", "so", "f\u00e4lt", "der", "zorn", "auf", "fl\u00f6h", "und", "l\u00e4u\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Bald hat der hund das fleisch gefressen/ bald die m\u00e4use/", "tokens": ["Bald", "hat", "der", "hund", "das", "fleisch", "ge\u00b7fres\u00b7sen", "/", "bald", "die", "m\u00e4u\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$(", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Den schincken und die wurst/ brod/ butter/ k\u00e4\u00df und speck/", "tokens": ["Den", "schin\u00b7cken", "und", "die", "wurst", "/", "brod", "/", "but\u00b7ter", "/", "k\u00e4\u00df", "und", "speck", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "PDS", "VAFIN", "$(", "NN", "$(", "NN", "$(", "VVFIN", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Darzu/ o hertzeleid! ist auch das messer weg.", "tokens": ["Dar\u00b7zu", "/", "o", "hert\u00b7ze\u00b7leid", "!", "ist", "auch", "das", "mes\u00b7ser", "weg", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "FM", "PTKVZ", "$.", "VAFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Die schl\u00fcssel sind verlegt/ da h\u00f6rt man erst sch\u00f6n fluchen/", "tokens": ["Die", "schl\u00fcs\u00b7sel", "sind", "ver\u00b7legt", "/", "da", "h\u00f6rt", "man", "erst", "sch\u00f6n", "flu\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "ADV", "VVFIN", "PIS", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Der arme mann erschrickt und hilft die schl\u00fcssel suchen/", "tokens": ["Der", "ar\u00b7me", "mann", "er\u00b7schrickt", "und", "hilft", "die", "schl\u00fcs\u00b7sel", "su\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "KON", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Ein jedes sucht und flucht/ ein jedes greift und keift/", "tokens": ["Ein", "je\u00b7des", "sucht", "und", "flucht", "/", "ein", "je\u00b7des", "greift", "und", "keift", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "VVFIN", "$(", "ART", "PIAT", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Da\u00df immer mit der na\u00df eins an das ander l\u00e4ufft.", "tokens": ["Da\u00df", "im\u00b7mer", "mit", "der", "na\u00df", "eins", "an", "das", "an\u00b7der", "l\u00e4ufft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "ADJD", "PIS", "APPR", "ART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Das ist ein lustig spiel; wer es von ferne siehet/", "tokens": ["Das", "ist", "ein", "lus\u00b7tig", "spiel", ";", "wer", "es", "von", "fer\u00b7ne", "sie\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "VVFIN", "$.", "PWS", "PPER", "APPR", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Wie sich das liebe volck bek\u00fcmmert und bem\u00fchet/", "tokens": ["Wie", "sich", "das", "lie\u00b7be", "volck", "be\u00b7k\u00fcm\u00b7mert", "und", "be\u00b7m\u00fc\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "NN", "VVPP", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Der meinet/ sie sind all unsinnig/ th\u00f6richt/ toll/", "tokens": ["Der", "mei\u00b7net", "/", "sie", "sind", "all", "un\u00b7sin\u00b7nig", "/", "th\u00f6\u00b7richt", "/", "toll", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "PPER", "VAFIN", "PIAT", "ADJD", "$(", "VVFIN", "$(", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Jedoch zum wenigsten von bier und wenie voll:", "tokens": ["Je\u00b7doch", "zum", "we\u00b7nigs\u00b7ten", "von", "bier", "und", "we\u00b7nie", "voll", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "PIS", "APPR", "NE", "KON", "ADV", "ADJD", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.47": {"text": "Wenn nu der zarten frau die bo\u00dfheit ist vergangen/", "tokens": ["Wenn", "nu", "der", "zar\u00b7ten", "frau", "die", "bo\u00df\u00b7heit", "ist", "ver\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "So k\u00f6mmt ihr wieder an ein sehnen und verlangen", "tokens": ["So", "k\u00f6mmt", "ihr", "wie\u00b7der", "an", "ein", "seh\u00b7nen", "und", "ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "VVINF", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Nach hoffart; Ist das nicht so eine sch\u00f6ne tracht?", "tokens": ["Nach", "hof\u00b7fart", ";", "Ist", "das", "nicht", "so", "ei\u00b7ne", "sch\u00f6\u00b7ne", "tracht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$.", "VAFIN", "PDS", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Die frau gevatterin hat sie von Leipzig bracht/", "tokens": ["Die", "frau", "ge\u00b7vat\u00b7te\u00b7rin", "hat", "sie", "von", "Leip\u00b7zig", "bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "PPER", "APPR", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Spricht sie: und ist das nicht so eine liebe m\u00fctze?", "tokens": ["Spricht", "sie", ":", "und", "ist", "das", "nicht", "so", "ei\u00b7ne", "lie\u00b7be", "m\u00fct\u00b7ze", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "KON", "VAFIN", "PDS", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Ey lieber sehet doch/ wie klar ist diese spitze?", "tokens": ["Ey", "lie\u00b7ber", "se\u00b7het", "doch", "/", "wie", "klar", "ist", "die\u00b7se", "spit\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "ADV", "$(", "PWAV", "ADJD", "VAFIN", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Jm kram ist neuer zeug/ mir mangelt gleich ein rock/", "tokens": ["Jm", "kram", "ist", "neu\u00b7er", "zeug", "/", "mir", "man\u00b7gelt", "gleich", "ein", "rock", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJD", "VAFIN", "ADJA", "NN", "$(", "PPER", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und zu dem alten peltz ein neuer \u00fcberzog.", "tokens": ["Und", "zu", "dem", "al\u00b7ten", "peltz", "ein", "neu\u00b7er", "\u00fc\u00b7ber\u00b7zog", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Der rock ist gar zu kahl/ ich mu\u00df mich drinne sch\u00e4men/", "tokens": ["Der", "rock", "ist", "gar", "zu", "kahl", "/", "ich", "mu\u00df", "mich", "drin\u00b7ne", "sch\u00e4\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$(", "PPER", "VMFIN", "PPER", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Was werd ich immermehr f\u00fcr farbe wieder nehmen?", "tokens": ["Was", "werd", "ich", "im\u00b7mer\u00b7mehr", "f\u00fcr", "far\u00b7be", "wie\u00b7der", "neh\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "APPR", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Blau Mourant/ nacquara curang und columbin/", "tokens": ["Blau", "Mou\u00b7rant", "/", "nac\u00b7qua\u00b7ra", "cu\u00b7rang", "und", "co\u00b7lum\u00b7bin", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "FM", "FM", "KON", "NE", "$("], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.58": {"text": "Von diesen mu\u00df es seyn braun/ blau/ gelb/ roth und gr\u00fcn/", "tokens": ["Von", "die\u00b7sen", "mu\u00df", "es", "seyn", "braun", "/", "blau", "/", "gelb", "/", "roth", "und", "gr\u00fcn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VMFIN", "PPER", "VAINF", "VVFIN", "$(", "ADJD", "$(", "ADJD", "$(", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Die\u00df alle mag ich nicht/ sie sind gar zu gemeine/", "tokens": ["Die\u00df", "al\u00b7le", "mag", "ich", "nicht", "/", "sie", "sind", "gar", "zu", "ge\u00b7mei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VMFIN", "PPER", "PTKNEG", "$(", "PPER", "VAFIN", "ADV", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Wenn ich was haben will/ so hab ichs gern alleine/", "tokens": ["Wenn", "ich", "was", "ha\u00b7ben", "will", "/", "so", "hab", "ichs", "gern", "al\u00b7lei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VAINF", "VMFIN", "$(", "ADV", "VAFIN", "PIS", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Sonst werf ichs balde weg/ ein iede handwercks-frau/", "tokens": ["Sonst", "werf", "ichs", "bal\u00b7de", "weg", "/", "ein", "ie\u00b7de", "handwercks\u00b7frau", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PTKVZ", "$(", "ART", "PIAT", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.62": {"text": "Tr\u00e4gt itzo in der stadt gelb/ gr\u00fcn/ roth/ braun und blau.", "tokens": ["Tr\u00e4gt", "it\u00b7zo", "in", "der", "stadt", "gelb", "/", "gr\u00fcn", "/", "roth", "/", "braun", "und", "blau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "ADJD", "$(", "ADJD", "$(", "ADJD", "$(", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Dem mann entf\u00e4llt der muth/ und sitzt dort wie auf kohlen;", "tokens": ["Dem", "mann", "ent\u00b7f\u00e4llt", "der", "muth", "/", "und", "sitzt", "dort", "wie", "auf", "koh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$(", "KON", "VVFIN", "ADV", "KOKOM", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Was hilfts/ sie l\u00e4st nicht ab/ er mu\u00df den beutel holen/", "tokens": ["Was", "hilfts", "/", "sie", "l\u00e4st", "nicht", "ab", "/", "er", "mu\u00df", "den", "beu\u00b7tel", "ho\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$(", "PPER", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Ob er sich noch so sehr mit vielen worten wehrt/", "tokens": ["Ob", "er", "sich", "noch", "so", "sehr", "mit", "vie\u00b7len", "wor\u00b7ten", "wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "So wird er doch damit durchaus gar nicht geh\u00f6rt.", "tokens": ["So", "wird", "er", "doch", "da\u00b7mit", "durc\u00b7haus", "gar", "nicht", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PAV", "ADV", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Nu beutel ducke dich/ jetzt wirstu m\u00fcssen schwitzen/", "tokens": ["Nu", "beu\u00b7tel", "du\u00b7cke", "dich", "/", "jetzt", "wirs\u00b7tu", "m\u00fcs\u00b7sen", "schwit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "$(", "ADV", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Gib geld zur neuen tracht/ gib geld zu m\u00fctz und spitzen/", "tokens": ["Gib", "geld", "zur", "neu\u00b7en", "tracht", "/", "gib", "geld", "zu", "m\u00fctz", "und", "spit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "APPRART", "ADJA", "NN", "$(", "VVIMP", "NN", "PTKA", "ADJD", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Hastu gleich nichts/ gib doch/ das weib h\u00e4lt st\u00fcrmisch an/", "tokens": ["Has\u00b7tu", "gleich", "nichts", "/", "gib", "doch", "/", "das", "weib", "h\u00e4lt", "st\u00fcr\u00b7misch", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PIS", "$(", "VVIMP", "ADV", "$(", "ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Gib doch/ und solten gleich die letzten heller dran.", "tokens": ["Gib", "doch", "/", "und", "sol\u00b7ten", "gleich", "die", "letz\u00b7ten", "hel\u00b7ler", "dran", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$(", "KON", "VMFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Dargegen mu\u00df der mann etwa von alten st\u00fccken/", "tokens": ["Dar\u00b7ge\u00b7gen", "mu\u00df", "der", "mann", "et\u00b7wa", "von", "al\u00b7ten", "st\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ART", "NN", "ADV", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Die sie hat abgelegt/ die hosen lassen flicken:", "tokens": ["Die", "sie", "hat", "ab\u00b7ge\u00b7legt", "/", "die", "ho\u00b7sen", "las\u00b7sen", "fli\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VAFIN", "VVPP", "$(", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Es thuts dem herren wohl/ er ist vorhin bekant/", "tokens": ["Es", "thuts", "dem", "her\u00b7ren", "wohl", "/", "er", "ist", "vor\u00b7hin", "be\u00b7kant", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Ob gleich zum dritten mahl sein kleid wird \u00fcmgewandt.", "tokens": ["Ob", "gleich", "zum", "drit\u00b7ten", "mahl", "sein", "kleid", "wird", "\u00fcm\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPRART", "ADJA", "ADV", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Der kaufmann nimmt das geld/ dort sitzt die edle tocke/", "tokens": ["Der", "kauf\u00b7mann", "nimmt", "das", "geld", "/", "dort", "sitzt", "die", "ed\u00b7le", "to\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "ART", "NN", "$(", "ADV", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und sperrt sich/ pralt und prangt in ihrem bunten rocke/", "tokens": ["Und", "sperrt", "sich", "/", "pralt", "und", "prangt", "in", "ih\u00b7rem", "bun\u00b7ten", "ro\u00b7cke", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$(", "VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Das maul wacht endlich auf/ und wil versorget seyn/", "tokens": ["Das", "maul", "wacht", "end\u00b7lich", "auf", "/", "und", "wil", "ver\u00b7sor\u00b7get", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "$(", "KON", "VMFIN", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Wo ist das beste bier/ wo ist der beste wein?", "tokens": ["Wo", "ist", "das", "bes\u00b7te", "bier", "/", "wo", "ist", "der", "bes\u00b7te", "wein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "$(", "PWAV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Mein schatz/ ey seyd doch nicht ein karger pfennig-trucker/", "tokens": ["Mein", "schatz", "/", "ey", "seyd", "doch", "nicht", "ein", "kar\u00b7ger", "pfen\u00b7nig\u00b7tru\u00b7cker", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "NE", "VAFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Gebt geld/ ich h\u00e4tte gern eitronen/ wein und zucker/", "tokens": ["Gebt", "geld", "/", "ich", "h\u00e4t\u00b7te", "gern", "eit\u00b7ro\u00b7nen", "/", "wein", "und", "zu\u00b7cker", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$(", "PPER", "VAFIN", "ADV", "VVINF", "$(", "PTKVZ", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Mir ist f\u00fcrwar nicht wohl/ wie schauret mir die haut/", "tokens": ["Mir", "ist", "f\u00fcr\u00b7war", "nicht", "wohl", "/", "wie", "schau\u00b7ret", "mir", "die", "haut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "$(", "PWAV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Ich a\u00df vorhin zu viel fett fleisch und sauerkraut;", "tokens": ["Ich", "a\u00df", "vor\u00b7hin", "zu", "viel", "fett", "fleisch", "und", "sau\u00b7er\u00b7kraut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKA", "PIS", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Und hat doch allbereit ein k\u00e4nnlein wein im schrancke/", "tokens": ["Und", "hat", "doch", "all\u00b7be\u00b7reit", "ein", "k\u00e4nn\u00b7lein", "wein", "im", "schran\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Wohl zugericht/ dahin l\u00e4uft die versofne krancke/", "tokens": ["Wohl", "zu\u00b7ge\u00b7richt", "/", "da\u00b7hin", "l\u00e4uft", "die", "ver\u00b7sof\u00b7ne", "kran\u00b7cke", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$(", "PAV", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Gar ordentlich/ so offt der virtels-seiger schl\u00e4gt/", "tokens": ["Gar", "or\u00b7dent\u00b7lich", "/", "so", "offt", "der", "vir\u00b7tels\u00b7\u00b7sei\u00b7ger", "schl\u00e4gt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "ADV", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Bi\u00df da\u00df durch manchen trunck der hunger sich erregt.", "tokens": ["Bi\u00df", "da\u00df", "durch", "man\u00b7chen", "trunck", "der", "hun\u00b7ger", "sich", "er\u00b7regt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "APPR", "PIAT", "NN", "ART", "ADJA", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Geht/ muhme/ lasset mir flugs ein paar kuchen backen/", "tokens": ["Geht", "/", "muh\u00b7me", "/", "las\u00b7set", "mir", "flugs", "ein", "paar", "ku\u00b7chen", "ba\u00b7cken", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "$(", "VVFIN", "PPER", "ADV", "ART", "PIAT", "ADJA", "VVFIN", "$("], "meter": "-+-+--+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.88": {"text": "Der fromme stehet dort/ und krauet sich im nacken/", "tokens": ["Der", "from\u00b7me", "ste\u00b7het", "dort", "/", "und", "krau\u00b7et", "sich", "im", "na\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "$(", "KON", "VVFIN", "PRF", "APPRART", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Doch wenn er freundlich ist/ so krieget er den rand", "tokens": ["Doch", "wenn", "er", "freund\u00b7lich", "ist", "/", "so", "krie\u00b7get", "er", "den", "rand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VAFIN", "$(", "ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Von kuchen/ und was sonst daran ist angebrandt.", "tokens": ["Von", "ku\u00b7chen", "/", "und", "was", "sonst", "da\u00b7ran", "ist", "an\u00b7ge\u00b7brandt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$(", "KON", "PWS", "ADV", "PAV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Bi\u00dfweilen will die frau auf himmel-wagen fahren/", "tokens": ["Bi\u00df\u00b7wei\u00b7len", "will", "die", "frau", "auf", "him\u00b7mel\u00b7wa\u00b7gen", "fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Da geht es eben zu/ als wie mit jenen stahren/", "tokens": ["Da", "geht", "es", "e\u00b7ben", "zu", "/", "als", "wie", "mit", "je\u00b7nen", "stah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKZU", "$(", "KOUS", "KOKOM", "APPR", "PDAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Die waren ihres stands im walde m\u00fcd und satt/", "tokens": ["Die", "wa\u00b7ren", "ih\u00b7res", "stands", "im", "wal\u00b7de", "m\u00fcd", "und", "satt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "APPRART", "NN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Sie wolten amseln seyn/ und flohen in die stadt/", "tokens": ["Sie", "wol\u00b7ten", "am\u00b7seln", "seyn", "/", "und", "flo\u00b7hen", "in", "die", "stadt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "VAINF", "$(", "KON", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Und sahen hin und her viel amselbauer hangen/", "tokens": ["Und", "sa\u00b7hen", "hin", "und", "her", "viel", "am\u00b7sel\u00b7bau\u00b7er", "han\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "ADV", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "In einen krochen sie und wolten drinnen prangen/", "tokens": ["In", "ei\u00b7nen", "kro\u00b7chen", "sie", "und", "wol\u00b7ten", "drin\u00b7nen", "pran\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "PPER", "KON", "VMFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Die leute lieffen zu/ und traten \u00fcmb das hau\u00df/", "tokens": ["Die", "leu\u00b7te", "lief\u00b7fen", "zu", "/", "und", "tra\u00b7ten", "\u00fcmb", "das", "hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PTKZU", "$(", "KON", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Und sprachen: lachet doch die groben narren aus.", "tokens": ["Und", "spra\u00b7chen", ":", "la\u00b7chet", "doch", "die", "gro\u00b7ben", "nar\u00b7ren", "aus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Di\u00df alles ginge hin/ als keiffen/ prangen/ trincken/", "tokens": ["Di\u00df", "al\u00b7les", "gin\u00b7ge", "hin", "/", "als", "keif\u00b7fen", "/", "pran\u00b7gen", "/", "trin\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PTKVZ", "$(", "KOKOM", "PIAT", "$(", "VVFIN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Wenn nur die sch\u00f6ne frau den hund nicht liesse hincken/", "tokens": ["Wenn", "nur", "die", "sch\u00f6\u00b7ne", "frau", "den", "hund", "nicht", "lies\u00b7se", "hin\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "NN", "PTKNEG", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Oft bl\u00e4ckt das reh/ oft kreht ein iunger stoltzer hahn/", "tokens": ["Oft", "bl\u00e4ckt", "das", "reh", "/", "oft", "kreht", "ein", "i\u00b7un\u00b7ger", "stolt\u00b7zer", "hahn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDS", "VVFIN", "$(", "ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.102": {"text": "Es findet sich auch bald ein cammer-capellan.", "tokens": ["Es", "fin\u00b7det", "sich", "auch", "bald", "ein", "cam\u00b7mer\u00b7ca\u00b7pel\u00b7lan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Da geht es seltzam zu/ es ist nicht zu beschreiben/", "tokens": ["Da", "geht", "es", "selt\u00b7zam", "zu", "/", "es", "ist", "nicht", "zu", "be\u00b7schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "$(", "PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Denn wer di\u00df handwerck will lang und verschwiegen treiben/", "tokens": ["Denn", "wer", "di\u00df", "hand\u00b7werck", "will", "lang", "und", "ver\u00b7schwie\u00b7gen", "trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PDS", "NN", "VMFIN", "ADJD", "KON", "VVINF", "VVINF", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.105": {"text": "Der thut es ingeheim/ derhalben wei\u00df man nicht/", "tokens": ["Der", "thut", "es", "in\u00b7ge\u00b7heim", "/", "der\u00b7hal\u00b7ben", "wei\u00df", "man", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$(", "PDS", "VVFIN", "PIS", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Von wem/ wie oder wenn etwas und was geschicht.", "tokens": ["Von", "wem", "/", "wie", "o\u00b7der", "wenn", "et\u00b7was", "und", "was", "ge\u00b7schicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "$(", "KOKOM", "KON", "KOUS", "PIS", "KON", "PWS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Die k\u00fche lassen oft auch frembde k\u00e4lber saugen/", "tokens": ["Die", "k\u00fc\u00b7he", "las\u00b7sen", "oft", "auch", "fremb\u00b7de", "k\u00e4l\u00b7ber", "sau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "ADV", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Ein scharffes beil wird stumpf/ und kan nicht immer taugen/", "tokens": ["Ein", "scharf\u00b7fes", "beil", "wird", "stumpf", "/", "und", "kan", "nicht", "im\u00b7mer", "tau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$(", "KON", "VMFIN", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Wer ist der nicht zuletzt daf\u00fcr ein eckel tr\u00e4gt/", "tokens": ["Wer", "ist", "der", "nicht", "zu\u00b7letzt", "da\u00b7f\u00fcr", "ein", "ec\u00b7kel", "tr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "PTKNEG", "ADV", "PAV", "ART", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Wenn ihm wird einerley zu essen vorgelegt?", "tokens": ["Wenn", "ihm", "wird", "ei\u00b7ner\u00b7ley", "zu", "es\u00b7sen", "vor\u00b7ge\u00b7legt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "PIS", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Voraus ein solches weib/ das will was neues haben/", "tokens": ["Vo\u00b7raus", "ein", "sol\u00b7ches", "weib", "/", "das", "will", "was", "neu\u00b7es", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIAT", "NN", "$(", "PDS", "VMFIN", "PWS", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Von kleidern/ spei\u00df und tranck und andern leibes-gaben/", "tokens": ["Von", "klei\u00b7dern", "/", "spei\u00df", "und", "tranck", "und", "an\u00b7dern", "lei\u00b7bes\u00b7ga\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$(", "ADJD", "KON", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Sie trachtet meisten theils nach dem/ was sie ergetzt/", "tokens": ["Sie", "trach\u00b7tet", "meis\u00b7ten", "theils", "nach", "dem", "/", "was", "sie", "er\u00b7getzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "APPR", "ART", "$(", "PWS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Wird gleich treu/ ehr und zucht weit hinten angesetzt.", "tokens": ["Wird", "gleich", "treu", "/", "ehr", "und", "zucht", "weit", "hin\u00b7ten", "an\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$(", "NN", "KON", "VVFIN", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Indessen hat der mann zwar einen grossen l\u00f6ffel/", "tokens": ["In\u00b7des\u00b7sen", "hat", "der", "mann", "zwar", "ei\u00b7nen", "gros\u00b7sen", "l\u00f6f\u00b7fel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "J\u00dft aber selten mit/ drischt \u00fcmb den zw\u00f6lfften scheffel/", "tokens": ["J\u00dft", "a\u00b7ber", "sel\u00b7ten", "mit", "/", "drischt", "\u00fcmb", "den", "zw\u00f6lff\u00b7ten", "schef\u00b7fel", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "$(", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.117": {"text": "Er liest die brocken auf/ und sticht die neigen ab/", "tokens": ["Er", "liest", "die", "bro\u00b7cken", "auf", "/", "und", "sticht", "die", "nei\u00b7gen", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "$(", "KON", "VVFIN", "ART", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Auch r\u00fchret ihn manchmahl ein schwerer liebes-tag.", "tokens": ["Auch", "r\u00fch\u00b7ret", "ihn", "manch\u00b7mahl", "ein", "schwe\u00b7rer", "lie\u00b7bes\u00b7tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.119": {"text": "Ist etwa nun ein weib mit bosheit/ sauffen/ fressen/", "tokens": ["Ist", "et\u00b7wa", "nun", "ein", "weib", "mit", "bos\u00b7heit", "/", "sauf\u00b7fen", "/", "fres\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "APPR", "NN", "$(", "VVFIN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Mit hoffart/ hader/ zanck und geiler lust besessen/", "tokens": ["Mit", "hof\u00b7fart", "/", "ha\u00b7der", "/", "zanck", "und", "gei\u00b7ler", "lust", "be\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "$(", "NE", "$(", "VVIMP", "KON", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Wohlan/ so sage mir mein lieber deutscher mann/", "tokens": ["Wo\u00b7hlan", "/", "so", "sa\u00b7ge", "mir", "mein", "lie\u00b7ber", "deut\u00b7scher", "mann", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "VVFIN", "PPER", "PPOSAT", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Ob auch auf dieser welt was \u00e4rgers leben kan?", "tokens": ["Ob", "auch", "auf", "die\u00b7ser", "welt", "was", "\u00e4r\u00b7gers", "le\u00b7ben", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PDAT", "NN", "PWS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.123": {"text": "Doch endlich gnug gesagt von solchen schlimmen sachen/", "tokens": ["Doch", "end\u00b7lich", "gnug", "ge\u00b7sagt", "von", "sol\u00b7chen", "schlim\u00b7men", "sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVPP", "APPR", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Ich m\u00f6cht euch weiberlein vieleicht gar zornig machen/", "tokens": ["Ich", "m\u00f6cht", "euch", "wei\u00b7berl\u00b7ein", "vie\u00b7leicht", "gar", "zor\u00b7nig", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Ich bitte/ z\u00fcrnet nicht/ seyd fromm und wohlgemut/", "tokens": ["Ich", "bit\u00b7te", "/", "z\u00fcr\u00b7net", "nicht", "/", "seyd", "fromm", "und", "wohl\u00b7ge\u00b7mut", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "PTKNEG", "$(", "VAFIN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Ich wei\u00df/ da\u00df kein\u2019 allhier dergleichen dinge thut/", "tokens": ["Ich", "wei\u00df", "/", "da\u00df", "kein'", "all\u00b7hier", "derg\u00b7lei\u00b7chen", "din\u00b7ge", "thut", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PIS", "ADV", "PIS", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Und fordert mich nur nicht vor euer hal\u00df-gerichte/", "tokens": ["Und", "for\u00b7dert", "mich", "nur", "nicht", "vor", "eu\u00b7er", "ha\u00b7l\u00df\u00b7ge\u00b7rich\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "APPR", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.128": {"text": "Es ist nur schimpf und schertz/ und ein geflickt gedichte/", "tokens": ["Es", "ist", "nur", "schimpf", "und", "schertz", "/", "und", "ein", "ge\u00b7flickt", "ge\u00b7dich\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$(", "KON", "ART", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Es reuet mich der schimpf/ ietzt \u00e4ndert sich mein sinn/", "tokens": ["Es", "reu\u00b7et", "mich", "der", "schimpf", "/", "ietzt", "\u00e4n\u00b7dert", "sich", "mein", "sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJD", "$(", "ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.130": {"text": "Und darumb werf ich auch die lose feder hin/", "tokens": ["Und", "da\u00b7rumb", "werf", "ich", "auch", "die", "lo\u00b7se", "fe\u00b7der", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Ein andre feder her/ darmit wil ich euch preisen/", "tokens": ["Ein", "and\u00b7re", "fe\u00b7der", "her", "/", "dar\u00b7mit", "wil", "ich", "euch", "prei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$(", "PAV", "VMFIN", "PPER", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Und loben/ und zugleich das wiederspiel beweisen.", "tokens": ["Und", "lo\u00b7ben", "/", "und", "zu\u00b7gleich", "das", "wie\u00b7der\u00b7spiel", "be\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "KON", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Es ist mein rechter ernst/ ich bleibe nur dabey/", "tokens": ["Es", "ist", "mein", "rech\u00b7ter", "ernst", "/", "ich", "blei\u00b7be", "nur", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$(", "PPER", "VVFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Wie da\u00df auf dieser welt ein weib das beste sey.", "tokens": ["Wie", "da\u00df", "auf", "die\u00b7ser", "welt", "ein", "weib", "das", "bes\u00b7te", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "APPR", "PDAT", "NN", "ART", "NN", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}