{"dta.poem.10707": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Sonnet.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Was will ich vber Pusch/ was will ich vber Sandt/", "tokens": ["Was", "will", "ich", "vber", "Pusch", "/", "was", "will", "ich", "vber", "Sandt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "NN", "$(", "PWS", "VMFIN", "PPER", "APPR", "NE", "$("], "meter": "-+-++-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Was will ich vber See/ vnd durch die w\u00fcste Wellen", "tokens": ["Was", "will", "ich", "vber", "See", "/", "vnd", "durch", "die", "w\u00fcs\u00b7te", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "NN", "$(", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "In eine frembde Welt/ den Perlen nach zustellen/", "tokens": ["In", "ei\u00b7ne", "fremb\u00b7de", "Welt", "/", "den", "Per\u00b7len", "nach", "zu\u00b7stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "ART", "NN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es sey ans Rote Meer/ es sey ins Mohrenlandt/", "tokens": ["Es", "sey", "ans", "Ro\u00b7te", "Meer", "/", "es", "sey", "ins", "Moh\u00b7ren\u00b7landt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN", "$(", "PPER", "VAFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mein Lieb hat doch allein (ach da\u00df ich sie erkant!)", "tokens": ["Mein", "Lieb", "hat", "doch", "al\u00b7lein", "(", "ach", "da\u00df", "ich", "sie", "er\u00b7kant", "!", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "$(", "XY", "KOUS", "PPER", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Perlen/ die so sch\u00f6n/ als jehmals funden waren/", "tokens": ["Die", "Per\u00b7len", "/", "die", "so", "sch\u00f6n", "/", "als", "jeh\u00b7mals", "fun\u00b7den", "wa\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "ADJD", "$(", "KOKOM", "ADV", "VVFIN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Al\u00df irgendt jemand auch von denen/ welche faren", "tokens": ["Al\u00df", "ir\u00b7gendt", "je\u00b7mand", "auch", "von", "de\u00b7nen", "/", "wel\u00b7che", "fa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADV", "PIS", "ADV", "APPR", "PRELS", "$(", "PWAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ins Reich Arabien vnd gantz Egypten/ fandt.", "tokens": ["Ins", "Reich", "A\u00b7ra\u00b7bi\u00b7en", "vnd", "gantz", "E\u00b7gyp\u00b7ten", "/", "fandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "NE", "KON", "ADV", "NE", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sie tregt in dem Gesicht zween Edel Asteriten/", "tokens": ["Sie", "tregt", "in", "dem", "Ge\u00b7sicht", "zween", "E\u00b7del", "As\u00b7te\u00b7ri\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVFIN", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Lippen sein Corall/ die Wangen sein Robin/", "tokens": ["Die", "Lip\u00b7pen", "sein", "Co\u00b7rall", "/", "die", "Wan\u00b7gen", "sein", "Ro\u00b7bin", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$(", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die zarten Br\u00fcste sein von sch\u00f6nen Chrisolithen.", "tokens": ["Die", "zar\u00b7ten", "Br\u00fcs\u00b7te", "sein", "von", "sch\u00f6\u00b7nen", "Chri\u00b7so\u00b7li\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "O were nicht Demant jhr Hertz vnd harter Sinn!", "tokens": ["O", "we\u00b7re", "nicht", "De\u00b7mant", "jhr", "Hertz", "vnd", "har\u00b7ter", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "NN", "PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Gewinn ich disen Schatz/ wegk aller vberflu\u00df:", "tokens": ["Ge\u00b7winn", "ich", "di\u00b7sen", "Schatz", "/", "wegk", "al\u00b7ler", "vberf\u00b7lu\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PDAT", "NN", "$(", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "Was soll mir Gut vnd Gelt/ so ich jhr darben mu\u00df.", "tokens": ["Was", "soll", "mir", "Gut", "vnd", "Gelt", "/", "so", "ich", "jhr", "dar\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADJD", "KON", "NN", "$(", "ADV", "PPER", "PPER", "PAV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}