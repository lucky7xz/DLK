{"textgrid.poem.54184": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Wenn eena jeborn wird", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nu liechste da, du kleene Kr\u00f6te!", "tokens": ["Nu", "liechs\u00b7te", "da", ",", "du", "klee\u00b7ne", "Kr\u00f6\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Siehst aus wie ne jebadte Maus.", "tokens": ["Siehst", "aus", "wie", "ne", "je\u00b7bad\u00b7te", "Maus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KOKOM", "NE", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Na la\u00df man, do \u2013 der olle Joethe,", "tokens": ["Na", "la\u00df", "man", ",", "do", "\u2013", "der", "ol\u00b7le", "Joe\u00b7the", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PIS", "$,", "KOUS", "$(", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der sah als Kind nich scheena aus.", "tokens": ["der", "sah", "als", "Kind", "nich", "schee\u00b7na", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "KOUS", "NN", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und hier \u2013 ick bring da ooch wat mit!", "tokens": ["Und", "hier", "\u2013", "ick", "bring", "da", "o\u00b7och", "wat", "mit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "PPER", "VVFIN", "ADV", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Tittittittittitt \u2013!", "tokens": ["Tit\u00b7tit\u00b7tit\u00b7tit\u00b7titt", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Die Neese haste ja von Vatan.", "tokens": ["Die", "Nee\u00b7se", "has\u00b7te", "ja", "von", "Va\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Det M\u00e4ulchen, wo de dir drin w\u00fchlst,", "tokens": ["Det", "M\u00e4ul\u00b7chen", ",", "wo", "de", "dir", "drin", "w\u00fchlst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWAV", "NE", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da sachste denn den Jrang im Schkat an.", "tokens": ["da", "sachs\u00b7te", "denn", "den", "Jrang", "im", "Sch\u00b7kat", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wolln hoffen, dette bessa spielst", "tokens": ["Wolln", "hof\u00b7fen", ",", "det\u00b7te", "bes\u00b7sa", "spielst"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "FM.la", "FM.la", "FM.la"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.5": {"text": "als wie der Olle, dein Papa!", "tokens": ["als", "wie", "der", "Ol\u00b7le", ",", "dein", "Pa\u00b7pa", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Allallallalla \u2013!", "tokens": ["Al\u00b7lal\u00b7lal\u00b7lal\u00b7la", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Un seh mah! Hast ja richtich Haare!", "tokens": ["Un", "seh", "mah", "!", "Hast", "ja", "rich\u00b7tich", "Haa\u00b7re", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "$.", "VAFIN", "ADV", "ADJD", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die hat dir Mutta mitjejehm.", "tokens": ["Die", "hat", "dir", "Mut\u00b7ta", "mit\u00b7je\u00b7jehm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du, Mensch, det is ne wunderbare", "tokens": ["Du", ",", "Mensch", ",", "det", "is", "ne", "wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "FM", "FM", "FM", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "unliebe Frau \u2013 nur etwas unbequem.", "tokens": ["un\u00b7lie\u00b7be", "Frau", "\u2013", "nur", "et\u00b7was", "un\u00b7be\u00b7quem", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ADV", "ADV", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Dein Olla, der macht vor ihr Kusch . . .", "tokens": ["Dein", "Ol\u00b7la", ",", "der", "macht", "vor", "ihr", "Kusch", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "NE", "$,", "PRELS", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Puschpuschpuschpuschpusch \u2013!", "tokens": ["Puschpu\u00b7schpu\u00b7schpu\u00b7schpusch", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$(", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Sieht man dir durch de Neese schnauhm", "tokens": ["Sieht", "man", "dir", "durch", "de", "Nee\u00b7se", "schnauhm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "NE", "NE", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "un wie du mit die Beenchen tanzt \u2013:", "tokens": ["un", "wie", "du", "mit", "die", "Been\u00b7chen", "tanzt", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "PPER", "APPR", "ART", "NN", "VVFIN", "$(", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "denn sollte man det jahnich jlauhm,", "tokens": ["denn", "soll\u00b7te", "man", "det", "jah\u00b7nich", "jlauhm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "VVFIN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wie jemeine du mal wern kannst.", "tokens": ["wie", "je\u00b7mei\u00b7ne", "du", "mal", "wern", "kannst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Wa \u2013?", "tokens": ["Wa", "\u2013", "?"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+", "measure": "single.up"}}, "stanza.5": {"line.1": {"text": "Ach, Menschenskind, ick wer da sahrn:", "tokens": ["Ach", ",", "Men\u00b7schen\u00b7skind", ",", "ick", "wer", "da", "sahrn", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "PPER", "PWS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schlach du nach Vatan! H\u00f6r ma an!", "tokens": ["Schlach", "du", "nach", "Va\u00b7tan", "!", "H\u00f6r", "ma", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$.", "NE", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du kannst ja ooch nach andre schlahrn . . .", "tokens": ["Du", "kannst", "ja", "o\u00b7och", "nach", "and\u00b7re", "schlahrn", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "PIS", "VVFIN", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Na, wirste denn als junga Mann jenau", "tokens": ["Na", ",", "wirs\u00b7te", "denn", "als", "jun\u00b7ga", "Mann", "je\u00b7nau"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "ADV", "KOUS", "ADJA", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "so doof wie Onkel Fritz?", "tokens": ["so", "doof", "wie", "On\u00b7kel", "Fritz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Zizzizzizzizzizz \u2013?", "tokens": ["Ziz\u00b7ziz\u00b7ziz\u00b7ziz\u00b7zizz", "\u2013", "?"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Da liechste nu in deine Wieje", "tokens": ["Da", "liechs\u00b7te", "nu", "in", "dei\u00b7ne", "Wie\u00b7je"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "un f\u00e4ngst nochmah von vorne an.", "tokens": ["un", "f\u00e4ngst", "noch\u00b7mah", "von", "vor\u00b7ne", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "ADV", "APPR", "ADV", "PTKVZ", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Na, Mensch, ob ick mah Kinda krieje?", "tokens": ["Na", ",", "Mensch", ",", "ob", "ick", "mah", "Kin\u00b7da", "krie\u00b7je", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "KOUS", "PPER", "VVFIN", "NE", "VVFIN", "$."], "meter": "-+--++--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Man jloobt ja imma wieda dran.", "tokens": ["Man", "jlo\u00b7obt", "ja", "im\u00b7ma", "wie\u00b7da", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Du machst dir nu die Windeln voll", "tokens": ["Du", "machst", "dir", "nu", "die", "Win\u00b7deln", "voll"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und wee\u00dft nich, wat det hei\u00dfen soll,", "tokens": ["und", "wee\u00dft", "nich", ",", "wat", "det", "hei\u00b7\u00dfen", "soll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "PWS", "PDS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "wenn eena dir mit Puda fecht,", "tokens": ["wenn", "e\u00b7e\u00b7na", "dir", "mit", "Pu\u00b7da", "fecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "dir abwischt un dir trocken lecht . . .", "tokens": ["dir", "ab\u00b7wischt", "un", "dir", "tro\u00b7cken", "lecht", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "FM", "PPER", "ADJD", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Denn loofste rum,", "tokens": ["Denn", "loofs\u00b7te", "rum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "klug oda dumm . . .", "tokens": ["klug", "o\u00b7da", "dumm", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ADJD", "ADV", "ADJD", "$.", "$.", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Un machst den janzen Lebensskandal", "tokens": ["Un", "machst", "den", "jan\u00b7zen", "Le\u00b7bens\u00b7skan\u00b7dal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "alles nochmal, alles nochmal \u2013!", "tokens": ["al\u00b7les", "noch\u00b7mal", ",", "al\u00b7les", "noch\u00b7mal", "\u2013", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PIS", "ADV", "$,", "PIS", "ADV", "$(", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}}}}