{"textgrid.poem.39999": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr Sonnen, die ihr ohne Zahl,", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Sonnen, die ihr ohne Zahl,", "tokens": ["Ihr", "Son\u00b7nen", ",", "die", "ihr", "oh\u00b7ne", "Zahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im unergr\u00fcndlichen unendlich-weiten Thal", "tokens": ["Im", "un\u00b7er\u00b7gr\u00fcnd\u00b7li\u00b7chen", "un\u00b7end\u00b7lich\u00b7wei\u00b7ten", "Thal"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "ADJA", "NN"], "meter": "-+-+--++-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Des hohlen Firmaments stehet:", "tokens": ["Des", "hoh\u00b7len", "Fir\u00b7ma\u00b7ments", "ste\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihr Welten, die ihr euch um diese Sonnen drehet,", "tokens": ["Ihr", "Wel\u00b7ten", ",", "die", "ihr", "euch", "um", "die\u00b7se", "Son\u00b7nen", "dre\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "PRF", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die voller W\u00e4rm' und Licht, voll Strahlen, Glantz und Gluth;", "tokens": ["Die", "vol\u00b7ler", "W\u00e4rm'", "und", "Licht", ",", "voll", "Strah\u00b7len", ",", "Glantz", "und", "Gluth", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,", "ADJD", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es soll von euch mein fast entz\u00fcckter Muth", "tokens": ["Es", "soll", "von", "euch", "mein", "fast", "ent\u00b7z\u00fcck\u00b7ter", "Muth"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "PPOSAT", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ein Andacht-volles Lied, ein Ehrerbietig's Singen", "tokens": ["Ein", "An\u00b7dacht\u00b7vol\u00b7les", "Lied", ",", "ein", "Ehr\u00b7er\u00b7bie\u00b7tig's", "Sin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem grossen ", "tokens": ["Dem", "gros\u00b7sen"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Ich f\u00fchle, da\u00df mein angeflammter Geist", "tokens": ["Ich", "f\u00fch\u00b7le", ",", "da\u00df", "mein", "an\u00b7ge\u00b7flamm\u00b7ter", "Geist"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dem gross- und kleinen Kreis der Erde sich entreisst,", "tokens": ["Dem", "gross", "und", "klei\u00b7nen", "Kreis", "der", "Er\u00b7de", "sich", "en\u00b7treisst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zugleich sich in die Tief' ohn' End' und Anfang neiget,", "tokens": ["Zu\u00b7gleich", "sich", "in", "die", "Tie\u00b7f'", "ohn'", "End'", "und", "An\u00b7fang", "nei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zugleich auch in die H\u00f6h' ohn' End' und Grentzen steiget.", "tokens": ["Zu\u00b7gleich", "auch", "in", "die", "H\u00f6h'", "ohn'", "End'", "und", "Grent\u00b7zen", "stei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein feur'ger Andachts-Trieb", "tokens": ["Ein", "feur'\u00b7ger", "An\u00b7dachts\u00b7Trieb"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Versetzt mich in die Ewigkeit.", "tokens": ["Ver\u00b7setzt", "mich", "in", "die", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein denckend Wesen breitet sich", "tokens": ["Mein", "den\u00b7ckend", "We\u00b7sen", "brei\u00b7tet", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "KON", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In's ungemessne Sternen-Haus,", "tokens": ["In's", "un\u00b7ge\u00b7mess\u00b7ne", "Ster\u00b7nen\u00b7Haus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vor Ehrfurcht stumm, vor Lust erstaunet, aus.", "tokens": ["Vor", "Ehr\u00b7furcht", "stumm", ",", "vor", "Lust", "er\u00b7stau\u00b7net", ",", "aus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "NN", "VVFIN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da ich anitzt die allertiefste H\u00f6he,", "tokens": ["Da", "ich", "a\u00b7nitzt", "die", "al\u00b7ler\u00b7tiefs\u00b7te", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den unbegrentzten Raum des hohlen Himmels, sehe,", "tokens": ["Den", "un\u00b7be\u00b7grentz\u00b7ten", "Raum", "des", "hoh\u00b7len", "Him\u00b7mels", ",", "se\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Weite sonder Ziel, die Gott allein erf\u00fcllet,", "tokens": ["Die", "Wei\u00b7te", "son\u00b7der", "Ziel", ",", "die", "Gott", "al\u00b7lein", "er\u00b7f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo Sein unendlich ewig Kleid,", "tokens": ["Wo", "Sein", "un\u00b7end\u00b7lich", "e\u00b7wig", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJD", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gewebt aus Licht und Dunckelheit,", "tokens": ["Ge\u00b7webt", "aus", "Licht", "und", "Dun\u00b7ckel\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Wesen zeiget und verh\u00fcllet;", "tokens": ["Sein", "We\u00b7sen", "zei\u00b7get", "und", "ver\u00b7h\u00fcl\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So stellet dieser Raum recht sichtbar, hell und klar", "tokens": ["So", "stel\u00b7let", "die\u00b7ser", "Raum", "recht", "sicht\u00b7bar", ",", "hell", "und", "klar"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "ADV", "ADJD", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nicht unserm Geiste nur, den Augen selber, dar", "tokens": ["Nicht", "un\u00b7serm", "Geis\u00b7te", "nur", ",", "den", "Au\u00b7gen", "sel\u00b7ber", ",", "dar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PTKNEG", "PPOSAT", "NN", "ADV", "$,", "ART", "NN", "ADV", "$,", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Selbst die Unendlichkeit,", "tokens": ["Selbst", "die", "Un\u00b7end\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "In deren Tiefe Licht und Dunckel sich vereinet,", "tokens": ["In", "de\u00b7ren", "Tie\u00b7fe", "Licht", "und", "Dun\u00b7ckel", "sich", "ver\u00b7ei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "NN", "KON", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die sonder Farbe blau, dicht sonder C\u00f6rper, scheinet.", "tokens": ["Die", "son\u00b7der", "Far\u00b7be", "blau", ",", "dicht", "son\u00b7der", "C\u00f6r\u00b7per", ",", "schei\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "ADJD", "KON", "NE", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Vor ungeheurer Tiefe l\u00e4sst", "tokens": ["Vor", "un\u00b7ge\u00b7heu\u00b7rer", "Tie\u00b7fe", "l\u00e4sst"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ungeheure Tief', als w\u00e4re sie nicht tief:", "tokens": ["Die", "un\u00b7ge\u00b7heu\u00b7re", "Tie\u00b7f'", ",", "als", "w\u00e4\u00b7re", "sie", "nicht", "tief", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KOKOM", "VAFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Es scheint der leere Raum, als w\u00e4r' er voll und fest,", "tokens": ["Es", "scheint", "der", "lee\u00b7re", "Raum", ",", "als", "w\u00e4r'", "er", "voll", "und", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "KOKOM", "VAFIN", "PPER", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da doch in diesen hohlen Gr\u00fcnden,", "tokens": ["Da", "doch", "in", "die\u00b7sen", "hoh\u00b7len", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn gleich ein schneller Blick best\u00e4ndig vor sich lief,", "tokens": ["Wenn", "gleich", "ein", "schnel\u00b7ler", "Blick", "be\u00b7st\u00e4n\u00b7dig", "vor", "sich", "lief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In Ewigkeit kein Ziel, kein Grund, zu finden:", "tokens": ["In", "E\u00b7wig\u00b7keit", "kein", "Ziel", ",", "kein", "Grund", ",", "zu", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und dennoch k\u00f6nnen wir so ungemess'ne H\u00f6hen", "tokens": ["Und", "den\u00b7noch", "k\u00f6n\u00b7nen", "wir", "so", "un\u00b7ge\u00b7mess'\u00b7ne", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mit unsern kleinen Augen sehen.", "tokens": ["Mit", "un\u00b7sern", "klei\u00b7nen", "Au\u00b7gen", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "O Wunder, das kein Mensch begreifen", "tokens": ["O", "Wun\u00b7der", ",", "das", "kein", "Mensch", "be\u00b7grei\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "PRELS", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und keine Klugheit fassen kann!", "tokens": ["Und", "kei\u00b7ne", "Klug\u00b7heit", "fas\u00b7sen", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "O Wunder-Werck, worin sich alle Wunder h\u00e4ufen!", "tokens": ["O", "Wun\u00b7der\u00b7\u00b7Werck", ",", "wo\u00b7rin", "sich", "al\u00b7le", "Wun\u00b7der", "h\u00e4u\u00b7fen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWAV", "PRF", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ach schauet es mit Ehrfurcht an!", "tokens": ["Ach", "schau\u00b7et", "es", "mit", "Ehr\u00b7furcht", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ein Schau-Platz, welcher Millionen", "tokens": ["Ein", "Schau\u00b7Platz", ",", "wel\u00b7cher", "Mil\u00b7lion\u00b7en"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PWAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Und Millionen Meilen gro\u00df,", "tokens": ["Und", "Mil\u00b7lion\u00b7en", "Mei\u00b7len", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Ein Platz, in dessen weitem Schoo\u00df", "tokens": ["Ein", "Platz", ",", "in", "des\u00b7sen", "wei\u00b7tem", "Schoo\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Viel Millionen Sonnen wohnen,", "tokens": ["Viel", "Mil\u00b7lion\u00b7en", "Son\u00b7nen", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.17": {"text": "Kann, nebst verschied'nen Erden,", "tokens": ["Kann", ",", "nebst", "ver\u00b7schie\u00b7d'\u00b7nen", "Er\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "Auf einmahl \u00fcbersehen werden,", "tokens": ["Auf", "ein\u00b7mahl", "\u00fc\u00b7ber\u00b7se\u00b7hen", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Auf einmahl in die spiegelnden Krystallen", "tokens": ["Auf", "ein\u00b7mahl", "in", "die", "spie\u00b7geln\u00b7den", "Krys\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Von unsern kleinen Augen fallen,", "tokens": ["Von", "un\u00b7sern", "klei\u00b7nen", "Au\u00b7gen", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Und sich so eng zusammen ziehn.", "tokens": ["Und", "sich", "so", "eng", "zu\u00b7sam\u00b7men", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Durch diese Wunder-reiche Klarheit", "tokens": ["Durch", "die\u00b7se", "Wun\u00b7der\u00b7rei\u00b7che", "Klar\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wird mein erstaunt Gesicht erquickt;", "tokens": ["Wird", "mein", "er\u00b7staunt", "Ge\u00b7sicht", "er\u00b7quickt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch zittert Aug' und Hertz, wenn, halb entz\u00fcckt,", "tokens": ["Doch", "zit\u00b7tert", "Aug'", "und", "Hertz", ",", "wenn", ",", "halb", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$,", "KOUS", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich diese Himmel-feste Wahrheit", "tokens": ["Ich", "die\u00b7se", "Him\u00b7mel\u00b7fes\u00b7te", "Wahr\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von dieser Lichter Wunder-Gr\u00f6sse", "tokens": ["Von", "die\u00b7ser", "Lich\u00b7ter", "Wun\u00b7der\u00b7Gr\u00f6s\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Augen der Vernunft ermesse;", "tokens": ["Mit", "Au\u00b7gen", "der", "Ver\u00b7nunft", "er\u00b7mes\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da, wenn ich nah bey einem jeden st\u00fcnde,", "tokens": ["Da", ",", "wenn", "ich", "nah", "bey", "ei\u00b7nem", "je\u00b7den", "st\u00fcn\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "APPR", "ART", "PIAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich einen jeden ja so gro\u00df,", "tokens": ["Ich", "ei\u00b7nen", "je\u00b7den", "ja", "so", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "PIAT", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als wie ich itzt des gantzen Himmels Schoo\u00df,", "tokens": ["Als", "wie", "ich", "itzt", "des", "gant\u00b7zen", "Him\u00b7mels", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "PPER", "ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "So wie ich ihn hier sehe, f\u00fcnde:", "tokens": ["So", "wie", "ich", "ihn", "hier", "se\u00b7he", ",", "f\u00fcn\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "PPER", "ADV", "VVFIN", "$,", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Indem ja Jupiter allein,", "tokens": ["In\u00b7dem", "ja", "Ju\u00b7pi\u00b7ter", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Nach aller Stern-Verst\u00e4ndigen Beweis,", "tokens": ["Nach", "al\u00b7ler", "Stern\u00b7Ver\u00b7st\u00e4n\u00b7di\u00b7gen", "Be\u00b7weis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Mehr als acht tausend mahl soll gr\u00f6sser seyn,", "tokens": ["Mehr", "als", "acht", "tau\u00b7send", "mahl", "soll", "gr\u00f6s\u00b7ser", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "CARD", "CARD", "ADV", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Wie unser gantzer Erden-Kreis.", "tokens": ["Wie", "un\u00b7ser", "gant\u00b7zer", "Er\u00b7den\u00b7Kreis", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ob gleich Huygenius, Cassin,", "tokens": ["Ob", "gleich", "Huy\u00b7gen\u00b7ius", ",", "Cas\u00b7sin", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "$,", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Horoccius und Wendelin,", "tokens": ["Ho\u00b7roc\u00b7ci\u00b7us", "und", "Wen\u00b7de\u00b7lin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "La Hire, nebst Flamstedius,", "tokens": ["La", "Hi\u00b7re", ",", "nebst", "Flams\u00b7te\u00b7dius", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "Auch Newton und Ricciolus", "tokens": ["Auch", "New\u00b7ton", "und", "Ric\u00b7cio\u00b7lus"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NE", "KON", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Von unsrer Sonnen Gr\u00f6sse schreiben,", "tokens": ["Von", "uns\u00b7rer", "Son\u00b7nen", "Gr\u00f6s\u00b7se", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Sie sey entsetzlich, und die Zahl,", "tokens": ["Sie", "sey", "ent\u00b7setz\u00b7lich", ",", "und", "die", "Zahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wodurch die\u00df helle Licht-Gef\u00e4sse", "tokens": ["Wo\u00b7durch", "die\u00df", "hel\u00b7le", "Licht\u00b7Ge\u00b7f\u00e4s\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "An Gr\u00f6sse dieser Erden Gr\u00f6sse", "tokens": ["An", "Gr\u00f6s\u00b7se", "die\u00b7ser", "Er\u00b7den", "Gr\u00f6s\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Noch \u00fcbertr\u00e4f', auf viel viel hundert tausend treiben;", "tokens": ["Noch", "\u00fc\u00b7ber\u00b7tr\u00e4f'", ",", "auf", "viel", "viel", "hun\u00b7dert", "tau\u00b7send", "trei\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ADV", "ADV", "CARD", "CARD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So wollen wir jedoch das allerkleinste setzen,", "tokens": ["So", "wol\u00b7len", "wir", "je\u00b7doch", "das", "al\u00b7ler\u00b7kleins\u00b7te", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und sie auf hundert tausend mahl", "tokens": ["Und", "sie", "auf", "hun\u00b7dert", "tau\u00b7send", "mahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "CARD", "CARD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Nur gr\u00f6sser, als die Erde, sch\u00e4tzen.", "tokens": ["Nur", "gr\u00f6s\u00b7ser", ",", "als", "die", "Er\u00b7de", ",", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "O Gott! wo bin ich doch? wer bin ich? Ich verschwinde,", "tokens": ["O", "Gott", "!", "wo", "bin", "ich", "doch", "?", "wer", "bin", "ich", "?", "Ich", "ver\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWAV", "VAFIN", "PPER", "ADV", "$.", "PWS", "VAFIN", "PPER", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem ich nicht einmahl die Welt,", "tokens": ["In\u00b7dem", "ich", "nicht", "ein\u00b7mahl", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nebst allem, was sie in sich h\u00e4lt,", "tokens": ["Nebst", "al\u00b7lem", ",", "was", "sie", "in", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "PPER", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur in Vergleich mit einer Sonne, finde.", "tokens": ["Nur", "in", "Ver\u00b7gleich", "mit", "ei\u00b7ner", "Son\u00b7ne", ",", "fin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Solch eine Gr\u00f6sse kommt, wie leicht zu glauben, mir,", "tokens": ["Solch", "ei\u00b7ne", "Gr\u00f6s\u00b7se", "kommt", ",", "wie", "leicht", "zu", "glau\u00b7ben", ",", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "ART", "NN", "VVFIN", "$,", "PWAV", "ADJD", "PTKZU", "VVINF", "$,", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn ich sie recht erweg', entsetzlich herrlich f\u00fcr;", "tokens": ["Wenn", "ich", "sie", "recht", "er\u00b7weg'", ",", "ent\u00b7setz\u00b7lich", "herr\u00b7lich", "f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVFIN", "$,", "ADJD", "ADJD", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja, wenn wir endlich gar bey dieser Gr\u00f6ss' und L\u00e4nge", "tokens": ["Ja", ",", "wenn", "wir", "end\u00b7lich", "gar", "bey", "die\u00b7ser", "Gr\u00f6ss'", "und", "L\u00e4n\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "ADV", "ADV", "APPR", "PDAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Noch vollends erst die ungez\u00e4hlte Menge,", "tokens": ["Noch", "vol\u00b7lends", "erst", "die", "un\u00b7ge\u00b7z\u00e4hl\u00b7te", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ja die Unendlichkeit", "tokens": ["Ja", "die", "Un\u00b7end\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["PTKANT", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "So ungeheurer Lichts- und Sonnen-C\u00f6rper schauen", "tokens": ["So", "un\u00b7ge\u00b7heu\u00b7rer", "Lichts", "und", "Son\u00b7nen\u00b7C\u00f6\u00b7rper", "schau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "TRUNC", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit Augen unsrer Seel'; entsteht ein heiligs Grauen.", "tokens": ["Mit", "Au\u00b7gen", "uns\u00b7rer", "Seel'", ";", "ent\u00b7steht", "ein", "hei\u00b7ligs", "Grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$.", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Im Haupt wird das Gehirn, das Hertz in unsrer Brust,", "tokens": ["Im", "Haupt", "wird", "das", "Ge\u00b7hirn", ",", "das", "Hertz", "in", "uns\u00b7rer", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Von einer frohen Angst, von einer bangen Lust", "tokens": ["Von", "ei\u00b7ner", "fro\u00b7hen", "Angst", ",", "von", "ei\u00b7ner", "ban\u00b7gen", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Geklemmt, gedruckt, gepresst,", "tokens": ["Ge\u00b7klemmt", ",", "ge\u00b7druckt", ",", "ge\u00b7presst", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Indem der Gottheit Bild,", "tokens": ["In\u00b7dem", "der", "Got\u00b7theit", "Bild", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Wodurch der gantze Bau der grossen Welt erf\u00fcllt,", "tokens": ["Wo\u00b7durch", "der", "gant\u00b7ze", "Bau", "der", "gros\u00b7sen", "Welt", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sich nicht ohn' Ehrfurcht schauen l\u00e4sst.", "tokens": ["Sich", "nicht", "ohn'", "Ehr\u00b7furcht", "schau\u00b7en", "l\u00e4sst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPR", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es \u00fcberleg' ein Mensch, wie ihm zu Muthe seyn,", "tokens": ["Es", "\u00fc\u00b7ber\u00b7leg'", "ein", "Mensch", ",", "wie", "ihm", "zu", "Mu\u00b7the", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Welch ein Entsetzen ihn mit Lust befallen w\u00fcrde,", "tokens": ["Welch", "ein", "Ent\u00b7set\u00b7zen", "ihn", "mit", "Lust", "be\u00b7fal\u00b7len", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "PPER", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn seinem heiteren Gesicht", "tokens": ["Wenn", "sei\u00b7nem", "hei\u00b7te\u00b7ren", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von solchem hellen Schein,", "tokens": ["Von", "sol\u00b7chem", "hel\u00b7len", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Von solcher Gr\u00f6ss' und schrecklich schweren B\u00fcrde", "tokens": ["Von", "sol\u00b7cher", "Gr\u00f6ss'", "und", "schreck\u00b7lich", "schwe\u00b7ren", "B\u00fcr\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Blitz-geschwinde Flug, und zwar von einer nicht,", "tokens": ["Der", "Blitz\u00b7ge\u00b7schwin\u00b7de", "Flug", ",", "und", "zwar", "von", "ei\u00b7ner", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ADV", "APPR", "ART", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Von tausend Millionen Kreisen,", "tokens": ["Von", "tau\u00b7send", "Mil\u00b7lion\u00b7en", "Krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Sich sollt' auf einmahl weisen.", "tokens": ["Sich", "sollt'", "auf", "ein\u00b7mahl", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VMFIN", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Des grossen Sch\u00f6pfers Wunder-Wercke", "tokens": ["Des", "gros\u00b7sen", "Sch\u00f6p\u00b7fers", "Wun\u00b7der\u00b7\u00b7Wer\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vermehren sich bey mir auf wunderbare Weise,", "tokens": ["Ver\u00b7meh\u00b7ren", "sich", "bey", "mir", "auf", "wun\u00b7der\u00b7ba\u00b7re", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wenn ich an die geschwinde Reise", "tokens": ["Wenn", "ich", "an", "die", "ge\u00b7schwin\u00b7de", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So grosser C\u00f6rper denck, und an die St\u00e4rcke,", "tokens": ["So", "gros\u00b7ser", "C\u00f6r\u00b7per", "denck", ",", "und", "an", "die", "St\u00e4r\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die sie bewegen kann: da erstlich ausgemacht,", "tokens": ["Die", "sie", "be\u00b7we\u00b7gen", "kann", ":", "da", "erst\u00b7lich", "aus\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$.", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und durch die Rechnung l\u00e4ngst gefunden,", "tokens": ["Und", "durch", "die", "Rech\u00b7nung", "l\u00e4ngst", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ungefehr in achtzehn Stunden", "tokens": ["Da\u00df", "un\u00b7ge\u00b7fehr", "in", "acht\u00b7zehn", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Kugel, welche man aus einem St\u00fccke scheusst,", "tokens": ["Die", "Ku\u00b7gel", ",", "wel\u00b7che", "man", "aus", "ei\u00b7nem", "St\u00fc\u00b7cke", "scheusst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie schnell sie gleich die Luft durchreisst,", "tokens": ["Wie", "schnell", "sie", "gleich", "die", "Luft", "durc\u00b7hreisst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Durchschnitt unsrer Welt vollf\u00fchren k\u00f6nne.", "tokens": ["Den", "Durch\u00b7schnitt", "uns\u00b7rer", "Welt", "voll\u00b7f\u00fch\u00b7ren", "k\u00f6n\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Nun soll der Venus Schnelligkeit", "tokens": ["Nun", "soll", "der", "Ve\u00b7nus", "Schnel\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Auf hundert sechs und viertzig mahl so weit", "tokens": ["Auf", "hun\u00b7dert", "sechs", "und", "viert\u00b7zig", "mahl", "so", "weit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "CARD", "KON", "CARD", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Sich, an Geschwindigkeit, erstrecken.", "tokens": ["Sich", ",", "an", "Ge\u00b7schwin\u00b7dig\u00b7keit", ",", "er\u00b7stre\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "$,", "APPR", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Wer kann doch, sonder Schrecken,", "tokens": ["Wer", "kann", "doch", ",", "son\u00b7der", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Solch ungemessner Gr\u00f6ss' und ungeheurer Last", "tokens": ["Solch", "un\u00b7ge\u00b7mess\u00b7ner", "Gr\u00f6ss'", "und", "un\u00b7ge\u00b7heu\u00b7rer", "Last"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und ungez\u00e4hlter Meng entsetzlichs schnell Bewegen,", "tokens": ["Und", "un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "Meng", "ent\u00b7setz\u00b7lichs", "schnell", "Be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NE", "NE", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "In seiner Seelen, \u00fcberlegen?", "tokens": ["In", "sei\u00b7ner", "See\u00b7len", ",", "\u00fc\u00b7berl\u00b7e\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Wer kann der so verschied'nen Kreise", "tokens": ["Wer", "kann", "der", "so", "ver\u00b7schie\u00b7d'\u00b7nen", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Verschied'ne Gr\u00f6ss' und grausam schnelle Reise,", "tokens": ["Ver\u00b7schie\u00b7d'\u00b7ne", "Gr\u00f6ss'", "und", "grau\u00b7sam", "schnel\u00b7le", "Rei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Ohn' einen Seelen-Schwindel, sehn", "tokens": ["Ohn'", "ei\u00b7nen", "See\u00b7len\u00b7Schwin\u00b7del", ",", "sehn"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "NN", "$,", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Entsetzlich durch einander gehn,", "tokens": ["Ent\u00b7setz\u00b7lich", "durch", "ein\u00b7an\u00b7der", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und zwar so ordentlich sich drehn,", "tokens": ["Und", "zwar", "so", "or\u00b7dent\u00b7lich", "sich", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Da\u00df nach viel tausend Jahren", "tokens": ["Da\u00df", "nach", "viel", "tau\u00b7send", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "Sie noch dieselben sind, die sie vorhero waren?", "tokens": ["Sie", "noch", "die\u00b7sel\u00b7ben", "sind", ",", "die", "sie", "vor\u00b7he\u00b7ro", "wa\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PDS", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "Es hat sie nichts verwirrt, nichts ihre Kraft geschw\u00e4cht,", "tokens": ["Es", "hat", "sie", "nichts", "ver\u00b7wirrt", ",", "nichts", "ih\u00b7re", "Kraft", "ge\u00b7schw\u00e4cht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "ADJD", "$,", "PIS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Nichts ihren Lauf gehemmt, der unaufh\u00f6rlich recht", "tokens": ["Nichts", "ih\u00b7ren", "Lauf", "ge\u00b7hemmt", ",", "der", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", "recht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "PPOSAT", "NN", "VVPP", "$,", "PRELS", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "In steter R\u00fcnde fliegt.", "tokens": ["In", "ste\u00b7ter", "R\u00fcn\u00b7de", "fliegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Gewi\u00df mich \u00fcberl\u00e4uft ein schreckendes Vergn\u00fcgen,", "tokens": ["Ge\u00b7wi\u00df", "mich", "\u00fc\u00b7berl\u00b7\u00e4uft", "ein", "schre\u00b7cken\u00b7des", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wann sich mein Geist dahin, blo\u00df in Gedancken, lenckt,", "tokens": ["Wann", "sich", "mein", "Geist", "da\u00b7hin", ",", "blo\u00df", "in", "Ge\u00b7dan\u00b7cken", ",", "lenckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "NN", "PAV", "$,", "ADV", "APPR", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und nur von weitem einst an einen Raum gedenckt,", "tokens": ["Und", "nur", "von", "wei\u00b7tem", "einst", "an", "ei\u00b7nen", "Raum", "ge\u00b7denckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIS", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo, in so grosser Eil', so grosse C\u00f6rper fliegen.", "tokens": ["Wo", ",", "in", "so", "gros\u00b7ser", "Eil'", ",", "so", "gros\u00b7se", "C\u00f6r\u00b7per", "flie\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ADV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sprich nicht: ich w\u00fcrde ja solch ein geschwindes Rennen", "tokens": ["Sprich", "nicht", ":", "ich", "w\u00fcr\u00b7de", "ja", "solch", "ein", "ge\u00b7schwin\u00b7des", "Ren\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PTKNEG", "$.", "PPER", "VAFIN", "ADV", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von so entsetzlichen Gesch\u00f6pfen sehen k\u00f6nnen.", "tokens": ["Von", "so", "ent\u00b7setz\u00b7li\u00b7chen", "Ge\u00b7sch\u00f6p\u00b7fen", "se\u00b7hen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "VVINF", "VMINF", "$."], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.7": {"text": "Es folget nicht, indem ja unsre Augen", "tokens": ["Es", "fol\u00b7get", "nicht", ",", "in\u00b7dem", "ja", "uns\u00b7re", "Au\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nicht das, was sich zu schnell bewegt, zu fassen taugen.", "tokens": ["Nicht", "das", ",", "was", "sich", "zu", "schnell", "be\u00b7wegt", ",", "zu", "fas\u00b7sen", "tau\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PDS", "$,", "PRELS", "PRF", "PTKA", "ADJD", "VVPP", "$,", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn wir ein feurig Holtz, das gl\u00fchet, drehen:", "tokens": ["Wenn", "wir", "ein", "feu\u00b7rig", "Holtz", ",", "das", "gl\u00fc\u00b7het", ",", "dre\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "NN", "$,", "PDS", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "So scheint's ein feur'ger Kreis, und g\u00e4ntzlich still zu stehen.", "tokens": ["So", "scheint's", "ein", "feur'\u00b7ger", "Kreis", ",", "und", "g\u00e4ntz\u00b7lich", "still", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Es kommt hinzu, da\u00df der Bewegung Stand,", "tokens": ["Es", "kommt", "hin\u00b7zu", ",", "da\u00df", "der", "Be\u00b7we\u00b7gung", "Stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "So wie der Stand der Ruh', uns g\u00e4ntzlich unbekannt:", "tokens": ["So", "wie", "der", "Stand", "der", "Ruh'", ",", "uns", "g\u00e4ntz\u00b7lich", "un\u00b7be\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ART", "NN", "$,", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da von Gesch\u00f6pfen ja ein ruhiges Verweilen", "tokens": ["Da", "von", "Ge\u00b7sch\u00f6p\u00b7fen", "ja", "ein", "ru\u00b7hi\u00b7ges", "Ver\u00b7wei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "---+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Nicht mehr nat\u00fcrlich ist, als ein geschwindes Eilen.", "tokens": ["Nicht", "mehr", "na\u00b7t\u00fcr\u00b7lich", "ist", ",", "als", "ein", "ge\u00b7schwin\u00b7des", "Ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "VAFIN", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Durch Gottes Willen fliesst sowohl die rege Fluth,", "tokens": ["Durch", "Got\u00b7tes", "Wil\u00b7len", "fliesst", "so\u00b7wohl", "die", "re\u00b7ge", "Fluth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Als da\u00df die Erd' in sich nat\u00fcrlich ruht.", "tokens": ["Als", "da\u00df", "die", "Erd'", "in", "sich", "na\u00b7t\u00fcr\u00b7lich", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Erweg't nun die fast grause Kraft,", "tokens": ["Er\u00b7weg't", "nun", "die", "fast", "grau\u00b7se", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die blo\u00df allein dazu geh\u00f6ret,", "tokens": ["Die", "blo\u00df", "al\u00b7lein", "da\u00b7zu", "ge\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den gantzen Erden-Ball, da\u00df er geschwinder f\u00e4hret,", "tokens": ["Den", "gant\u00b7zen", "Er\u00b7den\u00b7Ball", ",", "da\u00df", "er", "ge\u00b7schwin\u00b7der", "f\u00e4h\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als eine Kugel, fort zu bringen!", "tokens": ["Als", "ei\u00b7ne", "Ku\u00b7gel", ",", "fort", "zu", "brin\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Betrachtet eine Kraft, die, durch ein stetes Schwingen,", "tokens": ["Be\u00b7trach\u00b7tet", "ei\u00b7ne", "Kraft", ",", "die", ",", "durch", "ein", "ste\u00b7tes", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELS", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Viel tausend C\u00f6rper mit sich rafft,", "tokens": ["Viel", "tau\u00b7send", "C\u00f6r\u00b7per", "mit", "sich", "rafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wovon verschied'ne noch viel tausendmahl so gro\u00df!", "tokens": ["Wo\u00b7von", "ver\u00b7schie\u00b7d'\u00b7ne", "noch", "viel", "tau\u00b7send\u00b7mahl", "so", "gro\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ADV", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Wer kann des Wesens Macht, das alles dieses fasst,", "tokens": ["Wer", "kann", "des", "We\u00b7sens", "Macht", ",", "das", "al\u00b7les", "die\u00b7ses", "fasst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "NN", "$,", "PRELS", "PIS", "PDAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Erschaffen hat, erh\u00e4lt und tr\u00e4get,", "tokens": ["Er\u00b7schaf\u00b7fen", "hat", ",", "er\u00b7h\u00e4lt", "und", "tr\u00e4\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Allegegenw\u00e4rtig f\u00fchrt, beweget,", "tokens": ["Al\u00b7le\u00b7ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "f\u00fchrt", ",", "be\u00b7we\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Und zwar,", "tokens": ["Und", "zwar", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.12": {"text": "Da\u00df alles sich, in stiller Majest\u00e4t,", "tokens": ["Da\u00df", "al\u00b7les", "sich", ",", "in", "stil\u00b7ler", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und stets unwandelbar, in solcher Eile, dreht,", "tokens": ["Und", "stets", "un\u00b7wan\u00b7del\u00b7bar", ",", "in", "sol\u00b7cher", "Ei\u00b7le", ",", "dreht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$,", "APPR", "PIAT", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So unbegreiflich wunderbar,", "tokens": ["So", "un\u00b7be\u00b7greif\u00b7lich", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "In solcher Ordnung leiten kann,", "tokens": ["In", "sol\u00b7cher", "Ord\u00b7nung", "lei\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Ohn' einiges Erstaunen, sehen!", "tokens": ["Ohn'", "ei\u00b7ni\u00b7ges", "Er\u00b7stau\u00b7nen", ",", "se\u00b7hen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Ach! wie verschwinden hier die kindischen Ideen", "tokens": ["Ach", "!", "wie", "ver\u00b7schwin\u00b7den", "hier", "die", "kin\u00b7di\u00b7schen", "I\u00b7deen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von einem alten Mann,", "tokens": ["Von", "ei\u00b7nem", "al\u00b7ten", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Womit so mancher Mensch erb\u00e4rmlich sich getragen,", "tokens": ["Wo\u00b7mit", "so", "man\u00b7cher", "Mensch", "er\u00b7b\u00e4rm\u00b7lich", "sich", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "ADJD", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und, da er sich dadurch ein G\u00f6tzen-Bild gemacht,", "tokens": ["Und", ",", "da", "er", "sich", "da\u00b7durch", "ein", "G\u00f6t\u00b7zen\u00b7Bild", "ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PRF", "PAV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sich um die Gottheit selbst, durch eigne Schuld, gebracht.", "tokens": ["Sich", "um", "die", "Got\u00b7theit", "selbst", ",", "durch", "eig\u00b7ne", "Schuld", ",", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ADV", "$,", "APPR", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Bedencke, lieber Mensch, um Gottes willen,", "tokens": ["Be\u00b7den\u00b7cke", ",", "lie\u00b7ber", "Mensch", ",", "um", "Got\u00b7tes", "wil\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "NN", "$,", "KOUI", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie gr\u00f6blich du gefehlt! wie n\u00e4rrisch deine Grillen,", "tokens": ["Wie", "gr\u00f6b\u00b7lich", "du", "ge\u00b7fehlt", "!", "wie", "n\u00e4r\u00b7risch", "dei\u00b7ne", "Gril\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVPP", "$.", "PWAV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die, fast wie Lucifern, dein eitles Hirn erf\u00fcllt,", "tokens": ["Die", ",", "fast", "wie", "Lu\u00b7ci\u00b7fern", ",", "dein", "eit\u00b7les", "Hirn", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "KOKOM", "NE", "$,", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da du, aus einem stoltzen Triebe", "tokens": ["Da", "du", ",", "aus", "ei\u00b7nem", "stolt\u00b7zen", "Trie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der abgeschmackt'sten Eigen-Liebe,", "tokens": ["Der", "ab\u00b7ge\u00b7schmackt'\u00b7sten", "Ei\u00b7gen\u00b7Lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Fast mehr dich selbst zum Gott, als GOTT zum Menschen, machest,", "tokens": ["Fast", "mehr", "dich", "selbst", "zum", "Gott", ",", "als", "GoTT", "zum", "Men\u00b7schen", ",", "ma\u00b7chest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "APPRART", "NN", "$,", "KOUS", "NN", "APPRART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wirklich, wenn mans recht erweget, Gott verlachest.", "tokens": ["Und", "wirk\u00b7lich", ",", "wenn", "mans", "recht", "er\u00b7we\u00b7get", ",", "Gott", "ver\u00b7la\u00b7chest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$,", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dein alter Gott-Mann mu\u00df entweder klein,", "tokens": ["Dein", "al\u00b7ter", "Got\u00b7tMann", "mu\u00df", "ent\u00b7we\u00b7der", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "(der etwa, wie ein F\u00fcrst, durch andere, regieret,", "tokens": ["(", "der", "et\u00b7wa", ",", "wie", "ein", "F\u00fcrst", ",", "durch", "an\u00b7de\u00b7re", ",", "re\u00b7gie\u00b7ret", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "ADV", "$,", "PWAV", "ART", "NN", "$,", "APPR", "PIS", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch andre, sieht und h\u00f6rt und seinen Scepter f\u00fchret,)", "tokens": ["Durch", "and\u00b7re", ",", "sieht", "und", "h\u00f6rt", "und", "sei\u00b7nen", "Scep\u00b7ter", "f\u00fch\u00b7ret", ",", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIS", "$,", "VVFIN", "KON", "VVFIN", "KON", "PPOSAT", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wo nicht, m\u00fcst' er ein Mann von solcher Gr\u00f6sse seyn,", "tokens": ["Wo", "nicht", ",", "m\u00fcst'", "er", "ein", "Mann", "von", "sol\u00b7cher", "Gr\u00f6s\u00b7se", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "VMFIN", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dem hundert tausend tausend Meilen", "tokens": ["Dem", "hun\u00b7dert", "tau\u00b7send", "tau\u00b7send", "Mei\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "CARD", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Nicht einst ein Glied von seinem Finger theilen.", "tokens": ["Nicht", "einst", "ein", "Glied", "von", "sei\u00b7nem", "Fin\u00b7ger", "thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Ja, w\u00e4r' er auch so gro\u00df: So w\u00e4r' er dennoch klein.", "tokens": ["Ja", ",", "w\u00e4r'", "er", "auch", "so", "gro\u00df", ":", "So", "w\u00e4r'", "er", "den\u00b7noch", "klein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$.", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Denn h\u00e4tt' er eine Form: So m\u00fcst' er endlich seyn.", "tokens": ["Denn", "h\u00e4tt'", "er", "ei\u00b7ne", "Form", ":", "So", "m\u00fcst'", "er", "end\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "$.", "ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Was endlich's aber nun von einer Gottheit glauben,", "tokens": ["Was", "end\u00b7lich's", "a\u00b7ber", "nun", "von", "ei\u00b7ner", "Got\u00b7theit", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Heisst, Ihr Allgegenwart, ja gar die Gottheit, rauben.", "tokens": ["Heisst", ",", "Ihr", "All\u00b7ge\u00b7gen\u00b7wart", ",", "ja", "gar", "die", "Got\u00b7theit", ",", "rau\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$,", "ADV", "ADV", "ART", "NN", "$,", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Unendlich ewigs ALL, la\u00df unsrer Seelen Augen,", "tokens": ["Un\u00b7end\u00b7lich", "e\u00b7wigs", "AlL", ",", "la\u00df", "uns\u00b7rer", "See\u00b7len", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "VVIMP", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch Deine Lieb', er\u00f6ffnet seyn,", "tokens": ["Durch", "Dei\u00b7ne", "Lieb'", ",", "er\u00b7\u00f6ff\u00b7net", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df wir der wahren Gottheit Schein,", "tokens": ["Da\u00df", "wir", "der", "wah\u00b7ren", "Got\u00b7theit", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Deinem Werck zu seh'n, und zu verehren, taugen!", "tokens": ["In", "Dei\u00b7nem", "Werck", "zu", "seh'n", ",", "und", "zu", "ver\u00b7eh\u00b7ren", ",", "tau\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,", "KON", "PTKZU", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "La\u00df unsre Seelen doch Dein unbegreiflichs Wesen,", "tokens": ["La\u00df", "uns\u00b7re", "See\u00b7len", "doch", "Dein", "un\u00b7be\u00b7greif\u00b7lichs", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im Buch der Creatur, erstaunt, mit Ehrfurcht, lesen!", "tokens": ["Im", "Buch", "der", "Crea\u00b7tur", ",", "er\u00b7staunt", ",", "mit", "Ehr\u00b7furcht", ",", "le\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "VVPP", "$,", "APPR", "NN", "$,", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "La\u00df uns, auch in der finstern Nacht,", "tokens": ["La\u00df", "uns", ",", "auch", "in", "der", "fins\u00b7tern", "Nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von Deiner unerschaff'nen Macht,", "tokens": ["Von", "Dei\u00b7ner", "un\u00b7er\u00b7schaff'\u00b7nen", "Macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "In funckelndem Gestirn, das herrliche Gepr\u00e4nge,", "tokens": ["In", "fun\u00b7ckeln\u00b7dem", "Ge\u00b7stirn", ",", "das", "herr\u00b7li\u00b7che", "Ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die ungeheure Gr\u00f6ss', und ungeheure Menge,", "tokens": ["Die", "un\u00b7ge\u00b7heu\u00b7re", "Gr\u00f6ss'", ",", "und", "un\u00b7ge\u00b7heu\u00b7re", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und ungeheure Schnelligkeit", "tokens": ["Und", "un\u00b7ge\u00b7heu\u00b7re", "Schnel\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der himmlischen Gesch\u00f6pf' besehen und besingen!", "tokens": ["Der", "himm\u00b7li\u00b7schen", "Ge\u00b7sch\u00f6pf'", "be\u00b7se\u00b7hen", "und", "be\u00b7sin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So werden wir, in allen Dingen,", "tokens": ["So", "wer\u00b7den", "wir", ",", "in", "al\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Dich, ", "tokens": ["Dich", ","], "token_info": ["word", "punct"], "pos": ["PPER", "$,"], "meter": "-", "measure": "single.down"}, "line.15": {"text": "Uns selbst vernichtigen, und dich allein erh\u00f6hn.", "tokens": ["Uns", "selbst", "ver\u00b7nich\u00b7ti\u00b7gen", ",", "und", "dich", "al\u00b7lein", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "$,", "KON", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Seh' ich den Himmel an, so k\u00f6mmt mir sein Sapphir", "tokens": ["Seh'", "ich", "den", "Him\u00b7mel", "an", ",", "so", "k\u00f6mmt", "mir", "sein", "Sap\u00b7phir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als eine Tafel f\u00fcr,", "tokens": ["Als", "ei\u00b7ne", "Ta\u00b7fel", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die unerme\u00dflich ist, auf welcher eine Schrift,", "tokens": ["Die", "un\u00b7er\u00b7me\u00df\u00b7lich", "ist", ",", "auf", "wel\u00b7cher", "ei\u00b7ne", "Schrift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "$,", "APPR", "PRELS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die des allm\u00e4cht'gen Sch\u00f6pfers Wesen,", "tokens": ["Die", "des", "all\u00b7m\u00e4cht'\u00b7gen", "Sch\u00f6p\u00b7fers", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Huld, Weisheit, Macht und Majest\u00e4t betrifft,", "tokens": ["Huld", ",", "Weis\u00b7heit", ",", "Macht", "und", "Ma\u00b7jes\u00b7t\u00e4t", "be\u00b7tr\u00b7ifft", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Im schimmernden Gestirn, in heller Pracht zu lesen.", "tokens": ["Im", "schim\u00b7mern\u00b7den", "Ge\u00b7stirn", ",", "in", "hel\u00b7ler", "Pracht", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hilf Gott, welch eine Schrift! O! welch ein Wunder-Buch,", "tokens": ["Hilf", "Gott", ",", "welch", "ei\u00b7ne", "Schrift", "!", "O", "!", "welch", "ein", "Wun\u00b7der\u00b7Buch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWAT", "ART", "NN", "$.", "NE", "$.", "PWAT", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In welchem die Gestirne Zeilen,", "tokens": ["In", "wel\u00b7chem", "die", "Ge\u00b7stir\u00b7ne", "Zei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Lettern gr\u00f6sser sind, als hundert tausend Meilen,", "tokens": ["Die", "Let\u00b7tern", "gr\u00f6s\u00b7ser", "sind", ",", "als", "hun\u00b7dert", "tau\u00b7send", "Mei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$,", "KOUS", "CARD", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Woran, in wunderbarem Schein,", "tokens": ["Wo\u00b7ran", ",", "in", "wun\u00b7der\u00b7ba\u00b7rem", "Schein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die Puncte selbsten Sonnen seyn!", "tokens": ["Die", "Punc\u00b7te", "selbs\u00b7ten", "Son\u00b7nen", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ich seh' es, gantz erstaunt, in tiefster Ehrfurcht, an,", "tokens": ["Ich", "seh'", "es", ",", "gantz", "er\u00b7staunt", ",", "in", "tiefs\u00b7ter", "Ehr\u00b7furcht", ",", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADV", "ADJD", "$,", "APPR", "ADJA", "NN", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und, ob den Inhalt gleich mein Geist nicht fassen kann:", "tokens": ["Und", ",", "ob", "den", "In\u00b7halt", "gleich", "mein", "Geist", "nicht", "fas\u00b7sen", "kann", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV", "PPOSAT", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So sp\u00fcr' ich doch, da\u00df sie mich so zu dencken treibt:", "tokens": ["So", "sp\u00fcr'", "ich", "doch", ",", "da\u00df", "sie", "mich", "so", "zu", "den\u00b7cken", "treibt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "PRF", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "O dreymahl h\u00f6chst begl\u00fcckt', o dreymahl sel'ge Seelen,", "tokens": ["O", "drey\u00b7mahl", "h\u00f6chst", "be\u00b7gl\u00fcckt'", ",", "o", "drey\u00b7mahl", "sel'\u00b7ge", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "VVFIN", "$,", "FM", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Der ew'gen Weisheit Licht noch tiefer einzusehn,", "tokens": ["Der", "ew'\u00b7gen", "Weis\u00b7heit", "Licht", "noch", "tie\u00b7fer", "ein\u00b7zu\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Ihn, den Sch\u00f6pfer selbst, den Inhalt, zu verstehn!", "tokens": ["Und", "Ihn", ",", "den", "Sch\u00f6p\u00b7fer", "selbst", ",", "den", "In\u00b7halt", ",", "zu", "ver\u00b7stehn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "ADV", "$,", "ART", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Indessen m\u00fcssen wir,", "tokens": ["In\u00b7des\u00b7sen", "m\u00fcs\u00b7sen", "wir", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Zu unsers Sch\u00f6pfers Ruhm, so lange wir noch hier,", "tokens": ["Zu", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Ruhm", ",", "so", "lan\u00b7ge", "wir", "noch", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "ADV", "ADV", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das Wunder-ABC der Sternen", "tokens": ["Das", "Wun\u00b7der\u00b7ABC", "der", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "In Ehrfurcht buchstabiren lernen.", "tokens": ["In", "Ehr\u00b7furcht", "buch\u00b7sta\u00b7bi\u00b7ren", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.16": {"line.1": {"text": "Es ist kein' eintzige Figur", "tokens": ["Es", "ist", "kein'", "eint\u00b7zi\u00b7ge", "Fi\u00b7gur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im gantzen Reiche der Natur", "tokens": ["Im", "gant\u00b7zen", "Rei\u00b7che", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NE", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu finden, ja nur zu erdencken,", "tokens": ["Zu", "fin\u00b7den", ",", "ja", "nur", "zu", "er\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die, wenn wir Blick und Witz in diese H\u00f6he sencken,", "tokens": ["Die", ",", "wenn", "wir", "Blick", "und", "Witz", "in", "die\u00b7se", "H\u00f6\u00b7he", "sen\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "NN", "KON", "NN", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In diesen tiefen Gr\u00fcnden,", "tokens": ["In", "die\u00b7sen", "tie\u00b7fen", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "In dem unz\u00e4hligen Gestirn, nicht auch zu finden.", "tokens": ["In", "dem", "un\u00b7z\u00e4h\u00b7li\u00b7gen", "Ge\u00b7stirn", ",", "nicht", "auch", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "Sprich nicht: Was Schrift? ich kann sie nicht verstehn", "tokens": ["Sprich", "nicht", ":", "Was", "Schrift", "?", "ich", "kann", "sie", "nicht", "ver\u00b7stehn"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PTKNEG", "$.", "PWS", "NN", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ja nicht einmahl die Lettern sehn.", "tokens": ["Ja", "nicht", "ein\u00b7mahl", "die", "Let\u00b7tern", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PTKNEG", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn h\u00f6r! Kannst du die Lettern der Sinesen,", "tokens": ["Denn", "h\u00f6r", "!", "Kannst", "du", "die", "Let\u00b7tern", "der", "Si\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "VMFIN", "PPER", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Araber, der Russen, lesen?", "tokens": ["Der", "A\u00b7ra\u00b7ber", ",", "der", "Rus\u00b7sen", ",", "le\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "VVINF", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Und kommen ihre Schriften dir", "tokens": ["Und", "kom\u00b7men", "ih\u00b7re", "Schrif\u00b7ten", "dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht gantz verwirrt, ja sonder Ordnung, f\u00fcr?", "tokens": ["Nicht", "gantz", "ver\u00b7wirrt", ",", "ja", "son\u00b7der", "Ord\u00b7nung", ",", "f\u00fcr", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "$,", "ADV", "ADJA", "NN", "$,", "APPR", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die doch, wenn wir sie erst begreifen und entdecken,", "tokens": ["Die", "doch", ",", "wenn", "wir", "sie", "erst", "be\u00b7grei\u00b7fen", "und", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "KOUS", "PPER", "PPER", "ADV", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gar oft voll Geist und Weisheit stecken.", "tokens": ["Gar", "oft", "voll", "Geist", "und", "Weis\u00b7heit", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ich bin, ob dieser Schrift, im Dencken und im Lesen", "tokens": ["Ich", "bin", ",", "ob", "die\u00b7ser", "Schrift", ",", "im", "Den\u00b7cken", "und", "im", "Le\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PDAT", "NN", "$,", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gar oft erfreut, gar oft erstaunt gewesen.", "tokens": ["Gar", "oft", "er\u00b7freut", ",", "gar", "oft", "er\u00b7staunt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "ADV", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Noch j\u00fcngst, als ich im Buch der Sternen,", "tokens": ["Noch", "j\u00fcngst", ",", "als", "ich", "im", "Buch", "der", "Ster\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit inniglicher Lust, studirte,", "tokens": ["Mit", "in\u00b7nig\u00b7li\u00b7cher", "Lust", ",", "stu\u00b7dir\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und, voller Ehrfurcht, buchstabirte;", "tokens": ["Und", ",", "vol\u00b7ler", "Ehr\u00b7furcht", ",", "buch\u00b7sta\u00b7bir\u00b7te", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So deucht mich, da\u00df ich hie und da", "tokens": ["So", "deucht", "mich", ",", "da\u00df", "ich", "hie", "und", "da"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und \u00fcberall geschrieben sah", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "ge\u00b7schrie\u00b7ben", "sah"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den grossen Namen ", "tokens": ["Den", "gros\u00b7sen", "Na\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}}}}