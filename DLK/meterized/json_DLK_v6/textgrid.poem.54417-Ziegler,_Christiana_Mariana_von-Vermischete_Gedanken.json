{"textgrid.poem.54417": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "Vermischete Gedanken", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Dicht- und Redner Kunst liebt, was der Witz erfindet,", "tokens": ["Die", "Dicht", "und", "Red\u00b7ner", "Kunst", "liebt", ",", "was", "der", "Witz", "er\u00b7fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "NN", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Ausdruck lebhaft macht, und rein zusammen bindet;", "tokens": ["Der", "Aus\u00b7druck", "leb\u00b7haft", "macht", ",", "und", "rein", "zu\u00b7sam\u00b7men", "bin\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,", "KON", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie wollen beyderseits, um Aug und Ohr zu laben", "tokens": ["Sie", "wol\u00b7len", "bey\u00b7der\u00b7seits", ",", "um", "Aug", "und", "Ohr", "zu", "la\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "$,", "KOUI", "NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Recht n\u00fcchterne Vernunft und reine Sinne haben.", "tokens": ["Recht", "n\u00fcch\u00b7ter\u00b7ne", "Ver\u00b7nunft", "und", "rei\u00b7ne", "Sin\u00b7ne", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "KON", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wenn Fama sich recht hoch zum Himmel schwingen will,", "tokens": ["Wenn", "Fa\u00b7ma", "sich", "recht", "hoch", "zum", "Him\u00b7mel", "schwin\u00b7gen", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "ADJD", "ADJD", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und weiser Seelen Ruhm soll zu den Sternen tragen,", "tokens": ["Und", "wei\u00b7ser", "See\u00b7len", "Ruhm", "soll", "zu", "den", "Ster\u00b7nen", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So borgt sie bey dem Flug von M\u00e4nnern nur den Kiel,", "tokens": ["So", "borgt", "sie", "bey", "dem", "Flug", "von", "M\u00e4n\u00b7nern", "nur", "den", "Kiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "NN", "ADV", "ART", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Warum? sie darf es nicht, mit Frauenfedern wagen.", "tokens": ["Wa\u00b7rum", "?", "sie", "darf", "es", "nicht", ",", "mit", "Frau\u00b7en\u00b7fe\u00b7dern", "wa\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich meynte bey dem Trieb, den ich gar oft versp\u00fchrt,", "tokens": ["Ich", "meyn\u00b7te", "bey", "dem", "Trieb", ",", "den", "ich", "gar", "oft", "ver\u00b7sp\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und der durch Sehnsucht mir den regen Geist ger\u00fchrt,", "tokens": ["Und", "der", "durch", "Sehn\u00b7sucht", "mir", "den", "re\u00b7gen", "Geist", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NN", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mich noch auf den Olymp begl\u00fcckt hinauf zu schwingen", "tokens": ["Mich", "noch", "auf", "den", "O\u00b7lymp", "be\u00b7gl\u00fcckt", "hin\u00b7auf", "zu", "schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "ADV", "PTKZU", "VVINF"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Weil auch die Musen dort, als Frauenzimmer singen.", "tokens": ["Weil", "auch", "die", "Mu\u00b7sen", "dort", ",", "als", "Frau\u00b7en\u00b7zim\u00b7mer", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "$,", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jedoch mein Hoffen fehlt; ich kann voraus sehn,", "tokens": ["Je\u00b7doch", "mein", "Hof\u00b7fen", "fehlt", ";", "ich", "kann", "vo\u00b7raus", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Da\u00df, leider! selbiges unm\u00f6glich kann geschehn,", "tokens": ["Da\u00df", ",", "lei\u00b7der", "!", "sel\u00b7bi\u00b7ges", "un\u00b7m\u00f6g\u00b7lich", "kann", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "$.", "ADV", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Pierinnen Schaar dr\u00e4ngt mich von ihren Stufen,", "tokens": ["Der", "Pie\u00b7rin\u00b7nen", "Schaar", "dr\u00e4ngt", "mich", "von", "ih\u00b7ren", "Stu\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "So eifrig und bem\u00fcht ich ihr doch zu gerufen,", "tokens": ["So", "eif\u00b7rig", "und", "be\u00b7m\u00fcht", "ich", "ihr", "doch", "zu", "ge\u00b7ru\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Aus Eifersucht und Furcht, es m\u00f6chte nach und nach", "tokens": ["Aus", "Ei\u00b7fer\u00b7sucht", "und", "Furcht", ",", "es", "m\u00f6ch\u00b7te", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "PPER", "VMFIN", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Apollo, der sie liebt, zu nicht geringer Schmach,", "tokens": ["A\u00b7pol\u00b7lo", ",", "der", "sie", "liebt", ",", "zu", "nicht", "ge\u00b7rin\u00b7ger", "Schmach", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und ihrem gr\u00f6sten Schmerz, dem fremden Gast daneben", "tokens": ["Und", "ih\u00b7rem", "gr\u00f6s\u00b7ten", "Schmerz", ",", "dem", "frem\u00b7den", "Gast", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein freundliches Gesicht, und holdes Blickchen geben.", "tokens": ["Ein", "freund\u00b7li\u00b7ches", "Ge\u00b7sicht", ",", "und", "hol\u00b7des", "Bli\u00b7ck\u00b7chen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Man trifft von keinem Bild so viel Copien an", "tokens": ["Man", "trifft", "von", "kei\u00b7nem", "Bild", "so", "viel", "Co\u00b7pi\u00b7en", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "PIAT", "NN", "ADV", "PIAT", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als uns von ihrem Ri\u00df die Falschheit zeigen kann.", "tokens": ["Als", "uns", "von", "ih\u00b7rem", "Ri\u00df", "die", "Falschheit", "zei\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wie viele giebt es doch, die sich an sonst nichts kehren,", "tokens": ["Wie", "vie\u00b7le", "giebt", "es", "doch", ",", "die", "sich", "an", "sonst", "nichts", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "ADV", "$,", "PRELS", "PRF", "APPR", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und diese Schilderey aufs innigste verehren!", "tokens": ["Und", "die\u00b7se", "Schil\u00b7de\u00b7rey", "aufs", "in\u00b7nigs\u00b7te", "ver\u00b7eh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Allein ich kenne dich, Freund von ganz andrer Art,", "tokens": ["Al\u00b7lein", "ich", "ken\u00b7ne", "dich", ",", "Freund", "von", "ganz", "an\u00b7drer", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "$,", "NN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+++-+-+", "measure": "unknown.measure.septa"}, "line.6": {"text": "Drum da dein Redlich seyn gar kein Bem\u00fchen spart,", "tokens": ["Drum", "da", "dein", "Red\u00b7lich", "seyn", "gar", "kein", "Be\u00b7m\u00fc\u00b7hen", "spart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PPOSAT", "NN", "PPOSAT", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vor wahrer Freunde wohl das \u00e4usserste zu wagen,", "tokens": ["Vor", "wah\u00b7rer", "Freun\u00b7de", "wohl", "das", "\u00e4us\u00b7sers\u00b7te", "zu", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So kann ich dies Recht zu deinem Lobe sagen.", "tokens": ["So", "kann", "ich", "dies", "Recht", "zu", "dei\u00b7nem", "Lo\u00b7be", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PDS", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+---+-+-+-+-", "measure": "dactylic.init"}}, "stanza.5": {"line.1": {"text": "Das Schicksal l\u00e4\u00dft sich nicht auch von den kl\u00fcgsten Geistern", "tokens": ["Das", "Schick\u00b7sal", "l\u00e4\u00dft", "sich", "nicht", "auch", "von", "den", "kl\u00fcgs\u00b7ten", "Geis\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch Einhalt, Kunst und List, Verstand und Einsicht meistern,", "tokens": ["Durch", "Ein\u00b7halt", ",", "Kunst", "und", "List", ",", "Ver\u00b7stand", "und", "Ein\u00b7sicht", "meis\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sein Lauf bleibt ungest\u00f6rt, es lenkt die ganze Welt,", "tokens": ["Sein", "Lauf", "bleibt", "un\u00b7ge\u00b7st\u00f6rt", ",", "es", "lenkt", "die", "gan\u00b7ze", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und f\u00fchret alles so, wie es ihm selbst gef\u00e4llt.", "tokens": ["Und", "f\u00fch\u00b7ret", "al\u00b7les", "so", ",", "wie", "es", "ihm", "selbst", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Dem mu\u00df ein blinder Zug sein Aug und Ohr verriegeln,", "tokens": ["Dem", "mu\u00df", "ein", "blin\u00b7der", "Zug", "sein", "Aug", "und", "Ohr", "ver\u00b7rie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der frech in die Gefahr, und k\u00fchn ins Ungl\u00fcck geht,", "tokens": ["Der", "frech", "in", "die", "Ge\u00b7fahr", ",", "und", "k\u00fchn", "ins", "Un\u00b7gl\u00fcck", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "$,", "KON", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein ein kluger Mann der noch am Ufer steht,", "tokens": ["Al\u00b7lein", "ein", "klu\u00b7ger", "Mann", "der", "noch", "am", "U\u00b7fer", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ART", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird sich unfehlbar wohl an andrer Schiffbruch spiegeln.", "tokens": ["Wird", "sich", "un\u00b7fehl\u00b7bar", "wohl", "an", "an\u00b7drer", "Schiff\u00b7bruch", "spie\u00b7geln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADJD", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Das schnell seyn hilft zum Laufen nicht,", "tokens": ["Das", "schnell", "seyn", "hilft", "zum", "Lau\u00b7fen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VAINF", "VVFIN", "APPRART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn Zeit und Gl\u00fccke widerspricht.", "tokens": ["Wenn", "Zeit", "und", "Gl\u00fc\u00b7cke", "wi\u00b7der\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man l\u00e4uft umsonst auf dieser Bahn", "tokens": ["Man", "l\u00e4uft", "um\u00b7sonst", "auf", "die\u00b7ser", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und b\u00e4nden wir uns Schrittschuh an.", "tokens": ["Und", "b\u00e4n\u00b7den", "wir", "uns", "Schritt\u00b7schuh", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ein Jason, wenn er will das g\u00fcldne Vlie\u00df erfechten,", "tokens": ["Ein", "Ja\u00b7son", ",", "wenn", "er", "will", "das", "g\u00fcld\u00b7ne", "Vlie\u00df", "er\u00b7fech\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "VMFIN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Schl\u00e4gt der Centauren Heer zur linken und zur rechten,", "tokens": ["Schl\u00e4gt", "der", "Cen\u00b7tau\u00b7ren", "Heer", "zur", "lin\u00b7ken", "und", "zur", "rech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "APPRART", "ADJA", "KON", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum wer das Kleinod sucht, das uns die Pallas weist,", "tokens": ["Drum", "wer", "das", "Klei\u00b7nod", "sucht", ",", "das", "uns", "die", "Pal\u00b7las", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PWS", "ART", "NN", "VVFIN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ringe stets darnach mit unerschrocknem Geist.", "tokens": ["Der", "rin\u00b7ge", "stets", "dar\u00b7nach", "mit", "un\u00b7er\u00b7schrock\u00b7nem", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PAV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Es braucht zwar St\u00e4rk und Muth die Feinde zu bezwingen,", "tokens": ["Es", "braucht", "zwar", "St\u00e4rk", "und", "Muth", "die", "Fein\u00b7de", "zu", "be\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "KON", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und auch ein wildes Thier in Schling und Zaum zu bringen.", "tokens": ["Und", "auch", "ein", "wil\u00b7des", "Thier", "in", "Schling", "und", "Zaum", "zu", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch wer sich selbst bezwingt, der zeiget in der That,", "tokens": ["Doch", "wer", "sich", "selbst", "be\u00b7zwingt", ",", "der", "zei\u00b7get", "in", "der", "That", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "ADV", "VVFIN", "$,", "PRELS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df er den gr\u00f6sten Sieg dadurch erfochten hat.", "tokens": ["Da\u00df", "er", "den", "gr\u00f6s\u00b7ten", "Sieg", "da\u00b7durch", "er\u00b7foch\u00b7ten", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PAV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Apollo bildet sich auf dich was grosses ein", "tokens": ["A\u00b7pol\u00b7lo", "bil\u00b7det", "sich", "auf", "dich", "was", "gros\u00b7ses", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "APPR", "PPER", "PWS", "ADJA", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und spricht: \u2013 \u2013 \u2013 mu\u00df mein bester Pfeiler seyn.", "tokens": ["Und", "spricht", ":", "\u2013", "\u2013", "\u2013", "mu\u00df", "mein", "bes\u00b7ter", "Pfei\u00b7ler", "seyn", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "$(", "$(", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Allein der Musengott scheint sich zu \u00fcbereilen.", "tokens": ["Al\u00b7lein", "der", "Mu\u00b7sen\u00b7gott", "scheint", "sich", "zu", "\u00fc\u00b7be\u00b7rei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Denn Suada g\u00f6nnt ihm nicht aus Neid dergleichen Ruhm.", "tokens": ["Denn", "Sua\u00b7da", "g\u00f6nnt", "ihm", "nicht", "aus", "Neid", "derg\u00b7lei\u00b7chen", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "PIS", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie nennet dich zugleich mein Freund, ihr Eigenthum", "tokens": ["Sie", "nen\u00b7net", "dich", "zu\u00b7gleich", "mein", "Freund", ",", "ihr", "Ei\u00b7gen\u00b7thum"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was Rath? sie m\u00fcssen sich in dich unfehlbar theilen.", "tokens": ["Was", "Rath", "?", "sie", "m\u00fcs\u00b7sen", "sich", "in", "dich", "un\u00b7fehl\u00b7bar", "thei\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "PPER", "VMFIN", "PRF", "APPR", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+++-+-", "measure": "unknown.measure.septa"}}, "stanza.11": {"line.1": {"text": "Was dich, geehrter Freund, zu meinen Freuenden schreibt,", "tokens": ["Was", "dich", ",", "ge\u00b7ehr\u00b7ter", "Freund", ",", "zu", "mei\u00b7nen", "Freu\u00b7en\u00b7den", "schreibt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "$,", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ist deine Redlichkeit, und dein gelehrtes Wissen,", "tokens": ["Ist", "dei\u00b7ne", "Red\u00b7lich\u00b7keit", ",", "und", "dein", "ge\u00b7lehr\u00b7tes", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Davor dir in der That mein Angedenken bleibt,", "tokens": ["Da\u00b7vor", "dir", "in", "der", "That", "mein", "An\u00b7ge\u00b7den\u00b7ken", "bleibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob ich hinf\u00fchro gleich mu\u00df deinen Zuspruch missen.", "tokens": ["Ob", "ich", "hin\u00b7f\u00fch\u00b7ro", "gleich", "mu\u00df", "dei\u00b7nen", "Zu\u00b7spruch", "mis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VMFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}