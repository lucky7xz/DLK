{"textgrid.poem.24545": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Fabel", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ins Land der Wissenschafft gieng ", "tokens": ["Ins", "Land", "der", "Wis\u00b7sen\u00b7schafft", "gieng"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und traff drey Menschen an:", "tokens": ["Und", "traff", "drey", "Men\u00b7schen", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er dachte/ wenn ich sie zu Freunden haben kan/", "tokens": ["Er", "dach\u00b7te", "/", "wenn", "ich", "sie", "zu", "Freun\u00b7den", "ha\u00b7ben", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "PPER", "APPR", "NN", "VAINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So werden sie mich wohl zu rechte f\u00fchren.", "tokens": ["So", "wer\u00b7den", "sie", "mich", "wohl", "zu", "rech\u00b7te", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ADV", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Mine war an ihnen gut.", "tokens": ["Die", "Mi\u00b7ne", "war", "an", "ih\u00b7nen", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der erste sprach zu ihm: Wir werden M\u00fche haben/", "tokens": ["Der", "ers\u00b7te", "sprach", "zu", "ihm", ":", "Wir", "wer\u00b7den", "M\u00fc\u00b7he", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "PPER", "$.", "PPER", "VAFIN", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch dieses Land zu gehn: drum unser junges Blut", "tokens": ["Durch", "die\u00b7ses", "Land", "zu", "gehn", ":", "drum", "un\u00b7ser", "jun\u00b7ges", "Blut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "$.", "PAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Soll/ wenn es dir beliebt/ sich unter wegens laben.", "tokens": ["Soll", "/", "wenn", "es", "dir", "be\u00b7liebt", "/", "sich", "un\u00b7ter", "we\u00b7gens", "la\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$(", "KOUS", "PPER", "PPER", "ADJD", "$(", "PRF", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich wei\u00df ein Hau\u00df/ da hat man guten Wein/", "tokens": ["Ich", "wei\u00df", "ein", "Hau\u00df", "/", "da", "hat", "man", "gu\u00b7ten", "Wein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "ADV", "VAFIN", "PIS", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ich wei\u00df ein Hau\u00df/ da Sch\u00f6nen drinnen seyn/", "tokens": ["Ich", "wei\u00df", "ein", "Hau\u00df", "/", "da", "Sch\u00f6\u00b7nen", "drin\u00b7nen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "KOUS", "NN", "ADV", "VAINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ich wei\u00df ein Hau\u00df/ da spielet man in Karten:", "tokens": ["Ich", "wei\u00df", "ein", "Hau\u00df", "/", "da", "spie\u00b7let", "man", "in", "Kar\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "ADV", "VVFIN", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wenn wir daselbst gewesen sind/", "tokens": ["Wenn", "wir", "da\u00b7selbst", "ge\u00b7we\u00b7sen", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "VAPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So wollen wir auch unsrer Sachen warten.", "tokens": ["So", "wol\u00b7len", "wir", "auch", "uns\u00b7rer", "Sa\u00b7chen", "war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Ein Kluger wehlt die Lust/ und lauter M\u00fch ein Kind:", "tokens": ["Ein", "Klu\u00b7ger", "wehlt", "die", "Lust", "/", "und", "lau\u00b7ter", "M\u00fch", "ein", "Kind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$(", "KON", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bey den Gelehrten gilt di\u00df Kleeblat allzuviel;", "tokens": ["Bey", "den", "Ge\u00b7lehr\u00b7ten", "gilt", "di\u00df", "Klee\u00b7blat", "all\u00b7zu\u00b7viel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PDS", "NN", "PIAT", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.16": {"text": "Wein/ Weiber/ Karten-Spiel.", "tokens": ["Wein", "/", "Wei\u00b7ber", "/", "Kar\u00b7ten\u00b7Spiel", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Der andre sprach zu ihm: was wilst du hier ", "tokens": ["Der", "and\u00b7re", "sprach", "zu", "ihm", ":", "was", "wilst", "du", "hier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPER", "$.", "PWS", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Und deine Zeit verliehren?", "tokens": ["Und", "dei\u00b7ne", "Zeit", "ver\u00b7lieh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Ein besser Weg geht in des ", "tokens": ["Ein", "bes\u00b7ser", "Weg", "geht", "in", "des"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "Ein Degen und ein Pferd verdienen eher Geld/", "tokens": ["Ein", "De\u00b7gen", "und", "ein", "Pferd", "ver\u00b7die\u00b7nen", "e\u00b7her", "Geld", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "ADV", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Als ein gelehrtes Buch. Ich soll allhier zwar leben;", "tokens": ["Als", "ein", "ge\u00b7lehr\u00b7tes", "Buch", ".", "Ich", "soll", "all\u00b7hier", "zwar", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$.", "PPER", "VMFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Doch weil ich mich will in den Krieg begeben/", "tokens": ["Doch", "weil", "ich", "mich", "will", "in", "den", "Krieg", "be\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "VMFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Was ist es nutz/ da\u00df ein Soldat", "tokens": ["Was", "ist", "es", "nutz", "/", "da\u00df", "ein", "Sol\u00b7dat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "NN", "$(", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Viel Wissenschafft gelernet hat?", "tokens": ["Viel", "Wis\u00b7sen\u00b7schafft", "ge\u00b7ler\u00b7net", "hat", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Die er doch wieder wird vergessen.", "tokens": ["Die", "er", "doch", "wie\u00b7der", "wird", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Das Geld vergn\u00fcgt verthan/ ", "tokens": ["Das", "Geld", "ver\u00b7gn\u00fcgt", "ver\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Denn die Musqnete her/ das ist mein ", "tokens": ["Denn", "die", "Mus\u00b7qne\u00b7te", "her", "/", "das", "ist", "mein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PTKVZ", "$(", "PDS", "VAFIN", "PPOSAT"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.28": {"text": "Hier sahe sich der ", "tokens": ["Hier", "sa\u00b7he", "sich", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.29": {"text": "Was/ dacht er in sich selbst/ sind in des ", "tokens": ["Was", "/", "dacht", "er", "in", "sich", "selbst", "/", "sind", "in", "des"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "$(", "VVFIN", "PPER", "APPR", "PRF", "ADV", "$(", "VAFIN", "APPR", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Nur Menschen/ die so artig/ anzuschauen?", "tokens": ["Nur", "Men\u00b7schen", "/", "die", "so", "ar\u00b7tig", "/", "an\u00b7zu\u00b7schau\u00b7en", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "NN", "$(", "ART", "ADV", "ADJD", "$(", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Er sprach darauf den dritten an/", "tokens": ["Er", "sprach", "da\u00b7rauf", "den", "drit\u00b7ten", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ART", "ADJA", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Der bath ihn/ durch di\u00df Land/ und endlich durch", "tokens": ["Der", "ba\u00b7th", "ihn", "/", "durch", "di\u00df", "Land", "/", "und", "end\u00b7lich", "durch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "$(", "APPR", "PDS", "NN", "$(", "KON", "ADV", "APPR"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.33": {"text": "Mit ihm zu gehn.", "tokens": ["Mit", "ihm", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.34": {"text": "Dieweil es bald um diesen Tag gethan;", "tokens": ["Die\u00b7weil", "es", "bald", "um", "die\u00b7sen", "Tag", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Vor Abends w\u00fcrden sie sonst an den Ort nicht kommen/", "tokens": ["Vor", "A\u00b7bends", "w\u00fcr\u00b7den", "sie", "sonst", "an", "den", "Ort", "nicht", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Alwo der kl\u00fcgste Theil stets Herberge genommen/", "tokens": ["Al\u00b7wo", "der", "kl\u00fcgs\u00b7te", "Theil", "stets", "Her\u00b7ber\u00b7ge", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADV", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Und m\u00fcsten sonst zur Schande/ Schmach und Pein", "tokens": ["Und", "m\u00fcs\u00b7ten", "sonst", "zur", "Schan\u00b7de", "/", "Schmach", "und", "Pein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "APPRART", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Im Narren Wirths-Hau\u00df G\u00e4ste seyn.", "tokens": ["Im", "Nar\u00b7ren", "Wirths\u00b7Hau\u00df", "G\u00e4s\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Es w\u00fcrde sich das andere Vergn\u00fcgen", "tokens": ["Es", "w\u00fcr\u00b7de", "sich", "das", "an\u00b7de\u00b7re", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Rach abgelegter Reise f\u00fcgen.", "tokens": ["Rach", "ab\u00b7ge\u00b7leg\u00b7ter", "Rei\u00b7se", "f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Gelehrt- und Wehrter Freund/ du eilest nun dahin/", "tokens": ["Ge\u00b7lehr\u00b7t", "und", "Wehr\u00b7ter", "Freund", "/", "du", "ei\u00b7lest", "nun", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "NN", "$(", "PPER", "VVFIN", "ADV", "PAV", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.42": {"text": "Wo wir die Ehren Frucht auf M\u00fch und Arbeit lesen.", "tokens": ["Wo", "wir", "die", "Eh\u00b7ren", "Frucht", "auf", "M\u00fch", "und", "Ar\u00b7beit", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Wodurch ich aber gl\u00fccklich bin/", "tokens": ["Wo\u00b7durch", "ich", "a\u00b7ber", "gl\u00fcck\u00b7lich", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Ist weil wir lange Zeit Gefehrten sind gewesen.", "tokens": ["Ist", "weil", "wir", "lan\u00b7ge", "Zeit", "Ge\u00b7fehr\u00b7ten", "sind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOUS", "PPER", "ADV", "NN", "NN", "VAFIN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}