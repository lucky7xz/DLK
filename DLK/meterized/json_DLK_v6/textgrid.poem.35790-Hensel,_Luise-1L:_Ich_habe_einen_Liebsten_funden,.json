{"textgrid.poem.35790": {"metadata": {"author": {"name": "Hensel, Luise", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich habe einen Liebsten funden,", "genre": "verse", "period": "N.A.", "pub_year": 1816, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe einen Liebsten funden,", "tokens": ["Ich", "ha\u00b7be", "ei\u00b7nen", "Liebs\u00b7ten", "fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Derselb' ist nicht von dieser Welt,", "tokens": ["Der\u00b7selb'", "ist", "nicht", "von", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem hab' ich einzig mich verbunden,", "tokens": ["Dem", "hab'", "ich", "ein\u00b7zig", "mich", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm treu zu sein in allen Stunden;", "tokens": ["Ihm", "treu", "zu", "sein", "in", "al\u00b7len", "Stun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VAINF", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er ist's, der mir allein gef\u00e4llt.", "tokens": ["Er", "ist's", ",", "der", "mir", "al\u00b7lein", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Fr\u00fch stand Er schon an meiner Wiegen,", "tokens": ["Fr\u00fch", "stand", "Er", "schon", "an", "mei\u00b7ner", "Wie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sah l\u00e4chelnd auf mein kindlich Spiel.", "tokens": ["Sah", "l\u00e4\u00b7chelnd", "auf", "mein", "kind\u00b7lich", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich that so gern mich an Ihn schmiegen", "tokens": ["Ich", "that", "so", "gern", "mich", "an", "Ihn", "schmie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PPER", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und forschte nur in Seinen Z\u00fcgen,", "tokens": ["Und", "forschte", "nur", "in", "Sei\u00b7nen", "Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ob auch mein Spiel Ihm wohlgefiel.", "tokens": ["Ob", "auch", "mein", "Spiel", "Ihm", "wohl\u00b7ge\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Er hatte mir von wei\u00dfer Seiden", "tokens": ["Er", "hat\u00b7te", "mir", "von", "wei\u00b7\u00dfer", "Sei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein feines Kleidchen angethan:", "tokens": ["Ein", "fei\u00b7nes", "Kleid\u00b7chen", "an\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbo L\u00e4mmlein, komm zu Meiner Weiden;", "tokens": ["\u00bb", "o", "L\u00e4mm\u00b7lein", ",", "komm", "zu", "Mei\u00b7ner", "Wei\u00b7den", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nun mu\u00dft Du Dich von Allem scheiden,", "tokens": ["Nun", "mu\u00dft", "Du", "Dich", "von", "Al\u00b7lem", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was dies Gewand beflecken kann.\u00ab", "tokens": ["Was", "dies", "Ge\u00b7wand", "be\u00b7fle\u00b7cken", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "PDS", "NN", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "O w\u00e4r' ich doch mit Dir gegangen,", "tokens": ["O", "w\u00e4r'", "ich", "doch", "mit", "Dir", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du treuer Hirt, mit Dir allein!", "tokens": ["Du", "treu\u00b7er", "Hirt", ",", "mit", "Dir", "al\u00b7lein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Andrer wies mir Glanz und Spangen; \u2013", "tokens": ["Ein", "A\u00b7ndrer", "wies", "mir", "Glanz", "und", "Span\u00b7gen", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "O weh! die goldnen Ketten schlangen", "tokens": ["O", "weh", "!", "die", "gold\u00b7nen", "Ket\u00b7ten", "schlan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$.", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So fest sich um das Herze mein.", "tokens": ["So", "fest", "sich", "um", "das", "Her\u00b7ze", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PDS", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Da ging ich mit dem Fremden lieber", "tokens": ["Da", "ging", "ich", "mit", "dem", "Frem\u00b7den", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ri\u00df mich los von meinem Herrn;", "tokens": ["Und", "ri\u00df", "mich", "los", "von", "mei\u00b7nem", "Herrn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der sah noch oft zu mir her\u00fcber,", "tokens": ["Der", "sah", "noch", "oft", "zu", "mir", "her\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich sah wohl auch nach Ihm hin\u00fcber,", "tokens": ["Ich", "sah", "wohl", "auch", "nach", "Ihm", "hin\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch immer schien Er mir zu fern.", "tokens": ["Doch", "im\u00b7mer", "schien", "Er", "mir", "zu", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Bald dreht' ich mich in bunten T\u00e4nzen", "tokens": ["Bald", "dreht'", "ich", "mich", "in", "bun\u00b7ten", "T\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und tr\u00e4umte nur von Tand und Scherz;", "tokens": ["Und", "tr\u00e4um\u00b7te", "nur", "von", "Tand", "und", "Scherz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich that an schn\u00f6den Festen gl\u00e4nzen", "tokens": ["Ich", "that", "an", "schn\u00f6\u00b7den", "Fes\u00b7ten", "gl\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und war geschm\u00fcckt mit eitlen Kr\u00e4nzen,", "tokens": ["Und", "war", "ge\u00b7schm\u00fcckt", "mit", "eit\u00b7len", "Kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und hatte doch kein ruhig Herz.", "tokens": ["Und", "hat\u00b7te", "doch", "kein", "ru\u00b7hig", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Da dacht' ich einst, welch' blut'ge Wunden", "tokens": ["Da", "dacht'", "ich", "einst", ",", "welch'", "blut'\u00b7ge", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr mich der treue Heiland trug;", "tokens": ["F\u00fcr", "mich", "der", "treu\u00b7e", "Hei\u00b7land", "trug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich dacht' an fr\u00fche sel'ge Stunden \u2013", "tokens": ["Ich", "dacht'", "an", "fr\u00fc\u00b7he", "sel'\u00b7ge", "Stun\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die ganze Welt war mir verschwunden \u2013", "tokens": ["Die", "gan\u00b7ze", "Welt", "war", "mir", "ver\u00b7schwun\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich weint', und weinte nie genug.", "tokens": ["Ich", "weint'", ",", "und", "wein\u00b7te", "nie", "ge\u00b7nug", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Da sah ich meinen Heiland stehen,", "tokens": ["Da", "sah", "ich", "mei\u00b7nen", "Hei\u00b7land", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er war so ernst und war so mild;", "tokens": ["Er", "war", "so", "ernst", "und", "war", "so", "mild", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich mu\u00dfte immer nach Ihm sehen;", "tokens": ["Ich", "mu\u00df\u00b7te", "im\u00b7mer", "nach", "Ihm", "se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Herze wollte fast vergehen", "tokens": ["Mein", "Her\u00b7ze", "woll\u00b7te", "fast", "ver\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "VVFIN", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und war mit Lieb' und Leid erf\u00fcllt.", "tokens": ["Und", "war", "mit", "Lieb'", "und", "Leid", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich meint': Er w\u00fcrde mich nicht kennen,", "tokens": ["Ich", "meint'", ":", "Er", "w\u00fcr\u00b7de", "mich", "nicht", "ken\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Kleid war nicht mehr wei\u00df und rein.", "tokens": ["Mein", "Kleid", "war", "nicht", "mehr", "wei\u00df", "und", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bang that ich Seinen Namen nennen,", "tokens": ["Bang", "that", "ich", "Sei\u00b7nen", "Na\u00b7men", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und wollte nie mich wieder trennen", "tokens": ["Und", "woll\u00b7te", "nie", "mich", "wie\u00b7der", "tren\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und ganz und gar Sein eigen sein.", "tokens": ["Und", "ganz", "und", "gar", "Sein", "ei\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "PPOSAT", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Da sah Er meine Thr\u00e4nen flie\u00dfen,", "tokens": ["Da", "sah", "Er", "mei\u00b7ne", "Thr\u00e4\u00b7nen", "flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da rief Er freundlich: \u00bbL\u00e4mmlein, komm!\u00ab", "tokens": ["Da", "rief", "Er", "freund\u00b7lich", ":", "\u00bb", "L\u00e4mm\u00b7lein", ",", "komm", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "$(", "NN", "$,", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Froh eilt' ich hin zu Seinen F\u00fc\u00dfen;", "tokens": ["Froh", "eilt'", "ich", "hin", "zu", "Sei\u00b7nen", "F\u00fc\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Blut that auf mich niederflie\u00dfen,", "tokens": ["Sein", "Blut", "that", "auf", "mich", "nie\u00b7der\u00b7flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da war ich wieder rein und fromm.", "tokens": ["Da", "war", "ich", "wie\u00b7der", "rein", "und", "fromm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "So hab' ich meinen Liebsten funden,", "tokens": ["So", "hab'", "ich", "mei\u00b7nen", "Liebs\u00b7ten", "fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der besser ist denn diese Welt,", "tokens": ["Der", "bes\u00b7ser", "ist", "denn", "die\u00b7se", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hab' ich Ihm mich neu verbunden,", "tokens": ["So", "hab'", "ich", "Ihm", "mich", "neu", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm treu zu sein zu allen Stunden:", "tokens": ["Ihm", "treu", "zu", "sein", "zu", "al\u00b7len", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VAINF", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er ist's, der einzig mir gef\u00e4llt.", "tokens": ["Er", "ist's", ",", "der", "ein\u00b7zig", "mir", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}