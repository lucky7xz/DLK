{"dta.poem.9235": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n Der Jungfern Andrees-Gebet.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ach Sanet Andrees! erbarme dich/", "tokens": ["Ach", "Sa\u00b7net", "An\u00b7drees", "!", "er\u00b7bar\u00b7me", "dich", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PIS", "$.", "VVFIN", "PPER", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und gib mir einen mann/", "tokens": ["Und", "gib", "mir", "ei\u00b7nen", "mann", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und weil ich ihn so eigentlich", "tokens": ["Und", "weil", "ich", "ihn", "so", "ei\u00b7gent\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jetzund nicht nennen kan/", "tokens": ["Je\u00b7tzund", "nicht", "nen\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "So komm/ und bring ihn diese nacht/", "tokens": ["So", "komm", "/", "und", "bring", "ihn", "die\u00b7se", "nacht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KON", "VVFIN", "PPER", "PDAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df er vor meinen bette lacht", "tokens": ["Da\u00df", "er", "vor", "mei\u00b7nen", "bet\u00b7te", "lacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So bin ich wohl daran.", "tokens": ["So", "bin", "ich", "wohl", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Ist er nicht gro\u00df und lang genung/", "tokens": ["Ist", "er", "nicht", "gro\u00df", "und", "lang", "ge\u00b7nung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "KON", "ADJD", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So mag er kleine seyn/", "tokens": ["So", "mag", "er", "klei\u00b7ne", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJA", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist er nicht mehr an jahren jung/", "tokens": ["Ist", "er", "nicht", "mehr", "an", "jah\u00b7ren", "jung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mag er \u00e4ltlich seyn.", "tokens": ["So", "mag", "er", "\u00e4lt\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ist er nicht sitsam auf der freyth/", "tokens": ["Ist", "er", "nicht", "sit\u00b7sam", "auf", "der", "frey\u00b7th", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "APPR", "ART", "NN", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und hat zu wenig fr\u00f6mmigkeit/", "tokens": ["Und", "hat", "zu", "we\u00b7nig", "fr\u00f6m\u00b7mig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mag er b\u00f6se seyn.", "tokens": ["So", "mag", "er", "b\u00f6\u00b7se", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. Wei\u00df und versteht er nicht gar viel/", "tokens": ["Wei\u00df", "und", "ver\u00b7steht", "er", "nicht", "gar", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So mag er albern seyn/", "tokens": ["So", "mag", "er", "al\u00b7bern", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo er nicht hunger leiden wil/", "tokens": ["Wo", "er", "nicht", "hun\u00b7ger", "lei\u00b7den", "wil", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mag er fressig seyn.", "tokens": ["So", "mag", "er", "fres\u00b7sig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und wo er ja von morgen an", "tokens": ["Und", "wo", "er", "ja", "von", "mor\u00b7gen", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADV", "APPR", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den durst nicht wohl vertragen kan/", "tokens": ["Den", "durst", "nicht", "wohl", "ver\u00b7tra\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "ADV", "VVFIN", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mag er versoffen seyn.", "tokens": ["Mag", "er", "ver\u00b7sof\u00b7fen", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.4": {"line.1": {"text": "4. Ist er des schweigens nicht gewohnt/", "tokens": ["Ist", "er", "des", "schwei\u00b7gens", "nicht", "ge\u00b7wohnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADV", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So mag er keiffig seyn/", "tokens": ["So", "mag", "er", "keif\u00b7fig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo er das liebe geld nicht schont/", "tokens": ["Wo", "er", "das", "lie\u00b7be", "geld", "nicht", "schont", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mag er vertuhnlich seyn.", "tokens": ["Mag", "er", "ver\u00b7tuhn\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Und wenn es sich so wohl nicht f\u00fcgt/", "tokens": ["Und", "wenn", "es", "sich", "so", "wohl", "nicht", "f\u00fcgt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "ADV", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df er im bette trocken liegt/", "tokens": ["Da\u00df", "er", "im", "bet\u00b7te", "tro\u00b7cken", "liegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "VVFIN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mag er garstig seyn.", "tokens": ["So", "mag", "er", "gars\u00b7tig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "5. Ist er am leibe nicht gesund/", "tokens": ["Ist", "er", "am", "lei\u00b7be", "nicht", "ge\u00b7sund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So mag er unpa\u00df seyn.", "tokens": ["So", "mag", "er", "un\u00b7pa\u00df", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hat er nicht einen glatten mund/", "tokens": ["Hat", "er", "nicht", "ei\u00b7nen", "glat\u00b7ten", "mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mag er runtzlich seyn.", "tokens": ["So", "mag", "er", "runtz\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und zeiget sich sein angesicht", "tokens": ["Und", "zei\u00b7get", "sich", "sein", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In unbefleckten farben nicht/", "tokens": ["In", "un\u00b7be\u00b7fleck\u00b7ten", "far\u00b7ben", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mag er k\u00fcpffern seyn.", "tokens": ["So", "mag", "er", "k\u00fcpf\u00b7fern", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "6. Ist es kein feiner edelmann/", "tokens": ["Ist", "es", "kein", "fei\u00b7ner", "e\u00b7del\u00b7mann", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So mags ein bauer seyn/", "tokens": ["So", "mags", "ein", "bau\u00b7er", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Giebt sich kein grosser doctor an/", "tokens": ["Giebt", "sich", "kein", "gros\u00b7ser", "doc\u00b7tor", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIAT", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mags ein schuster seyn/", "tokens": ["So", "mags", "ein", "schus\u00b7ter", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJD", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "H\u00e4lt mich kein kauffmann nicht so werth/", "tokens": ["H\u00e4lt", "mich", "kein", "kauf\u00b7fmann", "nicht", "so", "werth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADV", "PTKNEG", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df er mich zu der frau begehrt/", "tokens": ["Da\u00df", "er", "mich", "zu", "der", "frau", "be\u00b7gehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mags ein m\u00e4ckler seyn.", "tokens": ["So", "mags", "ein", "m\u00e4ck\u00b7ler", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "7. Ist es kein Superintendent/", "tokens": ["Ist", "es", "kein", "Su\u00b7pe\u00b7rin\u00b7ten\u00b7dent", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "So mags ein k\u00fcster seyn/", "tokens": ["So", "mags", "ein", "k\u00fcs\u00b7ter", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJD", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ist kein sch\u00f6sser der mich kennt/", "tokens": ["Und", "ist", "kein", "sch\u00f6s\u00b7ser", "der", "mich", "kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "ADJA", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mags ein schreiber seyn.", "tokens": ["So", "mags", "ein", "schrei\u00b7ber", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und wo der b\u00fcrgermeister nicht", "tokens": ["Und", "wo", "der", "b\u00fcr\u00b7ger\u00b7meis\u00b7ter", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mir in der zeit die eh verspricht/", "tokens": ["Mir", "in", "der", "zeit", "die", "eh", "ver\u00b7spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mags der th\u00fcrknecht seyn.", "tokens": ["So", "mags", "der", "th\u00fcr\u00b7knecht", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "8. Wo er nicht tausend thaler schafft/", "tokens": ["Wo", "er", "nicht", "tau\u00b7send", "tha\u00b7ler", "schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So m\u00f6gens zwantzig seyn/", "tokens": ["So", "m\u00f6\u00b7gens", "zwant\u00b7zig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "CARD", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hat er kein kleid von doppeldafft/", "tokens": ["Hat", "er", "kein", "kleid", "von", "dop\u00b7pel\u00b7dafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "APPR", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mags wohl leinwand seyn/", "tokens": ["So", "mags", "wohl", "lein\u00b7wand", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Und wenn er in und aus der stadt", "tokens": ["Und", "wenn", "er", "in", "und", "aus", "der", "stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch nicht ein eignes h\u00e4u\u00dfgen hat/", "tokens": ["Auch", "nicht", "ein", "eig\u00b7nes", "h\u00e4u\u00df\u00b7gen", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mags ein mietmann seyn.", "tokens": ["So", "mags", "ein", "miet\u00b7mann", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "9. Wo sich kein junggeselle findt/", "tokens": ["Wo", "sich", "kein", "jung\u00b7ge\u00b7sel\u00b7le", "findt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PIAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So mags ein wittwer seyn.", "tokens": ["So", "mags", "ein", "witt\u00b7wer", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist es kein ehrlich mutterkind/", "tokens": ["Ist", "es", "kein", "ehr\u00b7lich", "mut\u00b7ter\u00b7kind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mags ein banck art seyn.", "tokens": ["So", "mags", "ein", "banck", "art", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und ist es kein bewehrter mann", "tokens": ["Und", "ist", "es", "kein", "be\u00b7wehr\u00b7ter", "mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der neunmahl neune zehlen kan/", "tokens": ["Der", "neun\u00b7mahl", "neu\u00b7ne", "zeh\u00b7len", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mags ein \u2012 \u2012 \u2012 \u2012 seyn.", "tokens": ["So", "mags", "ein", "\u2012", "\u2012", "\u2012", "\u2012", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "$(", "$(", "$(", "$(", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "10. Ach Sanct Andreas/ ich trage doch", "tokens": ["Ach", "Sanct", "A\u00b7ndre\u00b7as", "/", "ich", "tra\u00b7ge", "doch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "VVFIN", "NE", "$(", "PPER", "VVFIN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die keuschheit mit verdru\u00df/", "tokens": ["Die", "keuschheit", "mit", "ver\u00b7dru\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Drum komm/ mein trost/ und gib mir noch", "tokens": ["Drum", "komm", "/", "mein", "trost", "/", "und", "gib", "mir", "noch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "$(", "PPOSAT", "NN", "$(", "KON", "VVIMP", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was gutes zum beschlu\u00df/", "tokens": ["Was", "gu\u00b7tes", "zum", "be\u00b7schlu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "APPRART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Damit ich nicht in kurtzer zeit", "tokens": ["Da\u00b7mit", "ich", "nicht", "in", "kurt\u00b7zer", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor \u00fcbermachter bangigkeit", "tokens": ["Vor", "\u00fc\u00b7ber\u00b7mach\u00b7ter", "ban\u00b7gig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zur hu \u2012 \u2012 werden mu\u00df.", "tokens": ["Zur", "hu", "\u2012", "\u2012", "wer\u00b7den", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "$(", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}