{"textgrid.poem.41472": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Telephus, nach der neunzehnten Ode des Horaz", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du bist gelehrt, mein Telephus!", "tokens": ["Du", "bist", "ge\u00b7lehrt", ",", "mein", "Te\u00b7le\u00b7phus", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du wei\u00dft und du erz\u00e4hlst, wie manches Jahr verstrichen", "tokens": ["Du", "wei\u00dft", "und", "du", "er\u00b7z\u00e4hlst", ",", "wie", "man\u00b7ches", "Jahr", "ver\u00b7stri\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "PPER", "VVFIN", "$,", "PWAV", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vom fast verge\u00dfnen Inachus", "tokens": ["Vom", "fast", "ver\u00b7ge\u00df\u00b7nen", "I\u00b7nac\u00b7hus"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis auf des Codrus Zeit, der, nach des Schicksals Schlu\u00df,", "tokens": ["Bis", "auf", "des", "Cod\u00b7rus", "Zeit", ",", "der", ",", "nach", "des", "Schick\u00b7sals", "Schlu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "NN", "$,", "PRELS", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beherzt f\u00fcrs Vaterland verblichen;", "tokens": ["Be\u00b7herzt", "f\u00fcrs", "Va\u00b7ter\u00b7land", "ver\u00b7bli\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Du kennst den Stamm des Aeacus:", "tokens": ["Du", "kennst", "den", "Stamm", "des", "A\u00b7e\u00b7a\u00b7cus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Von ihm nennt niemand uns geschwinder", "tokens": ["Von", "ihm", "nennt", "nie\u00b7mand", "uns", "ge\u00b7schwin\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "PIS", "PPER", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Kinder und die Kindeskinder:", "tokens": ["Die", "Kin\u00b7der", "und", "die", "Kin\u00b7des\u00b7kin\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und Trojens G\u00f6ttersitz, um den Scamanderflu\u00df", "tokens": ["Und", "Tro\u00b7jens", "G\u00f6t\u00b7ter\u00b7sitz", ",", "um", "den", "Sca\u00b7man\u00b7der\u00b7flu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "NE", "$,", "KOUI", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Kennst du die Fliehenden, du kennst die Ueberwinder:", "tokens": ["Kennst", "du", "die", "Flie\u00b7hen\u00b7den", ",", "du", "kennst", "die", "Ue\u00b7ber\u00b7win\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "O hochgelehrter Telephus!", "tokens": ["O", "hoch\u00b7ge\u00b7lehr\u00b7ter", "Te\u00b7le\u00b7phus", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Hingegen hast du mir die Preise", "tokens": ["Hin\u00b7ge\u00b7gen", "hast", "du", "mir", "die", "Prei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der Chier Weine nie gemeldt,", "tokens": ["Der", "Chier", "Wei\u00b7ne", "nie", "ge\u00b7meldt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch nie den Ort der n\u00e4chsten Schm\u00e4use;", "tokens": ["Auch", "nie", "den", "Ort", "der", "n\u00e4chs\u00b7ten", "Schm\u00e4u\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht, wo, noch wann man mir ein warmes Bad bestellt,", "tokens": ["Nicht", ",", "wo", ",", "noch", "wann", "man", "mir", "ein", "war\u00b7mes", "Bad", "be\u00b7stellt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "$,", "KON", "PWAV", "PIS", "PPER", "ART", "ADJA", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn ein Peligner Frost die Glieder \u00fcberf\u00e4llt.", "tokens": ["Wenn", "ein", "Pe\u00b7lig\u00b7ner", "Frost", "die", "Glie\u00b7der", "\u00fc\u00b7berf\u00b7\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Gib, Schenke, gib vom Saft der Reben!", "tokens": ["Gib", ",", "Schen\u00b7ke", ",", "gib", "vom", "Saft", "der", "Re\u00b7ben", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NN", "$,", "VVIMP", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Neumond und der Mitternacht", "tokens": ["Dem", "Neu\u00b7mond", "und", "der", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sei dieser Weihtrunk ausgebracht.", "tokens": ["Sei", "die\u00b7ser", "Weih\u00b7trunk", "aus\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gib noch den dritten Kelch: Es soll Muraena leben,", "tokens": ["Gib", "noch", "den", "drit\u00b7ten", "Kelch", ":", "Es", "soll", "Mu\u00b7ra\u00b7e\u00b7na", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "ADJA", "NN", "$.", "PPER", "VMFIN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Den sein Verdienst zum Augur macht!", "tokens": ["Den", "sein", "Ver\u00b7dienst", "zum", "Au\u00b7gur", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Aus jenen Bechern w\u00e4hlt, die euch die besten d\u00fcnken.", "tokens": ["Aus", "je\u00b7nen", "Be\u00b7chern", "w\u00e4hlt", ",", "die", "euch", "die", "bes\u00b7ten", "d\u00fcn\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$,", "PRELS", "PPER", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drei- oder neunmal m\u00fc\u00dft ihr trinken.", "tokens": ["Drei", "o\u00b7der", "neun\u00b7mal", "m\u00fc\u00dft", "ihr", "trin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Dichter mu\u00df begeistert sein.", "tokens": ["Der", "Dich\u00b7ter", "mu\u00df", "be\u00b7geis\u00b7tert", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er wei\u00df, es sind der Musen neun.", "tokens": ["Er", "wei\u00df", ",", "es", "sind", "der", "Mu\u00b7sen", "neun", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bald wird er den Bedienten winken,", "tokens": ["Bald", "wird", "er", "den", "Be\u00b7dien\u00b7ten", "win\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der f\u00fcll' ihm von dem Dichterwein", "tokens": ["Der", "f\u00fcll'", "ihm", "von", "dem", "Dich\u00b7ter\u00b7wein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In den Pocal neun Stutzer ein.", "tokens": ["In", "den", "Po\u00b7cal", "neun", "Stut\u00b7zer", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Huldg\u00f6ttin, zu der sich zum Vergn\u00fcgen", "tokens": ["Die", "Huld\u00b7g\u00f6t\u00b7tin", ",", "zu", "der", "sich", "zum", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PRF", "APPRART", "NN"], "meter": "--+-+-++-+-", "measure": "anapaest.init"}, "line.9": {"text": "Die beiden nackten Schwestern f\u00fcgen,", "tokens": ["Die", "bei\u00b7den", "nack\u00b7ten", "Schwes\u00b7tern", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Pflegt Zanklust und Verdru\u00df zu scheun,", "tokens": ["Pflegt", "Zan\u00b7klust", "und", "Ver\u00b7dru\u00df", "zu", "scheun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und sie erlaubt von solchen Z\u00fcgen", "tokens": ["Und", "sie", "er\u00b7laubt", "von", "sol\u00b7chen", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVPP", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Nicht mehr als drei, euch andre zu erfreun.", "tokens": ["Nicht", "mehr", "als", "drei", ",", "euch", "and\u00b7re", "zu", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "KOKOM", "CARD", "$,", "PPER", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "O da\u00df der Ernst die Flucht erw\u00e4hle!", "tokens": ["O", "da\u00df", "der", "Ernst", "die", "Flucht", "er\u00b7w\u00e4h\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mir lob' ich Lust und Raserei.", "tokens": ["Mir", "lob'", "ich", "Lust", "und", "Ra\u00b7se\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie? Stimmt kein Spiel dem Jubel bei?", "tokens": ["Wie", "?", "Stimmt", "kein", "Spiel", "dem", "Ju\u00b7bel", "bei", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PIAT", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf! da\u00df die Fl\u00f6te der Cybele", "tokens": ["Auf", "!", "da\u00df", "die", "Fl\u00f6\u00b7te", "der", "Cy\u00b7be\u00b7le"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "$.", "KOUS", "ART", "NN", "ART", "NN"], "meter": "+--+--+--", "measure": "dactylic.tri"}, "line.5": {"text": "Sich jetzt mit neuem Hauch beseele!", "tokens": ["Sich", "jetzt", "mit", "neu\u00b7em", "Hauch", "be\u00b7see\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Auf! auf! da\u00df Leyer und Schalmei", "tokens": ["Auf", "!", "auf", "!", "da\u00df", "Le\u00b7yer", "und", "Schal\u00b7mei"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$.", "PTKVZ", "$.", "KOUS", "NE", "KON", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Die T\u00f6ne wohlgepaart verm\u00e4hle,", "tokens": ["Die", "T\u00f6\u00b7ne", "wohl\u00b7ge\u00b7paart", "ver\u00b7m\u00e4h\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht unsern Freuden l\u00e4nger fehle,", "tokens": ["Nicht", "un\u00b7sern", "Freu\u00b7den", "l\u00e4n\u00b7ger", "feh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Nicht stumm der W\u00e4nde Zierrath sei!", "tokens": ["Nicht", "stumm", "der", "W\u00e4n\u00b7de", "Zier\u00b7rath", "sei", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Man sollte sich der H\u00e4nde sch\u00e4men,", "tokens": ["Man", "soll\u00b7te", "sich", "der", "H\u00e4n\u00b7de", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die langsam sich zur Lust bequemen:", "tokens": ["Die", "lang\u00b7sam", "sich", "zur", "Lust", "be\u00b7que\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "APPRART", "NN", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wie ha\u00df' ich ihre Zauderei!", "tokens": ["Wie", "ha\u00df'", "ich", "ih\u00b7re", "Zau\u00b7de\u00b7rei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Streut Rosen aus; l\u00e4rmt durch die Ch\u00f6re,", "tokens": ["Streut", "Ro\u00b7sen", "aus", ";", "l\u00e4rmt", "durch", "die", "Ch\u00f6\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "$.", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.14": {"text": "Da\u00df unser tobendes Geschrei", "tokens": ["Da\u00df", "un\u00b7ser", "to\u00b7ben\u00b7des", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Des d\u00fcrren Lycus Neid vermehre!", "tokens": ["Des", "d\u00fcr\u00b7ren", "Ly\u00b7cus", "Neid", "ver\u00b7meh\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Da\u00df unsre Nachbarin, voll Scheu", "tokens": ["Da\u00df", "uns\u00b7re", "Nach\u00b7ba\u00b7rin", ",", "voll", "Scheu"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Vor dieses Alten Schmeichelei,", "tokens": ["Vor", "die\u00b7ses", "Al\u00b7ten", "Schmei\u00b7che\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Auf unser wildes Jauchzen h\u00f6re!", "tokens": ["Auf", "un\u00b7ser", "wil\u00b7des", "Jauch\u00b7zen", "h\u00f6\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Du bist mein Telephus, an vollen Locken reich,", "tokens": ["Du", "bist", "mein", "Te\u00b7le\u00b7phus", ",", "an", "vol\u00b7len", "Lo\u00b7cken", "reich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem heitern Abendstern macht dich dein Anblick gleich,", "tokens": ["Dem", "hei\u00b7tern", "A\u00b7bends\u00b7tern", "macht", "dich", "dein", "An\u00b7blick", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und Chloe, die dir reift, lockt dich zu zarten Trieben.", "tokens": ["Und", "Chloe", ",", "die", "dir", "reift", ",", "lockt", "dich", "zu", "zar\u00b7ten", "Trie\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Erkenne, wie begl\u00fcckt du bist,", "tokens": ["Er\u00b7ken\u00b7ne", ",", "wie", "be\u00b7gl\u00fcckt", "du", "bist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da meine Glycera nicht so gef\u00e4llig ist,", "tokens": ["Da", "mei\u00b7ne", "Gly\u00b7ce\u00b7ra", "nicht", "so", "ge\u00b7f\u00e4l\u00b7lig", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das Feuer kennt und n\u00e4hrt, das mich schon lange fri\u00dft,", "tokens": ["Das", "Feu\u00b7er", "kennt", "und", "n\u00e4hrt", ",", "das", "mich", "schon", "lan\u00b7ge", "fri\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und doch nicht eilet, mich zu lieben.", "tokens": ["Und", "doch", "nicht", "ei\u00b7let", ",", "mich", "zu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}