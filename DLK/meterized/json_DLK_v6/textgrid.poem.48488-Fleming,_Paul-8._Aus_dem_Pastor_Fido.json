{"textgrid.poem.48488": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "8. Aus dem Pastor Fido", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr blindes Volk, so euch denn d\u00fcrstet so,", "tokens": ["Ihr", "blin\u00b7des", "Volk", ",", "so", "euch", "denn", "d\u00fcrs\u00b7tet", "so", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "PPER", "ADV", "VMFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "viel Sch\u00e4tze, Geld und Gut zu haben,", "tokens": ["viel", "Sch\u00e4t\u00b7ze", ",", "Geld", "und", "Gut", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "KON", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "indem euch macht der liebe Geldsarg froh,", "tokens": ["in\u00b7dem", "euch", "macht", "der", "lie\u00b7be", "Geld\u00b7sarg", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "darein ein g\u00fcldnes Aas vergraben,", "tokens": ["da\u00b7rein", "ein", "g\u00fcld\u00b7nes", "Aas", "ver\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "welches schleicht um seine Gruft", "tokens": ["wel\u00b7ches", "schleicht", "um", "sei\u00b7ne", "Gruft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "als ein Schatt' und blasse Luft,", "tokens": ["als", "ein", "Schatt'", "und", "blas\u00b7se", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "was k\u00f6nt ihr Lust an toter Sch\u00f6nheit haben?", "tokens": ["was", "k\u00f6nt", "ihr", "Lust", "an", "to\u00b7ter", "Sch\u00f6n\u00b7heit", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Reichtum, Sch\u00e4tz' und andre G\u00fcter", "tokens": ["Reich\u00b7tum", ",", "Sch\u00e4tz'", "und", "and\u00b7re", "G\u00fc\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "haben keine Gegengunst,", "tokens": ["ha\u00b7ben", "kei\u00b7ne", "Ge\u00b7gen\u00b7gunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "wahre, lebensvolle Brunst.", "tokens": ["wah\u00b7re", ",", "le\u00b7bens\u00b7vol\u00b7le", "Brunst", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Die Gem\u00fcter sind Gem\u00fcter.", "tokens": ["Die", "Ge\u00b7m\u00fc\u00b7ter", "sind", "Ge\u00b7m\u00fc\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Alles andre, weils nicht wieder Liebe giebet,", "tokens": ["Al\u00b7les", "and\u00b7re", ",", "weils", "nicht", "wie\u00b7der", "Lie\u00b7be", "gie\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "$,", "KOUS", "PTKNEG", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "ist nicht wert, da\u00df es die Liebe liebet.", "tokens": ["ist", "nicht", "wert", ",", "da\u00df", "es", "die", "Lie\u00b7be", "lie\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.14": {"text": "Die Gegenbulerin, die Seele nur allein", "tokens": ["Die", "Ge\u00b7gen\u00b7bu\u00b7le\u00b7rin", ",", "die", "See\u00b7le", "nur", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "kan eines Bulern wert und Liebe w\u00fcrdig sein.", "tokens": ["kan", "ei\u00b7nes", "Bu\u00b7lern", "wert", "und", "Lie\u00b7be", "w\u00fcr\u00b7dig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADJD", "KON", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es ist wohl ein s\u00fc\u00dfes Wesen", "tokens": ["Es", "ist", "wohl", "ein", "s\u00fc\u00b7\u00dfes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "um den Ku\u00df; den man gelesen", "tokens": ["um", "den", "Ku\u00df", ";", "den", "man", "ge\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "ART", "PIS", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "von dem rosenroten Angesicht';", "tokens": ["von", "dem", "ro\u00b7sen\u00b7ro\u00b7ten", "An\u00b7ge\u00b7sicht'", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "aber doch, wer nach der Warheit Pflicht", "tokens": ["a\u00b7ber", "doch", ",", "wer", "nach", "der", "War\u00b7heit", "Pflicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "PWS", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "(wie die ihr, ihr Buler, pflegt, als die ihr es wisset,", "tokens": ["(", "wie", "die", "ihr", ",", "ihr", "Bu\u00b7ler", ",", "pflegt", ",", "als", "die", "ihr", "es", "wis\u00b7set", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ART", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "$,", "KOUS", "ART", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "die ihrs versucht) bekennt, wird sagen m\u00fcssen,", "tokens": ["die", "ihrs", "ver\u00b7sucht", ")", "be\u00b7kennt", ",", "wird", "sa\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$(", "VVFIN", "$,", "VAFIN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "es sei ein totes K\u00fcssen,", "tokens": ["es", "sei", "ein", "to\u00b7tes", "K\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "das die gek\u00fc\u00dfte Zier nicht wieder k\u00fcsset.", "tokens": ["das", "die", "ge\u00b7k\u00fc\u00df\u00b7te", "Zier", "nicht", "wie\u00b7der", "k\u00fcs\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Der verliebten Lippen Schm\u00e4tze", "tokens": ["Der", "ver\u00b7lieb\u00b7ten", "Lip\u00b7pen", "Schm\u00e4t\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "zweier herzvertrauten Sch\u00e4tze,", "tokens": ["zwei\u00b7er", "herz\u00b7ver\u00b7trau\u00b7ten", "Sch\u00e4t\u00b7ze", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "wenn sich Mund mit Munde schl\u00e4gt", "tokens": ["wenn", "sich", "Mund", "mit", "Mun\u00b7de", "schl\u00e4gt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "NN", "APPR", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "und der Streit zugleich erregt,", "tokens": ["und", "der", "Streit", "zu\u00b7gleich", "er\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "wenn die Lieb' auf eins in Eil'", "tokens": ["wenn", "die", "Lieb'", "auf", "eins", "in", "Eil'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PIS", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "einen und den andern Pfeil", "tokens": ["ei\u00b7nen", "und", "den", "an\u00b7dern", "Pfeil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "mit vers\u00fc\u00dfter Rache z\u00fccket", "tokens": ["mit", "ver\u00b7s\u00fc\u00df\u00b7ter", "Ra\u00b7che", "z\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "und auf einen Feind lostr\u00fccket,", "tokens": ["und", "auf", "ei\u00b7nen", "Feind", "lost\u00b7r\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "di\u00df la\u00dft mir K\u00fcsse sein, da eins so viel bek\u00f6mmt", "tokens": ["di\u00df", "la\u00dft", "mir", "K\u00fcs\u00b7se", "sein", ",", "da", "eins", "so", "viel", "be\u00b7k\u00f6mmt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "NN", "VAINF", "$,", "KOUS", "PIS", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "mit ebengleicher Lust, so viel das andre nimmt.", "tokens": ["mit", "e\u00b7ben\u00b7glei\u00b7cher", "Lust", ",", "so", "viel", "das", "and\u00b7re", "nimmt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "ADV", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Es k\u00fcsse nur ein wolverschlagner Mund", "tokens": ["Es", "k\u00fcs\u00b7se", "nur", "ein", "wol\u00b7ver\u00b7schlag\u00b7ner", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die Brust, die Hand, die Stirn' und merke gar genau,", "tokens": ["die", "Brust", ",", "die", "Hand", ",", "die", "Stirn'", "und", "mer\u00b7ke", "gar", "ge\u00b7nau", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "so wird es ihm bald werden kund,", "tokens": ["so", "wird", "es", "ihm", "bald", "wer\u00b7den", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "VAINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df sonst kein einigs Glied an einer sch\u00f6nen Frau", "tokens": ["da\u00df", "sonst", "kein", "ei\u00b7nigs", "Glied", "an", "ei\u00b7ner", "sch\u00f6\u00b7nen", "Frau"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIAT", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "als nur der Mund ihn wieder k\u00f6nne k\u00fcssen,", "tokens": ["als", "nur", "der", "Mund", "ihn", "wie\u00b7der", "k\u00f6n\u00b7ne", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "da Seel' und Seel' in Lust zusammen flie\u00dfen", "tokens": ["da", "Seel'", "und", "Seel'", "in", "Lust", "zu\u00b7sam\u00b7men", "flie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "APPR", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und sich auch k\u00fcssen m\u00fcssen.", "tokens": ["und", "sich", "auch", "k\u00fcs\u00b7sen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Durch die regen, fremde Geister", "tokens": ["Durch", "die", "re\u00b7gen", ",", "frem\u00b7de", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "hauchen sie des Lebens Wind", "tokens": ["hau\u00b7chen", "sie", "des", "Le\u00b7bens", "Wind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "in die k\u00fcssenden Rubinen,", "tokens": ["in", "die", "k\u00fcs\u00b7sen\u00b7den", "Ru\u00b7bi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "also da\u00df die edlen Meister", "tokens": ["al\u00b7so", "da\u00df", "die", "ed\u00b7len", "Meis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "manches Wort von gro\u00dfen Sachen", "tokens": ["man\u00b7ches", "Wort", "von", "gro\u00b7\u00dfen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "doch in kleinem Halle machen,", "tokens": ["doch", "in", "klei\u00b7nem", "Hal\u00b7le", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "von den H\u00e4ndeln so nur ihnen", "tokens": ["von", "den", "H\u00e4n\u00b7deln", "so", "nur", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "ADV", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "kund, uns andern heimlich sind.", "tokens": ["kund", ",", "uns", "an\u00b7dern", "heim\u00b7lich", "sind", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "PPER", "PIS", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "In einer solchen Lust, ja solchem Leben schwebt", "tokens": ["In", "ei\u00b7ner", "sol\u00b7chen", "Lust", ",", "ja", "sol\u00b7chem", "Le\u00b7ben", "schwebt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "$,", "ADV", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "ein liebesvoller Geist, der in dem andern lebt,", "tokens": ["ein", "lie\u00b7bes\u00b7vol\u00b7ler", "Geist", ",", "der", "in", "dem", "an\u00b7dern", "lebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "und sind die wiederum so bald gek\u00fc\u00dften K\u00fcsse,", "tokens": ["und", "sind", "die", "wie\u00b7de\u00b7rum", "so", "bald", "ge\u00b7k\u00fc\u00df\u00b7ten", "K\u00fcs\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "als wenn zwei liebender geliebter Herzen F\u00fc\u00dfe", "tokens": ["als", "wenn", "zwei", "lie\u00b7ben\u00b7der", "ge\u00b7lieb\u00b7ter", "Her\u00b7zen", "F\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "CARD", "ADJA", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "einander unversehns begegneten, so s\u00fc\u00dfe.", "tokens": ["ein\u00b7an\u00b7der", "un\u00b7ver\u00b7sehns", "be\u00b7ge\u00b7gne\u00b7ten", ",", "so", "s\u00fc\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}}}}