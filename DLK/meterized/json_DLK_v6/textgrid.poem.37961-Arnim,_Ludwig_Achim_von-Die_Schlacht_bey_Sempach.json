{"textgrid.poem.37961": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Die Schlacht bey Sempach", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Biene kam geflogen, macht in der Lind ihr Nest,", "tokens": ["Die", "Bie\u00b7ne", "kam", "ge\u00b7flo\u00b7gen", ",", "macht", "in", "der", "Lind", "ihr", "Nest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,", "VVFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es redet der gemeine Mann, das deutet fremde G\u00e4st.", "tokens": ["Es", "re\u00b7det", "der", "ge\u00b7mei\u00b7ne", "Mann", ",", "das", "deu\u00b7tet", "frem\u00b7de", "G\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "PDS", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.2": {"line.1": {"text": "Da sah man wie die Veste bey Willisow hell brennt,", "tokens": ["Da", "sah", "man", "wie", "die", "Ves\u00b7te", "bey", "Wil\u00b7li\u00b7sow", "hell", "brennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "KOKOM", "ART", "NN", "APPR", "NE", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+--+-+++", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Den Herzog mit dem Heere ein jeder daran kennt.", "tokens": ["Den", "Her\u00b7zog", "mit", "dem", "Hee\u00b7re", "ein", "je\u00b7der", "da\u00b7ran", "kennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "PIS", "PAV", "VVFIN", "$."], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Sie redeten zusammen in ihrem Uebermuth,", "tokens": ["Sie", "re\u00b7de\u00b7ten", "zu\u00b7sam\u00b7men", "in", "ih\u00b7rem", "Ue\u00b7ber\u00b7muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Die Schweizer wollen wir t\u00f6dten, das jung und alte Blut.", "tokens": ["Die", "Schwei\u00b7zer", "wol\u00b7len", "wir", "t\u00f6d\u00b7ten", ",", "das", "jung", "und", "al\u00b7te", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVFIN", "$,", "PRELS", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Sie zogen her mit Schalle von Sursee aus der Stadt,", "tokens": ["Sie", "zo\u00b7gen", "her", "mit", "Schal\u00b7le", "von", "Sur\u00b7see", "aus", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--++--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie fangen an zu ziehen mit ihrem k\u00f6stlichen Waat:", "tokens": ["Sie", "fan\u00b7gen", "an", "zu", "zie\u00b7hen", "mit", "ih\u00b7rem", "k\u00f6st\u00b7li\u00b7chen", "Waat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "\u00bbihr niederl\u00e4ndisch Herren, ihr zieht ins Oberland,", "tokens": ["\u00bb", "ihr", "nie\u00b7der\u00b7l\u00e4n\u00b7disch", "Her\u00b7ren", ",", "ihr", "zieht", "ins", "O\u00b7ber\u00b7land", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJD", "NN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Werdet ihr euch da ern\u00e4hren, es ist euch unbekannt.", "tokens": ["Wer\u00b7det", "ihr", "euch", "da", "er\u00b7n\u00e4h\u00b7ren", ",", "es", "ist", "euch", "un\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "VVINF", "$,", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Ihr solltet euch nach Beichte vorher noch umme sehen,", "tokens": ["Ihr", "soll\u00b7tet", "euch", "nach", "Beich\u00b7te", "vor\u00b7her", "noch", "um\u00b7me", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "NN", "ADV", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Im Oberl\u00e4ndchem Streite m\u00f6cht euch wohl Weh geschehen.\u00ab", "tokens": ["Im", "O\u00b7ber\u00b7l\u00e4nd\u00b7chem", "Strei\u00b7te", "m\u00f6cht", "euch", "wohl", "Weh", "ge\u00b7sche\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "VMFIN", "PPER", "ADV", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbwo sizt denn nur der Pfaffe dem einer da beichten mu\u00df?\u00ab", "tokens": ["\u00bb", "wo", "sizt", "denn", "nur", "der", "Pfaf\u00b7fe", "dem", "ei\u00b7ner", "da", "beich\u00b7ten", "mu\u00df", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VVFIN", "ADV", "ADV", "ART", "NN", "ART", "ART", "ADV", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbzu Schweiz ist er im Felde, er giebt einem schwere Bu\u00df,", "tokens": ["\u00bb", "zu", "Schweiz", "ist", "er", "im", "Fel\u00b7de", ",", "er", "giebt", "ei\u00b7nem", "schwe\u00b7re", "Bu\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NE", "VAFIN", "PPER", "APPRART", "NN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.8": {"line.1": {"text": "Er wird gar schwere Hand auf eure K\u00f6pfe legen,", "tokens": ["Er", "wird", "gar", "schwe\u00b7re", "Hand", "auf", "eu\u00b7re", "K\u00f6p\u00b7fe", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Helleparten giebt er euch den besten Segen.\u00ab", "tokens": ["Mit", "Hel\u00b7le\u00b7par\u00b7ten", "giebt", "er", "euch", "den", "bes\u00b7ten", "Se\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Jezt sicheln in dem Thau, sie waren Sempach nahe.", "tokens": ["Jezt", "si\u00b7cheln", "in", "dem", "Thau", ",", "sie", "wa\u00b7ren", "Sem\u00b7pach", "na\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VAFIN", "NE", "PTKVZ", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.10": {"line.1": {"text": "Die Herren von Luzerne, sich streckten festiglich,", "tokens": ["Die", "Her\u00b7ren", "von", "Lu\u00b7zer\u00b7ne", ",", "sich", "streck\u00b7ten", "fes\u00b7tig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,", "PRF", "VVFIN", "ADJD", "$,"], "meter": "-+--+---+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "An Mannheit gar ein Kerne, sah keiner hinter sich.", "tokens": ["An", "Mann\u00b7heit", "gar", "ein", "Ker\u00b7ne", ",", "sah", "kei\u00b7ner", "hin\u00b7ter", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "NN", "$,", "VVFIN", "PIS", "APPR", "PRF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Ein Herr von Hasenburg zum Herzog also sprach:", "tokens": ["Ein", "Herr", "von", "Ha\u00b7sen\u00b7burg", "zum", "Her\u00b7zog", "al\u00b7so", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbdas V\u00f6lklein ich beschaut, sie sind gar unverzagt.\u00ab", "tokens": ["\u00bb", "das", "V\u00f6l\u00b7klein", "ich", "be\u00b7schaut", ",", "sie", "sind", "gar", "un\u00b7ver\u00b7zagt", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "PPER", "VVPP", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Da redet Ochsenstein: O Hasenburg, o Hasenherz!", "tokens": ["Da", "re\u00b7det", "Och\u00b7sen\u00b7stein", ":", "O", "Ha\u00b7sen\u00b7burg", ",", "o", "Ha\u00b7sen\u00b7herz", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$.", "NE", "NE", "$,", "FM", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Der Hasenburg der sagt: Wir wollen sehn den Scherz.", "tokens": ["Der", "Ha\u00b7sen\u00b7burg", "der", "sagt", ":", "Wir", "wol\u00b7len", "sehn", "den", "Scherz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "$.", "PPER", "VMFIN", "VVINF", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Sie banden auf die Helme und th\u00e4ten sie vorher tragen,", "tokens": ["Sie", "ban\u00b7den", "auf", "die", "Hel\u00b7me", "und", "th\u00e4\u00b7ten", "sie", "vor\u00b7her", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von Schuchen hieben die Schn\u00e4bel, man f\u00fcllt damit 'nen Wagen.", "tokens": ["Von", "Schu\u00b7chen", "hie\u00b7ben", "die", "Schn\u00e4\u00b7bel", ",", "man", "f\u00fcllt", "da\u00b7mit", "'nen", "Wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,", "PIS", "VVFIN", "PAV", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "Zusammen sie dann sprachen: \u00bbDas V\u00f6lkchen ist zu klein,", "tokens": ["Zu\u00b7sam\u00b7men", "sie", "dann", "spra\u00b7chen", ":", "\u00bb", "Das", "V\u00f6lk\u00b7chen", "ist", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "VVINF", "$.", "$(", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wenn wir die Bauern schlagen, das Lob wird klein nur seyn.\u00ab", "tokens": ["Wenn", "wir", "die", "Bau\u00b7ern", "schla\u00b7gen", ",", "das", "Lob", "wird", "klein", "nur", "seyn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$,", "ART", "NN", "VAFIN", "ADJD", "ADV", "VAINF", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "Die biedern Eidgenossen Gott riefen im Himmel laut,", "tokens": ["Die", "bie\u00b7dern", "Eid\u00b7ge\u00b7nos\u00b7sen", "Gott", "rie\u00b7fen", "im", "Him\u00b7mel", "laut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+---+-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Ein Regenbogen gar helle vom hohen Himmel schaut.", "tokens": ["Ein", "Re\u00b7gen\u00b7bo\u00b7gen", "gar", "hel\u00b7le", "vom", "ho\u00b7hen", "Him\u00b7mel", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJA", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "Und Herz und Sinn ist wachsen von hoher Manneskraft,", "tokens": ["Und", "Herz", "und", "Sinn", "ist", "wach\u00b7sen", "von", "ho\u00b7her", "Man\u00b7nes\u00b7kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da\u00df sie sich tapfer kehrten jezt gegen die Ritterschaft.", "tokens": ["Da\u00df", "sie", "sich", "tap\u00b7fer", "kehr\u00b7ten", "jezt", "ge\u00b7gen", "die", "Rit\u00b7ter\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.17": {"line.1": {"text": "Der L\u00f6w fing an zu br\u00fcllen, zu schm\u00fccken seinen Wadel,", "tokens": ["Der", "L\u00f6w", "fing", "an", "zu", "br\u00fcl\u00b7len", ",", "zu", "schm\u00fc\u00b7cken", "sei\u00b7nen", "Wa\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie fingen an zu schie\u00dfen die Herren da von Adel.", "tokens": ["Sie", "fin\u00b7gen", "an", "zu", "schie\u00b7\u00dfen", "die", "Her\u00b7ren", "da", "von", "A\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "PTKZU", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Sie griffen mit langen Spie\u00dfen, der Schimpf war gar nicht s\u00fc\u00df,", "tokens": ["Sie", "grif\u00b7fen", "mit", "lan\u00b7gen", "Spie\u00b7\u00dfen", ",", "der", "Schimpf", "war", "gar", "nicht", "s\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Aeste von hohen B\u00e4umen fielen vor ihre F\u00fc\u00df.", "tokens": ["Der", "A\u00b7es\u00b7te", "von", "ho\u00b7hen", "B\u00e4u\u00b7men", "fie\u00b7len", "vor", "ih\u00b7re", "F\u00fc\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}}, "stanza.19": {"line.1": {"text": "Des Adels Heer war fest, ihr Ordnung dick verhagt,", "tokens": ["Des", "A\u00b7dels", "Heer", "war", "fest", ",", "ihr", "Ord\u00b7nung", "dick", "ver\u00b7hagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das verdro\u00df die frommen G\u00e4ste, ein Winkelried da sagt:", "tokens": ["Das", "ver\u00b7dro\u00df", "die", "from\u00b7men", "G\u00e4s\u00b7te", ",", "ein", "Win\u00b7kel\u00b7ried", "da", "sagt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "--+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "\u00bbhe werd ihr gniessen lon,", "tokens": ["\u00bb", "he", "werd", "ihr", "gnies\u00b7sen", "lon", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VAFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Min fromme Kind und Frauen, so will ich ein Frevel beston,", "tokens": ["Min", "from\u00b7me", "Kind", "und", "Frau\u00b7en", ",", "so", "will", "ich", "ein", "Fre\u00b7vel", "be\u00b7ston", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "NN", "$,", "ADV", "VMFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.21": {"line.1": {"text": "Sie hand ihr Ordnung gstossen, wir m\u00f6gens zu brechen nit;", "tokens": ["Sie", "hand", "ihr", "Ord\u00b7nung", "gs\u00b7tos\u00b7sen", ",", "wir", "m\u00f6\u00b7gens", "zu", "bre\u00b7chen", "nit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$,", "PPER", "ADV", "PTKZU", "VVINF", "PTKNEG", "$."], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.22": {"line.1": {"text": "He, ich will ein Inbruch han,", "tokens": ["He", ",", "ich", "will", "ein", "In\u00b7bruch", "han", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VMFIN", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Des wellend ihr min Gschlecht in ewig geniessen lan.\u00ab", "tokens": ["Des", "wel\u00b7lend", "ihr", "min", "Gschlecht", "in", "e\u00b7wig", "ge\u00b7nies\u00b7sen", "lan", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "PPER", "PPOSAT", "NN", "APPR", "ADJD", "VVPP", "ADV", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.23": {"line.1": {"text": "Hiemit so thut er fassen, ein Arm voll Spie\u00df behend,", "tokens": ["Hie\u00b7mit", "so", "thut", "er", "fas\u00b7sen", ",", "ein", "Arm", "voll", "Spie\u00df", "be\u00b7hend", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "VVINF", "$,", "ART", "NN", "ADJD", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Den Seinen macht er ein Gassen, sein Leben hat ein End.", "tokens": ["Den", "Sei\u00b7nen", "macht", "er", "ein", "Gas\u00b7sen", ",", "sein", "Le\u00b7ben", "hat", "ein", "End", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSS", "VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Er brach des L\u00f6wen Muth mit seinem theuren Blut,", "tokens": ["Er", "brach", "des", "L\u00f6\u00b7wen", "Muth", "mit", "sei\u00b7nem", "theu\u00b7ren", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sein mannlich tapfer Sterben war den vier Waldst\u00e4dten gut.", "tokens": ["Sein", "mann\u00b7lich", "tap\u00b7fer", "Ster\u00b7ben", "war", "den", "vier", "Wald\u00b7st\u00e4d\u00b7ten", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "ADJA", "NN", "VAFIN", "ART", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+++-+", "measure": "unknown.measure.octa.plus"}}, "stanza.25": {"line.1": {"text": "Sie brachen ein so schnelle des Adels Ordnung bald,", "tokens": ["Sie", "bra\u00b7chen", "ein", "so", "schnel\u00b7le", "des", "A\u00b7dels", "Ord\u00b7nung", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADV", "VVFIN", "ART", "NN", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit Hauen und mit Stechen: Gott seiner Seelen walt.", "tokens": ["Mit", "Hau\u00b7en", "und", "mit", "Ste\u00b7chen", ":", "Gott", "sei\u00b7ner", "See\u00b7len", "walt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$.", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.26": {"line.1": {"text": "Der L\u00f6w fing an zu mauen, zu treten hinter sich,", "tokens": ["Der", "L\u00f6w", "fing", "an", "zu", "mau\u00b7en", ",", "zu", "tre\u00b7ten", "hin\u00b7ter", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "APPR", "PRF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Stier starzt seine Brauen und gab ihm noch ein Stich.", "tokens": ["Der", "Stier", "starzt", "sei\u00b7ne", "Brau\u00b7en", "und", "gab", "ihm", "noch", "ein", "Stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.27": {"line.1": {"text": "Da lie\u00df er ihm das Panner, da lie\u00df er ihm die Weid,", "tokens": ["Da", "lie\u00df", "er", "ihm", "das", "Pan\u00b7ner", ",", "da", "lie\u00df", "er", "ihm", "die", "Weid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Zu K\u00f6nigsfeld im Kloster viel liegen begraben mit Leide.", "tokens": ["Zu", "K\u00f6\u00b7nigs\u00b7feld", "im", "Klos\u00b7ter", "viel", "lie\u00b7gen", "be\u00b7gra\u00b7ben", "mit", "Lei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "ADV", "VVFIN", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.28": {"line.1": {"text": "Der Herzog L\u00fcpolt wollte es gar f\u00fcrstlich wagen,", "tokens": ["Der", "Her\u00b7zog", "L\u00fc\u00b7polt", "woll\u00b7te", "es", "gar", "f\u00fcrst\u00b7lich", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da er an die Bauern kam, sie haben ihn todt geschlagen.", "tokens": ["Da", "er", "an", "die", "Bau\u00b7ern", "kam", ",", "sie", "ha\u00b7ben", "ihn", "todt", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "--+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.29": {"line.1": {"text": "Die Kuh die sprach zum Stiere: Ach sollt ich dir nicht klagen,", "tokens": ["Die", "Kuh", "die", "sprach", "zum", "Stie\u00b7re", ":", "Ach", "sollt", "ich", "dir", "nicht", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "APPRART", "NN", "$.", "NN", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mich wollt auf deinem Refiere ein Herr gemolken haben,", "tokens": ["Mich", "wollt", "auf", "dei\u00b7nem", "Re\u00b7fie\u00b7re", "ein", "Herr", "ge\u00b7mol\u00b7ken", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.30": {"line.1": {"text": "Da hab ich ihm den K\u00fcbel so eben umgeschlagen,", "tokens": ["Da", "hab", "ich", "ihm", "den", "K\u00fc\u00b7bel", "so", "e\u00b7ben", "um\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich gab ihm eins zum Ohre, da\u00df ihr ihn m\u00fc\u00dft begraben.", "tokens": ["Ich", "gab", "ihm", "eins", "zum", "Oh\u00b7re", ",", "da\u00df", "ihr", "ihn", "m\u00fc\u00dft", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "APPRART", "NN", "$,", "KOUS", "PPER", "PPER", "VMFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.31": {"line.1": {"text": "Ein Herre war entronnen, der war ein Herr von Ehren,", "tokens": ["Ein", "Her\u00b7re", "war", "ent\u00b7ron\u00b7nen", ",", "der", "war", "ein", "Herr", "von", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "PRELS", "VAFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er kam zu b\u00f6ser Stund bey Sempach zu dem See,", "tokens": ["Er", "kam", "zu", "b\u00f6\u00b7ser", "Stund", "bey", "Sem\u00b7pach", "zu", "dem", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Er klopft mit seinem Knecht da an bey Hans von Rot:", "tokens": ["Er", "klopft", "mit", "sei\u00b7nem", "Knecht", "da", "an", "bey", "Hans", "von", "Rot", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "APPR", "APPR", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbnun thus durch Gott und Geld, f\u00fchr uns aus aller Noth.\u00ab", "tokens": ["\u00bb", "nun", "thus", "durch", "Gott", "und", "Geld", ",", "f\u00fchr", "uns", "aus", "al\u00b7ler", "Noth", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "NE", "APPR", "NN", "KON", "NN", "$,", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Den er verdienen sollt, f\u00e4hrt \u00fcbern See also.", "tokens": ["Den", "er", "ver\u00b7die\u00b7nen", "sollt", ",", "f\u00e4hrt", "\u00fc\u00b7bern", "See", "al\u00b7so", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$,", "VVFIN", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Er rudert stark und schnelle, da er gen Notwyl war,", "tokens": ["Er", "ru\u00b7dert", "stark", "und", "schnel\u00b7le", ",", "da", "er", "gen", "Not\u00b7wyl", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da winkt der Herr dem Knechte, er sollt ihn erstechen gar.", "tokens": ["Da", "winkt", "der", "Herr", "dem", "Knech\u00b7te", ",", "er", "sollt", "ihn", "er\u00b7ste\u00b7chen", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,", "PPER", "VMFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.35": {"line.1": {"text": "Das wollt der Knecht vollbringen, am Schiffmann in der That,", "tokens": ["Das", "wollt", "der", "Knecht", "voll\u00b7brin\u00b7gen", ",", "am", "Schiff\u00b7mann", "in", "der", "That", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VVINF", "$,", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Hans Rot sieht's in dem Schatten, das Schifflein er umtrat.", "tokens": ["Hans", "Rot", "sieht's", "in", "dem", "Schat\u00b7ten", ",", "das", "Schif\u00b7flein", "er", "um\u00b7trat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "APPR", "ART", "NN", "$,", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.36": {"line.1": {"text": "Sie wollten sich noch halten, er warf sie in den See:", "tokens": ["Sie", "woll\u00b7ten", "sich", "noch", "hal\u00b7ten", ",", "er", "warf", "sie", "in", "den", "See", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "VVINF", "$,", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbnun trinket liebe Herren, ihr erstecht kein Schiffmann mehr.", "tokens": ["\u00bb", "nun", "trin\u00b7ket", "lie\u00b7be", "Her\u00b7ren", ",", "ihr", "er\u00b7stecht", "kein", "Schiff\u00b7mann", "mehr", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADJA", "NN", "$,", "PPER", "VVFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.37": {"line.1": {"text": "He, zween Fisch ich heute im See gefangen habe,", "tokens": ["He", ",", "zween", "Fisch", "ich", "heu\u00b7te", "im", "See", "ge\u00b7fan\u00b7gen", "ha\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "NN", "PPER", "ADV", "APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Ich bitt nur um die Schuppen, das Fleisch ist schlechte Gabe.\u00ab", "tokens": ["Ich", "bitt", "nur", "um", "die", "Schup\u00b7pen", ",", "das", "Fleisch", "ist", "schlech\u00b7te", "Ga\u00b7be", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,", "ART", "NN", "VAFIN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.38": {"line.1": {"text": "Es kam ein Bote endlich nach Oesterreich gesandt:", "tokens": ["Es", "kam", "ein", "Bo\u00b7te", "end\u00b7lich", "nach", "O\u00b7es\u00b7ter\u00b7reich", "ge\u00b7sandt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+---+-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "\u00bbach edle Frau von Oesterreich, min Herr liegt auf dem Land,", "tokens": ["\u00bb", "ach", "ed\u00b7le", "Frau", "von", "O\u00b7es\u00b7ter\u00b7reich", ",", "min", "Herr", "liegt", "auf", "dem", "Land", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "XY", "ADJA", "NN", "APPR", "NE", "$,", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+--+-+-+-+", "measure": "iambic.septa.invert"}}, "stanza.39": {"line.1": {"text": "Ach edle Frau er lieget vor Sempach blutig roth!\u00ab", "tokens": ["Ach", "ed\u00b7le", "Frau", "er", "lie\u00b7get", "vor", "Sem\u00b7pach", "blu\u00b7tig", "roth", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "ADJA", "NN", "PPER", "VVFIN", "APPR", "NE", "ADJD", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbach reicher Christ vom Himmel, was h\u00f6r ich gro\u00dfe Noth.\u00ab", "tokens": ["\u00bb", "ach", "rei\u00b7cher", "Christ", "vom", "Him\u00b7mel", ",", "was", "h\u00f6r", "ich", "gro\u00b7\u00dfe", "Noth", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "NN", "APPRART", "NN", "$,", "PWS", "VVFIN", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.40": {"line.1": {"text": "Halb Suter unvergessen, also ist er genannt,", "tokens": ["Halb", "Su\u00b7ter", "un\u00b7ver\u00b7ges\u00b7sen", ",", "al\u00b7so", "ist", "er", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADJD", "$,", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Z'Lucern ist er gesessen, also sehr wohl bekannt;", "tokens": ["Z'\u00b7Lu\u00b7cern", "ist", "er", "ge\u00b7ses\u00b7sen", ",", "al\u00b7so", "sehr", "wohl", "be\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVPP", "$,", "ADV", "ADV", "ADV", "ADJD", "$."], "meter": "---+--+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.41": {"line.1": {"text": "Er war ein fr\u00f6hlich Mann, das Lied hat er gedichtet,", "tokens": ["Er", "war", "ein", "fr\u00f6h\u00b7lich", "Mann", ",", "das", "Lied", "hat", "er", "ge\u00b7dich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$,", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als ab der Schlacht er kam, wo Gott der Herr gerichtet.", "tokens": ["Als", "ab", "der", "Schlacht", "er", "kam", ",", "wo", "Gott", "der", "Herr", "ge\u00b7rich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "VVFIN", "$,", "PWAV", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}