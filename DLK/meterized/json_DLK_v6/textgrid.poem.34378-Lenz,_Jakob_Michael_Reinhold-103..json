{"textgrid.poem.34378": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "103.", "genre": "verse", "period": "N.A.", "pub_year": 1780, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So ward ich denn noch dazu aufgehoben", "tokens": ["So", "ward", "ich", "denn", "noch", "da\u00b7zu", "auf\u00b7ge\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "PAV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Angesicht zu sehn, das unter Still und Nacht", "tokens": ["Das", "An\u00b7ge\u00b7sicht", "zu", "sehn", ",", "das", "un\u00b7ter", "Still", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "APPR", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und Sturm und Sonnenschein wie eine Gottheit oben", "tokens": ["Und", "Sturm", "und", "Son\u00b7nen\u00b7schein", "wie", "ei\u00b7ne", "Got\u00b7theit", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "KOKOM", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So manches Tagewerk ausbildend schon vollbracht", "tokens": ["So", "man\u00b7ches", "Ta\u00b7ge\u00b7werk", "aus\u00b7bil\u00b7dend", "schon", "voll\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVPP", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und V\u00f6lker, welche sie in hundert Sprachen loben,", "tokens": ["Und", "V\u00f6l\u00b7ker", ",", "wel\u00b7che", "sie", "in", "hun\u00b7dert", "Spra\u00b7chen", "lo\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "PPER", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu einer Nazion gemacht.", "tokens": ["Zu", "ei\u00b7ner", "Na\u00b7zi\u00b7on", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da stehn sie um sie her, mit Flammen in den Blicken", "tokens": ["Da", "stehn", "sie", "um", "sie", "her", ",", "mit", "Flam\u00b7men", "in", "den", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$,", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Gl\u00fccklichen, den Seegen auszudr\u00fccken,", "tokens": ["Die", "Gl\u00fcck\u00b7li\u00b7chen", ",", "den", "See\u00b7gen", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Der ihr seit der Vereinigung", "tokens": ["Der", "ihr", "seit", "der", "Ver\u00b7ei\u00b7ni\u00b7gung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Von einer halben Welt gelung. \u2013", "tokens": ["Von", "ei\u00b7ner", "hal\u00b7ben", "Welt", "ge\u00b7lung", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Da steht der grosse Geist: der, Muster von Regenten,", "tokens": ["Da", "steht", "der", "gros\u00b7se", "Geist", ":", "der", ",", "Mus\u00b7ter", "von", "Re\u00b7gen\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "ART", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Doch keine Mutter sah wie Die;", "tokens": ["Doch", "kei\u00b7ne", "Mut\u00b7ter", "sah", "wie", "Die", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "KOKOM", "ART", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Den Friedriche belohnen k\u00f6nnten", "tokens": ["Den", "Fried\u00b7ri\u00b7che", "be\u00b7loh\u00b7nen", "k\u00f6nn\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VMFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.14": {"text": "Doch gl\u00fccklich machen nicht, wie ", "tokens": ["Doch", "gl\u00fcck\u00b7lich", "ma\u00b7chen", "nicht", ",", "wie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ADJD", "VVFIN", "PTKNEG", "$,", "PWAV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.15": {"text": "Sie, die das Ganze zu umfassen", "tokens": ["Sie", ",", "die", "das", "Gan\u00b7ze", "zu", "um\u00b7fas\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Selbst ihrem Scharfsinn wehrt, sobald er Wesen dr\u00fcckt,", "tokens": ["Selbst", "ih\u00b7rem", "Scharf\u00b7sinn", "wehrt", ",", "so\u00b7bald", "er", "We\u00b7sen", "dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die zu Maschinen sich einmal nicht brauchen lassen", "tokens": ["Die", "zu", "Ma\u00b7schi\u00b7nen", "sich", "ein\u00b7mal", "nicht", "brau\u00b7chen", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "PRF", "ADV", "PTKNEG", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und schienen sie noch so begl\u00fcckt.", "tokens": ["Und", "schie\u00b7nen", "sie", "noch", "so", "be\u00b7gl\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Sie die so menschlich herrscht, da\u00df jeglichem Talente", "tokens": ["Sie", "die", "so", "menschlich", "herrscht", ",", "da\u00df", "jeg\u00b7li\u00b7chem", "Ta\u00b7len\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ART", "ADV", "ADJD", "VVPP", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Die Fessel von den H\u00e4nden sinkt,", "tokens": ["Die", "Fes\u00b7sel", "von", "den", "H\u00e4n\u00b7den", "sinkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Sie die selbst da, wo Titus zwingen k\u00f6nnte", "tokens": ["Sie", "die", "selbst", "da", ",", "wo", "Ti\u00b7tus", "zwin\u00b7gen", "k\u00f6nn\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ADV", "ADV", "$,", "PWAV", "NE", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Nie anders als durch Freiheit zwingt. \u2013", "tokens": ["Nie", "an\u00b7ders", "als", "durch", "Frei\u00b7heit", "zwingt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "KOKOM", "APPR", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Da steht der schwache Kopf, f\u00fcr den, in dem sie denket", "tokens": ["Da", "steht", "der", "schwa\u00b7che", "Kopf", ",", "f\u00fcr", "den", ",", "in", "dem", "sie", "den\u00b7ket"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "APPR", "ART", "$,", "APPR", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Erstaunt, da\u00df sies erg\u00e4nzt, an seiner Statt vollendt,", "tokens": ["Er\u00b7staunt", ",", "da\u00df", "sies", "er\u00b7g\u00e4nzt", ",", "an", "sei\u00b7ner", "Statt", "vol\u00b7lendt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PIS", "VVPP", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Worauf er hofnungslos die letzte Kraft verschwendt,", "tokens": ["Wo\u00b7rauf", "er", "hof\u00b7nungs\u00b7los", "die", "letz\u00b7te", "Kraft", "ver\u00b7schwendt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADJD", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Woran er sich zersann, da\u00df sie den Schwindel lenket", "tokens": ["Wo\u00b7ran", "er", "sich", "zer\u00b7sann", ",", "da\u00df", "sie", "den", "Schwin\u00b7del", "len\u00b7ket"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Und selbst den Pha\u00ebton sanft auf den Boden senket,", "tokens": ["Und", "selbst", "den", "Pha\u00ebton", "sanft", "auf", "den", "Bo\u00b7den", "sen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Damit er keine Welt verbrennt.", "tokens": ["Da\u00b7mit", "er", "kei\u00b7ne", "Welt", "ver\u00b7brennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So ist denn das die Frau, die \u00fcber jedes Lob,", "tokens": ["So", "ist", "denn", "das", "die", "Frau", ",", "die", "\u00fc\u00b7ber", "je\u00b7des", "Lob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "ART", "NN", "$,", "PRELS", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Schwachheit oder Furcht dicktirte,", "tokens": ["Das", "Schwach\u00b7heit", "o\u00b7der", "Furcht", "dick\u00b7tir\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Thaten, die kein Lob ber\u00fchrte,", "tokens": ["Durch", "Tha\u00b7ten", ",", "die", "kein", "Lob", "be\u00b7r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und durch Bescheidenheit unsterblich sich erhob? \u2013", "tokens": ["Und", "durch", "Be\u00b7schei\u00b7den\u00b7heit", "uns\u00b7terb\u00b7lich", "sich", "er\u00b7hob", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "NN", "PPER", "PRF", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die selbst die Schmeichelei durch unbesungne Schritte,", "tokens": ["Die", "selbst", "die", "Schmei\u00b7che\u00b7lei", "durch", "un\u00b7be\u00b7sung\u00b7ne", "Schrit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Womit sie nach der Wahrheit rang,", "tokens": ["Wo\u00b7mit", "sie", "nach", "der", "Wahr\u00b7heit", "rang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Offt durch das Gegenteil, offt durch die weisre Mitte", "tokens": ["Offt", "durch", "das", "Ge\u00b7gen\u00b7teil", ",", "offt", "durch", "die", "weis\u00b7re", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu heilsamer Besch\u00e4mung zwang.", "tokens": ["Zu", "heil\u00b7sa\u00b7mer", "Be\u00b7sch\u00e4\u00b7mung", "zwang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die jede Politick studierte,", "tokens": ["Die", "je\u00b7de", "Po\u00b7li\u00b7tick", "stu\u00b7dier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu lernen nie verschm\u00e4ht', auch wenn kein Lob es rieth;", "tokens": ["Zu", "ler\u00b7nen", "nie", "ver\u00b7schm\u00e4ht'", ",", "auch", "wenn", "kein", "Lob", "es", "rieth", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "VVFIN", "$,", "ADV", "KOUS", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Selbst das erschuf, was sie kopierte,", "tokens": ["Selbst", "das", "er\u00b7schuf", ",", "was", "sie", "ko\u00b7pier\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Fehler feinsten Anfang mied", "tokens": ["Der", "Feh\u00b7ler", "feins\u00b7ten", "An\u00b7fang", "mied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und standhaft, wenn um sie die Staatskunst kabalirte", "tokens": ["Und", "stand\u00b7haft", ",", "wenn", "um", "sie", "die", "Staats\u00b7kunst", "ka\u00b7ba\u00b7lir\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "KOUS", "APPR", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Selbst da, wo offt ein Pitt nur Zweiffel kalkulirte,", "tokens": ["Selbst", "da", ",", "wo", "offt", "ein", "Pitt", "nur", "Zweif\u00b7fel", "kal\u00b7ku\u00b7lir\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "ADV", "ART", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den feinen Schlangenpfad, der zur Vollendung f\u00fchrte", "tokens": ["Den", "fei\u00b7nen", "Schlan\u00b7gen\u00b7pfad", ",", "der", "zur", "Vol\u00b7len\u00b7dung", "f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Allzeit mit Sicherheit entschied. \u2013", "tokens": ["All\u00b7zeit", "mit", "Si\u00b7cher\u00b7heit", "ent\u00b7schied", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die still und sanft ihr Reich auf einen Felsen baute,", "tokens": ["Die", "still", "und", "sanft", "ihr", "Reich", "auf", "ei\u00b7nen", "Fel\u00b7sen", "bau\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auf zweyer Welten Schlangen trat", "tokens": ["Auf", "zwey\u00b7er", "Wel\u00b7ten", "Schlan\u00b7gen", "trat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und dann \u2013 mit ", "tokens": ["Und", "dann", "\u2013", "mit"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "ADV", "$(", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.16": {"text": "Auf einen ewigfesten Staat.", "tokens": ["Auf", "ei\u00b7nen", "e\u00b7wig\u00b7fes\u00b7ten", "Staat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die Frau! die selbst in ihren Kriegen", "tokens": ["Die", "Frau", "!", "die", "selbst", "in", "ih\u00b7ren", "Krie\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Noch Muster ist und Herzen nur besiegt,", "tokens": ["Noch", "Mus\u00b7ter", "ist", "und", "Her\u00b7zen", "nur", "be\u00b7siegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Der die Bezwungnen selbst mit Dank zu F\u00fcssen liegen,", "tokens": ["Der", "die", "Be\u00b7zwung\u00b7nen", "selbst", "mit", "Dank", "zu", "F\u00fcs\u00b7sen", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "APPR", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Weil sie ihr Ungl\u00fcck nur bekriegt.", "tokens": ["Weil", "sie", "ihr", "Un\u00b7gl\u00fcck", "nur", "be\u00b7kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie aber? \u2013 jener Blick voll Kraft und doch voll G\u00fcte", "tokens": ["Wie", "a\u00b7ber", "?", "\u2013", "je\u00b7ner", "Blick", "voll", "Kraft", "und", "doch", "voll", "G\u00fc\u00b7te"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "$.", "$(", "PDAT", "NN", "ADJD", "NN", "KON", "ADV", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Weise selbst zur Ehrfurcht zwingt,", "tokens": ["Der", "Wei\u00b7se", "selbst", "zur", "Ehr\u00b7furcht", "zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit wundervoller Jugendbl\u00fcthe", "tokens": ["Mit", "wun\u00b7der\u00b7vol\u00b7ler", "Ju\u00b7gend\u00b7bl\u00fc\u00b7the"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Mentors um sich her verj\u00fcngt:", "tokens": ["Die", "Men\u00b7tors", "um", "sich", "her", "ver\u00b7j\u00fcngt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "APZR", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist das der junge F\u00fcrst, der schon so lang sie heget", "tokens": ["Ist", "das", "der", "jun\u00b7ge", "F\u00fcrst", ",", "der", "schon", "so", "lang", "sie", "he\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gef\u00fchle jener Art, wie Peters Brust bewegt,", "tokens": ["Ge\u00b7f\u00fch\u00b7le", "je\u00b7ner", "Art", ",", "wie", "Pe\u00b7ters", "Brust", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "$,", "PWAV", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und sie verschlie\u00dft \u2013 weil er die Kr\u00e4fte w\u00e4get,", "tokens": ["Und", "sie", "ver\u00b7schlie\u00dft", "\u2013", "weil", "er", "die", "Kr\u00e4f\u00b7te", "w\u00e4\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Mit denen er die Welt einst tr\u00e4gt?", "tokens": ["Mit", "de\u00b7nen", "er", "die", "Welt", "einst", "tr\u00e4gt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "O theurer F\u00fcrst! der Kenner wird sie finden,", "tokens": ["O", "theu\u00b7rer", "F\u00fcrst", "!", "der", "Ken\u00b7ner", "wird", "sie", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des Weisen sch\u00e4rfster Blick sie gr\u00fcnden", "tokens": ["Des", "Wei\u00b7sen", "sch\u00e4rfs\u00b7ter", "Blick", "sie", "gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "In deinem feinsten Zug, wenn er dein Bild vergleicht,", "tokens": ["In", "dei\u00b7nem", "feins\u00b7ten", "Zug", ",", "wenn", "er", "dein", "Bild", "ver\u00b7gleicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den Ahnherrn sieht, erbla\u00dft \u2013 und schweigt.", "tokens": ["Den", "Ahn\u00b7herrn", "sieht", ",", "er\u00b7bla\u00dft", "\u2013", "und", "schweigt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "$(", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Geliebte Gr\u00f6sse! die durch sanft verschwiegne Tugend,", "tokens": ["Ge\u00b7lieb\u00b7te", "Gr\u00f6s\u00b7se", "!", "die", "durch", "sanft", "ver\u00b7schwieg\u00b7ne", "Tu\u00b7gend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ART", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die durch zur\u00fcckgehaltne Kraft", "tokens": ["Die", "durch", "zu\u00b7r\u00fcck\u00b7ge\u00b7halt\u00b7ne", "Kraft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Schon jetzt sich eine Welt erschafft,", "tokens": ["Schon", "jetzt", "sich", "ei\u00b7ne", "Welt", "er\u00b7schafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "In der sie ", "tokens": ["In", "der", "sie"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PRELS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "Bekannt mit jedem Reitz der Tugend,", "tokens": ["Be\u00b7kannt", "mit", "je\u00b7dem", "Reitz", "der", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Die still und froh in Deinem Beyspiel liest,", "tokens": ["Die", "still", "und", "froh", "in", "Dei\u00b7nem", "Bey\u00b7spiel", "liest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Der es, indem es sie zur Lust, zum Kampf begleitet,", "tokens": ["Der", "es", ",", "in\u00b7dem", "es", "sie", "zur", "Lust", ",", "zum", "Kampf", "be\u00b7glei\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "KOUS", "PPER", "PPER", "APPRART", "NN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Das S\u00e4itenspiel, so wie den Bogen leitet,", "tokens": ["Das", "S\u00e4i\u00b7ten\u00b7spiel", ",", "so", "wie", "den", "Bo\u00b7gen", "lei\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "KOKOM", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "In jeder Klasse Vorbild ist.", "tokens": ["In", "je\u00b7der", "Klas\u00b7se", "Vor\u00b7bild", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Kurz, der, Du Mensch-Apollo bist.", "tokens": ["Kurz", ",", "der", ",", "Du", "Men\u00b7schA\u00b7pol\u00b7lo", "bist", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PRELS", "$,", "PPER", "NE", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "F\u00fcr diese ists, da\u00df Du die Triebe zwingest,", "tokens": ["F\u00fcr", "die\u00b7se", "ists", ",", "da\u00df", "Du", "die", "Trie\u00b7be", "zwin\u00b7gest", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Die Dich so menschlich sanft zum Schutzgestirn erh\u00f6hn,", "tokens": ["Die", "Dich", "so", "menschlich", "sanft", "zum", "Schutz\u00b7ges\u00b7tirn", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "Und dann im Geist hoch \u00fcber Wolken dringest", "tokens": ["Und", "dann", "im", "Geist", "hoch", "\u00fc\u00b7ber", "Wol\u00b7ken", "drin\u00b7gest"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "ADJD", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Zahllose Herzen gl\u00fchn zu sehn.", "tokens": ["Zahl\u00b7lo\u00b7se", "Her\u00b7zen", "gl\u00fchn", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.27": {"text": "F\u00fcr diese ists, da\u00df sich in Unschuldst\u00e4nzen", "tokens": ["F\u00fcr", "die\u00b7se", "ists", ",", "da\u00df", "sich", "in", "Un\u00b7schuld\u00b7st\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDS", "VAFIN", "$,", "KOUS", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Der s\u00fcsse Pfeil in jeden Busen pflanzt", "tokens": ["Der", "s\u00fcs\u00b7se", "Pfeil", "in", "je\u00b7den", "Bu\u00b7sen", "pflanzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Und Beyfall, womit nur die freisten Seelen kr\u00e4nzen", "tokens": ["Und", "Bey\u00b7fall", ",", "wo\u00b7mit", "nur", "die", "freis\u00b7ten", "See\u00b7len", "kr\u00e4n\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "PWAV", "ADV", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Dein Herz, ganz G\u00fcte, sich ertanzt", "tokens": ["Dein", "Herz", ",", "ganz", "G\u00fc\u00b7te", ",", "sich", "er\u00b7tanzt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ADV", "NN", "$,", "PRF", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "F\u00fcr diese ists, da\u00df eitle Lorbeerreiser", "tokens": ["F\u00fcr", "die\u00b7se", "ists", ",", "da\u00df", "eit\u00b7le", "Lor\u00b7beer\u00b7rei\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PDS", "VAFIN", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Dies Herz verschm\u00e4ht und Alexanders Ruhm,", "tokens": ["Dies", "Herz", "ver\u00b7schm\u00e4ht", "und", "A\u00b7lex\u00b7an\u00b7ders", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVPP", "KON", "NE", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "F\u00fcr einen Blick, der redlicher und weiser", "tokens": ["F\u00fcr", "ei\u00b7nen", "Blick", ",", "der", "red\u00b7li\u00b7cher", "und", "wei\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART", "ADJA", "KON", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Dir sagt: Du wirst der Herzen K\u00e4iser \u2013", "tokens": ["Dir", "sagt", ":", "Du", "wirst", "der", "Her\u00b7zen", "K\u00e4i\u00b7ser", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Auch meines ist Dein Eigenthum.", "tokens": ["Auch", "mei\u00b7nes", "ist", "Dein", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja Prinz! die Frau, die Dich der Welt geschenket", "tokens": ["Ja", "Prinz", "!", "die", "Frau", ",", "die", "Dich", "der", "Welt", "ge\u00b7schen\u00b7ket"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "NN", "$.", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ward dadurch Mutter auch f\u00fcr mich.", "tokens": ["Ward", "da\u00b7durch", "Mut\u00b7ter", "auch", "f\u00fcr", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df sie der Welten Z\u00fcgel lenket", "tokens": ["Da\u00df", "sie", "der", "Wel\u00b7ten", "Z\u00fc\u00b7gel", "len\u00b7ket"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist gro\u00df, doch gr\u00f6sser nicht, als das: Sie schenkt' uns Dich.", "tokens": ["Ist", "gro\u00df", ",", "doch", "gr\u00f6s\u00b7ser", "nicht", ",", "als", "das", ":", "Sie", "schenkt'", "uns", "Dich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ADV", "ADJD", "PTKNEG", "$,", "KOUS", "PDS", "$.", "PPER", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie gab die F\u00fcrstinn uns, die ", "tokens": ["Sie", "gab", "die", "F\u00fcrs\u00b7tinn", "uns", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und durch ihn eine Welt, die, wenn er gl\u00fccklich ist,", "tokens": ["Und", "durch", "ihn", "ei\u00b7ne", "Welt", ",", "die", ",", "wenn", "er", "gl\u00fcck\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "$,", "PRELS", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mariens Schatten seegnend k\u00fc\u00dft", "tokens": ["Ma\u00b7ri\u00b7ens", "Schat\u00b7ten", "see\u00b7gnend", "k\u00fc\u00dft"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "ADJD", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Die den in ", "tokens": ["Die", "den", "in"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Der keines Staub's darauf vergi\u00dft.", "tokens": ["Der", "kei\u00b7nes", "Staub's", "da\u00b7rauf", "ver\u00b7gi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}