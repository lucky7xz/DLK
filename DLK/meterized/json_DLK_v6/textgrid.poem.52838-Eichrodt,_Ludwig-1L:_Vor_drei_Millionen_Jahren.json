{"textgrid.poem.52838": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Vor drei Millionen Jahren", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vor drei Millionen Jahren", "tokens": ["Vor", "drei", "Mil\u00b7lion\u00b7en", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Baut' in Kleinasium", "tokens": ["Baut'", "in", "Klei\u00b7na\u00b7si\u00b7um"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der F\u00fcrst der Vorfaharen", "tokens": ["Der", "F\u00fcrst", "der", "Vor\u00b7fa\u00b7ha\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Veste Ilium.", "tokens": ["Die", "Ves\u00b7te", "I\u00b7lium", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Grad \u00fcber sah man wohnen", "tokens": ["Grad", "\u00fc\u00b7ber", "sah", "man", "woh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "VVFIN", "PIS", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Griechen rohen Stamm,", "tokens": ["Der", "Grie\u00b7chen", "ro\u00b7hen", "Stamm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Priamus zum Hohne", "tokens": ["Der", "Pri\u00b7a\u00b7mus", "zum", "Hoh\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf Schiffen ihn beschwamm.", "tokens": ["Auf", "Schif\u00b7fen", "ihn", "be\u00b7schwamm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da gab es viele Kr\u00e4mpfe", "tokens": ["Da", "gab", "es", "vie\u00b7le", "Kr\u00e4mp\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vorm Stadtthor und am Meer,", "tokens": ["Vorm", "Stadt\u00b7thor", "und", "am", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und drinnen setzt' es Kr\u00e4mpfe", "tokens": ["Und", "drin\u00b7nen", "setzt'", "es", "Kr\u00e4mp\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und solche Sachen sehr.", "tokens": ["Und", "sol\u00b7che", "Sa\u00b7chen", "sehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die Helden thaten wilder", "tokens": ["Die", "Hel\u00b7den", "tha\u00b7ten", "wil\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als Tigerthier und Leu,", "tokens": ["Als", "Ti\u00b7ger\u00b7thier", "und", "Leu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es spielten die Weibsbilder", "tokens": ["Es", "spiel\u00b7ten", "die", "Weibs\u00b7bil\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die erste Roll dabei.", "tokens": ["Die", "ers\u00b7te", "Roll", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der Juppiter der litt es", "tokens": ["Der", "Jup\u00b7pi\u00b7ter", "der", "litt", "es"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zum Schmerze des Apoll,", "tokens": ["Zum", "Schmer\u00b7ze", "des", "A\u00b7poll", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Es lachte sich Thersites", "tokens": ["Es", "lach\u00b7te", "sich", "Ther\u00b7si\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Den krummen Buckel voll.", "tokens": ["Den", "krum\u00b7men", "Bu\u00b7ckel", "voll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der ha\u00dfte jeden K\u00f6nig,", "tokens": ["Der", "ha\u00df\u00b7te", "je\u00b7den", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und war genial wie Swift,", "tokens": ["Und", "war", "ge\u00b7ni\u00b7al", "wie", "Swift", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "KOKOM", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sein Blick war pur Arsenik,", "tokens": ["Sein", "Blick", "war", "pur", "Ar\u00b7se\u00b7nik", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und was er sprach, war Gift.", "tokens": ["Und", "was", "er", "sprach", ",", "war", "Gift", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Auf einmal sagt Achilles:", "tokens": ["Auf", "ein\u00b7mal", "sagt", "A\u00b7chil\u00b7les", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich spiele nimmer mit,", "tokens": ["Ich", "spie\u00b7le", "nim\u00b7mer", "mit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn meine Mutter will es", "tokens": ["Denn", "mei\u00b7ne", "Mut\u00b7ter", "will", "es"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die alte Amphitrit.", "tokens": ["Die", "al\u00b7te", "Am\u00b7phit\u00b7rit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Am Meere sa\u00df er rocklos", "tokens": ["Am", "Mee\u00b7re", "sa\u00df", "er", "rock\u00b7los"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADJD"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Im Hemd und gr\u00e4mte sich,", "tokens": ["Im", "Hemd", "und", "gr\u00e4m\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "VVFIN", "PRF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis da\u00df sein Freund Patroklos", "tokens": ["Bis", "da\u00df", "sein", "Freund", "Pat\u00b7ro\u00b7klos"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPOSAT", "NN", "NE"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Durch Hector's Spie\u00df erblich.", "tokens": ["Durch", "Hec\u00b7tor's", "Spie\u00df", "er\u00b7blich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Da wurmte sich Achilles,", "tokens": ["Da", "wurm\u00b7te", "sich", "A\u00b7chil\u00b7les", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er rast wie ein Bandit,", "tokens": ["Er", "rast", "wie", "ein", "Ban\u00b7dit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Unb\u00e4ndigen Gebr\u00fclles,", "tokens": ["Un\u00b7b\u00e4n\u00b7di\u00b7gen", "Ge\u00b7br\u00fcl\u00b7les", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Da spielt er wieder mit.", "tokens": ["Da", "spielt", "er", "wie\u00b7der", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Den gr\u00f6\u00dften Stadtdirector", "tokens": ["Den", "gr\u00f6\u00df\u00b7ten", "Stadt\u00b7di\u00b7rec\u00b7tor"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er richtet ihn zu Grund,", "tokens": ["Er", "rich\u00b7tet", "ihn", "zu", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach, auf den Namen Hector", "tokens": ["Ach", ",", "auf", "den", "Na\u00b7men", "Hec\u00b7tor"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "APPR", "ART", "NN", "NE"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "H\u00f6rt heut sogar der Hund!", "tokens": ["H\u00f6rt", "heut", "so\u00b7gar", "der", "Hund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Nun tobte auch der Ajas,", "tokens": ["Nun", "tob\u00b7te", "auch", "der", "A\u00b7jas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Kerl wie eine Schlacht,", "tokens": ["Ein", "Kerl", "wie", "ei\u00b7ne", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Thersites jener Bajazz", "tokens": ["Ther\u00b7si\u00b7tes", "je\u00b7ner", "Ba\u00b7jazz"], "token_info": ["word", "word", "word"], "pos": ["NE", "PDAT", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Hat oft ihn nachgemacht.", "tokens": ["Hat", "oft", "ihn", "nach\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Der Diomedes konnte", "tokens": ["Der", "Dio\u00b7me\u00b7des", "konn\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "NE", "VMFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nicht halten seinen Gaul,", "tokens": ["Nicht", "hal\u00b7ten", "sei\u00b7nen", "Gaul", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vor der Trojanerfronte,", "tokens": ["Vor", "der", "Tro\u00b7ja\u00b7ner\u00b7fron\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Der Nestor nicht das Maul.", "tokens": ["Der", "Nes\u00b7tor", "nicht", "das", "Maul", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Zum Schlusse aber ri\u00df es", "tokens": ["Zum", "Schlus\u00b7se", "a\u00b7ber", "ri\u00df", "es"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Griechen die Geduld,", "tokens": ["Den", "Grie\u00b7chen", "die", "Ge\u00b7duld", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und endlich war Ullysses", "tokens": ["Und", "end\u00b7lich", "war", "Ul\u00b7lys\u00b7ses"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "An Trojas Sturze schuld.", "tokens": ["An", "Tro\u00b7jas", "Stur\u00b7ze", "schuld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Da krochen die Spartiatten", "tokens": ["Da", "kro\u00b7chen", "die", "Spar\u00b7ti\u00b7at\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Aus des Geth\u00fcmes Bauch,", "tokens": ["Aus", "des", "Ge\u00b7th\u00fc\u00b7mes", "Bauch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und st\u00fcrmten frech wie Ratten", "tokens": ["Und", "st\u00fcrm\u00b7ten", "frech", "wie", "Rat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "KOKOM", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch Feuerwerk und Rauch.", "tokens": ["Durch", "Feu\u00b7er\u00b7werk", "und", "Rauch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Sie sengten und sie raubten", "tokens": ["Sie", "seng\u00b7ten", "und", "sie", "raub\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und metzelten, was kam,", "tokens": ["Und", "met\u00b7zel\u00b7ten", ",", "was", "kam", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "VVFIN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sie lachten und erlaubten", "tokens": ["Sie", "lach\u00b7ten", "und", "er\u00b7laub\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sich Vieles ohne Scham.", "tokens": ["Sich", "Vie\u00b7les", "oh\u00b7ne", "Scham", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Sie th\u00e4ten gar zerbrechen", "tokens": ["Sie", "th\u00e4\u00b7ten", "gar", "zer\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die M\u00f6bel und's Geschirr", "tokens": ["Die", "M\u00f6\u00b7bel", "un\u00b7d's", "Ge\u00b7schirr"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und um die Beute kn\u00f6cheln", "tokens": ["Und", "um", "die", "Beu\u00b7te", "kn\u00f6\u00b7cheln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit widrigem Geklirr.", "tokens": ["Mit", "wid\u00b7ri\u00b7gem", "Ge\u00b7klirr", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Kassandra, eine Nonne,", "tokens": ["Kas\u00b7sand\u00b7ra", ",", "ei\u00b7ne", "Non\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hat es vorausgesagt,", "tokens": ["Hat", "es", "vor\u00b7aus\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie ward in heller Sonne", "tokens": ["Sie", "ward", "in", "hel\u00b7ler", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom Ajax 'rumgeplagt.", "tokens": ["Vom", "A\u00b7jax", "'r\u00b7um\u00b7ge\u00b7plagt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Die Hekabeth, die Hexe,", "tokens": ["Die", "He\u00b7ka\u00b7be\u00b7th", ",", "die", "He\u00b7xe", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Lebendig ward verbrannt,", "tokens": ["Le\u00b7ben\u00b7dig", "ward", "ver\u00b7brannt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "VVPP", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und ihres Leibs Gew\u00e4chse", "tokens": ["Und", "ih\u00b7res", "Leibs", "Ge\u00b7w\u00e4ch\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geschleppt nach Griechenland.", "tokens": ["Ge\u00b7schleppt", "nach", "Grie\u00b7chen\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Nur einer war Aeneas,", "tokens": ["Nur", "ei\u00b7ner", "war", "A\u00b7e\u00b7neas", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kam ungeschoren fort,", "tokens": ["Kam", "un\u00b7ge\u00b7scho\u00b7ren", "fort", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit seinem Sohne Andreas,", "tokens": ["Mit", "sei\u00b7nem", "Soh\u00b7ne", "A\u00b7ndre\u00b7as", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An einen dritten Ort.", "tokens": ["An", "ei\u00b7nen", "drit\u00b7ten", "Ort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Er ist der Mann, der sp\u00e4ter", "tokens": ["Er", "ist", "der", "Mann", ",", "der", "sp\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Dido dran gekriegt,", "tokens": ["Die", "Di\u00b7do", "dran", "ge\u00b7kriegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PAV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als ein Uebelth\u00e4ter", "tokens": ["Und", "als", "ein", "Ue\u00b7belt\u00b7h\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sich heimlich wegverf\u00fcgt.", "tokens": ["Sich", "heim\u00b7lich", "weg\u00b7ver\u00b7f\u00fcgt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Das Schicksal war zufrieden,", "tokens": ["Das", "Schick\u00b7sal", "war", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Menschen weniger,", "tokens": ["Die", "Men\u00b7schen", "we\u00b7ni\u00b7ger", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zum Beispiel dem Atriden", "tokens": ["Zum", "Bei\u00b7spiel", "dem", "At\u00b7ri\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem ging es elend sehr.", "tokens": ["Dem", "ging", "es", "e\u00b7lend", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Das Opfer eines Schwertes", "tokens": ["Das", "Op\u00b7fer", "ei\u00b7nes", "Schwer\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ward der Aga Memnon,", "tokens": ["Ward", "der", "A\u00b7ga", "Mem\u00b7non", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NE", "NE", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und seekrank des Laertes", "tokens": ["Und", "see\u00b7krank", "des", "Laer\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sein vielverschlag'ner Sohn.", "tokens": ["Sein", "viel\u00b7ver\u00b7schlag'\u00b7ner", "Sohn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Da\u00df den Homer geschrieben", "tokens": ["Da\u00df", "den", "Ho\u00b7mer", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NE", "VVPP"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Hab' einstmals der Homer,", "tokens": ["Hab'", "einst\u00b7mals", "der", "Ho\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NE", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Das soll euch nicht betr\u00fcben", "tokens": ["Das", "soll", "euch", "nicht", "be\u00b7tr\u00fc\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So es erlogen w\u00e4r.", "tokens": ["So", "es", "er\u00b7lo\u00b7gen", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Im Gegentheil, die F\u00fchrer", "tokens": ["Im", "Ge\u00b7gen\u00b7theil", ",", "die", "F\u00fch\u00b7rer"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der deutschen Wissenschaft,", "tokens": ["Der", "deut\u00b7schen", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die gro\u00dfen Kritisirer,", "tokens": ["Die", "gro\u00b7\u00dfen", "Kri\u00b7ti\u00b7si\u00b7rer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Halten's f\u00fcr fabelhaft.", "tokens": ["Hal\u00b7ten's", "f\u00fcr", "fa\u00b7bel\u00b7haft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.25": {"line.1": {"text": "Sie strafen schm\u00e4hlich L\u00fcgen", "tokens": ["Sie", "stra\u00b7fen", "schm\u00e4h\u00b7lich", "L\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ganz Rom und Griechenland,", "tokens": ["Ganz", "Rom", "und", "Grie\u00b7chen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "KON", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wissens zur Gen\u00fcgen,", "tokens": ["Und", "wis\u00b7sens", "zur", "Ge\u00b7n\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df es von selbst entstand:", "tokens": ["Da\u00df", "es", "von", "selbst", "ent\u00b7stand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Das Buch der Iliade,", "tokens": ["Das", "Buch", "der", "I\u00b7lia\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Das Buch der Odyssee,", "tokens": ["Das", "Buch", "der", "O\u00b7dys\u00b7see", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ist's auch Jammerschade,", "tokens": ["Und", "ist's", "auch", "Jam\u00b7mer\u00b7scha\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie fanden's im Kaffee.", "tokens": ["Sie", "fan\u00b7den's", "im", "Kaf\u00b7fee", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}