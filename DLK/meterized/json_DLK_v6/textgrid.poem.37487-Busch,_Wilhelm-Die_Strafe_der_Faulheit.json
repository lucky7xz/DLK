{"textgrid.poem.37487": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Die Strafe der Faulheit", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Fr\u00e4ulein Ammer kost allhier", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "Am\u00b7mer", "kost", "all\u00b7hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Schnick, dem allerliebsten Tier.", "tokens": ["Mit", "Schnick", ",", "dem", "al\u00b7ler\u00b7liebs\u00b7ten", "Tier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sie f\u00fcttert ihn, soviel er mag,", "tokens": ["Sie", "f\u00fct\u00b7tert", "ihn", ",", "so\u00b7viel", "er", "mag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Zuckerbrot den ganzen Tag.", "tokens": ["Mit", "Zu\u00b7cker\u00b7brot", "den", "gan\u00b7zen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und nachts liegt er sogar im Bett,", "tokens": ["Und", "nachts", "liegt", "er", "so\u00b7gar", "im", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wird er freilich dick und fett.", "tokens": ["Da", "wird", "er", "frei\u00b7lich", "dick", "und", "fett", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Einstmals, als sie spazierengehen,", "tokens": ["Einst\u00b7mals", ",", "als", "sie", "spa\u00b7zie\u00b7ren\u00b7ge\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sieht man den Hundef\u00e4nger stehen.", "tokens": ["Sieht", "man", "den", "Hun\u00b7de\u00b7f\u00e4n\u00b7ger", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Er lockt den Schnick mit einer Brezen,", "tokens": ["Er", "lockt", "den", "Schnick", "mit", "ei\u00b7ner", "Bre\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Fr\u00e4ulein ruft ihn voll Entsetzen.", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "ruft", "ihn", "voll", "Ent\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch weil er nicht gehorchen kann,", "tokens": ["Doch", "weil", "er", "nicht", "ge\u00b7hor\u00b7chen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00e4ngt ihn gripsgraps der b\u00f6se Mann.", "tokens": ["F\u00e4ngt", "ihn", "grips\u00b7graps", "der", "b\u00f6\u00b7se", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.7": {"line.1": {"text": "Seht, wie er l\u00e4uft, der Hundeh\u00e4scher!", "tokens": ["Seht", ",", "wie", "er", "l\u00e4uft", ",", "der", "Hun\u00b7de\u00b7h\u00e4sc\u00b7her", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und tr\u00e4gt im Sack den dicken N\u00e4scher.", "tokens": ["Und", "tr\u00e4gt", "im", "Sack", "den", "di\u00b7cken", "N\u00e4\u00b7scher", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Gern lief er fort, der arme Schnick,", "tokens": ["Gern", "lief", "er", "fort", ",", "der", "ar\u00b7me", "Schnick", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch ist er viel zu dumm und dick.", "tokens": ["Doch", "ist", "er", "viel", "zu", "dumm", "und", "dick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbden schlacht' ich!\u00ab spricht der b\u00f6se Mann,", "tokens": ["\u00bb", "den", "schlacht'", "ich", "!", "\u00ab", "spricht", "der", "b\u00f6\u00b7se", "Mann", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "VVFIN", "PPER", "$.", "$(", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbweil er so fett und gar nichts kann.\u00ab", "tokens": ["\u00bb", "weil", "er", "so", "fett", "und", "gar", "nichts", "kann", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADJD", "KON", "ADV", "PIS", "VMFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Das Fr\u00e4ulein naht und jammert laut,", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "naht", "und", "jam\u00b7mert", "laut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist zu spat; da liegt die Haut.", "tokens": ["Es", "ist", "zu", "spat", ";", "da", "liegt", "die", "Haut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Zwei G\u00fclden zahlt sie in der Stille", "tokens": ["Zwei", "G\u00fcl\u00b7den", "zahlt", "sie", "in", "der", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Schnickens letzte Au\u00dfenh\u00fclle.", "tokens": ["F\u00fcr", "Schni\u00b7ckens", "letz\u00b7te", "Au\u00b7\u00dfen\u00b7h\u00fcl\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Hier steht der ausgestopfte Schnick. \u2013", "tokens": ["Hier", "steht", "der", "aus\u00b7ge\u00b7stopf\u00b7te", "Schnick", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer dick und faul, hat selten Gl\u00fcck.", "tokens": ["Wer", "dick", "und", "faul", ",", "hat", "sel\u00b7ten", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "$,", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}