{"textgrid.poem.53961": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Gebrauchslyrik", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vater, ich rufe dich!", "tokens": ["Va\u00b7ter", ",", "ich", "ru\u00b7fe", "dich", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Br\u00fcllend umdr\u00e4ut mich der Dampf der Gesch\u00fctze!", "tokens": ["Br\u00fcl\u00b7lend", "um\u00b7dr\u00e4ut", "mich", "der", "Dampf", "der", "Ge\u00b7sch\u00fct\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.2": {"line.1": {"text": "Rauh hat das Schwert den alten Traum zerschlagen.", "tokens": ["Rauh", "hat", "das", "Schwert", "den", "al\u00b7ten", "Traum", "zer\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So lang bewahrt auf tiefstem Herzensgrund:", "tokens": ["So", "lang", "be\u00b7wahrt", "auf", "tiefs\u00b7tem", "Her\u00b7zens\u00b7grund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Geeint in Freiheit sollte Deutschland ragen,", "tokens": ["Ge\u00b7eint", "in", "Frei\u00b7heit", "soll\u00b7te", "Deutschland", "ra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "VMFIN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein Bund des Volkes, nicht ein F\u00fcrstenbund!", "tokens": ["Ein", "Bund", "des", "Vol\u00b7kes", ",", "nicht", "ein", "F\u00fcrs\u00b7ten\u00b7bund", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ob sie sich hinter Tarifvertr\u00e4gen verstecken.", "tokens": ["Ob", "sie", "sich", "hin\u00b7ter", "Ta\u00b7rif\u00b7ver\u00b7tr\u00e4\u00b7gen", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ob sie in Arbeitsgemeinschaften", "tokens": ["Ob", "sie", "in", "Ar\u00b7beits\u00b7ge\u00b7mein\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "mit unsern eigenen Organisationen", "tokens": ["mit", "un\u00b7sern", "ei\u00b7ge\u00b7nen", "Or\u00b7ga\u00b7ni\u00b7sa\u00b7ti\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "im Produktionsprozesse den Profit retten.", "tokens": ["im", "Pro\u00b7duk\u00b7ti\u00b7ons\u00b7pro\u00b7zes\u00b7se", "den", "Pro\u00b7fit", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Mit unsern Bonzen Arm in Arm.", "tokens": ["Mit", "un\u00b7sern", "Bon\u00b7zen", "Arm", "in", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Oskar Kanehl", "tokens": ["Os\u00b7kar", "Ka\u00b7nehl"], "token_info": ["word", "word"], "pos": ["NE", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Nur nicht in euern K\u00e4mpfen", "tokens": ["Nur", "nicht", "in", "eu\u00b7ern", "K\u00e4mp\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "flie\u00dft unser Blut.", "tokens": ["flie\u00dft", "un\u00b7ser", "Blut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wir sind die", "tokens": ["Wir", "sind", "die"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Bonzen, Bonzen, Bonzen.", "tokens": ["Bon\u00b7zen", ",", "Bon\u00b7zen", ",", "Bon\u00b7zen", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Uns gehts gut.", "tokens": ["Uns", "gehts", "gut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Das sitzt. Oder:", "tokens": ["Das", "sitzt", ".", "O\u00b7der", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "KON", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Das Vaterland ist in Gefahr,", "tokens": ["Das", "Va\u00b7ter\u00b7land", "ist", "in", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was gehts uns an?", "tokens": ["Was", "gehts", "uns", "an", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}