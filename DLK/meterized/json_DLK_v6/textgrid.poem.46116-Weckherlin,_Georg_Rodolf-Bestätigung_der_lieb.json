{"textgrid.poem.46116": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Best\u00e4tigung der lieb", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df ihr von vilen seid geehret,", "tokens": ["Da\u00df", "ihr", "von", "vi\u00b7len", "seid", "ge\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ihr von vilen werd begehret,", "tokens": ["da\u00df", "ihr", "von", "vi\u00b7len", "werd", "be\u00b7ge\u00b7hret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "mag wol wahr sein;", "tokens": ["mag", "wol", "wahr", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "da\u00df aber ihr der andern seelen", "tokens": ["da\u00df", "a\u00b7ber", "ihr", "der", "an\u00b7dern", "see\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "k\u00f6nt so sehr, als die meine, qu\u00e4len,", "tokens": ["k\u00f6nt", "so", "sehr", ",", "als", "die", "mei\u00b7ne", ",", "qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "$,", "KOUS", "ART", "PPOSAT", "$,", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "hat keinen schein.", "tokens": ["hat", "kei\u00b7nen", "schein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Da\u00df vil sch\u00f6nheiten hie auf erden", "tokens": ["Da\u00df", "vil", "sch\u00f6n\u00b7hei\u00b7ten", "hie", "auf", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "gelobet und verwundert werden,", "tokens": ["ge\u00b7lo\u00b7bet", "und", "ver\u00b7wun\u00b7dert", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mag wol wahr sein;", "tokens": ["mag", "wol", "wahr", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "da\u00df aber eine auch aus allen", "tokens": ["da\u00df", "a\u00b7ber", "ei\u00b7ne", "auch", "aus", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "den g\u00f6ttern m\u00f6g, wie ihr, gefallen,", "tokens": ["den", "g\u00f6t\u00b7tern", "m\u00f6g", ",", "wie", "ihr", ",", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "PPER", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "hat keinen schein.", "tokens": ["hat", "kei\u00b7nen", "schein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Da\u00df einer, der euch nur ersehen,", "tokens": ["Da\u00df", "ei\u00b7ner", ",", "der", "euch", "nur", "er\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "w\u00f6ll euern dienst stracks undergehen,", "tokens": ["w\u00f6ll", "eu\u00b7ern", "dienst", "stracks", "un\u00b7der\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mag wol wahr sein;", "tokens": ["mag", "wol", "wahr", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "da\u00df aber ihr m\u00f6cht einen finden,", "tokens": ["da\u00df", "a\u00b7ber", "ihr", "m\u00f6cht", "ei\u00b7nen", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "den ihr so hart, als mich, k\u00f6nt binden,", "tokens": ["den", "ihr", "so", "hart", ",", "als", "mich", ",", "k\u00f6nt", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "$,", "KOUS", "PPER", "$,", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "hat keinen schein.", "tokens": ["hat", "kei\u00b7nen", "schein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Da\u00df auch durch eure s\u00fc\u00dfe sitten", "tokens": ["Da\u00df", "auch", "durch", "eu\u00b7re", "s\u00fc\u00b7\u00dfe", "sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ich nicht allein vil m\u00fch erlitten,", "tokens": ["ich", "nicht", "al\u00b7lein", "vil", "m\u00fch", "er\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mag wol wahr sein;", "tokens": ["mag", "wol", "wahr", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "da\u00df aber darum andre herzen", "tokens": ["da\u00df", "a\u00b7ber", "da\u00b7rum", "and\u00b7re", "her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PAV", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "dem meinen leiden gleiche schmerzen,", "tokens": ["dem", "mei\u00b7nen", "lei\u00b7den", "glei\u00b7che", "schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "hat keinen schein.", "tokens": ["hat", "kei\u00b7nen", "schein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Da\u00df, endlich solche pein zu fliehen,", "tokens": ["Da\u00df", ",", "end\u00b7lich", "sol\u00b7che", "pein", "zu", "flie\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "sich meine vernunft w\u00f6ll bem\u00fchen,", "tokens": ["sich", "mei\u00b7ne", "ver\u00b7nunft", "w\u00f6ll", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "mag wol wahr sein;", "tokens": ["mag", "wol", "wahr", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "da\u00df aber von so sch\u00f6nen h\u00e4nden", "tokens": ["da\u00df", "a\u00b7ber", "von", "so", "sch\u00f6\u00b7nen", "h\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ich mich zu andrer dienst k\u00f6nd wenden,", "tokens": ["ich", "mich", "zu", "an\u00b7drer", "dienst", "k\u00f6nd", "wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPR", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "hat keinen schein.", "tokens": ["hat", "kei\u00b7nen", "schein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Da\u00df der tod allein meine klagen", "tokens": ["Da\u00df", "der", "tod", "al\u00b7lein", "mei\u00b7ne", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "PPOSAT", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "und euern hochmut werd ertragen,", "tokens": ["und", "eu\u00b7ern", "hoch\u00b7mut", "werd", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mag wol wahr sein;", "tokens": ["mag", "wol", "wahr", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "da\u00df aber sich durch das beleiden", "tokens": ["da\u00df", "a\u00b7ber", "sich", "durch", "das", "be\u00b7lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PRF", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "mein herz w\u00f6ll und k\u00f6nd von euch scheiden,", "tokens": ["mein", "herz", "w\u00f6ll", "und", "k\u00f6nd", "von", "euch", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "KON", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "hat keinen schein.", "tokens": ["hat", "kei\u00b7nen", "schein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}