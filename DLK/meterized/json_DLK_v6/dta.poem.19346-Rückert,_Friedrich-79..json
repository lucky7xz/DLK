{"dta.poem.19346": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "79.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195090", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Dem Menschen ist ein Recht gegeben auf die Sachen,", "tokens": ["Dem", "Men\u00b7schen", "ist", "ein", "Recht", "ge\u00b7ge\u00b7ben", "auf", "die", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von Gott hat ers zu Lehn, wer kanns ihm streitig machen?", "tokens": ["Von", "Gott", "hat", "ers", "zu", "Lehn", ",", "wer", "kanns", "ihm", "strei\u00b7tig", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PIS", "PTKZU", "VVINF", "$,", "PWS", "VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wenn von den Menschen w\u00e4r' ein einziger am Leben,", "tokens": ["Wenn", "von", "den", "Men\u00b7schen", "w\u00e4r'", "ein", "ein\u00b7zi\u00b7ger", "am", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "APPRART", "NN", "$,"], "meter": "+--+-++-+--+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Die ganze Erde w\u00e4r' in seine Hand gegeben.", "tokens": ["Die", "gan\u00b7ze", "Er\u00b7de", "w\u00e4r'", "in", "sei\u00b7ne", "Hand", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So wie im Anbeginn, wir glauben's, einer war,", "tokens": ["So", "wie", "im", "An\u00b7be\u00b7ginn", ",", "wir", "glau\u00b7ben's", ",", "ei\u00b7ner", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPRART", "NN", "$,", "PPER", "VVFIN", "$,", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In dem sich ungetheilt die Menschheit stellte dar.", "tokens": ["In", "dem", "sich", "un\u00b7ge\u00b7theilt", "die", "Menschheit", "stell\u00b7te", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ADJD", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Doch als zum Manne nun das Weib hinzugekommen,", "tokens": ["Doch", "als", "zum", "Man\u00b7ne", "nun", "das", "Weib", "hin\u00b7zu\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "NN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ward diesem wohl ein Theil, der jenem ward genommen?", "tokens": ["Ward", "die\u00b7sem", "wohl", "ein", "Theil", ",", "der", "je\u00b7nem", "ward", "ge\u00b7nom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "ADV", "ART", "NN", "$,", "PRELS", "PDAT", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Mitnichten; weil das Paar in Zweiheit Eines war,", "tokens": ["Mit\u00b7nich\u00b7ten", ";", "weil", "das", "Paar", "in", "Zwei\u00b7heit", "Ei\u00b7nes", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "ART", "NN", "APPR", "NN", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "War zur Entzweiung im Besitz auch nicht Gefahr.", "tokens": ["War", "zur", "Ent\u00b7zwei\u00b7ung", "im", "Be\u00b7sitz", "auch", "nicht", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "APPRART", "NN", "ADV", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Und also, wo noch zwei in Liebe werden Eines,", "tokens": ["Und", "al\u00b7so", ",", "wo", "noch", "zwei", "in", "Lie\u00b7be", "wer\u00b7den", "Ei\u00b7nes", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "ADV", "CARD", "APPR", "NN", "VAFIN", "PIS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist ihr Besitzrecht an die Welt ein allgemeines.", "tokens": ["Ist", "ihr", "Be\u00b7sitz\u00b7recht", "an", "die", "Welt", "ein", "all\u00b7ge\u00b7mei\u00b7nes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Denn ganz in jedem Paar stellt sich die Menschheit dar,", "tokens": ["Denn", "ganz", "in", "je\u00b7dem", "Paar", "stellt", "sich", "die", "Menschheit", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von allwievielen schon die Welt besessen war.", "tokens": ["Von", "all\u00b7wie\u00b7vie\u00b7len", "schon", "die", "Welt", "be\u00b7ses\u00b7sen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Bescheiden ziehen sie auch ihr beschieden Lo\u00df,", "tokens": ["Be\u00b7schei\u00b7den", "zie\u00b7hen", "sie", "auch", "ihr", "be\u00b7schie\u00b7den", "Lo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sei es klein, so mach' es Lieb' und Treue gro\u00df.", "tokens": ["Und", "sei", "es", "klein", ",", "so", "mach'", "es", "Lieb'", "und", "Treu\u00b7e", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Doch als zum Vater dort hinzu die S\u00f6hne kamen,", "tokens": ["Doch", "als", "zum", "Va\u00b7ter", "dort", "hin\u00b7zu", "die", "S\u00f6h\u00b7ne", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "NN", "ADV", "PTKVZ", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Besa\u00df das Oberhaupt mit in der Glieder Namen.", "tokens": ["Be\u00b7sa\u00df", "das", "O\u00b7ber\u00b7haupt", "mit", "in", "der", "Glie\u00b7der", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Sie waren im Besitz von selbst mit eingeschlossen;", "tokens": ["Sie", "wa\u00b7ren", "im", "Be\u00b7sitz", "von", "selbst", "mit", "ein\u00b7ge\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "APPR", "ADV", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie h\u00e4tten nicht auch, was der Baum hat, seine Sprossen?", "tokens": ["Wie", "h\u00e4t\u00b7ten", "nicht", "auch", ",", "was", "der", "Baum", "hat", ",", "sei\u00b7ne", "Spros\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PTKNEG", "ADV", "$,", "PRELS", "ART", "NN", "VAFIN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Doch als die Glieder drauf sich los vom Haupte rissen,", "tokens": ["Doch", "als", "die", "Glie\u00b7der", "drauf", "sich", "los", "vom", "Haup\u00b7te", "ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PAV", "PRF", "PTKVZ", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da wollte jedes, was ihm eigen w\u00e4re, wissen.", "tokens": ["Da", "woll\u00b7te", "je\u00b7des", ",", "was", "ihm", "ei\u00b7gen", "w\u00e4\u00b7re", ",", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "$,", "PWS", "PPER", "ADJD", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Da sprach ihr Vater: Geht nun in die Welt hinaus,", "tokens": ["Da", "sprach", "ihr", "Va\u00b7ter", ":", "Geht", "nun", "in", "die", "Welt", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "VVFIN", "ADV", "APPR", "ART", "NN", "APZR", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und bauet, wie und wo ihr m\u00f6get, Feld und Haus.", "tokens": ["Und", "bau\u00b7et", ",", "wie", "und", "wo", "ihr", "m\u00f6\u00b7get", ",", "Feld", "und", "Haus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "KON", "PWAV", "PPER", "VMFIN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Die Welt ist weit genug, um drin euch auszuweichen,", "tokens": ["Die", "Welt", "ist", "weit", "ge\u00b7nug", ",", "um", "drin", "euch", "aus\u00b7zu\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADV", "$,", "KOUI", "ADV", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Euch auszubreiten ohn' einander zu erreichen.", "tokens": ["Euch", "aus\u00b7zu\u00b7brei\u00b7ten", "ohn'", "ein\u00b7an\u00b7der", "zu", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Es wird am Gegenstand nicht fehlen eurer Hand,", "tokens": ["Es", "wird", "am", "Ge\u00b7gen\u00b7stand", "nicht", "feh\u00b7len", "eu\u00b7rer", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PTKNEG", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und jeder habe, was er zu ergreifen fand.", "tokens": ["Und", "je\u00b7der", "ha\u00b7be", ",", "was", "er", "zu", "er\u00b7grei\u00b7fen", "fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "$,", "PWS", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Demselben dr\u00fcck' er auf das Zeichen des Besitzes,", "tokens": ["Dem\u00b7sel\u00b7ben", "dr\u00fcck", "er", "auf", "das", "Zei\u00b7chen", "des", "Be\u00b7sit\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Zeichen seiner Kraft, das Zeichen seines Witzes.", "tokens": ["Das", "Zei\u00b7chen", "sei\u00b7ner", "Kraft", ",", "das", "Zei\u00b7chen", "sei\u00b7nes", "Wit\u00b7zes", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Doch welcher Sache schon ihr eures Bruders Zeichen", "tokens": ["Doch", "wel\u00b7cher", "Sa\u00b7che", "schon", "ihr", "eu\u00b7res", "Bru\u00b7ders", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "ADV", "PPER", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Seht aufgedr\u00fcckt, davon sollt ihr zur\u00fccke weichen.", "tokens": ["Seht", "auf\u00b7ge\u00b7dr\u00fcckt", ",", "da\u00b7von", "sollt", "ihr", "zu\u00b7r\u00fc\u00b7cke", "wei\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$,", "PAV", "VMFIN", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Doch wann die Zweige nun zu St\u00e4mmen sind geworden,", "tokens": ["Doch", "wann", "die", "Zwei\u00b7ge", "nun", "zu", "St\u00e4m\u00b7men", "sind", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "APPR", "NN", "VAFIN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ihr das Land erf\u00fcllt mit Herden und mit Horden;", "tokens": ["Und", "ihr", "das", "Land", "er\u00b7f\u00fcllt", "mit", "Her\u00b7den", "und", "mit", "Hor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVFIN", "APPR", "NN", "KON", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Dann wird der Hader bald im Kleinen, bald im Gro\u00dfen", "tokens": ["Dann", "wird", "der", "Ha\u00b7der", "bald", "im", "Klei\u00b7nen", ",", "bald", "im", "Gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erwachsen da, wo ihr zusammen werdet sto\u00dfen,", "tokens": ["Er\u00b7wach\u00b7sen", "da", ",", "wo", "ihr", "zu\u00b7sam\u00b7men", "wer\u00b7det", "sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PWAV", "PPER", "ADV", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Wenn ihr entfremdet nicht mehr eure Zeichen kennt,", "tokens": ["Wenn", "ihr", "ent\u00b7frem\u00b7det", "nicht", "mehr", "eu\u00b7re", "Zei\u00b7chen", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PTKNEG", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und, statt was euch verband, nur f\u00fchlet was euch trennt.", "tokens": ["Und", ",", "statt", "was", "euch", "ver\u00b7band", ",", "nur", "f\u00fch\u00b7let", "was", "euch", "trennt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Dann wird Volk gegen Volk zum Schutze sich verb\u00fcnden,", "tokens": ["Dann", "wird", "Volk", "ge\u00b7gen", "Volk", "zum", "Schut\u00b7ze", "sich", "ver\u00b7b\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "APPR", "NN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und einzle Ganze sich im gro\u00dfen Ganzen r\u00fcnden.", "tokens": ["Und", "einz\u00b7le", "Gan\u00b7ze", "sich", "im", "gro\u00b7\u00dfen", "Gan\u00b7zen", "r\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PRF", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Nat\u00fcrlich steht zuerst als Mittelpunkt im Kreise", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "steht", "zu\u00b7erst", "als", "Mit\u00b7tel\u00b7punkt", "im", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "KOUS", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Aeltste, der zugleich der beste scheint und weise.", "tokens": ["Der", "A\u00b7elts\u00b7te", ",", "der", "zu\u00b7gleich", "der", "bes\u00b7te", "scheint", "und", "wei\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "ADJA", "VVFIN", "KON", "VVFIN", "$."], "meter": "--+-+-+-+-+-+-", "measure": "anapaest.init"}}, "stanza.22": {"line.1": {"text": "Ob einer dann den Platz dem andern streitig mache,", "tokens": ["Ob", "ei\u00b7ner", "dann", "den", "Platz", "dem", "an\u00b7dern", "strei\u00b7tig", "ma\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ART", "NN", "ART", "ADJA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch immer dienen wird dem st\u00e4rkeren der schwache.", "tokens": ["Doch", "im\u00b7mer", "die\u00b7nen", "wird", "dem", "st\u00e4r\u00b7ke\u00b7ren", "der", "schwa\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "VAFIN", "ART", "VVFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Der starke dienet auch dem schw\u00e4cheren zum Schutze;", "tokens": ["Der", "star\u00b7ke", "die\u00b7net", "auch", "dem", "schw\u00e4\u00b7che\u00b7ren", "zum", "Schut\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "ART", "ADJA", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch Kunst und Geist dient bald zur Wohlfahrt, bald zum Putze.", "tokens": ["Doch", "Kunst", "und", "Geist", "dient", "bald", "zur", "Wohl\u00b7fahrt", ",", "bald", "zum", "Put\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "ADV", "APPRART", "NN", "$,", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Den Muth zu dienen, der da Demuth hei\u00dfet, lernt,", "tokens": ["Den", "Muth", "zu", "die\u00b7nen", ",", "der", "da", "De\u00b7muth", "hei\u00b7\u00dfet", ",", "lernt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "ADV", "NN", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hochm\u00fcth'ge, die ihr euch vom Vaterhaus entfernt.", "tokens": ["Hoch\u00b7m\u00fcth'\u00b7ge", ",", "die", "ihr", "euch", "vom", "Va\u00b7ter\u00b7haus", "ent\u00b7fernt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Zum Vaterhaus f\u00fchrt euch der Geist der Demuth wieder,", "tokens": ["Zum", "Va\u00b7ter\u00b7haus", "f\u00fchrt", "euch", "der", "Geist", "der", "De\u00b7muth", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn menschlich ihr euch f\u00fchlt des Leibs der Menschheit Glieder.", "tokens": ["Wenn", "menschlich", "ihr", "euch", "f\u00fchlt", "des", "Leibs", "der", "Menschheit", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}}}}