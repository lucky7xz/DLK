{"textgrid.poem.66510": {"metadata": {"author": {"name": "Roquette, Otto", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nach dem Reichthum all' des S\u00fc\u00dfen,", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nach dem Reichthum all' des S\u00fc\u00dfen,", "tokens": ["Nach", "dem", "Reicht\u00b7hum", "all'", "des", "S\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Blumen Duft und Glanz,", "tokens": ["Und", "der", "Blu\u00b7men", "Duft", "und", "Glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Kommt noch sp\u00e4t dich zu begr\u00fc\u00dfen", "tokens": ["Kommt", "noch", "sp\u00e4t", "dich", "zu", "be\u00b7gr\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hier ein Sauerampferkranz!", "tokens": ["Hier", "ein", "Sau\u00b7e\u00b7ramp\u00b7fer\u00b7kranz", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ungew\u00f6hnlich ist vor Leuten", "tokens": ["Un\u00b7ge\u00b7w\u00f6hn\u00b7lich", "ist", "vor", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Solch ein Kranz, man mu\u00df gestehn!", "tokens": ["Solch", "ein", "Kranz", ",", "man", "mu\u00df", "ge\u00b7stehn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "$,", "PIS", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wollt' er gar etwas bedeuten,", "tokens": ["Wollt'", "er", "gar", "et\u00b7was", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "W\u00e4r' es um den Dank geschehn!", "tokens": ["W\u00e4r'", "es", "um", "den", "Dank", "ge\u00b7schehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch auf reineres Verst\u00e4ndni\u00df", "tokens": ["Doch", "auf", "rei\u00b7ne\u00b7res", "Ver\u00b7st\u00e4nd\u00b7ni\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hofft bei dir dies Maiengr\u00fcn:", "tokens": ["Hofft", "bei", "dir", "dies", "Mai\u00b7en\u00b7gr\u00fcn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PDS", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00f6rdrung der Geschmackserkenntni\u00df", "tokens": ["F\u00f6r\u00b7drung", "der", "Ge\u00b7schmack\u00b7ser\u00b7kennt\u00b7ni\u00df"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "NN"], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Einzig soll daraus erbl\u00fchn.", "tokens": ["Ein\u00b7zig", "soll", "da\u00b7raus", "er\u00b7bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PAV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und da\u00df ich mir Dank erwerbe,", "tokens": ["Und", "da\u00df", "ich", "mir", "Dank", "er\u00b7wer\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als ein Suppenkunst-Adept,", "tokens": ["Als", "ein", "Sup\u00b7pen\u00b7kunst\u00b7A\u00b7dept", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "F\u00fcr das Wilde und das Herbe", "tokens": ["F\u00fcr", "das", "Wil\u00b7de", "und", "das", "Her\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Geb' ich gleich das Kochrezept:", "tokens": ["Geb'", "ich", "gleich", "das", "Koch\u00b7re\u00b7zept", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Nimm denn Br\u00fche, sei's von Knochen,", "tokens": ["Nimm", "denn", "Br\u00fc\u00b7he", ",", "sei's", "von", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sei's von Muskeln, la\u00df drauf gut", "tokens": ["Sei's", "von", "Mus\u00b7keln", ",", "la\u00df", "drauf", "gut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPR", "NN", "$,", "VVIMP", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den gehackten Ampfer kochen,", "tokens": ["Den", "ge\u00b7hack\u00b7ten", "Amp\u00b7fer", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der krafterf\u00fcllten Flut.", "tokens": ["In", "der", "kraf\u00b7ter\u00b7f\u00fcll\u00b7ten", "Flut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Liebst du gr\u00fcnen Kerbels Spenden,", "tokens": ["Liebst", "du", "gr\u00fc\u00b7nen", "Ker\u00b7bels", "Spen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oder blauen Gundermann,", "tokens": ["O\u00b7der", "blau\u00b7en", "Gun\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Thu dann, ohne zu verschwenden,", "tokens": ["Thu", "dann", ",", "oh\u00b7ne", "zu", "ver\u00b7schwen\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Auch von diesem etwas dran.", "tokens": ["Auch", "von", "die\u00b7sem", "et\u00b7was", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch bevor sie angerichtet,", "tokens": ["Doch", "be\u00b7vor", "sie", "an\u00b7ge\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und sich biete sonder Fehl,", "tokens": ["Und", "sich", "bie\u00b7te", "son\u00b7der", "Fehl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00e4mig wird die Flut verdichtet", "tokens": ["S\u00e4\u00b7mig", "wird", "die", "Flut", "ver\u00b7dich\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch mit Eigelb, Rahm und Mehl.", "tokens": ["Noch", "mit", "Ei\u00b7gelb", ",", "Rahm", "und", "Mehl", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann, zum \u00e4u\u00dfersten Behagen,", "tokens": ["Dann", ",", "zum", "\u00e4u\u00b7\u00dfers\u00b7ten", "Be\u00b7ha\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "--+---+-", "measure": "anapaest.init"}, "line.6": {"text": "In das duft'ge Element", "tokens": ["In", "das", "duft'\u00b7ge", "E\u00b7le\u00b7ment"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Eier noch hineingeschlagen,", "tokens": ["Ei\u00b7er", "noch", "hin\u00b7ein\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Welche man \u00bbverlor'ne\u00ab nennt.", "tokens": ["Wel\u00b7che", "man", "\u00bb", "ver\u00b7lor'\u00b7ne", "\u00ab", "nennt", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "PIS", "$(", "ADJA", "$(", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch nun darf ich nicht verschweigen,", "tokens": ["Doch", "nun", "darf", "ich", "nicht", "ver\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df \u2013 zum Trost gereich' dir dies \u2013", "tokens": ["Da\u00df", "\u2013", "zum", "Trost", "ge\u00b7reich'", "dir", "dies", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "APPRART", "NN", "VVFIN", "PPER", "PDS", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Erfindung nicht mein eigen,", "tokens": ["Die", "Er\u00b7fin\u00b7dung", "nicht", "mein", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PPOSAT", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich sehr mir helfen lie\u00df.", "tokens": ["Und", "ich", "sehr", "mir", "hel\u00b7fen", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PPER", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ruf' denn die Familiengruppe", "tokens": ["Ruf'", "denn", "die", "Fa\u00b7mi\u00b7li\u00b7en\u00b7grup\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "L\u00f6ffeltapfer um's Gedeck!", "tokens": ["L\u00f6f\u00b7fel\u00b7tap\u00b7fer", "um's", "Ge\u00b7deck", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und behagt ihr dann die Suppe,", "tokens": ["Und", "be\u00b7hagt", "ihr", "dann", "die", "Sup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist erf\u00fcllt des Kranzes Zweck.", "tokens": ["Ist", "er\u00b7f\u00fcllt", "des", "Kran\u00b7zes", "Zweck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}