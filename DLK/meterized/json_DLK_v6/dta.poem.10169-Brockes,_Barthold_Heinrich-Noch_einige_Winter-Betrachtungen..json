{"dta.poem.10169": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Noch einige Winter-Betrachtungen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die B\u00e4ume sind ietzt wei\u00df, ein ieder Ast,", "tokens": ["Die", "B\u00e4u\u00b7me", "sind", "ietzt", "wei\u00df", ",", "ein", "ie\u00b7der", "Ast", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "$,", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ja auch der kleinste Zweig, tr\u00e4gt eine Flocken-Last,", "tokens": ["Ja", "auch", "der", "kleins\u00b7te", "Zweig", ",", "tr\u00e4gt", "ei\u00b7ne", "Flo\u00b7cken\u00b7Last", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wodurch, was biegsam, tieff gebogen abw\u00e4rtz h\u00e4nget.", "tokens": ["Wo\u00b7durch", ",", "was", "bieg\u00b7sam", ",", "tieff", "ge\u00b7bo\u00b7gen", "ab\u00b7w\u00e4rtz", "h\u00e4n\u00b7get", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PRELS", "ADJD", "$,", "ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch reisset offt der wilde Nord", "tokens": ["Doch", "reis\u00b7set", "offt", "der", "wil\u00b7de", "Nord"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die weisse B\u00fcrde mit sich fort,", "tokens": ["Die", "weis\u00b7se", "B\u00fcr\u00b7de", "mit", "sich", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und streuet sie, mit Schlossen untermenget,", "tokens": ["Und", "streu\u00b7et", "sie", ",", "mit", "Schlos\u00b7sen", "un\u00b7ter\u00b7men\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ergrimmet \u00fcberall. Es rasselt recht und zischt,", "tokens": ["Er\u00b7grim\u00b7met", "\u00fc\u00b7be\u00b7rall", ".", "Es", "ras\u00b7selt", "recht", "und", "zischt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "PPER", "VVFIN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wann er was hartes trifft. Der Schnee, gepresst, ge-", "tokens": ["Wann", "er", "was", "har\u00b7tes", "trifft", ".", "Der", "Schnee", ",", "ge\u00b7presst", ",", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "PPER", "PIS", "ADJA", "VVFIN", "$.", "ART", "NN", "$,", "VVPP", "$,", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Fliegt in der grauen Lufft, als wie ein weisser Schmauch,", "tokens": ["Fliegt", "in", "der", "grau\u00b7en", "Lufft", ",", "als", "wie", "ein", "weis\u00b7ser", "Schmauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,", "KOUS", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Hier wie ein weisser Schaum, dort wie ein weisser Rauch,", "tokens": ["Hier", "wie", "ein", "weis\u00b7ser", "Schaum", ",", "dort", "wie", "ein", "weis\u00b7ser", "Rauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$,", "ADV", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit weissem Staub vermischt.", "tokens": ["Mit", "weis\u00b7sem", "Staub", "ver\u00b7mischt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Dem folget bald ein Heer von luckern Flocken wieder,", "tokens": ["Dem", "fol\u00b7get", "bald", "ein", "Heer", "von", "lu\u00b7ckern", "Flo\u00b7cken", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die schweben, wann es still, gem\u00e4hlig auf und nieder:", "tokens": ["Die", "schwe\u00b7ben", ",", "wann", "es", "still", ",", "ge\u00b7m\u00e4h\u00b7lig", "auf", "und", "nie\u00b7der", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PWAV", "PPER", "PTKVZ", "$,", "ADJD", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wovon, wann viele sich allm\u00e4hlig aufw\u00e4rts ziehn,", "tokens": ["Wo\u00b7von", ",", "wann", "vie\u00b7le", "sich", "all\u00b7m\u00e4h\u00b7lig", "auf\u00b7w\u00e4rts", "ziehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "PIS", "PRF", "ADJD", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Viel\u2019 Ost- und viele West-w\u00e4rts fliehn.", "tokens": ["Viel'", "Ost", "und", "vie\u00b7le", "West\u00b7w\u00e4rts", "fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Des krummen Wandrers Haar wird, durch den rauhen", "tokens": ["Des", "krum\u00b7men", "Wand\u00b7rers", "Haar", "wird", ",", "durch", "den", "rau\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VAFIN", "$,", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Beeiset, wei\u00df und steiff.", "tokens": ["Be\u00b7ei\u00b7set", ",", "wei\u00df", "und", "steiff", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "H\u00e4lt gleich der Schnee das Land, das Eis die Fluth", "tokens": ["H\u00e4lt", "gleich", "der", "Schnee", "das", "Land", ",", "das", "Eis", "die", "Fluth"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ja st\u00fcrmt und schnaubt der Nord, wie er ietzt \u00f6ffters pflag;", "tokens": ["Ja", "st\u00fcrmt", "und", "schnaubt", "der", "Nord", ",", "wie", "er", "ietzt", "\u00f6ff\u00b7ters", "pflag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erinner\u2019 ich mich doch, offt manchen sch\u00f6nen Tag", "tokens": ["Er\u00b7in\u00b7ner'", "ich", "mich", "doch", ",", "offt", "man\u00b7chen", "sch\u00f6\u00b7nen", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "$,", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Jm Winter auch erlebt zu haben.", "tokens": ["Jm", "Win\u00b7ter", "auch", "er\u00b7lebt", "zu", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}