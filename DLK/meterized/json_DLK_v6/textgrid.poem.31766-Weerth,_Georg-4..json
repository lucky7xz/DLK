{"textgrid.poem.31766": {"metadata": {"author": {"name": "Weerth, Georg", "birth": "N.A.", "death": "N.A."}, "title": "4.", "genre": "verse", "period": "N.A.", "pub_year": 1839, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da standen wir auf den H\u00fcgeln, und", "tokens": ["Da", "stan\u00b7den", "wir", "auf", "den", "H\u00fc\u00b7geln", ",", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KON"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Romantisch ward mir zumute \u2013", "tokens": ["Ro\u00b7man\u00b7tisch", "ward", "mir", "zu\u00b7mu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "VVFIN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Politische Freunde m\u00fcssen dies", "tokens": ["Po\u00b7li\u00b7ti\u00b7sche", "Freun\u00b7de", "m\u00fcs\u00b7sen", "dies"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VMFIN", "PDS"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Gef\u00e4lligst mir halten zugute.", "tokens": ["Ge\u00b7f\u00e4l\u00b7ligst", "mir", "hal\u00b7ten", "zu\u00b7gu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Und ich sang: \u00bbWas mag es bedeuten doch,", "tokens": ["Und", "ich", "sang", ":", "\u00bb", "Was", "mag", "es", "be\u00b7deu\u00b7ten", "doch", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "PWS", "VMFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df ich o so traurig binne?", "tokens": ["Da\u00df", "ich", "o", "so", "trau\u00b7rig", "bin\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "FM", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein M\u00e4dchen aus alten Zeiten, ach,", "tokens": ["Ein", "M\u00e4d\u00b7chen", "aus", "al\u00b7ten", "Zei\u00b7ten", ",", "ach", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,", "ITJ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das kommt mir nicht aus dem Sinne!\u00ab", "tokens": ["Das", "kommt", "mir", "nicht", "aus", "dem", "Sin\u00b7ne", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Da fiel Herr Soherr mir eilig ins Wort:", "tokens": ["Da", "fiel", "Herr", "So\u00b7herr", "mir", "ei\u00b7lig", "ins", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbnicht ein M\u00e4dchen \u2013 ein M\u00e4rchen! sagt Heine!''", "tokens": ["\u00bb", "nicht", "ein", "M\u00e4d\u00b7chen", "\u2013", "ein", "M\u00e4r\u00b7chen", "!", "sagt", "Hei\u00b7ne", "!", "\""], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PTKNEG", "ART", "NN", "$(", "ART", "NN", "$.", "VVFIN", "NE", "$.", "$("], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und zusammenschrak ich, und mein Verstand", "tokens": ["Und", "zu\u00b7sam\u00b7men\u00b7schrak", "ich", ",", "und", "mein", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "KON", "PPOSAT", "NN"], "meter": "--+----+-+", "measure": "anapaest.init"}, "line.4": {"text": "Kam wiederum auf die Beine.", "tokens": ["Kam", "wie\u00b7de\u00b7rum", "auf", "die", "Bei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "\u00bbder Stadtkommandant, Herr Engels, der hat", "tokens": ["\u00bb", "der", "Stadt\u00b7kom\u00b7man\u00b7dant", ",", "Herr", "En\u00b7gels", ",", "der", "hat"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ART", "NN", "$,", "NN", "NE", "$,", "PRELS", "VAFIN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Macht jetzt, die materielle.", "tokens": ["Die", "Macht", "jetzt", ",", "die", "ma\u00b7te\u00b7ri\u00b7el\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PIS", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Doch Herr Joseph DuMont in K\u00f6ln, der besitzt", "tokens": ["Doch", "Herr", "Jo\u00b7se\u00b7ph", "Du\u00b7Mont", "in", "K\u00f6ln", ",", "der", "be\u00b7sitzt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "NE", "NE", "APPR", "NE", "$,", "PRELS", "VVFIN"], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die intellektuelle.", "tokens": ["Die", "in\u00b7tel\u00b7lek\u00b7tu\u00b7el\u00b7le", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Denn die K\u00f6lnische Zeitung ist einzig allein", "tokens": ["Denn", "die", "K\u00f6l\u00b7ni\u00b7sche", "Zei\u00b7tung", "ist", "ein\u00b7zig", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "ADJD", "ADV"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Der Unterdr\u00fcckung entgangen;", "tokens": ["Der", "Un\u00b7ter\u00b7dr\u00fc\u00b7ckung", "ent\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die andern Bl\u00e4tter wurden verp\u00f6nt,", "tokens": ["Die", "an\u00b7dern", "Bl\u00e4t\u00b7ter", "wur\u00b7den", "ver\u00b7p\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Gebraten, gesotten, gehangen.", "tokens": ["Ge\u00b7bra\u00b7ten", ",", "ge\u00b7sot\u00b7ten", ",", "ge\u00b7han\u00b7gen", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Die K\u00f6lnische Zeitung ward lang redigiert", "tokens": ["Die", "K\u00f6l\u00b7ni\u00b7sche", "Zei\u00b7tung", "ward", "lang", "re\u00b7di\u00b7giert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "VVFIN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Mit Rotstift und Schere, nicht ohne", "tokens": ["Mit", "Rot\u00b7stift", "und", "Sche\u00b7re", ",", "nicht", "oh\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "PTKNEG", "APPR"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Talent von der alten Frau DuMont, doch", "tokens": ["Ta\u00b7lent", "von", "der", "al\u00b7ten", "Frau", "Du\u00b7Mont", ",", "doch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "NE", "$,", "ADV"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die starb, und Joseph, dem Sohne,", "tokens": ["Die", "starb", ",", "und", "Jo\u00b7se\u00b7ph", ",", "dem", "Soh\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KON", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00dcberlie\u00df sie das h\u00fcbsche Annoncengesch\u00e4ft,", "tokens": ["\u00dc\u00b7ber\u00b7lie\u00df", "sie", "das", "h\u00fcb\u00b7sche", "An\u00b7non\u00b7cen\u00b7ge\u00b7sch\u00e4ft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und Joseph ist reich geworden", "tokens": ["Und", "Jo\u00b7se\u00b7ph", "ist", "reich", "ge\u00b7wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VAFIN", "ADJD", "VAPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "An den G\u00fctern des Gl\u00fccks und bekommt gewi\u00df", "tokens": ["An", "den", "G\u00fc\u00b7tern", "des", "Gl\u00fccks", "und", "be\u00b7kommt", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "KON", "VVFIN", "ADV"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Auch bald noch seinen Orden. \u2013", "tokens": ["Auch", "bald", "noch", "sei\u00b7nen", "Or\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Herr Joseph ist ein trefflicher Mann!", "tokens": ["Herr", "Jo\u00b7se\u00b7ph", "ist", "ein", "treff\u00b7li\u00b7cher", "Mann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Bis zur Revolution noch schrieb ich", "tokens": ["Bis", "zur", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "noch", "schrieb", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPRART", "NN", "ADV", "VVFIN", "PPER"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Unsterbliche Feuilletons f\u00fcr sein Blatt \u2013", "tokens": ["U\u00b7nsterb\u00b7li\u00b7che", "Feu\u00b7il\u00b7le\u00b7tons", "f\u00fcr", "sein", "Blatt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "+---+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und stets sein Verehrer blieb ich.", "tokens": ["Und", "stets", "sein", "Ver\u00b7eh\u00b7rer", "blieb", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Doch wie sich manche Verbindung l\u00f6st,", "tokens": ["Doch", "wie", "sich", "man\u00b7che", "Ver\u00b7bin\u00b7dung", "l\u00f6st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So ging auch unsre zu Ende,", "tokens": ["So", "ging", "auch", "uns\u00b7re", "zu", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und das Feuilleton kam in Levy, des", "tokens": ["Und", "das", "Feu\u00b7il\u00b7le\u00b7ton", "kam", "in", "Le\u00b7vy", ",", "des"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "NE", "$,", "ART"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Romantischen Schmules H\u00e4nde.", "tokens": ["Ro\u00b7man\u00b7ti\u00b7schen", "Schmu\u00b7les", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Herr Levy schmult das Feuilleton;", "tokens": ["Herr", "Le\u00b7vy", "schmult", "das", "Feu\u00b7il\u00b7le\u00b7ton", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Doch mit 'breitgeschnittener Feder'", "tokens": ["Doch", "mit", "'", "breit\u00b7ge\u00b7schnit\u00b7te\u00b7ner", "Fe\u00b7der", "'"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "$(", "ADJA", "NN", "$("], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Leitartikel Herr Br\u00fcggemann schreibt \u2013", "tokens": ["Die", "Leit\u00b7ar\u00b7ti\u00b7kel", "Herr", "Br\u00fcg\u00b7ge\u00b7mann", "schreibt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "VVFIN", "$("], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Die wei\u00df zu sch\u00e4tzen ein jeder.", "tokens": ["Die", "wei\u00df", "zu", "sch\u00e4t\u00b7zen", "ein", "je\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKZU", "VVINF", "ART", "PIS", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Herr Levy und Herr Br\u00fcggemann,", "tokens": ["Herr", "Le\u00b7vy", "und", "Herr", "Br\u00fcg\u00b7ge\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "NN", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Die schreiben mit Anstand und Sitte \u2013", "tokens": ["Die", "schrei\u00b7ben", "mit", "An\u00b7stand", "und", "Sit\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ein borstig, niedrigstirniger Kerl", "tokens": ["Ein", "bors\u00b7tig", ",", "nied\u00b7rigs\u00b7tir\u00b7ni\u00b7ger", "Kerl"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJD", "$,", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ist in dem Bunde der dritte.", "tokens": ["Ist", "in", "dem", "Bun\u00b7de", "der", "drit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "ADJA", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.12": {"line.1": {"text": "Ein Pommer zwar von Geburt, \u00fcberragt", "tokens": ["Ein", "Pom\u00b7mer", "zwar", "von", "Ge\u00b7burt", ",", "\u00fc\u00b7berr\u00b7agt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "$,", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er doch noch Herrn Wolffers, ich finde,", "tokens": ["Er", "doch", "noch", "Herrn", "Wolf\u00b7fers", ",", "ich", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "NN", "NE", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da\u00df dieser ein Belgier ist \u2013 o Gott,", "tokens": ["Da\u00df", "die\u00b7ser", "ein", "Bel\u00b7gier", "ist", "\u2013", "o", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ART", "NN", "VAFIN", "$(", "FM", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Vergib mir meine S\u00fcnde!", "tokens": ["Ver\u00b7gib", "mir", "mei\u00b7ne", "S\u00fcn\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ein Levy und ein Br\u00fcggemann,", "tokens": ["Ein", "Le\u00b7vy", "und", "ein", "Br\u00fcg\u00b7ge\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Flandre und ein Kalm\u00fccke:", "tokens": ["Ein", "Fland\u00b7re", "und", "ein", "Kal\u00b7m\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die sind's, so erleuchten die Rheinprovinz", "tokens": ["Die", "sin\u00b7d's", ",", "so", "er\u00b7leuch\u00b7ten", "die", "Rhein\u00b7pro\u00b7vinz"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NE", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit ungew\u00f6hnlichem Gl\u00fccke!", "tokens": ["Mit", "un\u00b7ge\u00b7w\u00f6hn\u00b7li\u00b7chem", "Gl\u00fc\u00b7cke", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "O Joseph, wie preis ich gl\u00fccklich dich,", "tokens": ["O", "Jo\u00b7se\u00b7ph", ",", "wie", "preis", "ich", "gl\u00fcck\u00b7lich", "dich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWAV", "NN", "PPER", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du hast, was die Erde bietet:", "tokens": ["Du", "hast", ",", "was", "die", "Er\u00b7de", "bie\u00b7tet", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du hast dir f\u00fcr dein gutes Geld", "tokens": ["Du", "hast", "dir", "f\u00fcr", "dein", "gu\u00b7tes", "Geld"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die vier besten Kerle gemietet!", "tokens": ["Die", "vier", "bes\u00b7ten", "Ker\u00b7le", "ge\u00b7mie\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.15": {"line.1": {"text": "Ja, lieber Herr Soherr, glauben Sie dreist", "tokens": ["Ja", ",", "lie\u00b7ber", "Herr", "So\u00b7herr", ",", "glau\u00b7ben", "Sie", "dreist"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "NN", "NN", "$,", "VVFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An des Vaterlandes Genesung,", "tokens": ["An", "des", "Va\u00b7ter\u00b7lan\u00b7des", "Ge\u00b7ne\u00b7sung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Solang noch die K\u00f6lnische Zeitung sprie\u00dft", "tokens": ["So\u00b7lang", "noch", "die", "K\u00f6l\u00b7ni\u00b7sche", "Zei\u00b7tung", "sprie\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Aus der allgemeinen Verwesung.", "tokens": ["Aus", "der", "all\u00b7ge\u00b7mei\u00b7nen", "Ver\u00b7we\u00b7sung", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Verwesungsr\u00fcchig noch manches Jahr", "tokens": ["Ver\u00b7we\u00b7sungs\u00b7r\u00fc\u00b7chig", "noch", "man\u00b7ches", "Jahr"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADV", "PIAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wird sie duften vom Pol zum \u00c4quator,", "tokens": ["Wird", "sie", "duf\u00b7ten", "vom", "Pol", "zum", "\u00c4\u00b7qua\u00b7tor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wenn l\u00e4ngst verschwunden Sie und ich", "tokens": ["Wenn", "l\u00e4ngst", "ver\u00b7schwun\u00b7den", "Sie", "und", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "VVFIN", "PPER", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Herr Engels, der k\u00f6ln'sche Diktator.", "tokens": ["Und", "Herr", "En\u00b7gels", ",", "der", "k\u00f6ln'\u00b7sche", "Dik\u00b7ta\u00b7tor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "$,", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.17": {"line.1": {"text": "Der Brite Coleridge roch zu K\u00f6ln", "tokens": ["Der", "Bri\u00b7te", "Co\u00b7le\u00b7rid\u00b7ge", "roch", "zu", "K\u00f6ln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An die siebzig verschiedne Ger\u00fcche;", "tokens": ["An", "die", "sieb\u00b7zig", "ver\u00b7schied\u00b7ne", "Ge\u00b7r\u00fc\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "ADJA", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Darunter gewi\u00df auch den Gestank", "tokens": ["Da\u00b7run\u00b7ter", "ge\u00b7wi\u00df", "auch", "den", "Ge\u00b7stank"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "ADV", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aus Josephs politischer K\u00fcche.\u00ab", "tokens": ["Aus", "Jo\u00b7se\u00b7phs", "po\u00b7li\u00b7ti\u00b7scher", "K\u00fc\u00b7che", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$.", "$("], "meter": "-+-+----+-", "measure": "unknown.measure.tri"}}}}}