{"textgrid.poem.41391": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mein Zimmermann, zu dem die Musen eilen,", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Zimmermann, zu dem die Musen eilen,", "tokens": ["Mein", "Zim\u00b7mer\u00b7mann", ",", "zu", "dem", "die", "Mu\u00b7sen", "ei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die unereilt den wilden Strephon fliehn!", "tokens": ["Die", "un\u00b7er\u00b7eilt", "den", "wil\u00b7den", "Stre\u00b7phon", "fliehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O lehre mich, durch wohlgepr\u00fcfte Zeilen", "tokens": ["O", "leh\u00b7re", "mich", ",", "durch", "wohl\u00b7ge\u00b7pr\u00fcf\u00b7te", "Zei\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mein sch\u00fcchtern Werk der Tadelsucht entziehn;", "tokens": ["Mein", "sch\u00fcch\u00b7tern", "Werk", "der", "Ta\u00b7del\u00b7sucht", "ent\u00b7ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Tadelsucht, die, Neidern zu gefallen,", "tokens": ["Der", "Ta\u00b7del\u00b7sucht", ",", "die", ",", "Nei\u00b7dern", "zu", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "$,", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nach Splittern sieht, nur fremde Fehler merkt,", "tokens": ["Nach", "Split\u00b7tern", "sieht", ",", "nur", "frem\u00b7de", "Feh\u00b7ler", "merkt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "In deren Ton hier auch oft Kinder lallen,", "tokens": ["In", "de\u00b7ren", "Ton", "hier", "auch", "oft", "Kin\u00b7der", "lal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "ADV", "ADV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die noch kein Mark der Wissenschaften st\u00e4rkt.", "tokens": ["Die", "noch", "kein", "Mark", "der", "Wis\u00b7sen\u00b7schaf\u00b7ten", "st\u00e4rkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sprich: Soll man nur, wie du, die Wahrheit lieben,", "tokens": ["Sprich", ":", "Soll", "man", "nur", ",", "wie", "du", ",", "die", "Wahr\u00b7heit", "lie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "VMFIN", "PIS", "ADV", "$,", "PWAV", "PPER", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(der sich mein Herz und meine Fabeln weihn)", "tokens": ["(", "der", "sich", "mein", "Herz", "und", "mei\u00b7ne", "Fa\u00b7beln", "weihn", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PRF", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dem Schmeicheln taub, und dem, was man geschrieben,", "tokens": ["Dem", "Schmei\u00b7cheln", "taub", ",", "und", "dem", ",", "was", "man", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "KON", "ART", "$,", "PRELS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit allem Ernst ein strenger Richter sein,", "tokens": ["Mit", "al\u00b7lem", "Ernst", "ein", "stren\u00b7ger", "Rich\u00b7ter", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Durch weisen Flei\u00df von Fehlern sich entfernen,", "tokens": ["Durch", "wei\u00b7sen", "Flei\u00df", "von", "Feh\u00b7lern", "sich", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Alten sich zu Mustern ausersehn,", "tokens": ["Die", "Al\u00b7ten", "sich", "zu", "Mus\u00b7tern", "au\u00b7ser\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Nachwelt scheun, und mit Horaz erlernen,", "tokens": ["Die", "Nach\u00b7welt", "scheun", ",", "und", "mit", "Ho\u00b7raz", "er\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "KON", "APPR", "NE", "VVINF", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Wie Geist und Kunst wol zu verbinden stehn?", "tokens": ["Wie", "Geist", "und", "Kunst", "wol", "zu", "ver\u00b7bin\u00b7den", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Das war genug zu jenen edlen Zeiten,", "tokens": ["Das", "war", "ge\u00b7nug", "zu", "je\u00b7nen", "ed\u00b7len", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als den Quintil die Wahrheit lehren hie\u00df,", "tokens": ["Als", "den", "Quin\u00b7til", "die", "Wahr\u00b7heit", "leh\u00b7ren", "hie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Ehrenmann, der, ohne zu verleiten,", "tokens": ["Den", "Eh\u00b7ren\u00b7mann", ",", "der", ",", "oh\u00b7ne", "zu", "ver\u00b7lei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem r\u00f6m'schen Witz die rechten Wege wies.", "tokens": ["Dem", "r\u00f6m'\u00b7schen", "Witz", "die", "rech\u00b7ten", "We\u00b7ge", "wies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein edler Geist, der aller Falschheit fluchte,", "tokens": ["Sein", "ed\u00b7ler", "Geist", ",", "der", "al\u00b7ler", "Falschheit", "fluch\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und Redlichkeit und Wissenschaft verband,", "tokens": ["Und", "Red\u00b7lich\u00b7keit", "und", "Wis\u00b7sen\u00b7schaft", "ver\u00b7band", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ersah mit Lust das Sch\u00f6ne, das er suchte,", "tokens": ["Er\u00b7sah", "mit", "Lust", "das", "Sch\u00f6\u00b7ne", ",", "das", "er", "such\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und suchte nicht die Fehler, die er fand.", "tokens": ["Und", "such\u00b7te", "nicht", "die", "Feh\u00b7ler", ",", "die", "er", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Sitzt ein Quintil im Rath der kleinen Kenner,", "tokens": ["Sitzt", "ein", "Quin\u00b7til", "im", "Rath", "der", "klei\u00b7nen", "Ken\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo man so keck den fr\u00fchen Machtspruch wagt?", "tokens": ["Wo", "man", "so", "keck", "den", "fr\u00fc\u00b7hen", "Machts\u00b7pruch", "wagt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADJD", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nein! jeder horcht im Schatten gr\u00f6\u00dfrer M\u00e4nner,", "tokens": ["Nein", "!", "je\u00b7der", "horcht", "im", "Schat\u00b7ten", "gr\u00f6\u00df\u00b7rer", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PIS", "VVFIN", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wiederholt, was man ihm vorgesagt.", "tokens": ["Und", "wie\u00b7der\u00b7holt", ",", "was", "man", "ihm", "vor\u00b7ge\u00b7sagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da richten Sie nach Stimmen, nicht nach Gr\u00fcnden,", "tokens": ["Da", "rich\u00b7ten", "Sie", "nach", "Stim\u00b7men", ",", "nicht", "nach", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie Stentor that; man folgt dem stolzen Ton.", "tokens": ["Wie", "Sten\u00b7tor", "that", ";", "man", "folgt", "dem", "stol\u00b7zen", "Ton", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "$.", "PIS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Fast jede Stadt wird einen Stentor finden,", "tokens": ["Fast", "je\u00b7de", "Stadt", "wird", "ei\u00b7nen", "Sten\u00b7tor", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Vielleicht noch mehr; und einen kennt man schon.", "tokens": ["Viel\u00b7leicht", "noch", "mehr", ";", "und", "ei\u00b7nen", "kennt", "man", "schon", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$.", "KON", "PIS", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Der hatte sich durch List und H\u00e4ndedr\u00fccken", "tokens": ["Der", "hat\u00b7te", "sich", "durch", "List", "und", "H\u00e4n\u00b7de\u00b7dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PRF", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bei Gro\u00dfen klein, bei Kleinen gro\u00df gemacht,", "tokens": ["Bei", "Gro\u00b7\u00dfen", "klein", ",", "bei", "Klei\u00b7nen", "gro\u00df", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und schien ein Mann, den, fast in allen St\u00fccken,", "tokens": ["Und", "schien", "ein", "Mann", ",", "den", ",", "fast", "in", "al\u00b7len", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ART", "$,", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Minervens Gunst mit klugem Salz bedacht.", "tokens": ["Mi\u00b7ner\u00b7vens", "Gunst", "mit", "klu\u00b7gem", "Salz", "be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Mit Celadon sang Thyrsis um die Wette;", "tokens": ["Mit", "Ce\u00b7la\u00b7don", "sang", "Thyr\u00b7sis", "um", "die", "Wet\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da sollte nun mein Stentor Schiedsmann sein.", "tokens": ["Da", "soll\u00b7te", "nun", "mein", "Sten\u00b7tor", "Schieds\u00b7mann", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der wu\u00dfte nicht, wer hier den Vorzug h\u00e4tte;", "tokens": ["Der", "wu\u00df\u00b7te", "nicht", ",", "wer", "hier", "den", "Vor\u00b7zug", "h\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "$,", "PWS", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch fiel ihm bald ein rechtes Kunstst\u00fcck ein.", "tokens": ["Doch", "fiel", "ihm", "bald", "ein", "rech\u00b7tes", "Kunst\u00b7st\u00fcck", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sein starker Mund rief gegen Fels und Kl\u00fcfte:", "tokens": ["Sein", "star\u00b7ker", "Mund", "rief", "ge\u00b7gen", "Fels", "und", "Kl\u00fcf\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ihr Kenner! sagt's: Wer tr\u00e4gt den Preis davon?", "tokens": ["Ihr", "Ken\u00b7ner", "!", "sagt's", ":", "Wer", "tr\u00e4gt", "den", "Preis", "da\u00b7von", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "$.", "PWS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ist's Celadon? Sogleich drang durch die L\u00fcfte,", "tokens": ["Ist's", "Ce\u00b7la\u00b7don", "?", "Sog\u00b7leich", "drang", "durch", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-++-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Bei jedem Ruf, ein deutlich Celadon.", "tokens": ["Bei", "je\u00b7dem", "Ruf", ",", "ein", "deut\u00b7lich", "Ce\u00b7la\u00b7don", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ART", "ADJD", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Drauf zeigt' er sich den Sch\u00e4fern l\u00e4chelnd wieder,", "tokens": ["Drauf", "zeigt'", "er", "sich", "den", "Sch\u00e4\u00b7fern", "l\u00e4\u00b7chelnd", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ART", "NN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Und schrie: Vernehmt, was keiner besser wei\u00df,", "tokens": ["Und", "schrie", ":", "Ver\u00b7nehmt", ",", "was", "kei\u00b7ner", "bes\u00b7ser", "wei\u00df", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "VVFIN", "$,", "PRELS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Was ich entdeckt, und zweifelt nicht, ihr Br\u00fcder,", "tokens": ["Was", "ich", "ent\u00b7deckt", ",", "und", "zwei\u00b7felt", "nicht", ",", "ihr", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "KON", "VVFIN", "PTKNEG", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "F\u00fcr dieses Mal hat Celadon den Preis!", "tokens": ["F\u00fcr", "die\u00b7ses", "Mal", "hat", "Ce\u00b7la\u00b7don", "den", "Preis", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Sie dankten ihm, und Stentor blieb bei Ehren.", "tokens": ["Sie", "dank\u00b7ten", "ihm", ",", "und", "Sten\u00b7tor", "blieb", "bei", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KON", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So geht es jetzt fast \u00fcberall;", "tokens": ["So", "geht", "es", "jetzt", "fast", "\u00fc\u00b7be\u00b7rall", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man glaubt Orakel anzuh\u00f6ren,", "tokens": ["Man", "glaubt", "O\u00b7ra\u00b7kel", "an\u00b7zu\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00f6rt nur einen Widerhall.", "tokens": ["Und", "h\u00f6rt", "nur", "ei\u00b7nen", "Wi\u00b7der\u00b7hall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}