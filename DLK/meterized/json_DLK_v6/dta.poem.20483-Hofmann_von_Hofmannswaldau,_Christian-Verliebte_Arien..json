{"dta.poem.20483": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Verliebte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich sehe dich zum ersten mahle/", "tokens": ["Ich", "se\u00b7he", "dich", "zum", "ers\u00b7ten", "mah\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und mu\u00df das erste mahl von dir entz\u00fcndet seyn.", "tokens": ["Und", "mu\u00df", "das", "ers\u00b7te", "mahl", "von", "dir", "ent\u00b7z\u00fcn\u00b7det", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "ADV", "APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein schwartzes auge schlug mit einem lichten strahle", "tokens": ["Dein", "schwart\u00b7zes", "au\u00b7ge", "schlug", "mit", "ei\u00b7nem", "lich\u00b7ten", "strah\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das feuer in mein hertz hinein.", "tokens": ["Das", "feu\u00b7er", "in", "mein", "hertz", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich f\u00fchle schon die glut mir ins gesichte steigen/", "tokens": ["Ich", "f\u00fch\u00b7le", "schon", "die", "glut", "mir", "ins", "ge\u00b7sich\u00b7te", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PPER", "APPRART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die flammen werden sich gar bald in augen zeigen.", "tokens": ["Die", "flam\u00b7men", "wer\u00b7den", "sich", "gar", "bald", "in", "au\u00b7gen", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VAFIN", "PRF", "ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was hab ich/ Celie/ verbrochen/", "tokens": ["Was", "hab", "ich", "/", "Ce\u00b7lie", "/", "ver\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$(", "NE", "$(", "VVPP", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df du denstarcken plitz auff mich zuerst gericht?", "tokens": ["Da\u00df", "du", "dens\u00b7tar\u00b7cken", "plitz", "auff", "mich", "zu\u00b7erst", "ge\u00b7richt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ADJD", "APPR", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und welches ist die schuld/ die du so hart gerochen?", "tokens": ["Und", "wel\u00b7ches", "ist", "die", "schuld", "/", "die", "du", "so", "hart", "ge\u00b7ro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "ADJD", "$(", "PRELS", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich wei\u00df von keiner s\u00fcnde nicht.", "tokens": ["Ich", "wei\u00df", "von", "kei\u00b7ner", "s\u00fcn\u00b7de", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "ADJA", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie? soll die straffe mir vielleicht darum geschehen/", "tokens": ["Wie", "?", "soll", "die", "straf\u00b7fe", "mir", "viel\u00b7leicht", "da\u00b7rum", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VMFIN", "ART", "VVFIN", "PPER", "ADV", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df dich/ du g\u00f6tter-bild/ ein mensch hat angesehen?", "tokens": ["Da\u00df", "dich", "/", "du", "g\u00f6t\u00b7ter\u00b7bild", "/", "ein", "mensch", "hat", "an\u00b7ge\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "PPER", "NE", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So mu\u00df ich durch den grimm verderben/", "tokens": ["So", "mu\u00df", "ich", "durch", "den", "grimm", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wofern dein strenger sinn Dianen \u00e4hnlich ist.", "tokens": ["Wo\u00b7fern", "dein", "stren\u00b7ger", "sinn", "Di\u00b7a\u00b7nen", "\u00e4hn\u00b7lich", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "NE", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Act\u00e4on sieht sie blo\u00df/ und mu\u00df de\u00dfwegen sterben;", "tokens": ["Ac\u00b7t\u00e4on", "sieht", "sie", "blo\u00df", "/", "und", "mu\u00df", "de\u00df\u00b7we\u00b7gen", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$(", "KON", "VMFIN", "PAV", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Doch weil du eine Venus bist/", "tokens": ["Doch", "weil", "du", "ei\u00b7ne", "Ve\u00b7nus", "bist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So dencke/ diese l\u00e4st mit feuer-heissen k\u00fcssen/", "tokens": ["So", "den\u00b7cke", "/", "die\u00b7se", "l\u00e4st", "mit", "feu\u00b7er\u00b7heis\u00b7sen", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "PDS", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als sie Adonis sieht/ den blick und frevel b\u00fcssen.", "tokens": ["Als", "sie", "A\u00b7do\u00b7nis", "sieht", "/", "den", "blick", "und", "fre\u00b7vel", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "$(", "ART", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer b\u00f6se zauberey getrieben/", "tokens": ["Wer", "b\u00f6\u00b7se", "zau\u00b7be\u00b7rey", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem wird das feuer sonst in rechten zuerkannt.", "tokens": ["Dem", "wird", "das", "feu\u00b7er", "sonst", "in", "rech\u00b7ten", "zu\u00b7er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich wei\u00df von solcher nichts. Ich wolte nur was lieben/", "tokens": ["Ich", "wei\u00df", "von", "sol\u00b7cher", "nichts", ".", "Ich", "wol\u00b7te", "nur", "was", "lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "PIS", "$.", "PPER", "VMFIN", "ADV", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und werde doch darum verbrannt.", "tokens": ["Und", "wer\u00b7de", "doch", "da\u00b7rum", "ver\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der richter/ welcher mich so grausam will verdammen/", "tokens": ["Der", "rich\u00b7ter", "/", "wel\u00b7cher", "mich", "so", "grau\u00b7sam", "will", "ver\u00b7dam\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWS", "PPER", "ADV", "ADJD", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Schl\u00e4gt selbst das feuer auff/ und tr\u00e4gt das holtz zusammen.", "tokens": ["Schl\u00e4gt", "selbst", "das", "feu\u00b7er", "auff", "/", "und", "tr\u00e4gt", "das", "holtz", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "$(", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ist ja dein eyffer nicht zu brechen/", "tokens": ["Ist", "ja", "dein", "eyf\u00b7fer", "nicht", "zu", "bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wann die unschuld mu\u00df vor g\u00f6ttern schuldig seyn/", "tokens": ["Und", "wann", "die", "un\u00b7schuld", "mu\u00df", "vor", "g\u00f6t\u00b7tern", "schul\u00b7dig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VMFIN", "APPR", "NN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wohlan! so will ich nicht dir/ g\u00f6ttin/ widersprechen;", "tokens": ["Wo\u00b7hlan", "!", "so", "will", "ich", "nicht", "dir", "/", "g\u00f6t\u00b7tin", "/", "wi\u00b7der\u00b7spre\u00b7chen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VMFIN", "PPER", "PTKNEG", "PPER", "$(", "NE", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich stelle mich zum urtheil ein/", "tokens": ["Ich", "stel\u00b7le", "mich", "zum", "ur\u00b7theil", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du wirst/ wie Venus that/ das blut-gerichte hegen/", "tokens": ["Du", "wirst", "/", "wie", "Ve\u00b7nus", "that", "/", "das", "blut\u00b7ge\u00b7rich\u00b7te", "he\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "KOKOM", "NN", "VVFIN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich will Adonis seyn/ und mich auffs feuer legen.", "tokens": ["Ich", "will", "A\u00b7do\u00b7nis", "seyn", "/", "und", "mich", "auffs", "feu\u00b7er", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "VAINF", "$(", "KON", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}