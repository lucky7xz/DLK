{"textgrid.poem.43042": {"metadata": {"author": {"name": "Jacoby, Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich ward von Groll und Gram verzehrt,", "genre": "verse", "period": "N.A.", "pub_year": 1867, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich ward von Groll und Gram verzehrt,", "tokens": ["Ich", "ward", "von", "Groll", "und", "Gram", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Welt schien mir verachtungswerth,", "tokens": ["Die", "Welt", "schien", "mir", "ver\u00b7ach\u00b7tungs\u00b7werth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Frauenbild hat mich bekehrt.", "tokens": ["Ein", "Frau\u00b7en\u00b7bild", "hat", "mich", "be\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da sie zuerst mein Auge sah,", "tokens": ["Da", "sie", "zu\u00b7erst", "mein", "Au\u00b7ge", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wu\u00dfte nicht, wie mir geschah,", "tokens": ["Ich", "wu\u00df\u00b7te", "nicht", ",", "wie", "mir", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus tiefstem Herzen rief ich da", "tokens": ["Aus", "tiefs\u00b7tem", "Her\u00b7zen", "rief", "ich", "da"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Halleluja!", "tokens": ["Hal\u00b7le\u00b7lu\u00b7ja", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Seitdem d\u00fcnkt mir an Gl\u00fcck so reich", "tokens": ["Seit\u00b7dem", "d\u00fcnkt", "mir", "an", "Gl\u00fcck", "so", "reich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "NN", "ADV", "ADJD"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Die Welt, getr\u00f6stet auch zugleich,", "tokens": ["Die", "Welt", ",", "ge\u00b7tr\u00f6s\u00b7tet", "auch", "zu\u00b7gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles Harte mild und weich.", "tokens": ["Und", "al\u00b7les", "Har\u00b7te", "mild", "und", "weich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich seh' den Jammer und den Schmerz,", "tokens": ["Ich", "seh'", "den", "Jam\u00b7mer", "und", "den", "Schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich seh' das Elend allerw\u00e4rts,", "tokens": ["Ich", "seh'", "das", "E\u00b7lend", "al\u00b7ler\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich wein' und dennoch ruft mein Herz", "tokens": ["Ich", "wein'", "und", "den\u00b7noch", "ruft", "mein", "Herz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Halleluja!", "tokens": ["Hal\u00b7le\u00b7lu\u00b7ja", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Mit solchem Zaubertalisman,", "tokens": ["Mit", "sol\u00b7chem", "Zau\u00b7be\u00b7rta\u00b7lis\u00b7man", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Wunder hat an mir gethan,", "tokens": ["Der", "Wun\u00b7der", "hat", "an", "mir", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Blick' ich im Leben himmelan.", "tokens": ["Blick'", "ich", "im", "Le\u00b7ben", "him\u00b7me\u00b7lan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir ist so worden hell und licht,", "tokens": ["Mir", "ist", "so", "wor\u00b7den", "hell", "und", "licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VAPP", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn jetzt im Tod mein Auge bricht,", "tokens": ["Wenn", "jetzt", "im", "Tod", "mein", "Au\u00b7ge", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPRART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich rufe doch und f\u00fcrcht' mich nicht:", "tokens": ["Ich", "ru\u00b7fe", "doch", "und", "f\u00fcrcht'", "mich", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Halleluja!", "tokens": ["Hal\u00b7le\u00b7lu\u00b7ja", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "Hier hielt der M\u00e4rchenerz\u00e4hler inne. \u2013", "tokens": ["Hier", "hielt", "der", "M\u00e4r\u00b7chen\u00b7er\u00b7z\u00e4h\u00b7ler", "in\u00b7ne", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und der Versammlung war ganz seltsam zu Sinne.", "tokens": ["Und", "der", "Ver\u00b7samm\u00b7lung", "war", "ganz", "selt\u00b7sam", "zu", "Sin\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Wie ein Windhauch im Schilf geht von Rohr zu Rohr,", "tokens": ["Wie", "ein", "Wind\u00b7hauch", "im", "Schilf", "geht", "von", "Rohr", "zu", "Rohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "So ging ein Gefl\u00fcster von Ohr zu Ohr,", "tokens": ["So", "ging", "ein", "Ge\u00b7fl\u00fcs\u00b7ter", "von", "Ohr", "zu", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Und von allen Lippen klang es da", "tokens": ["Und", "von", "al\u00b7len", "Lip\u00b7pen", "klang", "es", "da"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Unbewu\u00dft: Halleluja!", "tokens": ["Un\u00b7be\u00b7wu\u00dft", ":", "Hal\u00b7le\u00b7lu\u00b7ja", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$.", "ITJ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Erz\u00e4hler fuhr fort:", "tokens": ["Der", "Er\u00b7z\u00e4h\u00b7ler", "fuhr", "fort", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Eine Weile war's still nach diesem Lied,", "tokens": ["Ei\u00b7ne", "Wei\u00b7le", "wa\u00b7r's", "still", "nach", "die\u00b7sem", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Dann rief der erste, von Spott durchgl\u00fcht:", "tokens": ["Dann", "rief", "der", "ers\u00b7te", ",", "von", "Spott", "durch\u00b7gl\u00fcht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie kommst du mir vor?", "tokens": ["Wie", "kommst", "du", "mir", "vor", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Hat dich Amor am Ohr?", "tokens": ["Hat", "dich", "A\u00b7mor", "am", "Ohr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "APPRART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "College du,", "tokens": ["Col\u00b7le\u00b7ge", "du", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "PPER", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "O sieh doch zu,", "tokens": ["O", "sieh", "doch", "zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "O hilf ihm doch, o gro\u00dfe Noth!", "tokens": ["O", "hilf", "ihm", "doch", ",", "o", "gro\u00b7\u00dfe", "Noth", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der \u00e4rmste liebt und h\u00e4rmt sich todt.", "tokens": ["Der", "\u00e4rms\u00b7te", "liebt", "und", "h\u00e4rmt", "sich", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KON", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der zweite macht ein Grimassengesicht", "tokens": ["Der", "zwei\u00b7te", "macht", "ein", "Gri\u00b7mas\u00b7sen\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.2": {"text": "Und spricht:", "tokens": ["Und", "spricht", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Was ich ihm sagen kann, ist nicht viel.", "tokens": ["Was", "ich", "ihm", "sa\u00b7gen", "kann", ",", "ist", "nicht", "viel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "VVINF", "VMFIN", "$,", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es ist die Lieb' ein Trauerspiel,", "tokens": ["Es", "ist", "die", "Lieb'", "ein", "Trau\u00b7er\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Narrheit wundersam gepaart,", "tokens": ["Mit", "Nar\u00b7rheit", "wun\u00b7der\u00b7sam", "ge\u00b7paart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Eine Kom\u00f6die von solcher Art,", "tokens": ["Ei\u00b7ne", "Ko\u00b7m\u00f6\u00b7die", "von", "sol\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Wie der Marder den M\u00f6rder im Taubenhaus spielt,", "tokens": ["Wie", "der", "Mar\u00b7der", "den", "M\u00f6r\u00b7der", "im", "Tau\u00b7ben\u00b7haus", "spielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.8": {"text": "Wie die Katze den Liebhaber einer Maus spielt.", "tokens": ["Wie", "die", "Kat\u00b7ze", "den", "Lieb\u00b7ha\u00b7ber", "ei\u00b7ner", "Maus", "spielt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}}, "stanza.8": {"line.1": {"text": "Da rief der erste gut gelaunt", "tokens": ["Da", "rief", "der", "ers\u00b7te", "gut", "ge\u00b7launt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ganz erstaunt:", "tokens": ["Und", "ganz", "er\u00b7staunt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Hopsa, mein Held! bist du auch in Schwermuth?", "tokens": ["Hop\u00b7sa", ",", "mein", "Held", "!", "bist", "du", "auch", "in", "Schwer\u00b7muth", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$.", "VAFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Deine Worte sind ja der wahre Wermuth.", "tokens": ["Dei\u00b7ne", "Wor\u00b7te", "sind", "ja", "der", "wah\u00b7re", "Wer\u00b7muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Wie kann man so pudeln\u00e4rrisch sein?", "tokens": ["Wie", "kann", "man", "so", "pu\u00b7del\u00b7n\u00e4r\u00b7risch", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "ADV", "ADJD", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ich sage nein!", "tokens": ["Ich", "sa\u00b7ge", "nein", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKANT", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Liebe ist lieblicher denn Wein.", "tokens": ["Lie\u00b7be", "ist", "lieb\u00b7li\u00b7cher", "denn", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "KON", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Die sind es eben, die Weisheit \u00fcben,", "tokens": ["Die", "sind", "es", "e\u00b7ben", ",", "die", "Weis\u00b7heit", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Nur die leben, die da lieben.", "tokens": ["Nur", "die", "le\u00b7ben", ",", "die", "da", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVINF", "$,", "PRELS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Mit dem Spruch bin ich heiter geblieben bislang,", "tokens": ["Mit", "dem", "Spruch", "bin", "ich", "hei\u00b7ter", "ge\u00b7blie\u00b7ben", "bis\u00b7lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.11": {"text": "Und so will ich weiter lieben mein Leben lang.", "tokens": ["Und", "so", "will", "ich", "wei\u00b7ter", "lie\u00b7ben", "mein", "Le\u00b7ben", "lang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Darauf vom zweiten die Antwort klang:", "tokens": ["Da\u00b7rauf", "vom", "zwei\u00b7ten", "die", "Ant\u00b7wort", "klang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPRART", "ADJA", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bist doch noch ein kindischer Ritter,", "tokens": ["Bist", "doch", "noch", "ein", "kin\u00b7di\u00b7scher", "Rit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Kennst nicht den Spruch: Das Weib ist bitter!", "tokens": ["Kennst", "nicht", "den", "Spruch", ":", "Das", "Weib", "ist", "bit\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den sprach eine Weisheitszunge.", "tokens": ["Den", "sprach", "ei\u00b7ne", "Weis\u00b7heits\u00b7zun\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Geh' in die Schule, lieber Junge,", "tokens": ["Geh'", "in", "die", "Schu\u00b7le", ",", "lie\u00b7ber", "Jun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Lerne da,", "tokens": ["Ler\u00b7ne", "da", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Vielleicht singst du auch Halleluja.", "tokens": ["Viel\u00b7leicht", "singst", "du", "auch", "Hal\u00b7le\u00b7lu\u00b7ja", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NE", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Gott segne deine Studia!", "tokens": ["Gott", "seg\u00b7ne", "dei\u00b7ne", "Stu\u00b7dia", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Dabei legt er die H\u00e4nd' ihm auf den Kopf;", "tokens": ["Da\u00b7bei", "legt", "er", "die", "H\u00e4nd'", "ihm", "auf", "den", "Kopf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Der aber, nicht faul, fa\u00dfte jenen am Schopf,", "tokens": ["Der", "a\u00b7ber", ",", "nicht", "faul", ",", "fa\u00df\u00b7te", "je\u00b7nen", "am", "Schopf", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PTKNEG", "ADJD", "$,", "VVFIN", "PDS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Und so schnell Einer zieht ein Schwert aus der Scheide, \u2013", "tokens": ["Und", "so", "schnell", "Ei\u00b7ner", "zieht", "ein", "Schwert", "aus", "der", "Schei\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ADJD", "PIS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Pr\u00fcgelten sich beide.", "tokens": ["Pr\u00fc\u00b7gel\u00b7ten", "sich", "bei\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PRF", "PIS", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "In diesem Augenblick fuhr von der Th\u00fcr' heran", "tokens": ["In", "die\u00b7sem", "Au\u00b7gen\u00b7blick", "fuhr", "von", "der", "Th\u00fcr'", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Mann,", "tokens": ["Ein", "Mann", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ergriff die Laute von der Bank und mit klingendem Getos", "tokens": ["Er\u00b7griff", "die", "Lau\u00b7te", "von", "der", "Bank", "und", "mit", "klin\u00b7gen\u00b7dem", "Ge\u00b7tos"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Schlug er auf die sich Pr\u00fcgelnden los", "tokens": ["Schlug", "er", "auf", "die", "sich", "Pr\u00fc\u00b7geln\u00b7den", "los"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PRELS", "PRF", "NN", "PTKVZ"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Mit ritsch und ratsch,", "tokens": ["Mit", "ritsch", "und", "ratsch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Und klitsch und klatsch,", "tokens": ["Und", "klitsch", "und", "klatsch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Da\u00df die beiden auseinanderstoben im Hui und im Nu,", "tokens": ["Da\u00df", "die", "bei\u00b7den", "aus\u00b7ein\u00b7an\u00b7der\u00b7sto\u00b7ben", "im", "Hui", "und", "im", "Nu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIAT", "NN", "APPRART", "FM", "KON", "APPRART", "ADV", "$,"], "meter": "--+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Und der dritte sah ganz erschrocken zu. \u2013", "tokens": ["Und", "der", "drit\u00b7te", "sah", "ganz", "er\u00b7schro\u00b7cken", "zu", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "$("], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Das war der Lehrer,", "tokens": ["Das", "war", "der", "Leh\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Der Pr\u00fcgelbescherer,", "tokens": ["Der", "Pr\u00fc\u00b7gel\u00b7be\u00b7sche\u00b7rer", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Der seit den letzten Worten in der Th\u00fcr th\u00e4t stehn", "tokens": ["Der", "seit", "den", "letz\u00b7ten", "Wor\u00b7ten", "in", "der", "Th\u00fcr", "th\u00e4t", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von den dreien im Zimmer ungesehn.", "tokens": ["Von", "den", "drei\u00b7en", "im", "Zim\u00b7mer", "un\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "APPRART", "NN", "VVINF", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.13": {"text": "Der wischte sich jetzt, vom Schlagen noch hei\u00df,", "tokens": ["Der", "wischte", "sich", "jetzt", ",", "vom", "Schla\u00b7gen", "noch", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "$,", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.14": {"text": "Mit dem Aermel aus der Stirn den Schwei\u00df,", "tokens": ["Mit", "dem", "A\u00b7er\u00b7mel", "aus", "der", "Stirn", "den", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+----+-+", "measure": "anapaest.init"}, "line.15": {"text": "Dann", "tokens": ["Dann"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.16": {"text": "Holt er tief Athem und begann:", "tokens": ["Holt", "er", "tief", "A\u00b7them", "und", "be\u00b7gann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "KON", "VVFIN", "$."], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}}, "stanza.11": {"line.1": {"text": "O ich armer, geschlagener Mann!", "tokens": ["O", "ich", "ar\u00b7mer", ",", "ge\u00b7schla\u00b7ge\u00b7ner", "Mann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPER", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Kaum kann man drehen von hier den R\u00fccken,", "tokens": ["Kaum", "kann", "man", "dre\u00b7hen", "von", "hier", "den", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVINF", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So mu\u00df man sehen neue T\u00fccken.", "tokens": ["So", "mu\u00df", "man", "se\u00b7hen", "neu\u00b7e", "T\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVINF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Buben!", "tokens": ["Ihr", "Bu\u00b7ben", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ihr Beelzebuben!", "tokens": ["Ihr", "Beel\u00b7ze\u00b7bu\u00b7ben", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Was war's denn nun? was fuhr euch wieder", "tokens": ["Was", "wa\u00b7r's", "denn", "nun", "?", "was", "fuhr", "euch", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "$.", "PWS", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "In die Glieder,", "tokens": ["In", "die", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Da\u00df ihr euch hier die H\u00e4lse brecht?", "tokens": ["Da\u00df", "ihr", "euch", "hier", "die", "H\u00e4l\u00b7se", "brecht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Thut auf das Maul, redet, sprecht!", "tokens": ["Thut", "auf", "das", "Maul", ",", "re\u00b7det", ",", "sprecht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "Da fingen sie beide zu gleicher Zeit", "tokens": ["Da", "fin\u00b7gen", "sie", "bei\u00b7de", "zu", "glei\u00b7cher", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "An, zu erz\u00e4hlen von ihrem Streit.", "tokens": ["An", ",", "zu", "er\u00b7z\u00e4h\u00b7len", "von", "ih\u00b7rem", "Streit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "PTKZU", "VVINF", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.13": {"line.1": {"text": "Aber der Lehrer rief ganz emp\u00f6rt:", "tokens": ["A\u00b7ber", "der", "Leh\u00b7rer", "rief", "ganz", "em\u00b7p\u00f6rt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Unerh\u00f6rt!", "tokens": ["Un\u00b7er\u00b7h\u00f6rt", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wie, \u00fcber die Liebe fragt ihr euch,", "tokens": ["Wie", ",", "\u00fc\u00b7ber", "die", "Lie\u00b7be", "fragt", "ihr", "euch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und dar\u00fcber schlagt ihr euch?", "tokens": ["Und", "da\u00b7r\u00fc\u00b7ber", "schlagt", "ihr", "euch", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "O ich armer, geschlagener Mann!", "tokens": ["O", "ich", "ar\u00b7mer", ",", "ge\u00b7schla\u00b7ge\u00b7ner", "Mann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPER", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Mit solchen Buben, was f\u00e4ngt man an?", "tokens": ["Mit", "sol\u00b7chen", "Bu\u00b7ben", ",", "was", "f\u00e4ngt", "man", "an", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PWS", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ob ihr's nun gleich verdienet habt,", "tokens": ["Ob", "ih\u00b7r's", "nun", "gleich", "ver\u00b7die\u00b7net", "habt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Da\u00df ihr heut mit nichts Anderem werdet begabt,", "tokens": ["Da\u00df", "ihr", "heut", "mit", "nichts", "An\u00b7de\u00b7rem", "wer\u00b7det", "be\u00b7gabt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PIS", "PIS", "VAFIN", "ADJD", "$,"], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Als da\u00df man euch mit Pr\u00fcgel labt,", "tokens": ["Als", "da\u00df", "man", "euch", "mit", "Pr\u00fc\u00b7gel", "labt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So will ich doch sagen jetzt: Freuet euch.", "tokens": ["So", "will", "ich", "doch", "sa\u00b7gen", "jetzt", ":", "Freu\u00b7et", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVFIN", "ADV", "$.", "VVFIN", "PPER", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Und abermals sag' ich: Freuet euch.", "tokens": ["Und", "a\u00b7ber\u00b7mals", "sag'", "ich", ":", "Freu\u00b7et", "euch", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$.", "VVFIN", "PPER", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "H\u00f6ret zu, was euch soll frommen.", "tokens": ["H\u00f6\u00b7ret", "zu", ",", "was", "euch", "soll", "from\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Ihr habt gewi\u00dflich schon vernommen,", "tokens": ["Ihr", "habt", "ge\u00b7wi\u00df\u00b7lich", "schon", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Da\u00df demn\u00e4chst in die Stadt wird kommen", "tokens": ["Da\u00df", "dem\u00b7n\u00e4chst", "in", "die", "Stadt", "wird", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "VAFIN", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.15": {"text": "Vom S\u00fcden her ein f\u00fcrstliches Brautpaar.", "tokens": ["Vom", "S\u00fc\u00b7den", "her", "ein", "f\u00fcrst\u00b7li\u00b7ches", "Braut\u00b7paar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APZR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Nicht? so thu ich's euch jetzt verlautbar.", "tokens": ["Nicht", "?", "so", "thu", "ich's", "euch", "jetzt", "ver\u00b7laut\u00b7bar", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$.", "ADV", "VVFIN", "PIS", "PPER", "ADV", "ADJD", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.17": {"text": "Sie sollen von der Stadt mit Festlichkeit", "tokens": ["Sie", "sol\u00b7len", "von", "der", "Stadt", "mit", "Fest\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Empfangen werden in K\u00f6stlichkeit,", "tokens": ["Emp\u00b7fan\u00b7gen", "wer\u00b7den", "in", "K\u00f6st\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Dazu ihr drei ausersehen seid", "tokens": ["Da\u00b7zu", "ihr", "drei", "au\u00b7ser\u00b7se\u00b7hen", "seid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PPOSAT", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "Beizutragen; so macht euch bereit", "tokens": ["Bei\u00b7zu\u00b7tra\u00b7gen", ";", "so", "macht", "euch", "be\u00b7reit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$.", "ADV", "VVFIN", "PPER", "ADJD"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.21": {"text": "Zu guter Zeit.", "tokens": ["Zu", "gu\u00b7ter", "Zeit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.22": {"text": "Es wird aber ein Vetter der Braut mit ziehen ein,", "tokens": ["Es", "wird", "a\u00b7ber", "ein", "Vet\u00b7ter", "der", "Braut", "mit", "zie\u00b7hen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "APPR", "VVFIN", "PTKVZ", "$,"], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Ein Bischof, der erf\u00fcllet den Spruch gar fein:", "tokens": ["Ein", "Bi\u00b7schof", ",", "der", "er\u00b7f\u00fcl\u00b7let", "den", "Spruch", "gar", "fein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.24": {"text": "Ihre Heiligen sollen fr\u00f6hlich sein.", "tokens": ["Ih\u00b7re", "Hei\u00b7li\u00b7gen", "sol\u00b7len", "fr\u00f6h\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.25": {"text": "Es ist einer, der da liebt Scherz und Tand", "tokens": ["Es", "ist", "ei\u00b7ner", ",", "der", "da", "liebt", "Scherz", "und", "Tand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "$,", "PRELS", "ADV", "VVFIN", "NN", "KON", "NN"], "meter": "--+-+-++-+", "measure": "anapaest.init"}, "line.26": {"text": "Und dabei giebt mit Herz und Hand.", "tokens": ["Und", "da\u00b7bei", "giebt", "mit", "Herz", "und", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Vor dem sollt ihr beide zuerst, ihr Rangen,", "tokens": ["Vor", "dem", "sollt", "ihr", "bei\u00b7de", "zu\u00b7erst", ",", "ihr", "Ran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "VMFIN", "PPER", "PIS", "ADV", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.28": {"text": "In einem lustigen Wettkampf prangen,", "tokens": ["In", "ei\u00b7nem", "lus\u00b7ti\u00b7gen", "Wett\u00b7kampf", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "Mit einem Narrengespr\u00e4ch", "tokens": ["Mit", "ei\u00b7nem", "Nar\u00b7ren\u00b7ge\u00b7spr\u00e4ch"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.30": {"text": "Von echtem Gepr\u00e4g',", "tokens": ["Von", "ech\u00b7tem", "Ge\u00b7pr\u00e4g'", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.31": {"text": "Mit einem komischen Turnier,", "tokens": ["Mit", "ei\u00b7nem", "ko\u00b7mi\u00b7schen", "Tur\u00b7nier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Davon ich ein Mehres euch sage hier:", "tokens": ["Da\u00b7von", "ich", "ein", "Meh\u00b7res", "euch", "sa\u00b7ge", "hier", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ART", "PIS", "PPER", "VVFIN", "ADV", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.14": {"line.1": {"text": "Als Aufrichter und Niedermacher,", "tokens": ["Als", "Auf\u00b7rich\u00b7ter", "und", "Nie\u00b7der\u00b7ma\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Als F\u00fcrsprecher und Widersacher,", "tokens": ["Als", "F\u00fcr\u00b7spre\u00b7cher", "und", "Wi\u00b7der\u00b7sa\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Mit Rede und Gegenrede,", "tokens": ["Mit", "Re\u00b7de", "und", "Ge\u00b7gen\u00b7re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mit Fehde und Gegenfehde", "tokens": ["Mit", "Feh\u00b7de", "und", "Ge\u00b7gen\u00b7feh\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Sollt ihr mir fest im Kampf stehn beede.", "tokens": ["Sollt", "ihr", "mir", "fest", "im", "Kampf", "stehn", "bee\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADJD", "APPRART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von diesen Kampfregeln aber haltet mir jede:", "tokens": ["Von", "die\u00b7sen", "Kampf\u00b7re\u00b7geln", "a\u00b7ber", "hal\u00b7tet", "mir", "je\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "VVFIN", "PPER", "PIAT", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Um die Wahrheit sollt ihr mir nicht herumgehn", "tokens": ["Um", "die", "Wahr\u00b7heit", "sollt", "ihr", "mir", "nicht", "her\u00b7um\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und mit Schmeichelworten sollt ihr nicht umgehn;", "tokens": ["Und", "mit", "Schmei\u00b7chel\u00b7wor\u00b7ten", "sollt", "ihr", "nicht", "um\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Aber immer sei eure Rede, die scharfe,", "tokens": ["A\u00b7ber", "im\u00b7mer", "sei", "eu\u00b7re", "Re\u00b7de", ",", "die", "schar\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ein Saitenklang von einer Harfe. \u2013", "tokens": ["Ein", "Sai\u00b7ten\u00b7klang", "von", "ei\u00b7ner", "Har\u00b7fe", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Pfl\u00fcget ein Neues", "tokens": ["Pfl\u00fc\u00b7get", "ein", "Neu\u00b7es"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Und s\u00e4et nicht unter die Hecken", "tokens": ["Und", "s\u00e4et", "nicht", "un\u00b7ter", "die", "He\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Und la\u00dft euch vom richtigen Wege nicht schrecken.", "tokens": ["Und", "la\u00dft", "euch", "vom", "rich\u00b7ti\u00b7gen", "We\u00b7ge", "nicht", "schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPRART", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.16": {"line.1": {"text": "L\u00f6schet nicht, was schon erloschen", "tokens": ["L\u00f6\u00b7schet", "nicht", ",", "was", "schon", "er\u00b7lo\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$,", "PRELS", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dreschet nicht, was schon abgedroschen.", "tokens": ["Und", "dre\u00b7schet", "nicht", ",", "was", "schon", "ab\u00b7ge\u00b7dro\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nicht auf Gr\u00e4ber sollt euren Sitz ihr setzen,", "tokens": ["Nicht", "auf", "Gr\u00e4\u00b7ber", "sollt", "eu\u00b7ren", "Sitz", "ihr", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Am Lebendigen sollt euren Witz ihr wetzen,", "tokens": ["Am", "Le\u00b7ben\u00b7di\u00b7gen", "sollt", "eu\u00b7ren", "Witz", "ihr", "wet\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Allen Verst\u00e4ndigen zum Erg\u00f6tzen.", "tokens": ["Al\u00b7len", "Ver\u00b7st\u00e4n\u00b7di\u00b7gen", "zum", "Er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$."], "meter": "+--+-++-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Jach und gelinde,", "tokens": ["Jach", "und", "ge\u00b7lin\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJA", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Gemach und geschwinde", "tokens": ["Ge\u00b7mach", "und", "ge\u00b7schwin\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ADV", "KON", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Sollt ihr segeln bei gutem und schlechtem Winde.", "tokens": ["Sollt", "ihr", "se\u00b7geln", "bei", "gu\u00b7tem", "und", "schlech\u00b7tem", "Win\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Seid nicht zu plump und gradheraus;", "tokens": ["Seid", "nicht", "zu", "plump", "und", "grad\u00b7he\u00b7raus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PTKNEG", "PTKA", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nur ein T\u00f6lpel f\u00e4llt mit der Th\u00fcr ins Haus,", "tokens": ["Nur", "ein", "T\u00f6l\u00b7pel", "f\u00e4llt", "mit", "der", "Th\u00fcr", "ins", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Und sch\u00fcttet alles auf einmal aus.", "tokens": ["Und", "sch\u00fct\u00b7tet", "al\u00b7les", "auf", "ein\u00b7mal", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Dies Gleichni\u00df merkt euch f\u00fcr den Witz:", "tokens": ["Dies", "Gleich\u00b7ni\u00df", "merkt", "euch", "f\u00fcr", "den", "Witz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Was ist schneller als der Blitz,", "tokens": ["Was", "ist", "schnel\u00b7ler", "als", "der", "Blitz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Und doch durchl\u00e4uft er seine Pfade", "tokens": ["Und", "doch", "durch\u00b7l\u00e4uft", "er", "sei\u00b7ne", "Pfa\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Im Zickzack und nicht gerade.", "tokens": ["Im", "Zick\u00b7zack", "und", "nicht", "ge\u00b7ra\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "PTKNEG", "ADV", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Ging' er gradewegs so eilig,", "tokens": ["Ging'", "er", "gra\u00b7de\u00b7wegs", "so", "ei\u00b7lig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "W\u00fcrd' er langweilig.", "tokens": ["W\u00fcrd'", "er", "lang\u00b7wei\u00b7lig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.17": {"line.1": {"text": "Von seltenen Spr\u00fcchen werd' euer Schatz nie leer:", "tokens": ["Von", "sel\u00b7te\u00b7nen", "Spr\u00fc\u00b7chen", "werd'", "eu\u00b7er", "Schatz", "nie", "leer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Denn der Weise theilt aus und hat immer mehr,", "tokens": ["Denn", "der", "Wei\u00b7se", "theilt", "aus", "und", "hat", "im\u00b7mer", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "KON", "VAFIN", "ADV", "ADV", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Thor aber karget und wird immer \u00e4rmer.", "tokens": ["Der", "Thor", "a\u00b7ber", "kar\u00b7get", "und", "wird", "im\u00b7mer", "\u00e4r\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Thut kund vor aller Welt euer Thorheitsbekenntni\u00df", "tokens": ["Thut", "kund", "vor", "al\u00b7ler", "Welt", "eu\u00b7er", "Thor\u00b7heits\u00b7be\u00b7kennt\u00b7ni\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "APPR", "PIAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und eures Narrenthums Eingest\u00e4ndni\u00df,", "tokens": ["Und", "eu\u00b7res", "Nar\u00b7ren\u00b7thums", "Ein\u00b7ge\u00b7st\u00e4nd\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und doch mu\u00df euer Narrenduett unisono", "tokens": ["Und", "doch", "mu\u00df", "eu\u00b7er", "Nar\u00b7ren\u00b7du\u00b7ett", "u\u00b7ni\u00b7so\u00b7no"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPOSAT", "NN", "NE"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Uebereinstimmen an Weisheit so,", "tokens": ["Ue\u00b7be\u00b7re\u00b7in\u00b7stim\u00b7men", "an", "Weis\u00b7heit", "so", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ADV", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Als ob da spr\u00e4che frei und froh", "tokens": ["Als", "ob", "da", "spr\u00e4\u00b7che", "frei", "und", "froh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "ADV", "VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die K\u00f6nigin Saba mit Salomo.", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7gin", "Sa\u00b7ba", "mit", "Sa\u00b7lo\u00b7mo", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Es entbehre der kostbaren Fr\u00fcchte nimmer;", "tokens": ["Es", "ent\u00b7beh\u00b7re", "der", "kost\u00b7ba\u00b7ren", "Fr\u00fcch\u00b7te", "nim\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Von diesen aber gebet, weil doch immer", "tokens": ["Von", "die\u00b7sen", "a\u00b7ber", "ge\u00b7bet", ",", "weil", "doch", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADV", "VVFIN", "$,", "KOUS", "ADV", "ADV"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "F\u00fcr die einen ist verloren, was die andern haben gern,", "tokens": ["F\u00fcr", "die", "ei\u00b7nen", "ist", "ver\u00b7lo\u00b7ren", ",", "was", "die", "an\u00b7dern", "ha\u00b7ben", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "VAFIN", "VVPP", "$,", "PRELS", "ART", "ADJA", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Die Schaalen f\u00fcr die Thoren, f\u00fcr die Klugen den Kern.", "tokens": ["Die", "Schaa\u00b7len", "f\u00fcr", "die", "Tho\u00b7ren", ",", "f\u00fcr", "die", "Klu\u00b7gen", "den", "Kern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Den N\u00e4rrischen mu\u00df es blo\u00df Klingklang bedeuten,", "tokens": ["Den", "N\u00e4r\u00b7ri\u00b7schen", "mu\u00df", "es", "blo\u00df", "Kling\u00b7klang", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.6": {"text": "In Wahrheit aber ein Glockenl\u00e4uten,", "tokens": ["In", "Wahr\u00b7heit", "a\u00b7ber", "ein", "Glo\u00b7cken\u00b7l\u00e4u\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Das zum Gebet die Gedanken ruft der Gescheuten. \u2013", "tokens": ["Das", "zum", "Ge\u00b7bet", "die", "Ge\u00b7dan\u00b7ken", "ruft", "der", "Ge\u00b7scheu\u00b7ten", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "APPRART", "NN", "ART", "NN", "VVFIN", "ART", "NN", "$.", "$("], "meter": "--+---+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "An F\u00fclle des Klanges sei euer Werk", "tokens": ["An", "F\u00fcl\u00b7le", "des", "Klan\u00b7ges", "sei", "eu\u00b7er", "Werk"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ein blitzendes, flimmerndes Feuerwerk,", "tokens": ["Ein", "blit\u00b7zen\u00b7des", ",", "flim\u00b7mern\u00b7des", "Feu\u00b7er\u00b7werk", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wo die Reime wie strahlende Sterne sich zeigen", "tokens": ["Wo", "die", "Rei\u00b7me", "wie", "strah\u00b7len\u00b7de", "Ster\u00b7ne", "sich", "zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "KOKOM", "ADJA", "NN", "PRF", "VVINF"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Und die Witze auf als Raketen steigen,", "tokens": ["Und", "die", "Wit\u00b7ze", "auf", "als", "Ra\u00b7ke\u00b7ten", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "KOUS", "NN", "VVINF", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Da\u00df alle Umstehenden euer Lob posaunen,", "tokens": ["Da\u00df", "al\u00b7le", "Um\u00b7ste\u00b7hen\u00b7den", "eu\u00b7er", "Lob", "po\u00b7sau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Und alle es Sehenden stehen und staunen.", "tokens": ["Und", "al\u00b7le", "es", "Se\u00b7hen\u00b7den", "ste\u00b7hen", "und", "stau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PPER", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "Aber habt mir wohl Acht, da\u00df euer jeder Witz,", "tokens": ["A\u00b7ber", "habt", "mir", "wohl", "Acht", ",", "da\u00df", "eu\u00b7er", "je\u00b7der", "Witz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "CARD", "$,", "KOUS", "PPOSAT", "PIAT", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "So scharf wie spitz,", "tokens": ["So", "scharf", "wie", "spitz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "NE", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Sei zu etwas n\u00fctz;", "tokens": ["Sei", "zu", "et\u00b7was", "n\u00fctz", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "PIS", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.10": {"text": "Und so das Ganze sei vielhaltig,", "tokens": ["Und", "so", "das", "Gan\u00b7ze", "sei", "viel\u00b7hal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Vielgestaltig", "tokens": ["Viel\u00b7ge\u00b7stal\u00b7tig"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+-+-", "measure": "trochaic.di"}, "line.12": {"text": "Und mannigfaltig,", "tokens": ["Und", "man\u00b7nig\u00b7fal\u00b7tig", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Im Aeu\u00dfern bunt,", "tokens": ["Im", "A\u00b7e\u00b7u\u00b7\u00dfern", "bunt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Im Innern gesund,", "tokens": ["Im", "In\u00b7nern", "ge\u00b7sund", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "An Gedanken bl\u00fchend", "tokens": ["An", "Ge\u00b7dan\u00b7ken", "bl\u00fc\u00b7hend"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "Und Funken spr\u00fchend", "tokens": ["Und", "Fun\u00b7ken", "spr\u00fc\u00b7hend"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "VVPP"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Und beredt und behende", "tokens": ["Und", "be\u00b7redt", "und", "be\u00b7hen\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJA"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.18": {"text": "Von Anfang bis Ende.", "tokens": ["Von", "An\u00b7fang", "bis", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.20": {"line.1": {"text": "Nun lasset mich euch noch ein W\u00f6rtlein sagen,", "tokens": ["Nun", "las\u00b7set", "mich", "euch", "noch", "ein", "W\u00f6rt\u00b7lein", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das sollt ihr tief im Herzen tragen:", "tokens": ["Das", "sollt", "ihr", "tief", "im", "Her\u00b7zen", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich hab' aufgeschlossen euch klar und hell", "tokens": ["Ich", "hab'", "auf\u00b7ge\u00b7schlos\u00b7sen", "euch", "klar", "und", "hell"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Der deutschen Sprachkunst Wunderquell,", "tokens": ["Der", "deut\u00b7schen", "Sprach\u00b7kunst", "Wun\u00b7der\u00b7quell", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ihr nun daraus sch\u00f6pfet mit vollen Kr\u00fcgen", "tokens": ["Da\u00df", "ihr", "nun", "da\u00b7raus", "sch\u00f6p\u00b7fet", "mit", "vol\u00b7len", "Kr\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PAV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Und trinket daraus in vollen Z\u00fcgen.", "tokens": ["Und", "trin\u00b7ket", "da\u00b7raus", "in", "vol\u00b7len", "Z\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Aber ihr sollt mir davon keinen Mi\u00dfbrauch machen,", "tokens": ["A\u00b7ber", "ihr", "sollt", "mir", "da\u00b7von", "kei\u00b7nen", "Mi\u00df\u00b7brauch", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PAV", "PIAT", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Sondern nur einen Nie\u00dfbrauch machen,", "tokens": ["Son\u00b7dern", "nur", "ei\u00b7nen", "Nie\u00df\u00b7brauch", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Um die bittere Wahrheit s\u00fc\u00df zu machen", "tokens": ["Um", "die", "bit\u00b7te\u00b7re", "Wahr\u00b7heit", "s\u00fc\u00df", "zu", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "ADJA", "NN", "ADJD", "PTKZU", "VVINF"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Und den H\u00f6rern zur Freude, zum Jubel und Lachen.", "tokens": ["Und", "den", "H\u00f6\u00b7rern", "zur", "Freu\u00b7de", ",", "zum", "Ju\u00b7bel", "und", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "$,", "APPRART", "NN", "KON", "NN", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.11": {"text": "Ich kann zu euch sagen was ein Spr\u00fcchlein spricht:", "tokens": ["Ich", "kann", "zu", "euch", "sa\u00b7gen", "was", "ein", "Spr\u00fcch\u00b7lein", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "VVINF", "PWS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Gold und Silber hab' ich nicht,", "tokens": ["Gold", "und", "Sil\u00b7ber", "hab'", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Was ich aber habe, das gab ich euch.", "tokens": ["Was", "ich", "a\u00b7ber", "ha\u00b7be", ",", "das", "gab", "ich", "euch", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$,", "PDS", "VVFIN", "PPER", "PPER", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Bewahret es wohl, so seid ihr reich,", "tokens": ["Be\u00b7wah\u00b7ret", "es", "wohl", ",", "so", "seid", "ihr", "reich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "So habet ihr einen Hochgenu\u00df,", "tokens": ["So", "ha\u00b7bet", "ihr", "ei\u00b7nen", "Hoch\u00b7ge\u00b7nu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Den der h\u00f6chste im Land' euch neiden mu\u00df. \u2013", "tokens": ["Den", "der", "h\u00f6chs\u00b7te", "im", "Land'", "euch", "nei\u00b7den", "mu\u00df", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ART", "ADJA", "APPRART", "NN", "PPER", "VVINF", "VMFIN", "$.", "$("], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.21": {"line.1": {"text": "Drauf wendet er sich dem dritten zu:", "tokens": ["Drauf", "wen\u00b7det", "er", "sich", "dem", "drit\u00b7ten", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aber du,", "tokens": ["A\u00b7ber", "du", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Der sich selbst h\u00e4lt f\u00fcr auserlesen,", "tokens": ["Der", "sich", "selbst", "h\u00e4lt", "f\u00fcr", "au\u00b7ser\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "VVFIN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dessen Lehrer ich nicht gewesen,", "tokens": ["Des\u00b7sen", "Leh\u00b7rer", "ich", "nicht", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPER", "PTKNEG", "VAPP", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Du Tr\u00e4umer!", "tokens": ["Du", "Tr\u00e4u\u00b7mer", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Du S\u00e4umer!", "tokens": ["Du", "S\u00e4u\u00b7mer", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Was sinnst du?", "tokens": ["Was", "sinnst", "du", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Was spinnst du?", "tokens": ["Was", "spinnst", "du", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Und was beginnst du?", "tokens": ["Und", "was", "be\u00b7ginnst", "du", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Ueber welch R\u00e4tsel denkst du nach?", "tokens": ["Ue\u00b7ber", "welch", "R\u00e4t\u00b7sel", "denkst", "du", "nach", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Liegst du brach,", "tokens": ["Liegst", "du", "brach", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "So will ich Aussaat stecken in deinen Acker,", "tokens": ["So", "will", "ich", "Aus\u00b7saat", "ste\u00b7cken", "in", "dei\u00b7nen", "A\u00b7cker", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Schl\u00e4fst du, so will ich dich wecken wacker.", "tokens": ["Schl\u00e4fst", "du", ",", "so", "will", "ich", "dich", "we\u00b7cken", "wa\u00b7cker", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.22": {"line.1": {"text": "Der sah ihn an. \u2013", "tokens": ["Der", "sah", "ihn", "an", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.23": {"line.1": {"text": "Der Lehrer wandte die Augen ab", "tokens": ["Der", "Leh\u00b7rer", "wand\u00b7te", "die", "Au\u00b7gen", "ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und fuhr fort.", "tokens": ["Und", "fuhr", "fort", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "H\u00f6r' dies Wort:", "tokens": ["H\u00f6r'", "dies", "Wort", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.24": {"line.1": {"text": "Willst du in der Dichtkunst sein ein Prinz,", "tokens": ["Willst", "du", "in", "der", "Dicht\u00b7kunst", "sein", "ein", "Prinz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "PPOSAT", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und nicht wie die andern ein Kunz und Hinz,", "tokens": ["Und", "nicht", "wie", "die", "an\u00b7dern", "ein", "Kunz", "und", "Hinz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "KOKOM", "ART", "ADJA", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Deinen Voraus-Anspruch verbanne ihn,", "tokens": ["Dei\u00b7nen", "Vor\u00b7aus\u00b7An\u00b7spruch", "ver\u00b7ban\u00b7ne", "ihn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Hier ist der Bogen, spanne ihn.", "tokens": ["Hier", "ist", "der", "Bo\u00b7gen", ",", "span\u00b7ne", "ihn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wirst du treffen, so wollen wir glauben", "tokens": ["Wirst", "du", "tref\u00b7fen", ",", "so", "wol\u00b7len", "wir", "glau\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVINF", "$,", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Und werden dir deinen Ruhm nicht rauben.", "tokens": ["Und", "wer\u00b7den", "dir", "dei\u00b7nen", "Ruhm", "nicht", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Horch aber auf,", "tokens": ["Horch", "a\u00b7ber", "auf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Es steht dir ein hoher Preis zu Kauf.", "tokens": ["Es", "steht", "dir", "ein", "ho\u00b7her", "Preis", "zu", "Kauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wenn da wird zu schaun sein und zu sehn", "tokens": ["Wenn", "da", "wird", "zu", "schaun", "sein", "und", "zu", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "VAFIN", "PTKA", "ADJD", "VAINF", "KON", "PTKZU", "VVINF"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Welches ist herrlich, k\u00f6stlich, lieblich und sch\u00f6n,", "tokens": ["Wel\u00b7ches", "ist", "herr\u00b7lich", ",", "k\u00f6st\u00b7lich", ",", "lieb\u00b7lich", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.11": {"text": "Wenn das Volk einem Erw\u00e4hlten wird entgegengehn", "tokens": ["Wenn", "das", "Volk", "ei\u00b7nem", "Er\u00b7w\u00e4hl\u00b7ten", "wird", "ent\u00b7ge\u00b7gen\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VAFIN", "VVINF"], "meter": "--++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Mit Pauken, mit Freuden und mit Geigen,", "tokens": ["Mit", "Pau\u00b7ken", ",", "mit", "Freu\u00b7den", "und", "mit", "Gei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Dann sollst du dich zeigen", "tokens": ["Dann", "sollst", "du", "dich", "zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.14": {"text": "Mit einem Lied, das loben soll des Spruches Wahl:", "tokens": ["Mit", "ei\u00b7nem", "Lied", ",", "das", "lo\u00b7ben", "soll", "des", "Spru\u00b7ches", "Wahl", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PDS", "VVINF", "VMFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie ein Rubin in seinem Golde leuchtet,", "tokens": ["Wie", "ein", "Ru\u00b7bin", "in", "sei\u00b7nem", "Gol\u00b7de", "leuch\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Also ziert ein Gesang das Mahl.", "tokens": ["Al\u00b7so", "ziert", "ein", "Ge\u00b7sang", "das", "Mahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.17": {"text": "F\u00fcr die Ausf\u00fchrung geb' ich dir dies Verm\u00e4chtni\u00df,", "tokens": ["F\u00fcr", "die", "Aus\u00b7f\u00fch\u00b7rung", "geb'", "ich", "dir", "dies", "Ver\u00b7m\u00e4cht\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "PDS", "NN", "$,"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Pr\u00e4g' es tief in dein Ged\u00e4chtni\u00df:", "tokens": ["Pr\u00e4g'", "es", "tief", "in", "dein", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Was dein Gem\u00fcth erf\u00fcllt, das klage!", "tokens": ["Was", "dein", "Ge\u00b7m\u00fcth", "er\u00b7f\u00fcllt", ",", "das", "kla\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$,", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was aus dem Herzen quillt das sage! \u2013", "tokens": ["Was", "aus", "dem", "Her\u00b7zen", "quillt", "das", "sa\u00b7ge", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "PDS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Echt und gewichtig,", "tokens": ["Echt", "und", "ge\u00b7wich\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Recht und richtig", "tokens": ["Recht", "und", "rich\u00b7tig"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "ADJD"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Mu\u00df dein Sang sein und nicht nichtig.", "tokens": ["Mu\u00df", "dein", "Sang", "sein", "und", "nicht", "nich\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VAINF", "KON", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das Weltall mu\u00df darinnen wehn,", "tokens": ["Das", "Wel\u00b7tall", "mu\u00df", "da\u00b7rin\u00b7nen", "wehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und jede Zeile zum Ganzen stehn", "tokens": ["Und", "je\u00b7de", "Zei\u00b7le", "zum", "Gan\u00b7zen", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wie im Weizenfeld ein gef\u00fcllter Halm,", "tokens": ["Wie", "im", "Wei\u00b7zen\u00b7feld", "ein", "ge\u00b7f\u00fcll\u00b7ter", "Halm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Wie im Psalter ein Psalm.", "tokens": ["Wie", "im", "Psal\u00b7ter", "ein", "Psalm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Und das Ganze mu\u00df sein ein Vorw\u00e4rtssto\u00df,", "tokens": ["Und", "das", "Gan\u00b7ze", "mu\u00df", "sein", "ein", "Vor\u00b7w\u00e4rts\u00b7sto\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "PPOSAT", "ART", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.11": {"text": "Eine neue Welt bergend in seinem Schoo\u00df,", "tokens": ["Ei\u00b7ne", "neu\u00b7e", "Welt", "ber\u00b7gend", "in", "sei\u00b7nem", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "In Form, in Inhalt tadellos", "tokens": ["In", "Form", ",", "in", "In\u00b7halt", "ta\u00b7del\u00b7los"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und an Adel gro\u00df,", "tokens": ["Und", "an", "A\u00b7del", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Trostreich tief, klar und klingend,", "tokens": ["Trost\u00b7reich", "tief", ",", "klar", "und", "klin\u00b7gend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "ADJD", "KON", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.15": {"text": "Wahr und gleich ins Herze dringend,", "tokens": ["Wahr", "und", "gleich", "ins", "Her\u00b7ze", "drin\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "APPRART", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "So wird nachhaltig", "tokens": ["So", "wird", "nach\u00b7hal\u00b7tig"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Seine Wirkung sein und gewaltig.", "tokens": ["Sei\u00b7ne", "Wir\u00b7kung", "sein", "und", "ge\u00b7wal\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAINF", "KON", "ADJD", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.18": {"text": "Und was du so willst wagen,", "tokens": ["Und", "was", "du", "so", "willst", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Ernst froh willst sagen,", "tokens": ["Ernst", "froh", "willst", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.20": {"text": "Es ist dir schon vorgesagt von der Natur,", "tokens": ["Es", "ist", "dir", "schon", "vor\u00b7ge\u00b7sagt", "von", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Find' es nur! \u2013", "tokens": ["Find'", "es", "nur", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.22": {"text": "Dann faltet er die H\u00e4nde und betet and\u00e4chtig,", "tokens": ["Dann", "fal\u00b7tet", "er", "die", "H\u00e4n\u00b7de", "und", "be\u00b7tet", "an\u00b7d\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Seufzend aus tiefstem Innern und m\u00e4chtig:", "tokens": ["Seuf\u00b7zend", "aus", "tiefs\u00b7tem", "In\u00b7nern", "und", "m\u00e4ch\u00b7tig", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "KON", "ADJD", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.24": {"text": "O du himmlischer Vater, und all ihr Heiligen!", "tokens": ["O", "du", "himm\u00b7li\u00b7scher", "Va\u00b7ter", ",", "und", "all", "ihr", "Hei\u00b7li\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$,", "KON", "PIAT", "PPOSAT", "NN", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.25": {"text": "O wollet euch gn\u00e4dig an dem Werke betheiligen", "tokens": ["O", "wol\u00b7let", "euch", "gn\u00e4\u00b7dig", "an", "dem", "Wer\u00b7ke", "be\u00b7thei\u00b7li\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VVINF"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und lasset doch die verdammten Rangen", "tokens": ["Und", "las\u00b7set", "doch", "die", "ver\u00b7damm\u00b7ten", "Ran\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Einmal zu etwas Gutem gelangen,", "tokens": ["Ein\u00b7mal", "zu", "et\u00b7was", "Gu\u00b7tem", "ge\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "+----+--+-", "measure": "trochaic.tri.relaxed"}, "line.28": {"text": "Davon auch f\u00fcr uns was her sich schreib'", "tokens": ["Da\u00b7von", "auch", "f\u00fcr", "uns", "was", "her", "sich", "schreib'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "APPR", "PPER", "PIS", "APZR", "PRF", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.29": {"text": "Und \u00fcbrig bleib',", "tokens": ["Und", "\u00fcb\u00b7rig", "bleib'", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.30": {"text": "Auf da\u00df man die Sorgen von sich treib'", "tokens": ["Auf", "da\u00df", "man", "die", "Sor\u00b7gen", "von", "sich", "treib'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PIS", "ART", "NN", "APPR", "PRF", "VVFIN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.31": {"text": "Und st\u00e4rken k\u00f6nne seinen s\u00fcndigen Leib.", "tokens": ["Und", "st\u00e4r\u00b7ken", "k\u00f6n\u00b7ne", "sei\u00b7nen", "s\u00fcn\u00b7di\u00b7gen", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.26": {"line.1": {"text": "Vor allen Dingen aber bitt' ich dich, Herr, befrei' uns", "tokens": ["Vor", "al\u00b7len", "Din\u00b7gen", "a\u00b7ber", "bitt'", "ich", "dich", ",", "Herr", ",", "be\u00b7frei'", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVFIN", "PPER", "PRF", "$,", "NN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von dem phrasenspr\u00fchenden Gottseibeiuns,", "tokens": ["Von", "dem", "phra\u00b7sen\u00b7spr\u00fc\u00b7hen\u00b7den", "Got\u00b7tsei\u00b7bei\u00b7uns", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Der da ist hungrig bei uns gestern wie heute,", "tokens": ["Der", "da", "ist", "hung\u00b7rig", "bei", "uns", "ge\u00b7stern", "wie", "heu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "ADJD", "APPR", "PPER", "ADV", "KOKOM", "ADV", "$,"], "meter": "--+---+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Der da fri\u00dft Vieh und Volk und Land und Leute", "tokens": ["Der", "da", "fri\u00dft", "Vieh", "und", "Volk", "und", "Land", "und", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "NN", "KON", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mit Disteln und mit D\u00f6rnern,", "tokens": ["Mit", "Dis\u00b7teln", "und", "mit", "D\u00f6r\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Mit Haut und Haar und H\u00f6rnern.", "tokens": ["Mit", "Haut", "und", "Haar", "und", "H\u00f6r\u00b7nern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wollest du bald doch, o Herr, mit seinem ganzen", "tokens": ["Wol\u00b7lest", "du", "bald", "doch", ",", "o", "Herr", ",", "mit", "sei\u00b7nem", "gan\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "$,", "FM", "NN", "$,", "APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Pack von Modenamen und Schranzen", "tokens": ["Pack", "von", "Mo\u00b7de\u00b7na\u00b7men", "und", "Schran\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Einen gedeihlichen Kehraus tanzen,", "tokens": ["Ei\u00b7nen", "ge\u00b7deih\u00b7li\u00b7chen", "Ke\u00b7hraus", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Oder uns in Gnaden das Amt gew\u00e4hren,", "tokens": ["O\u00b7der", "uns", "in", "Gna\u00b7den", "das", "Amt", "ge\u00b7w\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ART", "NN", "VVINF", "$,"], "meter": "----+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Mit gutem Besen sie auszukehren,", "tokens": ["Mit", "gu\u00b7tem", "Be\u00b7sen", "sie", "aus\u00b7zu\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVIZU", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Da\u00df sie schreien Zeter und Mordio,", "tokens": ["Da\u00df", "sie", "schrei\u00b7en", "Ze\u00b7ter", "und", "Mor\u00b7dio", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "KON", "NE", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.13": {"text": "Drob werden sein die Engel im Himmel froh.", "tokens": ["Drob", "wer\u00b7den", "sein", "die", "En\u00b7gel", "im", "Him\u00b7mel", "froh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "ART", "NN", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Sie h\u00e4ngen ja zusammen mit ihren Weihrauchketten", "tokens": ["Sie", "h\u00e4n\u00b7gen", "ja", "zu\u00b7sam\u00b7men", "mit", "ih\u00b7ren", "Weih\u00b7rauch\u00b7ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Wie die Kletten.", "tokens": ["Wie", "die", "Klet\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.16": {"text": "Wie lange noch sollen wir uns gedulden,", "tokens": ["Wie", "lan\u00b7ge", "noch", "sol\u00b7len", "wir", "uns", "ge\u00b7dul\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.17": {"text": "Ihnen heimzuzahlen ihre Schulden?", "tokens": ["Ih\u00b7nen", "heim\u00b7zu\u00b7zah\u00b7len", "ih\u00b7re", "Schul\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.18": {"text": "Sieht man die Verblendung, die sie f\u00fchren herbei,", "tokens": ["Sieht", "man", "die", "Ver\u00b7blen\u00b7dung", ",", "die", "sie", "f\u00fch\u00b7ren", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.19": {"text": "Es fri\u00dft einem schier das Herz entzwei,", "tokens": ["Es", "fri\u00dft", "ei\u00b7nem", "schier", "das", "Herz", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "Und der trotzigste Mann mu\u00df schluchzen und weinen,", "tokens": ["Und", "der", "trot\u00b7zigs\u00b7te", "Mann", "mu\u00df", "schluch\u00b7zen", "und", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VMFIN", "VVINF", "KON", "VVINF", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.21": {"text": "Als wie man ein Erz schmilzt aus Steinen.", "tokens": ["Als", "wie", "man", "ein", "Erz", "schmilzt", "aus", "Stei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "PIS", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.27": {"line.1": {"text": "So sprach er und ging,", "tokens": ["So", "sprach", "er", "und", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Und seine Bewegung war nicht gering,", "tokens": ["Und", "sei\u00b7ne", "Be\u00b7we\u00b7gung", "war", "nicht", "ge\u00b7ring", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und Thr\u00e4nen rannen ihm, wie er sprach,", "tokens": ["Und", "Thr\u00e4\u00b7nen", "ran\u00b7nen", "ihm", ",", "wie", "er", "sprach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und alle drei sahen ihm verwundert nach.", "tokens": ["Und", "al\u00b7le", "drei", "sa\u00b7hen", "ihm", "ver\u00b7wun\u00b7dert", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "CARD", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.28": {"line.1": {"text": "Der Erz\u00e4hler schwieg. \u2013", "tokens": ["Der", "Er\u00b7z\u00e4h\u00b7ler", "schwieg", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.29": {"line.1": {"text": "Da erhob sich im Saal ein Gesumm und Gesause,", "tokens": ["Da", "er\u00b7hob", "sich", "im", "Saal", "ein", "Ge\u00b7summ", "und", "Ge\u00b7sau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPRART", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Ein Gebrumm und Gebrause", "tokens": ["Ein", "Ge\u00b7brumm", "und", "Ge\u00b7brau\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Wie bei den Schulkindern in der Pause.", "tokens": ["Wie", "bei", "den", "Schul\u00b7kin\u00b7dern", "in", "der", "Pau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Ein Jeder zischelt dem Nachbar leis", "tokens": ["Ein", "Je\u00b7der", "zi\u00b7schelt", "dem", "Nach\u00b7bar", "leis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sein Urtheil zu, so Tadel wie Preis.", "tokens": ["Sein", "Ur\u00b7theil", "zu", ",", "so", "Ta\u00b7del", "wie", "Preis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "ADV", "NN", "KOKOM", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Der Schah auf dem Throne sinnend sa\u00df", "tokens": ["Der", "Schah", "auf", "dem", "Thro\u00b7ne", "sin\u00b7nend", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und schier weiter zu rauchen verga\u00df.", "tokens": ["Und", "schier", "wei\u00b7ter", "zu", "rau\u00b7chen", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.30": {"line.1": {"text": "Und es war D\u00e4mmerung geworden innen.", "tokens": ["Und", "es", "war", "D\u00e4m\u00b7me\u00b7rung", "ge\u00b7wor\u00b7den", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "VAPP", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Eine Schaar von Dienern und Dienerinnen", "tokens": ["Ei\u00b7ne", "Schaar", "von", "Die\u00b7nern", "und", "Die\u00b7ne\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Eilten gesch\u00e4ftig und z\u00fcndeten dann", "tokens": ["Eil\u00b7ten", "ge\u00b7sch\u00e4f\u00b7tig", "und", "z\u00fcn\u00b7de\u00b7ten", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "KON", "VVFIN", "ADV"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Die krystallenen Kronleuchter an.", "tokens": ["Die", "krys\u00b7tal\u00b7le\u00b7nen", "Kron\u00b7leuch\u00b7ter", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.31": {"line.1": {"text": "Wie nun die Kerzen im Saale niederstrahlen", "tokens": ["Wie", "nun", "die", "Ker\u00b7zen", "im", "Saa\u00b7le", "nie\u00b7der\u00b7strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und in allen Spiegeln ihr Flammenbild malen,", "tokens": ["Und", "in", "al\u00b7len", "Spie\u00b7geln", "ihr", "Flam\u00b7men\u00b7bild", "ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da ward Thee gereicht und Scherbet in Schaalen.", "tokens": ["Da", "ward", "Thee", "ge\u00b7reicht", "und", "Scher\u00b7bet", "in", "Schaa\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "VVPP", "KON", "NN", "APPR", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Erz\u00e4hler aber, w\u00e4hrend er schl\u00fcrfte den Trank,", "tokens": ["Der", "Er\u00b7z\u00e4h\u00b7ler", "a\u00b7ber", ",", "w\u00e4h\u00b7rend", "er", "schl\u00fcrf\u00b7te", "den", "Trank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Lie\u00df seinen Blick streifen den Saal entlang,", "tokens": ["Lie\u00df", "sei\u00b7nen", "Blick", "strei\u00b7fen", "den", "Saal", "ent\u00b7lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Bis er haften blieb auf der Wandmalerei,", "tokens": ["Bis", "er", "haf\u00b7ten", "blieb", "auf", "der", "Wand\u00b7ma\u00b7le\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Wo Schah Abbas empf\u00e4ngt Abdul-Mumin-Bey,", "tokens": ["Wo", "Schah", "Ab\u00b7bas", "emp\u00b7f\u00e4ngt", "Ab\u00b7dul\u00b7Mu\u00b7mi\u00b7nBey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "Wo sich ein gl\u00e4nzendes Bild des Hofstaats breitet,", "tokens": ["Wo", "sich", "ein", "gl\u00e4n\u00b7zen\u00b7des", "Bild", "des", "Hof\u00b7staats", "brei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und der Narr auf einem H\u00f6fling reitet. \u2013", "tokens": ["Und", "der", "Narr", "auf", "ei\u00b7nem", "H\u00f6f\u00b7ling", "rei\u00b7tet", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.32": {"line.1": {"text": "Dann in die Vorhalle zur\u00fcck", "tokens": ["Dann", "in", "die", "Vor\u00b7hal\u00b7le", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Ging sein Blick,", "tokens": ["Ging", "sein", "Blick", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wo er dem Murmeln der Springbrunnen lauscht,", "tokens": ["Wo", "er", "dem", "Mur\u00b7meln", "der", "Spring\u00b7brun\u00b7nen", "lauscht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Das leis wie ein Regen rieselt und rauscht.", "tokens": ["Das", "leis", "wie", "ein", "Re\u00b7gen", "rie\u00b7selt", "und", "rauscht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "KOKOM", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Aber dazwischen", "tokens": ["A\u00b7ber", "da\u00b7zwi\u00b7schen"], "token_info": ["word", "word"], "pos": ["KON", "PAV"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "H\u00f6rt er's t\u00f6nen aus den Gartenb\u00fcschen,", "tokens": ["H\u00f6rt", "er's", "t\u00f6\u00b7nen", "aus", "den", "Gar\u00b7ten\u00b7b\u00fc\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Wo Vogelstimmen klangen", "tokens": ["Wo", "Vo\u00b7gel\u00b7stim\u00b7men", "klan\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und s\u00fc\u00dfe S\u00e4nger sangen", "tokens": ["Und", "s\u00fc\u00b7\u00dfe", "S\u00e4n\u00b7ger", "san\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Und durch die Fenster drangen der Nachtigall Klagen,", "tokens": ["Und", "durch", "die", "Fens\u00b7ter", "dran\u00b7gen", "der", "Nach\u00b7ti\u00b7gall", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Auf den Wogen des Wohllauts hereingetragen.", "tokens": ["Auf", "den", "Wo\u00b7gen", "des", "Wohl\u00b7lauts", "her\u00b7ein\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.33": {"line.1": {"text": "Der Schah auch trank und nickte dann,", "tokens": ["Der", "Schah", "auch", "trank", "und", "nick\u00b7te", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und der Erz\u00e4hler den Faden weiter spann.", "tokens": ["Und", "der", "Er\u00b7z\u00e4h\u00b7ler", "den", "Fa\u00b7den", "wei\u00b7ter", "spann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "---+--+-+-+", "measure": "iambic.tetra.relaxed"}}}}}