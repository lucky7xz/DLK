{"textgrid.poem.42461": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Erinnerst du dich der Tage:", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Erinnerst du dich der Tage:", "tokens": ["E\u00b7rin\u00b7nerst", "du", "dich", "der", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinter dir sa\u00dfen", "tokens": ["Hin\u00b7ter", "dir", "sa\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Conrad, der H\u00fcne, und ich.", "tokens": ["Con\u00b7rad", ",", "der", "H\u00fc\u00b7ne", ",", "und", "ich", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "KON", "PPER", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Du sangst uns", "tokens": ["Du", "sangst", "uns"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Deine 53,", "tokens": ["Dei\u00b7ne", "53", ","], "token_info": ["word", "number", "punct"], "pos": ["PPOSAT", "CARD", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Drei\u2013und\u2013f\u00fcnf\u2013zig!", "tokens": ["Drei", "\u2013", "und", "\u2013", "f\u00fcnf", "\u2013", "zig", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["CARD", "$(", "KON", "$(", "CARD", "$(", "NE", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "M\u00f6rike-Lieder vor", "tokens": ["M\u00f6\u00b7ri\u00b7ke\u00b7Lie\u00b7der", "vor"], "token_info": ["word", "word"], "pos": ["NN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Und deine ungez\u00e4hlten Wunderweisen", "tokens": ["Und", "dei\u00b7ne", "un\u00b7ge\u00b7z\u00e4hl\u00b7ten", "Wun\u00b7der\u00b7wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Aus Goethe und Eichendorff.", "tokens": ["Aus", "Goe\u00b7the", "und", "Ei\u00b7chen\u00b7dorff", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Wie war das Alles neu!", "tokens": ["Wie", "war", "das", "Al\u00b7les", "neu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "PIS", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Zum Erstarren neu!", "tokens": ["Zum", "Er\u00b7star\u00b7ren", "neu", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.12": {"text": "Vorn im M\u00f6rike-Heft,", "tokens": ["Vorn", "im", "M\u00f6\u00b7ri\u00b7ke\u00b7Heft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Auf erster Seite,", "tokens": ["Auf", "ers\u00b7ter", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "Hattest du, Bescheidener,", "tokens": ["Hat\u00b7test", "du", ",", "Be\u00b7schei\u00b7de\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "NN", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.15": {"text": "Des Dichters Bild verehrend aufgestellt.", "tokens": ["Des", "Dich\u00b7ters", "Bild", "ver\u00b7eh\u00b7rend", "auf\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Welcher Tonsetzer that je so?", "tokens": ["Wel\u00b7cher", "Ton\u00b7set\u00b7zer", "that", "je", "so", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Und w\u00e4hrend du gl\u00fchend sangst,", "tokens": ["Und", "w\u00e4h\u00b7rend", "du", "gl\u00fc\u00b7hend", "sangst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Gingen drau\u00dfen die Deutschen vor\u00fcber.", "tokens": ["Gin\u00b7gen", "drau\u00b7\u00dfen", "die", "Deut\u00b7schen", "vor\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Sie trugen in ihren Taschen", "tokens": ["Sie", "tru\u00b7gen", "in", "ih\u00b7ren", "Ta\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Billete zu \u00bbMamsell Nitouche\u00ab.", "tokens": ["Bil\u00b7le\u00b7te", "zu", "\u00bb", "Mam\u00b7sell", "Ni\u00b7tou\u00b7che", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "PTKZU", "$(", "NN", "NN", "$(", "$."], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.5": {"text": "Und die Schamr\u00f6te flog mir in's Gesicht", "tokens": ["Und", "die", "Scham\u00b7r\u00f6\u00b7te", "flog", "mir", "in's", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "F\u00fcr unsre Landsleute,", "tokens": ["F\u00fcr", "uns\u00b7re", "Lands\u00b7leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Da\u00df sie dir nicht horchten;", "tokens": ["Da\u00df", "sie", "dir", "nicht", "horch\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Da\u00df sie ihren gro\u00dfen, lieben", "tokens": ["Da\u00df", "sie", "ih\u00b7ren", "gro\u00b7\u00dfen", ",", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Dichter M\u00f6rike nicht kennen.", "tokens": ["Dich\u00b7ter", "M\u00f6\u00b7ri\u00b7ke", "nicht", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wir erhoben uns.", "tokens": ["Wir", "er\u00b7ho\u00b7ben", "uns", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Auf der Stra\u00dfe", "tokens": ["Auf", "der", "Stra\u00b7\u00dfe"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Nahm Conrad, der H\u00fcne, dich", "tokens": ["Nahm", "Con\u00b7rad", ",", "der", "H\u00fc\u00b7ne", ",", "dich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "NE", "$,", "ART", "NN", "$,", "PPER"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Auf seine Athletenschultern,", "tokens": ["Auf", "sei\u00b7ne", "Ath\u00b7le\u00b7ten\u00b7schul\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und trug dich durch die Menge,", "tokens": ["Und", "trug", "dich", "durch", "die", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wie einst der heilige Christoph das Jesulein", "tokens": ["Wie", "einst", "der", "hei\u00b7li\u00b7ge", "Chris\u00b7toph", "das", "Je\u00b7su\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch das tosende Wildwasser brachte.", "tokens": ["Durch", "das", "to\u00b7sen\u00b7de", "Wild\u00b7was\u00b7ser", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Einer Spielzeugt\u00e4ndlerin", "tokens": ["Ei\u00b7ner", "Spiel\u00b7zeug\u00b7t\u00e4nd\u00b7le\u00b7rin"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Kauft' ich ein F\u00e4hnchen ab.", "tokens": ["Kauft'", "ich", "ein", "F\u00e4hn\u00b7chen", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Und das F\u00e4hnchen wuchs schnell", "tokens": ["Und", "das", "F\u00e4hn\u00b7chen", "wuchs", "schnell"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "Zur m\u00e4chtigen prunkenden Fahne.", "tokens": ["Zur", "m\u00e4ch\u00b7ti\u00b7gen", "prun\u00b7ken\u00b7den", "Fah\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.12": {"text": "Einem Fl\u00f6tenbl\u00e4ser winkt' ich,", "tokens": ["Ei\u00b7nem", "Fl\u00f6\u00b7ten\u00b7bl\u00e4\u00b7ser", "winkt'", "ich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Der einsam im Kinderkreise blies;", "tokens": ["Der", "ein\u00b7sam", "im", "Kin\u00b7der\u00b7krei\u00b7se", "blies", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Und er kam und ging mit:", "tokens": ["Und", "er", "kam", "und", "ging", "mit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.15": {"text": "Duidldidum, duidldidum.", "tokens": ["Duidl\u00b7di\u00b7dum", ",", "duidl\u00b7di\u00b7dum", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "FM.la", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.16": {"text": "Einem Zinkenisten winkt' ich", "tokens": ["Ei\u00b7nem", "Zin\u00b7ke\u00b7nis\u00b7ten", "winkt'", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Aus einer Gassenmusik;", "tokens": ["Aus", "ei\u00b7ner", "Gas\u00b7sen\u00b7mu\u00b7sik", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.18": {"text": "Und er kam und ging mit:", "tokens": ["Und", "er", "kam", "und", "ging", "mit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.19": {"text": "Tatara ta, Tatara ta.", "tokens": ["Ta\u00b7ta\u00b7ra", "ta", ",", "Ta\u00b7ta\u00b7ra", "ta", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Einem Beckenschl\u00e4ger winkt' ich,", "tokens": ["Ei\u00b7nem", "Be\u00b7cken\u00b7schl\u00e4\u00b7ger", "winkt'", "ich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Der einem B\u00e4renzeiger gesellt stand;", "tokens": ["Der", "ei\u00b7nem", "B\u00e4\u00b7ren\u00b7zei\u00b7ger", "ge\u00b7sellt", "stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Und er kam und ging mit:", "tokens": ["Und", "er", "kam", "und", "ging", "mit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.23": {"text": "Dschingdada, Dschingdada.", "tokens": ["Dsching\u00b7da\u00b7da", ",", "Dsching\u00b7da\u00b7da", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Die drei machten Bocksspr\u00fcnge, w\u00e4hrend sie spielten,", "tokens": ["Die", "drei", "mach\u00b7ten", "Bocks\u00b7spr\u00fcn\u00b7ge", ",", "w\u00e4h\u00b7rend", "sie", "spiel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "VVFIN", "NE", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.25": {"text": "Und tanzten wie trunkene Derwische.", "tokens": ["Und", "tanz\u00b7ten", "wie", "trun\u00b7ke\u00b7ne", "Der\u00b7wi\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ADJA", "NN", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.26": {"text": "Vor dem Zuge schwang ich", "tokens": ["Vor", "dem", "Zu\u00b7ge", "schwang", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.27": {"text": "Die m\u00e4chtige Prunkfahne hin und her,", "tokens": ["Die", "m\u00e4ch\u00b7ti\u00b7ge", "Prunk\u00b7fah\u00b7ne", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Und ich rief:", "tokens": ["Und", "ich", "rief", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.29": {"text": "Platz da, Platz da, Gesindel,", "tokens": ["Platz", "da", ",", "Platz", "da", ",", "Ge\u00b7sin\u00b7del", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "NN", "PTKVZ", "$,", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.30": {"text": "Ein junger Germanenk\u00f6nig kommt,", "tokens": ["Ein", "jun\u00b7ger", "Ger\u00b7ma\u00b7nen\u00b7k\u00f6\u00b7nig", "kommt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "Ein K\u00f6nig der neuen Kunst!", "tokens": ["Ein", "K\u00f6\u00b7nig", "der", "neu\u00b7en", "Kunst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.32": {"text": "Platz da, Platz da, Gesindel,", "tokens": ["Platz", "da", ",", "Platz", "da", ",", "Ge\u00b7sin\u00b7del", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "NN", "PTKVZ", "$,", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.33": {"text": "Ein K\u00f6nig kommt!", "tokens": ["Ein", "K\u00f6\u00b7nig", "kommt", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.34": {"text": "Und die Deutschen", "tokens": ["Und", "die", "Deut\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.35": {"text": "Griffen entsetzt in ihre Taschen", "tokens": ["Grif\u00b7fen", "ent\u00b7setzt", "in", "ih\u00b7re", "Ta\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.36": {"text": "Und f\u00fchlten nach den Billeten", "tokens": ["Und", "f\u00fchl\u00b7ten", "nach", "den", "Bil\u00b7le\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.37": {"text": "Zu \u00bbMamsell Nitouche\u00ab.", "tokens": ["Zu", "\u00bb", "Mam\u00b7sell", "Ni\u00b7tou\u00b7che", "\u00ab", "."], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "$(", "NN", "NN", "$(", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.38": {"text": "Und sie rannten schleunig", "tokens": ["Und", "sie", "rann\u00b7ten", "schleu\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.39": {"text": "Zu \u00bbMamsell Nitouche\u00ab.", "tokens": ["Zu", "\u00bb", "Mam\u00b7sell", "Ni\u00b7tou\u00b7che", "\u00ab", "."], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "$(", "NN", "NN", "$(", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}