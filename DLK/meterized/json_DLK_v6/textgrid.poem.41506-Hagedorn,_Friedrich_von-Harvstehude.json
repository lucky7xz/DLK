{"textgrid.poem.41506": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Harvstehude", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin ein Freund der Klosterl\u00e4nder,", "tokens": ["Ich", "bin", "ein", "Freund", "der", "Klos\u00b7ter\u00b7l\u00e4n\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und g\u00f6nn' und w\u00fcnsch' insonderheit", "tokens": ["Und", "g\u00f6nn'", "und", "w\u00fcn\u00b7sch'", "in\u00b7son\u00b7der\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den rechten Kern der Segenspf\u00e4nder", "tokens": ["Den", "rech\u00b7ten", "Kern", "der", "Se\u00b7gen\u00b7spf\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der j\u00fcngferlichen Geistlichkeit.", "tokens": ["Der", "j\u00fcng\u00b7fer\u00b7li\u00b7chen", "Geist\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was Heilige f\u00fcr sich verwalten,", "tokens": ["Was", "Hei\u00b7li\u00b7ge", "f\u00fcr", "sich", "ver\u00b7wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "APPR", "PRF", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Das kann, das wird, das mu\u00df gedeihn,", "tokens": ["Das", "kann", ",", "das", "wird", ",", "das", "mu\u00df", "ge\u00b7deihn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "PDS", "VAFIN", "$,", "PDS", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und frommer Schwestern Wohlverhalten", "tokens": ["Und", "from\u00b7mer", "Schwes\u00b7tern", "Wohl\u00b7ver\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sollt' immer reich an Pfr\u00fcnden sein.", "tokens": ["Sollt'", "im\u00b7mer", "reich", "an", "Pfr\u00fcn\u00b7den", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ihr edlen Johanniterinnen,", "tokens": ["Ihr", "ed\u00b7len", "Jo\u00b7han\u00b7ni\u00b7te\u00b7rin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Euch str\u00f6men Gut und Ehre zu;", "tokens": ["Euch", "str\u00f6\u00b7men", "Gut", "und", "Eh\u00b7re", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr seid ein Muster keuscher Sinnen", "tokens": ["Ihr", "seid", "ein", "Mus\u00b7ter", "keu\u00b7scher", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In Harvstehudens sichrer Ruh'.", "tokens": ["In", "Harv\u00b7ste\u00b7hu\u00b7dens", "sich\u00b7rer", "Ruh'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie selten h\u00f6ret ihr die Klagen", "tokens": ["Wie", "sel\u00b7ten", "h\u00f6\u00b7ret", "ihr", "die", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der buhlerischen Schmeichelei!", "tokens": ["Der", "buh\u00b7le\u00b7ri\u00b7schen", "Schmei\u00b7che\u00b7lei", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Euch dr\u00fccken keine Landesplagen,", "tokens": ["Euch", "dr\u00fc\u00b7cken", "kei\u00b7ne", "Lan\u00b7des\u00b7pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Kein Alp und keine Ketzerei.", "tokens": ["Kein", "Alp", "und", "kei\u00b7ne", "Ket\u00b7ze\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nichts ist so sch\u00f6n als Harvstehude,", "tokens": ["Nichts", "ist", "so", "sch\u00f6n", "als", "Harv\u00b7ste\u00b7hu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und darum ist es Eurer werth,", "tokens": ["Und", "da\u00b7rum", "ist", "es", "Eu\u00b7rer", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PPER", "PPOSAT", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo auch der allerk\u00e4rgste Jude", "tokens": ["Wo", "auch", "der", "al\u00b7ler\u00b7k\u00e4rgs\u00b7te", "Ju\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den Silberling mit Muth verzehrt.", "tokens": ["Den", "Sil\u00b7ber\u00b7ling", "mit", "Muth", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das schw\u00f6r' ich bei der alten Linde,", "tokens": ["Das", "schw\u00f6r'", "ich", "bei", "der", "al\u00b7ten", "Lin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In der so mancher Vogel heckt,", "tokens": ["In", "der", "so", "man\u00b7cher", "Vo\u00b7gel", "heckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die gegen wilde Wirbelwinde", "tokens": ["Die", "ge\u00b7gen", "wil\u00b7de", "Wir\u00b7bel\u00b7win\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit neunundneunzig Aesten deckt.", "tokens": ["Mit", "neun\u00b7und\u00b7neun\u00b7zig", "A\u00b7es\u00b7ten", "deckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Hier gehet in gew\u00f6lbten L\u00fcften", "tokens": ["Hier", "ge\u00b7het", "in", "ge\u00b7w\u00f6lb\u00b7ten", "L\u00fcf\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonne recht gef\u00e4llig auf,", "tokens": ["Die", "Son\u00b7ne", "recht", "ge\u00b7f\u00e4l\u00b7lig", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lachet den bebl\u00fcmten Triften,", "tokens": ["Und", "la\u00b7chet", "den", "be\u00b7bl\u00fcm\u00b7ten", "Trif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sieht mit Lust der Alster Lauf.", "tokens": ["Und", "sieht", "mit", "Lust", "der", "Als\u00b7ter", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Oft taucht sich hier ein sch\u00f6ner Schwimmer", "tokens": ["Oft", "taucht", "sich", "hier", "ein", "sch\u00f6\u00b7ner", "Schwim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In ihrer Strahlen Wiederschein,", "tokens": ["In", "ih\u00b7rer", "Strah\u00b7len", "Wie\u00b7der\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und oftmals hei\u00dft ihr erster Schimmer", "tokens": ["Und", "oft\u00b7mals", "hei\u00dft", "ihr", "ers\u00b7ter", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sogar die Thiere fr\u00f6hlich sein.", "tokens": ["So\u00b7gar", "die", "Thie\u00b7re", "fr\u00f6h\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wir steigen bei den schlanken Weiden", "tokens": ["Wir", "stei\u00b7gen", "bei", "den", "schlan\u00b7ken", "Wei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Arch' und Nachen an den Strand,", "tokens": ["Aus", "Ar\u00b7ch'", "und", "Na\u00b7chen", "an", "den", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und dann begleitet unsre Freuden", "tokens": ["Und", "dann", "be\u00b7glei\u00b7tet", "uns\u00b7re", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lenz oder Sommer auf das Land.", "tokens": ["Lenz", "o\u00b7der", "Som\u00b7mer", "auf", "das", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Flugs k\u00f6mmt der aufmerksame Toppe", "tokens": ["Flugs", "k\u00f6mmt", "der", "auf\u00b7merk\u00b7sa\u00b7me", "Top\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So freundlich und so tiefgeneigt,", "tokens": ["So", "freund\u00b7lich", "und", "so", "tief\u00b7ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als an dem Boberflu\u00df ein Stoppe", "tokens": ["Als", "an", "dem", "Bo\u00b7berf\u00b7lu\u00df", "ein", "Stop\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den S\u00e4ttler guten Freunden zeigt.", "tokens": ["Den", "S\u00e4tt\u00b7ler", "gu\u00b7ten", "Freun\u00b7den", "zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Er selber siehet mit Erg\u00f6tzen,", "tokens": ["Er", "sel\u00b7ber", "sie\u00b7het", "mit", "Er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df diese Gegend uns gef\u00e4llt,", "tokens": ["Da\u00df", "die\u00b7se", "Ge\u00b7gend", "uns", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und gibt uns von den besten Sch\u00e4tzen,", "tokens": ["Und", "gibt", "uns", "von", "den", "bes\u00b7ten", "Sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die seines Kellers Kluft enth\u00e4lt.", "tokens": ["Die", "sei\u00b7nes", "Kel\u00b7lers", "Kluft", "ent\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er spricht fast, wie Achill gesprochen:", "tokens": ["Er", "spricht", "fast", ",", "wie", "A\u00b7chill", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "NE", "VVPP", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Herr Phoenix, Ajax und Uly\u00df ...", "tokens": ["Herr", "Phoe\u00b7nix", ",", "A\u00b7jax", "und", "U\u00b7ly\u00df", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "NE", "KON", "NE", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Die Herren setzen sich ... wir kochen,", "tokens": ["Die", "Her\u00b7ren", "set\u00b7zen", "sich", "...", "wir", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$(", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und reiner Wein erfolgt gewi\u00df.", "tokens": ["Und", "rei\u00b7ner", "Wein", "er\u00b7folgt", "ge\u00b7wi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wo findet man so gute Wirthe,", "tokens": ["Wo", "fin\u00b7det", "man", "so", "gu\u00b7te", "Wirt\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als an den Helden jener Zeit?", "tokens": ["Als", "an", "den", "Hel\u00b7den", "je\u00b7ner", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wann sich ein Wandersmann verirrte,", "tokens": ["Wann", "sich", "ein", "Wan\u00b7ders\u00b7mann", "ver\u00b7irr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So stand f\u00fcr ihn ihr Haus bereit.", "tokens": ["So", "stand", "f\u00fcr", "ihn", "ihr", "Haus", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hier folgt man t\u00e4glich dem Exempel", "tokens": ["Hier", "folgt", "man", "t\u00e4g\u00b7lich", "dem", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und tr\u00e4nkt und speiset jeden Gast,", "tokens": ["Und", "tr\u00e4nkt", "und", "spei\u00b7set", "je\u00b7den", "Gast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und uns macht diesen Comustempel", "tokens": ["Und", "uns", "macht", "die\u00b7sen", "Co\u00b7mus\u00b7tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PDAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Auch ein Cornaro nicht verha\u00dft.", "tokens": ["Auch", "ein", "Cor\u00b7na\u00b7ro", "nicht", "ver\u00b7ha\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Man \u00fcbet hier auf freier Wiese", "tokens": ["Man", "\u00fc\u00b7bet", "hier", "auf", "frei\u00b7er", "Wie\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bald das Gesicht, bald den Geschmack;", "tokens": ["Bald", "das", "Ge\u00b7sicht", ",", "bald", "den", "Ge\u00b7schmack", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Oft schallt hier bis zur Zirbeldr\u00fcse", "tokens": ["Oft", "schallt", "hier", "bis", "zur", "Zir\u00b7bel\u00b7dr\u00fc\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein auserles'ner Dudelsack:", "tokens": ["Ein", "aus\u00b7er\u00b7les'\u00b7ner", "Du\u00b7del\u00b7sack", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und weil auch f\u00fcr gelehrte M\u00e4nner", "tokens": ["Und", "weil", "auch", "f\u00fcr", "ge\u00b7lehr\u00b7te", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Thorweg schuldigst offen steht,", "tokens": ["Der", "Thor\u00b7weg", "schul\u00b7digst", "of\u00b7fen", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So kommen hier die Funkenkenner", "tokens": ["So", "kom\u00b7men", "hier", "die", "Fun\u00b7ken\u00b7ken\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und sehn die Elektricit\u00e4t.", "tokens": ["Und", "sehn", "die", "E\u00b7lek\u00b7tri\u00b7ci\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Vielleicht wird jetzt mein Lied gerathen;", "tokens": ["Viel\u00b7leicht", "wird", "jetzt", "mein", "Lied", "ge\u00b7ra\u00b7then", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein neuer Anblick gibt ihm Kraft:", "tokens": ["Ein", "neu\u00b7er", "An\u00b7blick", "gibt", "ihm", "Kraft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der H\u00fcgel der Licentiaten,", "tokens": ["Der", "H\u00fc\u00b7gel", "der", "Li\u00b7cen\u00b7ti\u00b7a\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Landung einer Hauptmannschaft.", "tokens": ["Die", "Lan\u00b7dung", "ei\u00b7ner", "Haupt\u00b7mann\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch wie? Ein Schw\u00e4tzer k\u00f6mmt gegangen,", "tokens": ["Doch", "wie", "?", "Ein", "Schw\u00e4t\u00b7zer", "k\u00f6mmt", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$.", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Lust und Einfall unterbricht.", "tokens": ["Der", "Lust", "und", "Ein\u00b7fall", "un\u00b7ter\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O h\u00e4tt' ich nur nicht angefangen!", "tokens": ["O", "h\u00e4tt'", "ich", "nur", "nicht", "an\u00b7ge\u00b7fan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Genug! Ich dichte weiter nicht.", "tokens": ["Ge\u00b7nug", "!", "Ich", "dich\u00b7te", "wei\u00b7ter", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}