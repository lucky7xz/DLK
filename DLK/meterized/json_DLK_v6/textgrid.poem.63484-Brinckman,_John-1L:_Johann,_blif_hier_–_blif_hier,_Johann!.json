{"textgrid.poem.63484": {"metadata": {"author": {"name": "Brinckman, John", "birth": "N.A.", "death": "N.A."}, "title": "1L: Johann, blif hier \u2013 blif hier, Johann!", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Johann, blif hier \u2013 blif hier, Johann!", "tokens": ["Jo\u00b7hann", ",", "blif", "hier", "\u2013", "blif", "hier", ",", "Jo\u00b7hann", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ADV", "$(", "VVFIN", "ADV", "$,", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Wat wist du in Amerika!", "tokens": ["Wat", "wist", "du", "in", "A\u00b7me\u00b7ri\u00b7ka", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Blif hier, wenn ick di raden kann;", "tokens": ["Blif", "hier", ",", "wenn", "ick", "di", "ra\u00b7den", "kann", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KOUS", "PPER", "NE", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "besinn di doch un denk eens nah!", "tokens": ["be\u00b7sinn", "di", "doch", "un", "denk", "e\u00b7ens", "nah", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "ADV", "FM", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Du seggst, di h\u00f6lt nu keen Spann Pir,", "tokens": ["Du", "seggst", ",", "di", "h\u00f6lt", "nu", "ke\u00b7en", "Spann", "Pir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "VVFIN", "ADV", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "noch v\u00f6r de Aust denn schall dat furt:", "tokens": ["noch", "v\u00f6r", "de", "Aust", "denn", "schall", "dat", "furt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NE", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "denn dat's doch hier all nicks nich mihr \u2013", "tokens": ["denn", "dat's", "doch", "hier", "all", "nicks", "nich", "mihr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "ADV", "PIAT", "PIS", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Amerika, dat is de Urt!", "tokens": ["A\u00b7me\u00b7ri\u00b7ka", ",", "dat", "is", "de", "Urt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM.nl", "FM.nl", "FM.nl", "FM.nl", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Du seggst, dat du hier racken m\u00f6st", "tokens": ["Du", "seggst", ",", "dat", "du", "hier", "ra\u00b7cken", "m\u00f6st"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "un slawen m\u00f6st, Johr in Johr ut \u2013", "tokens": ["un", "sla\u00b7wen", "m\u00f6st", ",", "Johr", "in", "Johr", "ut", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dat in dat D\u00f6rp keen Pird du weest,", "tokens": ["dat", "in", "dat", "D\u00f6rp", "ke\u00b7en", "Pird", "du", "weest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "ART", "NN", "VVFIN", "NE", "PPER", "VVFIN", "$,"], "meter": "+-----+-+", "measure": "dactylic.init"}, "line.4": {"text": "sau lat noch ran, sau tidig rut;", "tokens": ["sau", "lat", "noch", "ran", ",", "sau", "ti\u00b7dig", "rut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "PTKVZ", "$,", "ADJD", "ADJD", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "wat du ok in dei S\u00e4len liggst,", "tokens": ["wat", "du", "ok", "in", "dei", "S\u00e4\u00b7len", "liggst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "di afmarachst un an di spannst \u2013", "tokens": ["di", "af\u00b7ma\u00b7rachst", "un", "an", "di", "spannst", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "wer weet, wennihr du H\u00fcsung kriggst,", "tokens": ["wer", "weet", ",", "wen\u00b7nihr", "du", "H\u00fc\u00b7sung", "kriggst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wer weet, wennihr du frigen kannst.", "tokens": ["wer", "weet", ",", "wen\u00b7nihr", "du", "fri\u00b7gen", "kannst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Weet Gott, dat du dat suer hest!", "tokens": ["Weet", "Gott", ",", "dat", "du", "dat", "su\u00b7er", "hest", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dat is woll wohr, dat is woll wi\u00df;", "tokens": ["Dat", "is", "woll", "wohr", ",", "dat", "is", "woll", "wi\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "ADV", "ADJD", "$,", "ART", "FM", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch hest du ok dat Allerbest:", "tokens": ["doch", "hest", "du", "ok", "dat", "Al\u00b7ler\u00b7best", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gesundheit, de von Isen is.", "tokens": ["Ge\u00b7sund\u00b7heit", ",", "de", "von", "I\u00b7sen", "is", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "APPR", "NE", "FM", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Een ihrlich Blaut hest du dorbi,", "tokens": ["E\u00b7en", "ihr\u00b7lich", "Blaut", "hest", "du", "dor\u00b7bi", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "----+-++-", "measure": "unknown.measure.tri"}, "line.6": {"text": "un ihrlich hett noch nie verdarwt \u2013", "tokens": ["un", "ihr\u00b7lich", "hett", "noch", "nie", "ver\u00b7darwt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "un noch up eens verlat du di:", "tokens": ["un", "noch", "up", "e\u00b7ens", "ver\u00b7lat", "du", "di", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "ADV", "NE", "NE", "VVFIN", "PPER", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "dei G\u00e4us gaht allerw\u00e4gen barft.", "tokens": ["dei", "G\u00e4us", "gaht", "al\u00b7ler\u00b7w\u00e4\u00b7gen", "barft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Un wer man will, un wer man mag,", "tokens": ["Un", "wer", "man", "will", ",", "un", "wer", "man", "mag", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWS", "PIS", "VMFIN", "$,", "FM", "PWS", "PIS", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "de sleiht sick ok bi uns noch d\u00f6rch,", "tokens": ["de", "sleiht", "sick", "ok", "bi", "uns", "noch", "d\u00f6rch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "PPER", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "de k\u00fcmmt ok \u0153wer'n legsten Dag", "tokens": ["de", "k\u00fcmmt", "ok", "\u0153wer'n", "legs\u00b7ten", "Dag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "woll weg in oll Land M\u00e4kelb\u00f6rg;", "tokens": ["woll", "weg", "in", "oll", "Land", "M\u00e4\u00b7kel\u00b7b\u00f6rg", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJD", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "de brukt nich in de wide Welt", "tokens": ["de", "brukt", "nich", "in", "de", "wi\u00b7de", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG", "APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "un in dat Blag' irst rin tau gahn \u2013", "tokens": ["un", "in", "dat", "Blag'", "irst", "rin", "tau", "gahn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wenn he sin Sak man schicklich stellt,", "tokens": ["wenn", "he", "sin", "Sak", "man", "schick\u00b7lich", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "FM", "FM", "FM", "PIS", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "blifft up sin Been ok hier he stahn!", "tokens": ["blifft", "up", "sin", "Be\u00b7en", "ok", "hier", "he", "stahn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Un geiht't nich all sau, as dat schall", "tokens": ["Un", "geiht't", "nich", "all", "sau", ",", "as", "dat", "schall"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG", "PIAT", "ADJD", "$,", "NE", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "un as du m\u00fcchst \u2013 k\u00fcmmt Tit, k\u00fcmmt Rat.", "tokens": ["un", "as", "du", "m\u00fcchst", "\u2013", "k\u00fcmmt", "Tit", ",", "k\u00fcmmt", "Rat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM", "FM", "PPER", "VMFIN", "$(", "VVFIN", "NN", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer fast steiht, k\u00fcmmt nich licht tau Fall,", "tokens": ["Wer", "fast", "steiht", ",", "k\u00fcmmt", "nich", "licht", "tau", "Fall", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$,", "VVFIN", "PTKNEG", "NN", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "un keen Aust kem noch v\u00f6r de Saat;", "tokens": ["un", "ke\u00b7en", "Aust", "kem", "noch", "v\u00f6r", "de", "Saat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "un s\u00fchst du ok nich Stig noch Steg", "tokens": ["un", "s\u00fchst", "du", "ok", "nich", "Stig", "noch", "Steg"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["FM", "VVFIN", "PPER", "NE", "PTKNEG", "ADJD", "ADV", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.6": {"text": "un weest nich mihr, ob h\u00fcl ob hott \u2013", "tokens": ["un", "weest", "nich", "mihr", ",", "ob", "h\u00fcl", "ob", "hott", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "PTKNEG", "ADV", "$,", "KOUS", "ADV", "KOUS", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "man drist grad tau! Dat is de Weg,", "tokens": ["man", "drist", "grad", "tau", "!", "Dat", "is", "de", "Weg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "ADJD", "$.", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "denn k\u00fcmmt dat Gl\u00fcck, dor helpt di Gott.", "tokens": ["denn", "k\u00fcmmt", "dat", "Gl\u00fcck", ",", "dor", "helpt", "di", "Gott", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Denn k\u00fcmmt't oft b\u00e4ter, as du dacht,", "tokens": ["Denn", "k\u00fcmmt't", "oft", "b\u00e4\u00b7ter", ",", "as", "du", "dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "denn sleiht up eens di allens in,", "tokens": ["denn", "sleiht", "up", "e\u00b7ens", "di", "al\u00b7lens", "in", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "FM", "FM", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "denn dreiht sick dat, denn treckst du sacht", "tokens": ["denn", "dreiht", "sick", "dat", ",", "denn", "treckst", "du", "sacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "FM.nl", "FM.nl", "FM.nl", "$,", "KON", "VVFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "noch in den besten Katen rin;", "tokens": ["noch", "in", "den", "bes\u00b7ten", "Ka\u00b7ten", "rin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "kriggst Stall un Goren, Gaus un Kauh,", "tokens": ["kriggst", "Stall", "un", "Go\u00b7ren", ",", "Gaus", "un", "Kauh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "FM", "NN", "$,", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fru, J\u00f6ren, Hohn un Hahn un Swin,", "tokens": ["Fru", ",", "J\u00f6\u00b7ren", ",", "Hohn", "un", "Hahn", "un", "Swin", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "FM", "FM", "FM", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "b\u00fcst achterher vergn\u00f6gt dortau,", "tokens": ["b\u00fcst", "ach\u00b7ter\u00b7her", "ver\u00b7gn\u00f6gt", "dor\u00b7tau", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "kannst anners du vergn\u00f6gt man sin.", "tokens": ["kannst", "an\u00b7ners", "du", "ver\u00b7gn\u00f6gt", "man", "sin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch k\u00fcmmst du nah de anner Sit", "tokens": ["Doch", "k\u00fcmmst", "du", "nah", "de", "an\u00b7ner", "Sit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von dat graut Water, gl\u00f6w du man,", "tokens": ["von", "dat", "graut", "Wa\u00b7ter", ",", "gl\u00f6w", "du", "man", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "dor helpt ok wider nicks as Flit,", "tokens": ["dor", "helpt", "ok", "wi\u00b7der", "nicks", "as", "Flit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "m\u00f6st du noch eens sau dull heran.", "tokens": ["m\u00f6st", "du", "noch", "e\u00b7ens", "sau", "dull", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "ADJD", "ADJD", "PTKVZ", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Dor ward dat Smolt up't Brot ok gragt,", "tokens": ["Dor", "ward", "dat", "Smolt", "up't", "Brot", "ok", "gragt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "VVFIN", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wenn eener noch sau flitig pl\u00f6gt;", "tokens": ["wenn", "e\u00b7e\u00b7ner", "noch", "sau", "fli\u00b7tig", "pl\u00f6gt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ADJD", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "dor is keen Minsch, de nah di fragt,", "tokens": ["dor", "is", "ke\u00b7en", "Minsch", ",", "de", "nah", "di", "fragt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "VVFIN", "NN", "$,", "NE", "ADJD", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "\u00fcm di den l\u00fctten Finger r\u00f6gt.", "tokens": ["\u00fcm", "di", "den", "l\u00fct\u00b7ten", "Fin\u00b7ger", "r\u00f6gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Dor rackt een jeder f\u00f6r sick s\u00fclst,", "tokens": ["Dor", "rackt", "e\u00b7en", "je\u00b7der", "f\u00f6r", "sick", "s\u00fclst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "PIAT", "FM", "FM", "FM", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "un dor heet klauk, wer d\u00fcchtig l\u00fcggt", "tokens": ["un", "dor", "heet", "klauk", ",", "wer", "d\u00fcch\u00b7tig", "l\u00fcggt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "PWS", "ADJD", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "un wer sick h\u0153gt, wenn up dat d\u00fcllst", "tokens": ["un", "wer", "sick", "h\u0153gt", ",", "wenn", "up", "dat", "d\u00fcllst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "KOUS", "NE", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "he di beschummelt un bedr\u00fcggt.", "tokens": ["he", "di", "be\u00b7schum\u00b7melt", "un", "be\u00b7dr\u00fcggt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dor heet dat: Help di s\u00fclst un s\u00fch,", "tokens": ["Dor", "heet", "dat", ":", "Help", "di", "s\u00fclst", "un", "s\u00fch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$.", "FM", "FM", "FM", "FM", "FM", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "wur d\u00f6rch du k\u00fcmmst un wur di't gl\u00fcckt!", "tokens": ["wur", "d\u00f6rch", "du", "k\u00fcmmst", "un", "wur", "di't", "gl\u00fcckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "PPER", "VVFIN", "FM", "FM", "FM", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wat schert un deit dat uns, wur di", "tokens": ["Wat", "schert", "un", "deit", "dat", "uns", ",", "wur", "di"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,", "VVFIN", "NE"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "din St\u00e4wel knipt, din Schauh di dr\u00fcckt!", "tokens": ["din", "St\u00e4\u00b7wel", "knipt", ",", "din", "Schauh", "di", "dr\u00fcckt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PPOSAT", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Dor is all mennig, meenigeen \u2013", "tokens": ["Dor", "is", "all", "men\u00b7nig", ",", "mee\u00b7ni\u00b7geen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "FM", "PIAT", "NN", "$,", "VVFIN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "un keen Minsch h\u00fclp von alltausam' \u2013", "tokens": ["un", "ke\u00b7en", "Minsch", "h\u00fclp", "von", "all\u00b7tau\u00b7sam'", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "von Schauh un Kittel, Str\u00fcmp un Been", "tokens": ["von", "Schauh", "un", "Kit\u00b7tel", ",", "Str\u00fcmp", "un", "Be\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "FM", "NN", "$,", "FM", "FM", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "un achter'n Tun tum Starben kam'.", "tokens": ["un", "ach\u00b7ter'n", "Tun", "tum", "Star\u00b7ben", "kam'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Un mennigeen de sitt noch dor,", "tokens": ["Un", "men\u00b7ni\u00b7geen", "de", "sitt", "noch", "dor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VVFIN", "ADV", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "denkt Nacht un Dag nah Hus tor\u00fcgg,", "tokens": ["denkt", "Nacht", "un", "Dag", "nah", "Hus", "to\u00b7r\u00fcgg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "FM", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "kem wedder \u0153wer't Water gor", "tokens": ["kem", "wed\u00b7der", "\u0153wer't", "Wa\u00b7ter", "gor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "un gor tau girn \u2013 he kann man nich.", "tokens": ["un", "gor", "tau", "girn", "\u2013", "he", "kann", "man", "nich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "$(", "NE", "VMFIN", "PIS", "PTKNEG", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Dat is, as wenn utwussen B\u00f6m", "tokens": ["Dat", "is", ",", "as", "wenn", "ut\u00b7wus\u00b7sen", "B\u00f6m"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["FM", "FM", "$,", "NE", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "man utgr\u00f6fft un \u00fcmplanten deit,", "tokens": ["man", "ut\u00b7gr\u00f6fft", "un", "\u00fcm\u00b7plan\u00b7ten", "deit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "de quint s\u00fclst in den besten Lehm,", "tokens": ["de", "quint", "s\u00fclst", "in", "den", "bes\u00b7ten", "Lehm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "un hewwt se noch sau gaut s\u00fcnst bleuht;", "tokens": ["un", "hewwt", "se", "noch", "sau", "gaut", "s\u00fcnst", "bleuht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "ADV", "ADJD", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dat is, as wenn 'ne Stark man drifft", "tokens": ["dat", "is", ",", "as", "wenn", "'ne", "Stark", "man", "drifft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "FM", "$,", "NE", "KOUS", "ART", "NN", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "von'n Dreesch herin in Wisch un Brok \u2013", "tokens": ["von'n", "Dre\u00b7esch", "he\u00b7rin", "in", "Wisch", "un", "Brok", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "APPR", "NN", "FM", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "wenn se dor st\u00f6rt't un dot dor blifft,", "tokens": ["wenn", "se", "dor", "st\u00f6rt't", "un", "dot", "dor", "blifft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "FM", "FM", "FM", "FM", "FM", "FM", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "wat Wunner ok \u2013 wat Wunner ok!", "tokens": ["wat", "Wun\u00b7ner", "ok", "\u2013", "wat", "Wun\u00b7ner", "ok", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$(", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Denn sittst viellicht, wer weet wur bald,", "tokens": ["Denn", "sittst", "viel\u00b7licht", ",", "wer", "weet", "wur", "bald", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PWS", "VVFIN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du ok, verraden un verk\u00f6fft,", "tokens": ["du", "ok", ",", "ver\u00b7ra\u00b7den", "un", "ver\u00b7k\u00f6fft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "$,", "ADJA", "FM", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "in sonn amerikansche Wald,", "tokens": ["in", "sonn", "a\u00b7me\u00b7ri\u00b7kan\u00b7sche", "Wald", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "as v\u00f6r di v\u00e4l all s\u00e4ten hewwt \u2013", "tokens": ["as", "v\u00f6r", "di", "v\u00e4l", "all", "s\u00e4\u00b7ten", "hewwt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "un denkst, dat ick dat sau hier drap,", "tokens": ["un", "denkst", ",", "dat", "ick", "dat", "sau", "hier", "drap", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "$,", "FM.nl", "FM.nl", "FM.nl", "FM.nl", "FM.nl", "FM.nl", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "dat is min Straf, viellicht min Dod;", "tokens": ["dat", "is", "min", "Straf", ",", "viel\u00b7licht", "min", "Dod", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "FM", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "wuar\u00fcm wir ick ok sonn oll Schap", "tokens": ["wua\u00b7r\u00fcm", "wir", "ick", "ok", "sonn", "oll", "Schap"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "un spr\u00fcng dei Hamels nah in'n Sot!", "tokens": ["un", "spr\u00fcng", "dei", "Ha\u00b7mels", "nah", "in'n", "Sot", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "PPOSAT", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Denn denkst an din oll D\u00f6rp sau girn,", "tokens": ["Denn", "denkst", "an", "din", "oll", "D\u00f6rp", "sau", "girn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wur oft du dor hest eggt un seiht,", "tokens": ["wur", "oft", "du", "dor", "hest", "eggt", "un", "seiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "FM", "FM", "FM", "FM", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wat dor f\u00f6r sch\u00e4une K\u00e4uh doch wir'n \u2013", "tokens": ["wat", "dor", "f\u00f6r", "sch\u00e4u\u00b7ne", "K\u00e4uh", "doch", "wir'n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "un wat de Weit se woll all meiht?", "tokens": ["un", "wat", "de", "Weit", "se", "woll", "all", "meiht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "ADV", "PIAT", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Un as du noch den dullen Hingst,", "tokens": ["Un", "as", "du", "noch", "den", "dul\u00b7len", "Hingst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "den ble\u00dften, \u00fcnner Sadel redst \u2013", "tokens": ["den", "ble\u00df\u00b7ten", ",", "\u00fcn\u00b7ner", "Sa\u00b7del", "redst", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "un as du Mai noch halen g\u00fcngst", "tokens": ["un", "as", "du", "Mai", "noch", "ha\u00b7len", "g\u00fcngst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM", "FM", "PPER", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "un mit Marik noch danzen dedst;", "tokens": ["un", "mit", "Ma\u00b7rik", "noch", "dan\u00b7zen", "dedst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "APPR", "NN", "ADV", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.13": {"line.1": {"text": "un denkst, was dor ok v\u00e4l man schlicht", "tokens": ["un", "denkst", ",", "was", "dor", "ok", "v\u00e4l", "man", "schlicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["FM", "FM", "$,", "PWS", "FM", "FM", "FM", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "un k\u00fcnn dor b\u00e4ter w\u00e4sen v\u00e4l", "tokens": ["un", "k\u00fcnn", "dor", "b\u00e4\u00b7ter", "w\u00e4\u00b7sen", "v\u00e4l"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "un was de Arbeit ok nich licht \u2013", "tokens": ["un", "was", "de", "Ar\u00b7beit", "ok", "nich", "licht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "PTKNEG", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "man leg doch up'n warmen P\u0153hl.", "tokens": ["man", "leg", "doch", "up'n", "war\u00b7men", "P\u0153hl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NE", "ADV", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Du w\u00fc\u00dft doch dor, wuaran du wirst,", "tokens": ["Du", "w\u00fc\u00dft", "doch", "dor", ",", "wu\u00b7a\u00b7ran", "du", "wirst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "dor was doch Rat, dor was doch H\u00fclp,", "tokens": ["dor", "was", "doch", "Rat", ",", "dor", "was", "doch", "H\u00fclp", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "ADV", "NN", "$,", "ADV", "PWS", "ADV", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "dor kem doch Gotts Wurt noch tauirst", "tokens": ["dor", "kem", "doch", "Gotts", "Wurt", "noch", "tau\u00b7irst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "NE", "NE", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "un hadd doch jede Pott sin St\u00fclp.", "tokens": ["un", "hadd", "doch", "je\u00b7de", "Pott", "sin", "St\u00fclp", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "ADV", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Un geihst du weg un dr\u00f6ppst dat gaut,", "tokens": ["Un", "geihst", "du", "weg", "un", "dr\u00f6ppst", "dat", "gaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "FM", "FM", "FM", "FM", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.2": {"text": "as dat dor weck woll drapen m\u0153gt,", "tokens": ["as", "dat", "dor", "weck", "woll", "dra\u00b7pen", "m\u0153gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "denn isern Blaut un isern Maut", "tokens": ["denn", "i\u00b7sern", "Blaut", "un", "i\u00b7sern", "Maut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "FM", "FM", "FM", "FM", "FM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "de slahn den D\u00fcwel allerw\u00e4gt \u2013", "tokens": ["de", "slahn", "den", "D\u00fc\u00b7wel", "al\u00b7ler\u00b7w\u00e4gt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wat helpt dat all! Taufr\u00e4denheit", "tokens": ["wat", "helpt", "dat", "all", "!", "Tauf\u00b7r\u00e4\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "ART", "PIAT", "$.", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "de wa\u00dft nich West, de wa\u00dft nich Ost,", "tokens": ["de", "wa\u00dft", "nich", "West", ",", "de", "wa\u00dft", "nich", "Ost", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "NE", "$,", "NE", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "de wa\u00dft, sau wit een Minsch ok geiht,", "tokens": ["de", "wa\u00dft", ",", "sau", "wit", "e\u00b7en", "Minsch", "ok", "geiht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "doch narrns as in sin eegen Bost.", "tokens": ["doch", "narrns", "as", "in", "sin", "e\u00b7e\u00b7gen", "Bost", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.15": {"line.1": {"text": "Du seggst, wat h\u00f6llt di hier? Johann!", "tokens": ["Du", "seggst", ",", "wat", "h\u00f6llt", "di", "hier", "?", "Jo\u00b7hann", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "VVFIN", "NE", "ADV", "$.", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du wist nu nah Amerika \u2013", "tokens": ["Du", "wist", "nu", "nah", "A\u00b7me\u00b7ri\u00b7ka", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "kik doch din'n ollen Vader an!", "tokens": ["kik", "doch", "din'n", "ol\u00b7len", "Va\u00b7der", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fr\u00f6ggst nicks nah din oll Moder nah?", "tokens": ["Fr\u00f6ggst", "nicks", "nah", "din", "oll", "Mo\u00b7der", "nah", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Un wenn se ok nich Hoff un Veh,", "tokens": ["Un", "wenn", "se", "ok", "nich", "Hoff", "un", "Veh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "FM", "FM", "PTKNEG", "VVFIN", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "nich Wisch un Feld up di verarwt \u2013", "tokens": ["nich", "Wisch", "un", "Feld", "up", "di", "ver\u00b7arwt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "FM", "FM", "FM", "FM", "FM", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "sonn oll L\u00fcd deit dat gor tau weh,", "tokens": ["sonn", "oll", "L\u00fcd", "deit", "dat", "gor", "tau", "weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "wenn wit von ehren S\u0153hn se starwt.", "tokens": ["wenn", "wit", "von", "eh\u00b7ren", "S\u0153hn", "se", "starwt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "APPR", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Dat \u00d6ller is all sau sau kolt;", "tokens": ["Dat", "\u00d6l\u00b7ler", "is", "all", "sau", "sau", "kolt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "un hewwt sei ok ehr Ollendeel,", "tokens": ["un", "hewwt", "sei", "ok", "ehr", "Ol\u00b7len\u00b7deel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "dat is sau eensam, wenn man olt \u2013", "tokens": ["dat", "is", "sau", "e\u00b7en\u00b7sam", ",", "wenn", "man", "olt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "FM", "$,", "KOUS", "PIS", "ADJD", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "dat is nich half, dat is nich heel.", "tokens": ["dat", "is", "nich", "half", ",", "dat", "is", "nich", "heel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "PTKNEG", "VVFIN", "$,", "FM.nl", "FM.nl", "PTKNEG", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.5": {"text": "Dei Knaken lahm, sau fack dei Arm',", "tokens": ["Dei", "Kna\u00b7ken", "lahm", ",", "sau", "fack", "dei", "Arm'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "de Gicht de sitt in Hand un Tehn,", "tokens": ["de", "Gicht", "de", "sitt", "in", "Hand", "un", "Tehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.da", "FM.da", "FM.da", "FM.da", "APPR", "NN", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "di fr\u00fcst \u2013 un sittst du noch sau warm,", "tokens": ["di", "fr\u00fcst", "\u2013", "un", "sittst", "du", "noch", "sau", "warm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$(", "FM", "VVFIN", "PPER", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "du s\u00fchst \u2013 un kannst doch recht nich sehn.", "tokens": ["du", "s\u00fchst", "\u2013", "un", "kannst", "doch", "recht", "nich", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "FM", "VMFIN", "ADV", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Dat is 'ne gor tau lege Tit \u2013", "tokens": ["Dat", "is", "'ne", "gor", "tau", "le\u00b7ge", "Tit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "doch ach! wur leg \u2013 doch ach! wur leg,", "tokens": ["doch", "ach", "!", "wur", "leg", "\u2013", "doch", "ach", "!", "wur", "leg", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "VVFIN", "NE", "$(", "ADV", "ADV", "$.", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wenn man een Kind hett, dat sau wit,", "tokens": ["wenn", "man", "e\u00b7en", "Kind", "hett", ",", "dat", "sau", "wit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VAFIN", "$,", "FM.nl", "FM.nl", "FM.nl", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "wit weg von sin oll \u00d6llern t\u00f6g;", "tokens": ["wit", "weg", "von", "sin", "oll", "\u00d6l\u00b7lern", "t\u00f6g", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sau wit \u2013 man s\u00fcht em nie nich mihr.", "tokens": ["sau", "wit", "\u2013", "man", "s\u00fcht", "em", "nie", "nich", "mihr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$(", "PIS", "VVFIN", "PIS", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wur lang ward denn de Happen Brot!", "tokens": ["Wur", "lang", "ward", "denn", "de", "Hap\u00b7pen", "Brot", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VAFIN", "ADV", "NE", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sonn oll Mann w\u00fcnscht sick in de Ir',", "tokens": ["Sonn", "oll", "Mann", "w\u00fcnscht", "sick", "in", "de", "Ir'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "VVFIN", "PRF", "APPR", "NE", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "sonn oll Fru m\u00fccht woll, se wir dot.", "tokens": ["sonn", "oll", "Fru", "m\u00fccht", "woll", ",", "se", "wir", "dot", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "VMFIN", "ADV", "$,", "VVFIN", "PPER", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.18": {"line.1": {"text": "Keen Kinnskind sett't sick up sin Knee,", "tokens": ["Ke\u00b7en", "Kinns\u00b7kind", "sett't", "sick", "up", "sin", "Knee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "keen Kinnskind sitt up ehren Schot;", "tokens": ["ke\u00b7en", "Kinns\u00b7kind", "sitt", "up", "eh\u00b7ren", "Schot", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "VVFIN", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "ehr Og ward \u00fcmmer fucht, wenn se", "tokens": ["ehr", "Og", "ward", "\u00fcm\u00b7mer", "fucht", ",", "wenn", "se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "NE", "VAFIN", "ADV", "VVFIN", "$,", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "man h\u00fcrt von Brut un Br\u00fcjam blot;", "tokens": ["man", "h\u00fcrt", "von", "Brut", "un", "Br\u00fc\u00b7jam", "blot", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "se m\u00f6t an di denn denken glik,", "tokens": ["se", "m\u00f6t", "an", "di", "denn", "den\u00b7ken", "glik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NE", "KON", "VVINF", "VVFIN", "$,"], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "wen se di g\u00fcnnen deit as Fru:", "tokens": ["wen", "se", "di", "g\u00fcn\u00b7nen", "deit", "as", "Fru", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "FM", "FM", "FM", "FM", "FM", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "keen Dirn gef\u00f6llt ehr as Marik,", "tokens": ["ke\u00b7en", "Dirn", "ge\u00b7f\u00f6llt", "ehr", "as", "Ma\u00b7rik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "VVPP", "NN", "NE", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "de nehm di woll \u2013 doch wur b\u00fcst du?", "tokens": ["de", "nehm", "di", "woll", "\u2013", "doch", "wur", "b\u00fcst", "du", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$(", "ADV", "VVFIN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Un wenn dat Fierabend wad", "tokens": ["Un", "wenn", "dat", "Fier\u00b7a\u00b7bend", "wad"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "un all L\u00fcd sitten v\u00f6r de D\u00f6r,", "tokens": ["un", "all", "L\u00fcd", "sit\u00b7ten", "v\u00f6r", "de", "D\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "PIAT", "NN", "VVFIN", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "denn s\u00fcnd ehr beid' de Ogen natt \u2013", "tokens": ["denn", "s\u00fcnd", "ehr", "beid'", "de", "O\u00b7gen", "natt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wer kl\u0153hnt mit em? Wer kl\u0153hnt mit ehr?", "tokens": ["wer", "kl\u0153hnt", "mit", "em", "?", "Wer", "kl\u0153hnt", "mit", "ehr", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ADJA", "$.", "PWS", "VVFIN", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Wer spreckt f\u00f6r se een gaudes Wurt,", "tokens": ["Wer", "spreckt", "f\u00f6r", "se", "e\u00b7en", "gau\u00b7des", "Wurt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "FM", "FM", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "wenn't n\u00f6dig deit, mit rechte Schick?", "tokens": ["wenn't", "n\u00f6\u00b7dig", "deit", ",", "mit", "rech\u00b7te", "Schick", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ehr S\u0153hn, ehr eenzig S\u0153hn is furt,", "tokens": ["Ehr", "S\u0153hn", ",", "ehr", "e\u00b7en\u00b7zig", "S\u0153hn", "is", "furt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "un n\u00fcmms nich s\u00fcnst de r\u00fcppelt sick.", "tokens": ["un", "n\u00fcmms", "nich", "s\u00fcnst", "de", "r\u00fcp\u00b7pelt", "sick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.20": {"line.1": {"text": "Un k\u00fcmmt de Dod tauletzt un nimmt", "tokens": ["Un", "k\u00fcmmt", "de", "Dod", "tau\u00b7letzt", "un", "nimmt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "FM", "FM", "FM", "FM", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "se weg, denn is dat grad noch sau;", "tokens": ["se", "weg", ",", "denn", "is", "dat", "grad", "noch", "sau", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "KON", "FM", "ART", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wer sorgt denn f\u00f6r dat Sark? Wer k\u00fcmmt", "tokens": ["wer", "sorgt", "denn", "f\u00f6r", "dat", "Sark", "?", "Wer", "k\u00fcmmt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "KON", "NE", "ART", "NN", "$.", "PWS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "un dr\u00fcckt ehr sacht de Ogen tau?!", "tokens": ["un", "dr\u00fcckt", "ehr", "sacht", "de", "O\u00b7gen", "tau", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Kik doch din'n ollen Vader an!", "tokens": ["Kik", "doch", "din'n", "ol\u00b7len", "Va\u00b7der", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fr\u00f6ggst nicks nah din oll Moder nah?", "tokens": ["Fr\u00f6ggst", "nicks", "nah", "din", "oll", "Mo\u00b7der", "nah", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Nicks nah Marik? Blif hier, Johann!", "tokens": ["Nicks", "nah", "Ma\u00b7rik", "?", "Blif", "hier", ",", "Jo\u00b7hann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "$.", "NN", "ADV", "$,", "NE", "$."], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Wat wist du in Amerika!", "tokens": ["Wat", "wist", "du", "in", "A\u00b7me\u00b7ri\u00b7ka", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}