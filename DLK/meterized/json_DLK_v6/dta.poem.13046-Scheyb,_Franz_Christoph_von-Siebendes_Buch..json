{"dta.poem.13046": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "Siebendes Buch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20535-5", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "\u201everlassen wir das Feld! fort, gehn wir in die Stadt,", "tokens": ["\u201e", "ver\u00b7las\u00b7sen", "wir", "das", "Feld", "!", "fort", ",", "gehn", "wir", "in", "die", "Stadt", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "$.", "PTKVZ", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201edie sich ", "tokens": ["\u201e", "die", "sich"], "token_info": ["punct", "word", "word"], "pos": ["$(", "PRELS", "PRF"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "\u201eja! gehen wir herum, wie man die Nacht gegangen,", "tokens": ["\u201e", "ja", "!", "ge\u00b7hen", "wir", "he\u00b7rum", ",", "wie", "man", "die", "Nacht", "ge\u00b7gan\u00b7gen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$.", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eals ihre Feuers-Pracht zu gl\u00e4nzen angefangen.", "tokens": ["\u201e", "als", "ih\u00b7re", "Feu\u00b7er\u00b7sPracht", "zu", "gl\u00e4n\u00b7zen", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPOSAT", "NN", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201ewer wohnet hier und dort? ihr kennet ja das Haupt,", "tokens": ["\u201e", "wer", "woh\u00b7net", "hier", "und", "dort", "?", "ihr", "ken\u00b7net", "ja", "das", "Haupt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "KON", "ADV", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "370\u201dDem oft Theresia mehr als euch allen glaubt?", "tokens": ["\"", "Dem", "oft", "The\u00b7re\u00b7sia", "mehr", "als", "euch", "al\u00b7len", "glaubt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "NE", "ADV", "KOUS", "PPER", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "\u201eist euch der Kiel bekannt, den sie zum Herrschen brauchet?", "tokens": ["\u201e", "ist", "euch", "der", "Kiel", "be\u00b7kannt", ",", "den", "sie", "zum", "Herr\u00b7schen", "brau\u00b7chet", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NE", "PTKVZ", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201ewi\u00dft ihr, wo manche Nacht die Sorgen-Ampel rauchet?", "tokens": ["\u201e", "wi\u00dft", "ihr", ",", "wo", "man\u00b7che", "Nacht", "die", "Sor\u00b7gen\u00b7Am\u00b7pel", "rau\u00b7chet", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "PWAV", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201esagt, wo das Auge wacht, das L\u00e4nder \u00fcbersieht,", "tokens": ["\u201e", "sagt", ",", "wo", "das", "Au\u00b7ge", "wacht", ",", "das", "L\u00e4n\u00b7der", "\u00fc\u00b7ber\u00b7sieht", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.10": {"text": "\u201eund sie, der K\u00f6niginn zu dienen, an sich zieht?", "tokens": ["\u201e", "und", "sie", ",", "der", "K\u00f6\u00b7ni\u00b7ginn", "zu", "die\u00b7nen", ",", "an", "sich", "zieht", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF", "$,", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "375\u201dWer ist der fruh und sp\u00e4t nach M\u00f6glichkeiten sinnet,", "tokens": ["\"", "Wer", "ist", "der", "fruh", "und", "sp\u00e4t", "nach", "M\u00f6g\u00b7lich\u00b7kei\u00b7ten", "sin\u00b7net", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "ART", "NN", "KON", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eund an Erfindungen, uns aufzuhelffen, spinnet?", "tokens": ["\u201e", "und", "an", "Er\u00b7fin\u00b7dun\u00b7gen", ",", "uns", "auf\u00b7zu\u00b7hel\u00b7ffen", ",", "spin\u00b7net", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "KON", "APPR", "NN", "$,", "PPER", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "\u201ewo pr\u00e4get man dem Volck Muth und Gehorsam ein?", "tokens": ["\u201e", "wo", "pr\u00e4\u00b7get", "man", "dem", "Volck", "Muth", "und", "Ge\u00b7hor\u00b7sam", "ein", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PIS", "ART", "NN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "\u201ewer legte zum Geb\u00e4u des Siegs den ersten Stein?", "tokens": ["\u201e", "wer", "leg\u00b7te", "zum", "Ge\u00b7b\u00e4u", "des", "Siegs", "den", "ers\u00b7ten", "Stein", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "APPRART", "NN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ewer ist dann jederzeit im Raths-Gemach gesessen,", "tokens": ["\u201e", "wer", "ist", "dann", "je\u00b7der\u00b7zeit", "im", "Raths\u00b7Ge\u00b7mach", "ge\u00b7ses\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "ADV", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "380\u201dIn dem Theresia fast jeden Fall ermessen?", "tokens": ["\"", "In", "dem", "The\u00b7re\u00b7sia", "fast", "je\u00b7den", "Fall", "er\u00b7mes\u00b7sen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NE", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.17": {"text": "\u201ejhr habt allein gewi\u00df nicht alles ausgedacht,", "tokens": ["\u201e", "jhr", "habt", "al\u00b7lein", "ge\u00b7wi\u00df", "nicht", "al\u00b7les", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201ewas oft ein kluger F\u00fcrst durch seinen Rath vollbracht?", "tokens": ["\u201e", "was", "oft", "ein", "klu\u00b7ger", "F\u00fcrst", "durch", "sei\u00b7nen", "Rath", "voll\u00b7bracht", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201ekennt ihr diejenigen die stets zusammen kamen,", "tokens": ["\u201e", "kennt", "ihr", "die\u00b7je\u00b7ni\u00b7gen", "die", "stets", "zu\u00b7sam\u00b7men", "ka\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PDS", "ART", "ADV", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.20": {"text": "\u201eauch den geringsten Fall zu untersuchen nahmen,", "tokens": ["\u201e", "auch", "den", "ge\u00b7rings\u00b7ten", "Fall", "zu", "un\u00b7ter\u00b7su\u00b7chen", "nah\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "385\u201dNachdem sie Geist und Herz von jenem Wahn befreyt,", "tokens": ["\"", "Nach\u00b7dem", "sie", "Geist", "und", "Herz", "von", "je\u00b7nem", "Wahn", "be\u00b7freyt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "NN", "KON", "NN", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "\u201eder nur zu fragen pflegt und selten was entscheidt?", "tokens": ["\u201e", "der", "nur", "zu", "fra\u00b7gen", "pflegt", "und", "sel\u00b7ten", "was", "ent\u00b7scheidt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "PTKZU", "VVINF", "VVFIN", "KON", "ADJD", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "\u201ewie viele z\u00e4hlten wir, die miteinander wachten,", "tokens": ["\u201e", "wie", "vie\u00b7le", "z\u00e4hl\u00b7ten", "wir", ",", "die", "mi\u00b7tein\u00b7an\u00b7der", "wach\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "VVFIN", "PPER", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u201edamit auf jeden Fall sie sich gefasset machten?", "tokens": ["\u201e", "da\u00b7mit", "auf", "je\u00b7den", "Fall", "sie", "sich", "ge\u00b7fas\u00b7set", "mach\u00b7ten", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "APPR", "PIAT", "NN", "PPER", "PRF", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "\u201eaus ihrem Wiz und Flei\u00df entstunde mancher Schlu\u00df,", "tokens": ["\u201e", "aus", "ih\u00b7rem", "Wiz", "und", "Flei\u00df", "ent\u00b7stun\u00b7de", "man\u00b7cher", "Schlu\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "KON", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "390\u201dDer noch zu dieser Zeit zur Richtschnur dienen mu\u00df.", "tokens": ["\"", "Der", "noch", "zu", "die\u00b7ser", "Zeit", "zur", "Richt\u00b7schnur", "die\u00b7nen", "mu\u00df", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "APPR", "PDAT", "NN", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "\u201edie, die bem\u00fchten sich den Weeg zum Heil zu finden,", "tokens": ["\u201e", "die", ",", "die", "be\u00b7m\u00fch\u00b7ten", "sich", "den", "Weeg", "zum", "Heil", "zu", "fin\u00b7den", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "$,", "PRELS", "VVFIN", "PRF", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "\u201ewas fern und nahe war, in eines zu verbinden.", "tokens": ["\u201e", "was", "fern", "und", "na\u00b7he", "war", ",", "in", "ei\u00b7nes", "zu", "ver\u00b7bin\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADJD", "KON", "ADJD", "VAFIN", "$,", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}