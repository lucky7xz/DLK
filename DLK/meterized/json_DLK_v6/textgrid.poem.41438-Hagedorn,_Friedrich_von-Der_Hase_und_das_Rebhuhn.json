{"textgrid.poem.41438": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Hase und das Rebhuhn", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Has' und Rebhuhn fanden beide", "tokens": ["Ein", "Has'", "und", "Reb\u00b7huhn", "fan\u00b7den", "bei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Vorholz, Feld und Busch Fra\u00df, Sicherheit und Freude;", "tokens": ["Im", "Vor\u00b7holz", ",", "Feld", "und", "Busch", "Fra\u00df", ",", "Si\u00b7cher\u00b7heit", "und", "Freu\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "NN", "KON", "NN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und jener sa\u00df ganz ruhig im Getreide,", "tokens": ["Und", "je\u00b7ner", "sa\u00df", "ganz", "ru\u00b7hig", "im", "Ge\u00b7trei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als S\u00f6llmann und die Jagd rasch ins Geh\u00e4ge drang,", "tokens": ["Als", "S\u00f6ll\u00b7mann", "und", "die", "Jagd", "rasch", "ins", "Ge\u00b7h\u00e4\u00b7ge", "drang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "ART", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hochlautend ihn zum \u00f6ftern Wiedergang,", "tokens": ["Hoch\u00b7lau\u00b7tend", "ihn", "zum", "\u00f6f\u00b7tern", "Wie\u00b7der\u00b7gang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und f\u00fcrchterlich zum Absprung zwang.", "tokens": ["Und", "f\u00fcrch\u00b7ter\u00b7lich", "zum", "Ab\u00b7sprung", "zwang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu oft ist manche Lust benachbart mit dem Leide.", "tokens": ["Zu", "oft", "ist", "man\u00b7che", "Lust", "be\u00b7nach\u00b7bart", "mit", "dem", "Lei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VAFIN", "PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Sie rahmen ihn herum: er l\u00e4uft, und ach! wie schnell!", "tokens": ["Sie", "rah\u00b7men", "ihn", "he\u00b7rum", ":", "er", "l\u00e4uft", ",", "und", "ach", "!", "wie", "schnell", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "KON", "XY", "$.", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch seine F\u00e4hrte kennt der treue Waldgesell.", "tokens": ["Doch", "sei\u00b7ne", "F\u00e4hr\u00b7te", "kennt", "der", "treu\u00b7e", "Wald\u00b7ge\u00b7sell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Lager dr\u00fcckt er sich: noch hofft er zu entwischen;", "tokens": ["Im", "La\u00b7ger", "dr\u00fcckt", "er", "sich", ":", "noch", "hofft", "er", "zu", "ent\u00b7wi\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PRF", "$.", "ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Allein der Weidmann wei\u00df die St\u00f6ber anzufrischen:", "tokens": ["Al\u00b7lein", "der", "Weid\u00b7mann", "wei\u00df", "die", "St\u00f6\u00b7ber", "an\u00b7zu\u00b7fri\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Fl\u00fcchtling wird erreicht, so sehr er sich verbirgt,", "tokens": ["Der", "Fl\u00fccht\u00b7ling", "wird", "er\u00b7reicht", ",", "so", "sehr", "er", "sich", "ver\u00b7birgt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ADV", "ADV", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und, weil der Retter fehlt, indem er schreit, erw\u00fcrgt.", "tokens": ["Und", ",", "weil", "der", "Ret\u00b7ter", "fehlt", ",", "in\u00b7dem", "er", "schreit", ",", "er\u00b7w\u00fcrgt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Das Rebhuhn sa\u00df, und sprach: der Thor pflag sich zu preisen;", "tokens": ["Das", "Reb\u00b7huhn", "sa\u00df", ",", "und", "sprach", ":", "der", "Thor", "pflag", "sich", "zu", "prei\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "$.", "ART", "NN", "VVFIN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie prahlend r\u00fchmt' er mir der L\u00e4ufte Vorzug an!", "tokens": ["Wie", "prah\u00b7lend", "r\u00fchmt'", "er", "mir", "der", "L\u00e4uf\u00b7te", "Vor\u00b7zug", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nun stirbt er l\u00e4cherlich, und mu\u00df auch mir beweisen,", "tokens": ["Nun", "stirbt", "er", "l\u00e4\u00b7cher\u00b7lich", ",", "und", "mu\u00df", "auch", "mir", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "KON", "VMFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zehn Hasen k\u00f6nnen nicht, was ein Strick Hunde kann.", "tokens": ["Zehn", "Ha\u00b7sen", "k\u00f6n\u00b7nen", "nicht", ",", "was", "ein", "Strick", "Hun\u00b7de", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "PTKNEG", "$,", "PRELS", "ART", "NN", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es h\u00f6hnt': allein, wie lang'? Es scho\u00df aus ferner H\u00f6he", "tokens": ["Es", "h\u00f6hnt'", ":", "al\u00b7lein", ",", "wie", "lang'", "?", "Es", "scho\u00df", "aus", "fer\u00b7ner", "H\u00f6\u00b7he"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ADV", "$,", "PWAV", "ADV", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Habicht auf das Huhn herab;", "tokens": ["Ein", "Ha\u00b7bicht", "auf", "das", "Huhn", "her\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und, da\u00df man oft den Spott sogleich bestrafet sehe,", "tokens": ["Und", ",", "da\u00df", "man", "oft", "den", "Spott", "sog\u00b7leich", "be\u00b7stra\u00b7fet", "se\u00b7he", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "ADV", "ART", "NN", "ADV", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bekr\u00e4ftigte der Sto\u00df, den er dem Sp\u00f6tter gab.", "tokens": ["Be\u00b7kr\u00e4f\u00b7tig\u00b7te", "der", "Sto\u00df", ",", "den", "er", "dem", "Sp\u00f6t\u00b7ter", "gab", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Auf ein gewisses Gl\u00fcck kann niemand Rechnung machen,", "tokens": ["Auf", "ein", "ge\u00b7wis\u00b7ses", "Gl\u00fcck", "kann", "nie\u00b7mand", "Rech\u00b7nung", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VMFIN", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nichts ist th\u00f6richter, als solche zu belachen,", "tokens": ["Und", "nichts", "ist", "th\u00f6\u00b7rich\u00b7ter", ",", "als", "sol\u00b7che", "zu", "be\u00b7la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADJD", "$,", "KOUS", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Die ihr Verh\u00e4ngni\u00df dr\u00fcckt. R\u00fchrt dich nicht andrer Leid;", "tokens": ["Die", "ihr", "Ver\u00b7h\u00e4ng\u00b7ni\u00df", "dr\u00fcckt", ".", "R\u00fchrt", "dich", "nicht", "an\u00b7drer", "Leid", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$.", "VVFIN", "PPER", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Feind, so verdienest du barmherz'ger Henker Neid.", "tokens": ["Feind", ",", "so", "ver\u00b7die\u00b7nest", "du", "barm\u00b7her\u00b7z'\u00b7ger", "Hen\u00b7ker", "Neid", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "PPER", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "Die w\u00e4ren gl\u00fccklicher, so oft sie Menschen qu\u00e4len,", "tokens": ["Die", "w\u00e4\u00b7ren", "gl\u00fcck\u00b7li\u00b7cher", ",", "so", "oft", "sie", "Men\u00b7schen", "qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "$,", "ADV", "ADV", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bes\u00e4\u00dfen sie dein Herz, dem Lieb' und Mitleid fehlen.", "tokens": ["Be\u00b7s\u00e4\u00b7\u00dfen", "sie", "dein", "Herz", ",", "dem", "Lieb'", "und", "Mit\u00b7leid", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}