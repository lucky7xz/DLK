{"dta.poem.10026": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Anfang des Fr\u00fchlinges.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es scheinet ietzt bald hie bald da,", "tokens": ["Es", "schei\u00b7net", "ietzt", "bald", "hie", "bald", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An allen Orten fern und nah,", "tokens": ["An", "al\u00b7len", "Or\u00b7ten", "fern", "und", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des jungen Grases frisches Gr\u00fcn,", "tokens": ["Des", "jun\u00b7gen", "Gra\u00b7ses", "fri\u00b7sches", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit ungezehlten Lieblichkeiten,", "tokens": ["Mit", "un\u00b7ge\u00b7zehl\u00b7ten", "Lieb\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sich gleichsam \u00e4msig zu bem\u00fchn,", "tokens": ["Sich", "gleich\u00b7sam", "\u00e4m\u00b7sig", "zu", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das welcke Gelbe zu bestreiten,", "tokens": ["Das", "wel\u00b7cke", "Gel\u00b7be", "zu", "be\u00b7strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und itzt, bald hier bald dort, das Land zu \u00fcberziehn.", "tokens": ["Und", "itzt", ",", "bald", "hier", "bald", "dort", ",", "das", "Land", "zu", "\u00fc\u00b7ber\u00b7ziehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADV", "ADV", "ADV", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Hier siegt annoch des alten Grases Rest:", "tokens": ["Hier", "siegt", "an\u00b7noch", "des", "al\u00b7ten", "Gra\u00b7ses", "Rest", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sein falbes brann, sein schmutzigs grau", "tokens": ["Sein", "fal\u00b7bes", "brann", ",", "sein", "schmut\u00b7zigs", "grau"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "VVFIN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00e4lt, ob gleich welck, annoch an faulen Stengeln fest,", "tokens": ["H\u00e4lt", ",", "ob", "gleich", "welck", ",", "an\u00b7noch", "an", "fau\u00b7len", "Sten\u00b7geln", "fest", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "PTKVZ", "$,", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "----+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Indem ich dorten nichts, als neue Sch\u00f6nheit, schau.", "tokens": ["In\u00b7dem", "ich", "dor\u00b7ten", "nichts", ",", "als", "neu\u00b7e", "Sch\u00f6n\u00b7heit", ",", "schau", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "$,", "KOUS", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Hier drenget manche zarte Spitze", "tokens": ["Hier", "dren\u00b7get", "man\u00b7che", "zar\u00b7te", "Spit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich einzeln aus der Erd\u2019, und dorten siehet man", "tokens": ["Sich", "ein\u00b7zeln", "aus", "der", "Erd'", ",", "und", "dor\u00b7ten", "sie\u00b7het", "man"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "$,", "KON", "ADV", "VVFIN", "PIS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schon kleine H\u00fcgelchen von Gras, und kleine Blitze,", "tokens": ["Schon", "klei\u00b7ne", "H\u00fc\u00b7gel\u00b7chen", "von", "Gras", ",", "und", "klei\u00b7ne", "Blit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wann sie bestrahlet sind, auf ihrer gr\u00fcnen Gl\u00e4tte,", "tokens": ["Wann", "sie", "be\u00b7strah\u00b7let", "sind", ",", "auf", "ih\u00b7rer", "gr\u00fc\u00b7nen", "Gl\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "VAFIN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die man nicht sonder Lust beschauen kan:", "tokens": ["Die", "man", "nicht", "son\u00b7der", "Lust", "be\u00b7schau\u00b7en", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKNEG", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zumahl wann sich der linde Zephir reget,", "tokens": ["Zu\u00b7mahl", "wann", "sich", "der", "lin\u00b7de", "Ze\u00b7phir", "re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PRF", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und jedes Gr\u00e4schen sich gelinde mit beweget,", "tokens": ["Und", "je\u00b7des", "Gr\u00e4sc\u00b7hen", "sich", "ge\u00b7lin\u00b7de", "mit", "be\u00b7we\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PRF", "ADJA", "APPR", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sammt den durch sie erzeugten zarten Schatten,", "tokens": ["Sammt", "den", "durch", "sie", "er\u00b7zeug\u00b7ten", "zar\u00b7ten", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "APPR", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Die auch beweglich sind, und sich mit ihnen gatten,", "tokens": ["Die", "auch", "be\u00b7weg\u00b7lich", "sind", ",", "und", "sich", "mit", "ih\u00b7nen", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "$,", "KON", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Um, durch den Gegen-Satz, das, was so Wunder-sch\u00f6n,", "tokens": ["Um", ",", "durch", "den", "Ge\u00b7gen\u00b7Satz", ",", "das", ",", "was", "so", "Wun\u00b7der\u00b7sch\u00f6n", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "$,", "APPR", "ART", "NN", "$,", "PDS", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Noch zu verherrlichen, und mehr noch zu erh\u00f6hn.", "tokens": ["Noch", "zu", "ver\u00b7herr\u00b7li\u00b7chen", ",", "und", "mehr", "noch", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$,", "KON", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Hier prangt ein gr\u00fcner Platz, der rings \u00fcmher", "tokens": ["Hier", "prangt", "ein", "gr\u00fc\u00b7ner", "Platz", ",", "der", "rings", "\u00fcm\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADJA"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Von Stellen, die annoch von Grase leer,", "tokens": ["Von", "Stel\u00b7len", ",", "die", "an\u00b7noch", "von", "Gra\u00b7se", "leer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Als wie ein Inselchen, \u00fcmgeben; wann sich dort", "tokens": ["Als", "wie", "ein", "In\u00b7sel\u00b7chen", ",", "\u00fcm\u00b7ge\u00b7ben", ";", "wann", "sich", "dort"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$,", "VVINF", "$.", "PWAV", "PRF", "ADV"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Von braunem Staub und Sand ein kleiner Ort", "tokens": ["Von", "brau\u00b7nem", "Staub", "und", "Sand", "ein", "klei\u00b7ner", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Roch zwischen gr\u00fcnen Stellen zeiget.", "tokens": ["Roch", "zwi\u00b7schen", "gr\u00fc\u00b7nen", "Stel\u00b7len", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Noch anderw\u00e4rts l\u00e4sst ein vermischtes Braun,", "tokens": ["Noch", "an\u00b7der\u00b7w\u00e4rts", "l\u00e4sst", "ein", "ver\u00b7mischtes", "Braun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus welchem Gras und Kraut fast allenthalben steiget,", "tokens": ["Aus", "wel\u00b7chem", "Gras", "und", "Kraut", "fast", "al\u00b7len\u00b7thal\u00b7ben", "stei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein liebliches Gemisch im Strahl der Sonnen schaun,", "tokens": ["Ein", "lieb\u00b7li\u00b7ches", "Ge\u00b7misch", "im", "Strahl", "der", "Son\u00b7nen", "schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein in kurtzer Zeit ist Sand und Staub verstecket:", "tokens": ["Al\u00b7lein", "in", "kurt\u00b7zer", "Zeit", "ist", "Sand", "und", "Staub", "ver\u00b7ste\u00b7cket", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VAFIN", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Wunder-sch\u00f6nes Gr\u00fcn wird allgemein,", "tokens": ["Ein", "Wun\u00b7der\u00b7sch\u00f6\u00b7nes", "Gr\u00fcn", "wird", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und alles steht, zumahl im Sonnen-Schein,", "tokens": ["Und", "al\u00b7les", "steht", ",", "zu\u00b7mahl", "im", "Son\u00b7nen\u00b7Schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "KOUS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Mit einem gr\u00fcnen Glantz bedecket,", "tokens": ["Mit", "ei\u00b7nem", "gr\u00fc\u00b7nen", "Glantz", "be\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auf welchem wir in kurtzem, Wunder-sch\u00f6n,", "tokens": ["Auf", "wel\u00b7chem", "wir", "in", "kurt\u00b7zem", ",", "Wun\u00b7der\u00b7sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "ADJA", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Die bunte Pracht gef\u00e4rbter Bluhmen sehn.", "tokens": ["Die", "bun\u00b7te", "Pracht", "ge\u00b7f\u00e4rb\u00b7ter", "Bluh\u00b7men", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Die Erd-Gew\u00e4chse sieht man nun,", "tokens": ["Die", "Erd\u00b7Ge\u00b7w\u00e4ch\u00b7se", "sieht", "man", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rachdem sie ferner nicht mehr ruhn,", "tokens": ["Rach\u00b7dem", "sie", "fer\u00b7ner", "nicht", "mehr", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf den gevierten Garten-Beten,", "tokens": ["Auf", "den", "ge\u00b7vier\u00b7ten", "Gar\u00b7ten\u00b7Be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus ihrem Schlaff-Gemach im Fr\u00fchling gleichsam treten.", "tokens": ["Aus", "ih\u00b7rem", "Schlaff\u00b7Ge\u00b7mach", "im", "Fr\u00fch\u00b7ling", "gleich\u00b7sam", "tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie haben abgelegt den alten Leib,", "tokens": ["Sie", "ha\u00b7ben", "ab\u00b7ge\u00b7legt", "den", "al\u00b7ten", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und einen neuen angenommen;", "tokens": ["Und", "ei\u00b7nen", "neu\u00b7en", "an\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und, stat des alten Rocks, der gantz zerrissen,", "tokens": ["Und", ",", "stat", "des", "al\u00b7ten", "Rocks", ",", "der", "gantz", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Verwelckt, verweset und verschlissen,", "tokens": ["Ver\u00b7welckt", ",", "ver\u00b7we\u00b7set", "und", "ver\u00b7schlis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ein neues bunt-und sch\u00f6nes Kleid", "tokens": ["Ein", "neu\u00b7es", "bunt\u00b7\u00b7und", "sch\u00f6\u00b7nes", "Kleid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "In dieser frohen Fr\u00fchlings-Zeit", "tokens": ["In", "die\u00b7ser", "fro\u00b7hen", "Fr\u00fch\u00b7lings\u00b7Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "In neuem Schimmer \u00fcberkommen.", "tokens": ["In", "neu\u00b7em", "Schim\u00b7mer", "\u00fc\u00b7ber\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Mich deucht, ich sehe sie ihr schweigen unterbrechen;", "tokens": ["Mich", "deucht", ",", "ich", "se\u00b7he", "sie", "ihr", "schwei\u00b7gen", "un\u00b7ter\u00b7bre\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mich deucht, ich h\u00f6re sie mit bunten Lippen sprechen:", "tokens": ["Mich", "deucht", ",", "ich", "h\u00f6\u00b7re", "sie", "mit", "bun\u00b7ten", "Lip\u00b7pen", "spre\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Geliebte Menschen, seht uns an:", "tokens": ["Ge\u00b7lieb\u00b7te", "Men\u00b7schen", ",", "seht", "uns", "an", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir waren todt, wir leben wieder.", "tokens": ["Wir", "wa\u00b7ren", "todt", ",", "wir", "le\u00b7ben", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie? da\u00df denn jemand zweifeln kan,", "tokens": ["Wie", "?", "da\u00df", "denn", "je\u00b7mand", "zwei\u00b7feln", "kan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KOUS", "ADV", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df auch dereinst nicht eure Glieder,", "tokens": ["Da\u00df", "auch", "de\u00b7reinst", "nicht", "eu\u00b7re", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ob gleich, wie wir, verweset und gestorben,", "tokens": ["Ob", "gleich", ",", "wie", "wir", ",", "ver\u00b7we\u00b7set", "und", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "PWAV", "PPER", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ob gleich, wie wir, vernichtigt und verdorben,", "tokens": ["Ob", "gleich", ",", "wie", "wir", ",", "ver\u00b7nich\u00b7tigt", "und", "ver\u00b7dor\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "PWAV", "PPER", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nicht auch, wie wir anietzt, aus Staub und Erden", "tokens": ["Nicht", "auch", ",", "wie", "wir", "an\u00b7ietzt", ",", "aus", "Staub", "und", "Er\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Erneuert auferstehen werden!", "tokens": ["Er\u00b7neu\u00b7ert", "auf\u00b7er\u00b7ste\u00b7hen", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie wird nicht euer Schmuck und Schein", "tokens": ["Wie", "wird", "nicht", "eu\u00b7er", "Schmuck", "und", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PTKNEG", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So dann viel herrlicher, als unsre Farben seyn!", "tokens": ["So", "dann", "viel", "herr\u00b7li\u00b7cher", ",", "als", "uns\u00b7re", "Far\u00b7ben", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "ADJA", "$,", "KOUS", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn ihr nur eure Pflicht, den Sch\u00f6pffer zu erh\u00f6hn,", "tokens": ["Wenn", "ihr", "nur", "eu\u00b7re", "Pflicht", ",", "den", "Sch\u00f6pf\u00b7fer", "zu", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Seine Wunder-Werck mit Andacht anzusehn,", "tokens": ["Und", "Sei\u00b7ne", "Wun\u00b7der\u00b7\u00b7Werck", "mit", "An\u00b7dacht", "an\u00b7zu\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auf dieser Welt in Acht genommen.", "tokens": ["Auf", "die\u00b7ser", "Welt", "in", "Acht", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "CARD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ach! sehet uns denn an, wie sch\u00f6n, wie Wunder-sch\u00f6n", "tokens": ["Ach", "!", "se\u00b7het", "uns", "denn", "an", ",", "wie", "sch\u00f6n", ",", "wie", "Wun\u00b7der\u00b7sch\u00f6n"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "PWAV", "ADJD", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sch\u00f6pffer uns aufs nen gebildet;", "tokens": ["Der", "Sch\u00f6pf\u00b7fer", "uns", "aufs", "nen", "ge\u00b7bil\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wie bunt Er uns gef\u00e4rbt, versilbert und verg\u00fcldet.", "tokens": ["Wie", "bunt", "Er", "uns", "ge\u00b7f\u00e4rbt", ",", "ver\u00b7sil\u00b7bert", "und", "ver\u00b7g\u00fcl\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "VVPP", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ja \u00fcberlegt dabey das Wunder, und bedencket,", "tokens": ["Ja", "\u00fc\u00b7ber\u00b7legt", "da\u00b7bey", "das", "Wun\u00b7der", ",", "und", "be\u00b7den\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "PAV", "ART", "NN", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df Er nun seit so langer Zeit", "tokens": ["Da\u00df", "Er", "nun", "seit", "so", "lan\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns alle Jahr ein neues Kleid,", "tokens": ["Uns", "al\u00b7le", "Jahr", "ein", "neu\u00b7es", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und einen neuen Leib geschencket,", "tokens": ["Und", "ei\u00b7nen", "neu\u00b7en", "Leib", "ge\u00b7schen\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zum Zeugni\u00df Seiner G\u00fctigkeit.", "tokens": ["Zum", "Zeug\u00b7ni\u00df", "Sei\u00b7ner", "G\u00fc\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "F\u00fcr wen bereiten sich doch unsre S\u00e4ffte?", "tokens": ["F\u00fcr", "wen", "be\u00b7rei\u00b7ten", "sich", "doch", "uns\u00b7re", "S\u00e4ff\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VVFIN", "PRF", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr wen sind wir an Farb\u2019 und an Geruch so reich?", "tokens": ["F\u00fcr", "wen", "sind", "wir", "an", "Fa\u00b7rb'", "und", "an", "Ge\u00b7ruch", "so", "reich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VAFIN", "PPER", "APPR", "NN", "KON", "APPR", "NN", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wir geben euch all\u2019 unsre Kr\u00e4ffte:", "tokens": ["Wir", "ge\u00b7ben", "euch", "all'", "uns\u00b7re", "Kr\u00e4ff\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Denn unsre Krafft dient uns nicht selbst, nur euch.", "tokens": ["Denn", "uns\u00b7re", "Krafft", "dient", "uns", "nicht", "selbst", ",", "nur", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir bl\u00fchen nicht f\u00fcr uns, f\u00fcr euch allein.", "tokens": ["Wir", "bl\u00fc\u00b7hen", "nicht", "f\u00fcr", "uns", ",", "f\u00fcr", "euch", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "$,", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ja wenn wir sagten, da\u00df die G\u00fcte", "tokens": ["Ja", "wenn", "wir", "sag\u00b7ten", ",", "da\u00df", "die", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "KOUS", "PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des Sch\u00f6pffers Selber in uns bl\u00fchte,", "tokens": ["Des", "Sch\u00f6pf\u00b7fers", "Sel\u00b7ber", "in", "uns", "bl\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Euch selbst durch den Geruch erquickte,", "tokens": ["Euch", "selbst", "durch", "den", "Ge\u00b7ruch", "er\u00b7quick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "F\u00fcr euch nur blo\u00df so sch\u00f6n uns schm\u00fcckte,", "tokens": ["F\u00fcr", "euch", "nur", "blo\u00df", "so", "sch\u00f6n", "uns", "schm\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ADV", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "W\u00fcrd\u2019 es vielleicht nicht unrecht seyn.", "tokens": ["W\u00fcrd'", "es", "viel\u00b7leicht", "nicht", "un\u00b7recht", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "NN", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Es sehe denn doch iederman", "tokens": ["Es", "se\u00b7he", "denn", "doch", "ie\u00b7der\u00b7man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Erd-Gew\u00e4chs\u2019 als so viel tausend Zeugen", "tokens": ["Die", "Erd\u00b7Ge\u00b7w\u00e4chs'", "als", "so", "viel", "tau\u00b7send", "Zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOKOM", "ADV", "ADV", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Liebe, G\u00fct\u2019 und Allmacht GOttes, an!", "tokens": ["Der", "Lie\u00b7be", ",", "G\u00fct'", "und", "All\u00b7macht", "Got\u00b7tes", ",", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}