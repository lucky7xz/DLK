{"dta.poem.11414": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Von dem elende des menschlichen lebens.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.71", "af:0.28"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Armseeliges gel\u00fccke!", "tokens": ["Arm\u00b7see\u00b7li\u00b7ges", "ge\u00b7l\u00fc\u00b7cke", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "++-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das auf der welt des menschen hertze trifft!", "tokens": ["Das", "auf", "der", "welt", "des", "men\u00b7schen", "hert\u00b7ze", "trifft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der donner unterbricht die sch\u00f6nsten sonnen-blicke:", "tokens": ["Der", "don\u00b7ner", "un\u00b7ter\u00b7bricht", "die", "sch\u00f6ns\u00b7ten", "son\u00b7nen\u00b7bli\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was man zucker nennt, ist offt das \u00e4rgste gifft:", "tokens": ["Und", "was", "man", "zu\u00b7cker", "nennt", ",", "ist", "offt", "das", "\u00e4rgs\u00b7te", "gifft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "VVFIN", "$,", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die sterne werden uns zu feurigen cometen,", "tokens": ["Die", "ster\u00b7ne", "wer\u00b7den", "uns", "zu", "feu\u00b7ri\u00b7gen", "co\u00b7me\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und die erfahrung zeigt: Da\u00df auch wohl engel t\u00f6den.", "tokens": ["Und", "die", "er\u00b7fah\u00b7rung", "zeigt", ":", "Da\u00df", "auch", "wohl", "en\u00b7gel", "t\u00f6\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "KOUS", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was sind die s\u00fcssen rosen,", "tokens": ["Was", "sind", "die", "s\u00fcs\u00b7sen", "ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wenn sie der dorn vor unsern h\u00e4nden sch\u00fctzt?", "tokens": ["Wenn", "sie", "der", "dorn", "vor", "un\u00b7sern", "h\u00e4n\u00b7den", "sch\u00fctzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADV", "APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der himmel pflegt uns zwar von ferne zu liebkosen;", "tokens": ["Der", "him\u00b7mel", "pflegt", "uns", "zwar", "von", "fer\u00b7ne", "zu", "lieb\u00b7ko\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kommt man ihm aber nah, so f\u00fchlt man, da\u00df er blitzt.", "tokens": ["Kommt", "man", "ihm", "a\u00b7ber", "nah", ",", "so", "f\u00fchlt", "man", ",", "da\u00df", "er", "blitzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADV", "ADJD", "$,", "ADV", "VVFIN", "PIS", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es baut der selbst-betrug nur schl\u00f6sser in die l\u00fcffte:", "tokens": ["Es", "baut", "der", "selbst\u00b7be\u00b7trug", "nur", "schl\u00f6s\u00b7ser", "in", "die", "l\u00fcff\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADJD", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn, eh\u2019 man es bedenckt, so sind es todten-gr\u00fcffte.", "tokens": ["Denn", ",", "eh'", "man", "es", "be\u00b7denckt", ",", "so", "sind", "es", "tod\u00b7ten\u00b7gr\u00fcff\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Des lebens erster morgen", "tokens": ["Des", "le\u00b7bens", "ers\u00b7ter", "mor\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Hebt sich bey uns mit bittren thr\u00e4nen an.", "tokens": ["Hebt", "sich", "bey", "uns", "mit", "bit\u00b7tren", "thr\u00e4\u00b7nen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ein ausgekrochner wurm wei\u00df vor sich selbst zu sorgen;", "tokens": ["Ein", "aus\u00b7ge\u00b7kroch\u00b7ner", "wurm", "wei\u00df", "vor", "sich", "selbst", "zu", "sor\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da der gebohrne mensch ihm gar nicht helffen kan:", "tokens": ["Da", "der", "ge\u00b7bohr\u00b7ne", "mensch", "ihm", "gar", "nicht", "helf\u00b7fen", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er lernt mit fallen gehn, und wird, wenn falsche freunde", "tokens": ["Er", "lernt", "mit", "fal\u00b7len", "gehn", ",", "und", "wird", ",", "wenn", "fal\u00b7sche", "freun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "VVINF", "VVINF", "$,", "KON", "VAFIN", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nicht seine hencker sind, ihm endlich selbst zum feinde.", "tokens": ["Nicht", "sei\u00b7ne", "hen\u00b7cker", "sind", ",", "ihm", "end\u00b7lich", "selbst", "zum", "fein\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "VAFIN", "$,", "PPER", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Man schwatzt wohl vom gel\u00fccke,", "tokens": ["Man", "schwatzt", "wohl", "vom", "ge\u00b7l\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und schreibet uns viel weg und mittel f\u00fcr;", "tokens": ["Und", "schrei\u00b7bet", "uns", "viel", "weg", "und", "mit\u00b7tel", "f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "NN", "APPR", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Allein der meister selbst weicht von der bahn zur\u00fccke:", "tokens": ["Al\u00b7lein", "der", "meis\u00b7ter", "selbst", "weicht", "von", "der", "bahn", "zu\u00b7r\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die vergn\u00fcgung kennt nur w\u00f6rter und papier.", "tokens": ["Und", "die", "ver\u00b7gn\u00fc\u00b7gung", "kennt", "nur", "w\u00f6r\u00b7ter", "und", "pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn ob ihr schatten gleich die lippen eingenommen;", "tokens": ["Denn", "ob", "ihr", "schat\u00b7ten", "gleich", "die", "lip\u00b7pen", "ein\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So ist ihr wesen doch nicht in das hertze kommen.", "tokens": ["So", "ist", "ihr", "we\u00b7sen", "doch", "nicht", "in", "das", "hert\u00b7ze", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die nelcken werden nesseln:", "tokens": ["Die", "nel\u00b7cken", "wer\u00b7den", "nes\u00b7seln", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der perlen pracht verwandelt sich in sand:", "tokens": ["Der", "per\u00b7len", "pracht", "ver\u00b7wan\u00b7delt", "sich", "in", "sand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die freyheit will uns selbst in enge bande fesseln:", "tokens": ["Die", "frey\u00b7heit", "will", "uns", "selbst", "in", "en\u00b7ge", "ban\u00b7de", "fes\u00b7seln", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nichts ist best\u00e4ndiger, als angst und unbestand.", "tokens": ["Nichts", "ist", "be\u00b7st\u00e4n\u00b7di\u00b7ger", ",", "als", "angst", "und", "un\u00b7be\u00b7stand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "$,", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die sonnen kommen uns geschwind aus dem gefichte;", "tokens": ["Die", "son\u00b7nen", "kom\u00b7men", "uns", "ge\u00b7schwind", "aus", "dem", "ge\u00b7fich\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADJD", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die wolcken aber macht nicht bald ein stern zunichte.", "tokens": ["Die", "wol\u00b7cken", "a\u00b7ber", "macht", "nicht", "bald", "ein", "stern", "zu\u00b7nich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Des menschen gantzes wesen", "tokens": ["Des", "men\u00b7schen", "gant\u00b7zes", "we\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Ist durch und durch mit unruh angef\u00fcllt:", "tokens": ["Ist", "durch", "und", "durch", "mit", "un\u00b7ruh", "an\u00b7ge\u00b7f\u00fcllt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "KON", "APPR", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man kan das ungel\u00fcck auf allen gliedern lesen,", "tokens": ["Man", "kan", "das", "un\u00b7ge\u00b7l\u00fcck", "auf", "al\u00b7len", "glie\u00b7dern", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil nichts zugegen ist, was die begierden stillt.", "tokens": ["Weil", "nichts", "zu\u00b7ge\u00b7gen", "ist", ",", "was", "die", "be\u00b7gier\u00b7den", "stillt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "$,", "PRELS", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn wenn ihm fu\u00df und hand schon alles vorgenommen:", "tokens": ["Denn", "wenn", "ihm", "fu\u00df", "und", "hand", "schon", "al\u00b7les", "vor\u00b7ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKVZ", "KON", "NN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So hat das hertze doch noch keine ruh bekommen.", "tokens": ["So", "hat", "das", "hert\u00b7ze", "doch", "noch", "kei\u00b7ne", "ruh", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Das auge mag fich sehnen,", "tokens": ["Das", "au\u00b7ge", "mag", "fich", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und unser mund nach der vergn\u00fcgung schreyn.", "tokens": ["Und", "un\u00b7ser", "mund", "nach", "der", "ver\u00b7gn\u00fc\u00b7gung", "schreyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die sehn-sucht badet sich gemeiniglich in thr\u00e4nen,", "tokens": ["Die", "sehn\u00b7sucht", "ba\u00b7det", "sich", "ge\u00b7mei\u00b7nig\u00b7lich", "in", "thr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ein vergebnes wort bringt nichts als seufftzer ein.", "tokens": ["Und", "ein", "ver\u00b7geb\u00b7nes", "wort", "bringt", "nichts", "als", "seufft\u00b7zer", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PIS", "KOKOM", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die lippen werden zwar von langem klagen m\u00fcde;", "tokens": ["Die", "lip\u00b7pen", "wer\u00b7den", "zwar", "von", "lan\u00b7gem", "kla\u00b7gen", "m\u00fc\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch diese mattigkeit ist noch kein hertzens-friede.", "tokens": ["Doch", "die\u00b7se", "mat\u00b7tig\u00b7keit", "ist", "noch", "kein", "hert\u00b7zens\u00b7frie\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die \u00e4ngstlichen gedancken", "tokens": ["Die", "\u00e4ngst\u00b7li\u00b7chen", "ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Verlassen uns auch in dem schlafe nicht.", "tokens": ["Ver\u00b7las\u00b7sen", "uns", "auch", "in", "dem", "schla\u00b7fe", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der menschen ungel\u00fcck ist ausser allen schrancken,", "tokens": ["Der", "men\u00b7schen", "un\u00b7ge\u00b7l\u00fcck", "ist", "aus\u00b7ser", "al\u00b7len", "schran\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "PIS", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Weil weder tag noch nacht sein w\u00fcten unterbricht.", "tokens": ["Weil", "we\u00b7der", "tag", "noch", "nacht", "sein", "w\u00fc\u00b7ten", "un\u00b7ter\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KON", "NN", "ADV", "VVPP", "VAINF", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die unruh, die uns plagt, ist allezeit daheime:", "tokens": ["Die", "un\u00b7ruh", ",", "die", "uns", "plagt", ",", "ist", "al\u00b7le\u00b7zeit", "da\u00b7hei\u00b7me", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und qu\u00e4lt das wachen nicht; so schrecken doch die tr\u00e4ume.", "tokens": ["Und", "qu\u00e4lt", "das", "wa\u00b7chen", "nicht", ";", "so", "schre\u00b7cken", "doch", "die", "tr\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "PTKNEG", "$.", "ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Kommt auch gleich eine stunde,", "tokens": ["Kommt", "auch", "gleich", "ei\u00b7ne", "stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die uns den schatz erw\u00fcnschter ruh verhei\u00dft;", "tokens": ["Die", "uns", "den", "schatz", "er\u00b7w\u00fcnschter", "ruh", "ver\u00b7hei\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "So dringt die lieblichkeit uns dennoch kaum zum munde,", "tokens": ["So", "dringt", "die", "lieb\u00b7lich\u00b7keit", "uns", "den\u00b7noch", "kaum", "zum", "mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "ADV", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn die verw\u00f6hnte brust schon wieder wermuth speist.", "tokens": ["Wenn", "die", "ver\u00b7w\u00f6hn\u00b7te", "brust", "schon", "wie\u00b7der", "wer\u00b7muth", "speist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die hoffnung spielt mit uns, als wie mit einem kinde,", "tokens": ["Die", "hoff\u00b7nung", "spielt", "mit", "uns", ",", "als", "wie", "mit", "ei\u00b7nem", "kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "$,", "KOUS", "KOKOM", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Setzt marmeladen vor, und f\u00fcllet uns mit winde.", "tokens": ["Setzt", "mar\u00b7me\u00b7la\u00b7den", "vor", ",", "und", "f\u00fcl\u00b7let", "uns", "mit", "win\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "O himmel und verh\u00e4ngni\u00df!", "tokens": ["O", "him\u00b7mel", "und", "ver\u00b7h\u00e4ng\u00b7ni\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Beschliest doch einst das lange trauerspiel!", "tokens": ["Be\u00b7schliest", "doch", "einst", "das", "lan\u00b7ge", "trau\u00b7er\u00b7spiel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Macht allem ungel\u00fcck ein schnelles leich-beg\u00e4ngni\u00df,", "tokens": ["Macht", "al\u00b7lem", "un\u00b7ge\u00b7l\u00fcck", "ein", "schnel\u00b7les", "leich\u00b7be\u00b7g\u00e4ng\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und gebt uns so viel ruh, als unser hertze will!", "tokens": ["Und", "gebt", "uns", "so", "viel", "ruh", ",", "als", "un\u00b7ser", "hert\u00b7ze", "will", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,", "KOUS", "PPOSAT", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zerst\u00f6rt den labyrinth der langsamen beschwerden,", "tokens": ["Zer\u00b7st\u00f6rt", "den", "la\u00b7by\u00b7rinth", "der", "lang\u00b7sa\u00b7men", "be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df erd und hertzen uns zu paradiesen werden!", "tokens": ["Da\u00df", "erd", "und", "hert\u00b7zen", "uns", "zu", "pa\u00b7ra\u00b7die\u00b7sen", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}