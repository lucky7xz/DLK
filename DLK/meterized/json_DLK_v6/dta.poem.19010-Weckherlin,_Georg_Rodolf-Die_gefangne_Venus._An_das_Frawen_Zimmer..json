{"dta.poem.19010": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Die gefangne Venus.  \n An das Frawen Zimmer.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Princessin/ deren ehr vnd liebliche geberden/", "tokens": ["Prin\u00b7ces\u00b7sin", "/", "de\u00b7ren", "ehr", "vnd", "lieb\u00b7li\u00b7che", "ge\u00b7ber\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PRELAT", "NN", "KON", "ADJA", "NN", "$("], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Vnd deren Tugent pracht ein Paradis auff erd\u1ebd/", "tokens": ["Vnd", "de\u00b7ren", "Tu\u00b7gent", "pracht", "ein", "Pa\u00b7ra\u00b7dis", "auff", "erd\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "VVFIN", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr deren leib vnd sehl an allen gaben reich", "tokens": ["Ihr", "de\u00b7ren", "leib", "vnd", "sehl", "an", "al\u00b7len", "ga\u00b7ben", "reich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "PRELAT", "NN", "KON", "ADV", "APPR", "PIS", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Seind vnvergleichlich gleich.", "tokens": ["Seind", "vn\u00b7ver\u00b7gleich\u00b7lich", "gleich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Jhr/ deren s\u00fcsse blick liebreich/ nach ewerm willen/", "tokens": ["Ihr", "/", "de\u00b7ren", "s\u00fcs\u00b7se", "blick", "lieb\u00b7reich", "/", "nach", "e\u00b7werm", "wil\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PRELAT", "ADJA", "NN", "ADJD", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Die sehlen kan mit trost oder mit forcht erfillen:", "tokens": ["Die", "seh\u00b7len", "kan", "mit", "trost", "o\u00b7der", "mit", "forcht", "er\u00b7fil\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "APPR", "NN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr deren angesicht der hertzen s\u00fcsse waid", "tokens": ["Ihr", "de\u00b7ren", "an\u00b7ge\u00b7sicht", "der", "hert\u00b7zen", "s\u00fcs\u00b7se", "waid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PDS", "VVPP", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kan stewren meinem layd:", "tokens": ["Kan", "stew\u00b7ren", "mei\u00b7nem", "layd", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Jhr G\u00f6ttin/ duldet nicht dz mein Kind da soll hang\u1ebd/", "tokens": ["Ihr", "G\u00f6t\u00b7tin", "/", "dul\u00b7det", "nicht", "dz", "mein", "Kind", "da", "soll", "hang\u1ebd", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VVFIN", "PTKNEG", "KOUS", "PPOSAT", "NN", "ADV", "VMFIN", "NE", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch dz Ich (G\u00f6ttin) selbs bleib sp\u00f6tlich hie gefang\u1ebd:", "tokens": ["Noch", "dz", "Ich", "(", "G\u00f6t\u00b7tin", ")", "selbs", "bleib", "sp\u00f6t\u00b7lich", "hie", "ge\u00b7fang\u1ebd", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "$(", "NE", "$(", "ADV", "VVFIN", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dan gr\u00f6sser meine Rew/ wan meine schuld ist gro\u00df/", "tokens": ["Dan", "gr\u00f6s\u00b7ser", "mei\u00b7ne", "Rew", "/", "wan", "mei\u00b7ne", "schuld", "ist", "gro\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$(", "PWAV", "PPOSAT", "ADJD", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So sprechet mich nu lo\u00df.", "tokens": ["So", "spre\u00b7chet", "mich", "nu", "lo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Mein weinen soll (hoff ich) bald ewer hertz erwarmen;", "tokens": ["Mein", "wei\u00b7nen", "soll", "(", "hoff", "ich", ")", "bald", "e\u00b7wer", "hertz", "er\u00b7war\u00b7men", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "VMFIN", "$(", "VVFIN", "PPER", "$(", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil der ellenden sich die Frawen gern erbarmen:", "tokens": ["Weil", "der", "el\u00b7len\u00b7den", "sich", "die", "Fra\u00b7wen", "gern", "er\u00b7bar\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "PRF", "ART", "NN", "ADV", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die hohe G\u00f6tter selbs auff eines s\u00fcnders rew", "tokens": ["Die", "ho\u00b7he", "G\u00f6t\u00b7ter", "selbs", "auff", "ei\u00b7nes", "s\u00fcn\u00b7ders", "rew"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der straff jhn lassen frey.", "tokens": ["Der", "straff", "jhn", "las\u00b7sen", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich schw\u00f6r bey ewrem haar/ darein die sehle\u0304 schwebe\u0304/", "tokens": ["Ich", "schw\u00f6r", "bey", "ew\u00b7rem", "haar", "/", "da\u00b7rein", "die", "sehl\u0113", "schwe\u00b7b\u0113", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "PAV", "ART", "XY", "XY", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ewerm exempel nach f\u00fcrhin stehts keusch zu leben/", "tokens": ["E\u00b7werm", "ex\u00b7em\u00b7pel", "nach", "f\u00fcr\u00b7hin", "stehts", "keusch", "zu", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Vnd vbergib zugleich in ewre wehrte hand", "tokens": ["Vnd", "vber\u00b7gib", "zu\u00b7gleich", "in", "ew\u00b7re", "wehr\u00b7te", "hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Mein Reich vnd macht zu pfand.", "tokens": ["Mein", "Reich", "vnd", "macht", "zu", "pfand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}