{"dta.poem.21841": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n  Blinzel-Mau\u00df.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Eins hab' ich noch bi\u00dfher verschwiegen", "tokens": ["Eins", "hab'", "ich", "noch", "bi\u00df\u00b7her", "ver\u00b7schwie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "auch wolt\u2019 ichs sagen nimm ermehr/", "tokens": ["auch", "wolt'", "ichs", "sa\u00b7gen", "nimm", "er\u00b7mehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVINF", "VVIMP", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie sich Florind\u2019 um Zucht und Ehr", "tokens": ["wie", "sich", "Flo\u00b7rind'", "um", "Zucht", "und", "Ehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "NN", "APPR", "NN", "KON", "NN"], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.4": {"text": "lie\u00df lieder-liederlich betriegen/", "tokens": ["lie\u00df", "lie\u00b7der\u00b7lie\u00b7der\u00b7lich", "be\u00b7trie\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVFIN", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "weil aber sie mich stets verachtt/", "tokens": ["weil", "a\u00b7ber", "sie", "mich", "stets", "ver\u00b7achtt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PRF", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die Sonne war zur See gegangen", "tokens": ["Die", "Son\u00b7ne", "war", "zur", "See", "ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die Lufft sach schwarzen Kohlen gleich.", "tokens": ["die", "Lufft", "sach", "schwar\u00b7zen", "Koh\u00b7len", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man merkte kaum der Sternen Reich", "tokens": ["Man", "merk\u00b7te", "kaum", "der", "Ster\u00b7nen", "Reich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und Zyntien verbla\u00dfte Wangen.", "tokens": ["und", "Zyn\u00b7tien", "ver\u00b7bla\u00df\u00b7te", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die Ober-Erde ging zur Ruh", "tokens": ["Die", "O\u00b7ber\u00b7Er\u00b7de", "ging", "zur", "Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und hatte Sinn und Augen zu.", "tokens": ["und", "hat\u00b7te", "Sinn", "und", "Au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Da kahm das stolze Tier Florinde", "tokens": ["Da", "kahm", "das", "stol\u00b7ze", "Tier", "Flo\u00b7rin\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "durch einen finstern Gang daher.", "tokens": ["durch", "ei\u00b7nen", "fins\u00b7tern", "Gang", "da\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich hatte mich gleich ungefehr", "tokens": ["Ich", "hat\u00b7te", "mich", "gleich", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "gestrekket auff ein Heu-geb\u00fcnde", "tokens": ["ge\u00b7strek\u00b7ket", "auff", "ein", "Heu\u00b7ge\u00b7b\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "als diese geile Sch\u00e4ffer-magd", "tokens": ["als", "die\u00b7se", "gei\u00b7le", "Sch\u00e4f\u00b7fer\u00b7magd"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Seid ihr allhier/ Chorambus/ sagt.", "tokens": ["Seid", "ihr", "all\u00b7hier", "/", "Cho\u00b7ram\u00b7bus", "/", "sagt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAIMP", "PPER", "ADV", "$(", "NE", "$(", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie hatte den/ der sich so nannte/", "tokens": ["Sie", "hat\u00b7te", "den", "/", "der", "sich", "so", "nann\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "$(", "PRELS", "PRF", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "den Abend auff den Ort bestellt:", "tokens": ["den", "A\u00b7bend", "auff", "den", "Ort", "be\u00b7stellt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die T\u00fchr war aber zugekrellt/", "tokens": ["die", "T\u00fchr", "war", "a\u00b7ber", "zu\u00b7ge\u00b7krellt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich/ der sie straks an Reden kannte/", "tokens": ["Ich", "/", "der", "sie", "straks", "an", "Re\u00b7den", "kann\u00b7te", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PRELS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Da h\u00e4ttstu Spr\u00fcnge sollen sehen/", "tokens": ["Da", "h\u00e4tts\u00b7tu", "Spr\u00fcn\u00b7ge", "sol\u00b7len", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wie sie so pl\u00f6zlich zu mir kahm/", "tokens": ["wie", "sie", "so", "pl\u00f6z\u00b7lich", "zu", "mir", "kahm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie sie mich in die Arme nahm:", "tokens": ["wie", "sie", "mich", "in", "die", "Ar\u00b7me", "nahm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich lie\u00df es unerkant geschehen/", "tokens": ["Ich", "lie\u00df", "es", "un\u00b7er\u00b7kant", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und k\u00fc\u00dft\u2019 als h\u00e4tt\u2019 ich grosse Lust", "tokens": ["und", "k\u00fc\u00dft'", "als", "h\u00e4tt'", "ich", "gros\u00b7se", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "VAFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "an ihr/ die ganz entbl\u00f6\u00dfte Brust.", "tokens": ["an", "ihr", "/", "die", "ganz", "ent\u00b7bl\u00f6\u00df\u00b7te", "Brust", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "$(", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Da war der Schaam nicht zugedenken.", "tokens": ["Da", "war", "der", "Schaam", "nicht", "zu\u00b7ge\u00b7den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie stekkte meine Hand wohin.", "tokens": ["Sie", "stekk\u00b7te", "mei\u00b7ne", "Hand", "wo\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich wundert/ da\u00df damaal mein Sinn", "tokens": ["Mich", "wun\u00b7dert", "/", "da\u00df", "da\u00b7maal", "mein", "Sinn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gelegenheit hat den Verstand", "tokens": ["Ge\u00b7le\u00b7gen\u00b7heit", "hat", "den", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "offt auff verbotne Lust gewannt.", "tokens": ["offt", "auff", "ver\u00b7bot\u00b7ne", "Lust", "ge\u00b7wannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch war di\u00df schlecht mich zuber\u00fckken.", "tokens": ["Doch", "war", "di\u00df", "schlecht", "mich", "zu\u00b7be\u00b7r\u00fck\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wei\u00df nicht/ was am Rokke hing/", "tokens": ["Ich", "wei\u00df", "nicht", "/", "was", "am", "Rok\u00b7ke", "hing", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PWS", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie mit grosser Brunst umfing.", "tokens": ["da\u00df", "sie", "mit", "gros\u00b7ser", "Brunst", "um\u00b7fing", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da h\u00f6rt\u2019 ich Seuffzer/ f\u00fchlt\u2019 ich dr\u00fckken.", "tokens": ["Da", "h\u00f6rt'", "ich", "Seuff\u00b7zer", "/", "f\u00fchlt'", "ich", "dr\u00fck\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$(", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was meine ihr/ w\u00e4re da geschehn", "tokens": ["Was", "mei\u00b7ne", "ihr", "/", "w\u00e4\u00b7re", "da", "ge\u00b7schehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$(", "VAFIN", "ADV", "VVINF"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "h\u00e4tt\u2019 ich auff Tugend nicht gesehn?", "tokens": ["h\u00e4tt'", "ich", "auff", "Tu\u00b7gend", "nicht", "ge\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Drum stie\u00df ich Sie gemach zur\u00fckke/", "tokens": ["Drum", "stie\u00df", "ich", "Sie", "ge\u00b7mach", "zu\u00b7r\u00fck\u00b7ke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "indehm so boll\u2019 in guter Stund\u2019", "tokens": ["in\u00b7dehm", "so", "boll'", "in", "gu\u00b7ter", "Stund'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Melampus/ unser Hirten Hund:", "tokens": ["Me\u00b7lam\u00b7pus", "/", "un\u00b7ser", "Hir\u00b7ten", "Hund", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und dieses war mein h\u00f6chstes Gl\u00fckke", "tokens": ["und", "die\u00b7ses", "war", "mein", "h\u00f6chs\u00b7tes", "Gl\u00fck\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df ich nicht ihr Chorambus war.", "tokens": ["da\u00df", "ich", "nicht", "ihr", "Cho\u00b7ram\u00b7bus", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Indehm sie zu dem Hunde ginge", "tokens": ["In\u00b7dehm", "sie", "zu", "dem", "Hun\u00b7de", "gin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und streichelnd ihn zufrieden sprach:", "tokens": ["und", "strei\u00b7chelnd", "ihn", "zu\u00b7frie\u00b7den", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "barg ich mich heimlich unters Dach/", "tokens": ["barg", "ich", "mich", "heim\u00b7lich", "un\u00b7ters", "Dach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "das \u00fcber einem Stalle hinge:", "tokens": ["das", "\u00fc\u00b7ber", "ei\u00b7nem", "Stal\u00b7le", "hin\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "weil sie mich nacher dar nicht fand", "tokens": ["weil", "sie", "mich", "na\u00b7cher", "dar", "nicht", "fand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKVZ", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "erhub sie sich ins Feder-land.", "tokens": ["er\u00b7hub", "sie", "sich", "ins", "Fe\u00b7der\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wer schleu\u00dft nu nicht au\u00df diesen allen/", "tokens": ["Wer", "schleu\u00dft", "nu", "nicht", "au\u00df", "die\u00b7sen", "al\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PTKNEG", "APPR", "PDAT", "PIAT", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Chorambus sey das erste mahl", "tokens": ["Cho\u00b7ram\u00b7bus", "sey", "das", "ers\u00b7te", "mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "nicht kommen in Florinden Stall/", "tokens": ["nicht", "kom\u00b7men", "in", "Flo\u00b7rin\u00b7den", "Stall", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und was f\u00fcr Heu alldar gefallen.", "tokens": ["und", "was", "f\u00fcr", "Heu", "all\u00b7dar", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer klug ist/ kan es leicht verstehn/", "tokens": ["Wer", "klug", "ist", "/", "kan", "es", "leicht", "ver\u00b7stehn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$(", "VMFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "was offt Florinden sey geschehn.", "tokens": ["was", "offt", "Flo\u00b7rin\u00b7den", "sey", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}