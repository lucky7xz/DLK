{"textgrid.poem.25486": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du, die das Gl\u00fcck auf meinem Wege", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du, die das Gl\u00fcck auf meinem Wege", "tokens": ["Du", ",", "die", "das", "Gl\u00fcck", "auf", "mei\u00b7nem", "We\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mich wie ein Goldst\u00fcck finden lie\u00df,", "tokens": ["Mich", "wie", "ein", "Gold\u00b7st\u00fcck", "fin\u00b7den", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOKOM", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von \u00e4chtem Korn' und reinestem Gepr\u00e4ge,", "tokens": ["Von", "\u00e4ch\u00b7tem", "Korn'", "und", "rei\u00b7nes\u00b7tem", "Ge\u00b7pr\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das aber nur das Gl\u00fcck mir wie\u00df;", "tokens": ["Das", "a\u00b7ber", "nur", "das", "Gl\u00fcck", "mir", "wie\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kaum lernt' ich deinen Werth recht kennen,", "tokens": ["Kaum", "lernt'", "ich", "dei\u00b7nen", "Werth", "recht", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So mu\u00df ich mich von dir schon wieder trennen,", "tokens": ["So", "mu\u00df", "ich", "mich", "von", "dir", "schon", "wie\u00b7der", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Weil mich zur\u00fcck zum Harz mein Schicksal gehen hie\u00df.", "tokens": ["Weil", "mich", "zu\u00b7r\u00fcck", "zum", "Harz", "mein", "Schick\u00b7sal", "ge\u00b7hen", "hie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKVZ", "APPRART", "NE", "PPOSAT", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo find' ich wieder solch Vertrauen", "tokens": ["Wo", "find'", "ich", "wie\u00b7der", "solch", "Ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und solche Duldung, als bei dir?", "tokens": ["Und", "sol\u00b7che", "Dul\u00b7dung", ",", "als", "bei", "dir", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "KOUS", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dort werden mich die M\u00e4nner und die Frauen", "tokens": ["Dort", "wer\u00b7den", "mich", "die", "M\u00e4n\u00b7ner", "und", "die", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Als fremde M\u00fcnze erst beschauen,", "tokens": ["Als", "frem\u00b7de", "M\u00fcn\u00b7ze", "erst", "be\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und denken: Hm! Was gibt man wohl daf\u00fcr?", "tokens": ["Und", "den\u00b7ken", ":", "Hm", "!", "Was", "gibt", "man", "wohl", "da\u00b7f\u00fcr", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$.", "ITJ", "$.", "PWS", "VVFIN", "PIS", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Zu lang im Cours, schliff sich die Inschrift ab,", "tokens": ["Zu", "lang", "im", "Cours", ",", "schliff", "sich", "die", "In\u00b7schrift", "ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "APPRART", "NN", "$,", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Dem Zehnten jetzt unleserliche Chiffern,", "tokens": ["Dem", "Zehn\u00b7ten", "jetzt", "un\u00b7le\u00b7ser\u00b7li\u00b7che", "Chif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Nur der, dem die Natur dein scharfes Auge gab,", "tokens": ["Nur", "der", ",", "dem", "die", "Na\u00b7tur", "dein", "schar\u00b7fes", "Au\u00b7ge", "gab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Kann den Avers und Revers leicht entziffern.", "tokens": ["Kann", "den", "A\u00b7vers", "und", "Re\u00b7vers", "leicht", "ent\u00b7zif\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "KON", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Ich lasse hier dich in der Freundschaft Bank", "tokens": ["Ich", "las\u00b7se", "hier", "dich", "in", "der", "Freund\u00b7schaft", "Bank"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Als Kapital zur\u00fcck; zufrieden", "tokens": ["Als", "Ka\u00b7pi\u00b7tal", "zu\u00b7r\u00fcck", ";", "zu\u00b7frie\u00b7den"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KOUS", "NN", "PTKVZ", "$.", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Mit halben Zinsen, und, dem Gl\u00fccke sey es Dank!", "tokens": ["Mit", "hal\u00b7ben", "Zin\u00b7sen", ",", "und", ",", "dem", "Gl\u00fc\u00b7cke", "sey", "es", "Dank", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "$,", "ART", "NN", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Verzehren wird mein Herz am Harze sie in Frieden.", "tokens": ["Ver\u00b7zeh\u00b7ren", "wird", "mein", "Herz", "am", "Har\u00b7ze", "sie", "in", "Frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "APPRART", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Kaum w\u00e4r' es zu verzeihn, \u2013 das hast du selbst gef\u00fchlt! \u2013", "tokens": ["Kaum", "w\u00e4r'", "es", "zu", "ver\u00b7zeihn", ",", "\u2013", "das", "hast", "du", "selbst", "ge\u00b7f\u00fchlt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKZU", "VVINF", "$,", "$(", "PDS", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wenn ich es nicht als Gl\u00fcck empf\u00e4nde,", "tokens": ["Wenn", "ich", "es", "nicht", "als", "Gl\u00fcck", "em\u00b7pf\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Da\u00df meine Rolle hier zu Ende,", "tokens": ["Da\u00df", "mei\u00b7ne", "Rol\u00b7le", "hier", "zu", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Nach zwei durchseufzten Jahren spielt;", "tokens": ["Nach", "zwei", "durch\u00b7seufz\u00b7ten", "Jah\u00b7ren", "spielt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Da\u00df nicht das Heimweh mehr in meinem Herzen w\u00fchlt,", "tokens": ["Da\u00df", "nicht", "das", "Heim\u00b7weh", "mehr", "in", "mei\u00b7nem", "Her\u00b7zen", "w\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und ich dem Schlaf' die N\u00e4chte wieder spende.", "tokens": ["Und", "ich", "dem", "Schlaf'", "die", "N\u00e4ch\u00b7te", "wie\u00b7der", "spen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Hier konnt' ich nicht der Freundschaft Freuden leben,", "tokens": ["Hier", "konnt'", "ich", "nicht", "der", "Freund\u00b7schaft", "Freu\u00b7den", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Und was ist dann das Leben werth?", "tokens": ["Und", "was", "ist", "dann", "das", "Le\u00b7ben", "werth", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Hier konnte mir die Flur nicht neue Kr\u00e4fte geben,", "tokens": ["Hier", "konn\u00b7te", "mir", "die", "Flur", "nicht", "neu\u00b7e", "Kr\u00e4f\u00b7te", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Wo Berg' und Wald mein sehnend Aug' entbehrt;", "tokens": ["Wo", "Ber\u00b7g'", "und", "Wald", "mein", "seh\u00b7nend", "Aug'", "ent\u00b7behrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NN", "PPOSAT", "CARD", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Zu nichts, als allenfalls um damit einzuheitzen,", "tokens": ["Zu", "nichts", ",", "als", "al\u00b7len\u00b7falls", "um", "da\u00b7mit", "ein\u00b7zu\u00b7heit\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "KOUS", "ADV", "APPR", "PAV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "War meine Harfe brauchbar hier,", "tokens": ["War", "mei\u00b7ne", "Har\u00b7fe", "brauch\u00b7bar", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Was half's, mit meinen Stunden geitzen?", "tokens": ["Was", "ha\u00b7lf's", ",", "mit", "mei\u00b7nen", "Stun\u00b7den", "geit\u00b7zen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.34": {"text": "Wie selten ward f\u00fcr dich nur Eine mir!", "tokens": ["Wie", "sel\u00b7ten", "ward", "f\u00fcr", "dich", "nur", "Ei\u00b7ne", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "APPR", "PPER", "ADV", "ART", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Bin ich zum Eremitenleben", "tokens": ["Bin", "ich", "zum", "E\u00b7re\u00b7mi\u00b7ten\u00b7le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Bestimmt, so mag's am Harze seyn!", "tokens": ["Be\u00b7stimmt", ",", "so", "mag's", "am", "Har\u00b7ze", "seyn", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "NE", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Da wird der Genius der Ruhe mich umschweben,", "tokens": ["Da", "wird", "der", "Ge\u00b7nius", "der", "Ru\u00b7he", "mich", "um\u00b7schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.38": {"text": "Und noch einmal vielleicht mir seine Harfe leihn.", "tokens": ["Und", "noch", "ein\u00b7mal", "viel\u00b7leicht", "mir", "sei\u00b7ne", "Har\u00b7fe", "leihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.39": {"text": "Da werd' ich oft am Bach' im Walde dein gedenken,", "tokens": ["Da", "werd'", "ich", "oft", "am", "Bach'", "im", "Wal\u00b7de", "dein", "ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPRART", "NN", "APPRART", "NN", "PPOSAT", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Vergi\u00dfmeinnicht mit Sehnsuchtsz\u00e4hren tr\u00e4nken,", "tokens": ["Ver\u00b7gi\u00df\u00b7mein\u00b7nicht", "mit", "Sehn\u00b7suchts\u00b7z\u00e4h\u00b7ren", "tr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.41": {"text": "Sie in des Baches Kr\u00e4usel streun,", "tokens": ["Sie", "in", "des", "Ba\u00b7ches", "Kr\u00e4u\u00b7sel", "streun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Den tr\u00fcben Blick hinab zu ihnen senken,", "tokens": ["Den", "tr\u00fc\u00b7ben", "Blick", "hin\u00b7ab", "zu", "ih\u00b7nen", "sen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Und dann im Geiste bei dir seyn.", "tokens": ["Und", "dann", "im", "Geis\u00b7te", "bei", "dir", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "APPR", "PPER", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}