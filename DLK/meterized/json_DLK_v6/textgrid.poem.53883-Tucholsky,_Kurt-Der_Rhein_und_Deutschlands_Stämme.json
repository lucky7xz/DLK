{"textgrid.poem.53883": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der Rhein und Deutschlands St\u00e4mme", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es flie\u00dft ein Strom durch das deutsche Land,", "tokens": ["Es", "flie\u00dft", "ein", "Strom", "durch", "das", "deut\u00b7sche", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "drin spiegeln sich Schl\u00f6sser und Zinnen;", "tokens": ["drin", "spie\u00b7geln", "sich", "Schl\u00f6s\u00b7ser", "und", "Zin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "er ist in den deutschen Gauen bekannt,", "tokens": ["er", "ist", "in", "den", "deut\u00b7schen", "Gau\u00b7en", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "kein Refrain kann demselben entrinnen.", "tokens": ["kein", "Re\u00b7frain", "kann", "dem\u00b7sel\u00b7ben", "ent\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PDS", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und alle Romantik hat hier ihr Revier,", "tokens": ["Und", "al\u00b7le", "Ro\u00b7man\u00b7tik", "hat", "hier", "ihr", "Re\u00b7vier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "und je lauter das Rheinlied, je k\u00e4lter das Bier", "tokens": ["und", "je", "lau\u00b7ter", "das", "Rhein\u00b7lied", ",", "je", "k\u00e4l\u00b7ter", "das", "Bier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "ART", "NN", "$,", "ADV", "ADJD", "ART", "NN"], "meter": "-++--+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "der kleinen und gro\u00dfen Verdiener.", "tokens": ["der", "klei\u00b7nen", "und", "gro\u00b7\u00dfen", "Ver\u00b7die\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Zum Beispiel so der Berliner:", "tokens": ["Zum", "Bei\u00b7spiel", "so", "der", "Ber\u00b7li\u00b7ner", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "ADJA", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.9": {"text": "\u00bbein rheinischet Meechen \u2013 beim rheinischen Wein \u2013", "tokens": ["\u00bb", "ein", "rhei\u00b7ni\u00b7schet", "Mee\u00b7chen", "\u2013", "beim", "rhei\u00b7ni\u00b7schen", "Wein", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "VVFIN", "NN", "$(", "APPRART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.10": {"text": "Ja, Donnerwetter nich noch mal!", "tokens": ["Ja", ",", "Don\u00b7ner\u00b7wet\u00b7ter", "nich", "noch", "mal", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Na, det mu\u00df ja der H\u00fcmmel auf Erdn sein \u2013!", "tokens": ["Na", ",", "det", "mu\u00df", "ja", "der", "H\u00fcm\u00b7mel", "auf", "Erdn", "sein", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "PDS", "VMFIN", "ADV", "ART", "NN", "APPR", "NN", "VAINF", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Wat, Lucie \u2013?\u00ab", "tokens": ["Wat", ",", "Lu\u00b7cie", "\u2013", "?", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "NE", "$(", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Wer Lieder f\u00fcr Operetten schreibt", "tokens": ["Wer", "Lie\u00b7der", "f\u00fcr", "O\u00b7per\u00b7et\u00b7ten", "schreibt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "APPR", "NN", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "aus Prag, aus Wien und aus Bentschen \u2013:", "tokens": ["aus", "Prag", ",", "aus", "Wi\u00b7en", "und", "aus", "Bent\u00b7schen", "\u2013", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "NE", "KON", "APPR", "NE", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "den Rhein m\u00f6cht ich sehn, der da ungereimt bleibt \u2013", "tokens": ["den", "Rhein", "m\u00f6cht", "ich", "sehn", ",", "der", "da", "un\u00b7ge\u00b7reimt", "bleibt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "PPER", "VVINF", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "es sind halt geschickte Menschen!", "tokens": ["es", "sind", "halt", "ge\u00b7schick\u00b7te", "Men\u00b7schen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Und was sie dichten, ganz Deutschland gr\u00f6lts,", "tokens": ["Und", "was", "sie", "dich\u00b7ten", ",", "ganz", "Deutschland", "gr\u00f6lts", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJA", "$,", "ADV", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "von Aachen bis Dirschau, von Kiel bis nach \u00d6lz;", "tokens": ["von", "Aa\u00b7chen", "bis", "Dir\u00b7schau", ",", "von", "Kiel", "bis", "nach", "\u00d6lz", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$,", "APPR", "NE", "ADV", "APPR", "NE", "$."], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "wo nur Treue und Weinbrand wachsen.", "tokens": ["wo", "nur", "Treu\u00b7e", "und", "Wein\u00b7brand", "wach\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Zum Beispiel so unsere Sachsen:", "tokens": ["Zum", "Bei\u00b7spiel", "so", "un\u00b7se\u00b7re", "Sach\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.9": {"text": "\u00bbein rheinisches M\u00e4dchen \u2013 beim rheinischen Wein \u2013", "tokens": ["\u00bb", "ein", "rhei\u00b7ni\u00b7sches", "M\u00e4d\u00b7chen", "\u2013", "beim", "rhei\u00b7ni\u00b7schen", "Wein", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$(", "APPRART", "ADJA", "NN", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.10": {"text": "Nu heere mal, Agahde, was hasdn dn", "tokens": ["Nu", "hee\u00b7re", "mal", ",", "A\u00b7gah\u00b7de", ",", "was", "hasdn", "dn"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "$,", "NN", "$,", "PRELS", "XY", "XY"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Krachenschonr nich midgenomm? 's is doch", "tokens": ["Kra\u00b7chen\u00b7schonr", "nich", "mid\u00b7ge\u00b7nomm", "?", "'s", "is", "doch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "VVFIN", "$.", "PPER", "FM", "ADV"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "so giehle uffm Wasser?", "tokens": ["so", "gieh\u00b7le", "uffm", "Was\u00b7ser", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Di\u00df mu\u00df ja der Himmel auf Erden sein!", "tokens": ["Di\u00df", "mu\u00df", "ja", "der", "Him\u00b7mel", "auf", "Er\u00b7den", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ART", "NN", "APPR", "NN", "VAINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Eicha . . . !\u00ab", "tokens": ["Eic\u00b7ha", ".", ".", ".", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct"], "pos": ["NE", "$.", "$.", "$.", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "Im Rhein, da quillt unsere Mannesbrust,", "tokens": ["Im", "Rhein", ",", "da", "quillt", "un\u00b7se\u00b7re", "Man\u00b7nes\u00b7brust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da liegen dicke Tantiemen;", "tokens": ["da", "lie\u00b7gen", "di\u00b7cke", "Tan\u00b7tie\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "und bef\u00e4llt den Deutschen die Sangeslust:", "tokens": ["und", "be\u00b7f\u00e4llt", "den", "Deut\u00b7schen", "die", "San\u00b7ges\u00b7lust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "hier kann er das Ding unternehmen.", "tokens": ["hier", "kann", "er", "das", "Ding", "un\u00b7ter\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es reimt sich der Rhein", "tokens": ["Es", "reimt", "sich", "der", "Rhein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NE"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "auf Schein und auf Sein", "tokens": ["auf", "Schein", "und", "auf", "Sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "PPOSAT"], "meter": "-+-++", "measure": "unknown.measure.tri"}, "line.7": {"text": "und auf mein und auf dein,", "tokens": ["und", "auf", "mein", "und", "auf", "dein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "KON", "APPR", "PPOSAT", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "auf J\u00fcngferlein, Stelldichein, G\u00e4nseklein . . .", "tokens": ["auf", "J\u00fcng\u00b7fer\u00b7lein", ",", "Stell\u00b7dich\u00b7ein", ",", "G\u00e4n\u00b7se\u00b7klein", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$.", "$.", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Und ist auch zerkl\u00fcftet das Deutsche Reich:", "tokens": ["Und", "ist", "auch", "zer\u00b7kl\u00fcf\u00b7tet", "das", "Deut\u00b7sche", "Reich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "im Moorbad der Lyrik verstehn sie sich gleich.", "tokens": ["im", "Mo\u00b7or\u00b7bad", "der", "Ly\u00b7rik", "ver\u00b7stehn", "sie", "sich", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Viel schneller als bei Richard Dehmel.", "tokens": ["Viel", "schnel\u00b7ler", "als", "bei", "Ric\u00b7hard", "Deh\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zum Beispiel so jener aus Memel:", "tokens": ["Zum", "Bei\u00b7spiel", "so", "je\u00b7ner", "aus", "Me\u00b7mel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PDAT", "APPR", "NE", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bb\u00e4in rh\u00e4inisches M\u00e4dchen \u2013 b\u00e4im rh\u00e4inischen W\u00e4in \u2013", "tokens": ["\u00bb", "\u00e4\u00b7in", "rh\u00e4\u00b7i\u00b7ni\u00b7sches", "M\u00e4d\u00b7chen", "\u2013", "b\u00e4\u00b7im", "rh\u00e4\u00b7i\u00b7ni\u00b7schen", "W\u00e4in", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "ADJA", "NN", "$(", "APPRART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.6": {"text": "\u00e4i, das mu\u00df ja der Himmel \u2013 auf Erden s\u00e4in \u2013", "tokens": ["\u00e4\u00b7i", ",", "das", "mu\u00df", "ja", "der", "Him\u00b7mel", "\u2013", "auf", "Er\u00b7den", "s\u00e4\u00b7in", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "$,", "PDS", "VMFIN", "ADV", "ART", "NN", "$(", "APPR", "NN", "NE", "$("], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.7": {"text": "W\u00e4i\u00dft, wenn dir der W\u00e4in nich schmeckt,", "tokens": ["W\u00e4i\u00dft", ",", "wenn", "dir", "der", "W\u00e4in", "nich", "schmeckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "jie\u00df noch 'n kl\u00e4in Schnaps-che r\u00e4in! \u2013", "tokens": ["jie\u00df", "noch", "'n", "kl\u00e4\u00b7in", "Schnaps\u00b7che", "r\u00e4\u00b7in", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "\u00c4i, das mu\u00df ja der Himmel auf Erden s\u00e4in \u2013!", "tokens": ["\u00c4\u00b7i", ",", "das", "mu\u00df", "ja", "der", "Him\u00b7mel", "auf", "Er\u00b7den", "s\u00e4\u00b7in", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "PDS", "VMFIN", "ADV", "ART", "NN", "APPR", "NN", "NE", "$(", "$."], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.10": {"text": "Oder m\u00e4inst n\u00e4in \u2013?\u00ab", "tokens": ["O\u00b7der", "m\u00e4\u00b7inst", "n\u00e4\u00b7in", "\u2013", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "$(", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "So ist der Rheinstrom ohne Fehle,", "tokens": ["So", "ist", "der", "Rhein\u00b7strom", "oh\u00b7ne", "Feh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das Familienbad der deutschen Seele.", "tokens": ["das", "Fa\u00b7mi\u00b7li\u00b7en\u00b7bad", "der", "deut\u00b7schen", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}