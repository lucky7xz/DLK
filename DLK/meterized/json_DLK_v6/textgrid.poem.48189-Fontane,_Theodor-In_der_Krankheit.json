{"textgrid.poem.48189": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "In der Krankheit", "genre": "verse", "period": "N.A.", "pub_year": 1853, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein ganzes Zimmer riecht nach Wald,", "tokens": ["Mein", "gan\u00b7zes", "Zim\u00b7mer", "riecht", "nach", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das machen die kienenen Tische,", "tokens": ["Das", "ma\u00b7chen", "die", "kie\u00b7ne\u00b7nen", "Ti\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Glaub mir, ich mu\u00df genesen bald", "tokens": ["Glaub", "mir", ",", "ich", "mu\u00df", "ge\u00b7ne\u00b7sen", "bald"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "PPER", "VMFIN", "ADV", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "In dieser Harzesfrische.", "tokens": ["In", "die\u00b7ser", "Har\u00b7zes\u00b7fri\u00b7sche", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Du bist noch kaum bei uns daheim", "tokens": ["Du", "bist", "noch", "kaum", "bei", "uns", "da\u00b7heim"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An unsres Kindes Bettchen,", "tokens": ["An", "uns\u00b7res", "Kin\u00b7des", "Bett\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sieh, schon sitzt ein muntrer Reim", "tokens": ["Und", "sieh", ",", "schon", "sitzt", "ein", "mun\u00b7trer", "Reim"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf meinem Fensterbrettchen.", "tokens": ["Auf", "mei\u00b7nem", "Fens\u00b7ter\u00b7brett\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Er sitzt allda und schaut mich an", "tokens": ["Er", "sitzt", "all\u00b7da", "und", "schaut", "mich", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "KON", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie auf dem Felde die Lerchen", "tokens": ["Wie", "auf", "dem", "Fel\u00b7de", "die", "Ler\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Und singt: \u00bbDu hast ganz wohlgetan,", "tokens": ["Und", "singt", ":", "\u00bb", "Du", "hast", "ganz", "wohl\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dich still hier einzupferchen.", "tokens": ["Dich", "still", "hier", "ein\u00b7zu\u00b7pfer\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Steh nur fr\u00fch auf und schweif umher", "tokens": ["Steh", "nur", "fr\u00fch", "auf", "und", "schweif", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "PTKVZ", "KON", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und lache wie der Morgen,", "tokens": ["Und", "la\u00b7che", "wie", "der", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So wird dies gr\u00fcne Waldesmeer", "tokens": ["So", "wird", "dies", "gr\u00fc\u00b7ne", "Wal\u00b7des\u00b7meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schon weiter f\u00fcr dich sorgen.", "tokens": ["Schon", "wei\u00b7ter", "f\u00fcr", "dich", "sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und schiedst du ", "tokens": ["Und", "schiedst", "du"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "So tu es ohne Trauern,", "tokens": ["So", "tu", "es", "oh\u00b7ne", "Trau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das Leben, weil so sch\u00f6n es ist,", "tokens": ["Das", "Le\u00b7ben", ",", "weil", "so", "sch\u00f6n", "es", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "ADV", "ADJD", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann es nicht ewig dauern.\u00ab", "tokens": ["Kann", "es", "nicht", "e\u00b7wig", "dau\u00b7ern", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}