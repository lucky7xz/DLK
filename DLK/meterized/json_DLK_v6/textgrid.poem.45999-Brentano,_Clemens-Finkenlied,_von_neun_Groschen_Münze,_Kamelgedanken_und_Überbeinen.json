{"textgrid.poem.45999": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Finkenlied, von neun Groschen M\u00fcnze, Kamelgedanken und \u00dcberbeinen", "genre": "verse", "period": "N.A.", "pub_year": 1817, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vom Gesange lust'ger Finken", "tokens": ["Vom", "Ge\u00b7san\u00b7ge", "lust'\u00b7ger", "Fin\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch das Fenster aufgeweckt", "tokens": ["Durch", "das", "Fens\u00b7ter", "auf\u00b7ge\u00b7weckt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasse ich den Schleier sinken,", "tokens": ["Las\u00b7se", "ich", "den", "Schlei\u00b7er", "sin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der mir meine Seele deckt.", "tokens": ["Der", "mir", "mei\u00b7ne", "See\u00b7le", "deckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Durch des alten Birnbaums Bl\u00fcten", "tokens": ["Durch", "des", "al\u00b7ten", "Birn\u00b7baums", "Bl\u00fc\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schaut zwar tr\u00fcber Himmel her", "tokens": ["Schaut", "zwar", "tr\u00fc\u00b7ber", "Him\u00b7mel", "her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "APZR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch in meiner Brust ist Frieden,", "tokens": ["Doch", "in", "mei\u00b7ner", "Brust", "ist", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ach wenn's doch der ew'ge w\u00e4r'.", "tokens": ["Ach", "wenn's", "doch", "der", "ew'\u00b7ge", "w\u00e4r'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PIS", "ADV", "ART", "ADJA", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Nein, jetzt kann ich gar nicht trauern", "tokens": ["Nein", ",", "jetzt", "kann", "ich", "gar", "nicht", "trau\u00b7ern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles scheint mir lieb und gut,", "tokens": ["Al\u00b7les", "scheint", "mir", "lieb", "und", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mir w\u00e4chst da \u00fcberm Lauern", "tokens": ["Und", "mir", "w\u00e4chst", "da", "\u00fc\u00b7berm", "Lau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Auch ein Finkenliedermut.", "tokens": ["Auch", "ein", "Fin\u00b7ken\u00b7lie\u00b7der\u00b7mut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie die kleinen S\u00e4nger schweben", "tokens": ["Wie", "die", "klei\u00b7nen", "S\u00e4n\u00b7ger", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie es sehnt und lockt und zirpt.", "tokens": ["Wie", "es", "sehnt", "und", "lockt", "und", "zirpt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "O wie herrlich klingt das Leben", "tokens": ["O", "wie", "herr\u00b7lich", "klingt", "das", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ADJD", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn's zu neuem Leben wirbt.", "tokens": ["Wenn's", "zu", "neu\u00b7em", "Le\u00b7ben", "wirbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Keiner f\u00e4llt ohn' Gottes Willen", "tokens": ["Kei\u00b7ner", "f\u00e4llt", "ohn'", "Got\u00b7tes", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem Dach, vom Haupt kein Haar,", "tokens": ["Von", "dem", "Dach", ",", "vom", "Haupt", "kein", "Haar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPRART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mein Schmerz l\u00e4\u00dft sich schon stillen,", "tokens": ["Und", "mein", "Schmerz", "l\u00e4\u00dft", "sich", "schon", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil ich einst unschuldig war.", "tokens": ["Weil", "ich", "einst", "un\u00b7schul\u00b7dig", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und bin ich gleich abgefallen", "tokens": ["Und", "bin", "ich", "gleich", "ab\u00b7ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fiel ich doch in Gottes Scho\u00df", "tokens": ["Fiel", "ich", "doch", "in", "Got\u00b7tes", "Scho\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lieg' da mit den andern allen", "tokens": ["Lieg'", "da", "mit", "den", "an\u00b7dern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "APPR", "ART", "ADJA", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heil in seiner Gnade gro\u00df.", "tokens": ["Heil", "in", "sei\u00b7ner", "Gna\u00b7de", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Munter, Herz, schwing dein Gefieder", "tokens": ["Mun\u00b7ter", ",", "Herz", ",", "schwing", "dein", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf, wohl auf zum Kreuzesbaum", "tokens": ["Auf", ",", "wohl", "auf", "zum", "Kreu\u00b7zes\u00b7baum"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$,", "ADV", "APPR", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "T\u00e4glich Sonne, t\u00e4glich Lieder,", "tokens": ["T\u00e4g\u00b7lich", "Son\u00b7ne", ",", "t\u00e4g\u00b7lich", "Lie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Nacht ein frommer Traum!", "tokens": ["Al\u00b7le", "Nacht", "ein", "from\u00b7mer", "Traum", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und ein Nest in seine Wunden", "tokens": ["Und", "ein", "Nest", "in", "sei\u00b7ne", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner Leidensbrut ich bau',", "tokens": ["Mei\u00b7ner", "Lei\u00b7dens\u00b7brut", "ich", "bau'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gr\u00fcn liegt seine Erde unten", "tokens": ["Gr\u00fcn", "liegt", "sei\u00b7ne", "Er\u00b7de", "un\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oben schwebt sein Himmel blau.", "tokens": ["O\u00b7ben", "schwebt", "sein", "Him\u00b7mel", "blau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Und ich seh' auf gr\u00fcner Aue", "tokens": ["Und", "ich", "seh'", "auf", "gr\u00fc\u00b7ner", "Au\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine fromme Magd hinziehn", "tokens": ["Ei\u00b7ne", "from\u00b7me", "Magd", "hin\u00b7ziehn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Primlen bricht sie schwer vom Taue,", "tokens": ["Prim\u00b7len", "bricht", "sie", "schwer", "vom", "Tau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis der j\u00fcngste Tag erschien.", "tokens": ["Bis", "der", "j\u00fcngs\u00b7te", "Tag", "er\u00b7schien", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Bricht die Blumen, bricht die Bl\u00fcte", "tokens": ["Bricht", "die", "Blu\u00b7men", ",", "bricht", "die", "Bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bricht ihr Herz, die Heilandsfrucht", "tokens": ["Bricht", "ihr", "Herz", ",", "die", "Hei\u00b7lands\u00b7frucht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bietet es dem Gott der G\u00fcte", "tokens": ["Bie\u00b7tet", "es", "dem", "Gott", "der", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der den d\u00fcrren Baum verflucht.", "tokens": ["Der", "den", "d\u00fcr\u00b7ren", "Baum", "ver\u00b7flucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Und sie spricht mit schwerem Herzen", "tokens": ["Und", "sie", "spricht", "mit", "schwe\u00b7rem", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gestern war mein Leiden schwer,", "tokens": ["Ge\u00b7stern", "war", "mein", "Lei\u00b7den", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und ich fragte sie mit Schmerzen", "tokens": ["Und", "ich", "frag\u00b7te", "sie", "mit", "Schmer\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ihr dann begegnet w\u00e4r'.", "tokens": ["Was", "ihr", "dann", "be\u00b7geg\u00b7net", "w\u00e4r'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Bange zagten meine Ohren,", "tokens": ["Ban\u00b7ge", "zag\u00b7ten", "mei\u00b7ne", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was sie wohl f\u00fcr Leid angiebt,", "tokens": ["Was", "sie", "wohl", "f\u00fcr", "Leid", "an\u00b7giebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil neun Groschen ich verloren,", "tokens": ["Weil", "neun", "Gro\u00b7schen", "ich", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sagt sie, bin ich so betr\u00fcbt.", "tokens": ["Sagt", "sie", ",", "bin", "ich", "so", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "War's Courant? \u2013 Ei Gott beh\u00fcte,", "tokens": ["Wa\u00b7r's", "Cou\u00b7rant", "?", "\u2013", "Ei", "Gott", "be\u00b7h\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$.", "$(", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "M\u00fcnze war's, dem Herrn sei Dank! \u2013", "tokens": ["M\u00fcn\u00b7ze", "wa\u00b7r's", ",", "dem", "Herrn", "sei", "Dank", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "$,", "ART", "NN", "VAFIN", "NN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "O du Spiegel aller G\u00fcte!", "tokens": ["O", "du", "Spie\u00b7gel", "al\u00b7ler", "G\u00fc\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Machst du mich doch freudenkrank.", "tokens": ["Machst", "du", "mich", "doch", "freu\u00b7den\u00b7krank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Denk, vom Dache f\u00e4llt kein Sperling,", "tokens": ["Denk", ",", "vom", "Da\u00b7che", "f\u00e4llt", "kein", "Sper\u00b7ling", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPRART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ohne Gott, vom Haupt kein Haar,", "tokens": ["Oh\u00b7ne", "Gott", ",", "vom", "Haupt", "kein", "Haar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPRART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus dem Beutel kein Pfund Sterling,", "tokens": ["Aus", "dem", "Beu\u00b7tel", "kein", "Pfund", "Ster\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "NN", "$,"], "meter": "--+--++-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Oder auch neun Groschen bar.", "tokens": ["O\u00b7der", "auch", "neun", "Gro\u00b7schen", "bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Denk, was hatt' ich all verloren", "tokens": ["Denk", ",", "was", "hatt'", "ich", "all", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWS", "VAFIN", "PPER", "PIAT", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leib und Seel und Gut und Heil", "tokens": ["Leib", "und", "Seel", "und", "Gut", "und", "Heil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "KON", "ADJD", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles ward mir neu geboren", "tokens": ["Al\u00b7les", "ward", "mir", "neu", "ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und noch mehr ward mir zuteil.", "tokens": ["Und", "noch", "mehr", "ward", "mir", "zu\u00b7teil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.16": {"line.1": {"text": "Dich zu kennen, dich zu lieben,", "tokens": ["Dich", "zu", "ken\u00b7nen", ",", "dich", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dir zu folgen treu und still,", "tokens": ["Dir", "zu", "fol\u00b7gen", "treu", "und", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was mir wird, was mir geblieben,", "tokens": ["Was", "mir", "wird", ",", "was", "mir", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles ich dir teilen will.", "tokens": ["Al\u00b7les", "ich", "dir", "tei\u00b7len", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Leben, K\u00e4mpfen, Siegen, Sterben", "tokens": ["Le\u00b7ben", ",", "K\u00e4mp\u00b7fen", ",", "Sie\u00b7gen", ",", "Ster\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Abendrot und Morgenrot,", "tokens": ["A\u00b7ben\u00b7drot", "und", "Mor\u00b7gen\u00b7rot", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mitleid mit den armen Erben,", "tokens": ["Mit\u00b7leid", "mit", "den", "ar\u00b7men", "Er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Ihnen bleibt die Erdennot.", "tokens": ["Ih\u00b7nen", "bleibt", "die", "Er\u00b7den\u00b7not", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Als die Magd mein Lied vernommen", "tokens": ["Als", "die", "Magd", "mein", "Lied", "ver\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat sie freundlich mir genickt,", "tokens": ["Hat", "sie", "freund\u00b7lich", "mir", "ge\u00b7nickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Nebel schien verschwommen,", "tokens": ["Und", "der", "Ne\u00b7bel", "schien", "ver\u00b7schwom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ein bi\u00dfchen Sonne blickt.", "tokens": ["Und", "ein", "bi\u00df\u00b7chen", "Son\u00b7ne", "blickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "O lieb Herz! um Jesu willen", "tokens": ["O", "lieb", "Herz", "!", "um", "Je\u00b7su", "wil\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJD", "NN", "$.", "APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fasse einen frischen Mut", "tokens": ["Fas\u00b7se", "ei\u00b7nen", "fri\u00b7schen", "Mut"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df dich doch sein Herzblut stillen", "tokens": ["La\u00df", "dich", "doch", "sein", "Herz\u00b7blut", "stil\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bist ja Pelikanenbrut.", "tokens": ["Bist", "ja", "Pe\u00b7li\u00b7ka\u00b7nen\u00b7brut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Himmel, Himmel werd' doch heiter,", "tokens": ["Him\u00b7mel", ",", "Him\u00b7mel", "werd'", "doch", "hei\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, herrje! da regnet's gar!", "tokens": ["Ach", ",", "herr\u00b7je", "!", "da", "reg\u00b7net's", "gar", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "$.", "ADV", "VVFIN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Liebe Finklein, singt doch weiter,", "tokens": ["Lie\u00b7be", "Fin\u00b7klein", ",", "singt", "doch", "wei\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da versteckte sich die Schar.", "tokens": ["Da", "ver\u00b7steck\u00b7te", "sich", "die", "Schar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.21": {"line.1": {"text": "Liebes, liebes Linum denke", "tokens": ["Lie\u00b7bes", ",", "lie\u00b7bes", "Li\u00b7num", "den\u00b7ke"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An neun Groschen M\u00fcnze nicht.", "tokens": ["An", "neun", "Gro\u00b7schen", "M\u00fcn\u00b7ze", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch sie spricht: zur Erde senke", "tokens": ["Doch", "sie", "spricht", ":", "zur", "Er\u00b7de", "sen\u00b7ke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich des Opfers Fruchtgewicht.", "tokens": ["Ich", "des", "Op\u00b7fers", "Frucht\u00b7ge\u00b7wicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Doch es nimmt mit meinen Bl\u00fcten", "tokens": ["Doch", "es", "nimmt", "mit", "mei\u00b7nen", "Bl\u00fc\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ja mein Heiland schon vorlieb,", "tokens": ["Ja", "mein", "Hei\u00b7land", "schon", "vor\u00b7lieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Apfel brauch' ich nicht zu h\u00fcten", "tokens": ["Ap\u00b7fel", "brauch'", "ich", "nicht", "zu", "h\u00fc\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor dem schlauen Apfeldieb.", "tokens": ["Vor", "dem", "schlau\u00b7en", "Ap\u00b7fel\u00b7dieb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Als ich sonst mit br\u00fcnst'gen Ranken", "tokens": ["Als", "ich", "sonst", "mit", "br\u00fcnst'\u00b7gen", "Ran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch auf goldne Frucht gehofft", "tokens": ["Auch", "auf", "gold\u00b7ne", "Frucht", "ge\u00b7hofft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hatte ich Kamelgedanken", "tokens": ["Hat\u00b7te", "ich", "Ka\u00b7mel\u00b7ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "\u00dcber mich wohl selber oft.", "tokens": ["\u00dc\u00b7ber", "mich", "wohl", "sel\u00b7ber", "oft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Arme N\u00e4herin mu\u00dft' lesen", "tokens": ["Ar\u00b7me", "N\u00e4\u00b7he\u00b7rin", "mu\u00dft'", "le\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vom Kamel und Nadel\u00f6hr", "tokens": ["Vom", "Ka\u00b7mel", "und", "Na\u00b7de\u00b7l\u00f6hr"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und gab dann dem eiteln Wesen", "tokens": ["Und", "gab", "dann", "dem", "ei\u00b7teln", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nimmer wieder ein Geh\u00f6r.", "tokens": ["Nim\u00b7mer", "wie\u00b7der", "ein", "Ge\u00b7h\u00f6r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Bin jetzt eine arme Made,", "tokens": ["Bin", "jetzt", "ei\u00b7ne", "ar\u00b7me", "Ma\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Matte Fliege, St\u00e4ublein klein,", "tokens": ["Mat\u00b7te", "Flie\u00b7ge", ",", "St\u00e4ub\u00b7lein", "klein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin ein Ekel, der aus Gnade", "tokens": ["Bin", "ein", "E\u00b7kel", ",", "der", "aus", "Gna\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00f6chstens tr\u00e4gt ein \u00dcberbein.", "tokens": ["H\u00f6chs\u00b7tens", "tr\u00e4gt", "ein", "\u00dc\u00b7berb\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Wer giebt um solch schlechte Dinge", "tokens": ["Wer", "giebt", "um", "solch", "schlech\u00b7te", "Din\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wohl neun Groschen M\u00fcnze hin", "tokens": ["Wohl", "neun", "Gro\u00b7schen", "M\u00fcn\u00b7ze", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "ADJA", "NN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Drum mir mehr verloren gienge,", "tokens": ["Drum", "mir", "mehr", "ver\u00b7lo\u00b7ren", "gien\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ich selber wert ja bin.", "tokens": ["Als", "ich", "sel\u00b7ber", "wert", "ja", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "So? doch ist der armen Made", "tokens": ["So", "?", "doch", "ist", "der", "ar\u00b7men", "Ma\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keine Speise je zu gut,", "tokens": ["Kei\u00b7ne", "Spei\u00b7se", "je", "zu", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Selbst f\u00fcr Jesu Leib nicht schade,", "tokens": ["Selbst", "f\u00fcr", "Je\u00b7su", "Leib", "nicht", "scha\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schade nicht f\u00fcr Jesu Blut.", "tokens": ["Scha\u00b7de", "nicht", "f\u00fcr", "Je\u00b7su", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKNEG", "APPR", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Ja ganz wohl! die matte Fliege", "tokens": ["Ja", "ganz", "wohl", "!", "die", "mat\u00b7te", "Flie\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sitzt auf Gottes Angesicht,", "tokens": ["Sitzt", "auf", "Got\u00b7tes", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ein Engelsfl\u00fcgel schl\u00fcge,", "tokens": ["Wenn", "ein", "En\u00b7gels\u00b7fl\u00fc\u00b7gel", "schl\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er vertriebe sie da nicht.", "tokens": ["Er", "ver\u00b7trie\u00b7be", "sie", "da", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "St\u00e4ublein klein! o ja! um nimmer", "tokens": ["St\u00e4ub\u00b7lein", "klein", "!", "o", "ja", "!", "um", "nim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJD", "$.", "FM", "ADV", "$.", "KOUI", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Abzutreten von dem Tanz,", "tokens": ["Ab\u00b7zu\u00b7tre\u00b7ten", "von", "dem", "Tanz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sonnenst\u00e4ubchen tanzen immer", "tokens": ["Son\u00b7nen\u00b7st\u00e4ub\u00b7chen", "tan\u00b7zen", "im\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ADV"], "meter": "+-+-+-++", "measure": "unknown.measure.penta"}, "line.4": {"text": "Ohn' zu sinken aus dem Glanz.", "tokens": ["Ohn'", "zu", "sin\u00b7ken", "aus", "dem", "Glanz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Ei du Ekel! ja ich eckle", "tokens": ["Ei", "du", "E\u00b7kel", "!", "ja", "ich", "ec\u00b7kle"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "NN", "$.", "ADV", "PPER", "VVFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Seit ich dich im Herzen trug", "tokens": ["Seit", "ich", "dich", "im", "Her\u00b7zen", "trug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor der Welt, an allem m\u00e4ckle", "tokens": ["Vor", "der", "Welt", ",", "an", "al\u00b7lem", "m\u00e4ck\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PIS", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich, nur nie an mir genug.", "tokens": ["Ich", ",", "nur", "nie", "an", "mir", "ge\u00b7nug", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "ADV", "APPR", "PPER", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.31": {"line.1": {"text": "\u00dcberbeines Gnaden z\u00e4hle", "tokens": ["\u00dc\u00b7berb\u00b7ei\u00b7nes", "Gna\u00b7den", "z\u00e4h\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00dcberige Gnaden ein", "tokens": ["\u00dc\u00b7be\u00b7ri\u00b7ge", "Gna\u00b7den", "ein"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00dcberfleisch und \u00dcberseele,", "tokens": ["\u00dc\u00b7ber\u00b7fleisch", "und", "\u00dc\u00b7ber\u00b7see\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00dcberhimmelsschl\u00fcsselbein.", "tokens": ["\u00dc\u00b7berh\u00b7im\u00b7mels\u00b7schl\u00fcs\u00b7sel\u00b7bein", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.32": {"line.1": {"text": "Wer kann es dem Herrn verdenken", "tokens": ["Wer", "kann", "es", "dem", "Herrn", "ver\u00b7den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df er Milde an dir \u00fcbt,", "tokens": ["Da\u00df", "er", "Mil\u00b7de", "an", "dir", "\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dir, die ihm ihr Fleisch will schenken,", "tokens": ["Dir", ",", "die", "ihm", "ihr", "Fleisch", "will", "schen\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Daf\u00fcr \u00dcberbeine giebt.", "tokens": ["Da\u00b7f\u00fcr", "\u00dc\u00b7berb\u00b7ei\u00b7ne", "giebt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "War doch Eva auch im Schlafe", "tokens": ["War", "doch", "E\u00b7va", "auch", "im", "Schla\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur des Adams \u00dcberbein,", "tokens": ["Nur", "des", "A\u00b7dams", "\u00dc\u00b7berb\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eva umgekehrt ward Ave,", "tokens": ["E\u00b7va", "um\u00b7ge\u00b7kehrt", "ward", "A\u00b7ve", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "M\u00f6gst du auch gegr\u00fc\u00dfet sein.", "tokens": ["M\u00f6gst", "du", "auch", "ge\u00b7gr\u00fc\u00b7\u00dfet", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Und weil ein Kameles R\u00fccken", "tokens": ["Und", "weil", "ein", "Ka\u00b7me\u00b7les", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nur ein gro\u00dfes \u00dcberbein,", "tokens": ["Nur", "ein", "gro\u00b7\u00dfes", "\u00dc\u00b7berb\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mag's drum, wenn die Schuh' dich dr\u00fccken", "tokens": ["Mag's", "drum", ",", "wenn", "die", "Schuh'", "dich", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PAV", "$,", "KOUS", "ART", "NN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gotts Kamelgedanken sein.", "tokens": ["Gotts", "Ka\u00b7mel\u00b7ge\u00b7dan\u00b7ken", "sein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.35": {"line.1": {"text": "Und so soll mein Mut nicht wanken", "tokens": ["Und", "so", "soll", "mein", "Mut", "nicht", "wan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn er deinen hinken sieht,", "tokens": ["Wenn", "er", "dei\u00b7nen", "hin\u00b7ken", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Also aus Kamelgedanken", "tokens": ["Al\u00b7so", "aus", "Ka\u00b7mel\u00b7ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Sang ich dir dies Finkenlied.", "tokens": ["Sang", "ich", "dir", "dies", "Fin\u00b7ken\u00b7lied", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PDS", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}