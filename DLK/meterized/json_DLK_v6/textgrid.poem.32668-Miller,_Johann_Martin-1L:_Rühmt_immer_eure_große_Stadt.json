{"textgrid.poem.32668": {"metadata": {"author": {"name": "Miller, Johann Martin", "birth": "N.A.", "death": "N.A."}, "title": "1L: R\u00fchmt immer eure gro\u00dfe Stadt", "genre": "verse", "period": "N.A.", "pub_year": 1772, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "R\u00fchmt immer eure gro\u00dfe Stadt", "tokens": ["R\u00fchmt", "im\u00b7mer", "eu\u00b7re", "gro\u00b7\u00dfe", "Stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und la\u00dft ihr Lob erschallen!", "tokens": ["Und", "la\u00dft", "ihr", "Lob", "er\u00b7schal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein liebes kleines D\u00f6rfchen hat", "tokens": ["Mein", "lie\u00b7bes", "klei\u00b7nes", "D\u00f6rf\u00b7chen", "hat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir dennoch mehr gefallen.", "tokens": ["Mir", "den\u00b7noch", "mehr", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Hier mu\u00df ich ganze Tage lang", "tokens": ["Hier", "mu\u00df", "ich", "gan\u00b7ze", "Ta\u00b7ge", "lang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im \u00f6den Zimmer sitzen,", "tokens": ["Im", "\u00f6\u00b7den", "Zim\u00b7mer", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dort konnt' ich frei und ohne Zwang", "tokens": ["Dort", "konnt'", "ich", "frei", "und", "oh\u00b7ne", "Zwang"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sch\u00f6nen Tage n\u00fctzen.", "tokens": ["Die", "sch\u00f6\u00b7nen", "Ta\u00b7ge", "n\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Am fr\u00fchen Morgen konnt' ich gleich", "tokens": ["Am", "fr\u00fc\u00b7hen", "Mor\u00b7gen", "konnt'", "ich", "gleich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meinen Garten h\u00fcpfen", "tokens": ["In", "mei\u00b7nen", "Gar\u00b7ten", "h\u00fcp\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und nach den V\u00f6geln im Gestr\u00e4uch,", "tokens": ["Und", "nach", "den", "V\u00f6\u00b7geln", "im", "Ge\u00b7str\u00e4uch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Nest zu finden, schl\u00fcpfen.", "tokens": ["Ihr", "Nest", "zu", "fin\u00b7den", ",", "schl\u00fcp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wenn ich ein R\u00f6schen offen sah,", "tokens": ["Wenn", "ich", "ein", "R\u00f6\u00b7schen", "of\u00b7fen", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie pflegt' ich dann zu springen,", "tokens": ["Wie", "pflegt'", "ich", "dann", "zu", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Um es mit Freuden der Mama", "tokens": ["Um", "es", "mit", "Freu\u00b7den", "der", "Ma\u00b7ma"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PPER", "APPR", "NN", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Zum Morgengru\u00df zu bringen!", "tokens": ["Zum", "Mor\u00b7gen\u00b7gru\u00df", "zu", "brin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Sie nahm es freundlich, k\u00fc\u00dfte mich", "tokens": ["Sie", "nahm", "es", "freund\u00b7lich", ",", "k\u00fc\u00df\u00b7te", "mich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr meine kleine M\u00fche", "tokens": ["F\u00fcr", "mei\u00b7ne", "klei\u00b7ne", "M\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sah mich an und freute sich,", "tokens": ["Und", "sah", "mich", "an", "und", "freu\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich nicht minder bl\u00fche.", "tokens": ["Da\u00df", "ich", "nicht", "min\u00b7der", "bl\u00fc\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Da ging ich immer Hand in Hand", "tokens": ["Da", "ging", "ich", "im\u00b7mer", "Hand", "in", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit unsers Pachters K\u00e4thchen,", "tokens": ["Mit", "un\u00b7sers", "Pach\u00b7ters", "K\u00e4th\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr gleicht im ganzen weiten Land", "tokens": ["Ihr", "gleicht", "im", "gan\u00b7zen", "wei\u00b7ten", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in der Stadt kein M\u00e4dchen.", "tokens": ["Und", "in", "der", "Stadt", "kein", "M\u00e4d\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Sch\u00f6n, wie ein Maientag, war sie,", "tokens": ["Sch\u00f6n", ",", "wie", "ein", "Mai\u00b7en\u00b7tag", ",", "war", "sie", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "ART", "NN", "$,", "VAFIN", "PPER", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Gesch\u00e4ftig, wie ein Bienchen,", "tokens": ["Ge\u00b7sch\u00e4f\u00b7tig", ",", "wie", "ein", "Bien\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und speiste alle Morgen fr\u00fch", "tokens": ["Und", "speis\u00b7te", "al\u00b7le", "Mor\u00b7gen", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im H\u00fchnerhof die H\u00fchnchen.", "tokens": ["Im", "H\u00fch\u00b7ner\u00b7hof", "die", "H\u00fchn\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Da sah ich allemal hinab.", "tokens": ["Da", "sah", "ich", "al\u00b7le\u00b7mal", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Oft d\u00fcnkt' ich mich verborgen,", "tokens": ["Oft", "d\u00fcnkt'", "ich", "mich", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie aber sah mich doch, und gab", "tokens": ["Sie", "a\u00b7ber", "sah", "mich", "doch", ",", "und", "gab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir freundlich guten Morgen.", "tokens": ["Mir", "freund\u00b7lich", "gu\u00b7ten", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ein L\u00e4mmchen, wei\u00dfer noch als Schnee,", "tokens": ["Ein", "L\u00e4mm\u00b7chen", ",", "wei\u00b7\u00dfer", "noch", "als", "Schnee", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Folgt' ihr am roten B\u00e4ndchen,", "tokens": ["Folgt'", "ihr", "am", "ro\u00b7ten", "B\u00e4nd\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wohin sie ging, und a\u00df den Klee", "tokens": ["Wo\u00b7hin", "sie", "ging", ",", "und", "a\u00df", "den", "Klee"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus ihren wei\u00dfen H\u00e4ndchen.", "tokens": ["Aus", "ih\u00b7ren", "wei\u00b7\u00dfen", "H\u00e4nd\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Die Blumen wuchsen sch\u00f6ner, die", "tokens": ["Die", "Blu\u00b7men", "wuch\u00b7sen", "sch\u00f6\u00b7ner", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir unser G\u00e4rtner schenkte,", "tokens": ["Mir", "un\u00b7ser", "G\u00e4rt\u00b7ner", "schenk\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn das geliebte M\u00e4dchen sie", "tokens": ["Wenn", "das", "ge\u00b7lieb\u00b7te", "M\u00e4d\u00b7chen", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit klarem Wasser tr\u00e4nkte.", "tokens": ["Mit", "kla\u00b7rem", "Was\u00b7ser", "tr\u00e4nk\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Ans kleine Schmerlenufer ging", "tokens": ["Ans", "klei\u00b7ne", "Schmer\u00b7le\u00b7nu\u00b7fer", "ging"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie oft mit mir zum Fischen,", "tokens": ["Sie", "oft", "mit", "mir", "zum", "Fi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und lie\u00df, wenn ich ein Fischchen fing,", "tokens": ["Und", "lie\u00df", ",", "wenn", "ich", "ein", "Fischchen", "fing", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mitleidig es entwischen.", "tokens": ["Mit\u00b7lei\u00b7dig", "es", "ent\u00b7wi\u00b7schen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Da z\u00fcrnt' ich manchesmal mit ihr,", "tokens": ["Da", "z\u00fcrnt'", "ich", "man\u00b7ches\u00b7mal", "mit", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Doch war es bald vor\u00fcber,", "tokens": ["Doch", "war", "es", "bald", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und nach dem Schmollen hatten wir", "tokens": ["Und", "nach", "dem", "Schmol\u00b7len", "hat\u00b7ten", "wir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Einander desto lieber.", "tokens": ["Ein\u00b7an\u00b7der", "des\u00b7to", "lie\u00b7ber", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "O d\u00fcrft' ich, liebes D\u00f6rfchen, dich", "tokens": ["O", "d\u00fcrft'", "ich", ",", "lie\u00b7bes", "D\u00f6rf\u00b7chen", ",", "dich"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NE", "VMFIN", "PPER", "$,", "ADJA", "NN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur einmal wieder sehen,", "tokens": ["Nur", "ein\u00b7mal", "wie\u00b7der", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gewi\u00df, die St\u00e4dter sollten mich", "tokens": ["Ge\u00b7wi\u00df", ",", "die", "St\u00e4d\u00b7ter", "soll\u00b7ten", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sobald nicht wieder sehen!", "tokens": ["So\u00b7bald", "nicht", "wie\u00b7der", "se\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}