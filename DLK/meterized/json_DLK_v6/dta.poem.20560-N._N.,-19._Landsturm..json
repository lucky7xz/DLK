{"dta.poem.20560": {"metadata": {"author": {"name": "N. N., ", "birth": "N.A.", "death": "N.A."}, "title": "19.  \n  Landsturm.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1848", "urn": "urn:nbn:de:kobv:b4-25129-1", "language": ["de:0.99"], "booktitle": "[N. N.]: Erinnerungen eines freiwilligen reitenden J\u00e4gers aus den Kriegsjahren 1813\u20131815. Berlin, 1848."}, "poem": {"stanza.1": {"line.1": {"text": "Sch\u00f6n ist's unter freiem Himmel,", "tokens": ["Sch\u00f6n", "ist's", "un\u00b7ter", "frei\u00b7em", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn im Drang und im Gewimmel", "tokens": ["Wenn", "im", "Drang", "und", "im", "Ge\u00b7wim\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Rings herum die Flasche kreist;", "tokens": ["Rings", "he\u00b7rum", "die", "Fla\u00b7sche", "kreist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APZR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn des Marketenders Kringeln", "tokens": ["Wenn", "des", "Mar\u00b7ke\u00b7ten\u00b7ders", "Krin\u00b7geln"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Stolz sich uns entgegenringeln.", "tokens": ["Stolz", "sich", "uns", "ent\u00b7ge\u00b7gen\u00b7rin\u00b7geln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vivat drum, wer Landsturm hei\u00dft!", "tokens": ["Vi\u00b7vat", "drum", ",", "wer", "Land\u00b7sturm", "hei\u00dft", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "$,", "PWS", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Soll poet\u2019sche Menschheit graben,", "tokens": ["Soll", "po\u00b7et'\u00b7sche", "Menschheit", "gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Mu\u00df sie sich vorerst erlaben", "tokens": ["Mu\u00df", "sie", "sich", "vor\u00b7erst", "er\u00b7la\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Am Berliner Wei\u00dfbiertrank.", "tokens": ["Am", "Ber\u00b7li\u00b7ner", "Wei\u00df\u00b7bier\u00b7trank", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Kanoniers tragt fort Faschinen,", "tokens": ["Ka\u00b7no\u00b7niers", "tragt", "fort", "Fa\u00b7schi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kellner bringen Sie Blondinen", "tokens": ["Kell\u00b7ner", "brin\u00b7gen", "Sie", "Blon\u00b7di\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Volpi's uns im Glase schlank!", "tokens": ["Vol\u00b7pi's", "uns", "im", "Gla\u00b7se", "schlank", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Herr Oberst auf dem Schimmel", "tokens": ["Der", "Herr", "O\u00b7berst", "auf", "dem", "Schim\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Reiten durch das Schwerdtget\u00fcmmel.", "tokens": ["Rei\u00b7ten", "durch", "das", "Schwerdt\u00b7ge\u00b7t\u00fcm\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und Sie loben uns. \u2014 Auf Ehr\u2019!", "tokens": ["Und", "Sie", "lo\u00b7ben", "uns", ".", "Auf", "Ehr'", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$.", "$(", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Machen uns Jhr Complimente,", "tokens": ["Ma\u00b7chen", "uns", "Ihr", "Com\u00b7pli\u00b7men\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-++-++-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Sprechen: Ich bin sehr contente.", "tokens": ["Spre\u00b7chen", ":", "Ich", "bin", "sehr", "con\u00b7ten\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "ADV", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Mannszucht h\u00e4lt man, \u2014 fast zu sehr!", "tokens": ["Manns\u00b7zucht", "h\u00e4lt", "man", ",", "fast", "zu", "sehr", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "$,", "$(", "ADV", "PTKA", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Dort ein Kleiner ruft zum Langen:", "tokens": ["Dort", "ein", "Klei\u00b7ner", "ruft", "zum", "Lan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df uns aneinander hangen,", "tokens": ["La\u00df", "uns", "an\u00b7ein\u00b7an\u00b7der", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bleib\u2019 Du stets mein Nebenmann!", "tokens": ["Bleib'", "Du", "stets", "mein", "Ne\u00b7ben\u00b7mann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Halt Dich fest an meiner Linken!", "tokens": ["Halt", "Dich", "fest", "an", "mei\u00b7ner", "Lin\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da aus einem Krug wir trinken,", "tokens": ["Da", "aus", "ei\u00b7nem", "Krug", "wir", "trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kein Gen\u2019ral uns trennen kann!", "tokens": ["Kein", "Gen'\u00b7ral", "uns", "tren\u00b7nen", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wahrheitsfinder, ", "tokens": ["Wahr\u00b7heits\u00b7fin\u00b7der", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Satans k\u00fchlster Widersacher,", "tokens": ["Sa\u00b7tans", "k\u00fchls\u00b7ter", "Wi\u00b7der\u00b7sa\u00b7cher", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gl\u00fcht als braver Landsturmmann. \u2014", "tokens": ["Gl\u00fcht", "als", "bra\u00b7ver", "Land\u00b7sturm\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "KOKOM", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sinnend jauchzt Er: Klein gewachsen,", "tokens": ["Sin\u00b7nend", "jauchzt", "Er", ":", "Klein", "ge\u00b7wach\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "$.", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Steig\u2019 ich zu des Welschf\u00fcrst\u2019s Dachsen-", "tokens": ["Steig'", "ich", "zu", "des", "Welschf\u00fcr\u00b7st's", "Dach\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "L\u00fcgengipfel rasch hinauf!", "tokens": ["L\u00fc\u00b7gen\u00b7gip\u00b7fel", "rasch", "hin\u00b7auf", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Philosoph\u2019schen Glaubens Lenker,", "tokens": ["Phi\u00b7lo\u00b7so\u00b7ph'\u00b7schen", "Glau\u00b7bens", "Len\u00b7ker", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Fichte, scharf und tiefer Denker,", "tokens": ["Fich\u00b7te", ",", "scharf", "und", "tie\u00b7fer", "Den\u00b7ker", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Skepticirt als Objekt sich;", "tokens": ["Skep\u00b7ti\u00b7cirt", "als", "Ob\u00b7jekt", "sich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "NN", "PRF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Ruft drum: Sagt\u2019s mir unverholen,", "tokens": ["Ruft", "drum", ":", "Sagt's", "mir", "un\u00b7ver\u00b7ho\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "$.", "NN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier mit Pike und Pistolen,", "tokens": ["Hier", "mit", "Pi\u00b7ke", "und", "Pis\u00b7to\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Bin ich Nicht-Ich, oder Ich?", "tokens": ["Bin", "ich", "Nicht\u00b7Ich", ",", "o\u00b7der", "Ich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "$,", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Stultus kr&#228;ht: Nichts Landsturm n&#252;tzte;", "tokens": ["Stul\u00b7tus", "kr", "&#228;", "ht", ":", "Nichts", "Land\u00b7sturm", "n", "&#252;", "tz\u00b7te", ";"], "token_info": ["word", "word", "XML_entity", "word", "punct", "word", "word", "word", "XML_entity", "word", "punct"], "pos": ["FM.la", "FM.la", "$(", "VVFIN", "$.", "PIS", "NN", "XY", "$(", "VVFIN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Tauentzien und B&#252;low sch&#252;tzte", "tokens": ["Tau\u00b7ent\u00b7zien", "und", "B", "&#252;", "low", "sch", "&#252;", "tz\u00b7te"], "token_info": ["word", "word", "word", "XML_entity", "word", "word", "XML_entity", "word"], "pos": ["NE", "KON", "XY", "$(", "NE", "ADJD", "$(", "VVFIN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ja die Residenz Berlin!", "tokens": ["Ja", "die", "Re\u00b7si\u00b7denz", "Ber\u00b7lin", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dromedar Du schweigst! \u2014 Erhebend", "tokens": ["Dro\u00b7me\u00b7dar", "Du", "schweigst", "!", "Er\u00b7he\u00b7bend"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "PPER", "VVFIN", "$.", "$(", "VVPP"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "War es, sah man, jung auflebend,", "tokens": ["War", "es", ",", "sah", "man", ",", "jung", "auf\u00b7le\u00b7bend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "VVFIN", "PIS", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Greise f\u00fcr die Freiheit gl\u00fchn!", "tokens": ["Grei\u00b7se", "f\u00fcr", "die", "Frei\u00b7heit", "gl\u00fchn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}