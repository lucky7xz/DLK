{"textgrid.poem.33024": {"metadata": {"author": {"name": "Flaischlen, C\u00e4sar", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das ist das Leben! was erwartest du mehr?!", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das ist das Leben! was erwartest du mehr?!", "tokens": ["Das", "ist", "das", "Le\u00b7ben", "!", "was", "er\u00b7war\u00b7test", "du", "mehr", "?!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "was du hast, ist alles! es gibt nichts mehr?", "tokens": ["was", "du", "hast", ",", "ist", "al\u00b7les", "!", "es", "gibt", "nichts", "mehr", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "VAFIN", "PIS", "$.", "PPER", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Das ist das Leben:", "tokens": ["Das", "ist", "das", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "all diese kleinen Allt\u00e4glichkeiten", "tokens": ["all", "die\u00b7se", "klei\u00b7nen", "All\u00b7t\u00e4g\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "PDAT", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "von Stund zu Stunde: dies Aufstehn morgens", "tokens": ["von", "Stund", "zu", "Stun\u00b7de", ":", "dies", "Auf\u00b7stehn", "mor\u00b7gens"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN", "$.", "PDS", "NN", "ADV"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und dann den stillen Tag entlang", "tokens": ["und", "dann", "den", "stil\u00b7len", "Tag", "ent\u00b7lang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPO"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "in stillem Gleichlauf deine Arbeit ...", "tokens": ["in", "stil\u00b7lem", "Gleich\u00b7lauf", "dei\u00b7ne", "Ar\u00b7beit", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Reste von gestern, Sorgen zu morgen ...", "tokens": ["Res\u00b7te", "von", "ge\u00b7stern", ",", "Sor\u00b7gen", "zu", "mor\u00b7gen", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADV", "$,", "NN", "PTKZU", "VVINF", "$("], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "zuweilen auch wohl ein ... froherer Gang,", "tokens": ["zu\u00b7wei\u00b7len", "auch", "wohl", "ein", "...", "fro\u00b7he\u00b7rer", "Gang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "$(", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ein hellerer ... ein vollerer Klang ...", "tokens": ["ein", "hel\u00b7le\u00b7rer", "...", "ein", "vol\u00b7le\u00b7rer", "Klang", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "ein bi\u00dfchen Scherz, ein bi\u00dfchen \u00c4rger,", "tokens": ["ein", "bi\u00df\u00b7chen", "Scherz", ",", "ein", "bi\u00df\u00b7chen", "\u00c4r\u00b7ger", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "ein bi\u00dfchen Gl\u00fcck, ein bi\u00dfchen T\u00fcck ...", "tokens": ["ein", "bi\u00df\u00b7chen", "Gl\u00fcck", ",", "ein", "bi\u00df\u00b7chen", "T\u00fcck", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "hochwichtig alles f\u00fcr den Augenblick,", "tokens": ["hoch\u00b7wich\u00b7tig", "al\u00b7les", "f\u00fcr", "den", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "im n\u00e4chsten aber schon vergessen", "tokens": ["im", "n\u00e4chs\u00b7ten", "a\u00b7ber", "schon", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "und schlie\u00dflich auch ganz einerlei:", "tokens": ["und", "schlie\u00df\u00b7lich", "auch", "ganz", "ei\u00b7ner\u00b7lei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "ob morgen wohl sch\u00f6n Wetter sei?!", "tokens": ["ob", "mor\u00b7gen", "wohl", "sch\u00f6n", "Wet\u00b7ter", "sei", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "und wenn, wohin man abends gehe?", "tokens": ["und", "wenn", ",", "wo\u00b7hin", "man", "a\u00b7bends", "ge\u00b7he", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "und wie es da- und damit stehe?!", "tokens": ["und", "wie", "es", "da", "und", "da\u00b7mit", "ste\u00b7he", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "TRUNC", "KON", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "und dies und das und das und dies,", "tokens": ["und", "dies", "und", "das", "und", "das", "und", "dies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "KON", "PDS", "KON", "PDS", "KON", "PDS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "hundert kleine Was und Wie's,", "tokens": ["hun\u00b7dert", "klei\u00b7ne", "Was", "und", "Wie's", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "hundert kleine Wohl und Wehe! ...", "tokens": ["hun\u00b7dert", "klei\u00b7ne", "Wohl", "und", "We\u00b7he", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "ADJA", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Das ist das Leben! erwarte nicht mehr!", "tokens": ["Das", "ist", "das", "Le\u00b7ben", "!", "er\u00b7war\u00b7te", "nicht", "mehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "was du hast, ist alles! niemand hat mehr!", "tokens": ["was", "du", "hast", ",", "ist", "al\u00b7les", "!", "nie\u00b7mand", "hat", "mehr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "VAFIN", "PIS", "$.", "PIS", "VAFIN", "ADV", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.4": {"line.1": {"text": "Es fr\u00e4gt sich nur, wie's jeder fa\u00dft", "tokens": ["Es", "fr\u00e4gt", "sich", "nur", ",", "wie's", "je\u00b7der", "fa\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und schiebt und siebt ...", "tokens": ["und", "schiebt", "und", "siebt", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "und wie du's in die Z\u00fcgel straffst", "tokens": ["und", "wie", "du's", "in", "die", "Z\u00fc\u00b7gel", "straffst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und wie du's auseinanderspielst", "tokens": ["und", "wie", "du's", "aus\u00b7ein\u00b7an\u00b7der\u00b7spielst"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und wieder dann zusammenzielst,", "tokens": ["und", "wie\u00b7der", "dann", "zu\u00b7sam\u00b7men\u00b7zielst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "damit sich doch zuletzt ein Ganzes,", "tokens": ["da\u00b7mit", "sich", "doch", "zu\u00b7letzt", "ein", "Gan\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "gro\u00dflinig Eigenes draus ergibt!", "tokens": ["gro\u00df\u00b7li\u00b7nig", "Ei\u00b7ge\u00b7nes", "draus", "er\u00b7gibt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "PAV", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}}}}