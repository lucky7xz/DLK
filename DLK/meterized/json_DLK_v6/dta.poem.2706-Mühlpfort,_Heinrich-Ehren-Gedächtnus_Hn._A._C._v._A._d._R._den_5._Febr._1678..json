{"dta.poem.2706": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Ehren-Ged\u00e4chtnus/  \n  Hn. A. C. v. A. d. R. den 5. Febr.  1678.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Verlache nur dein Grab/ du Auge dieser Stadt/", "tokens": ["Ver\u00b7la\u00b7che", "nur", "dein", "Grab", "/", "du", "Au\u00b7ge", "die\u00b7ser", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "$(", "PPER", "NN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das zwar die lange Nacht nunmehr geschlossen hat;", "tokens": ["Das", "zwar", "die", "lan\u00b7ge", "Nacht", "nun\u00b7mehr", "ge\u00b7schlos\u00b7sen", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gib was verwesen kan/ den Rest der m\u00fcrben Glieder/", "tokens": ["Gib", "was", "ver\u00b7we\u00b7sen", "kan", "/", "den", "Rest", "der", "m\u00fcr\u00b7ben", "Glie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PWS", "VVINF", "VMFIN", "$(", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der alten Mutter Scho\u00df auf neuen Wucher wieder/", "tokens": ["Der", "al\u00b7ten", "Mut\u00b7ter", "Scho\u00df", "auf", "neu\u00b7en", "Wu\u00b7cher", "wie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPR", "ADJA", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nichts als der Leib bleibt tod. Nachdem nun allbereit", "tokens": ["Nichts", "als", "der", "Leib", "bleibt", "tod", ".", "Nach\u00b7dem", "nun", "all\u00b7be\u00b7reit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "KOKOM", "ART", "NN", "VVFIN", "NN", "$.", "KOUS", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Seelen himmlisch Feur in jener Ewigkeit", "tokens": ["Der", "See\u00b7len", "himm\u00b7lisch", "Feur", "in", "je\u00b7ner", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Als wie die Sterne gl\u00e4ntzt/ so l\u00e4st du uns zwar Zehren/", "tokens": ["Als", "wie", "die", "Ster\u00b7ne", "gl\u00e4ntzt", "/", "so", "l\u00e4st", "du", "uns", "zwar", "Zeh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "VVFIN", "$(", "ADV", "VVFIN", "PPER", "PRF", "ADV", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die anverwandtes Blut dir h\u00e4uffig wird gewehren/", "tokens": ["Die", "an\u00b7ver\u00b7wand\u00b7tes", "Blut", "dir", "h\u00e4uf\u00b7fig", "wird", "ge\u00b7weh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "ADJD", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und die die B\u00fcrgerschafft aus treuen Hertzen zollt", "tokens": ["Und", "die", "die", "B\u00fcr\u00b7ger\u00b7schafft", "aus", "treu\u00b7en", "Hert\u00b7zen", "zollt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In dem sie seufftzt und klagt. Ach wenn doch GOtt gewollt/", "tokens": ["In", "dem", "sie", "seufftzt", "und", "klagt", ".", "Ach", "wenn", "doch", "Gott", "ge\u00b7wollt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "KON", "VVFIN", "$.", "ITJ", "KOUS", "ADV", "NN", "VMPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df wir den theuren Mann noch l\u00e4nger solten haben!", "tokens": ["Da\u00df", "wir", "den", "theu\u00b7ren", "Mann", "noch", "l\u00e4n\u00b7ger", "sol\u00b7ten", "ha\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der herrliche Verstand/ die ungemeine Gaben/", "tokens": ["Der", "herr\u00b7li\u00b7che", "Ver\u00b7stand", "/", "die", "un\u00b7ge\u00b7mei\u00b7ne", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der Eyfer gegen GOtt und f\u00fcr gemeines Heil/", "tokens": ["Der", "Ey\u00b7fer", "ge\u00b7gen", "Gott", "und", "f\u00fcr", "ge\u00b7mei\u00b7nes", "Heil", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verdienen ewig Lob. Das Leben w\u00e4r\u2019 uns feil", "tokens": ["Ver\u00b7die\u00b7nen", "e\u00b7wig", "Lob", ".", "Das", "Le\u00b7ben", "w\u00e4r'", "uns", "feil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Umb seiner Jahre Frist noch l\u00e4nger zu erweitern.", "tokens": ["Umb", "sei\u00b7ner", "Jah\u00b7re", "Frist", "noch", "l\u00e4n\u00b7ger", "zu", "er\u00b7wei\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist alle Kunst umbsonst? ist nichts in Blum und Kr\u00e4utern", "tokens": ["Ist", "al\u00b7le", "Kunst", "um\u00b7bsonst", "?", "ist", "nichts", "in", "Blum", "und", "Kr\u00e4u\u00b7tern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "VVFIN", "$.", "VAFIN", "PIS", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Rettung bringen kan? So ist es gantz geschehn.", "tokens": ["Das", "Ret\u00b7tung", "brin\u00b7gen", "kan", "?", "So", "ist", "es", "gantz", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir B\u00fcrger m\u00fcssen nur die Mauren fallen sehn", "tokens": ["Wir", "B\u00fcr\u00b7ger", "m\u00fcs\u00b7sen", "nur", "die", "Mau\u00b7ren", "fal\u00b7len", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VMFIN", "ADV", "ART", "NN", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So uns bi\u00dfher besch\u00fctzt/ und wie Metellus klagen/", "tokens": ["So", "uns", "bi\u00df\u00b7her", "be\u00b7sch\u00fctzt", "/", "und", "wie", "Me\u00b7tel\u00b7lus", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVPP", "$(", "KON", "PWAV", "NE", "VVINF", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Pfeiler unsers Heils wird von uns weg getragen.", "tokens": ["Der", "Pfei\u00b7ler", "un\u00b7sers", "Heils", "wird", "von", "uns", "weg", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "APPR", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In solches Seufftzen bricht der allgemeine Mund", "tokens": ["In", "sol\u00b7ches", "Seufft\u00b7zen", "bricht", "der", "all\u00b7ge\u00b7mei\u00b7ne", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit heissen Thr\u00e4nen aus. Wer aber machet kund", "tokens": ["Mit", "heis\u00b7sen", "Thr\u00e4\u00b7nen", "aus", ".", "Wer", "a\u00b7ber", "ma\u00b7chet", "kund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$.", "PWS", "ADV", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das innre Seelen-Leid/ die tieffen Hertzens-Wunden", "tokens": ["Das", "inn\u00b7re", "See\u00b7len\u00b7Leid", "/", "die", "tief\u00b7fen", "Hert\u00b7zens\u00b7Wun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So Hochbetr\u00fcbtste sie ob diesem Fall empfunden?", "tokens": ["So", "Hoch\u00b7be\u00b7tr\u00b7\u00fcbts\u00b7te", "sie", "ob", "die\u00b7sem", "Fall", "emp\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PDAT", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Da die Frau Mutter mu\u00df den allerliebsten Sohn", "tokens": ["Da", "die", "Frau", "Mut\u00b7ter", "mu\u00df", "den", "al\u00b7ler\u00b7liebs\u00b7ten", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "De\u00df schwachen Alters Stab/ der grauen Haare Krohn/", "tokens": ["De\u00df", "schwa\u00b7chen", "Al\u00b7ters", "Stab", "/", "der", "grau\u00b7en", "Haa\u00b7re", "Krohn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$(", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "De\u00df Lebens besten Trost so fr\u00fch und bald vermissen/", "tokens": ["De\u00df", "Le\u00b7bens", "bes\u00b7ten", "Trost", "so", "fr\u00fch", "und", "bald", "ver\u00b7mis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADV", "ADJD", "KON", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihm/ was sie von ihm gehofft/ die Augen schliessen.", "tokens": ["Und", "ihm", "/", "was", "sie", "von", "ihm", "ge\u00b7hofft", "/", "die", "Au\u00b7gen", "schlies\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "PWS", "PPER", "APPR", "PPER", "VVPP", "$(", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Welch Redner stellt uns vor der beyden Br\u00fcder Weh", "tokens": ["Welch", "Red\u00b7ner", "stellt", "uns", "vor", "der", "bey\u00b7den", "Br\u00fc\u00b7der", "Weh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Angst erf\u00fclltes Leid? Der Liebsten Thr\u00e4nen-See/", "tokens": ["Und", "Angst", "er\u00b7f\u00fcll\u00b7tes", "Leid", "?", "Der", "Liebs\u00b7ten", "Thr\u00e4\u00b7nen\u00b7See", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Womit sie stets den Sarch aus treuer Pflicht benetzet?", "tokens": ["Wo\u00b7mit", "sie", "stets", "den", "Sarch", "aus", "treu\u00b7er", "Pflicht", "be\u00b7net\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lebt jemand in der Stadt der nicht h\u00f6chsikl\u00e4glich sch\u00e4tzet", "tokens": ["Lebt", "je\u00b7mand", "in", "der", "Stadt", "der", "nicht", "h\u00f6c\u00b7hsik\u00b7l\u00e4g\u00b7lich", "sch\u00e4t\u00b7zet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "ART", "PTKNEG", "ADJD", "VVFIN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den unverhofften Ri\u00df? Allein des Himmels Schlu\u00df/", "tokens": ["Den", "un\u00b7ver\u00b7hoff\u00b7ten", "Ri\u00df", "?", "Al\u00b7lein", "des", "Him\u00b7mels", "Schlu\u00df", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem unsre Sterbligkeit gehorsam folgen mu\u00df/", "tokens": ["Dem", "uns\u00b7re", "Ster\u00b7blig\u00b7keit", "ge\u00b7hor\u00b7sam", "fol\u00b7gen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Erweicht kein sehnlich flehn. Genug da\u00df wir die Gaben/", "tokens": ["Er\u00b7weicht", "kein", "sehn\u00b7lich", "flehn", ".", "Ge\u00b7nug", "da\u00df", "wir", "die", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJD", "VVINF", "$.", "ADV", "KOUS", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Sch\u00e4tze der Natur/ nicht wie den Leib begeaben.", "tokens": ["Die", "Sch\u00e4t\u00b7ze", "der", "Na\u00b7tur", "/", "nicht", "wie", "den", "Leib", "be\u00b7ge\u00b7a\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$(", "PTKNEG", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Herr Artzat lebt und bl\u00fcht den Hertzen eingepr\u00e4gt/", "tokens": ["Herr", "A\u00b7rtzat", "lebt", "und", "bl\u00fcht", "den", "Hert\u00b7zen", "ein\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "KON", "VVFIN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sein Ruhm/ den weder Zeit noch Neid zugrabe tr\u00e4gt/", "tokens": ["Sein", "Ruhm", "/", "den", "we\u00b7der", "Zeit", "noch", "Neid", "zu\u00b7gra\u00b7be", "tr\u00e4gt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ART", "KON", "NN", "ADV", "NN", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wird auch der j\u00fcngern Welt hell in die Augen scheinen.", "tokens": ["Wird", "auch", "der", "j\u00fcn\u00b7gern", "Welt", "hell", "in", "die", "Au\u00b7gen", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wem ist unbekand/ wie er von Kindes Beinen", "tokens": ["Und", "wem", "ist", "un\u00b7be\u00b7kand", "/", "wie", "er", "von", "Kin\u00b7des", "Bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "ADJD", "$(", "PWAV", "PPER", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Der Tugend nachgestrebt? Ob schon der Ahnen Ruhm/", "tokens": ["Der", "Tu\u00b7gend", "nach\u00b7ge\u00b7strebt", "?", "Ob", "schon", "der", "Ah\u00b7nen", "Ruhm", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "KOUS", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Adliches Geschlecht sein erstes Eigenthum/", "tokens": ["Und", "Ad\u00b7li\u00b7ches", "Ge\u00b7schlecht", "sein", "ers\u00b7tes", "Ei\u00b7gen\u00b7thum", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So meint er nicht genug von Eltern edel heissen.", "tokens": ["So", "meint", "er", "nicht", "ge\u00b7nug", "von", "El\u00b7tern", "e\u00b7del", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er wolte sich vor sich so auff ein Lob befleissen", "tokens": ["Er", "wol\u00b7te", "sich", "vor", "sich", "so", "auff", "ein", "Lob", "be\u00b7fleis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "PRF", "ADV", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das unverg\u00e4nglich ist. Sein unerm\u00fcdet Sinn", "tokens": ["Das", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "ist", ".", "Sein", "un\u00b7er\u00b7m\u00fc\u00b7det", "Sinn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "ADJD", "VAFIN", "$.", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hing freyen K\u00fcnsten nach/ er gieng begierig hin", "tokens": ["Hing", "frey\u00b7en", "K\u00fcns\u00b7ten", "nach", "/", "er", "gieng", "be\u00b7gie\u00b7rig", "hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "APPR", "$(", "PPER", "VVFIN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Wo theure Wissenschafft und Wei\u00dfheit war zu finden.", "tokens": ["Wo", "theu\u00b7re", "Wis\u00b7sen\u00b7schafft", "und", "Wei\u00df\u00b7heit", "war", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "KON", "NN", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man preiste seinen Flei\u00df bey den ber\u00fchmten Linden/", "tokens": ["Man", "preis\u00b7te", "sei\u00b7nen", "Flei\u00df", "bey", "den", "be\u00b7r\u00fchm\u00b7ten", "Lin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NE", "$("], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Wo er das heilge Recht mit grossem Eisser trieb.", "tokens": ["Wo", "er", "das", "heil\u00b7ge", "Recht", "mit", "gros\u00b7sem", "Eis\u00b7ser", "trieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Apollo ward ihm hold/ Minerva hat ihn lieb.", "tokens": ["A\u00b7pol\u00b7lo", "ward", "ihm", "hold", "/", "Mi\u00b7ner\u00b7va", "hat", "ihn", "lieb", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADJD", "$(", "NE", "VAFIN", "PPER", "ADJD", "$."], "meter": "+--+-+---+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Und wie ein feurig Geist stets seinem Himmel gleichet/", "tokens": ["Und", "wie", "ein", "feu\u00b7rig", "Geist", "stets", "sei\u00b7nem", "Him\u00b7mel", "glei\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJD", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So lie\u00df er auch nicht nach bi\u00df er den Zweg erreichet.", "tokens": ["So", "lie\u00df", "er", "auch", "nicht", "nach", "bi\u00df", "er", "den", "Zweg", "er\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "APPR", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}}, "stanza.10": {"line.1": {"text": "Er trat die Reisen an/ und als er in der Welt", "tokens": ["Er", "trat", "die", "Rei\u00b7sen", "an", "/", "und", "als", "er", "in", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$(", "KON", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was hoch- und sch\u00e4tzbar ist/ und was sie n\u00fctzlich h\u00e4lt/", "tokens": ["Was", "hoch", "und", "sch\u00e4tz\u00b7bar", "ist", "/", "und", "was", "sie", "n\u00fctz\u00b7lich", "h\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "TRUNC", "KON", "ADJD", "VAFIN", "$(", "KON", "PWS", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit Rath ihm beygelegt/ bracht er die reiffen Fr\u00fcchte", "tokens": ["Mit", "Rath", "ihm", "bey\u00b7ge\u00b7legt", "/", "bracht", "er", "die", "reif\u00b7fen", "Fr\u00fcch\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PPER", "VVPP", "$(", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ins Vaterlandes Scho\u00df. Gleich wie im ersten Lichte", "tokens": ["Ins", "Va\u00b7ter\u00b7lan\u00b7des", "Scho\u00df", ".", "Gleich", "wie", "im", "ers\u00b7ten", "Lich\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NN", "$.", "ADV", "KOKOM", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Morgenr\u00f6the schon den braunen Purpur zeigt", "tokens": ["Die", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", "schon", "den", "brau\u00b7nen", "Pur\u00b7pur", "zeigt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und drauf ins klare Gold des hellen Tages steigt:", "tokens": ["Und", "drauf", "ins", "kla\u00b7re", "Gold", "des", "hel\u00b7len", "Ta\u00b7ges", "steigt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "So schien Herr Artzats Thun auch da voll Ehren-Sonnen.", "tokens": ["So", "schien", "Herr", "A\u00b7rtzats", "Thun", "auch", "da", "voll", "Eh\u00b7ren\u00b7Son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NN", "VVFIN", "ADV", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Hoffnung hatte schon die Oberhand gewonnen", "tokens": ["Die", "Hoff\u00b7nung", "hat\u00b7te", "schon", "die", "O\u00b7ber\u00b7hand", "ge\u00b7won\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df er bey dieser Stadt ein Vater w\u00fcrde seyn/", "tokens": ["Da\u00df", "er", "bey", "die\u00b7ser", "Stadt", "ein", "Va\u00b7ter", "w\u00fcr\u00b7de", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "ART", "NN", "VAFIN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Ausgang traff begl\u00fcckt mit allen W\u00fcnschen ein.", "tokens": ["Der", "Aus\u00b7gang", "traff", "be\u00b7gl\u00fcckt", "mit", "al\u00b7len", "W\u00fcn\u00b7schen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier \u00f6ffnet sich ein Feld von seinem Ruhm zu melden.", "tokens": ["Hier", "\u00f6ff\u00b7net", "sich", "ein", "Feld", "von", "sei\u00b7nem", "Ruhm", "zu", "mel\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Rom sch\u00e4tzte sich ber\u00fchmt mit seineu theuren Helden.", "tokens": ["Rom", "sch\u00e4tz\u00b7te", "sich", "be\u00b7r\u00fchmt", "mit", "sei\u00b7neu", "theu\u00b7ren", "Hel\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wenn da ein Appius der B\u00fcrger Heilbewacht/", "tokens": ["Wenn", "da", "ein", "Ap\u00b7pius", "der", "B\u00fcr\u00b7ger", "Heil\u00b7be\u00b7wacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "ART", "NN", "NN", "$("], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Camillus es besch\u00fctzt/ und Cato den Verdacht", "tokens": ["Ca\u00b7mil\u00b7lus", "es", "be\u00b7sch\u00fctzt", "/", "und", "Ca\u00b7to", "den", "Ver\u00b7dacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PPER", "VVPP", "$(", "KON", "NE", "ART", "NN"], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Durch nichts als Unschuld d\u00e4mpfft und Tugendhafftes Leben:", "tokens": ["Durch", "nichts", "als", "Un\u00b7schuld", "d\u00e4mpfft", "und", "Tu\u00b7gend\u00b7haff\u00b7tes", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "NN", "VVFIN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So k\u00f6nnen wir gewi\u00df mit besserm Grund erheben", "tokens": ["So", "k\u00f6n\u00b7nen", "wir", "ge\u00b7wi\u00df", "mit", "bes\u00b7serm", "Grund", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Herrn Artzats edlen Ruhm. Denn als der Sterbligkeit", "tokens": ["Herrn", "A\u00b7rtzats", "ed\u00b7len", "Ruhm", ".", "Denn", "als", "der", "Ster\u00b7blig\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "ADJA", "NN", "$.", "KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der hochverdiente Grei\u00df der Vater sich befreyt/", "tokens": ["Der", "hoch\u00b7ver\u00b7dien\u00b7te", "Grei\u00df", "der", "Va\u00b7ter", "sich", "be\u00b7freyt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Und nun in gleiche W\u00fcrd und Stand der Sohn war kommen/", "tokens": ["Und", "nun", "in", "glei\u00b7che", "W\u00fcrd", "und", "Stand", "der", "Sohn", "war", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "KON", "NN", "ART", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie eyfrig hat er sich nicht alles angenommen?", "tokens": ["Wie", "ey\u00b7frig", "hat", "er", "sich", "nicht", "al\u00b7les", "an\u00b7ge\u00b7nom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PRF", "PTKNEG", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Gleich wie ein reicher Strom sich in viel B\u00e4che theilt/", "tokens": ["Gleich", "wie", "ein", "rei\u00b7cher", "Strom", "sich", "in", "viel", "B\u00e4\u00b7che", "theilt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "PRF", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mit dem Silber-Quell das Feld zu tr\u00e4ncken eilt:", "tokens": ["Und", "mit", "dem", "Sil\u00b7ber\u00b7Quell", "das", "Feld", "zu", "tr\u00e4n\u00b7cken", "eilt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So kam von seinem Rath/ als einem reichen Bronnen/", "tokens": ["So", "kam", "von", "sei\u00b7nem", "Rath", "/", "als", "ei\u00b7nem", "rei\u00b7chen", "Bron\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "KOUS", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gemeinem Wesen H\u00fclff und jedem Heil geronnen.", "tokens": ["Ge\u00b7mei\u00b7nem", "We\u00b7sen", "H\u00fclff", "und", "je\u00b7dem", "Heil", "ge\u00b7ron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der r\u00fchmte den Verstand/ ein ander seine Treu/", "tokens": ["Der", "r\u00fchm\u00b7te", "den", "Ver\u00b7stand", "/", "ein", "an\u00b7der", "sei\u00b7ne", "Treu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "ART", "ADJD", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der seine Redligkeit/ und das ohn Heucheley", "tokens": ["Der", "sei\u00b7ne", "Red\u00b7lig\u00b7keit", "/", "und", "das", "ohn", "Heu\u00b7che\u00b7ley"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "$(", "KON", "PDS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein reines Hertze war. Wie auch sein l\u00f6blich Leben", "tokens": ["Sein", "rei\u00b7nes", "Hert\u00b7ze", "war", ".", "Wie", "auch", "sein", "l\u00f6b\u00b7lich", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "VVFIN", "VAFIN", "$.", "PWAV", "ADV", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der gantzen B\u00fcrgerschafft kont einen Spiegel geben.", "tokens": ["Der", "gant\u00b7zen", "B\u00fcr\u00b7ger\u00b7schafft", "kont", "ei\u00b7nen", "Spie\u00b7gel", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und solten Menschen auch davor nicht danckbar seyn?", "tokens": ["Und", "sol\u00b7ten", "Men\u00b7schen", "auch", "da\u00b7vor", "nicht", "dan\u00b7ck\u00b7bar", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "PAV", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "So meldeten sein Lob/ Stadt/ W\u00e4lle/ Mauren/ Stein\u2019/", "tokens": ["So", "mel\u00b7de\u00b7ten", "sein", "Lob", "/", "Stadt", "/", "W\u00e4l\u00b7le", "/", "Mau\u00b7ren", "/", "Stein'", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$(", "NN", "$(", "NN", "$(", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und m\u00fcsten Zeugen seyn der immerwachen Sorgen.", "tokens": ["Und", "m\u00fcs\u00b7ten", "Zeu\u00b7gen", "seyn", "der", "im\u00b7mer\u00b7wa\u00b7chen", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dem grossen ", "tokens": ["Dem", "gros\u00b7sen"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "Er sah ihn gn\u00e4dig an/ und nannt ihn seinen Rath.", "tokens": ["Er", "sah", "ihn", "gn\u00e4\u00b7dig", "an", "/", "und", "nannt", "ihn", "sei\u00b7nen", "Rath", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$(", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ja wie die Tugend di\u00df zu ihrem Lohne hat/", "tokens": ["Ja", "wie", "die", "Tu\u00b7gend", "di\u00df", "zu", "ih\u00b7rem", "Loh\u00b7ne", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOKOM", "ART", "NN", "PDS", "APPR", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da\u00df sie der Ruhm bekr\u00f6hnt: So ward von vielen Zungen", "tokens": ["Da\u00df", "sie", "der", "Ruhm", "be\u00b7kr\u00f6hnt", ":", "So", "ward", "von", "vie\u00b7len", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$.", "ADV", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Herr Artzats weises Thun und Treffligkeit besungen", "tokens": ["Herr", "A\u00b7rtzats", "wei\u00b7ses", "Thun", "und", "Tref\u00b7flig\u00b7keit", "be\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "ADJA", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wie die Gerechtigkeit durch ihn ihr Recht vollf\u00fchrt/", "tokens": ["Wie", "die", "Ge\u00b7rech\u00b7tig\u00b7keit", "durch", "ihn", "ihr", "Recht", "voll\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "PPER", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie er sein Richter-Ampt mit Ansehn hat geziert/", "tokens": ["Wie", "er", "sein", "Rich\u00b7ter\u00b7Ampt", "mit", "An\u00b7sehn", "hat", "ge\u00b7ziert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Mit Glimpff und Ernst vermischt/ sein Ohre nie verschlossen.", "tokens": ["Mit", "Glimpff", "und", "Ernst", "ver\u00b7mischt", "/", "sein", "Oh\u00b7re", "nie", "ver\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$(", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wie in Verrichtungen der Stadt er unverdrossen", "tokens": ["Wie", "in", "Ver\u00b7rich\u00b7tun\u00b7gen", "der", "Stadt", "er", "un\u00b7ver\u00b7dros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "ART", "NN", "PPER", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Den besten Zweg erkiest. Und lie\u00df ja eine Ruh/", "tokens": ["Den", "bes\u00b7ten", "Zweg", "er\u00b7kiest", ".", "Und", "lie\u00df", "ja", "ei\u00b7ne", "Ruh", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "KON", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die doch sehr selten kam/ das Cammer-Wesen zu/", "tokens": ["Die", "doch", "sehr", "sel\u00b7ten", "kam", "/", "das", "Cam\u00b7mer\u00b7We\u00b7sen", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "VVFIN", "$(", "ART", "NN", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Hie\u00df seine gr\u00f6ste Lust ein gutes Buch zu lesen/", "tokens": ["Hie\u00df", "sei\u00b7ne", "gr\u00f6s\u00b7te", "Lust", "ein", "gu\u00b7tes", "Buch", "zu", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ein ander L\u00e4lius/ der m\u00fcssig nie gewesen/", "tokens": ["Ein", "an\u00b7der", "L\u00e4\u00b7lius", "/", "der", "m\u00fcs\u00b7sig", "nie", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NE", "$(", "ART", "ADJD", "ADV", "VAPP", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "Und dessen w\u00fcrdig Haupt die B\u00fcrger-Cron verdient/", "tokens": ["Und", "des\u00b7sen", "w\u00fcr\u00b7dig", "Haupt", "die", "B\u00fcr\u00b7ger\u00b7Cron", "ver\u00b7dient", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADJD", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und da\u00df sein Name stets in unsren Seelen gr\u00fcnt.", "tokens": ["Und", "da\u00df", "sein", "Na\u00b7me", "stets", "in", "un\u00b7sren", "See\u00b7len", "gr\u00fcnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So viel Vollkommenheit/ so hoch- und edle Gaben/", "tokens": ["So", "viel", "Voll\u00b7kom\u00b7men\u00b7heit", "/", "so", "hoch", "und", "ed\u00b7le", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$(", "ADV", "TRUNC", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Die k\u00f6nnen f\u00fcr den Tod kein frey Geleite haben.", "tokens": ["Die", "k\u00f6n\u00b7nen", "f\u00fcr", "den", "Tod", "kein", "frey", "Ge\u00b7lei\u00b7te", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "ART", "NN", "PIAT", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Das Auge schl\u00e4fft jetzt ein/ so f\u00fcr uns hat gewacht/", "tokens": ["Das", "Au\u00b7ge", "schl\u00e4fft", "jetzt", "ein", "/", "so", "f\u00fcr", "uns", "hat", "ge\u00b7wacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "$(", "ADV", "APPR", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Der Kopff ist ohne Rath der allem nachgedacht/", "tokens": ["Der", "Kopff", "ist", "oh\u00b7ne", "Rath", "der", "al\u00b7lem", "nach\u00b7ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ART", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die Zunge kan nicht mehr das Recht Partheyen sprechen/", "tokens": ["Die", "Zun\u00b7ge", "kan", "nicht", "mehr", "das", "Recht", "Par\u00b7the\u00b7yen", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "ADV", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die Ohren horen nicht der Armen ihr Gebrechen/", "tokens": ["Die", "Oh\u00b7ren", "ho\u00b7ren", "nicht", "der", "Ar\u00b7men", "ihr", "Ge\u00b7bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die H\u00e4nde schliessen nicht die Freunde ferner ein.", "tokens": ["Die", "H\u00e4n\u00b7de", "schlies\u00b7sen", "nicht", "die", "Freun\u00b7de", "fer\u00b7ner", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Kurtz/ so viel Sch\u00e4tze deckt der stumme Leichen-Stein.", "tokens": ["Kurtz", "/", "so", "viel", "Sch\u00e4t\u00b7ze", "deckt", "der", "stum\u00b7me", "Lei\u00b7chen\u00b7Stein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "ADV", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.35": {"text": "Wiewol sein Nachruhm lebt/ der giebt der Welt zulesen/", "tokens": ["Wie\u00b7wol", "sein", "Nach\u00b7ruhm", "lebt", "/", "der", "giebt", "der", "Welt", "zu\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$(", "ART", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Da\u00df er ein Scipio bey unsrer Stadt gewesen.", "tokens": ["Da\u00df", "er", "ein", "Sci\u00b7pio", "bey", "uns\u00b7rer", "Stadt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "APPR", "PPOSAT", "NN", "VAPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}}}}