{"textgrid.poem.60657": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es war der Griechen Art und Weise,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es war der Griechen Art und Weise,", "tokens": ["Es", "war", "der", "Grie\u00b7chen", "Art", "und", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn uns nicht t\u00e4uscht die alte Kunde,", "tokens": ["Wenn", "uns", "nicht", "t\u00e4uscht", "die", "al\u00b7te", "Kun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df sie auf jede Meeresreise", "tokens": ["Da\u00df", "sie", "auf", "je\u00b7de", "Mee\u00b7res\u00b7rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mitnahmen Affen und Gauklerhunde.", "tokens": ["Mit\u00b7nah\u00b7men", "Af\u00b7fen", "und", "Gauk\u00b7ler\u00b7hun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Einst stie\u00df ein so ger\u00fcstetes Schiff", "tokens": ["Einst", "stie\u00df", "ein", "so", "ge\u00b7r\u00fcs\u00b7te\u00b7tes", "Schiff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADV", "ADJA", "NN"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Nicht weit von Athen auf ein Felsenriff.", "tokens": ["Nicht", "weit", "von", "A\u00b7then", "auf", "ein", "Fel\u00b7sen\u00b7riff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPR", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Es w\u00e4re alles umgekommen,", "tokens": ["Es", "w\u00e4\u00b7re", "al\u00b7les", "um\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn nicht Delphine mitgeschwommen.", "tokens": ["Wenn", "nicht", "Del\u00b7phi\u00b7ne", "mit\u00b7ge\u00b7schwom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die sind uns Menschen sehr gewogen,", "tokens": ["Die", "sind", "uns", "Men\u00b7schen", "sehr", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sofern uns Plinius nicht belogen.", "tokens": ["So\u00b7fern", "uns", "Pli\u00b7nius", "nicht", "be\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Sie retteten alle nach M\u00f6glichkeit.", "tokens": ["Sie", "ret\u00b7te\u00b7ten", "al\u00b7le", "nach", "M\u00f6g\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Selbst einem der Affen, der Hilfe schreit,", "tokens": ["Selbst", "ei\u00b7nem", "der", "Af\u00b7fen", ",", "der", "Hil\u00b7fe", "schreit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Hat ein Delphin, den er betrogen", "tokens": ["Hat", "ein", "Del\u00b7phin", ",", "den", "er", "be\u00b7tro\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Durch seine Menschen\u00e4hnlichkeit,", "tokens": ["Durch", "sei\u00b7ne", "Men\u00b7schen\u00b7\u00e4hn\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Den sichern R\u00fccken hingebogen.", "tokens": ["Den", "si\u00b7chern", "R\u00fc\u00b7cken", "hin\u00b7ge\u00b7bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Der Aff stieg auf voll Ernst und W\u00fcrde,", "tokens": ["Der", "Aff", "stieg", "auf", "voll", "Ernst", "und", "W\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "War wie Arion anzusehn.", "tokens": ["War", "wie", "A\u00b7rion", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "NN", "VVIZU", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Wie der Delphin nun seine B\u00fcrde", "tokens": ["Wie", "der", "Del\u00b7phin", "nun", "sei\u00b7ne", "B\u00fcr\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Gen Land trug, fragte er den Affen:", "tokens": ["Gen", "Land", "trug", ",", "frag\u00b7te", "er", "den", "Af\u00b7fen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "\u00bbihr seid wohl einer aus Athen?\u00ab", "tokens": ["\u00bb", "ihr", "seid", "wohl", "ei\u00b7ner", "aus", "A\u00b7then", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ART", "APPR", "NE", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "\u00bbja,\u00ab sagte der, \u00bbman kennt mich gut.", "tokens": ["\u00bb", "ja", ",", "\u00ab", "sag\u00b7te", "der", ",", "\u00bb", "man", "kennt", "mich", "gut", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "ART", "$,", "$(", "PIS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Habt Ihr dort einmal was zu schaffen,", "tokens": ["Habt", "Ihr", "dort", "ein\u00b7mal", "was", "zu", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Kommt nur zu mir. In Ansehn stehn", "tokens": ["Kommt", "nur", "zu", "mir", ".", "In", "An\u00b7sehn", "stehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "ADV", "APPR", "PPER", "$.", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Wir dort, in unsern H\u00e4nden ruht", "tokens": ["Wir", "dort", ",", "in", "un\u00b7sern", "H\u00e4n\u00b7den", "ruht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Manch hohes Amt seit manchem Jahr,", "tokens": ["Manch", "ho\u00b7hes", "Amt", "seit", "man\u00b7chem", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Mein Vetter ist oberster Richter sogar.\u00ab", "tokens": ["Mein", "Vet\u00b7ter", "ist", "o\u00b7bers\u00b7ter", "Rich\u00b7ter", "so\u00b7gar", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.27": {"text": "Da sagte Dank das Tier der Flut.", "tokens": ["Da", "sag\u00b7te", "Dank", "das", "Tier", "der", "Flut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "\u00bbso werdet Ihr auch hin und wieder,", "tokens": ["\u00bb", "so", "wer\u00b7det", "Ihr", "auch", "hin", "und", "wie\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "PTKVZ", "KON", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Den herrlichen Pir\u00e4us sehn?\u00ab", "tokens": ["Den", "herr\u00b7li\u00b7chen", "Pi\u00b7r\u00e4us", "sehn", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.30": {"text": "\u00bbmein bester Freund ist der! So bieder", "tokens": ["\u00bb", "mein", "bes\u00b7ter", "Freund", "ist", "der", "!", "So", "bie\u00b7der"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "VAFIN", "ART", "$.", "ADV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Wie er ist keiner in Athen.\u00ab", "tokens": ["Wie", "er", "ist", "kei\u00b7ner", "in", "A\u00b7then", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "PIS", "APPR", "NE", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.32": {"text": "Der Affe hatte, unwissend genug,", "tokens": ["Der", "Af\u00b7fe", "hat\u00b7te", ",", "un\u00b7wis\u00b7send", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Den Namen, den der Hafen trug,", "tokens": ["Den", "Na\u00b7men", ",", "den", "der", "Ha\u00b7fen", "trug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "F\u00fcr eines Menschen Namen genommen", "tokens": ["F\u00fcr", "ei\u00b7nes", "Men\u00b7schen", "Na\u00b7men", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "VVPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "Und schwatzte, wie es manchen gibt,", "tokens": ["Und", "schwatz\u00b7te", ",", "wie", "es", "man\u00b7chen", "gibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Der dreist von allem zu reden liebt,", "tokens": ["Der", "dreist", "von", "al\u00b7lem", "zu", "re\u00b7den", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "APPR", "PIS", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.37": {"text": "Was er noch nie zu sehn bekommen.", "tokens": ["Was", "er", "noch", "nie", "zu", "sehn", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Doch der Delphin erhob den Kopf,", "tokens": ["Doch", "der", "Del\u00b7phin", "er\u00b7hob", "den", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Betrachtete sich den albernen Tropf", "tokens": ["Be\u00b7trach\u00b7te\u00b7te", "sich", "den", "al\u00b7ber\u00b7nen", "Tropf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "Und sah nun, da\u00df er aus den Wogen", "tokens": ["Und", "sah", "nun", ",", "da\u00df", "er", "aus", "den", "Wo\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Nichts als ein Vieh herausgezogen.", "tokens": ["Nichts", "als", "ein", "Vieh", "her\u00b7aus\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Schnell warf er's ab und suchte umher,", "tokens": ["Schnell", "warf", "er's", "ab", "und", "such\u00b7te", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PIS", "PTKVZ", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.43": {"text": "Ob nicht noch ein Mensch zu retten w\u00e4r.", "tokens": ["Ob", "nicht", "noch", "ein", "Mensch", "zu", "ret\u00b7ten", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}