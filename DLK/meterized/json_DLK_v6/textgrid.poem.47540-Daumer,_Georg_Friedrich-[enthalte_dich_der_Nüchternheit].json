{"textgrid.poem.47540": {"metadata": {"author": {"name": "Daumer, Georg Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[enthalte dich der N\u00fcchternheit]", "genre": "verse", "period": "N.A.", "pub_year": 1837, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Enthalte dich der N\u00fcchternheit,", "tokens": ["Ent\u00b7hal\u00b7te", "dich", "der", "N\u00fcch\u00b7tern\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So bist du auf der rechten Bahn;", "tokens": ["So", "bist", "du", "auf", "der", "rech\u00b7ten", "Bahn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn da\u00df der Rausch zur Seligkeit", "tokens": ["Denn", "da\u00df", "der", "Rausch", "zur", "Se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Unn\u00fctze sei, das ist ein Wahn.", "tokens": ["Un\u00b7n\u00fct\u00b7ze", "sei", ",", "das", "ist", "ein", "Wahn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wahrhafter Offenbarung Licht,", "tokens": ["Wahr\u00b7haf\u00b7ter", "Of\u00b7fen\u00b7ba\u00b7rung", "Licht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das wirst du nur im Rausch empfah'n;", "tokens": ["Das", "wirst", "du", "nur", "im", "Rausch", "emp\u00b7fah'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn das der Unberauschte nicht", "tokens": ["Denn", "das", "der", "Un\u00b7be\u00b7rauschte", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "ART", "NN", "PTKNEG"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Ganz finster sei, das ist ein Wahn.", "tokens": ["Ganz", "fins\u00b7ter", "sei", ",", "das", "ist", "ein", "Wahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Sieh an den M\u00f6nch, den fluchenden,", "tokens": ["Sieh", "an", "den", "M\u00f6nch", ",", "den", "flu\u00b7chen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und nimm dir ein Exempel dran!", "tokens": ["Und", "nimm", "dir", "ein", "Ex\u00b7em\u00b7pel", "dran", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Denn da\u00df er nicht mit Haut und Haar", "tokens": ["Denn", "da\u00df", "er", "nicht", "mit", "Haut", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Teufels sei, das ist ein Wahn.", "tokens": ["Des", "Teu\u00b7fels", "sei", ",", "das", "ist", "ein", "Wahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Mit aller Andacht fr\u00fch und spat", "tokens": ["Mit", "al\u00b7ler", "An\u00b7dacht", "fr\u00fch", "und", "spat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lies in der Sch\u00f6nheit Alkoran!", "tokens": ["Lies", "in", "der", "Sch\u00f6n\u00b7heit", "Al\u00b7ko\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Denn da\u00df ein ander heilig Buch", "tokens": ["Denn", "da\u00df", "ein", "an\u00b7der", "hei\u00b7lig", "Buch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJD", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Authentisch sei, das ist ein Wahn.", "tokens": ["Au\u00b7then\u00b7tisch", "sei", ",", "das", "ist", "ein", "Wahn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "Nur nicht dein Ich verg\u00f6ttere;", "tokens": ["Nur", "nicht", "dein", "Ich", "ver\u00b7g\u00f6t\u00b7te\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PPOSAT", "PPER", "VVFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Doch was du liebst, o bet' es an!", "tokens": ["Doch", "was", "du", "liebst", ",", "o", "bet'", "es", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "FM", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn da\u00df die Liebe G\u00f6tzendienst", "tokens": ["Denn", "da\u00df", "die", "Lie\u00b7be", "G\u00f6t\u00b7zen\u00b7dienst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Ketzerei, das ist ein Wahn.", "tokens": ["Und", "Ket\u00b7ze\u00b7rei", ",", "das", "ist", "ein", "Wahn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wie kniet Hafis vor seinem Stern!", "tokens": ["Wie", "kniet", "Ha\u00b7fis", "vor", "sei\u00b7nem", "Stern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und o, wie ist es wohlgethan!", "tokens": ["Und", "o", ",", "wie", "ist", "es", "wohl\u00b7ge\u00b7than", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "$,", "PWAV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn da\u00df dem Gott der Liebe fern", "tokens": ["Denn", "da\u00df", "dem", "Gott", "der", "Lie\u00b7be", "fern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Liebe sei, das ist ein Wahn.", "tokens": ["Die", "Lie\u00b7be", "sei", ",", "das", "ist", "ein", "Wahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}