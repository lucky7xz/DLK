{"textgrid.poem.46185": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Der mensch betr\u00fcb sich oder lach, ist er stets eitel, schlecht und schwach", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O ihr krumme schlimme seelen,", "tokens": ["O", "ihr", "krum\u00b7me", "schlim\u00b7me", "see\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wolt ihr euch lasterreich", "tokens": ["wolt", "ihr", "euch", "las\u00b7ter\u00b7reich"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADJD"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "nu mit diser welt verm\u00e4hlen?", "tokens": ["nu", "mit", "di\u00b7ser", "welt", "ver\u00b7m\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bochet nicht auf eure stell,", "tokens": ["bo\u00b7chet", "nicht", "auf", "eu\u00b7re", "stell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "PPOSAT", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "dan die welt nur eine h\u00f6ll,", "tokens": ["dan", "die", "welt", "nur", "ei\u00b7ne", "h\u00f6ll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "euch zu martern und zu qu\u00e4len.", "tokens": ["euch", "zu", "mar\u00b7tern", "und", "zu", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wollet ihr ein weil nu leben", "tokens": ["Wol\u00b7let", "ihr", "ein", "weil", "nu", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "KOUS", "ADV", "VVINF"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "nach geb\u00fchr, so solt ihr", "tokens": ["nach", "ge\u00b7b\u00fchr", ",", "so", "solt", "ihr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "ADV", "VMFIN", "PPER"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "alsbald nach dem himmel streben:", "tokens": ["als\u00b7bald", "nach", "dem", "him\u00b7mel", "stre\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ist der himmel euch nicht lieb,", "tokens": ["ist", "der", "him\u00b7mel", "euch", "nicht", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "so seid ihr nicht wert, ihr dieb,", "tokens": ["so", "seid", "ihr", "nicht", "wert", ",", "ihr", "dieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "da\u00df er euch sein liecht gegeben.", "tokens": ["da\u00df", "er", "euch", "sein", "liecht", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Lasset euch zu herzen gehen", "tokens": ["Las\u00b7set", "euch", "zu", "her\u00b7zen", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "was f\u00fcr freud, was f\u00fcr leid", "tokens": ["was", "f\u00fcr", "freud", ",", "was", "f\u00fcr", "leid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "APPR", "VVFIN", "$,", "PRELS", "APPR", "ADJD"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "immer in der welt zu sehen:", "tokens": ["im\u00b7mer", "in", "der", "welt", "zu", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kan ein mensch auf disem meer", "tokens": ["kan", "ein", "mensch", "auf", "di\u00b7sem", "meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADJD", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "in so viler \u00fcbeln heer", "tokens": ["in", "so", "vi\u00b7ler", "\u00fc\u00b7beln", "heer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "sicher und forchtlos bestehen?", "tokens": ["si\u00b7cher", "und", "forcht\u00b7los", "be\u00b7ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bis in das grab von der wiegen", "tokens": ["Bis", "in", "das", "grab", "von", "der", "wie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "mu\u00df alhie under m\u00fch", "tokens": ["mu\u00df", "al\u00b7hie", "un\u00b7der", "m\u00fch"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "KON", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "und elend der mensch sich biegen:", "tokens": ["und", "e\u00b7lend", "der", "mensch", "sich", "bie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "dan anfechtung, kreuz und not", "tokens": ["dan", "an\u00b7fech\u00b7tung", ",", "kreuz", "und", "not"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ihn bis in den bittern tod", "tokens": ["ihn", "bis", "in", "den", "bit\u00b7tern", "tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "stets verfolgen und bekriegen.", "tokens": ["stets", "ver\u00b7fol\u00b7gen", "und", "be\u00b7krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Auch ist sein geburt so kl\u00e4glich,", "tokens": ["Auch", "ist", "sein", "ge\u00b7burt", "so", "kl\u00e4g\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df die plag, mit dem tag", "tokens": ["da\u00df", "die", "plag", ",", "mit", "dem", "tag"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "gleich anfangend, kaum ertr\u00e4glich:", "tokens": ["gleich", "an\u00b7fan\u00b7gend", ",", "kaum", "er\u00b7tr\u00e4g\u00b7lich", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "seine schwachheit und der schmerz,", "tokens": ["sei\u00b7ne", "schwach\u00b7heit", "und", "der", "schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "t\u00f6dtend seiner mutter herz,", "tokens": ["t\u00f6d\u00b7tend", "sei\u00b7ner", "mut\u00b7ter", "herz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "seind empfindlich und uns\u00e4glich.", "tokens": ["seind", "emp\u00b7find\u00b7lich", "und", "un\u00b7s\u00e4g\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.6": {"line.1": {"text": "Wan durch schmerzen tief empfunden", "tokens": ["Wan", "durch", "schmer\u00b7zen", "tief", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "VVFIN", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "er voll pein schwach und klein", "tokens": ["er", "voll", "pein", "schwach", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "die geburt nun \u00fcberwunden,", "tokens": ["die", "ge\u00b7burt", "nun", "\u00fc\u00b7berw\u00b7un\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wird er seinem stand gem\u00e4\u00df", "tokens": ["wird", "er", "sei\u00b7nem", "stand", "ge\u00b7m\u00e4\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "VVFIN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "als ein \u00fcbelth\u00e4ter b\u00f6s", "tokens": ["als", "ein", "\u00fc\u00b7belt\u00b7h\u00e4\u00b7ter", "b\u00f6s"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "eingewickelt und gebunden.", "tokens": ["ein\u00b7ge\u00b7wi\u00b7ckelt", "und", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie oft mu\u00df, ihn zu geschweigen,", "tokens": ["Wie", "oft", "mu\u00df", ",", "ihn", "zu", "ge\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "ihm mit fug ohn verzug", "tokens": ["ihm", "mit", "fug", "ohn", "ver\u00b7zug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "seine s\u00e4ugam hilf erzeigen", "tokens": ["sei\u00b7ne", "s\u00e4u\u00b7gam", "hilf", "er\u00b7zei\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "FM", "FM", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und den s\u00e4ugling von dem wust", "tokens": ["und", "den", "s\u00e4ug\u00b7ling", "von", "dem", "wust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "reinigend, mit bloser brust", "tokens": ["rei\u00b7ni\u00b7gend", ",", "mit", "blo\u00b7ser", "brust"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "APPR", "ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "in der gr\u00f6sten k\u00e4ltin s\u00e4ugen!", "tokens": ["in", "der", "gr\u00f6s\u00b7ten", "k\u00e4l\u00b7tin", "s\u00e4u\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nemend ihn bald auf bald nider,", "tokens": ["Ne\u00b7mend", "ihn", "bald", "auf", "bald", "ni\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sunst hilflos, auf der scho\u00df", "tokens": ["sunst", "hil\u00b7flos", ",", "auf", "der", "scho\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "wieget sie ihn hin und wider,", "tokens": ["wie\u00b7get", "sie", "ihn", "hin", "und", "wi\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bis er, weil ihr sorg und m\u00fch", "tokens": ["bis", "er", ",", "weil", "ihr", "sorg", "und", "m\u00fch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "VVFIN", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "reibet seine bein und kn\u00fc,", "tokens": ["rei\u00b7bet", "sei\u00b7ne", "bein", "und", "kn\u00fc", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "st\u00e4rket seine schwache glider.", "tokens": ["st\u00e4r\u00b7ket", "sei\u00b7ne", "schwa\u00b7che", "gli\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Fanget er dan an zu gehen", "tokens": ["Fan\u00b7get", "er", "dan", "an", "zu", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auch die sprach nach und nach", "tokens": ["auch", "die", "sprach", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "VVFIN", "APPR", "KON", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "(bl\u00f6d und lisplend) zu verstehen:", "tokens": ["(", "bl\u00f6d", "und", "lis\u00b7plend", ")", "zu", "ver\u00b7ste\u00b7hen", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "KON", "ADJD", "$(", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ist sein gang und seine bit", "tokens": ["ist", "sein", "gang", "und", "sei\u00b7ne", "bit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "halbe wort und halbe trit,", "tokens": ["hal\u00b7be", "wort", "und", "hal\u00b7be", "trit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "schwach zu reden, schwach zu stehen.", "tokens": ["schwach", "zu", "re\u00b7den", ",", "schwach", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Seine kr\u00e4ften mit den jahren,", "tokens": ["Sei\u00b7ne", "kr\u00e4f\u00b7ten", "mit", "den", "jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "seine witz, seine hitz,", "tokens": ["sei\u00b7ne", "witz", ",", "sei\u00b7ne", "hitz", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "seine arbeit, m\u00fch, gefahren,", "tokens": ["sei\u00b7ne", "ar\u00b7beit", ",", "m\u00fch", ",", "ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nemen mit einander zu,", "tokens": ["ne\u00b7men", "mit", "ein\u00b7an\u00b7der", "zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "allein nimmer ab die ruh,", "tokens": ["al\u00b7lein", "nim\u00b7mer", "ab", "die", "ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "nichts kan ihn f\u00fcr leid bewahren.", "tokens": ["nichts", "kan", "ihn", "f\u00fcr", "leid", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "APPR", "ADJD", "VVINF", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.11": {"line.1": {"text": "Alsbald seine tag nu bl\u00fchen,", "tokens": ["Als\u00b7bald", "sei\u00b7ne", "tag", "nu", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "kan sein mut sich der wut", "tokens": ["kan", "sein", "mut", "sich", "der", "wut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "VAINF", "VMFIN", "PRF", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "seiner jugend nicht entziehen?", "tokens": ["sei\u00b7ner", "ju\u00b7gend", "nicht", "ent\u00b7zie\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "gro\u00df ist dan sein unbestand", "tokens": ["gro\u00df", "ist", "dan", "sein", "un\u00b7be\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und er f\u00e4llt in dise schand,", "tokens": ["und", "er", "f\u00e4llt", "in", "di\u00b7se", "schand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wan er will von jener fliehen.", "tokens": ["wan", "er", "will", "von", "je\u00b7ner", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "APPR", "PDAT", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Spielend mag er sich wol \u00fcben,", "tokens": ["Spie\u00b7lend", "mag", "er", "sich", "wol", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weil er noch ohn ein joch:", "tokens": ["weil", "er", "noch", "ohn", "ein", "joch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "aber ihn mehr zu betr\u00fcben", "tokens": ["a\u00b7ber", "ihn", "mehr", "zu", "be\u00b7tr\u00fc\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "reutet ihm auf einmal auf", "tokens": ["reu\u00b7tet", "ihm", "auf", "ein\u00b7mal", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "aller lastern gro\u00dfer hauf,", "tokens": ["al\u00b7ler", "las\u00b7tern", "gro\u00b7\u00dfer", "hauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "bis da\u00df er sich mu\u00df verlieben.", "tokens": ["bis", "da\u00df", "er", "sich", "mu\u00df", "ver\u00b7lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PRF", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Alsdan under Amors wafen", "tokens": ["Als\u00b7dan", "un\u00b7der", "A\u00b7mors", "wa\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NE", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "taub und blind wie ein kind", "tokens": ["taub", "und", "blind", "wie", "ein", "kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJD", "KOKOM", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "k\u00f6nden ihn zwei augen strafen:", "tokens": ["k\u00f6n\u00b7den", "ihn", "zwei", "au\u00b7gen", "stra\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "CARD", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "hofnung, trost, wollust, genu\u00df,", "tokens": ["hof\u00b7nung", ",", "trost", ",", "wol\u00b7lust", ",", "ge\u00b7nu\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VMFIN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "forcht, verzweiflung, zorn, verdru\u00df", "tokens": ["forcht", ",", "ver\u00b7zwei\u00b7flung", ",", "zorn", ",", "ver\u00b7dru\u00df"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen ihn nicht lassen schlafen.", "tokens": ["wol\u00b7len", "ihn", "nicht", "las\u00b7sen", "schla\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Kan er dises \u00fcberwinden,", "tokens": ["Kan", "er", "di\u00b7ses", "\u00fc\u00b7berw\u00b7in\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "findet er noch vil mehr", "tokens": ["fin\u00b7det", "er", "noch", "vil", "mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "tr\u00fcbsal und ungl\u00fcck dahinden:", "tokens": ["tr\u00fcb\u00b7sal", "und", "un\u00b7gl\u00fcck", "da\u00b7hin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "ehrgeiz, geldgeiz, \u00fcbermut,", "tokens": ["ehr\u00b7geiz", ",", "geld\u00b7geiz", ",", "\u00fc\u00b7ber\u00b7mut", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "hader, h\u00e4ndel, zank und wut", "tokens": ["ha\u00b7der", ",", "h\u00e4n\u00b7del", ",", "zank", "und", "wut"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVFIN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen ihn zu schinden binden.", "tokens": ["wol\u00b7len", "ihn", "zu", "schin\u00b7den", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Kommet er dan fortgegangen,", "tokens": ["Kom\u00b7met", "er", "dan", "fort\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "da\u00df das gl\u00fcck und die strick", "tokens": ["da\u00df", "das", "gl\u00fcck", "und", "die", "strick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "aller laster ihn nicht fangen,", "tokens": ["al\u00b7ler", "las\u00b7ter", "ihn", "nicht", "fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wird er aus der jugend saal", "tokens": ["wird", "er", "aus", "der", "ju\u00b7gend", "saal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "in der alten leut spital", "tokens": ["in", "der", "al\u00b7ten", "leut", "spi\u00b7tal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "schlim und liederlich empfangen.", "tokens": ["schlim", "und", "lie\u00b7der\u00b7lich", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Dan da kommen aufgezogen", "tokens": ["Dan", "da", "kom\u00b7men", "auf\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "kalte fl\u00fc\u00df f\u00fcr die k\u00fc\u00df,", "tokens": ["kal\u00b7te", "fl\u00fc\u00df", "f\u00fcr", "die", "k\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "die ihn unlangst jung betrogen:", "tokens": ["die", "ihn", "un\u00b7langst", "jung", "be\u00b7tro\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "zittrend werden h\u00e4nd und f\u00fc\u00df,", "tokens": ["zitt\u00b7rend", "wer\u00b7den", "h\u00e4nd", "und", "f\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "VAFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df gicht, zipperlein und gr\u00fc\u00df", "tokens": ["da\u00df", "gicht", ",", "zip\u00b7per\u00b7lein", "und", "gr\u00fc\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "$,", "PTKVZ", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "machen ihn krum und gebogen.", "tokens": ["ma\u00b7chen", "ihn", "krum", "und", "ge\u00b7bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KON", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.17": {"line.1": {"text": "Und wan schon das alter ehrlich,", "tokens": ["Und", "wan", "schon", "das", "al\u00b7ter", "ehr\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "ART", "ADJA", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "ist die ehr ihm doch schwer,", "tokens": ["ist", "die", "ehr", "ihm", "doch", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "weil ihn alles ganz beschwerlich:", "tokens": ["weil", "ihn", "al\u00b7les", "ganz", "be\u00b7schwer\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "seine z\u00e4hn nu fallen aus,", "tokens": ["sei\u00b7ne", "z\u00e4hn", "nu", "fal\u00b7len", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "haupt und herz voll schnee und graus", "tokens": ["haupt", "und", "herz", "voll", "schnee", "und", "graus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "NN", "ADJD", "ADJA", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "malen alle ding gef\u00e4hrlich.", "tokens": ["ma\u00b7len", "al\u00b7le", "ding", "ge\u00b7f\u00e4hr\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Ach, wie langsam er nu schreitet", "tokens": ["Ach", ",", "wie", "lang\u00b7sam", "er", "nu", "schrei\u00b7tet"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWAV", "ADJD", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weil die bu\u00df auf dem fu\u00df", "tokens": ["weil", "die", "bu\u00df", "auf", "dem", "fu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "folgend allzeit ihn bestreitet!", "tokens": ["fol\u00b7gend", "all\u00b7zeit", "ihn", "be\u00b7strei\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "alle hofnung ist dahin,", "tokens": ["al\u00b7le", "hof\u00b7nung", "ist", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ach und weh ist sein gewin,", "tokens": ["ach", "und", "weh", "ist", "sein", "ge\u00b7win", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "bis da\u00df ihn der tod erbeutet.", "tokens": ["bis", "da\u00df", "ihn", "der", "tod", "er\u00b7beu\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wie, wa, wan er auch mag leben,", "tokens": ["Wie", ",", "wa", ",", "wan", "er", "auch", "mag", "le\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "XY", "$,", "PWAV", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "jung und alt, warm und kalt,", "tokens": ["jung", "und", "alt", ",", "warm", "und", "kalt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "ihn die krankheiten umgeben;", "tokens": ["ihn", "die", "krank\u00b7hei\u00b7ten", "um\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "schwachheit, sorgen, falsche freind", "tokens": ["schwach\u00b7heit", ",", "sor\u00b7gen", ",", "fal\u00b7sche", "freind"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["ADJD", "$,", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "l\u00fcgen, neid, verleumdung, feind", "tokens": ["l\u00fc\u00b7gen", ",", "neid", ",", "ver\u00b7leum\u00b7dung", ",", "feind"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "ihm verdr\u00fc\u00dflich widerstreben.", "tokens": ["ihm", "ver\u00b7dr\u00fc\u00df\u00b7lich", "wi\u00b7der\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Wie ein vogel durch sein fliegen,", "tokens": ["Wie", "ein", "vo\u00b7gel", "durch", "sein", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "PPOSAT", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "wie ein pfeil in der eil", "tokens": ["wie", "ein", "pfeil", "in", "der", "eil"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "leichtlich kan das aug betriegen,", "tokens": ["leicht\u00b7lich", "kan", "das", "aug", "be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so schnell ist des menschen hab,", "tokens": ["so", "schnell", "ist", "des", "men\u00b7schen", "hab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "und sein schrit zu seinem grab", "tokens": ["und", "sein", "schrit", "zu", "sei\u00b7nem", "grab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "ist nicht weit von seiner wiegen.", "tokens": ["ist", "nicht", "weit", "von", "sei\u00b7ner", "wie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "APPR", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Endlich mu\u00df er sein verm\u00f6gen", "tokens": ["End\u00b7lich", "mu\u00df", "er", "sein", "ver\u00b7m\u00f6\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VAINF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "als den raub in den staub", "tokens": ["als", "den", "raub", "in", "den", "staub"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "mit dem k\u00f6rper niderlegen.", "tokens": ["mit", "dem", "k\u00f6r\u00b7per", "ni\u00b7der\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "also endet nu das spil,", "tokens": ["al\u00b7so", "en\u00b7det", "nu", "das", "spil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df weder l\u00fctzel noch vil", "tokens": ["da\u00df", "we\u00b7der", "l\u00fct\u00b7zel", "noch", "vil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KON", "NE", "ADV", "ADV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "kan ihn, kan er nu bewegen.", "tokens": ["kan", "ihn", ",", "kan", "er", "nu", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Wan man dan nicht kan verneinen,", "tokens": ["Wan", "man", "dan", "nicht", "kan", "ver\u00b7nei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df alhie tausend m\u00fch", "tokens": ["da\u00df", "al\u00b7hie", "tau\u00b7send", "m\u00fch"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJD", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "wider uns sich stets aufleinen:", "tokens": ["wi\u00b7der", "uns", "sich", "stets", "au\u00b7flei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "solten wir von herzen grund", "tokens": ["sol\u00b7ten", "wir", "von", "her\u00b7zen", "grund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "unser elend alle stund", "tokens": ["un\u00b7ser", "e\u00b7lend", "al\u00b7le", "stund"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "nicht beklagen und beweinen?", "tokens": ["nicht", "be\u00b7kla\u00b7gen", "und", "be\u00b7wei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Kan uns aber nichts klug machen,", "tokens": ["Kan", "uns", "a\u00b7ber", "nichts", "klug", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sondern wir ohn geb\u00fchr", "tokens": ["son\u00b7dern", "wir", "ohn", "ge\u00b7b\u00fchr"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "wollen lachen diser sachen:", "tokens": ["wol\u00b7len", "la\u00b7chen", "di\u00b7ser", "sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ach! so lachet reich und arm,", "tokens": ["ach", "!", "so", "la\u00b7chet", "reich", "und", "arm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "lachet, da\u00df es got erbarm,", "tokens": ["la\u00b7chet", ",", "da\u00df", "es", "got", "er\u00b7barm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "eures elends selbs zu lachen!", "tokens": ["eu\u00b7res", "e\u00b7lends", "selbs", "zu", "la\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}