{"dta.poem.8596": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1899", "urn": "urn:nbn:de:kobv:b4-200905192690", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die Diele knackt!", "tokens": ["Die", "Die\u00b7le", "knackt", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Mir graut", "tokens": ["Mir", "graut"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "vor meinem Schatten.", "tokens": ["vor", "mei\u00b7nem", "Schat\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Es hat einen dicken Kr\u00f6tenbauch,", "tokens": ["Es", "hat", "ei\u00b7nen", "di\u00b7cken", "Kr\u00f6\u00b7ten\u00b7bauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Geierkrallen,", "tokens": ["Gei\u00b7er\u00b7kral\u00b7len", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "lange, schlenkernde Affenarme und Schweinsaugen . . .", "tokens": ["lan\u00b7ge", ",", "schlen\u00b7kern\u00b7de", "Af\u00b7fen\u00b7ar\u00b7me", "und", "Schwein\u00b7sau\u00b7gen", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "KON", "NN", "$.", "$.", "$."], "meter": "+-+--+-+--++-", "measure": "trochaic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Ich leuchte in alle Winkel.", "tokens": ["Ich", "leuch\u00b7te", "in", "al\u00b7le", "Win\u00b7kel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Staub,", "tokens": ["Staub", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "abgebl\u00e4tterter Kalk, tote Fliegen und Spinnweben.", "tokens": ["ab\u00b7ge\u00b7bl\u00e4t\u00b7ter\u00b7ter", "Kalk", ",", "to\u00b7te", "Flie\u00b7gen", "und", "Spinn\u00b7we\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+--+--++-", "measure": "trochaic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Wie ich mich endlich unter das Bett b\u00fccke,", "tokens": ["Wie", "ich", "mich", "end\u00b7lich", "un\u00b7ter", "das", "Bett", "b\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die Haare str\u00e4uben sich mir, das Licht schlottert,", "tokens": ["die", "Haa\u00b7re", "str\u00e4u\u00b7ben", "sich", "mir", ",", "das", "Licht", "schlot\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PPER", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+--", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "in eine Ecke geklemmt,", "tokens": ["in", "ei\u00b7ne", "E\u00b7cke", "ge\u00b7klemmt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "sitzt das Biest da.", "tokens": ["sitzt", "das", "Biest", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Aus seinem Maul,", "tokens": ["Aus", "sei\u00b7nem", "Maul", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "halb zerkaut,", "tokens": ["halb", "zer\u00b7kaut", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "h\u00e4ngt mein Pantoffel.", "tokens": ["h\u00e4ngt", "mein", "Pan\u00b7tof\u00b7fel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Entsetzt", "tokens": ["Ent\u00b7setzt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "stieren wir uns an.", "tokens": ["stie\u00b7ren", "wir", "uns", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Leise,", "tokens": ["Lei\u00b7se", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "hin und her,", "tokens": ["hin", "und", "her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "ringelt sich sein Rattenschwanz.", "tokens": ["rin\u00b7gelt", "sich", "sein", "Rat\u00b7ten\u00b7schwanz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}