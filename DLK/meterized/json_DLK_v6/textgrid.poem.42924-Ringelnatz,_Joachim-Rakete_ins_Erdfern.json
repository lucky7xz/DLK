{"textgrid.poem.42924": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Rakete ins Erdfern", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Rakete ins Erdfern, zielfremder Schu\u00df \u2013 \u2013??", "tokens": ["Ra\u00b7ke\u00b7te", "ins", "Erd\u00b7fern", ",", "ziel\u00b7frem\u00b7der", "Schu\u00df", "\u2013", "\u2013", "??"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "ADJA", "NN", "$(", "$(", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ja, wenn es sein darf oder sein mu\u00df.", "tokens": ["Ja", ",", "wenn", "es", "sein", "darf", "o\u00b7der", "sein", "mu\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "VAINF", "VMFIN", "KON", "VAINF", "VMFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch der Eitle oder der \u00dcberm\u00fctige", "tokens": ["Doch", "der", "Eit\u00b7le", "o\u00b7der", "der", "\u00dc\u00b7berm\u00b7\u00fc\u00b7ti\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Z\u00e4hle sonst nicht aufs Allg\u00fctige.", "tokens": ["Z\u00e4h\u00b7le", "sonst", "nicht", "aufs", "All\u00b7g\u00fc\u00b7ti\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "APPRART", "ADJA", "$."], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}}, "stanza.2": {"line.1": {"text": "Sch\u00f6n ist das Wollen,", "tokens": ["Sch\u00f6n", "ist", "das", "Wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wenn Ehrlichkeiten die Mittel ihm gaben.", "tokens": ["Wenn", "Ehr\u00b7lich\u00b7kei\u00b7ten", "die", "Mit\u00b7tel", "ihm", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Aber die Ausf\u00fchrer sollen", "tokens": ["A\u00b7ber", "die", "Aus\u00b7f\u00fch\u00b7rer", "sol\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die ehren, die es ausgerechnet haben.", "tokens": ["Die", "eh\u00b7ren", ",", "die", "es", "aus\u00b7ge\u00b7rech\u00b7net", "ha\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "$,", "PRELS", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und die als erste ein Ziel erreichen,", "tokens": ["Und", "die", "als", "ers\u00b7te", "ein", "Ziel", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "KOKOM", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Weil sie pers\u00f6nlich den Schu\u00df unternommen,", "tokens": ["Weil", "sie", "per\u00b7s\u00f6n\u00b7lich", "den", "Schu\u00df", "un\u00b7ter\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+++-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "M\u00f6gen vor allem sich gleich vergleichen", "tokens": ["M\u00f6\u00b7gen", "vor", "al\u00b7lem", "sich", "gleich", "ver\u00b7glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "PIS", "PRF", "ADV", "VVINF"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Zudritt mit K\u00fchnen,", "tokens": ["Zu\u00b7dritt", "mit", "K\u00fch\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Zuzweit mit Weisen,", "tokens": ["Zu\u00b7zweit", "mit", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Zuerst mit Frommen.", "tokens": ["Zu\u00b7erst", "mit", "From\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}}}}