{"textgrid.poem.63904": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "Asylrecht", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In eine Stadt des alten Hellas kam", "tokens": ["In", "ei\u00b7ne", "Stadt", "des", "al\u00b7ten", "Hel\u00b7las", "kam"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Einst ein verfemter Mann mit Weib und Kind,", "tokens": ["Einst", "ein", "ver\u00b7fem\u00b7ter", "Mann", "mit", "Weib", "und", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Um schwere Blutschuld als ein G\u00f6tterfeind", "tokens": ["Um", "schwe\u00b7re", "Blut\u00b7schuld", "als", "ein", "G\u00f6t\u00b7ter\u00b7feind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ADJA", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Verjagt von Haus und Herd.", "tokens": ["Ver\u00b7jagt", "von", "Haus", "und", "Herd", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Er siedelte", "tokens": ["Er", "sie\u00b7del\u00b7te"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "--+-", "measure": "anapaest.init"}, "line.6": {"text": "Sich sch\u00fcchtern an und sorgte Tag und Nacht,", "tokens": ["Sich", "sch\u00fcch\u00b7tern", "an", "und", "sorg\u00b7te", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "PTKVZ", "KON", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Dem Hunger wehrend mit geduld'gem Flei\u00df,", "tokens": ["Dem", "Hun\u00b7ger", "weh\u00b7rend", "mit", "ge\u00b7duld'\u00b7gem", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und da die Not erfindrisch macht, gedieh", "tokens": ["Und", "da", "die", "Not", "er\u00b7fin\u00b7drisch", "macht", ",", "ge\u00b7dieh"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ihm sein Gewerb.", "tokens": ["Ihm", "sein", "Ge\u00b7werb", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Das sahn die M\u00e4chtigen", "tokens": ["Das", "sahn", "die", "M\u00e4ch\u00b7ti\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Der Stadt voll Neid und Ha\u00df und sprachen so:", "tokens": ["Der", "Stadt", "voll", "Neid", "und", "Ha\u00df", "und", "spra\u00b7chen", "so", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "KON", "NN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Liegt nicht die Blutschuld \u00fcber seinem Haupt", "tokens": ["Liegt", "nicht", "die", "Blut\u00b7schuld", "\u00fc\u00b7ber", "sei\u00b7nem", "Haupt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Noch unges\u00fchnt, und der Verfemte doch", "tokens": ["Noch", "un\u00b7ge\u00b7s\u00fchnt", ",", "und", "der", "Ver\u00b7fem\u00b7te", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KON", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Wird hier geduldet? Wenn der G\u00f6tter Zorn", "tokens": ["Wird", "hier", "ge\u00b7dul\u00b7det", "?", "Wenn", "der", "G\u00f6t\u00b7ter", "Zorn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "VVPP", "$.", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Auf uns herabf\u00e4hrt, b\u00fc\u00dfen wir f\u00fcr ihn.", "tokens": ["Auf", "uns", "her\u00b7ab\u00b7f\u00e4hrt", ",", "b\u00fc\u00b7\u00dfen", "wir", "f\u00fcr", "ihn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "$,", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Und doch \u2013 ein Gastrecht ward ihm einger\u00e4umt;", "tokens": ["Und", "doch", "\u2013", "ein", "Gast\u00b7recht", "ward", "ihm", "ein\u00b7ge\u00b7r\u00e4umt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Wer es verletzt, den straft Zeus Xenios.", "tokens": ["Wer", "es", "ver\u00b7letzt", ",", "den", "straft", "Zeus", "Xe\u00b7ni\u00b7os", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "ART", "NN", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So sandten sie nach Delphi Botschaft hin,", "tokens": ["So", "sand\u00b7ten", "sie", "nach", "Del\u00b7phi", "Bot\u00b7schaft", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu forschen aus Orakelmund, wie sie", "tokens": ["Zu", "for\u00b7schen", "aus", "O\u00b7ra\u00b7kel\u00b7mund", ",", "wie", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "$,", "PWAV", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit ihm verfahren sollten. Da erscholl", "tokens": ["Mit", "ihm", "ver\u00b7fah\u00b7ren", "soll\u00b7ten", ".", "Da", "er\u00b7scholl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "VVINF", "VMFIN", "$.", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "An des Gesandten Ohr der Pythia Spruch:", "tokens": ["An", "des", "Ge\u00b7sand\u00b7ten", "Ohr", "der", "Py\u00b7thia", "Spruch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "ART", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nimm alle Nester junger V\u00f6gel aus,", "tokens": ["Nimm", "al\u00b7le", "Nes\u00b7ter", "jun\u00b7ger", "V\u00f6\u00b7gel", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die droben hangen rings am Tempelsims! \u2013", "tokens": ["Die", "dro\u00b7ben", "han\u00b7gen", "rings", "am", "Tem\u00b7pel\u00b7sims", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "VVFIN", "ADV", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und jener, ob erschreckt und z\u00f6gernd auch,", "tokens": ["Und", "je\u00b7ner", ",", "ob", "er\u00b7schreckt", "und", "z\u00f6\u00b7gernd", "auch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "KOUS", "VVPP", "KON", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Gehorcht und tat's. Da, wie er noch am Werk,", "tokens": ["Ge\u00b7horcht", "und", "tat'", "s.", "Da", ",", "wie", "er", "noch", "am", "Werk", ","], "token_info": ["word", "word", "word", "abbreviation", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "VVIMP", "ADV", "$,", "PWAV", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erklang aus heitrer Luft ein Donnerschlag,", "tokens": ["Er\u00b7klang", "aus", "hei\u00b7trer", "Luft", "ein", "Don\u00b7ner\u00b7schlag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und unterirdisch dr\u00f6hnt' ein Echo nach.", "tokens": ["Und", "un\u00b7ter\u00b7ir\u00b7disch", "dr\u00f6hnt'", "ein", "E\u00b7cho", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Tag ward in Nacht verkehrt, als br\u00e4ch' herein", "tokens": ["Tag", "ward", "in", "Nacht", "ver\u00b7kehrt", ",", "als", "br\u00e4ch'", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "NN", "VVPP", "$,", "KOUS", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Von Erd' und Himmel her Weltuntergang.", "tokens": ["Von", "Erd'", "und", "Him\u00b7mel", "her", "Welt\u00b7un\u00b7ter\u00b7gang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APZR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Entsetzt zur heil'gen Pythia fl\u00fcchtete", "tokens": ["Ent\u00b7setzt", "zur", "heil'\u00b7gen", "Py\u00b7thia", "fl\u00fcch\u00b7te\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Mann und klagte: War's nicht ", "tokens": ["Der", "Mann", "und", "klag\u00b7te", ":", "Wa\u00b7r's", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "KON", "VVFIN", "$.", "VAFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was nun der \u00dcber-, Unterird'schen Grimm", "tokens": ["Was", "nun", "der", "\u00dc\u00b7ber", ",", "Un\u00b7ter\u00b7ird'\u00b7schen", "Grimm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "ADV", "ART", "TRUNC", "$,", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Zumal emp\u00f6rt? Nun sch\u00fctze mich! \u2013", "tokens": ["Zu\u00b7mal", "em\u00b7p\u00f6rt", "?", "Nun", "sch\u00fct\u00b7ze", "mich", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$.", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Alsbald", "tokens": ["Als\u00b7bald"], "token_info": ["word"], "pos": ["ADV"], "meter": "-+", "measure": "iambic.single"}, "line.12": {"text": "Kam Antwort ihm aus gottgeweihtem Mund:", "tokens": ["Kam", "Ant\u00b7wort", "ihm", "aus", "gott\u00b7ge\u00b7weih\u00b7tem", "Mund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.13": {"text": "Wer fragt, ob er am Gastrecht freveln darf,", "tokens": ["Wer", "fragt", ",", "ob", "er", "am", "Gast\u00b7recht", "fre\u00b7veln", "darf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ist gottlos, und gerechter G\u00f6tterzorn", "tokens": ["Ist", "gott\u00b7los", ",", "und", "ge\u00b7rech\u00b7ter", "G\u00f6t\u00b7ter\u00b7zorn"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "$,", "KON", "ADJD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "F\u00e4llt auf sein Haupt. \u2013", "tokens": ["F\u00e4llt", "auf", "sein", "Haupt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "So sprach ein Heidenmund", "tokens": ["So", "sprach", "ein", "Hei\u00b7den\u00b7mund"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Vor zwei Jahrtausenden. Und ihr, die ihr", "tokens": ["Vor", "zwei", "Jahr\u00b7tau\u00b7sen\u00b7den", ".", "Und", "ihr", ",", "die", "ihr"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "CARD", "NN", "$.", "KON", "PPER", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Euch r\u00fchmt der reinern, tiefern Gottesfurcht,", "tokens": ["Euch", "r\u00fchmt", "der", "rei\u00b7nern", ",", "tie\u00b7fern", "Got\u00b7tes\u00b7furcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Wie redet ihr?", "tokens": ["Wie", "re\u00b7det", "ihr", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}