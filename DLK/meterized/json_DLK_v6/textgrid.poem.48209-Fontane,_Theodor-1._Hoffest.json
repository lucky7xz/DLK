{"textgrid.poem.48209": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "1. Hoffest", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Erst kommt der Zar, der Herr aller Reu\u00dfen,", "tokens": ["Erst", "kommt", "der", "Zar", ",", "der", "Herr", "al\u00b7ler", "Reu\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dann kommt das offizielle Preu\u00dfen.", "tokens": ["Dann", "kommt", "das", "of\u00b7fi\u00b7zi\u00b7el\u00b7le", "Preu\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Im Wei\u00dfen Saal, unter der Gittervergildung,", "tokens": ["Im", "Wei\u00b7\u00dfen", "Saal", ",", "un\u00b7ter", "der", "Git\u00b7ter\u00b7ver\u00b7gil\u00b7dung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Eben beginnt die Gruppenbildung:", "tokens": ["E\u00b7ben", "be\u00b7ginnt", "die", "Grup\u00b7pen\u00b7bil\u00b7dung", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Geheimr\u00e4te, nach Regel und Normen,", "tokens": ["Ge\u00b7heim\u00b7r\u00e4\u00b7te", ",", "nach", "Re\u00b7gel", "und", "Nor\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "In Fracks, in Orden, in Staatsuniformen.", "tokens": ["In", "Fracks", ",", "in", "Or\u00b7den", ",", "in", "Staa\u00b7tsu\u00b7ni\u00b7for\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "NN", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Deinem besten Freunde, so rat' ich dir gern,", "tokens": ["Dei\u00b7nem", "bes\u00b7ten", "Freun\u00b7de", ",", "so", "rat'", "ich", "dir", "gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Er kennt dich, ach, und kennt dich nicht,", "tokens": ["Er", "kennt", "dich", ",", "ach", ",", "und", "kennt", "dich", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ITJ", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein eignes L\u00e4cheln umschwebt sein Gesicht,", "tokens": ["Ein", "eig\u00b7nes", "L\u00e4\u00b7cheln", "um\u00b7schwebt", "sein", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "Seren und ernst und verlegen zugleich,", "tokens": ["Se\u00b7ren", "und", "ernst", "und", "ver\u00b7le\u00b7gen", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KON", "ADJD", "ADV", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.4": {"line.1": {"text": "Deinem besten Freunde, so rat' ich dir gern,", "tokens": ["Dei\u00b7nem", "bes\u00b7ten", "Freun\u00b7de", ",", "so", "rat'", "ich", "dir", "gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Er stellt dich vor, doch du wirst's nicht froh,", "tokens": ["Er", "stellt", "dich", "vor", ",", "doch", "du", "wir\u00b7st's", "nicht", "froh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Alles sp\u00f6ttisch und nur so so:", "tokens": ["Al\u00b7les", "sp\u00f6t\u00b7tisch", "und", "nur", "so", "so", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "KON", "ADV", "ADV", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "\u00bbsie kennen ja unsren ber\u00fchmten S\u00e4nger\u00ab,", "tokens": ["\u00bb", "sie", "ken\u00b7nen", "ja", "un\u00b7sren", "be\u00b7r\u00fchm\u00b7ten", "S\u00e4n\u00b7ger", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$(", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Alle Gesichter werden l\u00e4nger.", "tokens": ["Al\u00b7le", "Ge\u00b7sich\u00b7ter", "wer\u00b7den", "l\u00e4n\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "So geht es dir weiter, dir wenig nach Wunsch,", "tokens": ["So", "geht", "es", "dir", "wei\u00b7ter", ",", "dir", "we\u00b7nig", "nach", "Wunsch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Bis er endlich kommt \u2013 der Fastnachtspunsch,", "tokens": ["Bis", "er", "end\u00b7lich", "kommt", "\u2013", "der", "Fast\u00b7nachts\u00b7punsch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$(", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Pfannkuchen und Punsch, und sieh, im Gem\u00fcte,", "tokens": ["Pfann\u00b7ku\u00b7chen", "und", "Pun\u00b7sch", ",", "und", "sieh", ",", "im", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "KON", "VVFIN", "$,", "APPRART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Bl\u00fcht wieder auf die Menschenbl\u00fcte,", "tokens": ["Bl\u00fcht", "wie\u00b7der", "auf", "die", "Men\u00b7schen\u00b7bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gemeinschaftlich und fidel und munter", "tokens": ["Ge\u00b7mein\u00b7schaft\u00b7lich", "und", "fi\u00b7del", "und", "mun\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJD", "KON", "ADJD"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Geht's schlie\u00dflich die Wendeltreppe hinunter,", "tokens": ["Geht's", "schlie\u00df\u00b7lich", "die", "Wen\u00b7del\u00b7trep\u00b7pe", "hin\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und unten hei\u00dft's wie vor drei\u00dfig Jahren:", "tokens": ["Und", "un\u00b7ten", "hei\u00dft's", "wie", "vor", "drei\u00b7\u00dfig", "Jah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "KOKOM", "APPR", "CARD", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "\u00bbwillst du nicht mit mir nach Hause fahren?\u00ab", "tokens": ["\u00bb", "willst", "du", "nicht", "mit", "mir", "nach", "Hau\u00b7se", "fah\u00b7ren", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "PTKNEG", "APPR", "PPER", "APPR", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}