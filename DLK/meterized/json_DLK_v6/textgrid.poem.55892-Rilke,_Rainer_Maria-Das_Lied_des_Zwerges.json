{"textgrid.poem.55892": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Das Lied des Zwerges", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Meine Seele ist vielleicht grad und gut;", "tokens": ["Mei\u00b7ne", "See\u00b7le", "ist", "viel\u00b7leicht", "grad", "und", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "KON", "ADJD", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "aber mein Herz, mein verbogenes Blut,", "tokens": ["a\u00b7ber", "mein", "Herz", ",", "mein", "ver\u00b7bo\u00b7ge\u00b7nes", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "alles das, was mir wehe tut,", "tokens": ["al\u00b7les", "das", ",", "was", "mir", "we\u00b7he", "tut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDS", "$,", "PWS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "kann sie nicht aufrecht tragen.", "tokens": ["kann", "sie", "nicht", "auf\u00b7recht", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Sie hat keinen Garten, sie hat kein Bett,", "tokens": ["Sie", "hat", "kei\u00b7nen", "Gar\u00b7ten", ",", "sie", "hat", "kein", "Bett", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "sie h\u00e4ngt an meinem scharfen Skelett", "tokens": ["sie", "h\u00e4ngt", "an", "mei\u00b7nem", "schar\u00b7fen", "Ske\u00b7lett"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "mit entsetztem Fl\u00fcgelschlagen.", "tokens": ["mit", "ent\u00b7setz\u00b7tem", "Fl\u00fc\u00b7gel\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Aus meinen H\u00e4nden wird auch nichts mehr.", "tokens": ["Aus", "mei\u00b7nen", "H\u00e4n\u00b7den", "wird", "auch", "nichts", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ADV", "PIS", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie verk\u00fcmmert sie sind: sieh her:", "tokens": ["Wie", "ver\u00b7k\u00fcm\u00b7mert", "sie", "sind", ":", "sieh", "her", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "VAFIN", "$.", "VVIMP", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "z\u00e4he h\u00fcpfen sie, feucht und schwer,", "tokens": ["z\u00e4\u00b7he", "h\u00fcp\u00b7fen", "sie", ",", "feucht", "und", "schwer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "wie kleine Kr\u00f6ten nach Regen.", "tokens": ["wie", "klei\u00b7ne", "Kr\u00f6\u00b7ten", "nach", "Re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und das Andre an mir ist", "tokens": ["Und", "das", "And\u00b7re", "an", "mir", "ist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PIS", "APPR", "PPER", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "abgetragen und alt und trist;", "tokens": ["ab\u00b7ge\u00b7tra\u00b7gen", "und", "alt", "und", "trist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "KON", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "warum z\u00f6gert Gott, auf den Mist", "tokens": ["wa\u00b7rum", "z\u00f6\u00b7gert", "Gott", ",", "auf", "den", "Mist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "alles das hinzulegen.", "tokens": ["al\u00b7les", "das", "hin\u00b7zu\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ART", "VVIZU", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "Ob er mir z\u00fcrnt f\u00fcr mein Gesicht", "tokens": ["Ob", "er", "mir", "z\u00fcrnt", "f\u00fcr", "mein", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit dem m\u00fcrrischen Munde?", "tokens": ["mit", "dem", "m\u00fcr\u00b7ri\u00b7schen", "Mun\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Es war ja so oft bereit, ganz licht", "tokens": ["Es", "war", "ja", "so", "oft", "be\u00b7reit", ",", "ganz", "licht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,", "ADV", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "und klar zu werden im Grunde;", "tokens": ["und", "klar", "zu", "wer\u00b7den", "im", "Grun\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VAINF", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "aber nichts kam ihm je so dicht", "tokens": ["a\u00b7ber", "nichts", "kam", "ihm", "je", "so", "dicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "ADV", "ADV", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "wie die gro\u00dfen Hunde.", "tokens": ["wie", "die", "gro\u00b7\u00dfen", "Hun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Und die Hunde haben das nicht.", "tokens": ["Und", "die", "Hun\u00b7de", "ha\u00b7ben", "das", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PDS", "PTKNEG", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}}}}