{"textgrid.poem.57503": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "An Seine Wohlehrw\u00fcrden, Herrn Nicolaus Kelz, Pastorn zu Waldau in Schlesien, und der K\u00f6nigl. D. Ges. zu K\u00f6nigsberg Mitgliede, zu seiner Magisterpromotion", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gl\u00fcck zu, beliebter ", "tokens": ["Gl\u00fcck", "zu", ",", "be\u00b7lieb\u00b7ter"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "PTKVZ", "$,", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Dazu dein edler Flei\u00df dich selbst geschickt gemacht.", "tokens": ["Da\u00b7zu", "dein", "ed\u00b7ler", "Flei\u00df", "dich", "selbst", "ge\u00b7schickt", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "ADJA", "NN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Weisheit schm\u00fccket dich durch ihrer Lehrer H\u00e4nde,", "tokens": ["Die", "Weis\u00b7heit", "schm\u00fc\u00b7cket", "dich", "durch", "ih\u00b7rer", "Leh\u00b7rer", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als ob sie sich dir selbst zum Eigenthum verb\u00e4nde.", "tokens": ["Als", "ob", "sie", "sich", "dir", "selbst", "zum", "Ei\u00b7gen\u00b7thum", "ver\u00b7b\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PRF", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie hats mit Lust gesehn, wie deinen muntern Geist,", "tokens": ["Sie", "hats", "mit", "Lust", "ge\u00b7sehn", ",", "wie", "dei\u00b7nen", "mun\u00b7tern", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "VVPP", "$,", "PWAV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der sich mit aller Macht der Niedrigkeit entrei\u00dft,", "tokens": ["Der", "sich", "mit", "al\u00b7ler", "Macht", "der", "Nied\u00b7rig\u00b7keit", "ent\u00b7rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PIAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Wissenschaft gen\u00e4hrt. Sie hat ihn selbst gest\u00e4rket,", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "ge\u00b7n\u00e4hrt", ".", "Sie", "hat", "ihn", "selbst", "ge\u00b7st\u00e4r\u00b7ket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So, da\u00df man t\u00e4glich fast dein Wachsthum angemerket.", "tokens": ["So", ",", "da\u00df", "man", "t\u00e4g\u00b7lich", "fast", "dein", "Wach\u00b7sthum", "an\u00b7ge\u00b7mer\u00b7ket", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "ADJD", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du kennst nunmehr die Welt, dich selbst, und Gottes Kraft,", "tokens": ["Du", "kennst", "nun\u00b7mehr", "die", "Welt", ",", "dich", "selbst", ",", "und", "Got\u00b7tes", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PPER", "ADV", "$,", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die allenthalben wirkt und lauter Gutes schafft.", "tokens": ["Die", "al\u00b7len\u00b7thal\u00b7ben", "wirkt", "und", "lau\u00b7ter", "Gu\u00b7tes", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Du sp\u00fcrst der Weisheit nach, die jedes Gras uns lehret,", "tokens": ["Du", "sp\u00fcrst", "der", "Weis\u00b7heit", "nach", ",", "die", "je\u00b7des", "Gras", "uns", "leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und nimmst der G\u00fcte wahr, die man erstaunend ehret.", "tokens": ["Und", "nimmst", "der", "G\u00fc\u00b7te", "wahr", ",", "die", "man", "er\u00b7stau\u00b7nend", "eh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "PIS", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Du kennst auch das Gesetz der redenden Natur,", "tokens": ["Du", "kennst", "auch", "das", "Ge\u00b7setz", "der", "re\u00b7den\u00b7den", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der Laster schn\u00f6den Schein, der wahren Tugend Spur;", "tokens": ["Der", "Las\u00b7ter", "schn\u00f6\u00b7den", "Schein", ",", "der", "wah\u00b7ren", "Tu\u00b7gend", "Spur", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und merkest kl\u00fcglich an, warum der Menschen Thaten", "tokens": ["Und", "mer\u00b7kest", "kl\u00fcg\u00b7lich", "an", ",", "wa\u00b7rum", "der", "Men\u00b7schen", "Tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Nicht stets nach ihrem Zweck zu ihrem Heil gerathen.", "tokens": ["Nicht", "stets", "nach", "ih\u00b7rem", "Zweck", "zu", "ih\u00b7rem", "Heil", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Du selbst bist auch bem\u00fcht, die rechte Bahn zu gehn,", "tokens": ["Du", "selbst", "bist", "auch", "be\u00b7m\u00fcht", ",", "die", "rech\u00b7te", "Bahn", "zu", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "VVPP", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Dein wahres Wohl zu baun, dein Gl\u00fccke zu erh\u00f6hn.", "tokens": ["Dein", "wah\u00b7res", "Wohl", "zu", "baun", ",", "dein", "Gl\u00fc\u00b7cke", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und darum konnte dirs ", "tokens": ["Und", "da\u00b7rum", "konn\u00b7te", "dirs"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PAV", "VMFIN", "PIS"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Der weisen Meister Schmuck, den Lehrerhut, zu tragen.", "tokens": ["Der", "wei\u00b7sen", "Meis\u00b7ter", "Schmuck", ",", "den", "Leh\u00b7rer\u00b7hut", ",", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Das ist noch nicht genug. Auch ", "tokens": ["Das", "ist", "noch", "nicht", "ge\u00b7nug", ".", "Auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "ADV", "$.", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Es hie\u00df: Du h\u00e4ttest dich mit vielem Ernst beflissen,", "tokens": ["Es", "hie\u00df", ":", "Du", "h\u00e4t\u00b7test", "dich", "mit", "vie\u00b7lem", "Ernst", "be\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "PPER", "APPR", "PIS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der gr\u00f6\u00dften Meister Kunst im Reden recht zu wissen;", "tokens": ["Der", "gr\u00f6\u00df\u00b7ten", "Meis\u00b7ter", "Kunst", "im", "Re\u00b7den", "recht", "zu", "wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPRART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du h\u00e4ttest jener Bahn der Alten nachgesp\u00fcrt,", "tokens": ["Du", "h\u00e4t\u00b7test", "je\u00b7ner", "Bahn", "der", "Al\u00b7ten", "nach\u00b7ge\u00b7sp\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Und w\u00fcrdest dir einmal der M\u00e4nner Preis erwerben,", "tokens": ["Und", "w\u00fcr\u00b7dest", "dir", "ein\u00b7mal", "der", "M\u00e4n\u00b7ner", "Preis", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die, was den Ruhm betrifft, in Wahrheit niemals sterben.", "tokens": ["Die", ",", "was", "den", "Ruhm", "be\u00b7tr\u00b7ifft", ",", "in", "Wahr\u00b7heit", "nie\u00b7mals", "ster\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ART", "NN", "VVFIN", "$,", "APPR", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Auch die\u00df hat dir, o Freund! ", "tokens": ["Auch", "die\u00df", "hat", "dir", ",", "o", "Freund", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "PPER", "$,", "FM", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Sie liebt die Reden sehr, darinnen Weisheit steckt:", "tokens": ["Sie", "liebt", "die", "Re\u00b7den", "sehr", ",", "da\u00b7rin\u00b7nen", "Weis\u00b7heit", "steckt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Drum scheinst du doppelt werth, den Titel zu erlangen,", "tokens": ["Drum", "scheinst", "du", "dop\u00b7pelt", "werth", ",", "den", "Ti\u00b7tel", "zu", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "ADJD", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Womit von Alters her der Weisheit Lehrer prangen.", "tokens": ["Wo\u00b7mit", "von", "Al\u00b7ters", "her", "der", "Weis\u00b7heit", "Leh\u00b7rer", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "APZR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Jedoch, belohnter Kelz! was sagt ", "tokens": ["Je\u00b7doch", ",", "be\u00b7lohn\u00b7ter", "Kelz", "!", "was", "sagt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "ADJA", "NN", "$.", "PWS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn wir am Plei\u00dfenstrom, im Reden oder Dichten,", "tokens": ["Wenn", "wir", "am", "Plei\u00b7\u00dfen\u00b7strom", ",", "im", "Re\u00b7den", "o\u00b7der", "Dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "$,", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Uns nicht nach jedem Ton der Odermusen richten.", "tokens": ["Uns", "nicht", "nach", "je\u00b7dem", "Ton", "der", "O\u00b7der\u00b7mu\u00b7sen", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "PIAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du weist ja mehr als wohl, was deine Vaterstadt", "tokens": ["Du", "weist", "ja", "mehr", "als", "wohl", ",", "was", "dei\u00b7ne", "Va\u00b7ter\u00b7stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "KOKOM", "ADV", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "F\u00fcr Eifersucht und Zorn auf unsre Linden hat.", "tokens": ["F\u00fcr", "Ei\u00b7fer\u00b7sucht", "und", "Zorn", "auf", "uns\u00b7re", "Lin\u00b7den", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "PPOSAT", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du weist, wie sehr sie z\u00fcrnt, wenn unsre Mei\u00dfnerfl\u00f6ten", "tokens": ["Du", "weist", ",", "wie", "sehr", "sie", "z\u00fcrnt", ",", "wenn", "uns\u00b7re", "Mei\u00df\u00b7ner\u00b7fl\u00f6\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADV", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sich auch einmal erk\u00fchnt, mit Schlesiens Poeten", "tokens": ["Sich", "auch", "ein\u00b7mal", "er\u00b7k\u00fchnt", ",", "mit", "Schle\u00b7si\u00b7ens", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADV", "ADV", "VVPP", "$,", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Wettstreit einzugehn; wenn sich ein Gr\u00fcbler wagt,", "tokens": ["Den", "Wett\u00b7streit", "ein\u00b7zu\u00b7gehn", ";", "wenn", "sich", "ein", "Gr\u00fcb\u00b7ler", "wagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$.", "KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.10": {"text": "Wie k\u00f6mmt es denn, o Freund! da\u00df du dich nicht gescheuet,", "tokens": ["Wie", "k\u00f6mmt", "es", "denn", ",", "o", "Freund", "!", "da\u00df", "du", "dich", "nicht", "ge\u00b7scheu\u00b7et", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "$,", "FM", "NN", "$.", "KOUS", "PPER", "PRF", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und nebst der Weisheit, dich der Redekunst geweihet,", "tokens": ["Und", "nebst", "der", "Weis\u00b7heit", ",", "dich", "der", "Re\u00b7de\u00b7kunst", "ge\u00b7wei\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So, wie sie Leipzig liebt? das itzt den Trieb verdammt,", "tokens": ["So", ",", "wie", "sie", "Leip\u00b7zig", "liebt", "?", "das", "itzt", "den", "Trieb", "ver\u00b7dammt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "NE", "VVFIN", "$.", "PDS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der ehmals auch allhier die Geister angeflammt;", "tokens": ["Der", "eh\u00b7mals", "auch", "all\u00b7hier", "die", "Geis\u00b7ter", "an\u00b7ge\u00b7flammt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und das, nachdem es mehr Natur und Wahrheit kennet,", "tokens": ["Und", "das", ",", "nach\u00b7dem", "es", "mehr", "Na\u00b7tur", "und", "Wahr\u00b7heit", "ken\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "KOUS", "PPER", "PIAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Geschwollner Reden Dunst nur Schaum und Blasen nennet;", "tokens": ["Ge\u00b7schwoll\u00b7ner", "Re\u00b7den", "Dunst", "nur", "Schaum", "und", "Bla\u00b7sen", "nen\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Mich hat kein Schlesien, kein Mei\u00dfnerland gezeugt:", "tokens": ["Mich", "hat", "kein", "Schle\u00b7si\u00b7en", ",", "kein", "Mei\u00df\u00b7ner\u00b7land", "ge\u00b7zeugt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das ferne Preu\u00dfenland hat meinen Mund ges\u00e4ugt;", "tokens": ["Das", "fer\u00b7ne", "Preu\u00b7\u00dfen\u00b7land", "hat", "mei\u00b7nen", "Mund", "ge\u00b7s\u00e4ugt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Geist mit Unterricht und Wissenschaft verpfleget,", "tokens": ["Den", "Geist", "mit", "Un\u00b7ter\u00b7richt", "und", "Wis\u00b7sen\u00b7schaft", "ver\u00b7pfle\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und mir zugleich die Lust zum Dichten eingepr\u00e4get.", "tokens": ["Und", "mir", "zu\u00b7gleich", "die", "Lust", "zum", "Dich\u00b7ten", "ein\u00b7ge\u00b7pr\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum gilt mir beydes gleich, ob dieses Mei\u00dfnerfeld,", "tokens": ["Drum", "gilt", "mir", "bey\u00b7des", "gleich", ",", "ob", "die\u00b7ses", "Mei\u00df\u00b7ner\u00b7feld", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIS", "ADV", "$,", "KOUS", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ob jener Oderstrom die Oberhand beh\u00e4lt.", "tokens": ["Ob", "je\u00b7ner", "O\u00b7der\u00b7strom", "die", "O\u00b7ber\u00b7hand", "be\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was geht es mich denn an, wenn gleich die Niedersachsen", "tokens": ["Was", "geht", "es", "mich", "denn", "an", ",", "wenn", "gleich", "die", "Nie\u00b7der\u00b7sach\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Franken in der Kunst zu Schreiben \u00fcberwachsen?", "tokens": ["Die", "Fran\u00b7ken", "in", "der", "Kunst", "zu", "Schrei\u00b7ben", "\u00fc\u00b7ber\u00b7wach\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was n\u00fctzt ein solcher Zank, der nie zum Ende geht?", "tokens": ["Was", "n\u00fctzt", "ein", "sol\u00b7cher", "Zank", ",", "der", "nie", "zum", "En\u00b7de", "geht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "PIAT", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wer deutsch kann, ist mir werth, wenn er es recht versteht.", "tokens": ["Wer", "deutsch", "kann", ",", "ist", "mir", "werth", ",", "wenn", "er", "es", "recht", "ver\u00b7steht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VMFIN", "$,", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Des P\u00f6bels Redensart pflegt \u00fcberall zu fehlen.", "tokens": ["Des", "P\u00f6\u00b7bels", "Re\u00b7den\u00b7sart", "pflegt", "\u00fc\u00b7be\u00b7rall", "zu", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wer richtig schreiben will, der mu\u00df aus allen w\u00e4hlen.", "tokens": ["Wer", "rich\u00b7tig", "schrei\u00b7ben", "will", ",", "der", "mu\u00df", "aus", "al\u00b7len", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "VMFIN", "$,", "ART", "VMFIN", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "So geht mich denn, o Freund! der Oder Zorn nichts an.", "tokens": ["So", "geht", "mich", "denn", ",", "o", "Freund", "!", "der", "O\u00b7der", "Zorn", "nichts", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "FM", "NN", "$.", "ART", "ADJA", "NN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich weis, da\u00df Schlesien und Mei\u00dfen dichten kann.", "tokens": ["Ich", "weis", ",", "da\u00df", "Schle\u00b7si\u00b7en", "und", "Mei\u00b7\u00dfen", "dich\u00b7ten", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "KOUS", "NN", "KON", "NN", "ADJA", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich lieb und hasse nicht das Vaterland der Dichter:", "tokens": ["Ich", "lieb", "und", "has\u00b7se", "nicht", "das", "Va\u00b7ter\u00b7land", "der", "Dich\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "VVFIN", "PTKNEG", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn beyde zeugten sonst die allergr\u00f6\u00dften Lichter.", "tokens": ["Denn", "bey\u00b7de", "zeug\u00b7ten", "sonst", "die", "al\u00b7ler\u00b7gr\u00f6\u00df\u00b7ten", "Lich\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als dort ein ", "tokens": ["Als", "dort", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADV", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Dem Preu\u00dfen seinen ", "tokens": ["Dem", "Preu\u00b7\u00dfen", "sei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Doch als dort ", "tokens": ["Doch", "als", "dort"], "token_info": ["word", "word", "word"], "pos": ["KON", "KOUS", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.9": {"text": "Durch sie ward dort und hier der reine Witz verderbt,", "tokens": ["Durch", "sie", "ward", "dort", "und", "hier", "der", "rei\u00b7ne", "Witz", "ver\u00b7derbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "KON", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den von dem ", "tokens": ["Den", "von", "dem"], "token_info": ["word", "word", "word"], "pos": ["ART", "APPR", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "Bis dorten ", "tokens": ["Bis", "dor\u00b7ten"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.12": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Wo ist der Fehler nun, den Breslau eifrig schilt,", "tokens": ["Wo", "ist", "der", "Feh\u00b7ler", "nun", ",", "den", "Bres\u00b7lau", "eif\u00b7rig", "schilt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADV", "$,", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Wenn wir vom Weizen Spreu, vom Golde Schlacken scheiden,", "tokens": ["Wenn", "wir", "vom", "Wei\u00b7zen", "Spreu", ",", "vom", "Gol\u00b7de", "Schla\u00b7cken", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "NE", "$,", "APPRART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und keinen leeren Schwulst in stolzen Worten leiden?", "tokens": ["Und", "kei\u00b7nen", "lee\u00b7ren", "Schwulst", "in", "stol\u00b7zen", "Wor\u00b7ten", "lei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir ehren die Vernunft, wie ", "tokens": ["Wir", "eh\u00b7ren", "die", "Ver\u00b7nunft", ",", "wie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Warum blieb ", "tokens": ["Wa\u00b7rum", "blieb"], "token_info": ["word", "word"], "pos": ["PWAV", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Der Wahrheit und Natur? Was hat ihn doch getrieben,", "tokens": ["Der", "Wahr\u00b7heit", "und", "Na\u00b7tur", "?", "Was", "hat", "ihn", "doch", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Wind der Spanier, der W\u00e4lschen Dunst zu lieben?", "tokens": ["Den", "Wind", "der", "Spa\u00b7nier", ",", "der", "W\u00e4l\u00b7schen", "Dunst", "zu", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Thats nicht sein gro\u00dfer ", "tokens": ["Thats", "nicht", "sein", "gro\u00b7\u00dfer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "PPOSAT", "ADJA"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Nur diesem gieng er nach, nur dieser schien ihm gro\u00df?", "tokens": ["Nur", "die\u00b7sem", "gieng", "er", "nach", ",", "nur", "die\u00b7ser", "schien", "ihm", "gro\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "PDS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Was Rom und Griechenland f\u00fcr Muster nachgelassen,", "tokens": ["Was", "Rom", "und", "Grie\u00b7chen\u00b7land", "f\u00fcr", "Mus\u00b7ter", "nach\u00b7ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NE", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das war ihm viel zu schlecht, das schien er gar zu hassen.", "tokens": ["Das", "war", "ihm", "viel", "zu", "schlecht", ",", "das", "schien", "er", "gar", "zu", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$,", "PDS", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein Irrlicht sp\u00e4ter Nacht verf\u00fchrt den Wandersmann,", "tokens": ["Ein", "Irr\u00b7licht", "sp\u00e4\u00b7ter", "Nacht", "ver\u00b7f\u00fchrt", "den", "Wan\u00b7ders\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der nicht die Stra\u00dfe kennt. Wer ihn nur warnen kann,", "tokens": ["Der", "nicht", "die", "Stra\u00b7\u00dfe", "kennt", ".", "Wer", "ihn", "nur", "war\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ART", "NN", "VVFIN", "$.", "PWS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der thut es freylich gern; wenn er den Freund nur h\u00f6ret,", "tokens": ["Der", "thut", "es", "frey\u00b7lich", "gern", ";", "wenn", "er", "den", "Freund", "nur", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$.", "KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der ihn zu retten denkt. Doch wenn ihn gar nichts st\u00f6ret;", "tokens": ["Der", "ihn", "zu", "ret\u00b7ten", "denkt", ".", "Doch", "wenn", "ihn", "gar", "nichts", "st\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKZU", "VVINF", "VVFIN", "$.", "KON", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wenn er sich kl\u00fcger d\u00fcnkt; den Freund f\u00fcr th\u00f6richt h\u00e4lt:", "tokens": ["Wenn", "er", "sich", "kl\u00fc\u00b7ger", "d\u00fcnkt", ";", "den", "Freund", "f\u00fcr", "th\u00f6\u00b7richt", "h\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "$.", "ART", "NN", "APPR", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So lachet man ihn aus, wenn er in S\u00fcmpfe f\u00e4llt.", "tokens": ["So", "la\u00b7chet", "man", "ihn", "aus", ",", "wenn", "er", "in", "S\u00fcmp\u00b7fe", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die Deutung ist gar leicht. Auch in gelehrten Sachen", "tokens": ["Die", "Deu\u00b7tung", "ist", "gar", "leicht", ".", "Auch", "in", "ge\u00b7lehr\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$.", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Pflegt Vorurtheil und Wahn oft taub und blind zu machen.", "tokens": ["Pflegt", "Vor\u00b7urt\u00b7heil", "und", "Wahn", "oft", "taub", "und", "blind", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "KON", "NN", "ADV", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Auf, edles ", "tokens": ["Auf", ",", "ed\u00b7les"], "token_info": ["word", "punct", "word"], "pos": ["APPR", "$,", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Schau; ", "tokens": ["Schau", ";"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Sey stolz auf diesen Held, durch den in Deutschlands Gr\u00e4nzen", "tokens": ["Sey", "stolz", "auf", "die\u00b7sen", "Held", ",", "durch", "den", "in", "Deutschlands", "Gr\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "APPR", "PDAT", "NN", "$,", "APPR", "ART", "APPR", "NE", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die freyen K\u00fcnste nun mit vollem Schimmer gl\u00e4nzen.", "tokens": ["Die", "frey\u00b7en", "K\u00fcns\u00b7te", "nun", "mit", "vol\u00b7lem", "Schim\u00b7mer", "gl\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vier Jahre sind noch hin bis an sein Todesjahr:", "tokens": ["Vier", "Jah\u00b7re", "sind", "noch", "hin", "bis", "an", "sein", "To\u00b7des\u00b7jahr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Begeh ein Jubelfest, und mach es offenbar,", "tokens": ["Be\u00b7geh", "ein", "Ju\u00b7bel\u00b7fest", ",", "und", "mach", "es", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie sehr du ihn verehrst. Man ehrt ihn auch in Mei\u00dfen,", "tokens": ["Wie", "sehr", "du", "ihn", "ver\u00b7ehrst", ".", "Man", "ehrt", "ihn", "auch", "in", "Mei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PPER", "VVFIN", "$.", "PIS", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und d\u00fcrfte dir vieleicht den Vorzug gar entrei\u00dfen.", "tokens": ["Und", "d\u00fcrf\u00b7te", "dir", "vie\u00b7leicht", "den", "Vor\u00b7zug", "gar", "ent\u00b7rei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mein Preu\u00dfen ehrt ihn auch, denn es bewahrt sein Grab:", "tokens": ["Mein", "Preu\u00b7\u00dfen", "ehrt", "ihn", "auch", ",", "denn", "es", "be\u00b7wahrt", "sein", "Grab", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,", "KON", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein Grabmaal fehlt ihm nur, das ihm noch niemand gab.", "tokens": ["Ein", "Grab\u00b7maal", "fehlt", "ihm", "nur", ",", "das", "ihm", "noch", "nie\u00b7mand", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,", "PRELS", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wir m\u00fcssen beyde Theil an solchen Pflichten haben,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "bey\u00b7de", "Theil", "an", "sol\u00b7chen", "Pflich\u00b7ten", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "APPR", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Weil ", "tokens": ["Weil"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}, "stanza.8": {"line.1": {"text": "Du aber, werther ", "tokens": ["Du", "a\u00b7ber", ",", "wert\u00b7her"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPER", "ADV", "$,", "PWS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Der Ehre nachzugehn, so wie mans heute sieht:", "tokens": ["Der", "Eh\u00b7re", "nach\u00b7zu\u00b7gehn", ",", "so", "wie", "mans", "heu\u00b7te", "sieht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ADV", "KOKOM", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Damit auch Breslau einst, gleich andern seiner S\u00f6hne,", "tokens": ["Da\u00b7mit", "auch", "Bres\u00b7lau", "einst", ",", "gleich", "an\u00b7dern", "sei\u00b7ner", "S\u00f6h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NE", "ADV", "$,", "ADV", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Leipzig heute thut, dich nach Verdiensten kr\u00f6ne.", "tokens": ["Wie", "Leip\u00b7zig", "heu\u00b7te", "thut", ",", "dich", "nach", "Ver\u00b7diens\u00b7ten", "kr\u00f6\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "VVFIN", "$,", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}