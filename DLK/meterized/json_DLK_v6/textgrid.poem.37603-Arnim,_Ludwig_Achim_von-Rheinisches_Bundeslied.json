{"textgrid.poem.37603": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Rheinisches Bundeslied", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Fa\u00df ist nun gebunden;", "tokens": ["Das", "Fa\u00df", "ist", "nun", "ge\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Viel Schl\u00e4ge hat's empfunden,", "tokens": ["Viel", "Schl\u00e4\u00b7ge", "hat's", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch ging es immer recht im Takt", "tokens": ["Doch", "ging", "es", "im\u00b7mer", "recht", "im", "Takt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis es sich krumm gebogen hat.", "tokens": ["Bis", "es", "sich", "krumm", "ge\u00b7bo\u00b7gen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Fa\u00df ist nun gebunden.", "tokens": ["Das", "Fa\u00df", "ist", "nun", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Dauben sind gehauen;", "tokens": ["Die", "Dau\u00b7ben", "sind", "ge\u00b7hau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wollt ihr die Stubben schauen", "tokens": ["Wollt", "ihr", "die", "Stub\u00b7ben", "schau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Eichen alt wie's deutsche Reich?", "tokens": ["Von", "Ei\u00b7chen", "alt", "wie's", "deut\u00b7sche", "Reich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst ist der Grund nun kahl und gleich.", "tokens": ["Sonst", "ist", "der", "Grund", "nun", "kahl", "und", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Dauben sind gehauen.", "tokens": ["Die", "Dau\u00b7ben", "sind", "ge\u00b7hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "In Eisen ist's gebunden;", "tokens": ["In", "Ei\u00b7sen", "ist's", "ge\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Eichbaum ist verschwunden.", "tokens": ["Der", "Eich\u00b7baum", "ist", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das deutsche Reich stand sch\u00f6n und stolz,", "tokens": ["Das", "deut\u00b7sche", "Reich", "stand", "sch\u00f6n", "und", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel gr\u00fcne Bl\u00e4tter trug das Holz.", "tokens": ["Viel", "gr\u00fc\u00b7ne", "Bl\u00e4t\u00b7ter", "trug", "das", "Holz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In Eisen ist's gebunden.", "tokens": ["In", "Ei\u00b7sen", "ist's", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Im Holz viel V\u00f6glein sangen;", "tokens": ["Im", "Holz", "viel", "V\u00f6\u00b7glein", "san\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Seit Beil und Axt erklangen \u2013", "tokens": ["Seit", "Beil", "und", "Axt", "er\u00b7klan\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwo ist mein Kind, wo ist mein Haus?", "tokens": ["\u00bb", "wo", "ist", "mein", "Kind", ",", "wo", "ist", "mein", "Haus", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPOSAT", "NN", "$,", "PWAV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Franzosen nahmen Alles aus.\u00ab", "tokens": ["Fran\u00b7zo\u00b7sen", "nah\u00b7men", "Al\u00b7les", "aus", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PIS", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die V\u00f6glein fl\u00fcsternd sangen.", "tokens": ["Die", "V\u00f6\u00b7glein", "fl\u00fcs\u00b7ternd", "san\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der B\u00f6ttcher, der's geschlagen,", "tokens": ["Der", "B\u00f6tt\u00b7cher", ",", "der's", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Will nicht mehr viel nachfragen.", "tokens": ["Will", "nicht", "mehr", "viel", "nach\u00b7fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er band es f\u00fcr die Langeweil.", "tokens": ["Er", "band", "es", "f\u00fcr", "die", "Lan\u00b7ge\u00b7weil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu Brennholz braucht er's bald in Eil,", "tokens": ["Zu", "Brenn\u00b7holz", "braucht", "er's", "bald", "in", "Eil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der B\u00f6ttcher, der's geschlagen.", "tokens": ["Der", "B\u00f6tt\u00b7cher", ",", "der's", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wir wollen mal dran schlagen,", "tokens": ["Wir", "wol\u00b7len", "mal", "dran", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PAV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ob es recht voll im Magen!", "tokens": ["Ob", "es", "recht", "voll", "im", "Ma\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das gro\u00dfe Fa\u00df, es klingt so hohl,", "tokens": ["Das", "gro\u00b7\u00dfe", "Fa\u00df", ",", "es", "klingt", "so", "hohl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wenn es bald der Teufel hol, \u2013", "tokens": ["Als", "wenn", "es", "bald", "der", "Teu\u00b7fel", "hol", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir wollen mal dran schlagen!", "tokens": ["Wir", "wol\u00b7len", "mal", "dran", "schla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "F\u00fcr Fremde h\u00e4ngt zum Scheine", "tokens": ["F\u00fcr", "Frem\u00b7de", "h\u00e4ngt", "zum", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "ein Anker drin mit Weine;", "tokens": ["ein", "An\u00b7ker", "drin", "mit", "Wei\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das gro\u00dfe Fa\u00df wird schon so spack,", "tokens": ["Das", "gro\u00b7\u00dfe", "Fa\u00df", "wird", "schon", "so", "spack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der schlechte Bund l\u00e4\u00dft balde nach;", "tokens": ["Der", "schlech\u00b7te", "Bund", "l\u00e4\u00dft", "bal\u00b7de", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gr\u00fcn war das Holz vom Rheine.", "tokens": ["Gr\u00fcn", "war", "das", "Holz", "vom", "Rhei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "APPRART", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "Zu Frankfurt steht's im Stillen,", "tokens": ["Zu", "Frank\u00b7furt", "steht's", "im", "Stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Rhein, der soll's noch f\u00fcllen;", "tokens": ["Der", "Rhein", ",", "der", "soll's", "noch", "f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Drum hei\u00dft es auch der Rheinsche Bund.", "tokens": ["Drum", "hei\u00dft", "es", "auch", "der", "Rhein\u00b7sche", "Bund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es kr\u00e4ht danach nicht Hahn noch Hund!", "tokens": ["Es", "kr\u00e4ht", "da\u00b7nach", "nicht", "Hahn", "noch", "Hund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PTKNEG", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu Frankfurt steht's im Stillen.", "tokens": ["Zu", "Frank\u00b7furt", "steht's", "im", "Stil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Der Rhein tr\u00e4gt \u00e4chte Trauben,", "tokens": ["Der", "Rhein", "tr\u00e4gt", "\u00e4ch\u00b7te", "Trau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Franzosen auch dran glauben;", "tokens": ["Fran\u00b7zo\u00b7sen", "auch", "dran", "glau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ganz h\u00f6flich schneiden Deutsche ein,", "tokens": ["Ganz", "h\u00f6f\u00b7lich", "schnei\u00b7den", "Deut\u00b7sche", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz gr\u00f6blich trinken sie den Wein.", "tokens": ["Ganz", "gr\u00f6b\u00b7lich", "trin\u00b7ken", "sie", "den", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Rhein tr\u00e4gt \u00e4chte Trauben.", "tokens": ["Der", "Rhein", "tr\u00e4gt", "\u00e4ch\u00b7te", "Trau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "So geht's dem Bund am Rheine,", "tokens": ["So", "geht's", "dem", "Bund", "am", "Rhei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So geht es mit dem Weine.", "tokens": ["So", "geht", "es", "mit", "dem", "Wei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der fromme Deutsche ist das Fa\u00df,", "tokens": ["Der", "from\u00b7me", "Deut\u00b7sche", "ist", "das", "Fa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Woraus der Franzmann trinkt zum Spa\u00df, \u2013", "tokens": ["Wo\u00b7raus", "der", "Franz\u00b7mann", "trinkt", "zum", "Spa\u00df", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPRART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So geht's dem Fa\u00df am Rheine!", "tokens": ["So", "geht's", "dem", "Fa\u00df", "am", "Rhei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Der Primas sich drauf setzet,", "tokens": ["Der", "Pri\u00b7mas", "sich", "drauf", "set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und seine Kehle netzet;", "tokens": ["Und", "sei\u00b7ne", "Keh\u00b7le", "net\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn ihm der Franzmann giebt 'nen Tritt", "tokens": ["Wenn", "ihm", "der", "Franz\u00b7mann", "giebt", "'nen", "Tritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So tr\u00f6stet er sich gleich damit,", "tokens": ["So", "tr\u00f6s\u00b7tet", "er", "sich", "gleich", "da\u00b7mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df er sich ruhig setzet.", "tokens": ["Da\u00df", "er", "sich", "ru\u00b7hig", "set\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Der B\u00f6ttcher ist Protekter,", "tokens": ["Der", "B\u00f6tt\u00b7cher", "ist", "Pro\u00b7tek\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er spricht zu ihm als Rekter:", "tokens": ["Er", "spricht", "zu", "ihm", "als", "Rek\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "KOUS", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ei sag doch an, mein lieber Sohn,", "tokens": ["Ei", "sag", "doch", "an", ",", "mein", "lie\u00b7ber", "Sohn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Fa\u00df ist nicht gemacht zum Thron.", "tokens": ["Das", "Fa\u00df", "ist", "nicht", "ge\u00b7macht", "zum", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich schlag dich hinunter mit dem Zepter!", "tokens": ["Ich", "schlag", "dich", "hin\u00b7un\u00b7ter", "mit", "dem", "Zep\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}}}}