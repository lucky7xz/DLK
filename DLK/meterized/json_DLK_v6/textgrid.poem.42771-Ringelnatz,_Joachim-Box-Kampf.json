{"textgrid.poem.42771": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Box-Kampf", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.85", "en:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bums! \u2013 Kock, Canada: \u2013 Bums!", "tokens": ["Bums", "!", "\u2013", "Kock", ",", "Ca\u00b7na\u00b7da", ":", "\u2013", "Bums", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["NE", "$.", "$(", "NE", "$,", "NE", "$.", "$(", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "K\u00e4sow aus Moskau: Puff! puff!", "tokens": ["K\u00e4\u00b7sow", "aus", "Mos\u00b7kau", ":", "Puff", "!", "puff", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "APPR", "NE", "$.", "NN", "$.", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Kock der Canadier: \u2013 Plumps!", "tokens": ["Kock", "der", "Ca\u00b7na\u00b7di\u00b7er", ":", "\u2013", "Plumps", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NE", "ART", "NN", "$.", "$(", "NE", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Richtet sich abermals uff.", "tokens": ["Rich\u00b7tet", "sich", "a\u00b7ber\u00b7mals", "uff", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Ob dann der K\u00e4sow den Kock haut,", "tokens": ["Ob", "dann", "der", "K\u00e4\u00b7sow", "den", "Kock", "haut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--++", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Oder ob er das vollzieht,", "tokens": ["O\u00b7der", "ob", "er", "das", "voll\u00b7zieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ob es im Bauchsto\u00df, im Knock-out", "tokens": ["Ob", "es", "im", "Bauch\u00b7sto\u00df", ",", "im", "Knock\u00b7out"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "$,", "APPRART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Oder von seitw\u00e4rts geschieht \u2013", "tokens": ["O\u00b7der", "von", "seit\u00b7w\u00e4rts", "ge\u00b7schieht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "VVFIN", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.9": {"text": "Kurz: Es verlaufen die heit'ren", "tokens": ["Kurz", ":", "Es", "ver\u00b7lau\u00b7fen", "die", "heit'\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "PPER", "VVFIN", "ART", "ADJA"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "Stunden wie Kinderpipi.", "tokens": ["Stun\u00b7den", "wie", "Kin\u00b7der\u00b7pi\u00b7pi", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "NE", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.11": {"text": "Sparen wir daher die weit'ren", "tokens": ["Spa\u00b7ren", "wir", "da\u00b7her", "die", "weit'\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PAV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Termini technici.", "tokens": ["Ter\u00b7mi\u00b7ni", "tech\u00b7ni\u00b7ci", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.13": {"text": "Und es endet zuletzt", "tokens": ["Und", "es", "en\u00b7det", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.14": {"text": "Reizvoll, wie es beginnt:", "tokens": ["Reiz\u00b7voll", ",", "wie", "es", "be\u00b7ginnt", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.15": {"text": "Kock wird t\u00f6dlich verletzt.", "tokens": ["Kock", "wird", "t\u00f6d\u00b7lich", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "K\u00e4sow aber gewinnt.", "tokens": ["K\u00e4\u00b7sow", "a\u00b7ber", "ge\u00b7winnt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Leiche von Kock wird bedeckt.", "tokens": ["Lei\u00b7che", "von", "Kock", "wird", "be\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.18": {"text": "Saal wird langsam ger\u00e4umt.", "tokens": ["Saal", "wird", "lang\u00b7sam", "ge\u00b7r\u00e4umt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.19": {"text": "K\u00e4sow besp\u00fclt sich mit Sekt.", "tokens": ["K\u00e4\u00b7sow", "be\u00b7sp\u00fclt", "sich", "mit", "Sekt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.20": {"text": "Leiche aus Canada tr\u00e4umt:", "tokens": ["Lei\u00b7che", "aus", "Ca\u00b7na\u00b7da", "tr\u00e4umt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Boxkampf \u2013", "tokens": ["Box\u00b7kampf", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.22": {"text": "Boxer \u2013", "tokens": ["Bo\u00b7xer", "\u2013"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.23": {"text": "Boxen \u2013", "tokens": ["Bo\u00b7xen", "\u2013"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.24": {"text": "Boxel \u2013", "tokens": ["Bo\u00b7xel", "\u2013"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.25": {"text": "Boxkalf \u2013", "tokens": ["Box\u00b7kalf", "\u2013"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.26": {"text": "Boxtrott \u2013", "tokens": ["Box\u00b7trott", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.27": {"text": "Boxtail \u2013.", "tokens": ["Box\u00b7tail", "\u2013", "."], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}}}}}