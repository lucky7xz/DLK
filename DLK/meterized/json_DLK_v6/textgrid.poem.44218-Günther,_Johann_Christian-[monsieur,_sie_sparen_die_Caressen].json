{"textgrid.poem.44218": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[monsieur, sie sparen die Caressen]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mitsamt der freyen Schmeicheley,", "tokens": ["Mit\u00b7samt", "der", "frey\u00b7en", "Schmei\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Mensch, der den Verstand verge\u00dfen,", "tokens": ["Ein", "Mensch", ",", "der", "den", "Ver\u00b7stand", "ver\u00b7ge\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Meint, da\u00df ich schon ein Engel sey;", "tokens": ["Meint", ",", "da\u00df", "ich", "schon", "ein", "En\u00b7gel", "sey", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von ihnen steht mir dieser Tittel,", "tokens": ["Von", "ih\u00b7nen", "steht", "mir", "die\u00b7ser", "Tit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Gunst gesagt, so gar nicht an.", "tokens": ["Mit", "Gunst", "ge\u00b7sagt", ",", "so", "gar", "nicht", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "ADV", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Warum? Es ist nun mehr kein Mittel,", "tokens": ["Wa\u00b7rum", "?", "Es", "ist", "nun", "mehr", "kein", "Mit\u00b7tel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VAFIN", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das sie und mich verbinden kan.", "tokens": ["Das", "sie", "und", "mich", "ver\u00b7bin\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "KON", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mich wundert, da\u00df sie sich nicht sch\u00e4men,", "tokens": ["Mich", "wun\u00b7dert", ",", "da\u00df", "sie", "sich", "nicht", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Als ein berufner Gottes-Mann", "tokens": ["Als", "ein", "be\u00b7ruf\u00b7ner", "Got\u00b7tes\u00b7Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Manch schl\u00fcpfrig Wort in Mund zu nehmen,", "tokens": ["Manch", "schl\u00fcpf\u00b7rig", "Wort", "in", "Mund", "zu", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Das keine Keuschheit leiden kan.", "tokens": ["Das", "kei\u00b7ne", "Keuschheit", "lei\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Auf Canzeln macht ihr heilger Eifer", "tokens": ["Auf", "Can\u00b7zeln", "macht", "ihr", "heil\u00b7ger", "Ei\u00b7fer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Uns M\u00e4gdgen stets die H\u00f6lle hei\u00df", "tokens": ["Uns", "M\u00e4gd\u00b7gen", "stets", "die", "H\u00f6l\u00b7le", "hei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und weckt dadurch der Misgunst Geifer,", "tokens": ["Und", "weckt", "da\u00b7durch", "der", "Mis\u00b7gunst", "Gei\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Der unsern Ku\u00df zu h\u00f6hnen weis,", "tokens": ["Der", "un\u00b7sern", "Ku\u00df", "zu", "h\u00f6h\u00b7nen", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PTKZU", "VVINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und gleichwohl stellt oft ihr Exempel", "tokens": ["Und", "gleich\u00b7wohl", "stellt", "oft", "ihr", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Die allergr\u00f6sten Heuchler vor;", "tokens": ["Die", "al\u00b7ler\u00b7gr\u00f6s\u00b7ten", "Heuch\u00b7ler", "vor", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Sie prahlen auf Altar und Tempel", "tokens": ["Sie", "prah\u00b7len", "auf", "Al\u00b7tar", "und", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Und donnern in des P\u00f6bels Ohr.", "tokens": ["Und", "don\u00b7nern", "in", "des", "P\u00f6\u00b7bels", "Ohr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Von au\u00dfen la\u00dfen sie als Engel,", "tokens": ["Von", "au\u00b7\u00dfen", "la\u00b7\u00dfen", "sie", "als", "En\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Doch sieht ein Kluger auf den Grund,", "tokens": ["Doch", "sieht", "ein", "Klu\u00b7ger", "auf", "den", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "So stecken sie voll gro\u00dfer M\u00e4ngel", "tokens": ["So", "ste\u00b7cken", "sie", "voll", "gro\u00b7\u00dfer", "M\u00e4n\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "So wie des Pharis\u00e4ers Mund.", "tokens": ["So", "wie", "des", "Pha\u00b7ri\u00b7s\u00e4\u00b7ers", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Das kommt nicht apostolisch raus;", "tokens": ["Das", "kommt", "nicht", "a\u00b7pos\u00b7to\u00b7lisch", "raus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Der Schaafspelz soll sie etwas zieren,", "tokens": ["Der", "Schaaf\u00b7spelz", "soll", "sie", "et\u00b7was", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Doch f\u00fcttert ihn der Wolfsbalg aus.", "tokens": ["Doch", "f\u00fct\u00b7tert", "ihn", "der", "Wolfs\u00b7balg", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Sie schwazen viel von Pfafensch\u00e4zen", "tokens": ["Sie", "schwa\u00b7zen", "viel", "von", "Pfa\u00b7fen\u00b7sch\u00e4\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und reden mir aus Hochmuth ein,", "tokens": ["Und", "re\u00b7den", "mir", "aus", "Hoch\u00b7muth", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.30": {"text": "Und wollen Hahn im Korbe seyn.", "tokens": ["Und", "wol\u00b7len", "Hahn", "im", "Kor\u00b7be", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NE", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Sie m\u00f6gen mit den ", "tokens": ["Sie", "m\u00f6\u00b7gen", "mit", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.32": {"text": "Und ihrer silbernen ", "tokens": ["Und", "ih\u00b7rer", "sil\u00b7ber\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.33": {"text": "Zu andern auf die Hochzeit fahren;", "tokens": ["Zu", "an\u00b7dern", "auf", "die", "Hoch\u00b7zeit", "fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Ich weis mein Theil und mag nichts mehr.", "tokens": ["Ich", "weis", "mein", "Theil", "und", "mag", "nichts", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPOSAT", "NN", "KON", "VMFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Sie ", "tokens": ["Sie"], "token_info": ["word"], "pos": ["PPER"], "meter": "+", "measure": "single.up"}, "line.36": {"text": "Der Fehler ist gewis nicht schlecht;", "tokens": ["Der", "Feh\u00b7ler", "ist", "ge\u00b7wis", "nicht", "schlecht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Drum mach ich mir auch jezt zu n\u00fcze,", "tokens": ["Drum", "mach", "ich", "mir", "auch", "jezt", "zu", "n\u00fc\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Was nechst ihr Reim geradebrecht.", "tokens": ["Was", "nechst", "ihr", "Reim", "ge\u00b7ra\u00b7de\u00b7brecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Ihr ", "tokens": ["Ihr"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.40": {"text": "Und bald als ", "tokens": ["Und", "bald", "als"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "KOKOM"], "meter": "+--", "measure": "dactylic.init"}, "line.41": {"text": "Mir darf es doch kein Brodt gew\u00e4hren,", "tokens": ["Mir", "darf", "es", "doch", "kein", "Brodt", "ge\u00b7w\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Denn dies kan anderw\u00e4rts geschehn.", "tokens": ["Denn", "dies", "kan", "an\u00b7der\u00b7w\u00e4rts", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Mein Liebster, den ich jezo k\u00fc\u00dfe", "tokens": ["Mein", "Liebs\u00b7ter", ",", "den", "ich", "je\u00b7zo", "k\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.44": {"text": "Und der mich wieder z\u00e4rtlich k\u00fcst,", "tokens": ["Und", "der", "mich", "wie\u00b7der", "z\u00e4rt\u00b7lich", "k\u00fcst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "Macht mir das Leben auch so s\u00fc\u00dfe,", "tokens": ["Macht", "mir", "das", "Le\u00b7ben", "auch", "so", "s\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADV", "ADV", "ADJA", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.46": {"text": "Als ein hochw\u00fcrdig \u00c4mtchen ist.", "tokens": ["Als", "ein", "hoch\u00b7w\u00fcr\u00b7dig", "\u00c4mt\u00b7chen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.48": {"text": "Ist nicht vor ihren Leib bestimmt,", "tokens": ["Ist", "nicht", "vor", "ih\u00b7ren", "Leib", "be\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Sie suchen andre Liebesfreude", "tokens": ["Sie", "su\u00b7chen", "and\u00b7re", "Lie\u00b7bes\u00b7freu\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.50": {"text": "Bey einer, die mit ", "tokens": ["Bey", "ei\u00b7ner", ",", "die", "mit"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "$,", "PRELS", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.51": {"text": "Und wollen sie sonst keine Myrthen,", "tokens": ["Und", "wol\u00b7len", "sie", "sonst", "kei\u00b7ne", "Myr\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.52": {"text": "So m\u00f6gens Hasepappeln seyn,", "tokens": ["So", "m\u00f6\u00b7gens", "Ha\u00b7se\u00b7pap\u00b7peln", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.53": {"text": "Die ihren Schlaf und Haar umg\u00fcrthen;", "tokens": ["Die", "ih\u00b7ren", "Schlaf", "und", "Haar", "um\u00b7g\u00fcr\u00b7then", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}