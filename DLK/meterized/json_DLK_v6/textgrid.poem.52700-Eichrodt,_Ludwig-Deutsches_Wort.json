{"textgrid.poem.52700": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Deutsches Wort", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Seckenheim im Neckargrund", "tokens": ["Zu", "Se\u00b7cken\u00b7heim", "im", "Ne\u00b7ck\u00b7ar\u00b7grund"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Fuhr auseinander der F\u00fcrstenbund,", "tokens": ["Fuhr", "aus\u00b7ein\u00b7an\u00b7der", "der", "F\u00fcrs\u00b7ten\u00b7bund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Fuhr in die Feinde wie der Blitz", "tokens": ["Fuhr", "in", "die", "Fein\u00b7de", "wie", "der", "Blitz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der \u00bbsieghaft\u00ab Held, der Pf\u00e4lzer Fritz.", "tokens": ["Der", "\u00bb", "sieg\u00b7haft", "\u00ab", "Held", ",", "der", "Pf\u00e4l\u00b7zer", "Fritz", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ADJD", "$(", "NN", "$,", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Markgraf Karl, der Bischof von Metz", "tokens": ["Der", "Mark\u00b7graf", "Karl", ",", "der", "Bi\u00b7schof", "von", "Metz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$,", "ART", "NN", "APPR", "NE"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vollstrecken wollten des Kaisers Gesetz,", "tokens": ["Voll\u00b7stre\u00b7cken", "woll\u00b7ten", "des", "Kai\u00b7sers", "Ge\u00b7setz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Graf Ulerich auch von W\u00fcrtemberg", "tokens": ["Graf", "U\u00b7le\u00b7rich", "auch", "von", "W\u00fcr\u00b7tem\u00b7berg"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADV", "APPR", "NE"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "War lustig bei dem Kriegshandwerk.", "tokens": ["War", "lus\u00b7tig", "bei", "dem", "Kriegs\u00b7hand\u00b7werk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Sie s\u00e4mmtlich schleppt \u00bbder b\u00f6se Fritz\u00ab", "tokens": ["Sie", "s\u00e4mmt\u00b7lich", "schleppt", "\u00bb", "der", "b\u00f6\u00b7se", "Fritz", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach Heidelberg zu festem Sitz,", "tokens": ["Nach", "Hei\u00b7del\u00b7berg", "zu", "fes\u00b7tem", "Sitz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort ruhen sie aus vom Waffensturm", "tokens": ["Dort", "ru\u00b7hen", "sie", "aus", "vom", "Waf\u00b7fen\u00b7sturm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u2013 Truz-Kaiser hie\u00df der dickste Thurm.", "tokens": ["\u2013", "Truz\u00b7Kai\u00b7ser", "hie\u00df", "der", "dicks\u00b7te", "Thurm", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und sa\u00dfen die Herrn dort Jahr und Tag,", "tokens": ["Und", "sa\u00b7\u00dfen", "die", "Herrn", "dort", "Jahr", "und", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bis ihre Geduld in Br\u00fcchen lag;", "tokens": ["Bis", "ih\u00b7re", "Ge\u00b7duld", "in", "Br\u00fc\u00b7chen", "lag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Markgraf Karl schwur einen Eid,", "tokens": ["Der", "Mark\u00b7graf", "Karl", "schwur", "ei\u00b7nen", "Eid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gab dahin viel Land und Leut.", "tokens": ["Und", "gab", "da\u00b7hin", "viel", "Land", "und", "Leut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Manch gutes Jahr, manch schlechtes Jahr", "tokens": ["Manch", "gu\u00b7tes", "Jahr", ",", "manch", "schlech\u00b7tes", "Jahr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seit dem nun wieder vor\u00fcberwar,", "tokens": ["Seit", "dem", "nun", "wie\u00b7der", "vor\u00b7\u00fc\u00b7berw\u00b7ar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ADV", "ADV", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Pfalzgraf ruht nach altem Brauch", "tokens": ["Der", "Pfalz\u00b7graf", "ruht", "nach", "al\u00b7tem", "Brauch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Sarg von Stein, der Markgraf auch.", "tokens": ["Im", "Sarg", "von", "Stein", ",", "der", "Mark\u00b7graf", "auch", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "$,", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und auf dem Schlo\u00df zu Baden sa\u00df", "tokens": ["Und", "auf", "dem", "Schlo\u00df", "zu", "Ba\u00b7den", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der weise Christoph, heil von Ha\u00df;", "tokens": ["Der", "wei\u00b7se", "Chris\u00b7toph", ",", "heil", "von", "Ha\u00df", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcrst Philipp thronte auf der Pfalz,", "tokens": ["F\u00fcrst", "Phi\u00b7lipp", "thron\u00b7te", "auf", "der", "Pfalz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "APPR", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem kam das Wetter \u00fcber den Hals.", "tokens": ["Dem", "kam", "das", "Wet\u00b7ter", "\u00fc\u00b7ber", "den", "Hals", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.7": {"line.1": {"text": "Von allen Seiten wie Gie\u00dfbachschwall", "tokens": ["Von", "al\u00b7len", "Sei\u00b7ten", "wie", "Gie\u00df\u00b7bach\u00b7schwall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KOKOM", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zerrei\u00dft ein armes sch\u00f6nes Thal,", "tokens": ["Zer\u00b7rei\u00dft", "ein", "ar\u00b7mes", "sch\u00f6\u00b7nes", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So nahm der Feinde Fluth \u00fcberhand,", "tokens": ["So", "nahm", "der", "Fein\u00b7de", "Fluth", "\u00fc\u00b7ber\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So fielen sie her \u00fcber pf\u00e4lzisch Land.", "tokens": ["So", "fie\u00b7len", "sie", "her", "\u00fc\u00b7ber", "pf\u00e4l\u00b7zisch", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Das heilige halbe r\u00f6mische Reich", "tokens": ["Das", "hei\u00b7li\u00b7ge", "hal\u00b7be", "r\u00f6\u00b7mi\u00b7sche", "Reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "War auf den Beinen, es galt den Streich", "tokens": ["War", "auf", "den", "Bei\u00b7nen", ",", "es", "galt", "den", "Streich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu f\u00fchren mit aller gebissenen Kraft,", "tokens": ["Zu", "f\u00fch\u00b7ren", "mit", "al\u00b7ler", "ge\u00b7bis\u00b7se\u00b7nen", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Drum ging auch Ruf an die Markgrafschaft.", "tokens": ["Drum", "ging", "auch", "Ruf", "an", "die", "Mark\u00b7graf\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Der Rach und Wiedervergeltung galts,", "tokens": ["Der", "Rach", "und", "Wie\u00b7der\u00b7ver\u00b7gel\u00b7tung", "galts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schon blutet das Antlitz der fr\u00f6hlichen Pfalz,", "tokens": ["Schon", "blu\u00b7tet", "das", "Ant\u00b7litz", "der", "fr\u00f6h\u00b7li\u00b7chen", "Pfalz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "War ausgew\u00fcstet und umgezerrt", "tokens": ["War", "aus\u00b7ge\u00b7w\u00fcs\u00b7tet", "und", "um\u00b7ge\u00b7zerrt"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "VVPP", "KON", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zur heulenden Fratze durch Feur und Schwert.", "tokens": ["Zur", "heu\u00b7len\u00b7den", "Frat\u00b7ze", "durch", "Feur", "und", "Schwert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Auf, auf, Herr Markgraf, seid mit uns!", "tokens": ["Auf", ",", "auf", ",", "Herr", "Mark\u00b7graf", ",", "seid", "mit", "uns", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "PTKVZ", "$,", "NN", "NE", "$,", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sprachen die Boten des F\u00fcrstenbunds,", "tokens": ["So", "spra\u00b7chen", "die", "Bo\u00b7ten", "des", "F\u00fcrs\u00b7ten\u00b7bunds", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Jetzt ist der rechte Augenblick,", "tokens": ["Jetzt", "ist", "der", "rech\u00b7te", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf! holt Euch Land und Leut zur\u00fcck!", "tokens": ["Auf", "!", "holt", "Euch", "Land", "und", "Leut", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Markgraf Christoph aber sprach:", "tokens": ["Der", "Mark\u00b7graf", "Chris\u00b7toph", "a\u00b7ber", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbnun sind meine Sachen nicht darnach,", "tokens": ["\u00bb", "nun", "sind", "mei\u00b7ne", "Sa\u00b7chen", "nicht", "dar\u00b7nach", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPOSAT", "NN", "PTKNEG", "PAV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mein Vater schwur dem Sieger den Eid", "tokens": ["Mein", "Va\u00b7ter", "schwur", "dem", "Sie\u00b7ger", "den", "Eid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Der Treu, mich bindt was ihn befreit.", "tokens": ["Der", "Treu", ",", "mich", "bindt", "was", "ihn", "be\u00b7freit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Und diese Treu soll unverletzt", "tokens": ["Und", "die\u00b7se", "Treu", "soll", "un\u00b7ver\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "NN", "VMFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erhalten sein auch gegen den jetzt", "tokens": ["Er\u00b7hal\u00b7ten", "sein", "auch", "ge\u00b7gen", "den", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "ADV", "APPR", "ART", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Besiegten Pfalzgraf \u2013 Ehr und Eid", "tokens": ["Be\u00b7sieg\u00b7ten", "Pfalz\u00b7graf", "\u2013", "Ehr", "und", "Eid"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geht allweg \u00fcber Land und Leut.\u00ab", "tokens": ["Geht", "all\u00b7weg", "\u00fc\u00b7ber", "Land", "und", "Leut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}