{"textgrid.poem.48699": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "20. Er beklagt die Aenderung und Furchtsamkeit itziger Deutschen", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Itzt f\u00e4llt man ins Konfect, in unsre vollen Schalen,", "tokens": ["Itzt", "f\u00e4llt", "man", "ins", "Kon\u00b7fect", ",", "in", "uns\u00b7re", "vol\u00b7len", "Scha\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "wie man uns l\u00e4ngst gedr\u00e4ut. Wo ist nun unser Mut,", "tokens": ["wie", "man", "uns", "l\u00e4ngst", "ge\u00b7dr\u00e4ut", ".", "Wo", "ist", "nun", "un\u00b7ser", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VVPP", "$.", "PWAV", "VAFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "der ausgest\u00e4lte Sinn, das kriegerische Blut?", "tokens": ["der", "aus\u00b7ge\u00b7st\u00e4l\u00b7te", "Sinn", ",", "das", "krie\u00b7ge\u00b7ri\u00b7sche", "Blut", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es f\u00e4llt kein Unger nicht von unserm eiteln Pralen.", "tokens": ["Es", "f\u00e4llt", "kein", "Un\u00b7ger", "nicht", "von", "un\u00b7serm", "ei\u00b7teln", "Pra\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Kein Pusch, kein Sch\u00fctzenrock, kein buntes Fahnenmalen", "tokens": ["Kein", "Pusch", ",", "kein", "Sch\u00fct\u00b7zen\u00b7rock", ",", "kein", "bun\u00b7tes", "Fah\u00b7nen\u00b7ma\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "schreckt den Krabaten ab. Das Ansehn ist sehr gut,", "tokens": ["schreckt", "den", "Kra\u00b7ba\u00b7ten", "ab", ".", "Das", "An\u00b7sehn", "ist", "sehr", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "das Ansehn mein' ich nur, das nichts zum Schlagen tut.", "tokens": ["das", "An\u00b7sehn", "mein'", "ich", "nur", ",", "das", "nichts", "zum", "Schla\u00b7gen", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,", "PRELS", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir feigsten Krieger wir, die Ph\u00f6bus kan bestralen,", "tokens": ["Wir", "feigs\u00b7ten", "Krie\u00b7ger", "wir", ",", "die", "Ph\u00f6\u00b7bus", "kan", "be\u00b7stra\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "PPER", "$,", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "was \u00e4ngsten wir uns doch und legen R\u00fcstung an,", "tokens": ["was", "\u00e4ngs\u00b7ten", "wir", "uns", "doch", "und", "le\u00b7gen", "R\u00fcs\u00b7tung", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "ADV", "KON", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die doch der weiche Leib nicht um sich leiden kan?", "tokens": ["die", "doch", "der", "wei\u00b7che", "Leib", "nicht", "um", "sich", "lei\u00b7den", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "PTKNEG", "APPR", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des gro\u00dfen Vatern Helm ist viel zu weit dem Sohne,", "tokens": ["Des", "gro\u00b7\u00dfen", "Va\u00b7tern", "Helm", "ist", "viel", "zu", "weit", "dem", "Soh\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "der Degen sch\u00e4ndet ihn. Wir M\u00e4nner ohne Man,", "tokens": ["der", "De\u00b7gen", "sch\u00e4n\u00b7det", "ihn", ".", "Wir", "M\u00e4n\u00b7ner", "oh\u00b7ne", "Man", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "PPER", "NN", "APPR", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "wir Starken auf den Schein, so ists um uns getan,", "tokens": ["wir", "Star\u00b7ken", "auf", "den", "Schein", ",", "so", "ists", "um", "uns", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ART", "NN", "$,", "ADV", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "uns Namensdeutsche nur! Ich sags auch mir zum Hohne.", "tokens": ["uns", "Na\u00b7mens\u00b7deut\u00b7sche", "nur", "!", "Ich", "sags", "auch", "mir", "zum", "Hoh\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "$.", "PPER", "ADV", "ADV", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}