{"textgrid.poem.40580": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zu Hofe ruft viel frohe G\u00e4st'", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Hofe ruft viel frohe G\u00e4st'", "tokens": ["Zu", "Ho\u00b7fe", "ruft", "viel", "fro\u00b7he", "G\u00e4st'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Herzogstochter Hochzeitfest.", "tokens": ["Der", "Her\u00b7zogs\u00b7toch\u00b7ter", "Hoch\u00b7zeit\u00b7fest", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Narr tritt vor des Herzogs Thron:", "tokens": ["Der", "Narr", "tritt", "vor", "des", "Her\u00b7zogs", "Thron", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbich fand ein neu Gef\u00e4ll der Kron',", "tokens": ["\u00bb", "ich", "fand", "ein", "neu", "Ge\u00b7f\u00e4ll", "der", "Kron'", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADJD", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es bringt manch sch\u00f6nen Pfennig.", "tokens": ["Es", "bringt", "manch", "sch\u00f6\u00b7nen", "Pfen\u00b7nig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Den Wink des Augenblicks erfa\u00dft!", "tokens": ["Den", "Wink", "des", "Au\u00b7gen\u00b7blicks", "er\u00b7fa\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und zu dem Fest der Sch\u00f6nheit la\u00dft,", "tokens": ["Und", "zu", "dem", "Fest", "der", "Sch\u00f6n\u00b7heit", "la\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was unsch\u00f6n, nur mit Zoll herein;", "tokens": ["Was", "un\u00b7sch\u00f6n", ",", "nur", "mit", "Zoll", "her\u00b7ein", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "$,", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich aber, Herr, mag Z\u00f6llner sein,", "tokens": ["Ich", "a\u00b7ber", ",", "Herr", ",", "mag", "Z\u00f6ll\u00b7ner", "sein", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NN", "$,", "VMFIN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Taxe nur ein Pfennig.\u00ab", "tokens": ["Die", "Ta\u00b7xe", "nur", "ein", "Pfen\u00b7nig", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Am Stadtthor gibt dem Volke kund", "tokens": ["Am", "Stadt\u00b7thor", "gibt", "dem", "Vol\u00b7ke", "kund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Pfahl in Landesfarben bunt:", "tokens": ["Ein", "Pfahl", "in", "Lan\u00b7des\u00b7far\u00b7ben", "bunt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbnur sch\u00f6nen Leib la\u00dft frei zum Fest;", "tokens": ["\u00bb", "nur", "sch\u00f6\u00b7nen", "Leib", "la\u00dft", "frei", "zum", "Fest", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer ungestalt, l\u00f6s't sein Gebrest", "tokens": ["Wer", "un\u00b7ge\u00b7stalt", ",", "l\u00f6s't", "sein", "Ge\u00b7brest"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADJD", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Per St\u00fcck mit einem Pfennig.\u00ab", "tokens": ["Per", "St\u00fcck", "mit", "ei\u00b7nem", "Pfen\u00b7nig", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ei, das stolzirt! das prunkt um die Wett'", "tokens": ["Ei", ",", "das", "stol\u00b7zirt", "!", "das", "prunkt", "um", "die", "Wett'"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVPP", "$.", "PDS", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Sammtm\u00e4ntel, Goldsch\u00e4rpen, Federbarett!", "tokens": ["Sammt\u00b7m\u00e4n\u00b7tel", ",", "Gold\u00b7sch\u00e4r\u00b7pen", ",", "Fe\u00b7der\u00b7ba\u00b7rett", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "++-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Von schmucken Junkern ein gl\u00e4nzender Zug.", "tokens": ["Von", "schmu\u00b7cken", "Jun\u00b7kern", "ein", "gl\u00e4n\u00b7zen\u00b7der", "Zug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dem Z\u00f6llner bringt er Unlust genug:", "tokens": ["Dem", "Z\u00f6ll\u00b7ner", "bringt", "er", "Un\u00b7lust", "ge\u00b7nug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "\u00bbda setzt's wohl keinen Pfennig.\u00ab", "tokens": ["\u00bb", "da", "setzt's", "wohl", "kei\u00b7nen", "Pfen\u00b7nig", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADV", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Doch dort am Fl\u00fcgel das Junkerlein,", "tokens": ["Doch", "dort", "am", "Fl\u00fc\u00b7gel", "das", "Jun\u00b7ker\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sieht's nicht, als ob es ", "tokens": ["Sieht's", "nicht", ",", "als", "ob", "es"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PTKNEG", "$,", "KOKOM", "KOUS", "PPER"], "meter": "+-++-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Der Z\u00f6llner kann's nicht genau ersehn,", "tokens": ["Der", "Z\u00f6ll\u00b7ner", "kann's", "nicht", "ge\u00b7nau", "er\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Drum mag er nur ganz sch\u00fcchtern flehn:", "tokens": ["Drum", "mag", "er", "nur", "ganz", "sch\u00fcch\u00b7tern", "flehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbsch\u00f6n Herrlein, meinen Pfennig!\u00ab", "tokens": ["\u00bb", "sch\u00f6n", "Herr\u00b7lein", ",", "mei\u00b7nen", "Pfen\u00b7nig", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der Junker schl\u00e4gt ihm die Gert' ins Gesicht", "tokens": ["Der", "Jun\u00b7ker", "schl\u00e4gt", "ihm", "die", "Gert'", "ins", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und stottert im Zorn: Betrunkner Wicht!", "tokens": ["Und", "stot\u00b7tert", "im", "Zorn", ":", "Be\u00b7trunk\u00b7ner", "Wicht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Z\u00f6llner doch h\u00f6rte genau zur Frist,", "tokens": ["Der", "Z\u00f6ll\u00b7ner", "doch", "h\u00f6r\u00b7te", "ge\u00b7nau", "zur", "Frist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Da\u00df das Herrlein auch ein ", "tokens": ["Da\u00df", "das", "Herr\u00b7lein", "auch", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ART"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "\u00bbdrum noch den zweiten Pfennig!\u00ab", "tokens": ["\u00bb", "drum", "noch", "den", "zwei\u00b7ten", "Pfen\u00b7nig", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und in die Z\u00fcgel greift er dem Pferd,", "tokens": ["Und", "in", "die", "Z\u00fc\u00b7gel", "greift", "er", "dem", "Pferd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Das scheut und wirft den Reiter zur Erd',", "tokens": ["Das", "scheut", "und", "wirft", "den", "Rei\u00b7ter", "zur", "Erd'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Im Fallen entfleucht Hut, Haar und Schopf,", "tokens": ["Im", "Fal\u00b7len", "ent\u00b7fleucht", "Hut", ",", "Haar", "und", "Schopf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Z\u00f6llner erschaut den ", "tokens": ["Der", "Z\u00f6ll\u00b7ner", "er\u00b7schaut", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "\u00bbund aber einen Pfennig!\u00ab", "tokens": ["\u00bb", "und", "a\u00b7ber", "ei\u00b7nen", "Pfen\u00b7nig", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Das Pferd rei\u00dft aus und sprengt feldein,", "tokens": ["Das", "Pferd", "rei\u00dft", "aus", "und", "sprengt", "feld\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der M\u00e4hre nach das Junkerlein,", "tokens": ["Der", "M\u00e4h\u00b7re", "nach", "das", "Jun\u00b7ker\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch schleppt's ein ", "tokens": ["Doch", "schleppt's", "ein"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.4": {"text": "Drum keucht der Z\u00f6llner hinterher:", "tokens": ["Drum", "keucht", "der", "Z\u00f6ll\u00b7ner", "hin\u00b7ter\u00b7her", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbund wieder einen Pfennig!\u00ab", "tokens": ["\u00bb", "und", "wie\u00b7der", "ei\u00b7nen", "Pfen\u00b7nig", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Jetzt h\u00e4lt er den Reitermantel fest,", "tokens": ["Jetzt", "h\u00e4lt", "er", "den", "Rei\u00b7ter\u00b7man\u00b7tel", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den ihm in den H\u00e4nden der Fl\u00fcchtige l\u00e4\u00dft;", "tokens": ["Den", "ihm", "in", "den", "H\u00e4n\u00b7den", "der", "Fl\u00fcch\u00b7ti\u00b7ge", "l\u00e4\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Des Z\u00f6llners Auge sogleich entdeckt", "tokens": ["Des", "Z\u00f6ll\u00b7ners", "Au\u00b7ge", "sog\u00b7leich", "ent\u00b7deckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ADV", "VVPP"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "\u00bbund aber einen Pfennig!\u00ab", "tokens": ["\u00bb", "und", "a\u00b7ber", "ei\u00b7nen", "Pfen\u00b7nig", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Was weiter geschah mit dem Junkerlein?", "tokens": ["Was", "wei\u00b7ter", "ge\u00b7schah", "mit", "dem", "Jun\u00b7ker\u00b7lein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Vielleicht noch sitzt es am Stra\u00dfenrain,", "tokens": ["Viel\u00b7leicht", "noch", "sitzt", "es", "am", "Stra\u00b7\u00dfen\u00b7rain", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und denkt und spricht dem Wandrer zur Lehr':", "tokens": ["Und", "denkt", "und", "spricht", "dem", "Wand\u00b7rer", "zur", "Lehr'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "\u00bbwie leicht ich ein sch\u00f6ner Junker noch w\u00e4r'!", "tokens": ["\u00bb", "wie", "leicht", "ich", "ein", "sch\u00f6\u00b7ner", "Jun\u00b7ker", "noch", "w\u00e4r'", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "PPER", "ART", "ADJA", "NN", "ADV", "VAFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Freund, zahle deinen Pfennig!\u00ab", "tokens": ["Freund", ",", "zah\u00b7le", "dei\u00b7nen", "Pfen\u00b7nig", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}