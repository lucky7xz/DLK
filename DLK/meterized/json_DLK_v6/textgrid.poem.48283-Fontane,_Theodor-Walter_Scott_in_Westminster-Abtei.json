{"textgrid.poem.48283": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Walter Scott in Westminster-Abtei", "genre": "verse", "period": "N.A.", "pub_year": 1888, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ganz London flaggt und jubelt und rennt:", "tokens": ["Ganz", "Lon\u00b7don", "flaggt", "und", "ju\u00b7belt", "und", "rennt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbheut wird er K\u00f6nig, der Prinz-Regent!\u00ab", "tokens": ["\u00bb", "heut", "wird", "er", "K\u00f6\u00b7nig", ",", "der", "Prinz\u00b7Re\u00b7gent", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "NN", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Schon wartet seiner die Klerisei", "tokens": ["Schon", "war\u00b7tet", "sei\u00b7ner", "die", "Kle\u00b7ri\u00b7sei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Vorm Altar der Westminster-Abtei,", "tokens": ["Vorm", "Al\u00b7tar", "der", "West\u00b7mins\u00b7ter\u00b7Ab\u00b7tei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Vorm Eingang aber, in Plaid und Kilt", "tokens": ["Vorm", "Ein\u00b7gang", "a\u00b7ber", ",", "in", "Plaid", "und", "Kilt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und im Helme, draus der Helmbusch quillt,", "tokens": ["Und", "im", "Hel\u00b7me", ",", "draus", "der", "Helm\u00b7busch", "quillt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "PAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "\u00dcber den Platz hin, zieht Spalier", "tokens": ["\u00dc\u00b7ber", "den", "Platz", "hin", ",", "zieht", "Spa\u00b7lier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "VVFIN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Das Regiment ", "tokens": ["Das", "Re\u00b7gi\u00b7ment"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Und wie gefegt der ganze Plan.", "tokens": ["Und", "wie", "ge\u00b7fegt", "der", "gan\u00b7ze", "Plan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer aber die zwei, die da sich nahn?", "tokens": ["Wer", "a\u00b7ber", "die", "zwei", ",", "die", "da", "sich", "nahn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "CARD", "$,", "PRELS", "ADV", "PRF", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie hoffen auf Zutritt, auf Gunst und Gl\u00fcck;", "tokens": ["Sie", "hof\u00b7fen", "auf", "Zu\u00b7tritt", ",", "auf", "Gunst", "und", "Gl\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Umsonst. Kommandoruf: \u00bbZur\u00fcck!\u00ab", "tokens": ["Um\u00b7sonst", ".", "Kom\u00b7man\u00b7do\u00b7ruf", ":", "\u00bb", "Zu\u00b7r\u00fcck", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "$.", "NN", "$.", "$(", "PTKVZ", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Und die Menge, sie lacht, und der eine wird bleich,", "tokens": ["Und", "die", "Men\u00b7ge", ",", "sie", "lacht", ",", "und", "der", "ei\u00b7ne", "wird", "bleich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "VVFIN", "$,", "KON", "ART", "PIS", "VAFIN", "ADJD", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.6": {"text": "Aber der andre: \u00bbDacht' es gleich;", "tokens": ["A\u00b7ber", "der", "and\u00b7re", ":", "\u00bb", "Dacht'", "es", "gleich", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "$.", "$(", "VVFIN", "PPER", "ADV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Das alte Lied vom Schaden und Spott,", "tokens": ["Das", "al\u00b7te", "Lied", "vom", "Scha\u00b7den", "und", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Lachen wir mit, ", "tokens": ["La\u00b7chen", "wir", "mit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Und sieh, eh' noch der Name verklang,", "tokens": ["Und", "sieh", ",", "eh'", "noch", "der", "Na\u00b7me", "ver\u00b7klang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In die Front ein blutjunger F\u00e4hnrich sprang,", "tokens": ["In", "die", "Front", "ein", "blut\u00b7jun\u00b7ger", "F\u00e4hn\u00b7rich", "sprang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-++-+-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Seinen Degen senkt salutierend er:", "tokens": ["Sei\u00b7nen", "De\u00b7gen", "senkt", "sa\u00b7lu\u00b7tie\u00b7rend", "er", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "PPER", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "\u00bbricht't euch; pr\u00e4sentiert das Gewehr!", "tokens": ["\u00bb", "richt't", "euch", ";", "pr\u00e4\u00b7sen\u00b7tiert", "das", "Ge\u00b7wehr", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$.", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Hoch K\u00f6nig Georg und segn' ihn Gott,", "tokens": ["Hoch", "K\u00f6\u00b7nig", "Ge\u00b7org", "und", "segn'", "ihn", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "NE", "KON", "VVIMP", "PPER", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Aber Platz, F\u00fcsiliers, f\u00fcr Sir Walter Scott!\u00ab", "tokens": ["A\u00b7ber", "Platz", ",", "F\u00fc\u00b7si\u00b7liers", ",", "f\u00fcr", "Sir", "Wal\u00b7ter", "Scott", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "$,", "NN", "$,", "APPR", "NN", "NE", "NE", "$.", "$("], "meter": "+-++-+--+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Der Weg ist offen, der Weg ist frei,", "tokens": ["Der", "Weg", "ist", "of\u00b7fen", ",", "der", "Weg", "ist", "frei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sir Walter betritt die Westminster-Abtei.", "tokens": ["Sir", "Wal\u00b7ter", "be\u00b7tritt", "die", "West\u00b7mins\u00b7ter\u00b7Ab\u00b7tei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Schotten fl\u00fcstern: \u00bbDas war er!\u00ab", "tokens": ["Die", "Schot\u00b7ten", "fl\u00fcs\u00b7tern", ":", "\u00bb", "Das", "war", "er", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "$(", "PDS", "VAFIN", "PPER", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Der Kr\u00f6nungszug kam weit hinterher.", "tokens": ["Der", "Kr\u00f6\u00b7nungs\u00b7zug", "kam", "weit", "hin\u00b7ter\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}