{"textgrid.poem.39095": {"metadata": {"author": {"name": "Prutz, Robert Eduard", "birth": "N.A.", "death": "N.A."}, "title": "9.", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist doch auf der Welt nichts besser", "tokens": ["Ist", "doch", "auf", "der", "Welt", "nichts", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "ART", "NN", "PIS", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "als solch deutscher, solch Professor!", "tokens": ["als", "solch", "deut\u00b7scher", ",", "solch", "Pro\u00b7fes\u00b7sor", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "$,", "PIAT", "NN", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Stillvergn\u00fcgt, ein m\u00e4\u00df'ger Esser,", "tokens": ["Still\u00b7ver\u00b7gn\u00fcgt", ",", "ein", "m\u00e4\u00df'\u00b7ger", "Es\u00b7ser", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "l\u00e4\u00dft er flie\u00dfen sein Gew\u00e4sser,", "tokens": ["l\u00e4\u00dft", "er", "flie\u00b7\u00dfen", "sein", "Ge\u00b7w\u00e4s\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "f\u00fcllt es selber noch auf F\u00e4sser \u2013", "tokens": ["f\u00fcllt", "es", "sel\u00b7ber", "noch", "auf", "F\u00e4s\u00b7ser", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gut verpicht h\u00e4lt es sich besser \u2013", "tokens": ["gut", "ver\u00b7picht", "h\u00e4lt", "es", "sich", "bes\u00b7ser", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VVFIN", "PPER", "PRF", "ADJD", "$("], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "spaltet Haare mit dem Messer:", "tokens": ["spal\u00b7tet", "Haa\u00b7re", "mit", "dem", "Mes\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "und indes ein k\u00fchner Fresser", "tokens": ["und", "in\u00b7des", "ein", "k\u00fch\u00b7ner", "Fres\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "stiehlt dem Allerweltsvergesser,", "tokens": ["stiehlt", "dem", "Al\u00b7ler\u00b7welts\u00b7ver\u00b7ges\u00b7ser", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "sel'gem Himmelsraumdurchmesser,", "tokens": ["sel'\u00b7gem", "Him\u00b7mels\u00b7raum\u00b7durch\u00b7mes\u00b7ser", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "vor der Nase stiehlt der Fresser", "tokens": ["vor", "der", "Na\u00b7se", "stiehlt", "der", "Fres\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Braten ihm und Brot und Messer! \u2013", "tokens": ["Bra\u00b7ten", "ihm", "und", "Brot", "und", "Mes\u00b7ser", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "KON", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Deutsche Freiheit, dir w\u00e4r' besser,", "tokens": ["Deut\u00b7sche", "Frei\u00b7heit", ",", "dir", "w\u00e4r'", "bes\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "st\u00fcrben s\u00e4mtliche Professor,", "tokens": ["st\u00fcr\u00b7ben", "s\u00e4mt\u00b7li\u00b7che", "Pro\u00b7fes\u00b7sor", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-++--", "measure": "unknown.measure.tetra"}, "line.15": {"text": "sie \u2013 und andre Bettdurchn\u00e4sser!", "tokens": ["sie", "\u2013", "und", "and\u00b7re", "Bett\u00b7durch\u00b7n\u00e4s\u00b7ser", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}