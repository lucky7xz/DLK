{"dta.poem.9177": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Vi.  \n Er entsagt der Marilis und ihrer anmuthigen  \n gesellschafft.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr m\u00e4dgen habt ihr meinetwegen", "tokens": ["Ihr", "m\u00e4d\u00b7gen", "habt", "ihr", "mei\u00b7net\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVINF", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00dfweilen einen b\u00f6sen sinn/", "tokens": ["Bi\u00df\u00b7wei\u00b7len", "ei\u00b7nen", "b\u00f6\u00b7sen", "sinn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dieweil ich offtmahls ungelegen", "tokens": ["Die\u00b7weil", "ich", "offt\u00b7mahls", "un\u00b7ge\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und zu der unzeit kommen bin?", "tokens": ["Und", "zu", "der", "un\u00b7zeit", "kom\u00b7men", "bin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verzeiht mir nur/ es ist versehn/", "tokens": ["Ver\u00b7zeiht", "mir", "nur", "/", "es", "ist", "ver\u00b7sehn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$(", "PPER", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und k\u00fcnfftig solls nicht mehr geschehn.", "tokens": ["Und", "k\u00fcnff\u00b7tig", "solls", "nicht", "mehr", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Ich bin mit euch so umgegangen", "tokens": ["Ich", "bin", "mit", "euch", "so", "um\u00b7ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als ein bekannter guter freund/", "tokens": ["Als", "ein", "be\u00b7kann\u00b7ter", "gu\u00b7ter", "freund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles was ich angefangen", "tokens": ["Und", "al\u00b7les", "was", "ich", "an\u00b7ge\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "PWS", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hab ich in einfalt gut gemeynt.", "tokens": ["Hab", "ich", "in", "ein\u00b7falt", "gut", "ge\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun aber werd ich durch verdacht", "tokens": ["Nun", "a\u00b7ber", "werd", "ich", "durch", "ver\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Beschuldigt und verhasst gemacht.", "tokens": ["Be\u00b7schul\u00b7digt", "und", "ver\u00b7hasst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Jhr kinder gebet euch zu frieden/", "tokens": ["Ihr", "kin\u00b7der", "ge\u00b7bet", "euch", "zu", "frie\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Ich wil euch nicht beschwerlich seyn/", "tokens": ["Ich", "wil", "euch", "nicht", "be\u00b7schwer\u00b7lich", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich habe mich von euch geschieden", "tokens": ["Ich", "ha\u00b7be", "mich", "von", "euch", "ge\u00b7schie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und stelle mich nicht weiter ein/", "tokens": ["Und", "stel\u00b7le", "mich", "nicht", "wei\u00b7ter", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADV", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die\u00df sey nunmehr das letzte lied", "tokens": ["Die\u00df", "sey", "nun\u00b7mehr", "das", "letz\u00b7te", "lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Damit euch meine faust bem\u00fcht.", "tokens": ["Da\u00b7mit", "euch", "mei\u00b7ne", "faust", "be\u00b7m\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Nun d\u00f6rfft ihr weiter nichts entgelte\u0303", "tokens": ["Nun", "d\u00f6rfft", "ihr", "wei\u00b7ter", "nichts", "ent\u00b7gel\u00b7t\u1ebd"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Hat gleich mein vorwitz was gethan/", "tokens": ["Hat", "gleich", "mein", "vor\u00b7witz", "was", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "APPR", "PRELS", "VVPP", "$("], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Kein mensch wird euch um etwas schelten", "tokens": ["Kein", "mensch", "wird", "euch", "um", "et\u00b7was", "schel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "APPR", "PIS", "VVFIN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Das euch und mich betreffen kan/", "tokens": ["Das", "euch", "und", "mich", "be\u00b7tref\u00b7fen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "KON", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und werd ich unversehns genannt.", "tokens": ["Und", "werd", "ich", "un\u00b7ver\u00b7sehns", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So sprecht ich sey euch unbekant.", "tokens": ["So", "sprecht", "ich", "sey", "euch", "un\u00b7be\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Lebt wohl ihr losen tausend kinder/", "tokens": ["Lebt", "wohl", "ihr", "lo\u00b7sen", "tau\u00b7send", "kin\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "CARD", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich lege lust und kurtzweil hin:", "tokens": ["Ich", "le\u00b7ge", "lust", "und", "kurt\u00b7zweil", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn dieses ist mir noch ges\u00fcnder", "tokens": ["Denn", "die\u00b7ses", "ist", "mir", "noch", "ge\u00b7s\u00fcn\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als wann ich euch verdrie\u00dflich bin:", "tokens": ["Als", "wann", "ich", "euch", "ver\u00b7drie\u00df\u00b7lich", "bin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gr\u00fcsst nochmahls euer liebes hau\u00df", "tokens": ["Gr\u00fcs\u00b7st", "noch\u00b7mahls", "eu\u00b7er", "lie\u00b7bes", "hau\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Und legt mir alls zum besten au\u00df.", "tokens": ["Und", "legt", "mir", "alls", "zum", "bes\u00b7ten", "au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Ich will die gassen nicht betreten/", "tokens": ["Ich", "will", "die", "gas\u00b7sen", "nicht", "be\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich will nach aller m\u00f6glichkeit", "tokens": ["Ich", "will", "nach", "al\u00b7ler", "m\u00f6g\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht mehr in jener kirche beten", "tokens": ["Nicht", "mehr", "in", "je\u00b7ner", "kir\u00b7che", "be\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "PDAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da ihr sonst anzutreffen seyd/", "tokens": ["Da", "ihr", "sonst", "an\u00b7zu\u00b7tref\u00b7fen", "seyd", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVIZU", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wo ihr etwan werdet stehn", "tokens": ["Und", "wo", "ihr", "et\u00b7wan", "wer\u00b7det", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADV", "VAFIN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da will ich aus dem wege gehn.", "tokens": ["Da", "will", "ich", "aus", "dem", "we\u00b7ge", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Eins hab ich endlich ausgenommen/", "tokens": ["Eins", "hab", "ich", "end\u00b7lich", "aus\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wofern ich noch verreisen mu\u00df/", "tokens": ["Wo\u00b7fern", "ich", "noch", "ver\u00b7rei\u00b7sen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So werd ich nur noch einmahl kommen/", "tokens": ["So", "werd", "ich", "nur", "noch", "ein\u00b7mahl", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Damit mein frommer abschieds gru\u00df", "tokens": ["Da\u00b7mit", "mein", "from\u00b7mer", "ab\u00b7schieds", "gru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Euch schuldigst werde beygebracht/", "tokens": ["Euch", "schul\u00b7digst", "wer\u00b7de", "bey\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sonst sag ich itzo gute nacht.", "tokens": ["Sonst", "sag", "ich", "it\u00b7zo", "gu\u00b7te", "nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "8. Verbrennt die lieder meine zeugen", "tokens": ["Ver\u00b7brennt", "die", "lie\u00b7der", "mei\u00b7ne", "zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der ungef\u00e4rbten redlichkeit/", "tokens": ["Der", "un\u00b7ge\u00b7f\u00e4rb\u00b7ten", "red\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lernt meinen nahmen bald verschweigen/", "tokens": ["Lernt", "mei\u00b7nen", "nah\u00b7men", "bald", "ver\u00b7schwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vergesset meiner wo ihr seyd.", "tokens": ["Ver\u00b7ges\u00b7set", "mei\u00b7ner", "wo", "ihr", "seyd", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es ist genung/ ich denck an sie/", "tokens": ["Es", "ist", "ge\u00b7nung", "/", "ich", "denck", "an", "sie", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$(", "PPER", "VVFIN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit mir verlohnt sichs nicht der m\u00fch.", "tokens": ["Mit", "mir", "ver\u00b7lohnt", "sichs", "nicht", "der", "m\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PIS", "PTKNEG", "ART", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}