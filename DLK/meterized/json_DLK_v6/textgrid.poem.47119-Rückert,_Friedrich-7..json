{"textgrid.poem.47119": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "7.", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Endlich hab' ich das errungen,", "tokens": ["End\u00b7lich", "hab'", "ich", "das", "er\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebster! es zu f\u00fchlen ganz,", "tokens": ["Liebs\u00b7ter", "!", "es", "zu", "f\u00fch\u00b7len", "ganz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "PTKZU", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df dich ebenso durchdrungen", "tokens": ["Da\u00df", "dich", "e\u00b7ben\u00b7so", "durch\u00b7drun\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat, wie mich, der Gottesglanz.", "tokens": ["Hat", ",", "wie", "mich", ",", "der", "Got\u00b7tes\u00b7glanz", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "$,", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Den Gedanken mu\u00dft' ich w\u00e4lzen", "tokens": ["Den", "Ge\u00b7dan\u00b7ken", "mu\u00dft'", "ich", "w\u00e4l\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "(war es Demut, war es Stolz?),", "tokens": ["(", "war", "es", "De\u00b7mut", ",", "war", "es", "Stolz", "?", ")", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VAFIN", "PPER", "NN", "$,", "VAFIN", "PPER", "NN", "$.", "$(", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob du so mir k\u00f6nntest schmelzen,", "tokens": ["Ob", "du", "so", "mir", "k\u00f6nn\u00b7test", "schmel\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Wie dir meine Seele schmolz.", "tokens": ["Wie", "dir", "mei\u00b7ne", "See\u00b7le", "schmolz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch nun f\u00fchl' ich, dir geh\u00f6r' ich", "tokens": ["Doch", "nun", "f\u00fchl'", "ich", ",", "dir", "ge\u00b7h\u00f6r'", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mehr nicht, als du mir geh\u00f6rst,", "tokens": ["Mehr", "nicht", ",", "als", "du", "mir", "ge\u00b7h\u00f6rst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dir nichts im Herzen schw\u00f6r' ich,", "tokens": ["Und", "dir", "nichts", "im", "Her\u00b7zen", "schw\u00f6r'", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "APPRART", "NN", "VVFIN", "PPER", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Was du nicht entgegenschw\u00f6rst.", "tokens": ["Was", "du", "nicht", "ent\u00b7ge\u00b7gen\u00b7schw\u00f6rst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ob du tagelang mich meidest,", "tokens": ["Ob", "du", "ta\u00b7ge\u00b7lang", "mich", "mei\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ob du nicht ein Wort mir gibst,", "tokens": ["Ob", "du", "nicht", "ein", "Wort", "mir", "gibst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob du ohne Ku\u00df mir scheidest,", "tokens": ["Ob", "du", "oh\u00b7ne", "Ku\u00df", "mir", "schei\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchl' ich doch, da\u00df du mich liebst.", "tokens": ["F\u00fchl'", "ich", "doch", ",", "da\u00df", "du", "mich", "liebst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Jetzo kann ich in die Ferne", "tokens": ["Jet\u00b7zo", "kann", "ich", "in", "die", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruhig, Freund, dich ziehen sehn,", "tokens": ["Ru\u00b7hig", ",", "Freund", ",", "dich", "zie\u00b7hen", "sehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "PPER", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und du bleibst gleich einem Sterne", "tokens": ["Und", "du", "bleibst", "gleich", "ei\u00b7nem", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fest an meinem Himmel stehn.", "tokens": ["Fest", "an", "mei\u00b7nem", "Him\u00b7mel", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}