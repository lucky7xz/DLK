{"textgrid.poem.33340": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Lob des Schwein's", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du n\u00fctzlich Thier, das man mit Eckel nennet,", "tokens": ["Du", "n\u00fctz\u00b7lich", "Thier", ",", "das", "man", "mit", "E\u00b7ckel", "nen\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "PRELS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-----", "measure": "unknown.measure.tri"}, "line.2": {"text": "Und doch so gierig i\u00dft,", "tokens": ["Und", "doch", "so", "gie\u00b7rig", "i\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mein Lied soll nun die Welt, die dich verkennet,", "tokens": ["Mein", "Lied", "soll", "nun", "die", "Welt", ",", "die", "dich", "ver\u00b7ken\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Belehren, was du bist.", "tokens": ["Be\u00b7leh\u00b7ren", ",", "was", "du", "bist", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wenn dich der Mensch, weil du im Koth und Schlamme", "tokens": ["Wenn", "dich", "der", "Mensch", ",", "weil", "du", "im", "Koth", "und", "Schlam\u00b7me"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "APPRART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Herumw\u00fchlst, garstig nennt:", "tokens": ["Her\u00b7um\u00b7w\u00fchlst", ",", "gars\u00b7tig", "nennt", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So frag' ihn: ob er denn von seinem Stamme", "tokens": ["So", "frag'", "ihn", ":", "ob", "er", "denn", "von", "sei\u00b7nem", "Stam\u00b7me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Urstoff nicht mehr kennt?", "tokens": ["Den", "Ur\u00b7stoff", "nicht", "mehr", "kennt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Dir dankt (wei\u00df man das Sprichwort recht zu deuten)", "tokens": ["Dir", "dankt", "(", "wei\u00df", "man", "das", "Sprich\u00b7wort", "recht", "zu", "deu\u00b7ten", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "PIS", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Selbst Pallas ihr Latein:", "tokens": ["Selbst", "Pal\u00b7las", "ihr", "La\u00b7tein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PPOSAT", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "D'rum h\u00fcllte sich die Weisheit aller Zeiten", "tokens": ["D'\u00b7rum", "h\u00fcll\u00b7te", "sich", "die", "Weis\u00b7heit", "al\u00b7ler", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PRF", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Stets in dein Leder ein.", "tokens": ["Stets", "in", "dein", "Le\u00b7der", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Das Menschenvolk verachtet dich vergebens;", "tokens": ["Das", "Men\u00b7schen\u00b7volk", "ver\u00b7ach\u00b7tet", "dich", "ver\u00b7ge\u00b7bens", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der weise Epikur", "tokens": ["Der", "wei\u00b7se", "E\u00b7pi\u00b7kur"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verspricht uns ja das h\u00f6chste Gl\u00fcck des Lebens,", "tokens": ["Ver\u00b7spricht", "uns", "ja", "das", "h\u00f6chs\u00b7te", "Gl\u00fcck", "des", "Le\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn wir dir gleichen, nur.", "tokens": ["Wenn", "wir", "dir", "glei\u00b7chen", ",", "nur", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "$,", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der stolze Mensch in seinem Hoheitstraume", "tokens": ["Der", "stol\u00b7ze", "Mensch", "in", "sei\u00b7nem", "Ho\u00b7heits\u00b7trau\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verga\u00df schon ganz und gar", "tokens": ["Ver\u00b7ga\u00df", "schon", "ganz", "und", "gar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Eichelkost, die unter einem Baume", "tokens": ["Der", "Ei\u00b7chel\u00b7kost", ",", "die", "un\u00b7ter", "ei\u00b7nem", "Bau\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dein und sein Futter war.", "tokens": ["Dein", "und", "sein", "Fut\u00b7ter", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "KON", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ja, die Gemeinschaft w\u00e4re ganz verschwunden,", "tokens": ["Ja", ",", "die", "Ge\u00b7mein\u00b7schaft", "w\u00e4\u00b7re", "ganz", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die dich zu uns gesellt,", "tokens": ["Die", "dich", "zu", "uns", "ge\u00b7sellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "H\u00e4tt' nicht ein grosser Heil'ger mit f\u00fcnf Wunden", "tokens": ["H\u00e4tt'", "nicht", "ein", "gros\u00b7ser", "Heil'\u00b7ger", "mit", "f\u00fcnf", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ART", "ADJA", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie wieder hergestellt.", "tokens": ["Sie", "wie\u00b7der", "her\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und h\u00e4lt dich gleich das Volk, das durch sein Stinken", "tokens": ["Und", "h\u00e4lt", "dich", "gleich", "das", "Volk", ",", "das", "durch", "sein", "Stin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ber\u00fchmt ist, nicht f\u00fcr rein,", "tokens": ["Be\u00b7r\u00fchmt", "ist", ",", "nicht", "f\u00fcr", "rein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "PTKNEG", "APPR", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So weiht man doch um Ostern deine Schinken", "tokens": ["So", "weiht", "man", "doch", "um", "Os\u00b7tern", "dei\u00b7ne", "Schin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fcr Christenm\u00e4gen ein.", "tokens": ["F\u00fcr", "Chris\u00b7ten\u00b7m\u00e4\u00b7gen", "ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und sind gleich deine groben Borsten nimmer", "tokens": ["Und", "sind", "gleich", "dei\u00b7ne", "gro\u00b7ben", "Bors\u00b7ten", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Von Schmutz und Koth befreit,", "tokens": ["Von", "Schmutz", "und", "Koth", "be\u00b7freit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So danken wir doch diesen Borsten immer", "tokens": ["So", "dan\u00b7ken", "wir", "doch", "die\u00b7sen", "Bors\u00b7ten", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "All' uns're Reinlichkeit.", "tokens": ["All'", "un\u00b7s'\u00b7re", "Rein\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Dein k\u00f6stlich Fleisch nimmt ohne viel Beschwerde", "tokens": ["Dein", "k\u00f6st\u00b7lich", "Fleisch", "nimmt", "oh\u00b7ne", "viel", "Be\u00b7schwer\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Beim schlecht'sten Futter zu:", "tokens": ["Beim", "schlecht'\u00b7sten", "Fut\u00b7ter", "zu", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Mensch verschlingt den F\u00fcnftelsaft der Erde:", "tokens": ["Der", "Mensch", "ver\u00b7schlingt", "den", "F\u00fcnf\u00b7tel\u00b7saft", "der", "Er\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und n\u00fctzt er so, wie du?", "tokens": ["Und", "n\u00fctzt", "er", "so", ",", "wie", "du", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Sogar dein Speck kann uns in manchem St\u00fccke", "tokens": ["So\u00b7gar", "dein", "Speck", "kann", "uns", "in", "man\u00b7chem", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VMFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von grossem Nutzen sein:", "tokens": ["Von", "gros\u00b7sem", "Nut\u00b7zen", "sein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O w\u00fcrde doch so mancher, der vom Gl\u00fccke", "tokens": ["O", "w\u00fcr\u00b7de", "doch", "so", "man\u00b7cher", ",", "der", "vom", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "ADV", "PIS", "$,", "PRELS", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich m\u00e4sten l\u00e4\u00dft \u2013 ein Schwein!", "tokens": ["Sich", "m\u00e4s\u00b7ten", "l\u00e4\u00dft", "\u2013", "ein", "Schwein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "VVINF", "VVFIN", "$(", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}