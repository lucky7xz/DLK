{"textgrid.poem.61949": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "Die Knaben", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie Du so viel Tr\u00e4nen weinst!", "tokens": ["Wie", "Du", "so", "viel", "Tr\u00e4\u00b7nen", "weinst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ziehest fort, Du lieber Freund,", "tokens": ["Zie\u00b7hest", "fort", ",", "Du", "lie\u00b7ber", "Freund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seh'n wir uns auch wieder einst?", "tokens": ["Seh'n", "wir", "uns", "auch", "wie\u00b7der", "einst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Weit zieh' ich, weit \u00fcber's Meer,", "tokens": ["Weit", "zieh'", "ich", ",", "weit", "\u00fc\u00b7ber's", "Meer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Und ob wir uns wiederseh'n:", "tokens": ["Und", "ob", "wir", "uns", "wie\u00b7der\u00b7seh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zweifle, zweifle ich gar sehr! \u2013", "tokens": ["Zweif\u00b7le", ",", "zweif\u00b7le", "ich", "gar", "sehr", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "In die L\u00e4nder ziehst Du hin,", "tokens": ["In", "die", "L\u00e4n\u00b7der", "ziehst", "Du", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo 's so sch\u00f6n und schw\u00fcl soll sein?", "tokens": ["Wo", "'s", "so", "sch\u00f6n", "und", "schw\u00fcl", "soll", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "KON", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kennst Du auch die Kinder drin?", "tokens": ["Kennst", "Du", "auch", "die", "Kin\u00b7der", "drin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Nach Amerika geht's hin,", "tokens": ["Nach", "A\u00b7me\u00b7ri\u00b7ka", "geht's", "hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dr\u00fcckend hei\u00df soll es dort sein,", "tokens": ["Dr\u00fc\u00b7ckend", "hei\u00df", "soll", "es", "dort", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PPER", "ADV", "VAINF", "$,"], "meter": "+-+---+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und ein Fremdling ich dort bin!", "tokens": ["Und", "ein", "Fremd\u00b7ling", "ich", "dort", "bin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Mach' das Herz mir nicht so schwer,", "tokens": ["Mach'", "das", "Herz", "mir", "nicht", "so", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Einstens seh'n wir uns noch, ja:", "tokens": ["Eins\u00b7tens", "seh'n", "wir", "uns", "noch", ",", "ja", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "$,", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einstens kommst Du wieder her!", "tokens": ["Eins\u00b7tens", "kommst", "Du", "wie\u00b7der", "her", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "La\u00df mich schau'n Dir ins Gesicht,", "tokens": ["La\u00df", "mich", "schau'n", "Dir", "ins", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Denn wenn wir uns wiederseh'n:", "tokens": ["Denn", "wenn", "wir", "uns", "wie\u00b7der\u00b7seh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Kinder sind wir dann doch nicht! \u2013", "tokens": ["Kin\u00b7der", "sind", "wir", "dann", "doch", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}