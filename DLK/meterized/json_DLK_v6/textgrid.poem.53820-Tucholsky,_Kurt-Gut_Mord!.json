{"textgrid.poem.53820": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Gut Mord!", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eine niedrige Stirn, zwei Augenritzen,", "tokens": ["Ei\u00b7ne", "nied\u00b7ri\u00b7ge", "Stirn", ",", "zwei", "Au\u00b7gen\u00b7rit\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "CARD", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "ein breites Kaschubengesicht;", "tokens": ["ein", "brei\u00b7tes", "Ka\u00b7schu\u00b7ben\u00b7ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "die da auf der Anklagebank sitzen,", "tokens": ["die", "da", "auf", "der", "An\u00b7kla\u00b7ge\u00b7bank", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "--+-+---+-", "measure": "anapaest.init"}, "line.4": {"text": "die waren es eigentlich nicht.", "tokens": ["die", "wa\u00b7ren", "es", "ei\u00b7gent\u00b7lich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Der scho\u00df. Der hat den Revolver getragen.", "tokens": ["Der", "scho\u00df", ".", "Der", "hat", "den", "Re\u00b7vol\u00b7ver", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "PDS", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Beweis? Aber wird er gestehn?", "tokens": ["Be\u00b7weis", "?", "A\u00b7ber", "wird", "er", "ge\u00b7stehn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Er kanns ja nicht sagen, er kanns ja nicht sagen \u2013", "tokens": ["Er", "kanns", "ja", "nicht", "sa\u00b7gen", ",", "er", "kanns", "ja", "nicht", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$("], "meter": "-+--+--++-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "er wei\u00df was auf wen.", "tokens": ["er", "wei\u00df", "was", "auf", "wen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "APPR", "PWS", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Auf den Vorgesetzten. Der wird ihn schon decken.", "tokens": ["Auf", "den", "Vor\u00b7ge\u00b7setz\u00b7ten", ".", "Der", "wird", "ihn", "schon", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Er mu\u00df. \u00bbSonst pack ick hier aus \u2013!\u00ab", "tokens": ["Er", "mu\u00df", ".", "\u00bb", "Sonst", "pack", "ick", "hier", "aus", "\u2013", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "$(", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sie werden sich h\u00fcten, zu vollstrecken;", "tokens": ["Sie", "wer\u00b7den", "sich", "h\u00fc\u00b7ten", ",", "zu", "voll\u00b7stre\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VVINF", "$,", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "was k\u00e4me da alles heraus!", "tokens": ["was", "k\u00e4\u00b7me", "da", "al\u00b7les", "he\u00b7raus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Packt man den Anstifter auch beim Kragen?", "tokens": ["Packt", "man", "den", "A\u00b7nstif\u00b7ter", "auch", "beim", "Kra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Leider wird das nicht gehn.", "tokens": ["Lei\u00b7der", "wird", "das", "nicht", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDS", "PTKNEG", "VVINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.7": {"text": "Er kann ja nichts sagen, er kann ja nichts sagen \u2013", "tokens": ["Er", "kann", "ja", "nichts", "sa\u00b7gen", ",", "er", "kann", "ja", "nichts", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "VVINF", "$,", "PPER", "VMFIN", "ADV", "PIS", "VVINF", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "er wei\u00df was auf wen.", "tokens": ["er", "wei\u00df", "was", "auf", "wen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "APPR", "PWS", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Auf die Vorgesetzten. Aufgegebene Befehle,", "tokens": ["Auf", "die", "Vor\u00b7ge\u00b7setz\u00b7ten", ".", "Auf\u00b7ge\u00b7ge\u00b7be\u00b7ne", "Be\u00b7feh\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.2": {"text": "auf Minister und B\u00fcros.", "tokens": ["auf", "Mi\u00b7nis\u00b7ter", "und", "B\u00fc\u00b7ros", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Es zittern Richter und Gener\u00e4le.", "tokens": ["Es", "zit\u00b7tern", "Rich\u00b7ter", "und", "Ge\u00b7ne\u00b7r\u00e4\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "H\u00e4nde weg \u2013 sonst gehts los!", "tokens": ["H\u00e4n\u00b7de", "weg", "\u2013", "sonst", "gehts", "los", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$(", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Der Letzte ists, den die Hunde jagen", "tokens": ["Der", "Letz\u00b7te", "ists", ",", "den", "die", "Hun\u00b7de", "ja\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "PRELS", "ART", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "unter Ausschlu\u00df der \u00d6ffentlichkeit.", "tokens": ["un\u00b7ter", "Aus\u00b7schlu\u00df", "der", "\u00d6f\u00b7fent\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Ihr braucht nicht zu fragen, ihr braucht nicht zu fragen \u2013", "tokens": ["Ihr", "braucht", "nicht", "zu", "fra\u00b7gen", ",", "ihr", "braucht", "nicht", "zu", "fra\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PTKZU", "VVINF", "$,", "PPER", "VVFIN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "wir wissen alle Bescheid.", "tokens": ["wir", "wis\u00b7sen", "al\u00b7le", "Be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Wer ist taub gegen herzzerrei\u00dfende Klagen", "tokens": ["Wer", "ist", "taub", "ge\u00b7gen", "herz\u00b7zer\u00b7rei\u00b7\u00dfen\u00b7de", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "der Frauen, tr\u00e4nenleer \u2013?", "tokens": ["der", "Frau\u00b7en", ",", "tr\u00e4\u00b7nen\u00b7leer", "\u2013", "?"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Ich kanns ja nicht sagen, ich kanns ja nicht sagen.", "tokens": ["Ich", "kanns", "ja", "nicht", "sa\u00b7gen", ",", "ich", "kanns", "ja", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Aber wir wissen alle: wer.", "tokens": ["A\u00b7ber", "wir", "wis\u00b7sen", "al\u00b7le", ":", "wer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$.", "PWS", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}