{"textgrid.poem.66920": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die L\u00e4nder brennen ...", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die L\u00e4nder brennen ...", "tokens": ["Die", "L\u00e4n\u00b7der", "bren\u00b7nen", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Wer hat Brand entfacht?", "tokens": ["Wer", "hat", "Brand", "ent\u00b7facht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NN", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Gier, Ha\u00df, Verkennen?", "tokens": ["Gier", ",", "Ha\u00df", ",", "Ver\u00b7ken\u00b7nen", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Blut will's noch kosten.", "tokens": ["Blut", "will's", "noch", "kos\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Posten,", "tokens": ["Pos\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Halt fest, halt fest auf treuer Wacht!", "tokens": ["Halt", "fest", ",", "halt", "fest", "auf", "treu\u00b7er", "Wacht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Durch H\u00f6hn und Gr\u00fcnde", "tokens": ["Durch", "H\u00f6hn", "und", "Gr\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Morgengraun erwacht.", "tokens": ["Mor\u00b7gen\u00b7graun", "er\u00b7wacht", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wer Gott verst\u00fcnde!", "tokens": ["Wer", "Gott", "ver\u00b7st\u00fcn\u00b7de", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADJA", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Aus Tr\u00fcmmerl\u00f6chern steigen", "tokens": ["Aus", "Tr\u00fcm\u00b7mer\u00b7l\u00f6\u00b7chern", "stei\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Lerchen. Unheimlich Schweigen", "tokens": ["Ler\u00b7chen", ".", "Un\u00b7heim\u00b7lich", "Schwei\u00b7gen"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$.", "ADJD", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Von Front zu Front. Bis da\u00df es heulend kracht.", "tokens": ["Von", "Front", "zu", "Front", ".", "Bis", "da\u00df", "es", "heu\u00b7lend", "kracht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "$.", "APPR", "KOUS", "PPER", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Mit Menschenwitze", "tokens": ["Mit", "Men\u00b7schen\u00b7wit\u00b7ze"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Bin ich am End. Die H\u00f6lle lacht.", "tokens": ["Bin", "ich", "am", "End", ".", "Die", "H\u00f6l\u00b7le", "lacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf Bajonettes Spitze", "tokens": ["Auf", "Ba\u00b7jo\u00b7net\u00b7tes", "Spit\u00b7ze"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Pflanz' ich den letzten Glauben,", "tokens": ["Pflanz'", "ich", "den", "letz\u00b7ten", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Kein Teufel soll ihn rauben:", "tokens": ["Kein", "Teu\u00b7fel", "soll", "ihn", "rau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Gen Not steh ich und Niedertracht.", "tokens": ["Gen", "Not", "steh", "ich", "und", "Nie\u00b7der\u00b7tracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nicht will ich morden.", "tokens": ["Nicht", "will", "ich", "mor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Um Land und Leben geht die Schlacht.", "tokens": ["Um", "Land", "und", "Le\u00b7ben", "geht", "die", "Schlacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich lockt kein Orden", "tokens": ["Mich", "lockt", "kein", "Or\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Und kein gemein Begehren,", "tokens": ["Und", "kein", "ge\u00b7mein", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Will nicht die Welt verheeren,", "tokens": ["Will", "nicht", "die", "Welt", "ver\u00b7hee\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das schw\u00f6r' ich hier mit ganzer Herzensmacht.", "tokens": ["Das", "schw\u00f6r'", "ich", "hier", "mit", "gan\u00b7zer", "Her\u00b7zens\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Einer f\u00fcr alle ...", "tokens": ["Ei\u00b7ner", "f\u00fcr", "al\u00b7le", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PIAT", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "An tausend M\u00fctter hab ich jetzt gedacht.", "tokens": ["An", "tau\u00b7send", "M\u00fct\u00b7ter", "hab", "ich", "jetzt", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn ich falle,", "tokens": ["Und", "wenn", "ich", "fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Soll ihren Tr\u00e4nen Sonne scheinen:", "tokens": ["Soll", "ih\u00b7ren", "Tr\u00e4\u00b7nen", "Son\u00b7ne", "schei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Alle f\u00fcr einen!", "tokens": ["Al\u00b7le", "f\u00fcr", "ei\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Deutschland, halt fest auf starker Freiheitswacht!", "tokens": ["Deutschland", ",", "halt", "fest", "auf", "star\u00b7ker", "Frei\u00b7heits\u00b7wacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}