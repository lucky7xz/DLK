{"dta.poem.21509": {"metadata": {"author": {"name": "N. N., ", "birth": "N.A.", "death": "N.A."}, "title": "Nach dem Strike.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1885", "urn": "urn:nbn:de:kobv:b4-200905196929", "language": ["de:0.99"], "booktitle": "Arent, Wilhelm (Hrsg.): Moderne Dichter-Charaktere. Leipzig, [1885]."}, "poem": {"stanza.1": {"line.1": {"text": "Wir schweigen schon. Ihr habt gewonnen,", "tokens": ["Wir", "schwei\u00b7gen", "schon", ".", "Ihr", "habt", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr M\u00e4nner vom Gesetz und Recht,", "tokens": ["Ihr", "M\u00e4n\u00b7ner", "vom", "Ge\u00b7setz", "und", "Recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sicher seid ihr eingesponnen", "tokens": ["Und", "si\u00b7cher", "seid", "ihr", "ein\u00b7ge\u00b7spon\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In eurer Ordnung eng\u2019 Geflecht.", "tokens": ["In", "eu\u00b7rer", "Ord\u00b7nung", "eng'", "Ge\u00b7flecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir schweigen schon. Stolz durft ihr zeigen,", "tokens": ["Wir", "schwei\u00b7gen", "schon", ".", "Stolz", "durft", "ihr", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Wie ihr gebeugt, was euch bedroht:", "tokens": ["Wie", "ihr", "ge\u00b7beugt", ",", "was", "euch", "be\u00b7droht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir schweigen schon und werden schweigen,", "tokens": ["Wir", "schwei\u00b7gen", "schon", "und", "wer\u00b7den", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Allein wir hungern, schafft uns Brod!", "tokens": ["Al\u00b7lein", "wir", "hun\u00b7gern", ",", "schafft", "uns", "Brod", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ihr sagt, uns eine keckes Wagen,", "tokens": ["Ihr", "sagt", ",", "uns", "ei\u00b7ne", "ke\u00b7ckes", "Wa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu st\u00fcrzen eures Staates Bau \u2014", "tokens": ["Zu", "st\u00fcr\u00b7zen", "eu\u00b7res", "Staa\u00b7tes", "Bau"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O glaubt, in uns das grimme Nagen", "tokens": ["O", "glaubt", ",", "in", "uns", "das", "grim\u00b7me", "Na\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Umgrenzt das Denken sehr genau;", "tokens": ["Um\u00b7grenzt", "das", "Den\u00b7ken", "sehr", "ge\u00b7nau", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir achten still, was fest und eigen,", "tokens": ["Wir", "ach\u00b7ten", "still", ",", "was", "fest", "und", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PRELS", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und uns\u2019re Fahne ist nicht roth:", "tokens": ["Und", "un\u00b7s'\u00b7re", "Fah\u00b7ne", "ist", "nicht", "roth", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Wir schweigen schon und werden schweigen,", "tokens": ["Wir", "schwei\u00b7gen", "schon", "und", "wer\u00b7den", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Allein wir hungern, schafft uns Brod!", "tokens": ["Al\u00b7lein", "wir", "hun\u00b7gern", ",", "schafft", "uns", "Brod", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Im tiefen Schacht, von Luft und Lichte,", "tokens": ["Im", "tie\u00b7fen", "Schacht", ",", "von", "Luft", "und", "Lich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von jedem frohen Blick entfernt,", "tokens": ["Von", "je\u00b7dem", "fro\u00b7hen", "Blick", "ent\u00b7fernt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gefahr, wohin der Fu\u00df sich richte \u2014", "tokens": ["Ge\u00b7fahr", ",", "wo\u00b7hin", "der", "Fu\u00df", "sich", "rich\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir haben tragen es gelernt.", "tokens": ["Wir", "ha\u00b7ben", "tra\u00b7gen", "es", "ge\u00b7lernt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir wissen uns dem Loos zu neigen,", "tokens": ["Wir", "wis\u00b7sen", "uns", "dem", "Loos", "zu", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wir geh\u2019n f\u00fcr\u2019s Leben in den Tod:", "tokens": ["Wir", "geh'n", "f\u00fcr's", "Le\u00b7ben", "in", "den", "Tod", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir schweigen schon und werden schweigen,", "tokens": ["Wir", "schwei\u00b7gen", "schon", "und", "wer\u00b7den", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Allein wir hungern, schafft uns Brod!", "tokens": ["Al\u00b7lein", "wir", "hun\u00b7gern", ",", "schafft", "uns", "Brod", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Vernehmt uns! Euer Ohr verwehre", "tokens": ["Ver\u00b7nehmt", "uns", "!", "Eu\u00b7er", "Ohr", "ver\u00b7weh\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht mehr den Eingang uns\u2019rem Flehn!", "tokens": ["Nicht", "mehr", "den", "Ein\u00b7gang", "un\u00b7s'\u00b7rem", "Flehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und helft, da\u00df von des Mangels Schwere", "tokens": ["Und", "helft", ",", "da\u00df", "von", "des", "Man\u00b7gels", "Schwe\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht Weib und Kinder uns vergeh\u2019n!", "tokens": ["Nicht", "Weib", "und", "Kin\u00b7der", "uns", "ver\u00b7geh'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "KON", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und la\u00dft es nicht zum H\u00f6chsten steigen,", "tokens": ["Und", "la\u00dft", "es", "nicht", "zum", "H\u00f6chs\u00b7ten", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PTKNEG", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bedenket, Eisen bricht die Noth \u2014", "tokens": ["Be\u00b7den\u00b7ket", ",", "Ei\u00b7sen", "bricht", "die", "Noth"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir schweigen schon und werden schweigen,", "tokens": ["Wir", "schwei\u00b7gen", "schon", "und", "wer\u00b7den", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Allein wir hungern, schafft uns Brod!", "tokens": ["Al\u00b7lein", "wir", "hun\u00b7gern", ",", "schafft", "uns", "Brod", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}