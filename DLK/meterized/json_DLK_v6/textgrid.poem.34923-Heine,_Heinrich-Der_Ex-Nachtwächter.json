{"textgrid.poem.34923": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Der Ex-Nachtw\u00e4chter", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mi\u00dfgelaunt, sagt man, verlie\u00df er", "tokens": ["Mi\u00df\u00b7ge\u00b7launt", ",", "sagt", "man", ",", "ver\u00b7lie\u00df", "er"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PIS", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stuttgart an dem Neckarstrand,", "tokens": ["Stutt\u00b7gart", "an", "dem", "Ne\u00b7ckarst\u00b7rand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "und zu M\u00fcnchen an der Isar", "tokens": ["und", "zu", "M\u00fcn\u00b7chen", "an", "der", "I\u00b7sar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ward er Schauspielintendant.", "tokens": ["Ward", "er", "Schau\u00b7spie\u00b7lin\u00b7ten\u00b7dant", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Das ist eine sch\u00f6ne Gegend", "tokens": ["Das", "ist", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Ge\u00b7gend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ebenfalls, es sch\u00e4umet hier,", "tokens": ["E\u00b7ben\u00b7falls", ",", "es", "sch\u00e4u\u00b7met", "hier", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geist- und phantasieerregend,", "tokens": ["Geist", "und", "phan\u00b7ta\u00b7sie\u00b7er\u00b7re\u00b7gend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Holder Bock, das beste Bier.", "tokens": ["Hol\u00b7der", "Bock", ",", "das", "bes\u00b7te", "Bier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch der arme Intendante,", "tokens": ["Doch", "der", "ar\u00b7me", "In\u00b7ten\u00b7dan\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hei\u00dft es, gehet dort herum", "tokens": ["Hei\u00dft", "es", ",", "ge\u00b7het", "dort", "he\u00b7rum"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "ADV", "APZR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Melancholisch wie ein Dante,", "tokens": ["Me\u00b7lan\u00b7cho\u00b7lisch", "wie", "ein", "Dan\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wie Lord Byron gloomy, stumm.", "tokens": ["Wie", "Lord", "By\u00b7ron", "gloo\u00b7my", ",", "stumm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "NN", "NE", "NE", "$,", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.4": {"line.1": {"text": "Ihn erg\u00f6tzen nicht Kom\u00f6dien,", "tokens": ["Ihn", "er\u00b7g\u00f6t\u00b7zen", "nicht", "Ko\u00b7m\u00f6\u00b7di\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Nicht das schlechteste Gedicht,", "tokens": ["Nicht", "das", "schlech\u00b7tes\u00b7te", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Selbst die traurigsten Trag\u00f6dien", "tokens": ["Selbst", "die", "trau\u00b7rigs\u00b7ten", "Tra\u00b7g\u00f6\u00b7di\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Liest er \u2013 doch er l\u00e4chelt nicht.", "tokens": ["Liest", "er", "\u2013", "doch", "er", "l\u00e4\u00b7chelt", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "KON", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Manche Sch\u00f6ne m\u00f6cht erheitern", "tokens": ["Man\u00b7che", "Sch\u00f6\u00b7ne", "m\u00f6cht", "er\u00b7hei\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses gramumflorte Herz,", "tokens": ["Die\u00b7ses", "gra\u00b7mum\u00b7flor\u00b7te", "Herz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch die Liebesblicke scheitern", "tokens": ["Doch", "die", "Lie\u00b7bes\u00b7bli\u00b7cke", "schei\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An dem Panzer, der von Erz", "tokens": ["An", "dem", "Pan\u00b7zer", ",", "der", "von", "Erz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Nannerl mit dem Riegelh\u00e4ubchen", "tokens": ["Nan\u00b7nerl", "mit", "dem", "Rie\u00b7gel\u00b7h\u00e4ub\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Girrt ihn an so muntern Sinns \u2013", "tokens": ["Girrt", "ihn", "an", "so", "mun\u00b7tern", "Sinns", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbgeh ins Kloster, armes T\u00e4ubchen\u00ab,", "tokens": ["\u00bb", "geh", "ins", "Klos\u00b7ter", ",", "ar\u00b7mes", "T\u00e4ub\u00b7chen", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "APPRART", "NN", "$,", "ADJA", "NN", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Spricht er wie ein D\u00e4nenprinz.", "tokens": ["Spricht", "er", "wie", "ein", "D\u00e4\u00b7nen\u00b7prinz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Seine Freunde sind vergebens", "tokens": ["Sei\u00b7ne", "Freun\u00b7de", "sind", "ver\u00b7ge\u00b7bens"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu erlust'gen ihn bem\u00fcht,", "tokens": ["Zu", "er\u00b7lust'\u00b7gen", "ihn", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Singen: \u00bbFreue dich des Lebens,", "tokens": ["Sin\u00b7gen", ":", "\u00bb", "Freu\u00b7e", "dich", "des", "Le\u00b7bens", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil dir noch dein L\u00e4mpchen gl\u00fcht!\u00ab", "tokens": ["Weil", "dir", "noch", "dein", "L\u00e4mp\u00b7chen", "gl\u00fcht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Kann dich nichts zum Frohsinn reizen", "tokens": ["Kann", "dich", "nichts", "zum", "Froh\u00b7sinn", "rei\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "PIS", "APPRART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hier in dieser h\u00fcbschen Stadt,", "tokens": ["Hier", "in", "die\u00b7ser", "h\u00fcb\u00b7schen", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die an am\u00fcsanten K\u00e4uzen", "tokens": ["Die", "an", "a\u00b7m\u00fcs\u00b7an\u00b7ten", "K\u00e4u\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wahrlich keinen Mangel hat?", "tokens": ["Wahr\u00b7lich", "kei\u00b7nen", "Man\u00b7gel", "hat", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Zwar hat sie in j\u00fcngsten Tagen", "tokens": ["Zwar", "hat", "sie", "in", "j\u00fcng\u00b7sten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Eingeb\u00fc\u00dft so manchen Mann,", "tokens": ["Ein\u00b7ge\u00b7b\u00fc\u00dft", "so", "man\u00b7chen", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Manchen trefflichen Choragen,", "tokens": ["Man\u00b7chen", "treff\u00b7li\u00b7chen", "Cho\u00b7ra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Den man schwer entbehren kann.", "tokens": ["Den", "man", "schwer", "ent\u00b7beh\u00b7ren", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "W\u00e4r der Ma\u00dfmann nur geblieben!", "tokens": ["W\u00e4r", "der", "Ma\u00df\u00b7mann", "nur", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieser h\u00e4tte wohl am End'", "tokens": ["Die\u00b7ser", "h\u00e4t\u00b7te", "wohl", "am", "End'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jeden Tr\u00fcbsinn dir vertrieben", "tokens": ["Je\u00b7den", "Tr\u00fcb\u00b7sinn", "dir", "ver\u00b7trie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch sein Burzelbaumtalent.", "tokens": ["Durch", "sein", "Bur\u00b7zel\u00b7baum\u00b7ta\u00b7lent", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Schelling, der ist unersetzlich!", "tokens": ["Schel\u00b7ling", ",", "der", "ist", "un\u00b7er\u00b7setz\u00b7lich", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Verlust vom h\u00f6chsten Wert!", "tokens": ["Ein", "Ver\u00b7lust", "vom", "h\u00f6chs\u00b7ten", "Wert", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "War als Philosoph erg\u00f6tzlich", "tokens": ["War", "als", "Phi\u00b7lo\u00b7soph", "er\u00b7g\u00f6tz\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "KOKOM", "NE", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und als Mime hochgeehrt.", "tokens": ["Und", "als", "Mi\u00b7me", "hoch\u00b7geehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Da\u00df der Gr\u00fcnder der Walhalla", "tokens": ["Da\u00df", "der", "Gr\u00fcn\u00b7der", "der", "Wal\u00b7hal\u00b7la"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Fortging und zur\u00fccke lie\u00df", "tokens": ["Fort\u00b7ging", "und", "zu\u00b7r\u00fc\u00b7cke", "lie\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "VVFIN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seine Manuskripte alle,", "tokens": ["Sei\u00b7ne", "Ma\u00b7nus\u00b7krip\u00b7te", "al\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleichfalls ein Verlust war dies!", "tokens": ["Gleich\u00b7falls", "ein", "Ver\u00b7lust", "war", "dies", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PDS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Mit Cornelius ging verloren", "tokens": ["Mit", "Cor\u00b7ne\u00b7li\u00b7us", "ging", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auch des Meisters J\u00fcngerschaft;", "tokens": ["Auch", "des", "Meis\u00b7ters", "J\u00fcn\u00b7ger\u00b7schaft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat das Haar sich abgeschoren,", "tokens": ["Hat", "das", "Haar", "sich", "ab\u00b7ge\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und im Haar war ihre Kraft.", "tokens": ["Und", "im", "Haar", "war", "ih\u00b7re", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.14": {"line.1": {"text": "Denn der kluge Meister legte", "tokens": ["Denn", "der", "klu\u00b7ge", "Meis\u00b7ter", "leg\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen Zauber in das Haar,", "tokens": ["Ei\u00b7nen", "Zau\u00b7ber", "in", "das", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Drin sich sichtbar oft bewegte", "tokens": ["Drin", "sich", "sicht\u00b7bar", "oft", "be\u00b7weg\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PRF", "ADJD", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Etwas, das lebendig war.", "tokens": ["Et\u00b7was", ",", "das", "le\u00b7ben\u00b7dig", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Tot ist G\u00f6rres, die Hy\u00e4ne.", "tokens": ["Tot", "ist", "G\u00f6r\u00b7res", ",", "die", "Hy\u00b7\u00e4\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NE", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ob des heiligen Offiz", "tokens": ["Ob", "des", "hei\u00b7li\u00b7gen", "Of\u00b7fiz"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Umsturz quoll ihm einst die Tr\u00e4ne", "tokens": ["Um\u00b7sturz", "quoll", "ihm", "einst", "die", "Tr\u00e4\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Aus des Auges rotem Schlitz.", "tokens": ["Aus", "des", "Au\u00b7ges", "ro\u00b7tem", "Schlitz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Dieses Raubtier hat ein S\u00fchnchen", "tokens": ["Die\u00b7ses", "Raub\u00b7tier", "hat", "ein", "S\u00fchn\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinterlassen, doch es ist", "tokens": ["Hin\u00b7ter\u00b7las\u00b7sen", ",", "doch", "es", "ist"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "KON", "PPER", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur ein giftiges Kaninchen,", "tokens": ["Nur", "ein", "gif\u00b7ti\u00b7ges", "Ka\u00b7nin\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches Nonnenf\u00fcrzchen fri\u00dft.", "tokens": ["Wel\u00b7ches", "Non\u00b7nen\u00b7f\u00fcrz\u00b7chen", "fri\u00dft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Apropos! Der erzinfame", "tokens": ["A\u00b7pro\u00b7pos", "!", "Der", "er\u00b7zin\u00b7fa\u00b7me"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADV", "$.", "ART", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Pfaffe Dollingerius \u2013", "tokens": ["Pfaf\u00b7fe", "Dol\u00b7lin\u00b7ge\u00b7rius", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Das ist ungef\u00e4hr sein Name \u2013", "tokens": ["Das", "ist", "un\u00b7ge\u00b7f\u00e4hr", "sein", "Na\u00b7me", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "PPOSAT", "NN", "$("], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "Lebt er noch am Isarflu\u00df?", "tokens": ["Lebt", "er", "noch", "am", "I\u00b7sar\u00b7flu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Dieser bleibt mir unverge\u00dflich!", "tokens": ["Die\u00b7ser", "bleibt", "mir", "un\u00b7ver\u00b7ge\u00df\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bei dem reinen Sonnenlicht!", "tokens": ["Bei", "dem", "rei\u00b7nen", "Son\u00b7nen\u00b7licht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemals schaut ich solch ein h\u00e4\u00dflich", "tokens": ["Nie\u00b7mals", "schaut", "ich", "solch", "ein", "h\u00e4\u00df\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ART", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Armes\u00fcnderangesicht.", "tokens": ["Ar\u00b7me\u00b7s\u00fcn\u00b7der\u00b7an\u00b7ge\u00b7sicht", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wie es hei\u00dft, ist er gekommen", "tokens": ["Wie", "es", "hei\u00dft", ",", "ist", "er", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf die Welt gar wundersam,", "tokens": ["Auf", "die", "Welt", "gar", "wun\u00b7der\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat den Afterweg genommen,", "tokens": ["Hat", "den", "Af\u00b7ter\u00b7weg", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu der Mutter Schreck und Scham.", "tokens": ["Zu", "der", "Mut\u00b7ter", "Schreck", "und", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Sah ihn am Karfreitag wallen", "tokens": ["Sah", "ihn", "am", "Kar\u00b7frei\u00b7tag", "wal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "VVINF"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "In dem Zug der Prozession,", "tokens": ["In", "dem", "Zug", "der", "Pro\u00b7zes\u00b7si\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Von den dunkeln M\u00e4nnern allen", "tokens": ["Von", "den", "dun\u00b7keln", "M\u00e4n\u00b7nern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wohl die dunkelste Person.", "tokens": ["Wohl", "die", "dun\u00b7kels\u00b7te", "Per\u00b7son", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Ja, Monacho Monachorum", "tokens": ["Ja", ",", "Mo\u00b7na\u00b7cho", "Mo\u00b7na\u00b7cho\u00b7rum"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "NE", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ist in unsrer Zeit der Sitz", "tokens": ["Ist", "in", "uns\u00b7rer", "Zeit", "der", "Sitz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Virorum obscurorum,", "tokens": ["Der", "Vi\u00b7ro\u00b7rum", "ob\u00b7scu\u00b7ro\u00b7rum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die verherrlicht Huttens Witz.", "tokens": ["Die", "ver\u00b7herr\u00b7licht", "Hut\u00b7tens", "Witz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Wie du zuckst beim Namen Hutten!", "tokens": ["Wie", "du", "zuckst", "beim", "Na\u00b7men", "Hut\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "APPRART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ex-Nachtw\u00e4chter, wache auf!", "tokens": ["Ex\u00b7Nacht\u00b7w\u00e4ch\u00b7ter", ",", "wa\u00b7che", "auf", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier die Pritsche, dort die Kutten,", "tokens": ["Hier", "die", "Prit\u00b7sche", ",", "dort", "die", "Kut\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wie eh'mals schlage drauf!", "tokens": ["Und", "wie", "eh'\u00b7mals", "schla\u00b7ge", "drauf", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.23": {"line.1": {"text": "Gei\u00dfle ihre R\u00fccken blutig,", "tokens": ["Gei\u00df\u00b7le", "ih\u00b7re", "R\u00fc\u00b7cken", "blu\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie einst tat der Ullerich;", "tokens": ["Wie", "einst", "tat", "der", "Ul\u00b7le\u00b7rich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "ART", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser schlug so rittermutig,", "tokens": ["Die\u00b7ser", "schlug", "so", "rit\u00b7ter\u00b7mu\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jene heulten f\u00fcrchterlich.", "tokens": ["Je\u00b7ne", "heul\u00b7ten", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Der Erasmus mu\u00dfte lachen", "tokens": ["Der", "Er\u00b7as\u00b7mus", "mu\u00df\u00b7te", "la\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So gewaltig ob dem Spa\u00df,", "tokens": ["So", "ge\u00b7wal\u00b7tig", "ob", "dem", "Spa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOUS", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihm platzte in dem Rachen", "tokens": ["Da\u00df", "ihm", "platz\u00b7te", "in", "dem", "Ra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sein Geschw\u00fcr und er genas.", "tokens": ["Sein", "Ge\u00b7schw\u00fcr", "und", "er", "ge\u00b7nas", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Auf der Ebersburg desgleichen", "tokens": ["Auf", "der", "E\u00b7bers\u00b7burg", "des\u00b7glei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lachte Sickingen wie toll,", "tokens": ["Lach\u00b7te", "Si\u00b7ckin\u00b7gen", "wie", "toll", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KOKOM", "ADJD", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Und in allen deutschen Reichen", "tokens": ["Und", "in", "al\u00b7len", "deut\u00b7schen", "Rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Gel\u00e4chter widerscholl.", "tokens": ["Das", "Ge\u00b7l\u00e4ch\u00b7ter", "wi\u00b7der\u00b7scholl", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Alte lachten wie die Jungen \u2013", "tokens": ["Al\u00b7te", "lach\u00b7ten", "wie", "die", "Jun\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine einz'ge Lache nur", "tokens": ["Ei\u00b7ne", "einz'\u00b7ge", "La\u00b7che", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "War ganz Wittenberg, sie sungen", "tokens": ["War", "ganz", "Wit\u00b7ten\u00b7berg", ",", "sie", "sun\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "NE", "$,", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbgaudeamus igitur!\u00ab", "tokens": ["\u00bb", "gau\u00b7dea\u00b7mus", "i\u00b7gi\u00b7tur", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "FM.la", "FM.la", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.27": {"line.1": {"text": "Freilich, klopft man faule Kutten,", "tokens": ["Frei\u00b7lich", ",", "klopft", "man", "fau\u00b7le", "Kut\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PIS", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4ngt man Fl\u00f6h' im \u00dcberflu\u00df,", "tokens": ["F\u00e4ngt", "man", "Fl\u00f6h'", "im", "\u00dc\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es mu\u00dfte sich der Hutten", "tokens": ["Und", "es", "mu\u00df\u00b7te", "sich", "der", "Hut\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PRF", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Manchmal kratzen vor Verdru\u00df.", "tokens": ["Manch\u00b7mal", "krat\u00b7zen", "vor", "Ver\u00b7dru\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Aber \u00bbAlea est jacta!\u00ab", "tokens": ["A\u00b7ber", "\u00bb", "A\u00b7lea", "est", "jac\u00b7ta", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$(", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War des Ritters Schlachtgeschrei,", "tokens": ["War", "des", "Rit\u00b7ters", "Schlacht\u00b7ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er knickte und er knackte", "tokens": ["Und", "er", "knick\u00b7te", "und", "er", "knack\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Pulices und Klerisei.", "tokens": ["Pu\u00b7li\u00b7ces", "und", "Kle\u00b7ri\u00b7sei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Ex-Nachtw\u00e4chter, Stundenrufer,", "tokens": ["Ex\u00b7Nacht\u00b7w\u00e4ch\u00b7ter", ",", "Stun\u00b7den\u00b7ru\u00b7fer", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "F\u00fchlst du nicht dein Herz ergl\u00fchn?", "tokens": ["F\u00fchlst", "du", "nicht", "dein", "Herz", "er\u00b7gl\u00fchn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rege dich am Isarufer,", "tokens": ["Re\u00b7ge", "dich", "am", "I\u00b7sa\u00b7ru\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sch\u00fcttle ab den kranken Spleen.", "tokens": ["Sch\u00fctt\u00b7le", "ab", "den", "kran\u00b7ken", "Spleen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Deine langen Fortschrittsbeine,", "tokens": ["Dei\u00b7ne", "lan\u00b7gen", "Fort\u00b7schritts\u00b7bei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heb sie auf zu neuem Lauf \u2013", "tokens": ["Heb", "sie", "auf", "zu", "neu\u00b7em", "Lauf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kutten grobe, Kutten feine,", "tokens": ["Kut\u00b7ten", "gro\u00b7be", ",", "Kut\u00b7ten", "fei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADJA", "$,", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind es Kutten, schlage drauf!", "tokens": ["Sind", "es", "Kut\u00b7ten", ",", "schla\u00b7ge", "drauf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Jener aber seufzt, und seine", "tokens": ["Je\u00b7ner", "a\u00b7ber", "seufzt", ",", "und", "sei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADV", "VVFIN", "$,", "KON", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4nde ringend er versetzt:", "tokens": ["H\u00e4n\u00b7de", "rin\u00b7gend", "er", "ver\u00b7setzt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbmeine langen Fortschrittsbeine", "tokens": ["\u00bb", "mei\u00b7ne", "lan\u00b7gen", "Fort\u00b7schritts\u00b7bei\u00b7ne"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind europam\u00fcde jetzt.", "tokens": ["Sind", "eu\u00b7ro\u00b7pa\u00b7m\u00fc\u00b7de", "jetzt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Meine H\u00fchneraugen j\u00fccken,", "tokens": ["Mei\u00b7ne", "H\u00fch\u00b7ner\u00b7au\u00b7gen", "j\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Habe deutsche enge Schuh',", "tokens": ["Ha\u00b7be", "deut\u00b7sche", "en\u00b7ge", "Schuh'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wo mich die Schuhe dr\u00fccken,", "tokens": ["Und", "wo", "mich", "die", "Schu\u00b7he", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wei\u00df ich wohl \u2013 la\u00df mich in Ruh'!\u00ab", "tokens": ["Wei\u00df", "ich", "wohl", "\u2013", "la\u00df", "mich", "in", "Ruh'", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$(", "VVIMP", "PPER", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}