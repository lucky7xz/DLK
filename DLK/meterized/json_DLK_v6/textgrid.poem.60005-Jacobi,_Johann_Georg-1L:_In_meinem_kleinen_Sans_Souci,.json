{"textgrid.poem.60005": {"metadata": {"author": {"name": "Jacobi, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "1L: In meinem kleinen Sans Souci,", "genre": "verse", "period": "N.A.", "pub_year": 1777, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In meinem kleinen Sans Souci,", "tokens": ["In", "mei\u00b7nem", "klei\u00b7nen", "Sans", "Sou\u00b7ci", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O liebster Freund, besuche mich!", "tokens": ["O", "liebs\u00b7ter", "Freund", ",", "be\u00b7su\u00b7che", "mich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In seinem gro\u00dfen Sans Souci", "tokens": ["In", "sei\u00b7nem", "gro\u00b7\u00dfen", "Sans", "Sou\u00b7ci"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist unser C\u00e4sar Friederich,", "tokens": ["Ist", "un\u00b7ser", "C\u00e4\u00b7sar", "Frie\u00b7de\u00b7rich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit seiner reichen Politik,", "tokens": ["Mit", "sei\u00b7ner", "rei\u00b7chen", "Po\u00b7li\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit seiner lieblichen Musik,", "tokens": ["Mit", "sei\u00b7ner", "lieb\u00b7li\u00b7chen", "Mu\u00b7sik", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit seiner gr\u00fcndlichen Kritik", "tokens": ["Mit", "sei\u00b7ner", "gr\u00fcnd\u00b7li\u00b7chen", "Kri\u00b7tik"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und Taktik und Metaphysik,", "tokens": ["Und", "Tak\u00b7tik", "und", "Me\u00b7ta\u00b7phy\u00b7sik", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.9": {"text": "So gl\u00fccklich lange nicht, als ich", "tokens": ["So", "gl\u00fcck\u00b7lich", "lan\u00b7ge", "nicht", ",", "als", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "PTKNEG", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit meiner armen Poesie", "tokens": ["Mit", "mei\u00b7ner", "ar\u00b7men", "Poe\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "In meinem kleinen Sans Souci.", "tokens": ["In", "mei\u00b7nem", "klei\u00b7nen", "Sans", "Sou\u00b7ci", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Klein ist es, gr\u00f6\u00dfer k\u00f6nnt' es seyn.", "tokens": ["Klein", "ist", "es", ",", "gr\u00f6\u00b7\u00dfer", "k\u00f6nnt'", "es", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "$,", "ADJD", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch meine K\u00e4mmerchen sind klein;", "tokens": ["Auch", "mei\u00b7ne", "K\u00e4m\u00b7mer\u00b7chen", "sind", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zwey Musen, Amor, ich und Du,", "tokens": ["Zwey", "Mu\u00b7sen", ",", "A\u00b7mor", ",", "ich", "und", "Du", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "NE", "$,", "PPER", "KON", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mehr, wahrlich! gehen nicht hinein;", "tokens": ["Mehr", ",", "wahr\u00b7lich", "!", "ge\u00b7hen", "nicht", "hin\u00b7ein", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "ADV", "$.", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch, sehn wir uns darin allein,", "tokens": ["Doch", ",", "sehn", "wir", "uns", "da\u00b7rin", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "PRF", "PAV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So schlie\u00dfen wir die Th\u00fcren zu,", "tokens": ["So", "schlie\u00b7\u00dfen", "wir", "die", "Th\u00fc\u00b7ren", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und lassen keinen mehr hinein!", "tokens": ["Und", "las\u00b7sen", "kei\u00b7nen", "mehr", "hin\u00b7ein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wozu sollt' es denn gr\u00f6\u00dfer seyn?", "tokens": ["Wo\u00b7zu", "sollt'", "es", "denn", "gr\u00f6\u00b7\u00dfer", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Das gro\u00dfe Sans Souci g\u00f6nn' ich", "tokens": ["Das", "gro\u00b7\u00dfe", "Sans", "Sou\u00b7ci", "g\u00f6nn'", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NE", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Von Herzen meinem Friederich.", "tokens": ["Von", "Her\u00b7zen", "mei\u00b7nem", "Frie\u00b7de\u00b7rich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ihm folgen allenthalben Haufen", "tokens": ["Ihm", "fol\u00b7gen", "al\u00b7len\u00b7thal\u00b7ben", "Hau\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Von k\u00f6niglichen Sorgen nach;", "tokens": ["Von", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Sor\u00b7gen", "nach", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ins Kabinet, ins Schlafgemach", "tokens": ["Ins", "Ka\u00b7bi\u00b7net", ",", "ins", "Schlaf\u00b7ge\u00b7mach"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wird nachgeritten, nachgelaufen;", "tokens": ["Wird", "nach\u00b7ge\u00b7rit\u00b7ten", ",", "nach\u00b7ge\u00b7lau\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Geruhig unter seinem Dach", "tokens": ["Ge\u00b7ru\u00b7hig", "un\u00b7ter", "sei\u00b7nem", "Dach"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "L\u00e4\u00dft Eichel", "tokens": ["L\u00e4\u00dft", "Ei\u00b7chel"], "token_info": ["word", "word"], "pos": ["VVFIN", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.17": {"text": "Couriere kommen angeflogen,", "tokens": ["Cou\u00b7ri\u00b7e\u00b7re", "kom\u00b7men", "an\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.18": {"text": "Er liest, ein gro\u00dfes Wetter dr\u00e4ut,", "tokens": ["Er", "liest", ",", "ein", "gro\u00b7\u00dfes", "Wet\u00b7ter", "dr\u00e4ut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Beweise geben zwanzig Bogen", "tokens": ["Be\u00b7wei\u00b7se", "ge\u00b7ben", "zwan\u00b7zig", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVINF", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Voll sch\u00e4ndlicher Treulosigkeit.", "tokens": ["Voll", "sch\u00e4nd\u00b7li\u00b7cher", "Treu\u00b7lo\u00b7sig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Verbunden wider einen Weisen", "tokens": ["Ver\u00b7bun\u00b7den", "wi\u00b7der", "ei\u00b7nen", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sieht er um sich die ganze Welt;", "tokens": ["Sieht", "er", "um", "sich", "die", "gan\u00b7ze", "Welt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er sinnt, beschlie\u00dfet, ist ein Held;", "tokens": ["Er", "sinnt", ",", "be\u00b7schlie\u00b7\u00dfet", ",", "ist", "ein", "Held", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die G\u00f6tter und die Menschen preisen", "tokens": ["Die", "G\u00f6t\u00b7ter", "und", "die", "Men\u00b7schen", "prei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den Philosophen und den Held,", "tokens": ["Den", "Phi\u00b7lo\u00b7so\u00b7phen", "und", "den", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Und wer ihn st\u00fcrzen wollte, f\u00e4llt.", "tokens": ["Und", "wer", "ihn", "st\u00fcr\u00b7zen", "woll\u00b7te", ",", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Allein, was hat er von der Ehre,", "tokens": ["Al\u00b7lein", ",", "was", "hat", "er", "von", "der", "Eh\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er ein Fels im Meere war?", "tokens": ["Da\u00df", "er", "ein", "Fels", "im", "Mee\u00b7re", "war", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er die rasende Meg\u00e4re", "tokens": ["Da\u00df", "er", "die", "ra\u00b7sen\u00b7de", "Me\u00b7g\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zur\u00fcck in ihre H\u00f6lle zwang,", "tokens": ["Zu\u00b7r\u00fcck", "in", "ih\u00b7re", "H\u00f6l\u00b7le", "zwang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sie mit Ketten feste band,", "tokens": ["Und", "sie", "mit", "Ket\u00b7ten", "fes\u00b7te", "band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sein geliebtes Vaterland", "tokens": ["Und", "sein", "ge\u00b7lieb\u00b7tes", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Errettete vom Untergang?", "tokens": ["Er\u00b7ret\u00b7te\u00b7te", "vom", "Un\u00b7ter\u00b7gang", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was hat der Held von dieser Ehre,", "tokens": ["Was", "hat", "der", "Held", "von", "die\u00b7ser", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Von dieser t\u00e4glichen Gefahr?", "tokens": ["Von", "die\u00b7ser", "t\u00e4g\u00b7li\u00b7chen", "Ge\u00b7fahr", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Im f\u00fcnften und im sechsten Jahr", "tokens": ["Im", "f\u00fcnf\u00b7ten", "und", "im", "sechs\u00b7ten", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "KON", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Von diesen zwanzig gro\u00dfen Siegen?", "tokens": ["Von", "die\u00b7sen", "zwan\u00b7zig", "gro\u00b7\u00dfen", "Sie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O, liebster Freund! ich schw\u00f6r' es Dir:", "tokens": ["O", ",", "liebs\u00b7ter", "Freund", "!", "ich", "schw\u00f6r'", "es", "Dir", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bist Du mit Deiner Muse hier", "tokens": ["Bist", "Du", "mit", "Dei\u00b7ner", "Mu\u00b7se", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In meinem Sans Souci bey mir;", "tokens": ["In", "mei\u00b7nem", "Sans", "Sou\u00b7ci", "bey", "mir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von meinem t\u00e4glichen Vergn\u00fcgen", "tokens": ["Von", "mei\u00b7nem", "t\u00e4g\u00b7li\u00b7chen", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geb' ich ihm keinen Tag daf\u00fcr!", "tokens": ["Geb'", "ich", "ihm", "kei\u00b7nen", "Tag", "da\u00b7f\u00fcr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "PIAT", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}