{"textgrid.poem.63099": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Resignation", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja, so geht es in der Welt,", "tokens": ["Ja", ",", "so", "geht", "es", "in", "der", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles f\u00fchlt man sich entgleiten,", "tokens": ["Al\u00b7les", "f\u00fchlt", "man", "sich", "ent\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jahre, Haare, Liebe, Geld", "tokens": ["Jah\u00b7re", ",", "Haa\u00b7re", ",", "Lie\u00b7be", ",", "Geld"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die gro\u00dfen Trunkenheiten.", "tokens": ["Und", "die", "gro\u00b7\u00dfen", "Trun\u00b7ken\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach, bald ist man Doktor juris", "tokens": ["Ach", ",", "bald", "ist", "man", "Dok\u00b7tor", "ju\u00b7ris"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "PIS", "NN", "NE"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "Und Assessor und verehlicht,", "tokens": ["Und", "As\u00b7ses\u00b7sor", "und", "ver\u00b7eh\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und was eine rechte Hur is,", "tokens": ["Und", "was", "ei\u00b7ne", "rech\u00b7te", "Hur", "is", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "FM", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Das verlernt man so allm\u00e4hlicht.", "tokens": ["Das", "ver\u00b7lernt", "man", "so", "all\u00b7m\u00e4h\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "N\u00fcchtern wurde man und schlecht.", "tokens": ["N\u00fcch\u00b7tern", "wur\u00b7de", "man", "und", "schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIS", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Herz, du stumpfer, dumpfer Hammer!", "tokens": ["Herz", ",", "du", "stump\u00b7fer", ",", "dum\u00b7pfer", "Ham\u00b7mer", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADJD", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist man jetzt einmal bezecht,", "tokens": ["Ist", "man", "jetzt", "ein\u00b7mal", "be\u00b7zecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat man gleich den Katzenjammer.", "tokens": ["Hat", "man", "gleich", "den", "Kat\u00b7zen\u00b7jam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}