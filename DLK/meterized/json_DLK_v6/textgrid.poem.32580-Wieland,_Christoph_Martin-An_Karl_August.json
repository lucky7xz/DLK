{"textgrid.poem.32580": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "An Karl August", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der K\u00f6nig zu Sanct Ildefons", "tokens": ["Der", "K\u00f6\u00b7nig", "zu", "Sanct", "Il\u00b7de\u00b7fons"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "versuchte \u2013 (den kleinen Reim auf ons", "tokens": ["ver\u00b7such\u00b7te", "\u2013", "(", "den", "klei\u00b7nen", "Reim", "auf", "ons"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "$(", "ART", "ADJA", "NN", "APPR", "NE"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "bitt ich mir heute zu creditieren)", "tokens": ["bitt", "ich", "mir", "heu\u00b7te", "zu", "cre\u00b7di\u00b7tie\u00b7ren", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "sich K\u00f6niglich zu divertieren,", "tokens": ["sich", "K\u00f6\u00b7nig\u00b7lich", "zu", "di\u00b7ver\u00b7tie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "versuchte nicht mit mehr Geduld", "tokens": ["ver\u00b7such\u00b7te", "nicht", "mit", "mehr", "Ge\u00b7duld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "auf seinen ", "tokens": ["auf", "sei\u00b7nen"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "als ich, \u2013 mit guter Art der Schuld", "tokens": ["als", "ich", ",", "\u2013", "mit", "gu\u00b7ter", "Art", "der", "Schuld"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "$(", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "des leidigen Gratulanten-Reigen", "tokens": ["des", "lei\u00b7di\u00b7gen", "Gra\u00b7tu\u00b7lan\u00b7ten\u00b7Rei\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "bei ", "tokens": ["bei"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.10": {"text": "auf meinen lahmen Pegasus,", "tokens": ["auf", "mei\u00b7nen", "lah\u00b7men", "Pe\u00b7ga\u00b7sus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "(nicht gl\u00fccklicher als Carolus)", "tokens": ["(", "nicht", "gl\u00fcck\u00b7li\u00b7cher", "als", "Ca\u00b7ro\u00b7lus", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "ADJD", "KOKOM", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "mich aufzuschwingen heut versuchte;", "tokens": ["mich", "auf\u00b7zu\u00b7schwin\u00b7gen", "heut", "ver\u00b7such\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "wiewohl ich Olymp und Tartarus", "tokens": ["wie\u00b7wohl", "ich", "O\u00b7lymp", "und", "Tar\u00b7ta\u00b7rus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "KON", "NN"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "auf gut poetisch zu H\u00fclfe fluchte.", "tokens": ["auf", "gut", "po\u00b7e\u00b7tisch", "zu", "H\u00fcl\u00b7fe", "fluch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Der Gaul zwar, wie ich r\u00fchmen mu\u00df", "tokens": ["Der", "Gaul", "zwar", ",", "wie", "ich", "r\u00fch\u00b7men", "mu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "PWAV", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "stund fr\u00f6mmer als ein Palmtags-Esel \u2013", "tokens": ["stund", "fr\u00f6m\u00b7mer", "als", "ein", "Palm\u00b7tags\u00b7E\u00b7sel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Hier fehlt mir, da der wackre R\u00f6sel", "tokens": ["Hier", "fehlt", "mir", ",", "da", "der", "wack\u00b7re", "R\u00f6\u00b7sel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "bekannter ma\u00dfen nur Keller Esel", "tokens": ["be\u00b7kann\u00b7ter", "ma\u00b7\u00dfen", "nur", "Kel\u00b7ler", "E\u00b7sel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ADV", "PIAT", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "in seinem ber\u00fchmten Insektenwerk", "tokens": ["in", "sei\u00b7nem", "be\u00b7r\u00fchm\u00b7ten", "In\u00b7sek\u00b7ten\u00b7werk"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "geliefert, schon wieder ein Reim auf esel,", "tokens": ["ge\u00b7lie\u00b7fert", ",", "schon", "wie\u00b7der", "ein", "Reim", "auf", "e\u00b7sel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "ADV", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.21": {"text": "so wie, wenn mir Herr Kriegsrat Merk", "tokens": ["so", "wie", ",", "wenn", "mir", "Herr", "Kriegs\u00b7rat", "Merk"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "$,", "KOUS", "PPER", "NN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "nicht gleich zu Hilfe k\u00e4m, auf werk.", "tokens": ["nicht", "gleich", "zu", "Hil\u00b7fe", "k\u00e4m", ",", "auf", "werk", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "VVFIN", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich seh aus diesem Reimen-Mangel,", "tokens": ["Ich", "seh", "aus", "die\u00b7sem", "Rei\u00b7men\u00b7Man\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "(und da ich, statt sie Scharenweis", "tokens": ["(", "und", "da", "ich", ",", "statt", "sie", "Scha\u00b7ren\u00b7weis"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "KOUS", "PPER", "$,", "KOUI", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ins Garn sonst fliegen, mit Angst und Schwei\u00df", "tokens": ["ins", "Garn", "sonst", "flie\u00b7gen", ",", "mit", "Angst", "und", "Schwei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVINF", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "durch R\u00f6sel und Merk bis von Archangel", "tokens": ["durch", "R\u00f6\u00b7sel", "und", "Merk", "bis", "von", "Ar\u00b7chan\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "APPR", "NN"], "meter": "-+--+--++-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "die Reime zusammentreiben mu\u00df)", "tokens": ["die", "Rei\u00b7me", "zu\u00b7sam\u00b7men\u00b7trei\u00b7ben", "mu\u00df", ")"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "da\u00df selbst Hans Sachsens Genius,", "tokens": ["da\u00df", "selbst", "Hans", "Sach\u00b7sens", "Ge\u00b7nius", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "NE", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "den ich zu H\u00fclfe herbei zitiert,", "tokens": ["den", "ich", "zu", "H\u00fcl\u00b7fe", "her\u00b7bei", "zi\u00b7tiert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "um meine Not sich wenig schiert.", "tokens": ["um", "mei\u00b7ne", "Not", "sich", "we\u00b7nig", "schiert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ich bitte, ", "tokens": ["Ich", "bit\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Sie wolln an meinen Platz sich setzen,", "tokens": ["Sie", "wolln", "an", "mei\u00b7nen", "Platz", "sich", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "und hocherleuchtet ermessen und sch\u00e4tzen,", "tokens": ["und", "ho\u00b7cher\u00b7leuch\u00b7tet", "er\u00b7mes\u00b7sen", "und", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "wie unser einem zu Mute wird,", "tokens": ["wie", "un\u00b7ser", "ei\u00b7nem", "zu", "Mu\u00b7te", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "der Tausend sch\u00f6ne Sachen zu sagen", "tokens": ["der", "Tau\u00b7send", "sch\u00f6\u00b7ne", "Sa\u00b7chen", "zu", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "so schuldig als erb\u00f6tig w\u00e4r,", "tokens": ["so", "schul\u00b7dig", "als", "er\u00b7b\u00f6\u00b7tig", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "und gleichwohl eher, ohne Zagen,", "tokens": ["und", "gleich\u00b7wohl", "e\u00b7her", ",", "oh\u00b7ne", "Za\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "gleich jenem edeln Schwabenheer", "tokens": ["gleich", "je\u00b7nem", "e\u00b7deln", "Schwa\u00b7ben\u00b7heer"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "sich gegen sechs Hasen mit Einem Speer", "tokens": ["sich", "ge\u00b7gen", "sechs", "Ha\u00b7sen", "mit", "Ei\u00b7nem", "Speer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "CARD", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "getraute, als einen Reim zu erjagen.", "tokens": ["ge\u00b7trau\u00b7te", ",", "als", "ei\u00b7nen", "Reim", "zu", "er\u00b7ja\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Indes, wer auch sonst nichts vermag", "tokens": ["In\u00b7des", ",", "wer", "auch", "sonst", "nichts", "ver\u00b7mag"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWS", "ADV", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vermag doch W\u00fcnsche am heutgen Tag.", "tokens": ["ver\u00b7mag", "doch", "W\u00fcn\u00b7sche", "am", "heut\u00b7gen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es ist nicht viel, das wei\u00df der Himmel!", "tokens": ["Es", "ist", "nicht", "viel", ",", "das", "wei\u00df", "der", "Him\u00b7mel", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "PDS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Allein, wer mehr hat, gebe mehr!", "tokens": ["Al\u00b7lein", ",", "wer", "mehr", "hat", ",", "ge\u00b7be", "mehr", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "ADV", "VAFIN", "$,", "VVFIN", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Und also empfangen Sie, ", "tokens": ["Und", "al\u00b7so", "emp\u00b7fan\u00b7gen", "Sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "hiemit von mir ", "tokens": ["hie\u00b7mit", "von", "mir"], "token_info": ["word", "word", "word"], "pos": ["PAV", "APPR", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "(wofern's ein Schimmel war) auf dem", "tokens": ["(", "wo\u00b7fern's", "ein", "Schim\u00b7mel", "war", ")", "auf", "dem"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "KOUS", "ART", "NN", "VAFIN", "$(", "APPR", "ART"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "die S\u00f6hne Haymons einst geritten,", "tokens": ["die", "S\u00f6h\u00b7ne", "Hay\u00b7mons", "einst", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "den Hippogryphen, der gar bequem", "tokens": ["den", "Hip\u00b7po\u00b7gry\u00b7phen", ",", "der", "gar", "be\u00b7quem"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "auf Wolken geht, und Astolfen mitten", "tokens": ["auf", "Wol\u00b7ken", "geht", ",", "und", "As\u00b7tol\u00b7fen", "mit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "$,", "KON", "NN", "ADV"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "ins Land des Mannes im Monde trug,", "tokens": ["ins", "Land", "des", "Man\u00b7nes", "im", "Mon\u00b7de", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPRART", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "und nebst der vogelschnellen Alfane", "tokens": ["und", "nebst", "der", "vo\u00b7gel\u00b7schnel\u00b7len", "Al\u00b7fa\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "das gute Schwert, die ", "tokens": ["das", "gu\u00b7te", "Schwert", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "womit auf einen einzgen Zug", "tokens": ["wo\u00b7mit", "auf", "ei\u00b7nen", "einz\u00b7gen", "Zug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Herr Carl, der gro\u00dfe und weise Kaiser", "tokens": ["Herr", "Carl", ",", "der", "gro\u00b7\u00dfe", "und", "wei\u00b7se", "Kai\u00b7ser"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "ART", "ADJA", "KON", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.16": {"text": "Armeen von Heiden nieder schlug;", "tokens": ["Ar\u00b7me\u00b7en", "von", "Hei\u00b7den", "nie\u00b7der", "schlug", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PTKVZ", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "sodann das ", "tokens": ["so\u00b7dann", "das"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "---", "measure": "unknown.measure.zero"}, "line.18": {"text": "zu Boden warf mit seinem Ton;", "tokens": ["zu", "Bo\u00b7den", "warf", "mit", "sei\u00b7nem", "Ton", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "den ", "tokens": ["den"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.20": {"text": "den ", "tokens": ["den"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.21": {"text": "die Sense des frommen Roboaster,", "tokens": ["die", "Sen\u00b7se", "des", "from\u00b7men", "Ro\u00b7boas\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.22": {"text": "und, wenn der Wunsch den jedes B\u00fcrgerherz", "tokens": ["und", ",", "wenn", "der", "Wunsch", "den", "je\u00b7des", "B\u00fcr\u00b7ger\u00b7herz"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "zum Himmel schickt, in diesen Scherz", "tokens": ["zum", "Him\u00b7mel", "schickt", ",", "in", "die\u00b7sen", "Scherz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "sich mischen darf, \u2013 zum Unterpfand", "tokens": ["sich", "mi\u00b7schen", "darf", ",", "\u2013", "zum", "Un\u00b7ter\u00b7pfand"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PRF", "VVINF", "VMFIN", "$,", "$(", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Gemeiner Wohlfahrt diesem Land,", "tokens": ["Ge\u00b7mei\u00b7ner", "Wohl\u00b7fahrt", "die\u00b7sem", "Land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "als Erben von Vater- und Mutter-Tugend", "tokens": ["als", "Er\u00b7ben", "von", "Va\u00b7ter", "und", "Mut\u00b7ter\u00b7Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "TRUNC", "KON", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.27": {"text": "bald einen tapfern ", "tokens": ["bald", "ei\u00b7nen", "tap\u00b7fern"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}}}}}