{"textgrid.poem.48654": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "17. Entsagung", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und soll es nun nicht anders gehen", "tokens": ["Und", "soll", "es", "nun", "nicht", "an\u00b7ders", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ich mu\u00df von ihr gehasset sein?", "tokens": ["ich", "mu\u00df", "von", "ihr", "ge\u00b7has\u00b7set", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So la\u00df die eiteln Sachen stehen,", "tokens": ["So", "la\u00df", "die", "ei\u00b7teln", "Sa\u00b7chen", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mein Sin, und gieb dich nur darein!", "tokens": ["mein", "Sin", ",", "und", "gieb", "dich", "nur", "da\u00b7rein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "VVIMP", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O wol dem, welcher ist vergn\u00fcget,", "tokens": ["O", "wol", "dem", ",", "wel\u00b7cher", "ist", "ver\u00b7gn\u00fc\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "$,", "PWAT", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wie sein Verh\u00e4ngn\u00fc\u00df sich auch f\u00fcget!", "tokens": ["wie", "sein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "sich", "auch", "f\u00fc\u00b7get", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kein be\u00dfrer Rat ist, als ertragen", "tokens": ["Kein", "be\u00df\u00b7rer", "Rat", "ist", ",", "als", "er\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "$,", "KOUS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "di\u00df, was man doch nicht \u00e4ndern kan.", "tokens": ["di\u00df", ",", "was", "man", "doch", "nicht", "\u00e4n\u00b7dern", "kan", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PIS", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein feiger Mut hebt an zu zagen.", "tokens": ["Ein", "fei\u00b7ger", "Mut", "hebt", "an", "zu", "za\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Best\u00e4ndig sein, das tut ein Man,", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "sein", ",", "das", "tut", "ein", "Man", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$,", "PDS", "VVFIN", "ART", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sieht Beides an, gleich in Geberden:", "tokens": ["sieht", "Bei\u00b7des", "an", ",", "gleich", "in", "Ge\u00b7ber\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKVZ", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "erfreuet und betr\u00fcbet werden.", "tokens": ["er\u00b7freu\u00b7et", "und", "be\u00b7tr\u00fc\u00b7bet", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Zwar ofte werd' ich seufzen m\u00fcssen,", "tokens": ["Zwar", "of\u00b7te", "werd'", "ich", "seuf\u00b7zen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wenn ich erw\u00e4ge jene Zeit,", "tokens": ["wenn", "ich", "er\u00b7w\u00e4\u00b7ge", "je\u00b7ne", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da ich den sch\u00f6nen Mund zu k\u00fcssen", "tokens": ["da", "ich", "den", "sch\u00f6\u00b7nen", "Mund", "zu", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mit gutem Fuge war befreit,", "tokens": ["mit", "gu\u00b7tem", "Fu\u00b7ge", "war", "be\u00b7freit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da ich des Lebens s\u00fc\u00dfes Wesen", "tokens": ["da", "ich", "des", "Le\u00b7bens", "s\u00fc\u00b7\u00dfes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "von ihren Lippen durfte lesen.", "tokens": ["von", "ih\u00b7ren", "Lip\u00b7pen", "durf\u00b7te", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was aber? Soll mich etwas kr\u00e4nken,", "tokens": ["Was", "a\u00b7ber", "?", "Soll", "mich", "et\u00b7was", "kr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das nichts ist als ein blo\u00dfer Wahn?", "tokens": ["das", "nichts", "ist", "als", "ein", "blo\u00b7\u00dfer", "Wahn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will vielmehr mich dahin lenken,", "tokens": ["Ich", "will", "viel\u00b7mehr", "mich", "da\u00b7hin", "len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PPER", "PAV", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "wohin mich Dapferkeit weist an", "tokens": ["wo\u00b7hin", "mich", "Dap\u00b7fer\u00b7keit", "weist", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und den verg\u00e4llten S\u00fc\u00dfigkeiten", "tokens": ["und", "den", "ver\u00b7g\u00e4ll\u00b7ten", "S\u00fc\u00b7\u00dfig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "mit gro\u00dfem Herzen widerstreiten.", "tokens": ["mit", "gro\u00b7\u00dfem", "Her\u00b7zen", "wi\u00b7der\u00b7strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Das hab' ich wol gedenken k\u00f6nnen.", "tokens": ["Das", "hab'", "ich", "wol", "ge\u00b7den\u00b7ken", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer klug ist, baut nicht auf den Sand.", "tokens": ["Wer", "klug", "ist", ",", "baut", "nicht", "auf", "den", "Sand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer suchet Trost bei leichten Sinnen,", "tokens": ["Wer", "su\u00b7chet", "Trost", "bei", "leich\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bei Unbest\u00e4ndigkeit Bestand,", "tokens": ["bei", "Un\u00b7be\u00b7st\u00e4n\u00b7dig\u00b7keit", "Be\u00b7stand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "bei Schatten Licht, bei Tode Leben?", "tokens": ["bei", "Schat\u00b7ten", "Licht", ",", "bei", "To\u00b7de", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Kan mir denn Nichts nicht Alles geben?", "tokens": ["Kan", "mir", "denn", "Nichts", "nicht", "Al\u00b7les", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "PTKNEG", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die glatte Gunst der falschen Frauen", "tokens": ["Die", "glat\u00b7te", "Gunst", "der", "fal\u00b7schen", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ist ein zerbr\u00fcchig, schlipfrich Eis,", "tokens": ["ist", "ein", "zer\u00b7br\u00fc\u00b7chig", ",", "schlipf\u00b7rich", "Eis", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJD", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "betreugt den Fu\u00df, der drauf will trauen,", "tokens": ["be\u00b7treugt", "den", "Fu\u00df", ",", "der", "drauf", "will", "trau\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELS", "PAV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "an nichts mehr als an K\u00e4lte hei\u00df,", "tokens": ["an", "nichts", "mehr", "als", "an", "K\u00e4l\u00b7te", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PIS", "KOKOM", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "kan nichts nicht als die Augen blenden", "tokens": ["kan", "nichts", "nicht", "als", "die", "Au\u00b7gen", "blen\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "PTKNEG", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und wird zu Wasser unter H\u00e4nden.", "tokens": ["und", "wird", "zu", "Was\u00b7ser", "un\u00b7ter", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wer ihnen traut, pfl\u00fcgt in die Winde", "tokens": ["Wer", "ih\u00b7nen", "traut", ",", "pfl\u00fcgt", "in", "die", "Win\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und s\u00e4et auf die w\u00fcste See,", "tokens": ["und", "s\u00e4et", "auf", "die", "w\u00fcs\u00b7te", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "mi\u00dft des verborgnen Meeres Gr\u00fcnde,", "tokens": ["mi\u00dft", "des", "ver\u00b7borg\u00b7nen", "Mee\u00b7res", "Gr\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "schreibt sein Ged\u00e4chtn\u00fc\u00df in den Schnee,", "tokens": ["schreibt", "sein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "in", "den", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "sch\u00f6pft, wie die Schwestern ohne Liebe,", "tokens": ["sch\u00f6pft", ",", "wie", "die", "Schwes\u00b7tern", "oh\u00b7ne", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "das Wasser mit durchbohrtem Siebe.", "tokens": ["das", "Was\u00b7ser", "mit", "durch\u00b7bohr\u00b7tem", "Sie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der freie Wind f\u00e4hrt ohne Z\u00fcgel,", "tokens": ["Der", "frei\u00b7e", "Wind", "f\u00e4hrt", "oh\u00b7ne", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ein leichter Pfeil eilt auf Gewin,", "tokens": ["ein", "leich\u00b7ter", "Pfeil", "eilt", "auf", "Ge\u00b7win", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der starke Plitz hat schnelle Fl\u00fcgel,", "tokens": ["der", "star\u00b7ke", "Plitz", "hat", "schnel\u00b7le", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein strenger Fall scheu\u00dft pl\u00f6tzlich hin:", "tokens": ["ein", "stren\u00b7ger", "Fall", "scheu\u00dft", "pl\u00f6tz\u00b7lich", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "f\u00fcr ihren Sinnen sind nicht schnelle", "tokens": ["f\u00fcr", "ih\u00b7ren", "Sin\u00b7nen", "sind", "nicht", "schnel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Luft, Pfeile, Plitz und Wasserf\u00e4lle.", "tokens": ["Luft", ",", "Pfei\u00b7le", ",", "Plitz", "und", "Was\u00b7ser\u00b7f\u00e4l\u00b7le", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wer will dem Panther abewaschen", "tokens": ["Wer", "will", "dem", "Pan\u00b7ther", "a\u00b7be\u00b7wa\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "was man auf seinem R\u00fccken schaut?", "tokens": ["was", "man", "auf", "sei\u00b7nem", "R\u00fc\u00b7cken", "schaut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie weichet keiner Seif' und Aschen,", "tokens": ["Sie", "wei\u00b7chet", "kei\u00b7ner", "Seif'", "und", "A\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "des braunen Mohren schwarze Haut.", "tokens": ["des", "brau\u00b7nen", "Moh\u00b7ren", "schwar\u00b7ze", "Haut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Wankelmut und leichte Zoren", "tokens": ["Der", "Wan\u00b7kel\u00b7mut", "und", "leich\u00b7te", "Zo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ist allen Weibern angeboren.", "tokens": ["ist", "al\u00b7len", "Wei\u00b7bern", "an\u00b7ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Was spielet g\u00fcldner als die Flammen,", "tokens": ["Was", "spie\u00b7let", "g\u00fcld\u00b7ner", "als", "die", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "was brennt auch mehr als eben sie?", "tokens": ["was", "brennt", "auch", "mehr", "als", "e\u00b7ben", "sie", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PIAT", "KOKOM", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Lust ist und Gefahr beisammen,", "tokens": ["Wo", "Lust", "ist", "und", "Ge\u00b7fahr", "bei\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da ist das Gl\u00fcck' ohn' Wandel nie,", "tokens": ["da", "ist", "das", "Gl\u00fcck", "ohn'", "Wan\u00b7del", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schau zu, der du zu k\u00fchne liebest,", "tokens": ["Schau", "zu", ",", "der", "du", "zu", "k\u00fch\u00b7ne", "lie\u00b7best", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "ADJA", "VVFIN", "$,"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "da\u00df du dich freuend nicht betr\u00fcbest!", "tokens": ["da\u00df", "du", "dich", "freu\u00b7end", "nicht", "be\u00b7tr\u00fc\u00b7best", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wer wei\u00df nicht, wie sich Venus stache,", "tokens": ["Wer", "wei\u00df", "nicht", ",", "wie", "sich", "Ve\u00b7nus", "sta\u00b7che", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$,", "PWAV", "PRF", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ihr das Antlitz lief voll Blut,", "tokens": ["da\u00df", "ihr", "das", "Ant\u00b7litz", "lief", "voll", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "als sie Adonis Rosen brache?", "tokens": ["als", "sie", "A\u00b7do\u00b7nis", "Ro\u00b7sen", "bra\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Strauche wuchs daher der Mut.", "tokens": ["Dem", "Strau\u00b7che", "wuchs", "da\u00b7her", "der", "Mut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Farbe hat er angenommen,", "tokens": ["Die", "Far\u00b7be", "hat", "er", "an\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "darvon die Purpur-Rosen kommen.", "tokens": ["dar\u00b7von", "die", "Pur\u00b7pur\u00b7Ro\u00b7sen", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der s\u00fc\u00dfe Saft der gelben Bienen,", "tokens": ["Der", "s\u00fc\u00b7\u00dfe", "Saft", "der", "gel\u00b7ben", "Bie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kupido, der verf\u00fchrte dich;", "tokens": ["Ku\u00b7pi\u00b7do", ",", "der", "ver\u00b7f\u00fchr\u00b7te", "dich", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "VVFIN", "PPER", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "da du dich woltst zu tief erk\u00fchnen,", "tokens": ["da", "du", "dich", "woltst", "zu", "tief", "er\u00b7k\u00fch\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKA", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so kriegst du einen bittern Stich.", "tokens": ["so", "kriegst", "du", "ei\u00b7nen", "bit\u00b7tern", "Stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Di\u00df dein Exempel lehret Alle:", "tokens": ["Di\u00df", "dein", "Ex\u00b7em\u00b7pel", "leh\u00b7ret", "Al\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "VVFIN", "PIS", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "wo Honig ist, da ist auch Galle.", "tokens": ["wo", "Ho\u00b7nig", "ist", ",", "da", "ist", "auch", "Gal\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "$,", "ADV", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Es ist ein Wechsel aller Sachen.", "tokens": ["Es", "ist", "ein", "Wech\u00b7sel", "al\u00b7ler", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Schein kommt Plitz, auf Tag folgt Nacht,", "tokens": ["Auf", "Schein", "kommt", "Plitz", ",", "auf", "Tag", "folgt", "Nacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "NE", "$,", "APPR", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein nasses Leid auf trucknes Lachen,", "tokens": ["ein", "nas\u00b7ses", "Leid", "auf", "truck\u00b7nes", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "auf Wollust das, was Eckel macht.", "tokens": ["auf", "Wol\u00b7lust", "das", ",", "was", "E\u00b7ckel", "macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDS", "$,", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und diese, die dich gestern liebet,", "tokens": ["Und", "die\u00b7se", ",", "die", "dich", "ge\u00b7stern", "lie\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "ists, die dich heute so betr\u00fcbet.", "tokens": ["ists", ",", "die", "dich", "heu\u00b7te", "so", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Nicht, da\u00df ich daher hoffen wolte", "tokens": ["Nicht", ",", "da\u00df", "ich", "da\u00b7her", "hof\u00b7fen", "wol\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "$,", "KOUS", "PPER", "PAV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "(wo Hoffnung bei Verzweiflung ist),", "tokens": ["(", "wo", "Hoff\u00b7nung", "bei", "Ver\u00b7zwei\u00b7flung", "ist", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "NN", "APPR", "NN", "VAFIN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie mich wieder lieben solte.", "tokens": ["da\u00df", "sie", "mich", "wie\u00b7der", "lie\u00b7ben", "sol\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nein! Sie hat einen Sinn erkiest,", "tokens": ["Nein", "!", "Sie", "hat", "ei\u00b7nen", "Sinn", "er\u00b7kiest", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dem fester Stahl nicht zu vergleichen", "tokens": ["dem", "fes\u00b7ter", "Stahl", "nicht", "zu", "ver\u00b7glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und harte Diamanten weichen.", "tokens": ["und", "har\u00b7te", "Di\u00b7a\u00b7man\u00b7ten", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Sie darf sich darum nicht erheben,", "tokens": ["Sie", "darf", "sich", "da\u00b7rum", "nicht", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PAV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df sie mich hat gegeben hin.", "tokens": ["da\u00df", "sie", "mich", "hat", "ge\u00b7ge\u00b7ben", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VVPP", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich kan, Gott Lob! ohn' sie wol leben.", "tokens": ["Ich", "kan", ",", "Gott", "Lob", "!", "ohn'", "sie", "wol", "le\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "NN", "NN", "$.", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer sie ist, wei\u00df ich, da\u00df ich bin.", "tokens": ["Wer", "sie", "ist", ",", "wei\u00df", "ich", ",", "da\u00df", "ich", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was einem einmal wird genommen,", "tokens": ["Was", "ei\u00b7nem", "ein\u00b7mal", "wird", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "um das kan er nicht zweimal kommen.", "tokens": ["um", "das", "kan", "er", "nicht", "zwei\u00b7mal", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDS", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.16": {"line.1": {"text": "Will sie schon itzt von mir nicht wissen, -", "tokens": ["Will", "sie", "schon", "itzt", "von", "mir", "nicht", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "PTKNEG", "VVINF", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "sie hei\u00dft mich weder Freund noch Feind, -", "tokens": ["sie", "hei\u00dft", "mich", "we\u00b7der", "Freund", "noch", "Feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "NN", "ADV", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "noch dennoch wird sie sagen m\u00fcssen,", "tokens": ["noch", "den\u00b7noch", "wird", "sie", "sa\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df ich es habe gut gemeint.", "tokens": ["da\u00df", "ich", "es", "ha\u00b7be", "gut", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.6": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.17": {"line.1": {"text": "Ihr Gift der Zeit, ihr Pest der Jugend,", "tokens": ["Ihr", "Gift", "der", "Zeit", ",", "ihr", "Pest", "der", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "weg Venus, Amor, weg von mir!", "tokens": ["weg", "Ve\u00b7nus", ",", "A\u00b7mor", ",", "weg", "von", "mir", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NE", "$,", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Forthin so dien' ich nur der Tugend.", "tokens": ["For\u00b7thin", "so", "dien'", "ich", "nur", "der", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn ihr verwelkt, bleibt ihre Zier.", "tokens": ["Wenn", "ihr", "ver\u00b7welkt", ",", "bleibt", "ih\u00b7re", "Zier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer sich der Weisheit ganz ergiebet,", "tokens": ["Wer", "sich", "der", "Weis\u00b7heit", "ganz", "er\u00b7gie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "der liebet recht und wird geliebet.", "tokens": ["der", "lie\u00b7bet", "recht", "und", "wird", "ge\u00b7lie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ADJD", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Komm, g\u00fcldne Freiheit, komm, mein Leben,", "tokens": ["Komm", ",", "g\u00fcld\u00b7ne", "Frei\u00b7heit", ",", "komm", ",", "mein", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$,", "VVFIN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und setze mir dein H\u00fctlein auf!", "tokens": ["und", "set\u00b7ze", "mir", "dein", "H\u00fct\u00b7lein", "auf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich habe gute Nacht gegeben", "tokens": ["Ich", "ha\u00b7be", "gu\u00b7te", "Nacht", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der Eitelkeiten schn\u00f6dem Lauf.", "tokens": ["der", "Ei\u00b7tel\u00b7kei\u00b7ten", "schn\u00f6\u00b7dem", "Lauf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sei nun, wie sie will, alleine!", "tokens": ["Sie", "sei", "nun", ",", "wie", "sie", "will", ",", "al\u00b7lei\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PWAV", "PPER", "VMFIN", "$,", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Auch ich bin Niemands mehr als meine.", "tokens": ["Auch", "ich", "bin", "Nie\u00b7mands", "mehr", "als", "mei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "PIAT", "KOKOM", "PPOSAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}