{"dta.poem.2921": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "120.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Unser Ged\u00e4chtni\u00df ist wie eines Wirthes Zimmer,", "tokens": ["Un\u00b7ser", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "ist", "wie", "ei\u00b7nes", "Wirt\u00b7hes", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Das doch, wie weit es sei, beschr\u00e4nkt von Raum ist immer.", "tokens": ["Das", "doch", ",", "wie", "weit", "es", "sei", ",", "be\u00b7schr\u00e4nkt", "von", "Raum", "ist", "im\u00b7mer", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$,", "VVFIN", "APPR", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Von G\u00e4sten gehn darein nicht zuviel auf einmal,", "tokens": ["Von", "G\u00e4s\u00b7ten", "gehn", "da\u00b7rein", "nicht", "zu\u00b7viel", "auf", "ein\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PAV", "PTKNEG", "ADV", "APPR", "ADV", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und von Vorstellungen nur immer eine Zahl.", "tokens": ["Und", "von", "Vor\u00b7stel\u00b7lun\u00b7gen", "nur", "im\u00b7mer", "ei\u00b7ne", "Zahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Doch nach einander gehn der G\u00e4ste viele drein,", "tokens": ["Doch", "nach", "ein\u00b7an\u00b7der", "gehn", "der", "G\u00e4s\u00b7te", "vie\u00b7le", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRF", "VVFIN", "ART", "NN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und alle schreiben auch wol ihre Namen ein.", "tokens": ["Und", "al\u00b7le", "schrei\u00b7ben", "auch", "wol", "ih\u00b7re", "Na\u00b7men", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die in das Fremdenbuch, die auf die Fensterscheiben,", "tokens": ["Die", "in", "das", "Frem\u00b7den\u00b7buch", ",", "die", "auf", "die", "Fens\u00b7ter\u00b7schei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das sind Erinnrungen die von den G\u00e4sten bleiben.", "tokens": ["Das", "sind", "E\u00b7rinn\u00b7run\u00b7gen", "die", "von", "den", "G\u00e4s\u00b7ten", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "ART", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+-++-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Erneun kann sich der Wirth die Z\u00fcge nach Belieben,", "tokens": ["Er\u00b7neun", "kann", "sich", "der", "Wirth", "die", "Z\u00fc\u00b7ge", "nach", "Be\u00b7lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PRF", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn zu-unleserlich nicht einer hat geschrieben.", "tokens": ["Wenn", "zu\u00b7un\u00b7le\u00b7ser\u00b7lich", "nicht", "ei\u00b7ner", "hat", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PTKNEG", "PIS", "VAFIN", "VVPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Doch mancher lief auch durch auf fl\u00fcchtigem Besuch,", "tokens": ["Doch", "man\u00b7cher", "lief", "auch", "durch", "auf", "fl\u00fcch\u00b7ti\u00b7gem", "Be\u00b7such", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der weder an die Wand sich einschrieb noch ins Buch.", "tokens": ["Der", "we\u00b7der", "an", "die", "Wand", "sich", "ein\u00b7schrieb", "noch", "ins", "Buch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "APPR", "ART", "NN", "PRF", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Das ist was du gelernt und schnell vergessen hast,", "tokens": ["Das", "ist", "was", "du", "ge\u00b7lernt", "und", "schnell", "ver\u00b7ges\u00b7sen", "hast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PWS", "PPER", "VVPP", "KON", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht im Ged\u00e4chtni\u00df hat verewigt sich der Gast.", "tokens": ["Nicht", "im", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "hat", "ve\u00b7re\u00b7wigt", "sich", "der", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "VAFIN", "VVPP", "PRF", "ART", "NN", "$."], "meter": "+--+----+--+", "measure": "dactylic.di.plus"}}}}}