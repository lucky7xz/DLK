{"textgrid.poem.60669": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Im Lenz, da linder Wind", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Lenz, da linder Wind", "tokens": ["Im", "Lenz", ",", "da", "lin\u00b7der", "Wind"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die Kr\u00e4uter weckt und schm\u00fcckt", "tokens": ["Die", "Kr\u00e4u\u00b7ter", "weckt", "und", "schm\u00fcckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit gr\u00fcnem und mit buntem Kleide", "tokens": ["Mit", "gr\u00fc\u00b7nem", "und", "mit", "bun\u00b7tem", "Klei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Ziege, Ro\u00df und Rind,", "tokens": ["Und", "Zie\u00b7ge", ",", "Ro\u00df", "und", "Rind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dem engen Stall entr\u00fcckt,", "tokens": ["Dem", "en\u00b7gen", "Stall", "ent\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Nach Nahrung gehn auf frischer Weide,", "tokens": ["Nach", "Nah\u00b7rung", "gehn", "auf", "fri\u00b7scher", "Wei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da sah ein Wolf ein Pferd beim Schmaus.", "tokens": ["Da", "sah", "ein", "Wolf", "ein", "Pferd", "beim", "Schmaus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Malt selbst euch seine Freude aus!", "tokens": ["Malt", "selbst", "euch", "sei\u00b7ne", "Freu\u00b7de", "aus", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Er sagte: \u00bbGute Jagd f\u00fcr den, der es bezwingt.", "tokens": ["Er", "sag\u00b7te", ":", "\u00bb", "Gu\u00b7te", "Jagd", "f\u00fcr", "den", ",", "der", "es", "be\u00b7zwingt", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADJA", "NN", "APPR", "ART", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ach, w\u00e4r es doch ein Schaf! Dann w\u00e4r es unbedingt", "tokens": ["Ach", ",", "w\u00e4r", "es", "doch", "ein", "Schaf", "!", "Dann", "w\u00e4r", "es", "un\u00b7be\u00b7dingt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VAFIN", "PPER", "ADV", "ART", "NN", "$.", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mein n\u00e4chstes Mahl. Doch so mu\u00df ich mich plagen,", "tokens": ["Mein", "n\u00e4chs\u00b7tes", "Mahl", ".", "Doch", "so", "mu\u00df", "ich", "mich", "pla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "KON", "ADV", "VMFIN", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Ob mir's durch List und Hinterlist gelingt,", "tokens": ["Ob", "mir's", "durch", "List", "und", "Hin\u00b7ter\u00b7list", "ge\u00b7lingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Dem gro\u00dfen Tier die Z\u00e4hne ins Genick zu schlagen.\u00ab", "tokens": ["Dem", "gro\u00b7\u00dfen", "Tier", "die", "Z\u00e4h\u00b7ne", "ins", "Ge\u00b7nick", "zu", "schla\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er nahm gewichtige Miene an,", "tokens": ["Er", "nahm", "ge\u00b7wich\u00b7ti\u00b7ge", "Mie\u00b7ne", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Trat als ein Sch\u00fcler des Hippokrates heran", "tokens": ["Trat", "als", "ein", "Sch\u00fc\u00b7ler", "des", "Hip\u00b7po\u00b7kra\u00b7tes", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "ART", "NN", "PTKVZ"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.16": {"text": "Und sprach, er kenne alle die geheimen Kr\u00e4fte", "tokens": ["Und", "sprach", ",", "er", "ken\u00b7ne", "al\u00b7le", "die", "ge\u00b7hei\u00b7men", "Kr\u00e4f\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "PIS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Wiesenkr\u00e4uter, alle S\u00e4fte,", "tokens": ["Der", "Wie\u00b7sen\u00b7kr\u00e4u\u00b7ter", ",", "al\u00b7le", "S\u00e4f\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Und schlage jede Art von Krankheit bald in Bann.", "tokens": ["Und", "schla\u00b7ge", "je\u00b7de", "Art", "von", "Krank\u00b7heit", "bald", "in", "Bann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "APPR", "NN", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Herr Renner m\u00f6ge ihm nur nichts verhehlen;", "tokens": ["Herr", "Ren\u00b7ner", "m\u00f6\u00b7ge", "ihm", "nur", "nichts", "ver\u00b7heh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Da\u00df er hier weide so von Zaum und Z\u00fcgel frei,", "tokens": ["Da\u00df", "er", "hier", "wei\u00b7de", "so", "von", "Zaum", "und", "Z\u00fc\u00b7gel", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Beweise ihm, es m\u00fcsse irgendwas ihm fehlen.", "tokens": ["Be\u00b7wei\u00b7se", "ihm", ",", "es", "m\u00fcs\u00b7se", "ir\u00b7gend\u00b7was", "ihm", "feh\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "VMFIN", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Er m\u00f6ge ihm, dem Wolf, bekennen, was es sei,", "tokens": ["Er", "m\u00f6\u00b7ge", "ihm", ",", "dem", "Wolf", ",", "be\u00b7ken\u00b7nen", ",", "was", "es", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "$,", "ART", "NE", "$,", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Dann gebe er ihm kostenlos die Arzenei.", "tokens": ["Dann", "ge\u00b7be", "er", "ihm", "kos\u00b7ten\u00b7los", "die", "Ar\u00b7ze\u00b7nei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u00bbich habe,\u00ab sprach das Pferdevieh voll List,", "tokens": ["\u00bb", "ich", "ha\u00b7be", ",", "\u00ab", "sprach", "das", "Pfer\u00b7de\u00b7vieh", "voll", "List", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "$(", "VVFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "\u00bbeinen Absze\u00df am Fu\u00df.", "tokens": ["\u00bb", "ei\u00b7nen", "Abs\u00b7ze\u00df", "am", "Fu\u00df", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.26": {"text": "Kannst du mich heilen, nun, so tu's.\u00ab", "tokens": ["Kannst", "du", "mich", "hei\u00b7len", ",", "nun", ",", "so", "tu'", "s.", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "abbreviation", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$,", "ADV", "$,", "ADV", "ADJD", "VVIMP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "\u00bbes gibt kaum einen Teil, der so empfindlich ist,\u00ab", "tokens": ["\u00bb", "es", "gibt", "kaum", "ei\u00b7nen", "Teil", ",", "der", "so", "emp\u00b7find\u00b7lich", "ist", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Entgegnete der Arzt, \u00bbindes ich diene gern", "tokens": ["Ent\u00b7geg\u00b7ne\u00b7te", "der", "Arzt", ",", "\u00bb", "in\u00b7des", "ich", "die\u00b7ne", "gern"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "$(", "ADV", "PPER", "PDS", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Auch als Chirurg dem Herrn.\u00ab", "tokens": ["Auch", "als", "Chi\u00b7rurg", "dem", "Herrn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "KOUS", "NN", "ART", "NN", "$.", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.30": {"text": "Der Bursche glaubte schon, gekommen sei die Frist,", "tokens": ["Der", "Bur\u00b7sche", "glaub\u00b7te", "schon", ",", "ge\u00b7kom\u00b7men", "sei", "die", "Frist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Da er den Kranken packen k\u00f6nne hinterr\u00fccks;", "tokens": ["Da", "er", "den", "Kran\u00b7ken", "pa\u00b7cken", "k\u00f6n\u00b7ne", "hin\u00b7ter\u00b7r\u00fccks", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "VMFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Jedoch der ahnungsvolle Gaul", "tokens": ["Je\u00b7doch", "der", "ah\u00b7nungs\u00b7vol\u00b7le", "Gaul"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Versetzt der Bestie einen Hufschlag augenblicks,", "tokens": ["Ver\u00b7setzt", "der", "Be\u00b7stie", "ei\u00b7nen", "Huf\u00b7schlag", "au\u00b7gen\u00b7blicks", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.34": {"text": "Der Marmelade macht aus ihrem M\u00f6rdermaul.", "tokens": ["Der", "Mar\u00b7me\u00b7la\u00b7de", "macht", "aus", "ih\u00b7rem", "M\u00f6r\u00b7der\u00b7maul", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "\u00bbso geht es,\u00ab heulte da der Wolf mit Schmerzgef\u00fchlen,", "tokens": ["\u00bb", "so", "geht", "es", ",", "\u00ab", "heul\u00b7te", "da", "der", "Wolf", "mit", "Schmerz\u00b7ge\u00b7f\u00fch\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "$(", "VVFIN", "ADV", "ART", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "\u00bbder Schuster soll bei seinem Leisten bleiben.", "tokens": ["\u00bb", "der", "Schus\u00b7ter", "soll", "bei", "sei\u00b7nem", "Leis\u00b7ten", "blei\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich wollte hier den Medizinmann spielen", "tokens": ["Ich", "woll\u00b7te", "hier", "den", "Me\u00b7di\u00b7zin\u00b7mann", "spie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und kann doch nichts als nur das Schl\u00e4chterhandwerk treiben.\u00ab", "tokens": ["Und", "kann", "doch", "nichts", "als", "nur", "das", "Schl\u00e4ch\u00b7ter\u00b7hand\u00b7werk", "trei\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "ADV", "PIS", "KOKOM", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}