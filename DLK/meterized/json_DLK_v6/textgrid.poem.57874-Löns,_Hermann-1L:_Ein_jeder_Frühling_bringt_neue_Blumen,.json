{"textgrid.poem.57874": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein jeder Fr\u00fchling bringt neue Blumen,", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein jeder Fr\u00fchling bringt neue Blumen,", "tokens": ["Ein", "je\u00b7der", "Fr\u00fch\u00b7ling", "bringt", "neu\u00b7e", "Blu\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auch dieser zeigt sich der Ahnen wert,", "tokens": ["Auch", "die\u00b7ser", "zeigt", "sich", "der", "Ah\u00b7nen", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Indem er uns als Angebinde", "tokens": ["In\u00b7dem", "er", "uns", "als", "An\u00b7ge\u00b7bin\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "KOUS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Eine Fahrradsteuer-Erw\u00e4gung beschert.", "tokens": ["Ei\u00b7ne", "Fahr\u00b7rad\u00b7steu\u00b7er\u00b7Er\u00b7w\u00e4\u00b7gung", "be\u00b7schert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Wer auf dem Rover oder Hochrad", "tokens": ["Wer", "auf", "dem", "Ro\u00b7ver", "o\u00b7der", "Hoch\u00b7rad"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Oder auf beh\u00e4bigem Dreirad nur", "tokens": ["O\u00b7der", "auf", "be\u00b7h\u00e4\u00b7bi\u00b7gem", "Drei\u00b7rad", "nur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "ADV"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Die Welt durchf\u00e4hrt, mu\u00df daf\u00fcr blechen", "tokens": ["Die", "Welt", "durch\u00b7f\u00e4hrt", ",", "mu\u00df", "da\u00b7f\u00fcr", "ble\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "VMFIN", "PAV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Goldst\u00fcck f\u00fcr Luxus und \u00dcberkultur.", "tokens": ["Ein", "Gold\u00b7st\u00fcck", "f\u00fcr", "Lu\u00b7xus", "und", "\u00dc\u00b7ber\u00b7kul\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.3": {"line.1": {"text": "Ich hoffe, die st\u00e4dtischen Kollegien,", "tokens": ["Ich", "hof\u00b7fe", ",", "die", "st\u00e4d\u00b7ti\u00b7schen", "Kol\u00b7le\u00b7gi\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die nehmen den Vorschlag mit Freuden an", "tokens": ["Die", "neh\u00b7men", "den", "Vor\u00b7schlag", "mit", "Freu\u00b7den", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "NN", "PTKVZ"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und gehen noch weiter, als Steuerobjekte", "tokens": ["Und", "ge\u00b7hen", "noch", "wei\u00b7ter", ",", "als", "Steu\u00b7er\u00b7ob\u00b7jek\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$,", "KOUS", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ich ferner ihnen empfehlen kann:", "tokens": ["Ich", "fer\u00b7ner", "ih\u00b7nen", "emp\u00b7feh\u00b7len", "kann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Die Kinderwagen, die Krankenfahrst\u00fchle", "tokens": ["Die", "Kin\u00b7der\u00b7wa\u00b7gen", ",", "die", "Kran\u00b7ken\u00b7fahr\u00b7st\u00fch\u00b7le"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Handkarren; doch zu verschonen sind", "tokens": ["Und", "Hand\u00b7kar\u00b7ren", ";", "doch", "zu", "ver\u00b7scho\u00b7nen", "sind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "$.", "ADV", "PTKZU", "VVINF", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Equipagen, das ist kein Luxus,", "tokens": ["Die", "E\u00b7qui\u00b7pa\u00b7gen", ",", "das", "ist", "kein", "Lu\u00b7xus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer das nicht einsieht, ist taub und blind.", "tokens": ["Wer", "das", "nicht", "ein\u00b7sieht", ",", "ist", "taub", "und", "blind", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "PTKNEG", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}