{"textgrid.poem.46840": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[was geschehn, ist nicht zu \u00e4ndern]", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was geschehn, ist nicht zu \u00e4ndern,", "tokens": ["Was", "ge\u00b7schehn", ",", "ist", "nicht", "zu", "\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "$,", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit verweinten Augenr\u00e4ndern.", "tokens": ["Mit", "ver\u00b7wein\u00b7ten", "Au\u00b7gen\u00b7r\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Nicht zu \u00e4ndern sind die Sachen,", "tokens": ["Nicht", "zu", "\u00e4n\u00b7dern", "sind", "die", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVINF", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch auch, wie sie sind, zu lassen,", "tokens": ["Noch", "auch", ",", "wie", "sie", "sind", ",", "zu", "las\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern so zurecht zu machen,", "tokens": ["Son\u00b7dern", "so", "zu\u00b7recht", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie uns, wir ihnen, passen;", "tokens": ["Da\u00df", "sie", "uns", ",", "wir", "ih\u00b7nen", ",", "pas\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "$,", "PPER", "PPER", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also la\u00df den Punkt uns fassen", "tokens": ["Al\u00b7so", "la\u00df", "den", "Punkt", "uns", "fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "ART", "NN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Von den uns geraubten Pf\u00e4ndern!", "tokens": ["Von", "den", "uns", "ge\u00b7raub\u00b7ten", "Pf\u00e4n\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Was geschehn, ist nicht zu \u00e4ndern.", "tokens": ["Was", "ge\u00b7schehn", ",", "ist", "nicht", "zu", "\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "$,", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Fehlt dein einz'ges M\u00e4dchen dir,", "tokens": ["Fehlt", "dein", "einz'\u00b7ges", "M\u00e4d\u00b7chen", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir dein j\u00fcngster liebster Sohn;", "tokens": ["Mir", "dein", "j\u00fcngs\u00b7ter", "liebs\u00b7ter", "Sohn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denke, da\u00df wie viele wir", "tokens": ["Den\u00b7ke", ",", "da\u00df", "wie", "vie\u00b7le", "wir"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "PWAV", "PIS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eben uns entschlossen schon,", "tokens": ["E\u00b7ben", "uns", "ent\u00b7schlos\u00b7sen", "schon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie in gute Pension", "tokens": ["Sie", "in", "gu\u00b7te", "Pen\u00b7si\u00b7on"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Einzuthun in fernen L\u00e4ndern.", "tokens": ["Ein\u00b7zu\u00b7thun", "in", "fer\u00b7nen", "L\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was geschehn, ist nicht zu \u00e4ndern.", "tokens": ["Was", "ge\u00b7schehn", ",", "ist", "nicht", "zu", "\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "$,", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Besser wird man dort sie ziehn,", "tokens": ["Bes\u00b7ser", "wird", "man", "dort", "sie", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PIS", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als sie w\u00fcrden hier erzogen;", "tokens": ["Als", "sie", "w\u00fcr\u00b7den", "hier", "er\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und als wir sie lie\u00dfen ziehn,", "tokens": ["Und", "als", "wir", "sie", "lie\u00b7\u00dfen", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVFIN", "VVINF", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Blieb uns manches unentzogen,", "tokens": ["Blieb", "uns", "man\u00b7ches", "un\u00b7ent\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was sie haben ausgezogen", "tokens": ["Was", "sie", "ha\u00b7ben", "aus\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PPER", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hier von farbigen Gew\u00e4ndern,", "tokens": ["Hier", "von", "far\u00b7bi\u00b7gen", "Ge\u00b7w\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Nichts soll deren Farben \u00e4ndern!", "tokens": ["Nichts", "soll", "de\u00b7ren", "Far\u00b7ben", "\u00e4n\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRELAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "La\u00df das Angedenken prangen", "tokens": ["La\u00df", "das", "An\u00b7ge\u00b7den\u00b7ken", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deiner Kinder, fleckenrein,", "tokens": ["Dei\u00b7ner", "Kin\u00b7der", ",", "fle\u00b7cken\u00b7rein", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df es in den Schr\u00e4nken hangen,", "tokens": ["La\u00df", "es", "in", "den", "Schr\u00e4n\u00b7ken", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liegen in des Herzens Schrein!", "tokens": ["Lie\u00b7gen", "in", "des", "Her\u00b7zens", "Schrein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wird es je erbleichen? Nein!", "tokens": ["Wird", "es", "je", "er\u00b7blei\u00b7chen", "?", "Nein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$.", "PTKANT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und sie selbst, gleich ihren B\u00e4ndern,", "tokens": ["Und", "sie", "selbst", ",", "gleich", "ih\u00b7ren", "B\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Werden auch den Glanz nicht \u00e4ndern.", "tokens": ["Wer\u00b7den", "auch", "den", "Glanz", "nicht", "\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Gr\u00fc\u00dfe kannst du ihnen senden", "tokens": ["Gr\u00fc\u00b7\u00dfe", "kannst", "du", "ih\u00b7nen", "sen\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jeden Tag ins ferne Land;", "tokens": ["Je\u00b7den", "Tag", "ins", "fer\u00b7ne", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gru\u00df auch werden sie dir spenden,", "tokens": ["Gru\u00df", "auch", "wer\u00b7den", "sie", "dir", "spen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Frisches Blatt von ihrer Hand,", "tokens": ["Fri\u00b7sches", "Blatt", "von", "ih\u00b7rer", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aufzufrischen altes Band,", "tokens": ["Auf\u00b7zu\u00b7fri\u00b7schen", "al\u00b7tes", "Band", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn sich dessen Farben \u00e4ndern", "tokens": ["Wenn", "sich", "des\u00b7sen", "Far\u00b7ben", "\u00e4n\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PDS", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Von verweinten Augenr\u00e4ndern.", "tokens": ["Von", "ver\u00b7wein\u00b7ten", "Au\u00b7gen\u00b7r\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}