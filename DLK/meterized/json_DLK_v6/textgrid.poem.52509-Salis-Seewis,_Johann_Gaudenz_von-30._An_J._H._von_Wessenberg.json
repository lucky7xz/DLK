{"textgrid.poem.52509": {"metadata": {"author": {"name": "Salis-Seewis, Johann Gaudenz von", "birth": "N.A.", "death": "N.A."}, "title": "30. An J. H. von Wessenberg", "genre": "verse", "period": "N.A.", "pub_year": 1798, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sei unser Fenelon, so weise, mild und gut!", "tokens": ["Sei", "un\u00b7ser", "Fe\u00b7ne\u00b7lon", ",", "so", "wei\u00b7se", ",", "mild", "und", "gut", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer sich im Meinungskampf der Wahrheit treu bew\u00e4hrte,", "tokens": ["Wer", "sich", "im", "Mei\u00b7nungs\u00b7kampf", "der", "Wahr\u00b7heit", "treu", "be\u00b7w\u00e4hr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPRART", "NN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer sich durch hellen Geist und edle Thaten ehrte,", "tokens": ["Wer", "sich", "durch", "hel\u00b7len", "Geist", "und", "ed\u00b7le", "Tha\u00b7ten", "ehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat bl\u00f6den Unbill zu ertragen Kraft und Mut.", "tokens": ["Hat", "bl\u00f6\u00b7den", "Un\u00b7bill", "zu", "er\u00b7tra\u00b7gen", "Kraft", "und", "Mut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "PTKZU", "VVINF", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ihm ward ein Name, der im Schutz der Nachwelt ruht.", "tokens": ["Ihm", "ward", "ein", "Na\u00b7me", ",", "der", "im", "Schutz", "der", "Nach\u00b7welt", "ruht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mi\u00dfkenne seinen Wert, wer sich vom Lichte kehrte.", "tokens": ["Mi\u00df\u00b7ken\u00b7ne", "sei\u00b7nen", "Wert", ",", "wer", "sich", "vom", "Lich\u00b7te", "kehr\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PWS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es steigt, wenn Zuggew\u00f6lk im Westen sich verkl\u00e4rte,", "tokens": ["Es", "steigt", ",", "wenn", "Zug\u00b7ge\u00b7w\u00f6lk", "im", "Wes\u00b7ten", "sich", "ver\u00b7kl\u00e4r\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "NN", "APPRART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur heller Hesperus aus sturmbewegter Flut.", "tokens": ["Nur", "hel\u00b7ler", "Hes\u00b7pe\u00b7rus", "aus", "sturm\u00b7be\u00b7weg\u00b7ter", "Flut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "O leuchte ferner vor im Guten und im Sch\u00f6nen!", "tokens": ["O", "leuch\u00b7te", "fer\u00b7ner", "vor", "im", "Gu\u00b7ten", "und", "im", "Sch\u00f6\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lehr Eifrer Christussinn, und Priester duldsam sein.", "tokens": ["Lehr", "Eif\u00b7rer", "Chris\u00b7tus\u00b7sinn", ",", "und", "Pries\u00b7ter", "duld\u00b7sam", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "NN", "$,", "KON", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dring mit der Wahrheit Licht bis zu den F\u00fcrsten S\u00f6hnen,", "tokens": ["Dring", "mit", "der", "Wahr\u00b7heit", "Licht", "bis", "zu", "den", "F\u00fcrs\u00b7ten", "S\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN", "APPR", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Und weih des Volkes Herz zur reinsten Liebe ein!", "tokens": ["Und", "weih", "des", "Vol\u00b7kes", "Herz", "zur", "reins\u00b7ten", "Lie\u00b7be", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dann la\u00df uns \u00f6fter noch die frommen Laute t\u00f6nen,", "tokens": ["Dann", "la\u00df", "uns", "\u00f6f\u00b7ter", "noch", "die", "from\u00b7men", "Lau\u00b7te", "t\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der bessern Menschheit zum harmonischen Verein!", "tokens": ["Der", "bes\u00b7sern", "Menschheit", "zum", "har\u00b7mo\u00b7ni\u00b7schen", "Ver\u00b7ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}