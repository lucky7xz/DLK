{"textgrid.poem.53084": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Alexander Buhlbeck und Elisabeth Gro\u00df", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lachen jetzt der Sonnen Wangen", "tokens": ["La\u00b7chen", "jetzt", "der", "Son\u00b7nen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die Lufft vns freundlich zu,", "tokens": ["Durch", "die", "Lufft", "vns", "freund\u00b7lich", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liegt des Westes Sturm gefangen,", "tokens": ["Liegt", "des", "Wes\u00b7tes", "Sturm", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist die stoltze See in Ruh,", "tokens": ["Ist", "die", "stolt\u00b7ze", "See", "in", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeigen sich die Felder g\u00fctig,", "tokens": ["Zei\u00b7gen", "sich", "die", "Fel\u00b7der", "g\u00fc\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stehn die Saaten \u00fcberm\u00fctig,", "tokens": ["Stehn", "die", "Saa\u00b7ten", "\u00fc\u00b7berm\u00b7\u00fc\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Dencket, ob es lang auch hin,", "tokens": ["Den\u00b7cket", ",", "ob", "es", "lang", "auch", "hin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADJD", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df die Zier der Lufft vnd Erden", "tokens": ["Da\u00df", "die", "Zier", "der", "Lufft", "vnd", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Soll nur Leid vnd Grawen werden", "tokens": ["Soll", "nur", "Leid", "vnd", "Gra\u00b7wen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "NN", "KON", "NN", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Durch des Herbstes Eigen-Sinn.", "tokens": ["Durch", "des", "Herbs\u00b7tes", "Ei\u00b7gen\u00b7Sinn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Warumb sol man nun verseumen,", "tokens": ["Wa\u00b7rumb", "sol", "man", "nun", "ver\u00b7seu\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was die liebe Zeit vns g\u00f6nnt?", "tokens": ["Was", "die", "lie\u00b7be", "Zeit", "vns", "g\u00f6nnt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Trollt euch, die jhr nichts als tr\u00e4umen,", "tokens": ["Trollt", "euch", ",", "die", "jhr", "nichts", "als", "tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PPER", "PIS", "KOKOM", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nichts als sawer sehen k\u00f6nnt:", "tokens": ["Nichts", "als", "sa\u00b7wer", "se\u00b7hen", "k\u00f6nnt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ADJD", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df vns wo in einem Garten", "tokens": ["La\u00df", "vns", "wo", "in", "ei\u00b7nem", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PWAV", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Vnsers frischen Leibes warten,", "tokens": ["Vn\u00b7sers", "fri\u00b7schen", "Lei\u00b7bes", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder vmb der B\u00e4che Randt", "tokens": ["O\u00b7der", "vmb", "der", "B\u00e4\u00b7che", "Randt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "In ein weiches Gra\u00df vns strecken,", "tokens": ["In", "ein", "wei\u00b7ches", "Gra\u00df", "vns", "stre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Wo die Rosen vns bedecken", "tokens": ["Wo", "die", "Ro\u00b7sen", "vns", "be\u00b7de\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "F\u00fcr der heissen Sonnen Brandt.", "tokens": ["F\u00fcr", "der", "heis\u00b7sen", "Son\u00b7nen", "Brandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Jungen, gebt das Flaschenfutter!", "tokens": ["Jun\u00b7gen", ",", "gebt", "das", "Fla\u00b7schen\u00b7fut\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ey nicht dieses, dort den Wein!", "tokens": ["Ey", "nicht", "die\u00b7ses", ",", "dort", "den", "Wein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PDAT", "$,", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sagt bey leibe nicht der Mutter,", "tokens": ["Sagt", "bey", "lei\u00b7be", "nicht", "der", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df wir jetzund fr\u00f6lich seyn:", "tokens": ["Da\u00df", "wir", "je\u00b7tzund", "fr\u00f6\u00b7lich", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weht, jhr Winde, weht vnd k\u00fchlet!", "tokens": ["Weht", ",", "jhr", "Win\u00b7de", ",", "weht", "vnd", "k\u00fch\u00b7let", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihr schertzhaffte Quellen, spielet,", "tokens": ["Ihr", "schertz\u00b7haff\u00b7te", "Quel\u00b7len", ",", "spie\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Klunckert hin auff ewren Zweck,", "tokens": ["Klun\u00b7ckert", "hin", "auff", "ew\u00b7ren", "Zweck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Keine r\u00fcckfahrt k\u00f6nnt jhr halten,", "tokens": ["Kei\u00b7ne", "r\u00fcck\u00b7fahrt", "k\u00f6nnt", "jhr", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Wenn auch wir einmahl erkalten,", "tokens": ["Wenn", "auch", "wir", "ein\u00b7mahl", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Sind vnd bleiben wir schon weg.", "tokens": ["Sind", "vnd", "blei\u00b7ben", "wir", "schon", "weg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Komm, Du meiner Seelen Leben,", "tokens": ["Komm", ",", "Du", "mei\u00b7ner", "See\u00b7len", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du mein Trost, den Gott mir schenckt!", "tokens": ["Du", "mein", "Trost", ",", "den", "Gott", "mir", "schenckt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Komm, Du kanst vollauff mir geben", "tokens": ["Komm", ",", "Du", "kanst", "vol\u00b7lauff", "mir", "ge\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VMFIN", "APPR", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles was mein Hertz gedenckt,", "tokens": ["Al\u00b7les", "was", "mein", "Hertz", "ge\u00b7denckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil wir ja denn mit den Jahren", "tokens": ["Weil", "wir", "ja", "denn", "mit", "den", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zu dem Tode m\u00fcssen fahren,", "tokens": ["Zu", "dem", "To\u00b7de", "m\u00fcs\u00b7sen", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "La\u00df es jmmer hin geschehn,", "tokens": ["La\u00df", "es", "jm\u00b7mer", "hin", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wenn wir vns vnd vnsern Nahmen", "tokens": ["Wenn", "wir", "vns", "vnd", "vn\u00b7sern", "Nah\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "In gew\u00fcndschtem Heyraths-Samen", "tokens": ["In", "ge\u00b7w\u00fcnd\u00b7schtem", "Hey\u00b7raths\u00b7Sa\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Nur zuvor erstattet sehn.", "tokens": ["Nur", "zu\u00b7vor", "er\u00b7stat\u00b7tet", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}