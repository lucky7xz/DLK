{"dta.poem.23824": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Lob des Tobacks.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Sonn und Licht hat sich verkrochen/", "tokens": ["Sonn", "und", "Licht", "hat", "sich", "ver\u00b7kro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PRF", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Nacht ist angebrochen/", "tokens": ["Und", "die", "Nacht", "ist", "an\u00b7ge\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Soll ich nun des Tages-Last/", "tokens": ["Soll", "ich", "nun", "des", "Ta\u00b7ges\u00b7Last", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine Sorgen und mein Gr\u00e4men/", "tokens": ["Mei\u00b7ne", "Sor\u00b7gen", "und", "mein", "Gr\u00e4\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auff das Lager mit mir nehmen?", "tokens": ["Auff", "das", "La\u00b7ger", "mit", "mir", "neh\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nein/ ich wil um meine Rast", "tokens": ["Nein", "/", "ich", "wil", "um", "mei\u00b7ne", "Rast"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "PPER", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Zu befordern/ erst die Pfeiffen", "tokens": ["Zu", "be\u00b7for\u00b7dern", "/", "erst", "die", "Pfeif\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Mit Toback gestopfft ergreiffen.", "tokens": ["Mit", "To\u00b7back", "ge\u00b7stopfft", "er\u00b7greif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Unter allen seltnen Wahren/", "tokens": ["Un\u00b7ter", "al\u00b7len", "selt\u00b7nen", "Wah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die man uns in vielen Jahren", "tokens": ["Die", "man", "uns", "in", "vie\u00b7len", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "PRF", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat aus Indien gebracht/", "tokens": ["Hat", "aus", "In\u00b7di\u00b7en", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NE", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Wird bey Jungen und bey Alten", "tokens": ["Wird", "bey", "Jun\u00b7gen", "und", "bey", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieses Kraut den Prei\u00df behalten/", "tokens": ["Die\u00b7ses", "Kraut", "den", "Prei\u00df", "be\u00b7hal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil es frohe Geister macht;", "tokens": ["Weil", "es", "fro\u00b7he", "Geis\u00b7ter", "macht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ja bi\u00df sich die Welt wird trennen/", "tokens": ["Ja", "bi\u00df", "sich", "die", "Welt", "wird", "tren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KON", "PRF", "ART", "NN", "VAFIN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Wird sein stetes Opffer brennen.", "tokens": ["Wird", "sein", "ste\u00b7tes", "Opf\u00b7fer", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Andrer Tand der Specereyen", "tokens": ["A\u00b7ndrer", "Tand", "der", "Spe\u00b7ce\u00b7re\u00b7yen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN"], "meter": "+-+----+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Kan dem Leibe nicht gedeyen/", "tokens": ["Kan", "dem", "Lei\u00b7be", "nicht", "ge\u00b7de\u00b7yen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und was ist f\u00fcr Angst und Noht/", "tokens": ["Und", "was", "ist", "f\u00fcr", "Angst", "und", "Noht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was f\u00fcr Kriegen und f\u00fcr Morden", "tokens": ["Was", "f\u00fcr", "Krie\u00b7gen", "und", "f\u00fcr", "Mor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nach der Zeit versp\u00fcret worden/", "tokens": ["Nach", "der", "Zeit", "ver\u00b7sp\u00fc\u00b7ret", "wor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da des Goldes theurer Koth", "tokens": ["Da", "des", "Gol\u00b7des", "theu\u00b7rer", "Koth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Selbst in ihren eignen Haafen/", "tokens": ["Selbst", "in", "ih\u00b7ren", "eig\u00b7nen", "Haa\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Macht die K\u00f6nige zu Sclaven?", "tokens": ["Macht", "die", "K\u00f6\u00b7ni\u00b7ge", "zu", "Scla\u00b7ven", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Des Tobacks-Kraut g\u00fcldne Bl\u00e4tter", "tokens": ["Des", "To\u00b7backs\u00b7Kraut", "g\u00fcld\u00b7ne", "Bl\u00e4t\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sind bey manchem Ungl\u00fccks-Wetter", "tokens": ["Sind", "bey", "man\u00b7chem", "Un\u00b7gl\u00fccks\u00b7Wet\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein beliebter Gegen-Gifft/", "tokens": ["Ein", "be\u00b7lieb\u00b7ter", "Ge\u00b7gen\u00b7Gifft", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wider Pest und Leibes-Wunden/", "tokens": ["Wi\u00b7der", "Pest", "und", "Lei\u00b7bes\u00b7Wun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind sie schon bewerth gefunden/", "tokens": ["Sind", "sie", "schon", "be\u00b7werth", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und wenn uns ein Kummer trifft/", "tokens": ["Und", "wenn", "uns", "ein", "Kum\u00b7mer", "trifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "K\u00f6nnen wir durch sanfftes Hauchen/", "tokens": ["K\u00f6n\u00b7nen", "wir", "durch", "sanff\u00b7tes", "Hau\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Sie zu unserm Labsal brauchen.", "tokens": ["Sie", "zu", "un\u00b7serm", "Lab\u00b7sal", "brau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Da\u00df die Lust und Pracht der Erden/", "tokens": ["Da\u00df", "die", "Lust", "und", "Pracht", "der", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und ich selbst zu nichts mu\u00df werden/", "tokens": ["Und", "ich", "selbst", "zu", "nichts", "mu\u00df", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PTKA", "PIS", "VMFIN", "VAINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat mich der Toback gelehrt/", "tokens": ["Hat", "mich", "der", "To\u00b7back", "ge\u00b7lehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Wenn sein zarter Dampff sich zeiget/", "tokens": ["Wenn", "sein", "zar\u00b7ter", "Dampff", "sich", "zei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PRF", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der hoch in die L\u00fcffte steiget/", "tokens": ["Der", "hoch", "in", "die", "L\u00fcff\u00b7te", "stei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und sich bald in nichts verkehrt;", "tokens": ["Und", "sich", "bald", "in", "nichts", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "APPR", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df nun solch ein Kraut entsprossen/", "tokens": ["Da\u00df", "nun", "solch", "ein", "Kraut", "ent\u00b7spros\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Hat dem Satan sehr verdrossen.", "tokens": ["Hat", "dem", "Sa\u00b7tan", "sehr", "ver\u00b7dros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Er kan ohne dem nicht leiden/", "tokens": ["Er", "kan", "oh\u00b7ne", "dem", "nicht", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PRELS", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn ein Mensch in stillen Freuden", "tokens": ["Wenn", "ein", "Mensch", "in", "stil\u00b7len", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In ihm selbst vergn\u00fcget ist.", "tokens": ["In", "ihm", "selbst", "ver\u00b7gn\u00fc\u00b7get", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Drum des Vaters eitler Grillen", "tokens": ["Drum", "des", "Va\u00b7ters", "eit\u00b7ler", "Gril\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seinen Wunsch nicht zu erf\u00fcllen/", "tokens": ["Sei\u00b7nen", "Wunsch", "nicht", "zu", "er\u00b7f\u00fcl\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schmauch ich als ein frommer Christ.", "tokens": ["Schmauch", "ich", "als", "ein", "from\u00b7mer", "Christ", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Er und alle Welt mag toben/", "tokens": ["Er", "und", "al\u00b7le", "Welt", "mag", "to\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PIAT", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ich wil den Toback doch loben.", "tokens": ["Ich", "wil", "den", "To\u00b7back", "doch", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}