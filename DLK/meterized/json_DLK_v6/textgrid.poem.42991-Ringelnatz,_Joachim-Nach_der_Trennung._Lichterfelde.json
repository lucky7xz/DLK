{"textgrid.poem.42991": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Nach der Trennung. Lichterfelde", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "War so oft schon dieses Scheiden.", "tokens": ["War", "so", "oft", "schon", "die\u00b7ses", "Schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bblebewohl!\u00ab (Auf nur vier Wochen)", "tokens": ["\u00bb", "le\u00b7be\u00b7wohl", "!", "\u00ab", "(", "Auf", "nur", "vier", "Wo\u00b7chen", ")"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "$(", "$(", "APPR", "ADV", "CARD", "NN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Schon gemeinsam schwer gesprochen, \u2013", "tokens": ["Schon", "ge\u00b7mein\u00b7sam", "schwer", "ge\u00b7spro\u00b7chen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "ADJD", "VVPP", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwerer jedem dann von beiden.", "tokens": ["Schwe\u00b7rer", "je\u00b7dem", "dann", "von", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADV", "APPR", "PIAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Jedes l\u00e4chelte und lachte", "tokens": ["Je\u00b7des", "l\u00e4\u00b7chel\u00b7te", "und", "lach\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00dcber das, was \u00dcblich sprach.", "tokens": ["\u00dc\u00b7ber", "das", ",", "was", "\u00dcb\u00b7lich", "sprach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jedes wu\u00dfte das und dachte", "tokens": ["Je\u00b7des", "wu\u00df\u00b7te", "das", "und", "dach\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hinterher ganz anders, lange nach.", "tokens": ["Hin\u00b7ter\u00b7her", "ganz", "an\u00b7ders", ",", "lan\u00b7ge", "nach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$,", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Dies Berlin ist grausig tief und flach", "tokens": ["Dies", "Ber\u00b7lin", "ist", "grau\u00b7sig", "tief", "und", "flach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "NE", "VAFIN", "ADJD", "ADJD", "KON", "VVFIN"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und so breit. Es gibt daf\u00fcr kein Dach.", "tokens": ["Und", "so", "breit", ".", "Es", "gibt", "da\u00b7f\u00fcr", "kein", "Dach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$.", "PPER", "VVFIN", "PAV", "PIAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Schaurig schon, da\u00df Menschen dort verschwinden.", "tokens": ["Schau\u00b7rig", "schon", ",", "da\u00df", "Men\u00b7schen", "dort", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Aber stelle arme Fraun dir vor, die dort", "tokens": ["A\u00b7ber", "stel\u00b7le", "ar\u00b7me", "Fraun", "dir", "vor", ",", "die", "dort"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJA", "ADJA", "NN", "PPER", "PTKVZ", "$,", "PRELS", "ADV"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Schamvoll irrend einen \u00f6ffentlichen Abort", "tokens": ["Scham\u00b7voll", "ir\u00b7rend", "ei\u00b7nen", "\u00f6f\u00b7fent\u00b7li\u00b7chen", "Ab\u00b7ort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVPP", "ART", "ADJA", "NN"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Suchen und nicht finden.", "tokens": ["Su\u00b7chen", "und", "nicht", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Lichterfelde. Blieb mein D-Zug stehn.", "tokens": ["Lich\u00b7ter\u00b7fel\u00b7de", ".", "Blieb", "mein", "D\u00b7\u00b7Zug", "stehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und ich sah im Schnellzug vis-\u00e0-vis", "tokens": ["Und", "ich", "sah", "im", "Schnell\u00b7zug", "vis\u00b7\u00e0\u00b7vis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ein so blasses sch\u00f6nes Eisenbahnergesicht,", "tokens": ["Ein", "so", "blas\u00b7ses", "sch\u00f6\u00b7nes", "Ei\u00b7sen\u00b7bah\u00b7ner\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.4": {"text": "Wie ich fremdfern nie", "tokens": ["Wie", "ich", "fremd\u00b7fern", "nie"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Ein Gesicht so innig hab gesehn.", "tokens": ["Ein", "Ge\u00b7sicht", "so", "in\u00b7nig", "hab", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Du, du meine Frau, wirst mich verstehn.", "tokens": ["Du", ",", "du", "mei\u00b7ne", "Frau", ",", "wirst", "mich", "ver\u00b7stehn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "PPOSAT", "NN", "$,", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}