{"textgrid.poem.66497": {"metadata": {"author": {"name": "Roquette, Otto", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zu Darmstadt in der Ochsenga\u00df'", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Darmstadt in der Ochsenga\u00df'", "tokens": ["Zu", "Darm\u00b7stadt", "in", "der", "Och\u00b7sen\u00b7ga\u00df'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da schrei'n die Buben, was ist das?", "tokens": ["Da", "schrei'n", "die", "Bu\u00b7ben", ",", "was", "ist", "das", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PWS", "VAFIN", "PDS", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Was rennt von allen Seiten?", "tokens": ["Was", "rennt", "von", "al\u00b7len", "Sei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das frankensteiner Eslein kommt,", "tokens": ["Das", "fran\u00b7ken\u00b7stei\u00b7ner", "Es\u00b7lein", "kommt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Weib sitzt drauf zu reiten.", "tokens": ["Ein", "Weib", "sitzt", "drauf", "zu", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Was hat das Biederweib gethan?", "tokens": ["Was", "hat", "das", "Bie\u00b7der\u00b7weib", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gepr\u00fcgelt hat sie ihren Mann.", "tokens": ["Ge\u00b7pr\u00fc\u00b7gelt", "hat", "sie", "ih\u00b7ren", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich kann ihn nicht beklagen,", "tokens": ["Ich", "kann", "ihn", "nicht", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom Weib erwirb dir Z\u00e4rtlichkeit,", "tokens": ["Vom", "Weib", "er\u00b7wirb", "dir", "Z\u00e4rt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dann wird sie dich nicht schlagen!", "tokens": ["Dann", "wird", "sie", "dich", "nicht", "schla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Doch anders denkt der hohe Rath,", "tokens": ["Doch", "an\u00b7ders", "denkt", "der", "ho\u00b7he", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mannesehr' zu wahren hat.", "tokens": ["Der", "Man\u00b7nes\u00b7ehr'", "zu", "wah\u00b7ren", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr M\u00fcthlein abzub\u00fc\u00dfen", "tokens": ["Ihr", "M\u00fcth\u00b7lein", "ab\u00b7zu\u00b7b\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVIZU"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Soll sie zu Esel durch die Stadt", "tokens": ["Soll", "sie", "zu", "E\u00b7sel", "durch", "die", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Schanden reiten m\u00fcssen!", "tokens": ["Mit", "Schan\u00b7den", "rei\u00b7ten", "m\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Doch weil die Esel noch so rar,", "tokens": ["Doch", "weil", "die", "E\u00b7sel", "noch", "so", "rar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer leiht zur Bu\u00df' uns einen dar?", "tokens": ["Wer", "leiht", "zur", "Bu\u00df'", "uns", "ei\u00b7nen", "dar", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPRART", "NN", "PPER", "ART", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des B\u00fcrgermeisters Pathe,", "tokens": ["Des", "B\u00fcr\u00b7ger\u00b7meis\u00b7ters", "Pa\u00b7the", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der edle Herr von Frankenstein,", "tokens": ["Der", "ed\u00b7le", "Herr", "von", "Fran\u00b7ken\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der leiht ihn gern dem Rathe.", "tokens": ["Der", "leiht", "ihn", "gern", "dem", "Ra\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und weil das ging jahrein, jahraus,", "tokens": ["Und", "weil", "das", "ging", "ja\u00b7hrein", ",", "ja\u00b7hraus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "VVFIN", "PTKANT", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ward ein Eselslehn daraus,", "tokens": ["So", "ward", "ein", "E\u00b7sels\u00b7lehn", "da\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ward f\u00fcr Mannesw\u00fcrde", "tokens": ["Und", "ward", "f\u00fcr", "Man\u00b7nes\u00b7w\u00fcr\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zw\u00f6lf Malter Korn in Jahr bezahlt,", "tokens": ["Zw\u00f6lf", "Mal\u00b7ter", "Korn", "in", "Jahr", "be\u00b7zahlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und f\u00fcr des Esleins B\u00fcrde.", "tokens": ["Und", "f\u00fcr", "des", "Es\u00b7leins", "B\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die alte gute Zeit ist aus,", "tokens": ["Die", "al\u00b7te", "gu\u00b7te", "Zeit", "ist", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VAFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dahin das Frankensteiner Haus.", "tokens": ["Da\u00b7hin", "das", "Fran\u00b7ken\u00b7stei\u00b7ner", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verj\u00e4hrt ist auch das Lehen,", "tokens": ["Ver\u00b7j\u00e4hrt", "ist", "auch", "das", "Le\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Esel sind nicht mehr so rar,", "tokens": ["Die", "E\u00b7sel", "sind", "nicht", "mehr", "so", "rar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und z\u00e4rtlicher die Ehen.", "tokens": ["Und", "z\u00e4rt\u00b7li\u00b7cher", "die", "E\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "In Sommerzeit zum Frankenstein", "tokens": ["In", "Som\u00b7mer\u00b7zeit", "zum", "Fran\u00b7ken\u00b7stein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geht Arm in Arm zu k\u00fchlem Wein", "tokens": ["Geht", "Arm", "in", "Arm", "zu", "k\u00fch\u00b7lem", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "APPR", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jetzt Weiblein hold und M\u00e4nnlein,", "tokens": ["Jetzt", "Weib\u00b7lein", "hold", "und", "M\u00e4nn\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und denkt nicht mehr der alten Zeit,", "tokens": ["Und", "denkt", "nicht", "mehr", "der", "al\u00b7ten", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und leert vergn\u00fcgt sein K\u00e4nnlein.", "tokens": ["Und", "leert", "ver\u00b7gn\u00fcgt", "sein", "K\u00e4nn\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}