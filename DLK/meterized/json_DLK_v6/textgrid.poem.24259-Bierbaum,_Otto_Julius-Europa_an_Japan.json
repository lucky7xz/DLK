{"textgrid.poem.24259": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Europa an Japan", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sei mir gegr\u00fc\u00dft, o Japan, sei willkommen", "tokens": ["Sei", "mir", "ge\u00b7gr\u00fc\u00dft", ",", "o", "Ja\u00b7pan", ",", "sei", "will\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "FM", "NE", "$,", "VAFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Ehrenkreise westlicher Kultur!", "tokens": ["Im", "Eh\u00b7ren\u00b7krei\u00b7se", "west\u00b7li\u00b7cher", "Kul\u00b7tur", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich hab dich einst nicht ganz f\u00fcr voll genommen,", "tokens": ["Ich", "hab", "dich", "einst", "nicht", "ganz", "f\u00fcr", "voll", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als ich von dir blo\u00df Freundliches erfuhr:", "tokens": ["Als", "ich", "von", "dir", "blo\u00df", "Freund\u00b7li\u00b7ches", "er\u00b7fuhr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sch\u00f6nheit und Grazie, bunte Pracht in frommen", "tokens": ["Sch\u00f6n\u00b7heit", "und", "Gra\u00b7zie", ",", "bun\u00b7te", "Pracht", "in", "from\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "ADJA", "NN", "APPR", "ADJA"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Werken der Kunst voll Stil und voll Natur:", "tokens": ["Wer\u00b7ken", "der", "Kunst", "voll", "Stil", "und", "voll", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "NN", "KON", "ADJD", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.7": {"text": "H\u00f3k'sai, Toy\u00f3kuni et cetera, \u2013", "tokens": ["H\u00f3k'\u00b7sai", ",", "Toy\u00f3\u00b7ku\u00b7ni", "et", "ce\u00b7te\u00b7ra", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "FM", "FM", "FM", "$,", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Alles ganz gut und sch\u00f6n, gewi\u00df \u2013 na ja:", "tokens": ["Al\u00b7les", "ganz", "gut", "und", "sch\u00f6n", ",", "ge\u00b7wi\u00df", "\u2013", "na", "ja", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "KON", "ADJD", "$,", "ADV", "$(", "ITJ", "ADV", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Du wei\u00dft erstaunlich kunstvoll zu lackieren,", "tokens": ["Du", "wei\u00dft", "er\u00b7staun\u00b7lich", "kunst\u00b7voll", "zu", "la\u00b7ckie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dein Porzellan ist aller Ehren wert,", "tokens": ["Dein", "Por\u00b7zel\u00b7lan", "ist", "al\u00b7ler", "Eh\u00b7ren", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "An deinen Bronzewerken delektieren", "tokens": ["An", "dei\u00b7nen", "Bron\u00b7ze\u00b7wer\u00b7ken", "de\u00b7lek\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Sich alle Kenner, ja du hast belehrt", "tokens": ["Sich", "al\u00b7le", "Ken\u00b7ner", ",", "ja", "du", "hast", "be\u00b7lehrt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "PIAT", "NN", "$,", "ADV", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Selbst ", "tokens": ["Selbst"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Kurz, was aus Japan kam, war sehr begehrt;", "tokens": ["Kurz", ",", "was", "aus", "Ja\u00b7pan", "kam", ",", "war", "sehr", "be\u00b7gehrt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PRELS", "APPR", "NE", "VVFIN", "$,", "VAFIN", "ADV", "VVPP", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Jedoch im Grund erschienst du mir, pardon,", "tokens": ["Je\u00b7doch", "im", "Grund", "er\u00b7schienst", "du", "mir", ",", "par\u00b7don", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "PPER", "PPER", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wirklich verwendbar nur beim Kotillon, \u2013", "tokens": ["Wirk\u00b7lich", "ver\u00b7wend\u00b7bar", "nur", "beim", "Ko\u00b7til\u00b7lon", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "ADJD", "ADV", "APPRART", "NN", "$,", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.3": {"line.1": {"text": "Ich meine: f\u00fcr die netten Nebensachen,", "tokens": ["Ich", "mei\u00b7ne", ":", "f\u00fcr", "die", "net\u00b7ten", "Ne\u00b7ben\u00b7sa\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zum Beispiel Dichtung, Kunst, Philosophie,", "tokens": ["Zum", "Bei\u00b7spiel", "Dich\u00b7tung", ",", "Kunst", ",", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die wohl auch mir manchmal Vergn\u00fcgen machen", "tokens": ["Die", "wohl", "auch", "mir", "manch\u00b7mal", "Ver\u00b7gn\u00fc\u00b7gen", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "PPER", "ADV", "NN", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "(doch nie soviel etwa wie Artillrie);", "tokens": ["(", "doch", "nie", "so\u00b7viel", "et\u00b7wa", "wie", "Ar\u00b7till\u00b7rie", ")", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "PIS", "ADV", "KOKOM", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Du schienst mir putzig, schienst ein Ding zum Lachen,", "tokens": ["Du", "schienst", "mir", "put\u00b7zig", ",", "schienst", "ein", "Ding", "zum", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch ernst, o Japan, ernst nahm ich dich nie.", "tokens": ["Doch", "ernst", ",", "o", "Ja\u00b7pan", ",", "ernst", "nahm", "ich", "dich", "nie", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "FM", "NE", "$,", "ADJD", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Im Grunde fand ich doch, das Ganze sei", "tokens": ["Im", "Grun\u00b7de", "fand", "ich", "doch", ",", "das", "Gan\u00b7ze", "sei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Heidnisch lackierte gelbe Barbarei.", "tokens": ["Heid\u00b7nisch", "la\u00b7ckier\u00b7te", "gel\u00b7be", "Bar\u00b7ba\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.4": {"line.1": {"text": "Jetzt aber, Japan, mu\u00df ich frei bekennen:", "tokens": ["Jetzt", "a\u00b7ber", ",", "Ja\u00b7pan", ",", "mu\u00df", "ich", "frei", "be\u00b7ken\u00b7nen", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "NE", "$,", "VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich habe dich betr\u00e4chtlich untersch\u00e4tzt;", "tokens": ["Ich", "ha\u00b7be", "dich", "be\u00b7tr\u00e4cht\u00b7lich", "un\u00b7ter\u00b7sch\u00e4tzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich mu\u00df dich Freund, ich mu\u00df dich Bruder nennen,", "tokens": ["Ich", "mu\u00df", "dich", "Freund", ",", "ich", "mu\u00df", "dich", "Bru\u00b7der", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "NN", "$,", "PPER", "VMFIN", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Komm an mein Herz, ich habe dich verletzt;", "tokens": ["Komm", "an", "mein", "Herz", ",", "ich", "ha\u00b7be", "dich", "ver\u00b7letzt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Bewundrung f\u00fchle ich in mir entbrennen", "tokens": ["Be\u00b7wund\u00b7rung", "f\u00fch\u00b7le", "ich", "in", "mir", "ent\u00b7bren\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und ebenb\u00fcrtig hei\u00dfe ich dich jetzt.", "tokens": ["Und", "e\u00b7ben\u00b7b\u00fcr\u00b7tig", "hei\u00b7\u00dfe", "ich", "dich", "jetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wer so wie du en gros mit Blut lackiert,", "tokens": ["Wer", "so", "wie", "du", "en", "gros", "mit", "Blut", "la\u00b7ckiert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "KOKOM", "PPER", "VVFIN", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der ist Europen gleich zivilisiert.", "tokens": ["Der", "ist", "Eu\u00b7ro\u00b7pen", "gleich", "zi\u00b7vi\u00b7li\u00b7siert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Es ist erreicht! darfst du mit Recht nun sagen,", "tokens": ["Es", "ist", "er\u00b7reicht", "!", "darfst", "du", "mit", "Recht", "nun", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "VMFIN", "PPER", "APPR", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es ist erreicht! Du darfst den Schnurrbart nun,", "tokens": ["Es", "ist", "er\u00b7reicht", "!", "Du", "darfst", "den", "Schnurr\u00b7bart", "nun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Held der Bildung, aufgezwirbelt tragen,", "tokens": ["Ein", "Held", "der", "Bil\u00b7dung", ",", "auf\u00b7ge\u00b7zwir\u00b7belt", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und f\u00fcrder nicht mehr mit Mongolenschuhn,", "tokens": ["Und", "f\u00fcr\u00b7der", "nicht", "mehr", "mit", "Mon\u00b7go\u00b7len\u00b7schuhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKNEG", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nein mit Schaftstiefeln und im Stechschritt schlagen", "tokens": ["Nein", "mit", "Schaft\u00b7stie\u00b7feln", "und", "im", "Stech\u00b7schritt", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "APPR", "NN", "KON", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Darfst du das Erdreich, wie die Meinen tun.", "tokens": ["Darfst", "du", "das", "Er\u00b7dreich", ",", "wie", "die", "Mei\u00b7nen", "tun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "$,", "PWAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und dann: zieh Hosen an! Dies fehlt dir nur", "tokens": ["Und", "dann", ":", "zieh", "Ho\u00b7sen", "an", "!", "Dies", "fehlt", "dir", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "VVFIN", "NN", "PTKVZ", "$.", "PDS", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Zum Zeichen ganz vollkommener Kultur.", "tokens": ["Zum", "Zei\u00b7chen", "ganz", "voll\u00b7kom\u00b7me\u00b7ner", "Kul\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+---+", "measure": "zehnsilber"}}, "stanza.6": {"line.1": {"text": "Zieh Hosen an und la\u00df dich auch bekleiden", "tokens": ["Zieh", "Ho\u00b7sen", "an", "und", "la\u00df", "dich", "auch", "be\u00b7klei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PTKVZ", "KON", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(es geht in einem) mit der Religion", "tokens": ["(", "es", "geht", "in", "ei\u00b7nem", ")", "mit", "der", "Re\u00b7li\u00b7gi\u00b7on"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "APPR", "ART", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Liebe, die die Wollust sucht im Leiden", "tokens": ["Der", "Lie\u00b7be", ",", "die", "die", "Wol\u00b7lust", "sucht", "im", "Lei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "(hab keine Angst: das Leiden gibt sich schon),", "tokens": ["(", "hab", "kei\u00b7ne", "Angst", ":", "das", "Lei\u00b7den", "gibt", "sich", "schon", ")", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIAT", "NN", "$.", "ART", "NN", "VVFIN", "PRF", "ADV", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn schlecht steht, glaub mir, Japan, einem ", "tokens": ["Denn", "schlecht", "steht", ",", "glaub", "mir", ",", "Ja\u00b7pan", ",", "ei\u00b7nem"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "ADJD", "VVFIN", "$,", "VVFIN", "PPER", "$,", "NE", "$,", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Des Westens holde Zivilisation.", "tokens": ["Des", "Wes\u00b7tens", "hol\u00b7de", "Zi\u00b7vi\u00b7li\u00b7sa\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "(zu glauben brauchst du schlie\u00dflich nicht daran;", "tokens": ["(", "zu", "glau\u00b7ben", "brauchst", "du", "schlie\u00df\u00b7lich", "nicht", "da\u00b7ran", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VVINF", "VVFIN", "PPER", "ADV", "PTKNEG", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Es sieht sich nur die Sache besser an.)", "tokens": ["Es", "sieht", "sich", "nur", "die", "Sa\u00b7che", "bes\u00b7ser", "an", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ART", "NN", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Dann aber, in des Westens Hosenr\u00f6hren", "tokens": ["Dann", "a\u00b7ber", ",", "in", "des", "Wes\u00b7tens", "Ho\u00b7sen\u00b7r\u00f6h\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gesteckt und in das Taufbuch registriert,", "tokens": ["Ge\u00b7steckt", "und", "in", "das", "Tauf\u00b7buch", "re\u00b7gist\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Tritt in mein Exerzierhaus ein! Mit Ch\u00f6ren", "tokens": ["Tritt", "in", "mein", "Ex\u00b7er\u00b7zier\u00b7haus", "ein", "!", "Mit", "Ch\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$.", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Ehrensalven wirst du hoch fetiert;", "tokens": ["Und", "Eh\u00b7ren\u00b7sal\u00b7ven", "wirst", "du", "hoch", "fe\u00b7tiert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df zueinander wir von jetzt geh\u00f6ren,", "tokens": ["Da\u00df", "zu\u00b7ei\u00b7nan\u00b7der", "wir", "von", "jetzt", "ge\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Steht au\u00dfer Frage, seit du konstatiert,", "tokens": ["Steht", "au\u00b7\u00dfer", "Fra\u00b7ge", ",", "seit", "du", "kons\u00b7ta\u00b7tiert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Da\u00df du im regelrechten Massenmord", "tokens": ["Da\u00df", "du", "im", "re\u00b7gel\u00b7rech\u00b7ten", "Mas\u00b7sen\u00b7mord"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ruhmreich geschlagen jeglichen Rekord.", "tokens": ["Ruhm\u00b7reich", "ge\u00b7schla\u00b7gen", "jeg\u00b7li\u00b7chen", "Re\u00b7kord", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "PIAT", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}}}}