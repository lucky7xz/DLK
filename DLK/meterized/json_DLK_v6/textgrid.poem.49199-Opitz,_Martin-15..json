{"textgrid.poem.49199": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "15.", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tugend ist der beste Freundt,", "tokens": ["Tu\u00b7gend", "ist", "der", "bes\u00b7te", "Freundt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die uns allzeit pflegt zu lieben,", "tokens": ["Die", "uns", "all\u00b7zeit", "pflegt", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wann die sch\u00f6ne Sonne scheint", "tokens": ["Wann", "die", "sch\u00f6\u00b7ne", "Son\u00b7ne", "scheint"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Wolcken uns betr\u00fcben;", "tokens": ["Und", "die", "Wol\u00b7cken", "uns", "be\u00b7tr\u00fc\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Reisen wir gleich hin und her,", "tokens": ["Rei\u00b7sen", "wir", "gleich", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ueber Land und \u00fcber Meer,", "tokens": ["Ue\u00b7ber", "Land", "und", "\u00fc\u00b7ber", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Es ist ihr kein Beschwer.", "tokens": ["Es", "ist", "ihr", "kein", "Be\u00b7schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Sie wei\u00df nichts von Menschen Gunst,", "tokens": ["Sie", "wei\u00df", "nichts", "von", "Men\u00b7schen", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Wie es zwar manch Freund hier machet,", "tokens": ["Wie", "es", "zwar", "manch", "Freund", "hier", "ma\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der au\u00df falscher Liebesbrunst", "tokens": ["Der", "au\u00df", "fal\u00b7scher", "Lie\u00b7bes\u00b7brunst"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fr\u00f6lich klagt und kl\u00e4glich lachet,", "tokens": ["Fr\u00f6\u00b7lich", "klagt", "und", "kl\u00e4g\u00b7lich", "la\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der zwar gut ist vom Gesicht", "tokens": ["Der", "zwar", "gut", "ist", "vom", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "APPRART", "NN"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Und sich aller Treu verspricht;", "tokens": ["Und", "sich", "al\u00b7ler", "Treu", "ver\u00b7spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Das Hertze meint es nicht.", "tokens": ["Das", "Hert\u00b7ze", "meint", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Als das leichte Gl\u00fccke mich", "tokens": ["Als", "das", "leich\u00b7te", "Gl\u00fc\u00b7cke", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schien' ein wenig zu erheben,", "tokens": ["Schien'", "ein", "we\u00b7nig", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PIS", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wolte der und jener sich", "tokens": ["Wol\u00b7te", "der", "und", "je\u00b7ner", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "KON", "PDS", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In den Todt auch f\u00fcr mich geben;", "tokens": ["In", "den", "Todt", "auch", "f\u00fcr", "mich", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nun ein kleiner rauer Wind", "tokens": ["Nun", "ein", "klei\u00b7ner", "rau\u00b7er", "Wind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur zu wittern sich beginnt,", "tokens": ["Nur", "zu", "wit\u00b7tern", "sich", "be\u00b7ginnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVFIN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist niemand, der sich findt.", "tokens": ["Ist", "nie\u00b7mand", ",", "der", "sich", "findt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "PRELS", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Doch will ich von meinem Muth'", "tokens": ["Doch", "will", "ich", "von", "mei\u00b7nem", "Muth'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch das minste noch nicht schreiten", "tokens": ["Auch", "das", "mins\u00b7te", "noch", "nicht", "schrei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "ADV", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und gedencken, da\u00df mein Guth", "tokens": ["Und", "ge\u00b7den\u00b7cken", ",", "da\u00df", "mein", "Guth"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00e4ren wird zu allen Zeiten;", "tokens": ["W\u00e4\u00b7ren", "wird", "zu", "al\u00b7len", "Zei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann mein Trost in Gl\u00fcck und Noth,", "tokens": ["Dann", "mein", "Trost", "in", "Gl\u00fcck", "und", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hier und da, in Ehr' und Spott,", "tokens": ["Hier", "und", "da", ",", "in", "Ehr'", "und", "Spott", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist Tugend und ist Gott.", "tokens": ["Ist", "Tu\u00b7gend", "und", "ist", "Gott", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}