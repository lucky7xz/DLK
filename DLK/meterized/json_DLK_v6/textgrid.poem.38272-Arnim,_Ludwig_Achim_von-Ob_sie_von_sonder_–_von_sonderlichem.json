{"textgrid.poem.38272": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Ob sie von sonder \u2013 von sonderlichem", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun freue dich mein Herzelein, der Sommer,", "tokens": ["Nun", "freu\u00b7e", "dich", "mein", "Her\u00b7ze\u00b7lein", ",", "der", "Som\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Sommer, der bricht an,", "tokens": ["Der", "Som\u00b7mer", ",", "der", "bricht", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weiche alle Traurigkeit,", "tokens": ["Wei\u00b7che", "al\u00b7le", "Trau\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und kehr wieder Fr\u00f6hlichkeit,", "tokens": ["Und", "kehr", "wie\u00b7der", "Fr\u00f6h\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Mir und dir ohn Unterlahn.", "tokens": ["Mir", "und", "dir", "ohn", "Un\u00b7ter\u00b7lahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Die Heide gr\u00fcnt und tr\u00e4gt nun, so sch\u00f6ne", "tokens": ["Die", "Hei\u00b7de", "gr\u00fcnt", "und", "tr\u00e4gt", "nun", ",", "so", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NE", "VVFIN", "KON", "VVFIN", "ADV", "$,", "ADV", "ADJA"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So sch\u00f6ne Bl\u00fcmelein,", "tokens": ["So", "sch\u00f6\u00b7ne", "Bl\u00fc\u00b7me\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und von diesen Bl\u00fcmlein allen,", "tokens": ["Und", "von", "die\u00b7sen", "Bl\u00fcm\u00b7lein", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Thust du mir gar wohl gefallen,", "tokens": ["Thust", "du", "mir", "gar", "wohl", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach zart liebes Jungfr\u00e4ulein!", "tokens": ["Ach", "zart", "lie\u00b7bes", "Jung\u00b7fr\u00e4u\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Schau ich dich an, du d\u00e4uchst mir viel sch\u00f6ner,", "tokens": ["Schau", "ich", "dich", "an", ",", "du", "d\u00e4uchst", "mir", "viel", "sch\u00f6\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Viel sch\u00f6ner noch jetzund,", "tokens": ["Viel", "sch\u00f6\u00b7ner", "noch", "je\u00b7tzund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als zuvor, wo k\u00f6mmt dies her?", "tokens": ["Als", "zu\u00b7vor", ",", "wo", "k\u00f6mmt", "dies", "her", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "PWAV", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sag mirs, das ist mein Begehr,", "tokens": ["Sag", "mirs", ",", "das", "ist", "mein", "Be\u00b7gehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lieblein zart zu jeder Stund.", "tokens": ["Lieb\u00b7lein", "zart", "zu", "je\u00b7der", "Stund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "I\u00dft du etwa mein Liebchen von sonder", "tokens": ["I\u00dft", "du", "et\u00b7wa", "mein", "Lieb\u00b7chen", "von", "son\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Von sonderlichem Brod?", "tokens": ["Von", "son\u00b7der\u00b7li\u00b7chem", "Brod", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Oder macht es dein Gebet?", "tokens": ["O\u00b7der", "macht", "es", "dein", "Ge\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Da\u00df dir alles wohl ansteht,", "tokens": ["Da\u00df", "dir", "al\u00b7les", "wohl", "an\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch bist so sch\u00f6n wei\u00df und roth.", "tokens": ["Auch", "bist", "so", "sch\u00f6n", "wei\u00df", "und", "roth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}