{"textgrid.poem.53840": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Zwei Seelen", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich, Herr Tiger, bestehe zu meinem Heil", "tokens": ["Ich", ",", "Herr", "Ti\u00b7ger", ",", "be\u00b7ste\u00b7he", "zu", "mei\u00b7nem", "Heil"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "NN", "$,", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-++--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "aus einem Oberteil und einem Unterteil.", "tokens": ["aus", "ei\u00b7nem", "O\u00b7bert\u00b7eil", "und", "ei\u00b7nem", "Un\u00b7ter\u00b7teil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Das Oberteil f\u00fchlt seine bescheidene Kleinheit,", "tokens": ["Das", "O\u00b7bert\u00b7eil", "f\u00fchlt", "sei\u00b7ne", "be\u00b7schei\u00b7de\u00b7ne", "Klein\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "ihm ist nur wohl in v\u00f6lliger Reinheit;", "tokens": ["ihm", "ist", "nur", "wohl", "in", "v\u00f6l\u00b7li\u00b7ger", "Rein\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "es ist tapfer, wahr, anst\u00e4ndig und", "tokens": ["es", "ist", "tap\u00b7fer", ",", "wahr", ",", "an\u00b7st\u00e4n\u00b7dig", "und"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "bis in seine tiefsten Tiefen klar und gesund.", "tokens": ["bis", "in", "sei\u00b7ne", "tiefs\u00b7ten", "Tie\u00b7fen", "klar", "und", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.5": {"text": "Das Oberteil ist auch durchaus befugt, Ratschl\u00e4ge zu erteilen", "tokens": ["Das", "O\u00b7bert\u00b7eil", "ist", "auch", "durc\u00b7haus", "be\u00b7fugt", ",", "Rat\u00b7schl\u00e4\u00b7ge", "zu", "er\u00b7tei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.6": {"text": "und die Verbrechen von andern Oberteilen", "tokens": ["und", "die", "Ver\u00b7bre\u00b7chen", "von", "an\u00b7dern", "O\u00b7bert\u00b7ei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "zu gei\u00dfeln \u2013 es darf sich \u00fcber die Menschen lustig machen,", "tokens": ["zu", "gei\u00b7\u00dfeln", "\u2013", "es", "darf", "sich", "\u00fc\u00b7ber", "die", "Men\u00b7schen", "lus\u00b7tig", "ma\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "und wenn andre den Naseninhalt hochziehn, darf es lachen.", "tokens": ["und", "wenn", "and\u00b7re", "den", "Na\u00b7sen\u00b7in\u00b7halt", "hoch\u00b7ziehn", ",", "darf", "es", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ART", "NN", "VVINF", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "--+--+-+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "Soweit das.", "tokens": ["So\u00b7weit", "das", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "PDS", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Aber, Dunnerkeil,", "tokens": ["A\u00b7ber", ",", "Dun\u00b7ner\u00b7keil", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "das Unterteil!", "tokens": ["das", "Un\u00b7ter\u00b7teil", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Feige, unentschlossen, heuchlerisch, woll\u00fcstig und verlogen;", "tokens": ["Fei\u00b7ge", ",", "un\u00b7ent\u00b7schlos\u00b7sen", ",", "heuch\u00b7le\u00b7risch", ",", "wol\u00b7l\u00fcs\u00b7tig", "und", "ver\u00b7lo\u00b7gen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "zu den pfinstersten Pfreuden des Pfleisches f\u00fchlt es sich hingezogen \u2013", "tokens": ["zu", "den", "pfins\u00b7ters\u00b7ten", "Pfreu\u00b7den", "des", "Pflei\u00b7sches", "f\u00fchlt", "es", "sich", "hin\u00b7ge\u00b7zo\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PPER", "PRF", "VVPP", "$("], "meter": "--+--+--+-+--+-+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "dabei dumpf, kalt, zwergig, ein greuliches", "tokens": ["da\u00b7bei", "dumpf", ",", "kalt", ",", "zwer\u00b7gig", ",", "ein", "greu\u00b7li\u00b7ches"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["PAV", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ART", "ADJA"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "pessimistisches Ding: etwas ganz und gar Abscheuliches.", "tokens": ["pes\u00b7si\u00b7mis\u00b7ti\u00b7sches", "Ding", ":", "et\u00b7was", "ganz", "und", "gar", "Ab\u00b7scheu\u00b7li\u00b7ches", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADV", "ADV", "KON", "ADV", "NN", "$."], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.8": {"text": "Nun w\u00e4re aber auch einer denkbar \u2013 sehr bemerkenswert! \u2013,", "tokens": ["Nun", "w\u00e4\u00b7re", "a\u00b7ber", "auch", "ei\u00b7ner", "denk\u00b7bar", "\u2013", "sehr", "be\u00b7mer\u00b7kens\u00b7wert", "!", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "ADJD", "$(", "ADV", "VVPP", "$.", "$(", "$,"], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "der umgekehrt.", "tokens": ["der", "um\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Der in seinen untern Teilen nichts zu scheuen h\u00e4tte,", "tokens": ["Der", "in", "sei\u00b7nen", "un\u00b7tern", "Tei\u00b7len", "nichts", "zu", "scheu\u00b7en", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN", "PIS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "keinen seiner diesbez\u00fcglichen Schritte zu bereuen h\u00e4tte \u2013", "tokens": ["kei\u00b7nen", "sei\u00b7ner", "dies\u00b7be\u00b7z\u00fcg\u00b7li\u00b7chen", "Schrit\u00b7te", "zu", "be\u00b7reu\u00b7en", "h\u00e4t\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "VAFIN", "$("], "meter": "+-+-+-+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "ein sauberes Triebwesen, ein ganzer Mann und", "tokens": ["ein", "sau\u00b7be\u00b7res", "Trieb\u00b7we\u00b7sen", ",", "ein", "gan\u00b7zer", "Mann", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "KON"], "meter": "-+--++--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "bis in seine tiefsten Tiefen klar und gesund.", "tokens": ["bis", "in", "sei\u00b7ne", "tiefs\u00b7ten", "Tie\u00b7fen", "klar", "und", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}}, "stanza.5": {"line.1": {"text": "Und es w\u00e4re zu denken, da\u00df er am gleichen Skelette", "tokens": ["Und", "es", "w\u00e4\u00b7re", "zu", "den\u00b7ken", ",", "da\u00df", "er", "am", "glei\u00b7chen", "Ske\u00b7let\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "eine Seele mit Maukbeene h\u00e4tte.", "tokens": ["ei\u00b7ne", "See\u00b7le", "mit", "Mauk\u00b7be\u00b7e\u00b7ne", "h\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Was er nur andenkt, wird faulig-verschmiert;", "tokens": ["Was", "er", "nur", "an\u00b7denkt", ",", "wird", "fau\u00b7lig\u00b7ver\u00b7schmiert", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "NE", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "sein Verstand l\u00e4uft nie offen, sondern stets maskiert;", "tokens": ["sein", "Ver\u00b7stand", "l\u00e4uft", "nie", "of\u00b7fen", ",", "son\u00b7dern", "stets", "mas\u00b7kiert", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "$,", "KON", "ADV", "VVFIN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "sogar wenn er l\u00fcgt, l\u00fcgt er; glaubt sich nichts, redet sichs aber ein \u2013", "tokens": ["so\u00b7gar", "wenn", "er", "l\u00fcgt", ",", "l\u00fcgt", "er", ";", "glaubt", "sich", "nichts", ",", "re\u00b7det", "sichs", "a\u00b7ber", "ein", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$.", "VVFIN", "PRF", "PIS", "$,", "VVFIN", "PIS", "ADV", "ART", "$("], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.4": {"text": "und ist oben herum \u00fcberhaupt ein Schwein.", "tokens": ["und", "ist", "o\u00b7ben", "he\u00b7rum", "\u00fc\u00b7ber\u00b7haupt", "ein", "Schwein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APZR", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.7": {"line.1": {"text": "Vor solchem Menschen m\u00fcssen ja alle, die ihn begucken,", "tokens": ["Vor", "sol\u00b7chem", "Men\u00b7schen", "m\u00fcs\u00b7sen", "ja", "al\u00b7le", ",", "die", "ihn", "be\u00b7gu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "ADV", "PIS", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+---+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "vor Ekel mitten in die n\u00e4chste Gosse spucken!", "tokens": ["vor", "E\u00b7kel", "mit\u00b7ten", "in", "die", "n\u00e4chs\u00b7te", "Gos\u00b7se", "spu\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da striche auch ich mein doppelkollriges Kinn", "tokens": ["Da", "stri\u00b7che", "auch", "ich", "mein", "dop\u00b7pel\u00b7koll\u00b7ri\u00b7ges", "Kinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "und betete ergriffen: \u00bbIch danke dir, Gott, da\u00df ich bin, wie ich bin!\u00ab", "tokens": ["und", "be\u00b7te\u00b7te", "er\u00b7grif\u00b7fen", ":", "\u00bb", "Ich", "dan\u00b7ke", "dir", ",", "Gott", ",", "da\u00df", "ich", "bin", ",", "wie", "ich", "bin", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$.", "$(", "PPER", "VVFIN", "PPER", "$,", "NN", "$,", "KOUS", "PPER", "VAFIN", "$,", "PWAV", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+--+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.8": {"line.1": {"text": "Was aber Menschen aus einem Gusse betrifft in der sch\u00f6nsten der Welten \u2013:", "tokens": ["Was", "a\u00b7ber", "Men\u00b7schen", "aus", "ei\u00b7nem", "Gus\u00b7se", "be\u00b7tr\u00b7ifft", "in", "der", "sch\u00f6ns\u00b7ten", "der", "Wel\u00b7ten", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADV", "NN", "APPR", "ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "ART", "NN", "$(", "$."], "meter": "-+-+--+-+--++--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "der Fall ist \u00e4u\u00dferst selten.", "tokens": ["der", "Fall", "ist", "\u00e4u\u00b7\u00dferst", "sel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}