{"textgrid.poem.56097": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Geburt Christi", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00e4ttest du der Einfalt nicht, wie sollte", "tokens": ["H\u00e4t\u00b7test", "du", "der", "Ein\u00b7falt", "nicht", ",", "wie", "soll\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "$,", "PWAV", "VMFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "dir geschehn, was jetzt die Nacht erhellt?", "tokens": ["dir", "ge\u00b7schehn", ",", "was", "jetzt", "die", "Nacht", "er\u00b7hellt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Sieh, der Gott, der \u00fcber V\u00f6lkern grollte,", "tokens": ["Sieh", ",", "der", "Gott", ",", "der", "\u00fc\u00b7ber", "V\u00f6l\u00b7kern", "groll\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "macht sich mild und kommt in dir zur Welt.", "tokens": ["macht", "sich", "mild", "und", "kommt", "in", "dir", "zur", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "KON", "VVFIN", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Hast du dir ihn gr\u00f6\u00dfer vorgestellt?", "tokens": ["Hast", "du", "dir", "ihn", "gr\u00f6\u00b7\u00dfer", "vor\u00b7ge\u00b7stellt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Was ist Gr\u00f6\u00dfe? Quer durch alle Ma\u00dfe,", "tokens": ["Was", "ist", "Gr\u00f6\u00b7\u00dfe", "?", "Quer", "durch", "al\u00b7le", "Ma\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NN", "$.", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "die er durchstreicht, geht sein grades Los.", "tokens": ["die", "er", "durch\u00b7streicht", ",", "geht", "sein", "gra\u00b7des", "Los", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "VVFIN", "$,", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Selbst ein Stern hat keine solche Stra\u00dfe.", "tokens": ["Selbst", "ein", "Stern", "hat", "kei\u00b7ne", "sol\u00b7che", "Stra\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PIAT", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Siehst du, diese K\u00f6nige sind gro\u00df,", "tokens": ["Siehst", "du", ",", "die\u00b7se", "K\u00f6\u00b7ni\u00b7ge", "sind", "gro\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PDAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "und sie schleppen dir vor deinen Schoo\u00df", "tokens": ["und", "sie", "schlep\u00b7pen", "dir", "vor", "dei\u00b7nen", "Schoo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Sch\u00e4tze, die sie f\u00fcr die gr\u00f6\u00dften halten,", "tokens": ["Sch\u00e4t\u00b7ze", ",", "die", "sie", "f\u00fcr", "die", "gr\u00f6\u00df\u00b7ten", "hal\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "APPR", "ART", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "und du staunst vielleicht bei dieser Gift \u2013:", "tokens": ["und", "du", "staunst", "viel\u00b7leicht", "bei", "die\u00b7ser", "Gift", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPR", "PDAT", "NN", "$(", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "aber schau in deines Tuches Falten,", "tokens": ["a\u00b7ber", "schau", "in", "dei\u00b7nes", "Tu\u00b7ches", "Fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "wie er jetzt schon alles \u00fcbertrifft.", "tokens": ["wie", "er", "jetzt", "schon", "al\u00b7les", "\u00fc\u00b7bert\u00b7rifft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Aller Amber, den man weit verschifft,", "tokens": ["Al\u00b7ler", "Am\u00b7ber", ",", "den", "man", "weit", "ver\u00b7schifft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PIS", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "jeder Goldschmuck und das Luftgew\u00fcrze,", "tokens": ["je\u00b7der", "Gold\u00b7schmuck", "und", "das", "Luft\u00b7ge\u00b7w\u00fcr\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "das sich tr\u00fcbend in die Sinne streut:", "tokens": ["das", "sich", "tr\u00fc\u00b7bend", "in", "die", "Sin\u00b7ne", "streut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "alles dieses war von rascher K\u00fcrze,", "tokens": ["al\u00b7les", "die\u00b7ses", "war", "von", "ra\u00b7scher", "K\u00fcr\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDS", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und am Ende hat man es bereut.", "tokens": ["und", "am", "En\u00b7de", "hat", "man", "es", "be\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "PIS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Aber (du wirst sehen): Er erfreut.", "tokens": ["A\u00b7ber", "(", "du", "wirst", "se\u00b7hen", ")", ":", "Er", "er\u00b7freut", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "$(", "PPER", "VAFIN", "VVINF", "$(", "$.", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}