{"dta.poem.19103": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "LxXXV.   Auf des Jenaischen Theologi,  \n  D.   Buddei Hingang.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Fleuch, Vater! fleuch! die St\u00e4tte h\u00e4lt nicht Stand.", "tokens": ["Fleuch", ",", "Va\u00b7ter", "!", "fleuch", "!", "die", "St\u00e4t\u00b7te", "h\u00e4lt", "nicht", "Stand", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "NN", "$.", "ART", "NN", "VVFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Des Kedars-Zelt l\u00e4st deinen Fu\u00df nicht ruhen:", "tokens": ["Des", "Ke\u00b7dar\u00b7sZelt", "l\u00e4st", "dei\u00b7nen", "Fu\u00df", "nicht", "ru\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bem\u00fche dich ihn hurtig auszuschuhen:", "tokens": ["Be\u00b7m\u00fc\u00b7he", "dich", "ihn", "hur\u00b7tig", "aus\u00b7zu\u00b7schu\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die St\u00e4tte, da man ruht, ist heilig Land.", "tokens": ["Die", "St\u00e4t\u00b7te", ",", "da", "man", "ruht", ",", "ist", "hei\u00b7lig", "Land", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "VVFIN", "$,", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Komm, ", "tokens": ["Komm", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Egypten ist zur\u00fcck, die W\u00fcsten aus.", "tokens": ["E\u00b7gyp\u00b7ten", "ist", "zu\u00b7r\u00fcck", ",", "die", "W\u00fcs\u00b7ten", "aus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKVZ", "$,", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Die Lection ist starck vor einen Mann,", "tokens": ["Die", "Lec\u00b7ti\u00b7on", "ist", "starck", "vor", "ei\u00b7nen", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der sich nicht gut in GOttes Wege schicket,", "tokens": ["Der", "sich", "nicht", "gut", "in", "Got\u00b7tes", "We\u00b7ge", "schi\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PTKNEG", "ADJD", "APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Warum der HErr dich itzt dahin ger\u00fccket?", "tokens": ["Wa\u00b7rum", "der", "Herr", "dich", "itzt", "da\u00b7hin", "ge\u00b7r\u00fc\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Es war ja nicht mehr weit nach Canaan.", "tokens": ["Es", "war", "ja", "nicht", "mehr", "weit", "nach", "Ca\u00b7naan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "APPR", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Allein ich bin gewi\u00df, der HErr hat recht:", "tokens": ["Al\u00b7lein", "ich", "bin", "ge\u00b7wi\u00df", ",", "der", "Herr", "hat", "recht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Spricht er zum Knechte: ", "tokens": ["Spricht", "er", "zum", "Knech\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Jhr Hauffen, die ihr unsern K\u00f6nig kennt,", "tokens": ["Ihr", "Hauf\u00b7fen", ",", "die", "ihr", "un\u00b7sern", "K\u00f6\u00b7nig", "kennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "L\u00e4st Juda sich nach allen seinen St\u00e4mmen,", "tokens": ["L\u00e4st", "Ju\u00b7da", "sich", "nach", "al\u00b7len", "sei\u00b7nen", "St\u00e4m\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PRF", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Durch Asahel im Lauf auf einmal hemmen,", "tokens": ["Durch", "As\u00b7a\u00b7hel", "im", "Lauf", "auf", "ein\u00b7mal", "hem\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "NN", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil er sich ihres Hertzogs Bruder nennt;", "tokens": ["Weil", "er", "sich", "ih\u00b7res", "Hert\u00b7zogs", "Bru\u00b7der", "nennt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Gewi\u00df! Jhr h\u00f6rt so bald nicht das Geth\u00f6n:", "tokens": ["Ge\u00b7wi\u00df", "!", "Ihr", "h\u00f6rt", "so", "bald", "nicht", "das", "Ge\u00b7th\u00f6n", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VVFIN", "ADV", "ADV", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Du sehend Aug, auf Christi Creutz gericht,", "tokens": ["Du", "se\u00b7hend", "Aug", ",", "auf", "Chris\u00b7ti", "Creutz", "ge\u00b7richt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "NN", "$,", "APPR", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ge\u00f6fnet und verkl\u00e4hrt im Niederknien,", "tokens": ["Ge\u00b7\u00f6f\u00b7net", "und", "ver\u00b7kl\u00e4hrt", "im", "Nie\u00b7der\u00b7kni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du am Altar vom heissen Kohlen spr\u00fchen,", "tokens": ["Du", "am", "Al\u00b7tar", "vom", "heis\u00b7sen", "Koh\u00b7len", "spr\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ger\u00fchrt, geheiligt, und entflammtes Licht!", "tokens": ["Ge\u00b7r\u00fchrt", ",", "ge\u00b7hei\u00b7ligt", ",", "und", "ent\u00b7flamm\u00b7tes", "Licht", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dein Demuths-Blick gewann der Liebe Sinn,", "tokens": ["Dein", "De\u00b7muths\u00b7Blick", "ge\u00b7wann", "der", "Lie\u00b7be", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der R\u00fccken b\u00fcckte sich zum Creutze hin.", "tokens": ["Der", "R\u00fc\u00b7cken", "b\u00fcck\u00b7te", "sich", "zum", "Creut\u00b7ze", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wer um den Unterschied der Glieder wei\u00df,", "tokens": ["Wer", "um", "den", "Un\u00b7ter\u00b7schied", "der", "Glie\u00b7der", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die sich an Christi Leibe brauchen lassen,", "tokens": ["Die", "sich", "an", "Chris\u00b7ti", "Lei\u00b7be", "brau\u00b7chen", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NE", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der kan dich bald in gr\u00f6ster Liebe fassen.", "tokens": ["Der", "kan", "dich", "bald", "in", "gr\u00f6s\u00b7ter", "Lie\u00b7be", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Treu in deinem Theil treibt ihren Schwei\u00df:", "tokens": ["Die", "Treu", "in", "dei\u00b7nem", "Theil", "treibt", "ih\u00b7ren", "Schwei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und da\u00df du mit an Christi Creutz geh\u00f6rt\u2019st,", "tokens": ["Und", "da\u00df", "du", "mit", "an", "Chris\u00b7ti", "Creutz", "ge\u00b7h\u00f6rt'st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "APPR", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zeigt, was du aus dem Hertzen schriebst und lehrt\u2019st.", "tokens": ["Zeigt", ",", "was", "du", "aus", "dem", "Hert\u00b7zen", "schriebst", "und", "lehrt'", "st."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "$,", "PWS", "PPER", "APPR", "ART", "NN", "VVFIN", "KON", "VVFIN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Jhr alle, die ihr von ihm hergestammt,", "tokens": ["Ihr", "al\u00b7le", ",", "die", "ihr", "von", "ihm", "her\u00b7ge\u00b7stammt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "PRELS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Auf! ", "tokens": ["Auf", "!"], "token_info": ["word", "punct"], "pos": ["APPR", "$."], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Auf! auf! Jhr Streiter in des HErren Kriege,", "tokens": ["Auf", "!", "auf", "!", "Ihr", "Strei\u00b7ter", "in", "des", "Her\u00b7ren", "Krie\u00b7ge", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "PTKVZ", "$.", "PPOSAT", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erkennet dieses eures F\u00fcrsten Amt.", "tokens": ["Er\u00b7ken\u00b7net", "die\u00b7ses", "eu\u00b7res", "F\u00fcrs\u00b7ten", "Amt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Jhr, die ihr Babel schleiffen ", "tokens": ["Ihr", ",", "die", "ihr", "Ba\u00b7bel", "schleif\u00b7fen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wann ihr nur Hirten-Knaben werden wolt!", "tokens": ["Wann", "ihr", "nur", "Hir\u00b7ten\u00b7Kna\u00b7ben", "wer\u00b7den", "wolt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Hat nicht ", "tokens": ["Hat", "nicht"], "token_info": ["word", "word"], "pos": ["VAFIN", "PTKNEG"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "An einem Ort ein doppelt Gut vereinet,", "tokens": ["An", "ei\u00b7nem", "Ort", "ein", "dop\u00b7pelt", "Gut", "ver\u00b7ei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das dieser Zeit kaum zu verbinden scheinet,", "tokens": ["Das", "die\u00b7ser", "Zeit", "kaum", "zu", "ver\u00b7bin\u00b7den", "schei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PDAT", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die so gar wenig Guts bey sammen kennt;", "tokens": ["Die", "so", "gar", "we\u00b7nig", "Guts", "bey", "sam\u00b7men", "kennt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PIAT", "NN", "APPR", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Den Ruhm der orthodoxen Reinigkeit,", "tokens": ["Den", "Ruhm", "der", "or\u00b7tho\u00b7do\u00b7xen", "Rei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das Zeugni\u00df, da\u00df die Kirch um Be\u00dfrung schreyt.", "tokens": ["Das", "Zeug\u00b7ni\u00df", ",", "da\u00df", "die", "Kirch", "um", "Be\u00df\u00b7rung", "schreyt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Das eben ists, was mich mit ihm verband,", "tokens": ["Das", "e\u00b7ben", "ists", ",", "was", "mich", "mit", "ihm", "ver\u00b7band", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAFIN", "$,", "PRELS", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der ich gantz kein Geheimni\u00df daraus mache,", "tokens": ["Der", "ich", "gantz", "kein", "Ge\u00b7heim\u00b7ni\u00df", "da\u00b7raus", "ma\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PIAT", "NN", "PAV", "VVFIN", "$,"], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Da\u00df eine Kirch-Verwandlung keine Sache,", "tokens": ["Da\u00df", "ei\u00b7ne", "Kirch\u00b7Ver\u00b7wand\u00b7lung", "kei\u00b7ne", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn ohne Glieder hat sie nicht Bestand;", "tokens": ["Denn", "oh\u00b7ne", "Glie\u00b7der", "hat", "sie", "nicht", "Be\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VAFIN", "PPER", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df aber auch in ieglicher Gemein", "tokens": ["Da\u00df", "a\u00b7ber", "auch", "in", "ieg\u00b7li\u00b7cher", "Ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ein Muster von der Kirche solte seyn.", "tokens": ["Ein", "Mus\u00b7ter", "von", "der", "Kir\u00b7che", "sol\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Wenn ein Student den Kopf mit Bildern f\u00fcllt,", "tokens": ["Wenn", "ein", "Stu\u00b7dent", "den", "Kopf", "mit", "Bil\u00b7dern", "f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wie eine Kirchen-Republic zu tichten,", "tokens": ["Wie", "ei\u00b7ne", "Kir\u00b7chen\u00b7Re\u00b7pu\u00b7blic", "zu", "tich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und will dereinst sein Kirchspiel darnach richten,", "tokens": ["Und", "will", "de\u00b7reinst", "sein", "Kirch\u00b7spiel", "dar\u00b7nach", "rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PPOSAT", "NN", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ists eben wie mit Doctor Luthers Bild: ", "tokens": ["Ists", "e\u00b7ben", "wie", "mit", "Doc\u00b7tor", "Lu\u00b7thers", "Bild", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KOKOM", "APPR", "NN", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch wehe dem, der davon nichts versteht,", "tokens": ["Doch", "we\u00b7he", "dem", ",", "der", "da\u00b7von", "nichts", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "$,", "PRELS", "PAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was mitten im Verderben gleichwol geht.", "tokens": ["Was", "mit\u00b7ten", "im", "Ver\u00b7der\u00b7ben", "gleich\u00b7wol", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wer ", "tokens": ["Wer"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Nun hat uns Doctor ", "tokens": ["Nun", "hat", "uns", "Doc\u00b7tor"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Und zwar im B\u00fcchlein, das die Kinder fassen,", "tokens": ["Und", "zwar", "im", "B\u00fcch\u00b7lein", ",", "das", "die", "Kin\u00b7der", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df dieses erst die rechte Kirche sey:", "tokens": ["Da\u00df", "die\u00b7ses", "erst", "die", "rech\u00b7te", "Kir\u00b7che", "sey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und wo sich auch das Volck dadurch bekehrt.", "tokens": ["Und", "wo", "sich", "auch", "das", "Volck", "da\u00b7durch", "be\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "ADV", "ART", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Die Lehre halt ich \u00fcber Hof und Hau\u00df.", "tokens": ["Die", "Leh\u00b7re", "halt", "ich", "\u00fc\u00b7ber", "Hof", "und", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zwar wagts die Welt mit unsers Meisters Lehren,", "tokens": ["Zwar", "wagts", "die", "Welt", "mit", "un\u00b7sers", "Meis\u00b7ters", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie ihn und her zu wenden und zu kehren;", "tokens": ["Sie", "ihn", "und", "her", "zu", "wen\u00b7den", "und", "zu", "keh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "KON", "ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo aber ", "tokens": ["Wo", "a\u00b7ber"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Und bleibet sie, (wie billig,) ewig wahr,", "tokens": ["Und", "blei\u00b7bet", "sie", ",", "(", "wie", "bil\u00b7lig", ",", ")", "e\u00b7wig", "wahr", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "$(", "KOKOM", "ADJD", "$,", "$(", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was fehlt uns noch am Attischen Altar?", "tokens": ["Was", "fehlt", "uns", "noch", "am", "At\u00b7ti\u00b7schen", "Al\u00b7tar", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Er hofte zwar, es solte sich noch geben,", "tokens": ["Er", "hof\u00b7te", "zwar", ",", "es", "sol\u00b7te", "sich", "noch", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VMFIN", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es w\u00fcrde sich die H\u00fctte GOttes heben,", "tokens": ["Es", "w\u00fcr\u00b7de", "sich", "die", "H\u00fct\u00b7te", "Got\u00b7tes", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu der er sein Geschenck mit dargereicht.", "tokens": ["Zu", "der", "er", "sein", "Ge\u00b7schenck", "mit", "dar\u00b7ge\u00b7reicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch, langes Thun, und eine kurtze Zeit,", "tokens": ["Doch", ",", "lan\u00b7ges", "Thun", ",", "und", "ei\u00b7ne", "kurt\u00b7ze", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJA", "NN", "$,", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Erfordert bey dem Flei\u00df Geschwindigkeit.", "tokens": ["Er\u00b7for\u00b7dert", "bey", "dem", "Flei\u00df", "Ge\u00b7schwin\u00b7dig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Und hielte gleich des Mannes kluger Geist", "tokens": ["Und", "hiel\u00b7te", "gleich", "des", "Man\u00b7nes", "klu\u00b7ger", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nicht allzuviel auf weit-gesuchte Dinge,", "tokens": ["Nicht", "all\u00b7zu\u00b7viel", "auf", "weit\u00b7ge\u00b7such\u00b7te", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Damits dem Reich des HErrn nicht mi\u00dfgelinge,", "tokens": ["Da\u00b7mits", "dem", "Reich", "des", "Herrn", "nicht", "mi\u00df\u00b7ge\u00b7lin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So bleibt doch mir bey allem Sonnen-klar,", "tokens": ["So", "bleibt", "doch", "mir", "bey", "al\u00b7lem", "Son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df er des Reichs der Kraft Geh\u00fclffe war.", "tokens": ["Da\u00df", "er", "des", "Reichs", "der", "Kraft", "Ge\u00b7h\u00fclf\u00b7fe", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Ein grosser Mann erfordert sonderlich", "tokens": ["Ein", "gros\u00b7ser", "Mann", "er\u00b7for\u00b7dert", "son\u00b7der\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Ursprung aller Sachen auszufragen;", "tokens": ["Den", "Ur\u00b7sprung", "al\u00b7ler", "Sa\u00b7chen", "aus\u00b7zu\u00b7fra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ist di\u00df, so kan man wohl mit Wahrheit sagen,", "tokens": ["Ist", "di\u00df", ",", "so", "kan", "man", "wohl", "mit", "Wahr\u00b7heit", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "$,", "ADV", "VMFIN", "PIS", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df dieser nicht mehr einem Neuling glich:", "tokens": ["Da\u00df", "die\u00b7ser", "nicht", "mehr", "ei\u00b7nem", "Neu\u00b7ling", "glich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "So wird auch schon der Selige sein Zweck.", "tokens": ["So", "wird", "auch", "schon", "der", "Se\u00b7li\u00b7ge", "sein", "Zweck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Um ", "tokens": ["Um"], "token_info": ["word"], "pos": ["KOUI"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Er gab ihm was von den gelehrten Briefen,", "tokens": ["Er", "gab", "ihm", "was", "von", "den", "ge\u00b7lehr\u00b7ten", "Brie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da war ein Satz von Plato angeregt,", "tokens": ["Da", "war", "ein", "Satz", "von", "Pla\u00b7to", "an\u00b7ge\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und Zweiffels-frey geh\u00f6rig widerlegt.", "tokens": ["Und", "Zweif\u00b7fels\u00b7frey", "ge\u00b7h\u00f6\u00b7rig", "wi\u00b7der\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Wie da\u00df in GOtt kein Intellect vorhanden,", "tokens": ["Wie", "da\u00df", "in", "Gott", "kein", "In\u00b7tel\u00b7lect", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "APPR", "NN", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er werde auch von gar niemand verstanden,", "tokens": ["Er", "wer\u00b7de", "auch", "von", "gar", "nie\u00b7mand", "ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Recht! dieses hat auf hohen Schulen Platz,", "tokens": ["Recht", "!", "die\u00b7ses", "hat", "auf", "ho\u00b7hen", "Schu\u00b7len", "Platz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PDS", "VAFIN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Spricht ", "tokens": ["Spricht"], "token_info": ["word"], "pos": ["NN"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Buddeus denckt, da\u00df ihn der Donner streift.", "tokens": ["Bud\u00b7deus", "denckt", ",", "da\u00df", "ihn", "der", "Don\u00b7ner", "streift", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.17": {"line.1": {"text": "Er eilt zur\u00fcck nach seinem Saal-Athen,", "tokens": ["Er", "eilt", "zu\u00b7r\u00fcck", "nach", "sei\u00b7nem", "Saa\u00b7lA\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "L\u00e4uft aber gleich dem ", "tokens": ["L\u00e4uft", "a\u00b7ber", "gleich", "dem"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Der in der Zeit dem Br\u00e4utigam gewogen,", "tokens": ["Der", "in", "der", "Zeit", "dem", "Br\u00e4u\u00b7ti\u00b7gam", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich M\u00fche gab ihm Seelen zu bestehn;", "tokens": ["Sich", "M\u00fc\u00b7he", "gab", "ihm", "See\u00b7len", "zu", "be\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "VVFIN", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und als er auch von dar nach Coburg wich,", "tokens": ["Und", "als", "er", "auch", "von", "dar", "nach", "Co\u00b7burg", "wich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PTKVZ", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Rief ", "tokens": ["Rief"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.18": {"line.1": {"text": "Ein so gehetzt und umgetriebnes Reh", "tokens": ["Ein", "so", "ge\u00b7hetzt", "und", "um\u00b7ge\u00b7trieb\u00b7nes", "Reh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVPP", "KON", "ADJA", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Sucht Ruh und Rast, und eine Wasser-Quelle.", "tokens": ["Sucht", "Ruh", "und", "Rast", ",", "und", "ei\u00b7ne", "Was\u00b7ser\u00b7Quel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "$,", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In Halle war das Wasser gut und helle.", "tokens": ["In", "Hal\u00b7le", "war", "das", "Was\u00b7ser", "gut", "und", "hel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Gnaden-Licht entdeckt ihm diese H\u00f6h,", "tokens": ["Das", "Gna\u00b7den\u00b7Licht", "ent\u00b7deckt", "ihm", "die\u00b7se", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da ward sein Geist von einem Mann erquickt,", "tokens": ["Da", "ward", "sein", "Geist", "von", "ei\u00b7nem", "Mann", "er\u00b7quickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der immer denckt, da\u00df er nur Netze flickt.", "tokens": ["Der", "im\u00b7mer", "denckt", ",", "da\u00df", "er", "nur", "Net\u00b7ze", "flickt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "$,", "KOUS", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Hier brach er aus, und zeigte munter an,", "tokens": ["Hier", "brach", "er", "aus", ",", "und", "zeig\u00b7te", "mun\u00b7ter", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er mache sich nunmehr das Creutz zur Ehre,", "tokens": ["Er", "ma\u00b7che", "sich", "nun\u00b7mehr", "das", "Creutz", "zur", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Drum brachte er der B\u00f6hmen M\u00e4rtrer Heere,", "tokens": ["Drum", "brach\u00b7te", "er", "der", "B\u00f6h\u00b7men", "M\u00e4r\u00b7trer", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ihre Zucht, gleich Luthern, auf die Bahn.", "tokens": ["Und", "ih\u00b7re", "Zucht", ",", "gleich", "Lu\u00b7thern", ",", "auf", "die", "Bahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADV", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er sagte frey: So ", "tokens": ["Er", "sag\u00b7te", "frey", ":", "So"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.20": {"line.1": {"text": "So gehe, sprach der heilge W\u00e4chter Rath,", "tokens": ["So", "ge\u00b7he", ",", "sprach", "der", "heil\u00b7ge", "W\u00e4ch\u00b7ter", "Rath", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NE", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und thue nun an deinem Ort de\u00dfgleichen,", "tokens": ["Und", "thue", "nun", "an", "dei\u00b7nem", "Ort", "de\u00df\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "----+-+-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Nach Jena hin: Du wirst den Zweck erreichen,", "tokens": ["Nach", "Je\u00b7na", "hin", ":", "Du", "wirst", "den", "Zweck", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du w\u00fcnschest viel, bereite dich zur That.", "tokens": ["Du", "w\u00fcn\u00b7schest", "viel", ",", "be\u00b7rei\u00b7te", "dich", "zur", "That", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Du k\u00f6mmst zurecht; denn der getreue ", "tokens": ["Du", "k\u00f6mmst", "zu\u00b7recht", ";", "denn", "der", "ge\u00b7treu\u00b7e"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "KON", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist bald vorbey: Nimm seinen Dienst und Sold.", "tokens": ["Ist", "bald", "vor\u00b7bey", ":", "Nimm", "sei\u00b7nen", "Dienst", "und", "Sold", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKVZ", "$.", "NE", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Buddeus trat, auf seines Meisters Wort,", "tokens": ["Bud\u00b7deus", "trat", ",", "auf", "sei\u00b7nes", "Meis\u00b7ters", "Wort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "In Jena auf, und zeugte vom Catheder,", "tokens": ["In", "Je\u00b7na", "auf", ",", "und", "zeug\u00b7te", "vom", "Cat\u00b7he\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$,", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Nur band er sich an keine Zeit und Ort:", "tokens": ["Nur", "band", "er", "sich", "an", "kei\u00b7ne", "Zeit", "und", "Ort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und da er sah\u2019, man w\u00e4re seiner satt,", "tokens": ["Und", "da", "er", "sah'", ",", "man", "w\u00e4\u00b7re", "sei\u00b7ner", "satt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "PIS", "VAFIN", "PPOSAT", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So gieng er dann in eine andre Stadt.", "tokens": ["So", "gieng", "er", "dann", "in", "ei\u00b7ne", "and\u00b7re", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Buddeus blieb des Himmel-Reichs Agent", "tokens": ["Bud\u00b7deus", "blieb", "des", "Him\u00b7mel\u00b7Reichs", "A\u00b7gent"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bey einem Volck, dem unsers K\u00f6nigs Fahnen", "tokens": ["Bey", "ei\u00b7nem", "Volck", ",", "dem", "un\u00b7sers", "K\u00f6\u00b7nigs", "Fah\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nicht anders sind, als Feindes Unterthanen,", "tokens": ["Nicht", "an\u00b7ders", "sind", ",", "als", "Fein\u00b7des", "Un\u00b7ter\u00b7tha\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAFIN", "$,", "KOUS", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da ist man gern nicht sonderlich gekennt,", "tokens": ["Da", "ist", "man", "gern", "nicht", "son\u00b7der\u00b7lich", "ge\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Man \u00f6fnet sich den Wohlgesinnten blo\u00df,", "tokens": ["Man", "\u00f6f\u00b7net", "sich", "den", "Wohl\u00b7ge\u00b7sinn\u00b7ten", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und w\u00fcrckt inde\u00df aufs K\u00f6nigs Nutzen lo\u00df.", "tokens": ["Und", "w\u00fcrckt", "in\u00b7de\u00df", "aufs", "K\u00f6\u00b7nigs", "Nut\u00b7zen", "lo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "H\u00f6rt ", "tokens": ["H\u00f6rt"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Den dritten Mann kan uns Herr ", "tokens": ["Den", "drit\u00b7ten", "Mann", "kan", "uns", "Herr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die lieben: ", "tokens": ["Die", "lie\u00b7ben", ":"], "token_info": ["word", "word", "punct"], "pos": ["ART", "ADJA", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Die zeugen ja dem ", "tokens": ["Die", "zeu\u00b7gen", "ja", "dem"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.24": {"line.1": {"text": "Wer giebet doch den Thoren Unterricht,", "tokens": ["Wer", "gie\u00b7bet", "doch", "den", "Tho\u00b7ren", "Un\u00b7ter\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich meyne hier dieselbigen Gelehrten,", "tokens": ["Ich", "mey\u00b7ne", "hier", "die\u00b7sel\u00b7bi\u00b7gen", "Ge\u00b7lehr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Christi Stuhl gern \u00fcberall zerst\u00f6hrten,", "tokens": ["Die", "Chris\u00b7ti", "Stuhl", "gern", "\u00fc\u00b7be\u00b7rall", "zer\u00b7st\u00f6hr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und kr\u00fcmmen ihm doch keinen Nagel nicht;", "tokens": ["Und", "kr\u00fcm\u00b7men", "ihm", "doch", "kei\u00b7nen", "Na\u00b7gel", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIAT", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df ihre Einigkeit sich gerne zanckt,", "tokens": ["Da\u00df", "ih\u00b7re", "Ei\u00b7nig\u00b7keit", "sich", "ger\u00b7ne", "zanckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und unsre sich des Widerspruchs bedanckt.", "tokens": ["Und", "uns\u00b7re", "sich", "des", "Wi\u00b7der\u00b7spruchs", "be\u00b7danckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Begreift ihrs nicht, ihr Academici!", "tokens": ["Be\u00b7greift", "ihrs", "nicht", ",", "ihr", "A\u00b7ca\u00b7de\u00b7mi\u00b7ci", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "PTKNEG", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Jhr, da der Spruch des Plato eingetroffen,", "tokens": ["Ihr", ",", "da", "der", "Spruch", "des", "Pla\u00b7to", "ein\u00b7ge\u00b7trof\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "ART", "NN", "ART", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df ich noch was kan von ", "tokens": ["Da\u00df", "ich", "noch", "was", "kan", "von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PWS", "VMFIN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ja, da\u00df ich ihn nicht ins Gerichte zieh,", "tokens": ["Ja", ",", "da\u00df", "ich", "ihn", "nicht", "ins", "Ge\u00b7rich\u00b7te", "zieh", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PPER", "PTKNEG", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Noch mehr! da\u00df mich des Mannes T\u00fcchtigkeit,", "tokens": ["Noch", "mehr", "!", "da\u00df", "mich", "des", "Man\u00b7nes", "T\u00fcch\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "KOUS", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Am Dienst des HErrn, noch diesen Tag erfreut.", "tokens": ["Am", "Dienst", "des", "Herrn", ",", "noch", "die\u00b7sen", "Tag", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADV", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "So sag ich euch vor dem, der alles kennt,", "tokens": ["So", "sag", "ich", "euch", "vor", "dem", ",", "der", "al\u00b7les", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich kan ihn nicht aus meinem Hertzen schliessen,", "tokens": ["Ich", "kan", "ihn", "nicht", "aus", "mei\u00b7nem", "Hert\u00b7zen", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich kan es nur allein auf die verdriessen,", "tokens": ["Mich", "kan", "es", "nur", "al\u00b7lein", "auf", "die", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "APPR", "ART", "VVINF", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die mein getreuer Heyland Feinde nennt.", "tokens": ["Die", "mein", "ge\u00b7treu\u00b7er", "Hey\u00b7land", "Fein\u00b7de", "nennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Blieb Petro nicht der Apostolsche Grund,", "tokens": ["Blieb", "Pe\u00b7tro", "nicht", "der", "A\u00b7pos\u00b7tol\u00b7sche", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ob Paulus ihm; Er Paulo widerstund?", "tokens": ["Ob", "Pau\u00b7lus", "ihm", ";", "Er", "Pau\u00b7lo", "wi\u00b7der\u00b7stund", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "$.", "PPER", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Der Richter-Spruch war zwar nicht wohl gef\u00e4llt,", "tokens": ["Der", "Rich\u00b7ter\u00b7Spruch", "war", "zwar", "nicht", "wohl", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der, was vom ", "tokens": ["Der", ",", "was", "vom"], "token_info": ["word", "punct", "word", "word"], "pos": ["ART", "$,", "PRELS", "APPRART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "In einer Schrift zur Nachbarschaft verdammte: ", "tokens": ["In", "ei\u00b7ner", "Schrift", "zur", "Nach\u00b7bar\u00b7schaft", "ver\u00b7damm\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Allein, es sey der Liebe heimgestellt.", "tokens": ["Al\u00b7lein", ",", "es", "sey", "der", "Lie\u00b7be", "heim\u00b7ge\u00b7stellt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein Nahm ist da; Ich kenne seinen Sinn,", "tokens": ["Sein", "Nahm", "ist", "da", ";", "Ich", "ken\u00b7ne", "sei\u00b7nen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sein letzter Brief ", "tokens": ["Sein", "letz\u00b7ter", "Brief"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.28": {"line.1": {"text": "Geh hin, du Knecht des HErrn in deiner Art", "tokens": ["Geh", "hin", ",", "du", "Knecht", "des", "Herrn", "in", "dei\u00b7ner", "Art"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$,", "PPER", "NN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Darinnen du nicht deines gleichen hattest!", "tokens": ["Da\u00b7rin\u00b7nen", "du", "nicht", "dei\u00b7nes", "glei\u00b7chen", "hat\u00b7test", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "PPOSAT", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Geh hin! da\u00df du dich mit den Seelen gattest,", "tokens": ["Geh", "hin", "!", "da\u00df", "du", "dich", "mit", "den", "See\u00b7len", "gat\u00b7test", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vor welche du ein treues Hertz bewahrt!", "tokens": ["Vor", "wel\u00b7che", "du", "ein", "treu\u00b7es", "Hertz", "be\u00b7wahrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich wei\u00df, wenn einst mein Geist zu Ruhe zieht,", "tokens": ["Ich", "wei\u00df", ",", "wenn", "einst", "mein", "Geist", "zu", "Ru\u00b7he", "zieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df ihn dein Hertz mit Freuden kommen sieht!", "tokens": ["Da\u00df", "ihn", "dein", "Hertz", "mit", "Freu\u00b7den", "kom\u00b7men", "sieht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Du aber steh, ", "tokens": ["Du", "a\u00b7ber", "steh", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Ich meyne dich, ", "tokens": ["Ich", "mey\u00b7ne", "dich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Dein Grund ist auch der Bau-Herr deiner Steine,", "tokens": ["Dein", "Grund", "ist", "auch", "der", "Bau\u00b7Herr", "dei\u00b7ner", "Stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "La\u00df sehen! wen du bey dir drinnen hast,", "tokens": ["La\u00df", "se\u00b7hen", "!", "wen", "du", "bey", "dir", "drin\u00b7nen", "hast", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVINF", "$.", "PWS", "PPER", "APPR", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn f\u00e4llst du hin, so spricht man: Das war Bel,", "tokens": ["Denn", "f\u00e4llst", "du", "hin", ",", "so", "spricht", "man", ":", "Das", "war", "Bel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PIS", "$.", "PDS", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und stehest du: Hier ist Jmmanuel!", "tokens": ["Und", "ste\u00b7hest", "du", ":", "Hier", "ist", "Jm\u00b7ma\u00b7nu\u00b7el", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "ADV", "VAFIN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}