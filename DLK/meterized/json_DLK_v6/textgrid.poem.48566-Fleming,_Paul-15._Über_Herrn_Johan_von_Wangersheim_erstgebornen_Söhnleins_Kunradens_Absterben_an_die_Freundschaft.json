{"textgrid.poem.48566": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "15. \u00dcber Herrn Johan von Wangersheim erstgebornen S\u00f6hnleins Kunradens Absterben an die Freundschaft", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O du wolgeplagtes Haus,", "tokens": ["O", "du", "wol\u00b7ge\u00b7plag\u00b7tes", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wievielmal doch solt du weinen", "tokens": ["wie\u00b7viel\u00b7mal", "doch", "solt", "du", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "um die abgelebten Deinen,", "tokens": ["um", "die", "ab\u00b7ge\u00b7leb\u00b7ten", "Dei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die man von dir tr\u00e4get aus,", "tokens": ["die", "man", "von", "dir", "tr\u00e4\u00b7get", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und mit ungegl\u00e4ubter Not", "tokens": ["und", "mit", "un\u00b7ge\u00b7gl\u00e4ub\u00b7ter", "Not"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mehr im Tode sein als tot?", "tokens": ["mehr", "im", "To\u00b7de", "sein", "als", "tot", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VAINF", "KOKOM", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "F\u00fcnfmal hat nun, als ich wei\u00df,", "tokens": ["F\u00fcnf\u00b7mal", "hat", "nun", ",", "als", "ich", "wei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ph\u00f6be neue H\u00f6rner krieget,", "tokens": ["Ph\u00f6\u00b7be", "neu\u00b7e", "H\u00f6r\u00b7ner", "krie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "seit das dritte Kind erlieget", "tokens": ["seit", "das", "drit\u00b7te", "Kind", "er\u00b7lie\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und tut seinen Todesschwei\u00df.", "tokens": ["und", "tut", "sei\u00b7nen", "To\u00b7des\u00b7schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Seit der Zeit f\u00fchlst du die Qual", "tokens": ["Seit", "der", "Zeit", "f\u00fchlst", "du", "die", "Qual"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "itzund nun das dritte Mal.", "tokens": ["it\u00b7zund", "nun", "das", "drit\u00b7te", "Mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Tu betr\u00fcbt und schlag die Brust,", "tokens": ["Tu", "be\u00b7tr\u00fcbt", "und", "schlag", "die", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "doch gedenk in solchem Zagen,", "tokens": ["doch", "ge\u00b7denk", "in", "sol\u00b7chem", "Za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "das dich fast kein Wort l\u00e4\u00dft sagen,", "tokens": ["das", "dich", "fast", "kein", "Wort", "l\u00e4\u00dft", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PIAT", "NN", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ob du denn so recht dran tust,", "tokens": ["ob", "du", "denn", "so", "recht", "dran", "tust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "PAV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df du dich um das du liebst", "tokens": ["da\u00df", "du", "dich", "um", "das", "du", "liebst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PRELS", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "aus der Weise so betr\u00fcbst!", "tokens": ["aus", "der", "Wei\u00b7se", "so", "be\u00b7tr\u00fcbst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Weine, was du kanst und wilst!", "tokens": ["Wei\u00b7ne", ",", "was", "du", "kanst", "und", "wilst", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VMFIN", "KON", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er wird, wo er ist, wol bleiben.", "tokens": ["Er", "wird", ",", "wo", "er", "ist", ",", "wol", "blei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PPER", "VAFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wilst denn du den Wehmut treiben,", "tokens": ["Wilst", "denn", "du", "den", "Weh\u00b7mut", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bis auch du die Erde f\u00fcllst,", "tokens": ["bis", "auch", "du", "die", "Er\u00b7de", "f\u00fcllst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "dahin Alles Fu\u00df f\u00fcr Fu\u00df,", "tokens": ["da\u00b7hin", "Al\u00b7les", "Fu\u00df", "f\u00fcr", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "wider Willen, eilen mu\u00df?", "tokens": ["wi\u00b7der", "Wil\u00b7len", ",", "ei\u00b7len", "mu\u00df", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was beseufzt man so ein Kind?", "tokens": ["Was", "be\u00b7seufzt", "man", "so", "ein", "Kind", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel' tapfrer Helden sterben,", "tokens": ["So", "viel'", "tapf\u00b7rer", "Hel\u00b7den", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "ganze L\u00e4nder die verderben,", "tokens": ["gan\u00b7ze", "L\u00e4n\u00b7der", "die", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "manche Stadt fleugt in den Wind,", "tokens": ["man\u00b7che", "Stadt", "fleugt", "in", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und wie soll ein Mensch bestehen,", "tokens": ["und", "wie", "soll", "ein", "Mensch", "be\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mu\u00df di\u00df Ganze doch vergehen?", "tokens": ["mu\u00df", "di\u00df", "Gan\u00b7ze", "doch", "ver\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Du klagst und bist doch ergetzt:", "tokens": ["Du", "klagst", "und", "bist", "doch", "er\u00b7getzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "wird schon Eines itzt verloren,", "tokens": ["wird", "schon", "Ei\u00b7nes", "itzt", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "so ist Eines schon geboren,", "tokens": ["so", "ist", "Ei\u00b7nes", "schon", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das den bittern Fall ersetzt.", "tokens": ["das", "den", "bit\u00b7tern", "Fall", "er\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So verzuckert di\u00df dein Leid", "tokens": ["So", "ver\u00b7zu\u00b7ckert", "di\u00df", "dein", "Leid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gott mit einer S\u00fc\u00dfigkeit.", "tokens": ["Gott", "mit", "ei\u00b7ner", "S\u00fc\u00b7\u00dfig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Kleiner Sohn, was schadets doch,", "tokens": ["Klei\u00b7ner", "Sohn", ",", "was", "scha\u00b7dets", "doch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWS", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df die, so dir gab das Leben,", "tokens": ["da\u00df", "die", ",", "so", "dir", "gab", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "ADV", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "dir nicht das Geleit' hilft geben", "tokens": ["dir", "nicht", "das", "Ge\u00b7leit'", "hilft", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKNEG", "ART", "NN", "VVFIN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "bis hin an dein enges Loch?", "tokens": ["bis", "hin", "an", "dein", "en\u00b7ges", "Loch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihrer Liebe Gegenwart", "tokens": ["Ih\u00b7rer", "Lie\u00b7be", "Ge\u00b7gen\u00b7wart"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wird doch mit dir eingescharrt.", "tokens": ["wird", "doch", "mit", "dir", "ein\u00b7ge\u00b7scharrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Schlafe wol! Wir Armen, wir", "tokens": ["Schla\u00b7fe", "wol", "!", "Wir", "Ar\u00b7men", ",", "wir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "$.", "PPER", "NN", "$,", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "bleiben, was wir Anfangs waren,", "tokens": ["blei\u00b7ben", ",", "was", "wir", "An\u00b7fangs", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVINF", "$,", "PRELS", "PPER", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "jung von Weisheit, alt von Jahren,", "tokens": ["jung", "von", "Weis\u00b7heit", ",", "alt", "von", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "unverst\u00e4ndig f\u00fcr und f\u00fcr,", "tokens": ["un\u00b7ver\u00b7st\u00e4n\u00b7dig", "f\u00fcr", "und", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "KON", "APPR", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "stumm am Mund', an Augen blind,", "tokens": ["stumm", "am", "Mund'", ",", "an", "Au\u00b7gen", "blind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kinder, wie wir kommen sind.", "tokens": ["Kin\u00b7der", ",", "wie", "wir", "kom\u00b7men", "sind", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}