{"textgrid.poem.39615": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Parabel vom Eulenspiegel und den Schneidern", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Unter vielen l\u00f6blichen Thaten,", "tokens": ["Un\u00b7ter", "vie\u00b7len", "l\u00f6b\u00b7li\u00b7chen", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Die Eulenspiegels Witze gerathen,", "tokens": ["Die", "Eu\u00b7len\u00b7spie\u00b7gels", "Wit\u00b7ze", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist eine von sondrer Lehr und Nutzen,", "tokens": ["Ist", "ei\u00b7ne", "von", "sond\u00b7rer", "Lehr", "und", "Nut\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie er die Schneider zurecht th\u00e4t stutzen.", "tokens": ["Wie", "er", "die", "Schnei\u00b7der", "zu\u00b7recht", "th\u00e4t", "stut\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NE", "PTKVZ", "VVFIN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Nach Rostock, der ber\u00fchmten Stadt,", "tokens": ["Nach", "Ros\u00b7tock", ",", "der", "be\u00b7r\u00fchm\u00b7ten", "Stadt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.6": {"text": "Beschied er sie zu gemeinem Rath,", "tokens": ["Be\u00b7schied", "er", "sie", "zu", "ge\u00b7mei\u00b7nem", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Er woll' ihnen etwas offenbaren,", "tokens": ["Er", "woll'", "ih\u00b7nen", "et\u00b7was", "of\u00b7fen\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "----+-+-+-", "measure": "unknown.measure.tri"}, "line.8": {"text": "Auf ewige Zeiten zu bewahren,", "tokens": ["Auf", "e\u00b7wi\u00b7ge", "Zei\u00b7ten", "zu", "be\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Da\u00df jeder es auf die Seinen vererbe,", "tokens": ["Da\u00df", "je\u00b7der", "es", "auf", "die", "Sei\u00b7nen", "ver\u00b7er\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "APPR", "ART", "PPOSS", "VVFIN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Eine gro\u00dfe Sach f\u00fcr ihr Gewerbe.", "tokens": ["Ei\u00b7ne", "gro\u00b7\u00dfe", "Sach", "f\u00fcr", "ihr", "Ge\u00b7wer\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Durch ein Ausschreiben gab er Kunde", "tokens": ["Durch", "ein", "Aus\u00b7schrei\u00b7ben", "gab", "er", "Kun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Den wendischen St\u00e4dten in die Runde,", "tokens": ["Den", "wen\u00b7di\u00b7schen", "St\u00e4d\u00b7ten", "in", "die", "Run\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "In Holstein, Pommern, bis Stettin", "tokens": ["In", "Hol\u00b7stein", ",", "Pom\u00b7mern", ",", "bis", "Stet\u00b7tin"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "$,", "NN", "$,", "KOUS", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Nach Wismar, L\u00fcbeck und Hamburg hin.", "tokens": ["Nach", "Wis\u00b7mar", ",", "L\u00fc\u00b7beck", "und", "Ham\u00b7burg", "hin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NE", "KON", "NE", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Die Schneider kamen in hellen Haufen", "tokens": ["Die", "Schnei\u00b7der", "ka\u00b7men", "in", "hel\u00b7len", "Hau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Von ihren Werkst\u00e4tten hergelaufen;", "tokens": ["Von", "ih\u00b7ren", "Werk\u00b7st\u00e4t\u00b7ten", "her\u00b7ge\u00b7lau\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Bracht' jeder Scheer', Elle, Nadel und Zwirn,", "tokens": ["Bracht'", "je\u00b7der", "Scheer'", ",", "El\u00b7le", ",", "Na\u00b7del", "und", "Zwirn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Und plagt' im voraus drob sein Gehirn,", "tokens": ["Und", "plagt'", "im", "vo\u00b7raus", "drob", "sein", "Ge\u00b7hirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "Was er doch Neues h\u00e4tt' ersonnen,", "tokens": ["Was", "er", "doch", "Neu\u00b7es", "h\u00e4tt'", "er\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Das sie noch nicht gewu\u00dft, noch begonnen.", "tokens": ["Das", "sie", "noch", "nicht", "ge\u00b7wu\u00dft", ",", "noch", "be\u00b7gon\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "PTKNEG", "VVPP", "$,", "ADV", "VVINF", "$."], "meter": "---+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "Als sie nun warteten auf dem Platz,", "tokens": ["Als", "sie", "nun", "war\u00b7te\u00b7ten", "auf", "dem", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.22": {"text": "Stieg Eulenspiegel, der schlaue Fratz,", "tokens": ["Stieg", "Eu\u00b7len\u00b7spie\u00b7gel", ",", "der", "schlau\u00b7e", "Fratz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.23": {"text": "Frei hinauf in ein hohes Haus,", "tokens": ["Frei", "hin\u00b7auf", "in", "ein", "ho\u00b7hes", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.24": {"text": "Und schaute oben zum Fenster hinaus.", "tokens": ["Und", "schau\u00b7te", "o\u00b7ben", "zum", "Fens\u00b7ter", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Ehrbare Meister vom Schneidergewerke,", "tokens": ["Ehr\u00b7ba\u00b7re", "Meis\u00b7ter", "vom", "Schnei\u00b7der\u00b7ge\u00b7wer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.26": {"text": "So sprach er, jeder h\u00f6r' und merke:", "tokens": ["So", "sprach", "er", ",", "je\u00b7der", "h\u00f6r'", "und", "mer\u00b7ke", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Habt ihr Scheer', Ell' und Nadel gut,", "tokens": ["Habt", "ihr", "Scheer'", ",", "Ell'", "und", "Na\u00b7del", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "NE", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Dazu noch Zwirn und Fingerhut,", "tokens": ["Da\u00b7zu", "noch", "Zwirn", "und", "Fin\u00b7ger\u00b7hut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "So habt ihr zu eurem Handwerk genug;", "tokens": ["So", "habt", "ihr", "zu", "eu\u00b7rem", "Hand\u00b7werk", "ge\u00b7nug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Das schafft sich jeder mit gutem Fug.", "tokens": ["Das", "schafft", "sich", "je\u00b7der", "mit", "gu\u00b7tem", "Fug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PIS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "An allem dem ist keine Kunst,", "tokens": ["An", "al\u00b7lem", "dem", "ist", "kei\u00b7ne", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ART", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Nur Eines, bitt' ich, bemerkt mit Gunst.", "tokens": ["Nur", "Ei\u00b7nes", ",", "bitt'", "ich", ",", "be\u00b7merkt", "mit", "Gunst", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "VVFIN", "PPER", "$,", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Wenn ihr die Nadel habt einge\u00f6hrt,", "tokens": ["Wenn", "ihr", "die", "Na\u00b7del", "habt", "ein\u00b7ge\u00f6hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "So macht einen Knoten, wie sich's geh\u00f6rt,", "tokens": ["So", "macht", "ei\u00b7nen", "Kno\u00b7ten", ",", "wie", "sich's", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "An's andere Ende des Fadens recht,", "tokens": ["An's", "an\u00b7de\u00b7re", "En\u00b7de", "des", "Fa\u00b7dens", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.36": {"text": "Da\u00df ihr umsonst viel Stiche nicht stecht.", "tokens": ["Da\u00df", "ihr", "um\u00b7sonst", "viel", "Sti\u00b7che", "nicht", "stecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.37": {"text": "Denn, wenn ihr nicht den Knoten kn\u00fcpft,", "tokens": ["Denn", ",", "wenn", "ihr", "nicht", "den", "Kno\u00b7ten", "kn\u00fcpft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Der Faden euch durch das Tuch hinschl\u00fcpft;", "tokens": ["Der", "Fa\u00b7den", "euch", "durch", "das", "Tuch", "hin\u00b7schl\u00fcpft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "So bringt ihr nimmer zu Stand die Nath:", "tokens": ["So", "bringt", "ihr", "nim\u00b7mer", "zu", "Stand", "die", "Nath", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "Verge\u00dft es nicht, die\u00df ist mein Rath.", "tokens": ["Ver\u00b7ge\u00dft", "es", "nicht", ",", "die\u00df", "ist", "mein", "Rath", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die Schneider sahen einander an,", "tokens": ["Die", "Schnei\u00b7der", "sa\u00b7hen", "ein\u00b7an\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sprach jeder zu seinem Nachbarsmann:", "tokens": ["Sprach", "je\u00b7der", "zu", "sei\u00b7nem", "Nach\u00b7bars\u00b7mann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Was ist das f\u00fcr eine Phantasei,", "tokens": ["Was", "ist", "das", "f\u00fcr", "ei\u00b7ne", "Phan\u00b7ta\u00b7sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df er uns ruft so weit herbei?", "tokens": ["Da\u00df", "er", "uns", "ruft", "so", "weit", "her\u00b7bei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon lange wu\u00dften wir diese Kunst,", "tokens": ["Schon", "lan\u00b7ge", "wu\u00df\u00b7ten", "wir", "die\u00b7se", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Unsre Reise war gar umsunst.", "tokens": ["Uns\u00b7re", "Rei\u00b7se", "war", "gar", "um\u00b7sunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Der Schalksnarr, als er dieses sah,", "tokens": ["Der", "Schalks\u00b7narr", ",", "als", "er", "die\u00b7ses", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach: Was vor tausend Jahren geschah,", "tokens": ["Sprach", ":", "Was", "vor", "tau\u00b7send", "Jah\u00b7ren", "ge\u00b7schah", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Des ist oft niemand eingedenk;", "tokens": ["Des", "ist", "oft", "nie\u00b7mand", "ein\u00b7ge\u00b7denk", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Drum seiner M\u00fche sich keiner kr\u00e4nk'.", "tokens": ["Drum", "sei\u00b7ner", "M\u00fc\u00b7he", "sich", "kei\u00b7ner", "kr\u00e4nk'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "PRF", "PIS", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Auch meint' er, sollten sie sich sch\u00e4men,", "tokens": ["Auch", "meint'", "er", ",", "soll\u00b7ten", "sie", "sich", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Statt Danks mit Unwillen aufzunehmen", "tokens": ["Statt", "Danks", "mit", "Un\u00b7wil\u00b7len", "auf\u00b7zu\u00b7neh\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "NN", "VVIZU"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Die Treu, so er zum Handwerk tr\u00fcge.", "tokens": ["Die", "Treu", ",", "so", "er", "zum", "Hand\u00b7werk", "tr\u00fc\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So schlich er sich fort auf neue Z\u00fcge.", "tokens": ["So", "schlich", "er", "sich", "fort", "auf", "neu\u00b7e", "Z\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Die Schneider schalten zwar mit Recht", "tokens": ["Die", "Schnei\u00b7der", "schal\u00b7ten", "zwar", "mit", "Recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Eulenspiegel, den schlimmen Knecht,", "tokens": ["Auf", "Eu\u00b7len\u00b7spie\u00b7gel", ",", "den", "schlim\u00b7men", "Knecht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch wollt ihr erw\u00e4gen des Spruches Sinn,", "tokens": ["Doch", "wollt", "ihr", "er\u00b7w\u00e4\u00b7gen", "des", "Spru\u00b7ches", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "So bringt er vielleicht euch noch Gewinn.", "tokens": ["So", "bringt", "er", "viel\u00b7leicht", "euch", "noch", "Ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPER", "ADV", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ich wei\u00df wohl manchen, dem's th\u00e4t vonn\u00f6then,", "tokens": ["Ich", "wei\u00df", "wohl", "man\u00b7chen", ",", "dem's", "th\u00e4t", "von\u00b7n\u00f6\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVINF", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da\u00df wir nach Rostock ihn entb\u00f6ten,", "tokens": ["Da\u00df", "wir", "nach", "Ros\u00b7tock", "ihn", "ent\u00b7b\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "'s giebt Leute, die ihr alle kennt,", "tokens": ["'s", "giebt", "Leu\u00b7te", ",", "die", "ihr", "al\u00b7le", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "PRELS", "PPER", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Der Weltweisheit Lehrer man sie nennt,", "tokens": ["Der", "Welt\u00b7weis\u00b7heit", "Leh\u00b7rer", "man", "sie", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die sind in diesen Tagen bem\u00fcht,", "tokens": ["Die", "sind", "in", "die\u00b7sen", "Ta\u00b7gen", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Wo Wi\u00dfenschaft und Kunst erbl\u00fcht,", "tokens": ["Wo", "Wi\u00b7\u00dfen\u00b7schaft", "und", "Kunst", "er\u00b7bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Aus mancherlei Lappen von geistigen Kleidern", "tokens": ["Aus", "man\u00b7cher\u00b7lei", "Lap\u00b7pen", "von", "geis\u00b7ti\u00b7gen", "Klei\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.12": {"text": "Dem alten Adam 'nen Rock zu schneidern.", "tokens": ["Dem", "al\u00b7ten", "A\u00b7dam", "'nen", "Rock", "zu", "schnei\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+----+-+-", "measure": "dactylic.init"}, "line.13": {"text": "Sie nehmen die Brille nach Schneiderart", "tokens": ["Sie", "neh\u00b7men", "die", "Bril\u00b7le", "nach", "Schnei\u00b7der\u00b7art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Vor die Augenbraunen, struppig behaart,", "tokens": ["Vor", "die", "Au\u00b7gen\u00b7brau\u00b7nen", ",", "strup\u00b7pig", "be\u00b7haart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.15": {"text": "Sie kauern auf einem Tische hoch,", "tokens": ["Sie", "kau\u00b7ern", "auf", "ei\u00b7nem", "Ti\u00b7sche", "hoch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Und stecken die F\u00fc\u00dfe durch das Loch,", "tokens": ["Und", "ste\u00b7cken", "die", "F\u00fc\u00b7\u00dfe", "durch", "das", "Loch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Sie halten die Nadel zur Nasenspitze,", "tokens": ["Sie", "hal\u00b7ten", "die", "Na\u00b7del", "zur", "Na\u00b7sen\u00b7spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Um recht zu treffen die schmale Ritze,", "tokens": ["Um", "recht", "zu", "tref\u00b7fen", "die", "schma\u00b7le", "Rit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "PTKZU", "VVINF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Sie ziehn den Faden hindurch gar fein,", "tokens": ["Sie", "ziehn", "den", "Fa\u00b7den", "hin\u00b7durch", "gar", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Das Kn\u00f6tlein verge\u00dfen sie allein.", "tokens": ["Das", "Kn\u00f6t\u00b7lein", "ver\u00b7ge\u00b7\u00dfen", "sie", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "So n\u00e4h'n sie, da\u00df ihnen der Schwei\u00df ausbricht,", "tokens": ["So", "n\u00e4h'n", "sie", ",", "da\u00df", "ih\u00b7nen", "der", "Schwei\u00df", "aus\u00b7bricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.22": {"text": "So will die Nath doch f\u00f6rdern nicht,", "tokens": ["So", "will", "die", "Nath", "doch", "f\u00f6r\u00b7dern", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Und nimmer will sich der Mantel gestalten,", "tokens": ["Und", "nim\u00b7mer", "will", "sich", "der", "Man\u00b7tel", "ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Der Leib und Seele zusammen soll halten.", "tokens": ["Der", "Leib", "und", "See\u00b7le", "zu\u00b7sam\u00b7men", "soll", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Die Nadel hei\u00dfet Logica,", "tokens": ["Die", "Na\u00b7del", "hei\u00b7\u00dfet", "Lo\u00b7gi\u00b7ca", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Der Faden Metaphysica,", "tokens": ["Der", "Fa\u00b7den", "Me\u00b7ta\u00b7phy\u00b7si\u00b7ca", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Und was sothanes Kn\u00f6tlein bedeute,", "tokens": ["Und", "was", "sot\u00b7ha\u00b7nes", "Kn\u00f6t\u00b7lein", "be\u00b7deu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Das merken nun schon die gescheiten Leute.", "tokens": ["Das", "mer\u00b7ken", "nun", "schon", "die", "ge\u00b7schei\u00b7ten", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Die Weltweisen aber sp\u00fcren's nicht,", "tokens": ["Die", "Welt\u00b7wei\u00b7sen", "a\u00b7ber", "sp\u00fc\u00b7ren's", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PTKNEG", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.30": {"text": "Weil's ihnen an t\u00fcchtigem Sinn gebricht.", "tokens": ["Weil's", "ih\u00b7nen", "an", "t\u00fcch\u00b7ti\u00b7gem", "Sinn", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "O Eulenspiegel, weiser Narr!", "tokens": ["O", "Eu\u00b7len\u00b7spie\u00b7gel", ",", "wei\u00b7ser", "Narr", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schau auf der heutigen Welt Wirrwarr.", "tokens": ["Schau", "auf", "der", "heu\u00b7ti\u00b7gen", "Welt", "Wirr\u00b7warr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Kannst du vom Grab' erstehn, so komm,", "tokens": ["Kannst", "du", "vom", "Grab'", "er\u00b7stehn", ",", "so", "komm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVINF", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mache durch Spott die Narren fromm.", "tokens": ["Und", "ma\u00b7che", "durch", "Spott", "die", "Nar\u00b7ren", "fromm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}}}}