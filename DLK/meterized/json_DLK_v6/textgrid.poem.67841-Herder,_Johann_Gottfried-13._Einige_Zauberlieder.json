{"textgrid.poem.67841": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "13. Einige Zauberlieder", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Komm hinan den gelben Sand,", "tokens": ["Komm", "hi\u00b7nan", "den", "gel\u00b7ben", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Dann wechsle Hand!", "tokens": ["Dann", "wechs\u00b7le", "Hand", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "---+", "measure": "unknown.measure.single"}, "line.3": {"text": "Hast geliebt du und gek\u00fcst,", "tokens": ["Hast", "ge\u00b7liebt", "du", "und", "ge\u00b7k\u00fcst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "PPER", "KON", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sanft die Woge ist:", "tokens": ["Sanft", "die", "Wo\u00b7ge", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wandl' umher und komm hervor!", "tokens": ["Wandl'", "um\u00b7her", "und", "komm", "her\u00b7vor", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Geisterchen, ihr singt im Chor:", "tokens": ["Geis\u00b7ter\u00b7chen", ",", "ihr", "singt", "im", "Chor", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.2": {"line.1": {"text": "ChOR DER GEISTER ", "tokens": ["ChOR", "DeR", "GeIS\u00b7TER"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Horch, horch, Wau \u2013 Wau!", "tokens": ["Horch", ",", "horch", ",", "Wau", "\u2013", "Wau", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "$,", "NN", "$(", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Der Wachhund bellt \u2013 Wau \u2013 Wau!", "tokens": ["Der", "Wach\u00b7hund", "bellt", "\u2013", "Wau", "\u2013", "Wau", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "NN", "$(", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "ArIEL.", "tokens": ["A\u00b7rIEL", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.5": {"line.1": {"text": "Horch, horch, ich h\u00f6r'", "tokens": ["Horch", ",", "horch", ",", "ich", "h\u00f6r'"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$,", "VVIMP", "$,", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Der Hahn kr\u00e4ht; munter kr\u00e4het er:", "tokens": ["Der", "Hahn", "kr\u00e4ht", ";", "mun\u00b7ter", "kr\u00e4\u00b7het", "er", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ADJD", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kriki!", "tokens": ["Kri\u00b7ki", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.6": {"line.1": {"text": "FeRDINAND.", "tokens": ["FeR\u00b7DI\u00b7NAND", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Wo sollte die Musik doch seyn? in der Luft?", "tokens": ["Wo", "soll\u00b7te", "die", "Mu\u00b7sik", "doch", "seyn", "?", "in", "der", "Luft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "ADV", "VAINF", "$.", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "auf Erden? \u2013 Und sie schweigt! Gewi\u00df sie dient", "tokens": ["auf", "Er\u00b7den", "?", "\u2013", "Und", "sie", "schweigt", "!", "Ge\u00b7wi\u00df", "sie", "dient"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$.", "$(", "KON", "PPER", "VVFIN", "$.", "PTKANT", "PPER", "VVFIN"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "ein'm Gotte dieser Insel. Ich sa\u00df da,", "tokens": ["ein'm", "Got\u00b7te", "die\u00b7ser", "In\u00b7sel", ".", "Ich", "sa\u00df", "da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "$.", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "auf einer Sandbank, weinete ins Meer", "tokens": ["auf", "ei\u00b7ner", "Sand\u00b7bank", ",", "wei\u00b7ne\u00b7te", "ins", "Meer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "schlich auf dem Wasser sie heran, mir bei,", "tokens": ["schlich", "auf", "dem", "Was\u00b7ser", "sie", "he\u00b7ran", ",", "mir", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PPER", "PTKVZ", "$,", "PPER", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "und Meeres Wut, und Toben meiner Brust", "tokens": ["und", "Mee\u00b7res", "Wut", ",", "und", "To\u00b7ben", "mei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "NN", "$,", "KON", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "ward stille mit dem s\u00fcssen Sange. Da", "tokens": ["ward", "stil\u00b7le", "mit", "dem", "s\u00fcs\u00b7sen", "San\u00b7ge", ".", "Da"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$.", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "zog sie mich fort, ich muste folgen, und", "tokens": ["zog", "sie", "mich", "fort", ",", "ich", "mus\u00b7te", "fol\u00b7gen", ",", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PRF", "PTKVZ", "$,", "PPER", "VMFIN", "VVINF", "$,", "KON"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "nun schweigt sie! \u2013 nun beginnt sie wieder: \u2013", "tokens": ["nun", "schweigt", "sie", "!", "\u2013", "nun", "be\u00b7ginnt", "sie", "wie\u00b7der", ":", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "ArIEL ", "tokens": ["A\u00b7rIEL"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.9": {"line.1": {"text": "F\u00fcnf Faden tief der Vater dein", "tokens": ["F\u00fcnf", "Fa\u00b7den", "tief", "der", "Va\u00b7ter", "dein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADJD", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Liegt; sein Auge Perle ward,", "tokens": ["Liegt", ";", "sein", "Au\u00b7ge", "Per\u00b7le", "ward", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPOSAT", "NN", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zu Korallen sein Gebein", "tokens": ["Zu", "Ko\u00b7ral\u00b7len", "sein", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Liegt im Meeresgrund' erstarrt;", "tokens": ["Liegt", "im", "Mee\u00b7res\u00b7grund'", "er\u00b7starrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Unversehret, reich und sch\u00f6n", "tokens": ["Un\u00b7ver\u00b7seh\u00b7ret", ",", "reich", "und", "sch\u00f6n"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist er verwandelt da zu sehn,", "tokens": ["Ist", "er", "ver\u00b7wan\u00b7delt", "da", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Stund' auf Stunde l\u00e4uten ihm", "tokens": ["Stund'", "auf", "Stun\u00b7de", "l\u00e4u\u00b7ten", "ihm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nymphen die Todtenglock' \u2013 ich h\u00f6r sie \u2013 Bim!", "tokens": ["Nym\u00b7phen", "die", "Tod\u00b7ten\u00b7glock'", "\u2013", "ich", "h\u00f6r", "sie", "\u2013", "Bim", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "NN", "$(", "PPER", "VVFIN", "PPER", "$(", "NE", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.10": {"line.1": {"text": "ChOR.", "tokens": ["ChOR", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.11": {"line.1": {"text": "Bim! Bim!", "tokens": ["Bim", "!", "Bim", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.12": {"line.1": {"text": "FeRDINAND.", "tokens": ["FeR\u00b7DI\u00b7NAND", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.13": {"line.1": {"text": "Es denkt an mein'n ertrunknen Vater. Nein,", "tokens": ["Es", "denkt", "an", "mein'n", "er\u00b7trunk\u00b7nen", "Va\u00b7ter", ".", "Nein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$.", "PTKANT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "das ist nicht Menschenwerk, kein Erdenton! \u2013", "tokens": ["das", "ist", "nicht", "Men\u00b7schen\u00b7werk", ",", "kein", "Er\u00b7den\u00b7ton", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "NN", "$,", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nun h\u00f6r' ichs droben mir \u2013", "tokens": ["Nun", "h\u00f6r'", "ichs", "dro\u00b7ben", "mir", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVFIN", "PPER", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "PrOSPERO.", "tokens": ["PrOS\u00b7PE\u00b7RO", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.15": {"line.1": {"text": "Zieh, Tochter, auf", "tokens": ["Zieh", ",", "Toch\u00b7ter", ",", "auf"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "die weinend zugezognen Augenlieder!", "tokens": ["die", "wei\u00b7nend", "zu\u00b7ge\u00b7zog\u00b7nen", "Au\u00b7gen\u00b7lie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was siehst du dort?", "tokens": ["Was", "siehst", "du", "dort", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "MiRANDA.", "tokens": ["Mi\u00b7RANDA", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.17": {"line.1": {"text": "Was ists? ein Geist?", "tokens": ["Was", "ists", "?", "ein", "Geist", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$.", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Gott, wie blickts vor sich hin! o glaubt mir, Herr,", "tokens": ["Gott", ",", "wie", "blickts", "vor", "sich", "hin", "!", "o", "glaubt", "mir", ",", "Herr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VVFIN", "APPR", "PRF", "PTKVZ", "$.", "FM", "VVFIN", "PPER", "$,", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "es ist ein sch\u00f6nes Wesen \u2013 Ab'r ein Geist! \u2013", "tokens": ["es", "ist", "ein", "sch\u00f6\u00b7nes", "We\u00b7sen", "\u2013", "Ab'r", "ein", "Geist", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "PrOSPERO.", "tokens": ["PrOS\u00b7PE\u00b7RO", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.19": {"line.1": {"text": "Nein, Kind, es i\u00dft und schl\u00e4ft und hat so Sinne", "tokens": ["Nein", ",", "Kind", ",", "es", "i\u00dft", "und", "schl\u00e4ft", "und", "hat", "so", "Sin\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VAFIN", "ADV", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wie wir, grad so. Der Art'ge, den du siehst,", "tokens": ["wie", "wir", ",", "grad", "so", ".", "Der", "Art'\u00b7ge", ",", "den", "du", "siehst", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "ADV", "ADV", "$.", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "war auch im Schifbruch, und h\u00e4tt' ihm nicht Gram,", "tokens": ["war", "auch", "im", "Schif\u00b7bruch", ",", "und", "h\u00e4tt'", "ihm", "nicht", "Gram", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "$,", "KON", "VAFIN", "PPER", "PTKNEG", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "(gram ist der Krebs der Sch\u00f6nheit) seine Wange", "tokens": ["(", "gram", "ist", "der", "Krebs", "der", "Sch\u00f6n\u00b7heit", ")", "sei\u00b7ne", "Wan\u00b7ge"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "NE", "VAFIN", "ART", "NN", "ART", "NN", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "gebleicht, du k\u00f6nntest sch\u00f6n ihn nennen. Er hat", "tokens": ["ge\u00b7bleicht", ",", "du", "k\u00f6nn\u00b7test", "sch\u00f6n", "ihn", "nen\u00b7nen", ".", "Er", "hat"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "PPER", "VMFIN", "ADJD", "PPER", "VVINF", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "verloren seine Kammeraden und sucht sie. \u2013", "tokens": ["ver\u00b7lo\u00b7ren", "sei\u00b7ne", "Kam\u00b7me\u00b7ra\u00b7den", "und", "sucht", "sie", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}}, "stanza.20": {"line.1": {"text": "MiRANDA.", "tokens": ["Mi\u00b7RANDA", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.21": {"line.1": {"text": "Ich m\u00f6cht' ihn g\u00f6ttlich nennen; denn f\u00fcrwahr,", "tokens": ["Ich", "m\u00f6cht'", "ihn", "g\u00f6tt\u00b7lich", "nen\u00b7nen", ";", "denn", "f\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$.", "KON", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "nichts sah ich in der Natur so Edles.", "tokens": ["nichts", "sah", "ich", "in", "der", "Na\u00b7tur", "so", "Ed\u00b7les", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "PrOSPERO.", "tokens": ["PrOS\u00b7PE\u00b7RO", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.23": {"line.1": {"text": "Wohl!", "tokens": ["Wohl", "!"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "-", "measure": "single.down"}}}}}