{"textgrid.poem.26698": {"metadata": {"author": {"name": "Schiller, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Beklagen soll ich dich? Mit Tr\u00e4nen bittrer Reue", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Beklagen soll ich dich? Mit Tr\u00e4nen bittrer Reue", "tokens": ["Be\u00b7kla\u00b7gen", "soll", "ich", "dich", "?", "Mit", "Tr\u00e4\u00b7nen", "bit\u00b7trer", "Reu\u00b7e"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PRF", "$.", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wird Hymens Band von dir verflucht?", "tokens": ["Wird", "Hy\u00b7mens", "Band", "von", "dir", "ver\u00b7flucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum? Weil deine Ungetreue", "tokens": ["Wa\u00b7rum", "?", "Weil", "dei\u00b7ne", "Un\u00b7ge\u00b7treu\u00b7e"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PWAV", "$.", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In eines andern Armen sucht,", "tokens": ["In", "ei\u00b7nes", "an\u00b7dern", "Ar\u00b7men", "sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was ihr die deinigen versagen?", "tokens": ["Was", "ihr", "die", "dei\u00b7ni\u00b7gen", "ver\u00b7sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "PPOSS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Freund, h\u00f6re fremde Leiden an", "tokens": ["Freund", ",", "h\u00f6\u00b7re", "frem\u00b7de", "Lei\u00b7den", "an"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und lerne ", "tokens": ["Und", "ler\u00b7ne"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Dich schmerzt, da\u00df sich in deine Rechte", "tokens": ["Dich", "schmerzt", ",", "da\u00df", "sich", "in", "dei\u00b7ne", "Rech\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein zweiter teilt? \u2013 Beneidenswerter Mann!", "tokens": ["Ein", "zwei\u00b7ter", "teilt", "?", "\u2013", "Be\u00b7nei\u00b7dens\u00b7wer\u00b7ter", "Mann", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$(", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vom Belt bis an der Mosel Strand,", "tokens": ["Vom", "Belt", "bis", "an", "der", "Mo\u00b7sel", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis an die Apenninenwand,", "tokens": ["Bis", "an", "die", "A\u00b7pen\u00b7ni\u00b7nen\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis in die Vaterstadt der Moden", "tokens": ["Bis", "in", "die", "Va\u00b7ter\u00b7stadt", "der", "Mo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird sie in allen Buden feil geboten,", "tokens": ["Wird", "sie", "in", "al\u00b7len", "Bu\u00b7den", "feil", "ge\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PIAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Mu\u00df sie auf Diligencen, Paketbooten", "tokens": ["Mu\u00df", "sie", "auf", "Di\u00b7li\u00b7gen\u00b7cen", ",", "Pa\u00b7ket\u00b7boo\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "PPER", "APPR", "NN", "$,", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "Von jedem Schulfuchs, jedem Hasen", "tokens": ["Von", "je\u00b7dem", "Schul\u00b7fuchs", ",", "je\u00b7dem", "Ha\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Kunstrichterlich sich mustern lassen,", "tokens": ["Kuns\u00b7trich\u00b7ter\u00b7lich", "sich", "mus\u00b7tern", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mu\u00df sie der Brille des Philisters stehn", "tokens": ["Mu\u00df", "sie", "der", "Bril\u00b7le", "des", "Phi\u00b7lis\u00b7ters", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und, wie's ein schmutzger Aristarch befohlen,", "tokens": ["Und", ",", "wie's", "ein", "schmutz\u00b7ger", "A\u00b7rist\u00b7arch", "be\u00b7foh\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Auf Blumen oder hei\u00dfen Kohlen", "tokens": ["Auf", "Blu\u00b7men", "o\u00b7der", "hei\u00b7\u00dfen", "Koh\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Zum Ehrentempel oder Pranger gehn.", "tokens": ["Zum", "Eh\u00b7ren\u00b7tem\u00b7pel", "o\u00b7der", "Pran\u00b7ger", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ein Leipziger \u2013 da\u00df Gott ihn strafen wollte!", "tokens": ["Ein", "Leip\u00b7zi\u00b7ger", "\u2013", "da\u00df", "Gott", "ihn", "stra\u00b7fen", "woll\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOUS", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Nimmt topographisch sie wie eine Festung auf", "tokens": ["Nimmt", "to\u00b7po\u00b7gra\u00b7phisch", "sie", "wie", "ei\u00b7ne", "Fes\u00b7tung", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PPER", "KOKOM", "ART", "NN", "APPR"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.16": {"text": "Und bietet Gegenden dem Publikum zu Kauf,", "tokens": ["Und", "bie\u00b7tet", "Ge\u00b7gen\u00b7den", "dem", "Pub\u00b7li\u00b7kum", "zu", "Kauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wovon ich billig doch ", "tokens": ["Wo\u00b7von", "ich", "bil\u00b7lig", "doch"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADJD", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wei\u00df deiner ", "tokens": ["Wei\u00df", "dei\u00b7ner"], "token_info": ["word", "word"], "pos": ["NN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Sie wei\u00df ", "tokens": ["Sie", "wei\u00df"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Du klagst, da\u00df im Parterr' und an den Pharotischen,", "tokens": ["Du", "klagst", ",", "da\u00df", "im", "Par\u00b7terr'", "und", "an", "den", "Pha\u00b7ro\u00b7ti\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPRART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Erscheinst du, alle Zungen zischen?", "tokens": ["Er\u00b7scheinst", "du", ",", "al\u00b7le", "Zun\u00b7gen", "zi\u00b7schen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O Mann des Gl\u00fccks! Wer einmal das von sich", "tokens": ["O", "Mann", "des", "Gl\u00fccks", "!", "Wer", "ein\u00b7mal", "das", "von", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "NN", "$.", "PWS", "ADV", "ART", "APPR", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zu r\u00fchmen h\u00e4tte! \u2013 Mich, Herr Bruder, mich,", "tokens": ["Zu", "r\u00fch\u00b7men", "h\u00e4t\u00b7te", "!", "\u2013", "Mich", ",", "Herr", "Bru\u00b7der", ",", "mich", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "$.", "$(", "PPER", "$,", "NN", "NN", "$,", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Beschert mir endlich eine Molkenkur", "tokens": ["Be\u00b7schert", "mir", "end\u00b7lich", "ei\u00b7ne", "Mol\u00b7ken\u00b7kur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Das rare Gl\u00fcck \u2013 den Platz an ihrer Linken,", "tokens": ["Das", "ra\u00b7re", "Gl\u00fcck", "\u2013", "den", "Platz", "an", "ih\u00b7rer", "Lin\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Auf meine stolze H\u00e4lfte nur.", "tokens": ["Auf", "mei\u00b7ne", "stol\u00b7ze", "H\u00e4lf\u00b7te", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Kaum ist der Morgen grau,", "tokens": ["Kaum", "ist", "der", "Mor\u00b7gen", "grau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "So kracht die Treppe schon von blau und gelben R\u00f6cken,", "tokens": ["So", "kracht", "die", "Trep\u00b7pe", "schon", "von", "blau", "und", "gel\u00b7ben", "R\u00f6\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit Briefen, Ballen, unfrankierten P\u00e4cken,", "tokens": ["Mit", "Brie\u00b7fen", ",", "Bal\u00b7len", ",", "un\u00b7fran\u00b7kier\u00b7ten", "P\u00e4\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Signiert: An die ", "tokens": ["Sig\u00b7niert", ":", "An", "die"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$.", "APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Sie schl\u00e4ft so s\u00fc\u00df! \u2013 Doch ", "tokens": ["Sie", "schl\u00e4ft", "so", "s\u00fc\u00df", "!", "\u2013", "Doch"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$.", "$(", "KON"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "\u00bbdie Zeitungen, Madam, aus Jena und Berlin!\u00ab", "tokens": ["\u00bb", "die", "Zei\u00b7tun\u00b7gen", ",", "Ma\u00b7dam", ",", "aus", "Je\u00b7na", "und", "Ber\u00b7lin", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$,", "NN", "$,", "APPR", "NE", "KON", "NE", "$.", "$("], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Rasch \u00f6ffnet sich das Aug der holden Schl\u00e4ferin,", "tokens": ["Rasch", "\u00f6ff\u00b7net", "sich", "das", "Aug", "der", "hol\u00b7den", "Schl\u00e4\u00b7fe\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PRF", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ihr erster Blick f\u00e4llt \u2013 auf Rezensionen.", "tokens": ["Ihr", "ers\u00b7ter", "Blick", "f\u00e4llt", "\u2013", "auf", "Re\u00b7zen\u00b7si\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$(", "APPR", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Das sch\u00f6ne blaue Auge! \u2013 ", "tokens": ["Das", "sch\u00f6\u00b7ne", "blau\u00b7e", "Au\u00b7ge", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Nicht ", "tokens": ["Nicht"], "token_info": ["word"], "pos": ["PTKNEG"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "(laut h\u00f6rt man in der Kinderstube weinen)", "tokens": ["(", "laut", "h\u00f6rt", "man", "in", "der", "Kin\u00b7der\u00b7stu\u00b7be", "wei\u00b7nen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PIS", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Sie legt es endlich weg und fr\u00e4gt nach ihren Kleinen.", "tokens": ["Sie", "legt", "es", "end\u00b7lich", "weg", "und", "fr\u00e4gt", "nach", "ih\u00b7ren", "Klei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die Toilette wartet schon,", "tokens": ["Die", "To\u00b7i\u00b7let\u00b7te", "war\u00b7tet", "schon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch halbe Blicke nur begl\u00fccken ihren Spiegel.", "tokens": ["Doch", "hal\u00b7be", "Bli\u00b7cke", "nur", "be\u00b7gl\u00fc\u00b7cken", "ih\u00b7ren", "Spie\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein m\u00fcrrisch ungeduldig Drohn", "tokens": ["Ein", "m\u00fcr\u00b7risch", "un\u00b7ge\u00b7dul\u00b7dig", "Drohn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gibt der erschrocknen Zofe Fl\u00fcgel.", "tokens": ["Gibt", "der", "er\u00b7schrock\u00b7nen", "Zo\u00b7fe", "Fl\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von ihrem Putztisch sind die Grazien entflohn,", "tokens": ["Von", "ih\u00b7rem", "Putz\u00b7tisch", "sind", "die", "Gra\u00b7zi\u00b7en", "ent\u00b7flohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und an der Stelle holde Amorinen", "tokens": ["Und", "an", "der", "Stel\u00b7le", "hol\u00b7de", "A\u00b7mo\u00b7ri\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Sieht man Erinnyen den Lockenbau bedienen.", "tokens": ["Sieht", "man", "E\u00b7rin\u00b7ny\u00b7en", "den", "Lo\u00b7cken\u00b7bau", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Karossen rasseln jetzt heran,", "tokens": ["Ka\u00b7ros\u00b7sen", "ras\u00b7seln", "jetzt", "he\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Mietlakaien springen von den Tritten,", "tokens": ["Und", "Miet\u00b7la\u00b7kai\u00b7en", "sprin\u00b7gen", "von", "den", "Trit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dem d\u00fcftenden Abb\u00e9, dem Reichsbaron, dem Briten,", "tokens": ["Dem", "d\u00fcf\u00b7ten\u00b7den", "Ab\u00b7b\u00e9", ",", "dem", "Reichs\u00b7ba\u00b7ron", ",", "dem", "Bri\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Der \u2013 nur nichts Deutsches lesen kann,", "tokens": ["Der", "\u2013", "nur", "nichts", "Deut\u00b7sches", "le\u00b7sen", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ADV", "PIS", "ADJA", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gro\u00dfing und Compagnie, dem Z** Wundermann", "tokens": ["Gro\u00b7\u00dfing", "und", "Com\u00b7pag\u00b7nie", ",", "dem", "Z", "*", "*", "Wun\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word"], "pos": ["NN", "KON", "NN", "$,", "ART", "NN", "XY", "XY", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Geh\u00f6r bei der ", "tokens": ["Ge\u00b7h\u00f6r", "bei", "der"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "ART"], "meter": "-+--", "measure": "dactylic.init"}, "line.7": {"text": "Ein Ding, das demutsvoll sich in die Ecke dr\u00fcckt", "tokens": ["Ein", "Ding", ",", "das", "de\u00b7muts\u00b7voll", "sich", "in", "die", "E\u00b7cke", "dr\u00fcckt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "PRF", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Ehmann hei\u00dft, wird vornehm angeblickt.", "tokens": ["Und", "Eh\u00b7mann", "hei\u00dft", ",", "wird", "vor\u00b7nehm", "an\u00b7ge\u00b7blickt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Hier darf ihr \u2013 wird ", "tokens": ["Hier", "darf", "ihr", "\u2013", "wird"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "VMFIN", "PPER", "$(", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Der d\u00fcmmste ", "tokens": ["Der", "d\u00fcmms\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Und darfs vor meinem Angesicht!", "tokens": ["Und", "darfs", "vor", "mei\u00b7nem", "An\u00b7ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ich steh dabei, und, will ich artig hei\u00dfen,", "tokens": ["Ich", "steh", "da\u00b7bei", ",", "und", ",", "will", "ich", "ar\u00b7tig", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "$,", "KON", "$,", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Mu\u00df ich ihn bitten mitzuspeisen.", "tokens": ["Mu\u00df", "ich", "ihn", "bit\u00b7ten", "mit\u00b7zu\u00b7spei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Bei Tafel, Freund, beginnt erst meine Not,", "tokens": ["Bei", "Ta\u00b7fel", ",", "Freund", ",", "be\u00b7ginnt", "erst", "mei\u00b7ne", "Not", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da geht es \u00fcber meine Flaschen,", "tokens": ["Da", "geht", "es", "\u00fc\u00b7ber", "mei\u00b7ne", "Fla\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Weinen von Burgund, die ", "tokens": ["Mit", "Wei\u00b7nen", "von", "Bur\u00b7gund", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "NN", "APPR", "NE", "$,", "PRELS"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Mu\u00df ich die Kehlen ihrer Lober waschen.", "tokens": ["Mu\u00df", "ich", "die", "Keh\u00b7len", "ih\u00b7rer", "Lo\u00b7ber", "wa\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mein schwer verdienter Bissen Brot", "tokens": ["Mein", "schwer", "ver\u00b7dien\u00b7ter", "Bis\u00b7sen", "Brot"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird hungriger Schmarotzer Beute;", "tokens": ["Wird", "hung\u00b7ri\u00b7ger", "Schma\u00b7rot\u00b7zer", "Beu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "NN", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "O diese leidige, vermaledeite", "tokens": ["O", "die\u00b7se", "lei\u00b7di\u00b7ge", ",", "ver\u00b7ma\u00b7le\u00b7dei\u00b7te"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "PDAT", "ADJA", "$,", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Den Wurm an alle Finger, welche drucken!", "tokens": ["Den", "Wurm", "an", "al\u00b7le", "Fin\u00b7ger", ",", "wel\u00b7che", "dru\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$,", "PRELS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Was, meinst du, sei mein Dank? Ein Achselzucken,", "tokens": ["Was", ",", "meinst", "du", ",", "sei", "mein", "Dank", "?", "Ein", "Ach\u00b7sel\u00b7zu\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPOSAT", "NN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ein Mienenspiel, ein ungeschliffenes Beklagen;", "tokens": ["Ein", "Mie\u00b7nen\u00b7spiel", ",", "ein", "un\u00b7ge\u00b7schlif\u00b7fe\u00b7nes", "Be\u00b7kla\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.11": {"text": "Err\u00e4tst dus nicht? O ich verstehs genau!", "tokens": ["Er\u00b7r\u00e4tst", "dus", "nicht", "?", "O", "ich", "ver\u00b7stehs", "ge\u00b7nau", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PTKNEG", "$.", "NE", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Da\u00df diesen Brillant von einer Frau", "tokens": ["Da\u00df", "die\u00b7sen", "Bril\u00b7lant", "von", "ei\u00b7ner", "Frau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Ein solcher Pavian davongetragen.", "tokens": ["Ein", "sol\u00b7cher", "Pa\u00b7vi\u00b7an", "da\u00b7von\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Der Fr\u00fchling kommt. Auf Wiesen und auf Feldern", "tokens": ["Der", "Fr\u00fch\u00b7ling", "kommt", ".", "Auf", "Wie\u00b7sen", "und", "auf", "Fel\u00b7dern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Streut die Natur den bunten Teppich hin,", "tokens": ["Streut", "die", "Na\u00b7tur", "den", "bun\u00b7ten", "Tep\u00b7pich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Die Blumen kleiden sich in angenehmes Gr\u00fcn,", "tokens": ["Die", "Blu\u00b7men", "klei\u00b7den", "sich", "in", "an\u00b7ge\u00b7neh\u00b7mes", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Lerche singt, es lebt in allen W\u00e4ldern.", "tokens": ["Die", "Ler\u00b7che", "singt", ",", "es", "lebt", "in", "al\u00b7len", "W\u00e4l\u00b7dern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "\u2013 Ihr ist der Fr\u00fchling wonneleer.", "tokens": ["\u2013", "Ihr", "ist", "der", "Fr\u00fch\u00b7ling", "won\u00b7ne\u00b7leer", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die S\u00e4ngerin der s\u00fc\u00dfesten Gef\u00fchle,", "tokens": ["Die", "S\u00e4n\u00b7ge\u00b7rin", "der", "s\u00fc\u00b7\u00dfes\u00b7ten", "Ge\u00b7f\u00fch\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Der sch\u00f6ne Hain, der Zeuge unsrer Spiele,", "tokens": ["Der", "sch\u00f6\u00b7ne", "Hain", ",", "der", "Zeu\u00b7ge", "uns\u00b7rer", "Spie\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sagt ihrem Herzen jetzt nichts mehr.", "tokens": ["Sagt", "ih\u00b7rem", "Her\u00b7zen", "jetzt", "nichts", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Nachtigallen haben nicht gelesen,", "tokens": ["Die", "Nach\u00b7ti\u00b7gal\u00b7len", "ha\u00b7ben", "nicht", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Die Lilien ", "tokens": ["Die", "Li\u00b7li\u00b7en"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Der allgemeine Jubelruf der Wesen", "tokens": ["Der", "all\u00b7ge\u00b7mei\u00b7ne", "Ju\u00b7bel\u00b7ruf", "der", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Begeistert ", "tokens": ["Be\u00b7geis\u00b7tert"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "Doch nein! Die Jahrszeit ist so sch\u00f6n \u2013 zum ", "tokens": ["Doch", "nein", "!", "Die", "Jahrs\u00b7zeit", "ist", "so", "sch\u00f6n", "\u2013", "zum"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PTKANT", "$.", "ART", "NN", "VAFIN", "ADV", "ADJD", "$(", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Wie dr\u00e4ngend voll mags jetzt in Pyrmont sein!", "tokens": ["Wie", "dr\u00e4n\u00b7gend", "voll", "mags", "jetzt", "in", "Pyr\u00b7mont", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADJD", "VMFIN", "ADV", "APPR", "NE", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Auch h\u00f6rt man \u00fcberall das Karlsbad preisen.", "tokens": ["Auch", "h\u00f6rt", "man", "\u00fc\u00b7be\u00b7rall", "das", "Karls\u00b7bad", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Husch ist sie dort \u2013 in jenem ehrenvollen Reihn,", "tokens": ["Husch", "ist", "sie", "dort", "\u2013", "in", "je\u00b7nem", "eh\u00b7ren\u00b7vol\u00b7len", "Reihn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "$(", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.18": {"text": "Zelebrit\u00e4ten ", "tokens": ["Ze\u00b7leb\u00b7ri\u00b7t\u00e4\u00b7ten"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Vertraulich wie in Charons Kahn gepaart,", "tokens": ["Ver\u00b7trau\u00b7lich", "wie", "in", "Cha\u00b7rons", "Kahn", "ge\u00b7paart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "APPR", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.21": {"text": "Wo, eingeschickt von fernen Meilen,", "tokens": ["Wo", ",", "ein\u00b7ge\u00b7schickt", "von", "fer\u00b7nen", "Mei\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Zerri\u00dfne ", "tokens": ["Zer\u00b7ri\u00df\u00b7ne"], "token_info": ["word"], "pos": ["NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.23": {"text": "Noch andre \u2013 sie mit W\u00fcrde zu bestehn!", "tokens": ["Noch", "and\u00b7re", "\u2013", "sie", "mit", "W\u00fcr\u00b7de", "zu", "be\u00b7stehn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$(", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Um die ", "tokens": ["Um", "die"], "token_info": ["word", "word"], "pos": ["KOUI", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.25": {"text": "Dort, Freund \u2013 o lerne ", "tokens": ["Dort", ",", "Freund", "\u2013", "o", "ler\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "NN", "$(", "FM", "FM"], "meter": "-+-+-", "measure": "iambic.di"}, "line.26": {"text": "Dort wandelt ", "tokens": ["Dort", "wan\u00b7delt"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.9": {"line.1": {"text": "O meiner Liebe erstes Flitterjahr!", "tokens": ["O", "mei\u00b7ner", "Lie\u00b7be", "ers\u00b7tes", "Flit\u00b7ter\u00b7jahr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie schnell \u2013 ach wie so schnell bist du entflogen!", "tokens": ["Wie", "schnell", "\u2013", "ach", "wie", "so", "schnell", "bist", "du", "ent\u00b7flo\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$(", "XY", "KOKOM", "ADV", "ADJD", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein Weib, wie keines ist, und keines war,", "tokens": ["Ein", "Weib", ",", "wie", "kei\u00b7nes", "ist", ",", "und", "kei\u00b7nes", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PIS", "VAFIN", "$,", "KON", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit hellem Geist, mit aufgetanem Sinn", "tokens": ["Mit", "hel\u00b7lem", "Geist", ",", "mit", "auf\u00b7ge\u00b7ta\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und weichen leicht beweglichen Gef\u00fchlen,", "tokens": ["Und", "wei\u00b7chen", "leicht", "be\u00b7weg\u00b7li\u00b7chen", "Ge\u00b7f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sah ich sie, die Herzenfe\u00dflerin,", "tokens": ["So", "sah", "ich", "sie", ",", "die", "Her\u00b7zen\u00b7fe\u00df\u00b7le\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Gleich einem Maitag mir zur Seite spielen.", "tokens": ["Gleich", "ei\u00b7nem", "Mai\u00b7tag", "mir", "zur", "Sei\u00b7te", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das s\u00fc\u00dfe Wort: Ich liebe dich!", "tokens": ["Das", "s\u00fc\u00b7\u00dfe", "Wort", ":", "Ich", "lie\u00b7be", "dich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sprach aus dem holden Augenpaare.", "tokens": ["Sprach", "aus", "dem", "hol\u00b7den", "Au\u00b7gen\u00b7paa\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So f\u00fchrt ich sie zum Traualtare,", "tokens": ["So", "f\u00fchrt", "ich", "sie", "zum", "Trau\u00b7al\u00b7ta\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "O wer war gl\u00fccklicher als ich!", "tokens": ["O", "wer", "war", "gl\u00fcck\u00b7li\u00b7cher", "als", "ich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VAFIN", "ADJD", "KOKOM", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Ein Bl\u00fctenfeld beneidenswerter Jahre", "tokens": ["Ein", "Bl\u00fc\u00b7ten\u00b7feld", "be\u00b7nei\u00b7dens\u00b7wer\u00b7ter", "Jah\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sah lachend mich aus diesem Spiegel an.", "tokens": ["Sah", "la\u00b7chend", "mich", "aus", "die\u00b7sem", "Spie\u00b7gel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Mein Himmel war mir aufgetan.", "tokens": ["Mein", "Him\u00b7mel", "war", "mir", "auf\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Schon sah ich sch\u00f6ne Kinder um mich scherzen,", "tokens": ["Schon", "sah", "ich", "sch\u00f6\u00b7ne", "Kin\u00b7der", "um", "mich", "scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "In ihrem Kreis die Sch\u00f6nste ", "tokens": ["In", "ih\u00b7rem", "Kreis", "die", "Sch\u00f6ns\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Die Gl\u00fccklichste von allen ", "tokens": ["Die", "Gl\u00fcck\u00b7lichs\u00b7te", "von", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.19": {"text": "Durch ewig festen Bund der Herzen.", "tokens": ["Durch", "e\u00b7wig", "fes\u00b7ten", "Bund", "der", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und nun erscheint \u2013 o m\u00f6g ihn Gott verdammen!", "tokens": ["Und", "nun", "er\u00b7scheint", "\u2013", "o", "m\u00f6g", "ihn", "Gott", "ver\u00b7dam\u00b7men", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$(", "FM", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.22": {"text": "Der gro\u00dfe Mann tut eine Tat! \u2013 und rei\u00dft", "tokens": ["Der", "gro\u00b7\u00dfe", "Mann", "tut", "ei\u00b7ne", "Tat", "!", "\u2013", "und", "rei\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$.", "$(", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Mein Kartenhaus von Himmelreich zusammen.", "tokens": ["Mein", "Kar\u00b7ten\u00b7haus", "von", "Him\u00b7mel\u00b7reich", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wen hab ich nun? \u2013 Beweinenswerter Tausch!", "tokens": ["Wen", "hab", "ich", "nun", "?", "\u2013", "Be\u00b7wei\u00b7nens\u00b7wer\u00b7ter", "Tausch", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$.", "$(", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Erwacht aus diesem Wonnerausch,", "tokens": ["Er\u00b7wacht", "aus", "die\u00b7sem", "Won\u00b7ne\u00b7rausch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was ist von diesem Engel mir geblieben?", "tokens": ["Was", "ist", "von", "die\u00b7sem", "En\u00b7gel", "mir", "ge\u00b7blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PDAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Ein Zwitter zwischen Mann und Weib,", "tokens": ["Ein", "Zwit\u00b7ter", "zwi\u00b7schen", "Mann", "und", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gleich ungeschickt zum Herrschen und zum Lieben.", "tokens": ["Gleich", "un\u00b7ge\u00b7schickt", "zum", "Herr\u00b7schen", "und", "zum", "Lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "KON", "APPRART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein Kind mit eines Riesen Waffen,", "tokens": ["Ein", "Kind", "mit", "ei\u00b7nes", "Rie\u00b7sen", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Mittelding von Weisen und von Affen!", "tokens": ["Ein", "Mit\u00b7tel\u00b7ding", "von", "Wei\u00b7sen", "und", "von", "Af\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Um k\u00fcmmerlich dem ", "tokens": ["Um", "k\u00fcm\u00b7mer\u00b7lich", "dem"], "token_info": ["word", "word", "word"], "pos": ["KOUI", "ADJD", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Dem ", "tokens": ["Dem"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Herabgest\u00fcrzt von einem Thron,", "tokens": ["Her\u00b7ab\u00b7ge\u00b7st\u00fcrzt", "von", "ei\u00b7nem", "Thron", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Des Reizes heiligen Mysterien entwichen,", "tokens": ["Des", "Rei\u00b7zes", "hei\u00b7li\u00b7gen", "Mys\u00b7te\u00b7ri\u00b7en", "ent\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Aus Cythereas ", "tokens": ["Aus", "Cy\u00b7the\u00b7re\u00b7as"], "token_info": ["word", "word"], "pos": ["APPR", "NE"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "F\u00fcr \u2013 einer Zeitung Gnadenlohn.", "tokens": ["F\u00fcr", "\u2013", "ei\u00b7ner", "Zei\u00b7tung", "Gna\u00b7den\u00b7lohn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}