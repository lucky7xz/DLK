{"textgrid.poem.47770": {"metadata": {"author": {"name": "Daumer, Georg Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[wie k\u00f6nnte man Verzicht auf Liebe]", "genre": "verse", "period": "N.A.", "pub_year": 1837, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie k\u00f6nnte man Verzicht auf Liebe,", "tokens": ["Wie", "k\u00f6nn\u00b7te", "man", "Ver\u00b7zicht", "auf", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf holder Anmuth Schimmer thun?", "tokens": ["Auf", "hol\u00b7der", "An\u00b7muth", "Schim\u00b7mer", "thun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl mehr, denn hundertmal versucht' ich's,", "tokens": ["Wohl", "mehr", ",", "denn", "hun\u00b7dert\u00b7mal", "ver\u00b7sucht'", "ich's", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KON", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch jetzo will ich's nimmer thun.", "tokens": ["Doch", "jet\u00b7zo", "will", "ich's", "nim\u00b7mer", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Zwar grollt der Scheich, der ernste Mahner,", "tokens": ["Zwar", "grollt", "der", "Scheich", ",", "der", "erns\u00b7te", "Mah\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und deutet in die Sternen-Au;", "tokens": ["Und", "deu\u00b7tet", "in", "die", "Ster\u00b7nen\u00b7Au", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dagegen ich: \u00bbMein Gott, was soll ich", "tokens": ["Da\u00b7ge\u00b7gen", "ich", ":", "\u00bb", "Mein", "Gott", ",", "was", "soll", "ich"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "PPER", "$.", "$(", "PPOSAT", "NN", "$,", "PWS", "VMFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit einem hohlen Flimmer thun?", "tokens": ["Mit", "ei\u00b7nem", "hoh\u00b7len", "Flim\u00b7mer", "thun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein Vivat unserm alten Wirthe!", "tokens": ["Ein", "Vi\u00b7vat", "un\u00b7serm", "al\u00b7ten", "Wirt\u00b7he", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn was wir immer s\u00fcndigen,", "tokens": ["Denn", "was", "wir", "im\u00b7mer", "s\u00fcn\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihm sind es eitel gute Thaten,", "tokens": ["Ihm", "sind", "es", "ei\u00b7tel", "gu\u00b7te", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ob wir auch noch schlimmer thun.\u00ab ", "tokens": ["Und", "ob", "wir", "auch", "noch", "schlim\u00b7mer", "thun", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}