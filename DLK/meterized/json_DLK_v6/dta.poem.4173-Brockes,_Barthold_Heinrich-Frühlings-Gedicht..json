{"dta.poem.4173": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Fr\u00fchlings-Gedicht.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da die gew\u00fcnschte Nachbarschaft", "tokens": ["Da", "die", "ge\u00b7w\u00fcnschte", "Nach\u00b7bar\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der Sonnen uns nunmehr begl\u00fccket,", "tokens": ["Der", "Son\u00b7nen", "uns", "nun\u00b7mehr", "be\u00b7gl\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wird, durch derselben rege Kraft,", "tokens": ["Wird", ",", "durch", "der\u00b7sel\u00b7ben", "re\u00b7ge", "Kraft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gemach, gemach so Dunst als Duft,", "tokens": ["Ge\u00b7mach", ",", "ge\u00b7mach", "so", "Dunst", "als", "Duft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die bis daher uns und die Luft,", "tokens": ["Die", "bis", "da\u00b7her", "uns", "und", "die", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PAV", "PPER", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als eine kalte Last, gedr\u00fccket,", "tokens": ["Als", "ei\u00b7ne", "kal\u00b7te", "Last", ",", "ge\u00b7dr\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Zertheilt, verd\u00fcnnt, zerstreut, zerst\u00fccket.", "tokens": ["Zer\u00b7theilt", ",", "ver\u00b7d\u00fcnnt", ",", "zer\u00b7streut", ",", "zer\u00b7st\u00fc\u00b7cket", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was uns an Feuchtigkeit zu viel, zu nahe war,", "tokens": ["Was", "uns", "an", "Feuch\u00b7tig\u00b7keit", "zu", "viel", ",", "zu", "na\u00b7he", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "APPR", "PIS", "$,", "PTKA", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wird ausgedehnet, ausgebreitet,", "tokens": ["Wird", "aus\u00b7ge\u00b7deh\u00b7net", ",", "aus\u00b7ge\u00b7brei\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Jm h\u00f6hern Luft-Kreis ausgespreitet,", "tokens": ["Jm", "h\u00f6\u00b7hern", "Luft\u00b7Kreis", "aus\u00b7ge\u00b7sprei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Gem\u00e4hlich in die hohe Tiefe, in einen gr\u00f6\u00df- und weitern", "tokens": ["Ge\u00b7m\u00e4h\u00b7lich", "in", "die", "ho\u00b7he", "Tie\u00b7fe", ",", "in", "ei\u00b7nen", "gr\u00f6\u00df", "und", "wei\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "TRUNC", "KON", "VVINF"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "Bogen,", "tokens": ["Bo\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Durch rege Strahlen, ausgespannt, von uns entfernt hin-", "tokens": ["Durch", "re\u00b7ge", "Strah\u00b7len", ",", "aus\u00b7ge\u00b7spannt", ",", "von", "uns", "ent\u00b7fernt", "hin"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "VVPP", "$,", "APPR", "PPER", "ADJD", "TRUNC"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.14": {"text": "aufgezogen;", "tokens": ["auf\u00b7ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.15": {"text": "Wodurch denn unsre L\u00fcfte klar,", "tokens": ["Wo\u00b7durch", "denn", "uns\u00b7re", "L\u00fcf\u00b7te", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und, durch den unbew\u00f6lkten Schein,", "tokens": ["Und", ",", "durch", "den", "un\u00b7be\u00b7w\u00f6lk\u00b7ten", "Schein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die Fr\u00fchlings-Tage heiter seyn.", "tokens": ["Die", "Fr\u00fch\u00b7lings\u00b7Ta\u00b7ge", "hei\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Schnee, Hagel, Frost und St\u00fcrme fliehn,", "tokens": ["Schnee", ",", "Ha\u00b7gel", ",", "Frost", "und", "St\u00fcr\u00b7me", "fliehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und scheinen von dem Nord nach S\u00fcden sich zu ziehn.", "tokens": ["Und", "schei\u00b7nen", "von", "dem", "Nord", "nach", "S\u00fc\u00b7den", "sich", "zu", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Jm holden Sonnen-Reich, voll Segen, W\u00e4rm\u2019 und Leben,", "tokens": ["Jm", "hol\u00b7den", "Son\u00b7nen\u00b7Reich", ",", "voll", "Se\u00b7gen", ",", "W\u00e4rm'", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "ADJD", "NN", "$,", "VVIMP", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "In welchem wir, nebst unsrer Fl\u00e4ch\u2019, jetzt schweben,", "tokens": ["In", "wel\u00b7chem", "wir", ",", "nebst", "uns\u00b7rer", "Fl\u00e4ch'", ",", "jetzt", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Wird ihnen kein Quartier gegeben.", "tokens": ["Wird", "ih\u00b7nen", "kein", "Quar\u00b7tier", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Es lispeln \u00fcberall, statt ihrer, sanft, gelinde,", "tokens": ["Es", "lis\u00b7peln", "\u00fc\u00b7be\u00b7rall", ",", "statt", "ih\u00b7rer", ",", "sanft", ",", "ge\u00b7lin\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUI", "PPOSAT", "$,", "ADJD", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Voll fetter Fruchtbarkeit, die lauen Fr\u00fchlings-Winde;", "tokens": ["Voll", "fet\u00b7ter", "Frucht\u00b7bar\u00b7keit", ",", "die", "lau\u00b7en", "Fr\u00fch\u00b7lings\u00b7Win\u00b7de", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wodurch wir, auch von kalten H\u00f6h\u2019n,", "tokens": ["Wo\u00b7durch", "wir", ",", "auch", "von", "kal\u00b7ten", "H\u00f6h'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Den aufgel\u00f6s\u2019ten Schnee erst tr\u00f6pflend abwerts rinnen,", "tokens": ["Den", "auf\u00b7ge\u00b7l\u00f6s'\u00b7ten", "Schnee", "erst", "tr\u00f6pf\u00b7lend", "ab\u00b7werts", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Und bald darauf ihn schnell von hinnen,", "tokens": ["Und", "bald", "da\u00b7rauf", "ihn", "schnell", "von", "hin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PAV", "PPER", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Besch\u00e4umet, Meer-werts fliehen sehn.", "tokens": ["Be\u00b7sch\u00e4u\u00b7met", ",", "Meer\u00b7werts", "flie\u00b7hen", "sehn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Das schl\u00fcpfrige morast\u2019ge Schwarz der Erden", "tokens": ["Das", "schl\u00fcpf\u00b7ri\u00b7ge", "mo\u00b7rast'\u00b7ge", "Schwarz", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Wird gelblich grau, f\u00e4ngt trocken an zu werden:", "tokens": ["Wird", "gelb\u00b7lich", "grau", ",", "f\u00e4ngt", "tro\u00b7cken", "an", "zu", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJD", "$,", "VVFIN", "ADJD", "PTKVZ", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ja schimmert, gl\u00e4nzet, gr\u00fcnet, bl\u00fcht", "tokens": ["Ja", "schim\u00b7mert", ",", "gl\u00e4n\u00b7zet", ",", "gr\u00fc\u00b7net", ",", "bl\u00fcht"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["PTKANT", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vielf\u00e4rbig, eh man sichs versieht.", "tokens": ["Viel\u00b7f\u00e4r\u00b7big", ",", "eh", "man", "sichs", "ver\u00b7sieht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verworfner Koht, der unsern Blicken", "tokens": ["Ver\u00b7worf\u00b7ner", "Koht", ",", "der", "un\u00b7sern", "Bli\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Recht ekelhaft und widrig war,", "tokens": ["Recht", "e\u00b7kel\u00b7haft", "und", "wid\u00b7rig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00e4ngt jetzt sich an mit einer bunten Schaar", "tokens": ["F\u00e4ngt", "jetzt", "sich", "an", "mit", "ei\u00b7ner", "bun\u00b7ten", "Schaar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PRF", "APPR", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Von Gras und Bluhmen hier und dar", "tokens": ["Von", "Gras", "und", "Bluh\u00b7men", "hier", "und", "dar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu decken und so sch\u00f6n zu schm\u00fccken,", "tokens": ["Zu", "de\u00b7cken", "und", "so", "sch\u00f6n", "zu", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df nichts mit dieser Zucht der Erden", "tokens": ["Da\u00df", "nichts", "mit", "die\u00b7ser", "Zucht", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "PDAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "An Sch\u00f6nheit kann verglichen werden;", "tokens": ["An", "Sch\u00f6n\u00b7heit", "kann", "ver\u00b7gli\u00b7chen", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So da\u00df, was gestern braun und grau,", "tokens": ["So", "da\u00df", ",", "was", "ge\u00b7stern", "braun", "und", "grau", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "$,", "PRELS", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.11": {"text": "Ich heute schon begr\u00fcnet schau,", "tokens": ["Ich", "heu\u00b7te", "schon", "be\u00b7gr\u00fc\u00b7net", "schau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Begr\u00fcnt, und zwar so gl\u00e4nzend gr\u00fcn,", "tokens": ["Be\u00b7gr\u00fcnt", ",", "und", "zwar", "so", "gl\u00e4n\u00b7zend", "gr\u00fcn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "ADV", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Da\u00df, wenn die Sonne durch das Gras,", "tokens": ["Da\u00df", ",", "wenn", "die", "Son\u00b7ne", "durch", "das", "Gras", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Das noch so zart und d\u00fcnne, schien\u2019,", "tokens": ["Das", "noch", "so", "zart", "und", "d\u00fcn\u00b7ne", ",", "schien'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADJD", "KON", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Es recht, als wie ein gr\u00fcnes Glas,", "tokens": ["Es", "recht", ",", "als", "wie", "ein", "gr\u00fc\u00b7nes", "Glas", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "KOUS", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Durchsichtig, gl\u00e4nzend, hell und klar,", "tokens": ["Durch\u00b7sich\u00b7tig", ",", "gl\u00e4n\u00b7zend", ",", "hell", "und", "klar", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und in der That durchleuchtig war.", "tokens": ["Und", "in", "der", "That", "durch\u00b7leuch\u00b7tig", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Man sieht jetzt aus den saft\u2019gen Zweigen", "tokens": ["Man", "sieht", "jetzt", "aus", "den", "saft'\u00b7gen", "Zwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Das, womit sie sich zieren, steigen,", "tokens": ["Das", ",", "wo\u00b7mit", "sie", "sich", "zie\u00b7ren", ",", "stei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und das, womit sie sich verh\u00fcllen,", "tokens": ["Und", "das", ",", "wo\u00b7mit", "sie", "sich", "ver\u00b7h\u00fcl\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PWAV", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Fast \u00fcberall aus ihnen quillen.", "tokens": ["Fast", "\u00fc\u00b7be\u00b7rall", "aus", "ih\u00b7nen", "quil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie sieht jetzt alles, was man siehet, so lieblich und so", "tokens": ["Wie", "sieht", "jetzt", "al\u00b7les", ",", "was", "man", "sie\u00b7het", ",", "so", "lieb\u00b7lich", "und", "so"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ADV", "PIS", "$,", "PRELS", "PIS", "VVFIN", "$,", "ADV", "ADJD", "KON", "ADV"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "fr\u00f6hlich aus!", "tokens": ["fr\u00f6h\u00b7lich", "aus", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Die Fluht ist mit sapphirnem Glanz, das Feld mit gr\u00fcnem", "tokens": ["Die", "Fluht", "ist", "mit", "sap\u00b7phir\u00b7nem", "Glanz", ",", "das", "Feld", "mit", "gr\u00fc\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Schmelz gezieret;", "tokens": ["Schmelz", "ge\u00b7zie\u00b7ret", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Ein jeder Baum voll sch\u00f6ner Bl\u00fcht zeigt recht nat\u00fcrlich,", "tokens": ["Ein", "je\u00b7der", "Baum", "voll", "sch\u00f6\u00b7ner", "Bl\u00fcht", "zeigt", "recht", "na\u00b7t\u00fcr\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "ADJA", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "und formiret", "tokens": ["und", "for\u00b7mi\u00b7ret"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Aus tausend kleinen Blumen-Str\u00e4ussen jetzt einen grossen", "tokens": ["Aus", "tau\u00b7send", "klei\u00b7nen", "Blu\u00b7men\u00b7Str\u00e4us\u00b7sen", "jetzt", "ei\u00b7nen", "gros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "ADJA", "NN", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Blumen-Strau\u00df.", "tokens": ["Blu\u00b7men\u00b7Strau\u00df", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Wo etwas uns die weise G\u00fcte", "tokens": ["Wo", "et\u00b7was", "uns", "die", "wei\u00b7se", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Sch\u00f6pfers zeigt; so ists die Bl\u00fchte,", "tokens": ["Des", "Sch\u00f6p\u00b7fers", "zeigt", ";", "so", "ists", "die", "Bl\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die jetzt aus allen Zweigen quillet,", "tokens": ["Die", "jetzt", "aus", "al\u00b7len", "Zwei\u00b7gen", "quil\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die, durch der Sonnen Lebens-Licht,", "tokens": ["Die", ",", "durch", "der", "Son\u00b7nen", "Le\u00b7bens\u00b7Licht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Luft mit Pracht und Balsam f\u00fcllet,", "tokens": ["Die", "Luft", "mit", "Pracht", "und", "Bal\u00b7sam", "f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und uns im Sommer Frucht verspricht.", "tokens": ["Und", "uns", "im", "Som\u00b7mer", "Frucht", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier streicht ein Vogel schnell vorbey", "tokens": ["Hier", "streicht", "ein", "Vo\u00b7gel", "schnell", "vor\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit einem fr\u00f6hlichen Get\u00f6n;", "tokens": ["Mit", "ei\u00b7nem", "fr\u00f6h\u00b7li\u00b7chen", "Ge\u00b7t\u00f6n", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da kann man ganze Schaaren fliegen,", "tokens": ["Da", "kann", "man", "gan\u00b7ze", "Schaa\u00b7ren", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und hier mit innigem Vergn\u00fcgen", "tokens": ["Und", "hier", "mit", "in\u00b7ni\u00b7gem", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Ein Paar verliebt sich schn\u00e4beln, sehn;", "tokens": ["Ein", "Paar", "ver\u00b7liebt", "sich", "schn\u00e4\u00b7beln", ",", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch dorten ein vergn\u00fcgt Geschrey", "tokens": ["Auch", "dor\u00b7ten", "ein", "ver\u00b7gn\u00fcgt", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "VVPP", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In manchem Ton, von manchen Ch\u00f6ren", "tokens": ["In", "man\u00b7chem", "Ton", ",", "von", "man\u00b7chen", "Ch\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "In hellem Wettstreit zwitschern h\u00f6ren.", "tokens": ["In", "hel\u00b7lem", "Wett\u00b7streit", "zwit\u00b7schern", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Seht! auf dem noch nicht gr\u00fcnen Aestchen", "tokens": ["Seht", "!", "auf", "dem", "noch", "nicht", "gr\u00fc\u00b7nen", "A\u00b7est\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "APPR", "ART", "ADV", "PTKNEG", "ADJA", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Baut jener dort sein k\u00fcnstlich Nestchen.", "tokens": ["Baut", "je\u00b7ner", "dort", "sein", "k\u00fcnst\u00b7lich", "Nest\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "An jedem Ort, an allen Enden,", "tokens": ["An", "je\u00b7dem", "Ort", ",", "an", "al\u00b7len", "En\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wohin wir jetzt die Blicke wenden,", "tokens": ["Wo\u00b7hin", "wir", "jetzt", "die", "Bli\u00b7cke", "wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Ist, was wir h\u00f6ren, was wir sehn,", "tokens": ["Ist", ",", "was", "wir", "h\u00f6\u00b7ren", ",", "was", "wir", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "PPER", "VVINF", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Voll Anmuht, lieblich, wundersch\u00f6n.", "tokens": ["Voll", "An\u00b7muht", ",", "lieb\u00b7lich", ",", "wun\u00b7der\u00b7sch\u00f6n", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "NN", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Meine Schafe, meine Ziegen", "tokens": ["Mei\u00b7ne", "Scha\u00b7fe", ",", "mei\u00b7ne", "Zie\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kann ich jetzo mit Vergn\u00fcgen", "tokens": ["Kann", "ich", "jet\u00b7zo", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An des Walles gr\u00fcnen H\u00f6h\u2019n", "tokens": ["An", "des", "Wal\u00b7les", "gr\u00fc\u00b7nen", "H\u00f6h'n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00fcpfen, grasen, springen, liegen,", "tokens": ["H\u00fcp\u00b7fen", ",", "gra\u00b7sen", ",", "sprin\u00b7gen", ",", "lie\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weiden, klettern, stehen, gehn,", "tokens": ["Wei\u00b7den", ",", "klet\u00b7tern", ",", "ste\u00b7hen", ",", "gehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und mit regem Maul das Gras", "tokens": ["Und", "mit", "re\u00b7gem", "Maul", "das", "Gras"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Recht gesch\u00e4ftig rupfen sehn.", "tokens": ["Recht", "ge\u00b7sch\u00e4f\u00b7tig", "rup\u00b7fen", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wenn hier eines r\u00fcstig fra\u00df,", "tokens": ["Wenn", "hier", "ei\u00b7nes", "r\u00fcs\u00b7tig", "fra\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "H\u00fcpften am erhabnern Ort", "tokens": ["H\u00fcpf\u00b7ten", "am", "er\u00b7hab\u00b7nern", "Ort"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Kleine B\u00f6cke, Ziegen dort.", "tokens": ["Klei\u00b7ne", "B\u00f6\u00b7cke", ",", "Zie\u00b7gen", "dort", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Oft sucht eins sich, vor Ergetzen,", "tokens": ["Oft", "sucht", "eins", "sich", ",", "vor", "Er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "$,", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Von dem Boden aufzuschwingen,", "tokens": ["Von", "dem", "Bo\u00b7den", "auf\u00b7zu\u00b7schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "In die Luft mit kurzen S\u00e4tzen", "tokens": ["In", "die", "Luft", "mit", "kur\u00b7zen", "S\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wiederholt hinaufzudringen,", "tokens": ["Wie\u00b7der\u00b7holt", "hin\u00b7auf\u00b7zu\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schnell, vor innigem Vergn\u00fcgen,", "tokens": ["Schnell", ",", "vor", "in\u00b7ni\u00b7gem", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "L\u00e4cherlich den R\u00fccken biegen,", "tokens": ["L\u00e4\u00b7cher\u00b7lich", "den", "R\u00fc\u00b7cken", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und auf allen Vieren springen.", "tokens": ["Und", "auf", "al\u00b7len", "Vie\u00b7ren", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wie gl\u00e4nzt, zu unsrer Augen Weide,", "tokens": ["Wie", "gl\u00e4nzt", ",", "zu", "uns\u00b7rer", "Au\u00b7gen", "Wei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das jetzt den Frost besiegende Getrayde!", "tokens": ["Das", "jetzt", "den", "Frost", "be\u00b7sie\u00b7gen\u00b7de", "Ge\u00b7tray\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie breitet es sich aus! Man kann es gleichsam sehn,", "tokens": ["Wie", "brei\u00b7tet", "es", "sich", "aus", "!", "Man", "kann", "es", "gleich\u00b7sam", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "PTKVZ", "$.", "PIS", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Bl\u00e4tter, Halmen und das Kraut", "tokens": ["Wie", "Bl\u00e4t\u00b7ter", ",", "Hal\u00b7men", "und", "das", "Kraut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So in die H\u00f6h, als aus einander, gehn,", "tokens": ["So", "in", "die", "H\u00f6h", ",", "als", "aus", "ein\u00b7an\u00b7der", ",", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "KOUS", "APPR", "PRF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Es wird ohn Anmuht nicht geschaut,", "tokens": ["Es", "wird", "ohn", "An\u00b7muht", "nicht", "ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn sich die langen Bl\u00e4tter biegen,", "tokens": ["Wenn", "sich", "die", "lan\u00b7gen", "Bl\u00e4t\u00b7ter", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da sie so glatt, wie kleine Blitze,", "tokens": ["Da", "sie", "so", "glatt", ",", "wie", "klei\u00b7ne", "Blit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auf ihren glatten B\u00f6gen liegen;", "tokens": ["Auf", "ih\u00b7ren", "glat\u00b7ten", "B\u00f6\u00b7gen", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wozwischen denn so manche Spitze,", "tokens": ["Woz\u00b7wi\u00b7schen", "denn", "so", "man\u00b7che", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die annoch aufwerts steht und steiget,", "tokens": ["Die", "an\u00b7noch", "auf\u00b7werts", "steht", "und", "stei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Nicht minder angenehm sich zeiget.", "tokens": ["Nicht", "min\u00b7der", "an\u00b7ge\u00b7nehm", "sich", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wenn man die Saat im Strahl der Sonnen sieht,", "tokens": ["Wenn", "man", "die", "Saat", "im", "Strahl", "der", "Son\u00b7nen", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "So l\u00e4\u00dft es einem achtsamen Gem\u00fcht,", "tokens": ["So", "l\u00e4\u00dft", "es", "ei\u00b7nem", "acht\u00b7sa\u00b7men", "Ge\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Als st\u00fcnd\u2019 es hie und da voll weisser Bl\u00fcht,", "tokens": ["Als", "st\u00fcnd'", "es", "hie", "und", "da", "voll", "weis\u00b7ser", "Bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "ADV", "KON", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Es schien dadurch mit heller Lieblichkeit", "tokens": ["Es", "schien", "da\u00b7durch", "mit", "hel\u00b7ler", "Lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Der Felder gr\u00fcn Gewand mit Silber \u00fcberstreut,", "tokens": ["Der", "Fel\u00b7der", "gr\u00fcn", "Ge\u00b7wand", "mit", "Sil\u00b7ber", "\u00fc\u00b7bers\u00b7treut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und gleichsam reich durchwirkt, wodurch es anzusehn,", "tokens": ["Und", "gleich\u00b7sam", "reich", "durch\u00b7wirkt", ",", "wo\u00b7durch", "es", "an\u00b7zu\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VVPP", "$,", "PWAV", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Als wie ein ", "tokens": ["Als", "wie", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "Jetzt brauset recht die frische Saat,", "tokens": ["Jetzt", "brau\u00b7set", "recht", "die", "fri\u00b7sche", "Saat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Die, wie ein gr\u00fcner Sammt, das Feld bedecket hat;", "tokens": ["Die", ",", "wie", "ein", "gr\u00fc\u00b7ner", "Sammt", ",", "das", "Feld", "be\u00b7de\u00b7cket", "hat", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Doch nein, es kann kein Sammt der gr\u00fcnen Sch\u00f6nheit", "tokens": ["Doch", "nein", ",", "es", "kann", "kein", "Sammt", "der", "gr\u00fc\u00b7nen", "Sch\u00f6n\u00b7heit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKANT", "$,", "PPER", "VMFIN", "PIAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "gleichen,", "tokens": ["glei\u00b7chen", ","], "token_info": ["word", "punct"], "pos": ["ADJA", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.24": {"text": "Ja selber ein Smaragd mu\u00df ihrer Farbe weichen.", "tokens": ["Ja", "sel\u00b7ber", "ein", "Sma\u00b7ragd", "mu\u00df", "ih\u00b7rer", "Far\u00b7be", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die\u00df Gr\u00fcn\u2019scheint keine Farb\u2019, es scheint ein gr\u00fcner Schein,", "tokens": ["Die\u00df", "Gr\u00fcn'\u00b7scheint", "kei\u00b7ne", "Fa\u00b7rb'", ",", "es", "scheint", "ein", "gr\u00fc\u00b7ner", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und gar kein irdisches, ein himmlisch Gr\u00fcn zu seyn,", "tokens": ["Und", "gar", "kein", "ir\u00b7di\u00b7sches", ",", "ein", "himm\u00b7lisch", "Gr\u00fcn", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "ADJA", "$,", "ART", "ADJD", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Fast recht, als h\u00e4tte sich vom sch\u00f6nen Regen-Bogen", "tokens": ["Fast", "recht", ",", "als", "h\u00e4t\u00b7te", "sich", "vom", "sch\u00f6\u00b7nen", "Re\u00b7gen\u00b7Bo\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOKOM", "VAFIN", "PRF", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sein sch\u00f6nstes Gr\u00fcn herabgezogen,", "tokens": ["Sein", "sch\u00f6ns\u00b7tes", "Gr\u00fcn", "her\u00b7ab\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Um unsre Welt so herrlich auszuschm\u00fccken,", "tokens": ["Um", "uns\u00b7re", "Welt", "so", "herr\u00b7lich", "aus\u00b7zu\u00b7schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Menschen Herz durchs Auge zu erquicken", "tokens": ["Der", "Men\u00b7schen", "Herz", "durchs", "Au\u00b7ge", "zu", "er\u00b7qui\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "APPRART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und zu belustigen. Absonderlich", "tokens": ["Und", "zu", "be\u00b7lus\u00b7ti\u00b7gen", ".", "Ab\u00b7son\u00b7der\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "PTKZU", "VVINF", "$.", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Hebt sich der Felder gr\u00fcne Pracht,", "tokens": ["Hebt", "sich", "der", "Fel\u00b7der", "gr\u00fc\u00b7ne", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Wenn durch die Nachbarschaft gebrochter Aecker sich,", "tokens": ["Wenn", "durch", "die", "Nach\u00b7bar\u00b7schaft", "ge\u00b7broch\u00b7ter", "A\u00b7e\u00b7cker", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ADJA", "NN", "PRF", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Durch ihre Dunkelheit, was an sich so schon sch\u00f6n,", "tokens": ["Durch", "ih\u00b7re", "Dun\u00b7kel\u00b7heit", ",", "was", "an", "sich", "so", "schon", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "APPR", "PRF", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Jm braunen Gegensatz sich mehr noch zu erh\u00f6hn,", "tokens": ["Jm", "brau\u00b7nen", "Ge\u00b7gen\u00b7satz", "sich", "mehr", "noch", "zu", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PRF", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Verdoppelt und noch sch\u00f6ner macht.", "tokens": ["Ver\u00b7dop\u00b7pelt", "und", "noch", "sch\u00f6\u00b7ner", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wenn ein benachbart Land erst umgepfl\u00fcget,", "tokens": ["Wenn", "ein", "be\u00b7nach\u00b7bart", "Land", "erst", "um\u00b7ge\u00b7pfl\u00fc\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Steckt in der braunen Dunkelheit", "tokens": ["Steckt", "in", "der", "brau\u00b7nen", "Dun\u00b7kel\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Vor sich schon eine Lieblichkeit,", "tokens": ["Vor", "sich", "schon", "ei\u00b7ne", "Lieb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die ein betrachtend Aug ergetzet und vergn\u00fcget;", "tokens": ["Die", "ein", "be\u00b7trach\u00b7tend", "Aug", "er\u00b7get\u00b7zet", "und", "ver\u00b7gn\u00fc\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "NN", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Doch hebt die frische Schw\u00e4rz annoch", "tokens": ["Doch", "hebt", "die", "fri\u00b7sche", "Schw\u00e4rz", "an\u00b7noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Das schon mit Saat bedeckte Joch", "tokens": ["Das", "schon", "mit", "Saat", "be\u00b7deck\u00b7te", "Joch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "In ihrer Nachbarschaft.", "tokens": ["In", "ih\u00b7rer", "Nach\u00b7bar\u00b7schaft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Zieht nun darauf der Sonnen Kraft", "tokens": ["Zieht", "nun", "da\u00b7rauf", "der", "Son\u00b7nen", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PAV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Die Feuchtigkeit und den zu vielen Saft", "tokens": ["Die", "Feuch\u00b7tig\u00b7keit", "und", "den", "zu", "vie\u00b7len", "Saft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Aus der ger\u00fchrt- und umgest\u00fcrzten Erden;", "tokens": ["Aus", "der", "ge\u00b7r\u00fchr\u00b7t", "und", "um\u00b7ge\u00b7st\u00fcrz\u00b7ten", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Scheint wei\u00df und roht sich sanft darauf zu mischen,", "tokens": ["Scheint", "wei\u00df", "und", "roht", "sich", "sanft", "da\u00b7rauf", "zu", "mi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "PRF", "ADJD", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Und unser Aug und unsre Blicke,", "tokens": ["Und", "un\u00b7ser", "Aug", "und", "uns\u00b7re", "Bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Damit es uns um destomehr erquicke,", "tokens": ["Da\u00b7mit", "es", "uns", "um", "des\u00b7to\u00b7mehr", "er\u00b7qui\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Mit einer sanften Art von Leib-Farb zu erfrischen,", "tokens": ["Mit", "ei\u00b7ner", "sanf\u00b7ten", "Art", "von", "Leib\u00b7Fa\u00b7rb", "zu", "er\u00b7fri\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-++-+-+-", "measure": "unknown.measure.septa"}, "line.25": {"text": "Das ebenfalls dem Acker, der begr\u00fcnt,", "tokens": ["Das", "e\u00b7ben\u00b7falls", "dem", "A\u00b7cker", ",", "der", "be\u00b7gr\u00fcnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Jhn destomehr noch zu erh\u00f6hen, dient.", "tokens": ["Jhn", "des\u00b7to\u00b7mehr", "noch", "zu", "er\u00b7h\u00f6\u00b7hen", ",", "dient", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PTKZU", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Und kurz, wohin wir uns jetzt drehn,", "tokens": ["Und", "kurz", ",", "wo\u00b7hin", "wir", "uns", "jetzt", "drehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Wohin wir gehen, wo wir stehn,", "tokens": ["Wo\u00b7hin", "wir", "ge\u00b7hen", ",", "wo", "wir", "stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVINF", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Ist jeder Vorwurf, den wir sehn,", "tokens": ["Ist", "je\u00b7der", "Vor\u00b7wurf", ",", "den", "wir", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Nicht sch\u00f6n nur; er ist wundersch\u00f6n.", "tokens": ["Nicht", "sch\u00f6n", "nur", ";", "er", "ist", "wun\u00b7der\u00b7sch\u00f6n", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "$.", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Man f\u00fchlt, doch mu\u00df man dran gedenken,", "tokens": ["Man", "f\u00fchlt", ",", "doch", "mu\u00df", "man", "dran", "ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "ADV", "VMFIN", "PIS", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df, wenn sie sich, durch unsre Blicke", "tokens": ["Da\u00df", ",", "wenn", "sie", "sich", ",", "durch", "uns\u00b7re", "Bli\u00b7cke"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "PRF", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Sinnen, in die Seele senken,", "tokens": ["Und", "Sin\u00b7nen", ",", "in", "die", "See\u00b7le", "sen\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie sich recht innig dran erquicke.", "tokens": ["Sie", "sich", "recht", "in\u00b7nig", "dran", "er\u00b7qui\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "ADV", "ADJD", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zumahl, wenn wir zugleich dabey,", "tokens": ["Zu\u00b7mahl", ",", "wenn", "wir", "zu\u00b7gleich", "da\u00b7bey", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Woher es alles kommen sey,", "tokens": ["Wo\u00b7her", "es", "al\u00b7les", "kom\u00b7men", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIS", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Auf Den, Der es uns wollen schenken,", "tokens": ["Auf", "Den", ",", "Der", "es", "uns", "wol\u00b7len", "schen\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Durch sie ger\u00fchrt, die Seele lenken.", "tokens": ["Durch", "sie", "ge\u00b7r\u00fchrt", ",", "die", "See\u00b7le", "len\u00b7ken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Dann wird, wie alles, durch die Sonne,", "tokens": ["Dann", "wird", ",", "wie", "al\u00b7les", ",", "durch", "die", "Son\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "PWAV", "PIS", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sich wunderw\u00fcrdig herrlich mahlt,", "tokens": ["Sich", "wun\u00b7der\u00b7w\u00fcr\u00b7dig", "herr\u00b7lich", "mahlt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Vom geistgen Glanz, voll Freud und Wonne", "tokens": ["Vom", "geist\u00b7gen", "Glanz", ",", "voll", "Freud", "und", "Won\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Die Seele selbst recht angestrahlt.", "tokens": ["Die", "See\u00b7le", "selbst", "recht", "an\u00b7ge\u00b7strahlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}