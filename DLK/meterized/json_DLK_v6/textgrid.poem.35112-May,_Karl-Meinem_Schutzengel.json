{"textgrid.poem.35112": {"metadata": {"author": {"name": "May, Karl", "birth": "N.A.", "death": "N.A."}, "title": "Meinem Schutzengel", "genre": "verse", "period": "N.A.", "pub_year": 1877, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich war bei dir und lag doch so entlegen", "tokens": ["Ich", "war", "bei", "dir", "und", "lag", "doch", "so", "ent\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "KON", "VVFIN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von deiner Wohnung betend auf den Knien.", "tokens": ["Von", "dei\u00b7ner", "Woh\u00b7nung", "be\u00b7tend", "auf", "den", "Kni\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich war bei dir; ich bat um deinen Segen", "tokens": ["Ich", "war", "bei", "dir", ";", "ich", "bat", "um", "dei\u00b7nen", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und fragte, ob du mir vielleicht verziehn.", "tokens": ["Und", "frag\u00b7te", ",", "ob", "du", "mir", "viel\u00b7leicht", "ver\u00b7ziehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Du warst bei mir und standest doch so ferne", "tokens": ["Du", "warst", "bei", "mir", "und", "stan\u00b7dest", "doch", "so", "fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "KON", "VVFIN", "ADV", "ADV", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von meinem Erdenheim vor Gottes Thron.", "tokens": ["Von", "mei\u00b7nem", "Er\u00b7den\u00b7heim", "vor", "Got\u00b7tes", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir athmen zwar nicht auf demselben Sterne,", "tokens": ["Wir", "ath\u00b7men", "zwar", "nicht", "auf", "dem\u00b7sel\u00b7ben", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch f\u00fchl ich Segen und Verzeihung schon.", "tokens": ["Doch", "f\u00fchl", "ich", "Se\u00b7gen", "und", "Ver\u00b7zei\u00b7hung", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wir haben uns, du Geist, ich Staub, gefunden,", "tokens": ["Wir", "ha\u00b7ben", "uns", ",", "du", "Geist", ",", "ich", "Staub", ",", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PPER", "NN", "$,", "PPER", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als ich durch dich den Weg zum Himmel fand,", "tokens": ["Als", "ich", "durch", "dich", "den", "Weg", "zum", "Him\u00b7mel", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und sind wie Leib und Seele nun verbunden,", "tokens": ["Und", "sind", "wie", "Leib", "und", "See\u00b7le", "nun", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "KOKOM", "NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie Gottes Wille und des Menschen Hand.", "tokens": ["Wie", "Got\u00b7tes", "Wil\u00b7le", "und", "des", "Men\u00b7schen", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und kann ich diesen Willen nicht begreifen,", "tokens": ["Und", "kann", "ich", "die\u00b7sen", "Wil\u00b7len", "nicht", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PDAT", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So giebst du mir ihn klar und klarer kund:", "tokens": ["So", "giebst", "du", "mir", "ihn", "klar", "und", "kla\u00b7rer", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPER", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich soll durch dich empor und zu dir reifen;", "tokens": ["Ich", "soll", "durch", "dich", "em\u00b7por", "und", "zu", "dir", "rei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "PTKVZ", "KON", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dann gehn wir weiter; das ist unser Bund.", "tokens": ["Dann", "gehn", "wir", "wei\u00b7ter", ";", "das", "ist", "un\u00b7ser", "Bund", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}