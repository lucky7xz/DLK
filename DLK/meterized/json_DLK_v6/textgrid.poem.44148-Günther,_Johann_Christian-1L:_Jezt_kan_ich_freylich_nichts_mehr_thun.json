{"textgrid.poem.44148": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Jezt kan ich freylich nichts mehr thun", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jezt kan ich freylich nichts mehr thun", "tokens": ["Jezt", "kan", "ich", "frey\u00b7lich", "nichts", "mehr", "thun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PIS", "ADV", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00fcntschen und mit Gro\u00dfmuth schweigen,", "tokens": ["Als", "w\u00fcnt\u00b7schen", "und", "mit", "Gro\u00df\u00b7muth", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "KON", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da Ungl\u00fcck, Feind und Neid nicht ruhn,", "tokens": ["Da", "Un\u00b7gl\u00fcck", ",", "Feind", "und", "Neid", "nicht", "ruhn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich aller Welt geschw\u00e4rzt zu zeigen.", "tokens": ["Mich", "al\u00b7ler", "Welt", "ge\u00b7schw\u00e4rzt", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vielleicht erscheint einmahl ein Tag,", "tokens": ["Viel\u00b7leicht", "er\u00b7scheint", "ein\u00b7mahl", "ein", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An dem ich be\u00dfer weisen mag,", "tokens": ["An", "dem", "ich", "be\u00b7\u00dfer", "wei\u00b7sen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie hoch ich [Leonoren] sch\u00e4ze;", "tokens": ["Wie", "hoch", "ich", "Le\u00b7o\u00b7no\u00b7ren", "sch\u00e4\u00b7ze", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "$(", "NE", "$(", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Sie dencke von mir, was sie will,", "tokens": ["Sie", "den\u00b7cke", "von", "mir", ",", "was", "sie", "will", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ich halte dem Verh\u00e4ngn\u00fc\u00df still", "tokens": ["Ich", "hal\u00b7te", "dem", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "still"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und w\u00fcntsche, da\u00df ihr Gott, was ich nicht kan, erseze.", "tokens": ["Und", "w\u00fcnt\u00b7sche", ",", "da\u00df", "ihr", "Gott", ",", "was", "ich", "nicht", "kan", ",", "er\u00b7se\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "$,", "PWS", "PPER", "PTKNEG", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es machen Fehler junger Zeit", "tokens": ["Es", "ma\u00b7chen", "Feh\u00b7ler", "jun\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein redlich Herz gar oft verd\u00e4chtig,", "tokens": ["Mein", "red\u00b7lich", "Herz", "gar", "oft", "ver\u00b7d\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als w\u00e4r ich aus Geniesligkeit", "tokens": ["Als", "w\u00e4r", "ich", "aus", "Ge\u00b7nies\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der blinden Regung niemahls m\u00e4chtig;", "tokens": ["Der", "blin\u00b7den", "Re\u00b7gung", "nie\u00b7mahls", "m\u00e4ch\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch weil manch Kluger in der Welt", "tokens": ["Doch", "weil", "manch", "Klu\u00b7ger", "in", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus Noth und \u00dcbereilung f\u00e4llt", "tokens": ["Aus", "Noth", "und", "\u00dc\u00b7be\u00b7rei\u00b7lung", "f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und manchmahl gro\u00dfe Leute fehlen,", "tokens": ["Und", "manch\u00b7mahl", "gro\u00b7\u00dfe", "Leu\u00b7te", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So, hof ich, wird auch dein Verstand", "tokens": ["So", ",", "hof", "ich", ",", "wird", "auch", "dein", "Ver\u00b7stand"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mich, der ich dir so frey bekand,", "tokens": ["Mich", ",", "der", "ich", "dir", "so", "frey", "be\u00b7kand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nicht mit der scharfen Straf versagter Freundschaft qu\u00e4len.", "tokens": ["Nicht", "mit", "der", "schar\u00b7fen", "Straf", "ver\u00b7sag\u00b7ter", "Freund\u00b7schaft", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Las, was du giebst, verloren seyn,", "tokens": ["Las", ",", "was", "du", "giebst", ",", "ver\u00b7lo\u00b7ren", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "VVFIN", "$,", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Himmel kan es wiedergeben", "tokens": ["Der", "Him\u00b7mel", "kan", "es", "wie\u00b7der\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und, ob gleich tausend L\u00e4strer schreyn,", "tokens": ["Und", ",", "ob", "gleich", "tau\u00b7send", "L\u00e4st\u00b7rer", "schreyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ADV", "CARD", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich dennoch aus dem Staube heben;", "tokens": ["Mich", "den\u00b7noch", "aus", "dem", "Stau\u00b7be", "he\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die F\u00fchrung schickt's oft wunderlich.", "tokens": ["Die", "F\u00fch\u00b7rung", "schickt's", "oft", "wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es ist nicht rathsam, da\u00df ich mich", "tokens": ["Es", "ist", "nicht", "rath\u00b7sam", ",", "da\u00df", "ich", "mich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Auf Blat und Feder mehr erkl\u00e4re,", "tokens": ["Auf", "Blat", "und", "Fe\u00b7der", "mehr", "er\u00b7kl\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Indem ich schon zuviel gesagt", "tokens": ["In\u00b7dem", "ich", "schon", "zu\u00b7viel", "ge\u00b7sagt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und ofenherzig hier geklagt;", "tokens": ["Und", "o\u00b7fen\u00b7her\u00b7zig", "hier", "ge\u00b7klagt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das macht, ich sag's allein der klugen . . . . . [Speere].", "tokens": ["Das", "macht", ",", "ich", "sag's", "al\u00b7lein", "der", "klu\u00b7gen", ".", ".", ".", ".", ".", "Spee\u00b7re", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ART", "ADJA", "$.", "$.", "$.", "$.", "$.", "$(", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Von nun an hoft mein fester Schlu\u00df,", "tokens": ["Von", "nun", "an", "hoft", "mein", "fes\u00b7ter", "Schlu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Durch einsam und gelehrtes Wachen", "tokens": ["Durch", "ein\u00b7sam", "und", "ge\u00b7lehr\u00b7tes", "Wa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da, wo mich niemand finden mu\u00df,", "tokens": ["Da", ",", "wo", "mich", "nie\u00b7mand", "fin\u00b7den", "mu\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein zornig Gl\u00fccke gut zu machen.", "tokens": ["Mein", "zor\u00b7nig", "Gl\u00fc\u00b7cke", "gut", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df eine Frau von Wiz und Geist", "tokens": ["Da\u00df", "ei\u00b7ne", "Frau", "von", "Wiz", "und", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich in der Noth mit Huld gespeist,", "tokens": ["Mich", "in", "der", "Noth", "mit", "Huld", "ge\u00b7speist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das wird die Redligkeit bedencken,", "tokens": ["Das", "wird", "die", "Red\u00b7lig\u00b7keit", "be\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und w\u00fcrdestu auch achtzig Jahr,", "tokens": ["Und", "w\u00fcr\u00b7des\u00b7tu", "auch", "acht\u00b7zig", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So soll dir doch der Musen Schaar", "tokens": ["So", "soll", "dir", "doch", "der", "Mu\u00b7sen", "Schaar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit Recht der Sch\u00f6nheit Ruhm vor allen M\u00e4gdgen schencken.", "tokens": ["Mit", "Recht", "der", "Sch\u00f6n\u00b7heit", "Ruhm", "vor", "al\u00b7len", "M\u00e4gd\u00b7gen", "schen\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die Ehrfurcht gegen deinen Werth", "tokens": ["Die", "Ehr\u00b7furcht", "ge\u00b7gen", "dei\u00b7nen", "Werth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Soll unterdes verborgen glimmen,", "tokens": ["Soll", "un\u00b7ter\u00b7des", "ver\u00b7bor\u00b7gen", "glim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Weil doch der P\u00f6bel nicht erf\u00e4hrt,", "tokens": ["Weil", "doch", "der", "P\u00f6\u00b7bel", "nicht", "er\u00b7f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie z\u00e4rtlich kluge Seelen stimmen.", "tokens": ["Wie", "z\u00e4rt\u00b7lich", "klu\u00b7ge", "See\u00b7len", "stim\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du magst mich ha\u00dfen, fliehn und schm\u00e4hn,", "tokens": ["Du", "magst", "mich", "ha\u00b7\u00dfen", ",", "fliehn", "und", "schm\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "$,", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es wird mir freylich weh geschehn,", "tokens": ["Es", "wird", "mir", "frey\u00b7lich", "weh", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch soll mich nichts von dir verdrie\u00dfen.", "tokens": ["Doch", "soll", "mich", "nichts", "von", "dir", "ver\u00b7drie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PIS", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zerrei\u00df sogar auch dieses Blat,", "tokens": ["Zer\u00b7rei\u00df", "so\u00b7gar", "auch", "die\u00b7ses", "Blat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wofern es dich beleidigt hat;", "tokens": ["Wo\u00b7fern", "es", "dich", "be\u00b7lei\u00b7digt", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Neigung gegen dich bleibt ewig unzerri\u00dfen.", "tokens": ["Die", "Nei\u00b7gung", "ge\u00b7gen", "dich", "bleibt", "e\u00b7wig", "un\u00b7zer\u00b7ri\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}