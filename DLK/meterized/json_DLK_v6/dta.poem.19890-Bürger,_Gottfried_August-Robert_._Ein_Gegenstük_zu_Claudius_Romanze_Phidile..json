{"dta.poem.19890": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Robert .  \n Ein Gegenst\u00fck zu Claudius Romanze  \n Phidile.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1778", "urn": "urn:nbn:de:kobv:b4-20090519672", "language": ["de:0.99"], "booktitle": "B\u00fcrger, Gottfried August: Gedichte. G\u00f6ttingen, 1778."}, "poem": {"stanza.1": {"line.1": {"text": "Ich war wol recht ein Springinsfeld,               ", "tokens": ["Ich", "war", "wol", "recht", "ein", "Sprin\u00b7gins\u00b7feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meinen J\u00fcnglingstagen;", "tokens": ["In", "mei\u00b7nen", "J\u00fcng\u00b7lings\u00b7ta\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und that nichts lieber auf der Welt,", "tokens": ["Und", "that", "nichts", "lie\u00b7ber", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als reiten, fischen, jagen.", "tokens": ["Als", "rei\u00b7ten", ",", "fi\u00b7schen", ",", "ja\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Einst zogen meine Streiferei\u2019n \u2014", "tokens": ["Einst", "zo\u00b7gen", "mei\u00b7ne", "Strei\u00b7fe\u00b7rei'n"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weis nicht, auf welche Weise?", "tokens": ["Weis", "nicht", ",", "auf", "wel\u00b7che", "Wei\u00b7se", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "APPR", "PWAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch war es recht, als solt\u2019 es seyn. \u2014", "tokens": ["Doch", "war", "es", "recht", ",", "als", "solt'", "es", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich ab von meinem Gleise.", "tokens": ["Mich", "ab", "von", "mei\u00b7nem", "Glei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da sah ich \u00fcber\u2019n gr\u00fcnen Zaun,", "tokens": ["Da", "sah", "ich", "\u00fc\u00b7ber'n", "gr\u00fc\u00b7nen", "Zaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im lichten Fr\u00fchlingsgarten,", "tokens": ["Im", "lich\u00b7ten", "Fr\u00fch\u00b7lings\u00b7gar\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein M\u00e4dchen, rosig anzuschaun,", "tokens": ["Ein", "M\u00e4d\u00b7chen", ",", "ro\u00b7sig", "an\u00b7zu\u00b7schaun", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Schwesterblumen warten.", "tokens": ["Der", "Schwes\u00b7ter\u00b7blu\u00b7men", "war\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ein M\u00e4dchen, so von Angesicht,", "tokens": ["Ein", "M\u00e4d\u00b7chen", ",", "so", "von", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Stirn und Augenstralen,", "tokens": ["Von", "Stirn", "und", "Au\u00b7gen\u00b7stra\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Wuchs und Wesen, l\u00e4st sich nicht", "tokens": ["Von", "Wuchs", "und", "We\u00b7sen", ",", "l\u00e4st", "sich", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VVFIN", "PRF", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beschreiben und nicht malen.", "tokens": ["Be\u00b7schrei\u00b7ben", "und", "nicht", "ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich freundlich hin, sie freundlich her,", "tokens": ["Ich", "freund\u00b7lich", "hin", ",", "sie", "freund\u00b7lich", "her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKVZ", "$,", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir musten beid\u2019 uns gr\u00fcssen,", "tokens": ["Wir", "mus\u00b7ten", "beid'", "uns", "gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und fragten nicht, wohin? woher?", "tokens": ["Und", "frag\u00b7ten", "nicht", ",", "wo\u00b7hin", "?", "wo\u00b7her", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "PWAV", "$.", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch minder, wie wir hiessen?", "tokens": ["Noch", "min\u00b7der", ",", "wie", "wir", "hies\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Sie schm\u00fckte gr\u00fcn und rot den Hut,", "tokens": ["Sie", "schm\u00fck\u00b7te", "gr\u00fcn", "und", "rot", "den", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Brach Fr\u00fcchte mir vom Stengel;", "tokens": ["Brach", "Fr\u00fcch\u00b7te", "mir", "vom", "Sten\u00b7gel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und war so lieblich, war so gut,", "tokens": ["Und", "war", "so", "lieb\u00b7lich", ",", "war", "so", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So himlisch, wie ein Engel!", "tokens": ["So", "him\u00b7lisch", ",", "wie", "ein", "En\u00b7gel", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Doch wust\u2019 ich nicht, was tief aus mir", "tokens": ["Doch", "wust'", "ich", "nicht", ",", "was", "tief", "aus", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "ADJD", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So seufzte, so erbebte,", "tokens": ["So", "seufz\u00b7te", ",", "so", "er\u00b7beb\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und, unter Druk und K\u00fcssen, ihr", "tokens": ["Und", ",", "un\u00b7ter", "Druk", "und", "K\u00fcs\u00b7sen", ",", "ihr"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "$,", "APPR", "NN", "KON", "NN", "$,", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was vorzuweinen strebte.", "tokens": ["Was", "vor\u00b7zu\u00b7wei\u00b7nen", "streb\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ich konte weder her noch hin,", "tokens": ["Ich", "kon\u00b7te", "we\u00b7der", "her", "noch", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht weg, nicht zu ihr kommen;", "tokens": ["Nicht", "weg", ",", "nicht", "zu", "ihr", "kom\u00b7men", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKVZ", "$,", "PTKNEG", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auch lag\u2019s nicht anders mir im Sin,", "tokens": ["Auch", "lag's", "nicht", "an\u00b7ders", "mir", "im", "Sin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "ADV", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als w\u00e4r\u2019 mir was genommen.", "tokens": ["Als", "w\u00e4r'", "mir", "was", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Mich d\u00fcnkt\u2019 ich hatt\u2019 ihr tausendviel,", "tokens": ["Mich", "d\u00fcnkt'", "ich", "hatt'", "ihr", "tau\u00b7send\u00b7viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weis Gott al was? zu sagen:", "tokens": ["Weis", "Gott", "al", "was", "?", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "PWS", "$.", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch kont\u2019 ich, welch ein Zauberspiel!", "tokens": ["Doch", "kont'", "ich", ",", "welch", "ein", "Zau\u00b7ber\u00b7spiel", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$,", "PWAT", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht eine Sylbe wagen.", "tokens": ["Nicht", "ei\u00b7ne", "Syl\u00b7be", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "In heller Unschuld frug sie: Was?", "tokens": ["In", "hel\u00b7ler", "Un\u00b7schuld", "frug", "sie", ":", "Was", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "$.", "PWS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was ich wol von ihr wolte?", "tokens": ["Was", "ich", "wol", "von", "ihr", "wol\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "APPR", "PPER", "VMFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ach Liebe! rief ich, als mir\u2019s nas", "tokens": ["Ach", "Lie\u00b7be", "!", "rief", "ich", ",", "als", "mir's", "nas"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "NN", "$.", "VVFIN", "PPER", "$,", "KOUS", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von beiden Wangen rolte.", "tokens": ["Von", "bei\u00b7den", "Wan\u00b7gen", "rol\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Sie aber schlug den dunkeln Blik", "tokens": ["Sie", "a\u00b7ber", "schlug", "den", "dun\u00b7keln", "Blik"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum sch\u00f6nen Busen nieder,", "tokens": ["Zum", "sch\u00f6\u00b7nen", "Bu\u00b7sen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ich versch\u00fcchtert floh zur\u00fck,", "tokens": ["Und", "ich", "ver\u00b7sch\u00fcch\u00b7tert", "floh", "zu\u00b7r\u00fck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und fand sie noch nicht wieder! \u2014", "tokens": ["Und", "fand", "sie", "noch", "nicht", "wie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wie konte wol dies Eine Wort,", "tokens": ["Wie", "kon\u00b7te", "wol", "dies", "Ei\u00b7ne", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "PDS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies W\u00f6rtchen sie betr\u00fcben? \u2014", "tokens": ["Dies", "W\u00f6rt\u00b7chen", "sie", "be\u00b7tr\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "O bl\u00f6der Junge! w\u00e4rst du dort,", "tokens": ["O", "bl\u00f6\u00b7der", "Jun\u00b7ge", "!", "w\u00e4rst", "du", "dort", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "W\u00e4rst du doch dort geblieben!", "tokens": ["W\u00e4rst", "du", "doch", "dort", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}