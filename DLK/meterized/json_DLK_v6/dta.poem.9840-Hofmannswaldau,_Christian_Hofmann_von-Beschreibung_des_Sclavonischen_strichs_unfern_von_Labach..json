{"dta.poem.9840": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Beschreibung des Sclavonischen strichs  \n unfern von Labach.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So Agatha mich nicht vergessen hat zu lieben/", "tokens": ["So", "A\u00b7gat\u00b7ha", "mich", "nicht", "ver\u00b7ges\u00b7sen", "hat", "zu", "lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PPER", "PTKNEG", "VVPP", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nachdem man dich von mir und mich von dir getrieben/", "tokens": ["Nach\u00b7dem", "man", "dich", "von", "mir", "und", "mich", "von", "dir", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "PPER", "KON", "PRF", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und meine wenigkeit gerissen von der brust/", "tokens": ["Und", "mei\u00b7ne", "we\u00b7nig\u00b7keit", "ge\u00b7ris\u00b7sen", "von", "der", "brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die stets bereichert steht mit s\u00fcsser liebes-kost;", "tokens": ["Die", "stets", "be\u00b7rei\u00b7chert", "steht", "mit", "s\u00fcs\u00b7ser", "lie\u00b7bes\u00b7kost", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wird sie dis papier/ den zeugen meiner sinnen/", "tokens": ["So", "wird", "sie", "dis", "pa\u00b7pier", "/", "den", "zeu\u00b7gen", "mei\u00b7ner", "sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "NN", "$(", "ART", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ewig dienstbar sind/ nicht gantz umbstossen k\u00f6nnen/", "tokens": ["Die", "e\u00b7wig", "dienst\u00b7bar", "sind", "/", "nicht", "gantz", "umbs\u00b7tos\u00b7sen", "k\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "VAFIN", "$(", "PTKNEG", "ADV", "VVINF", "VMINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und h\u00f6ren/ wo und wie derselbe sich befindt/", "tokens": ["Und", "h\u00f6\u00b7ren", "/", "wo", "und", "wie", "der\u00b7sel\u00b7be", "sich", "be\u00b7findt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "PWAV", "KON", "PWAV", "PDAT", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der durch die seufftzer itzt vermehret luft und wind.", "tokens": ["Der", "durch", "die", "seufft\u00b7zer", "itzt", "ver\u00b7meh\u00b7ret", "luft", "und", "wind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "ADV", "VVFIN", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich/ edle Agatha/ bin hier umzirckt mit steinen/", "tokens": ["Ich", "/", "ed\u00b7le", "A\u00b7gat\u00b7ha", "/", "bin", "hier", "um\u00b7zirckt", "mit", "stei\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "ADJA", "NE", "$(", "VAFIN", "ADV", "VVFIN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der regen mehrt die pein/ den regen mehrt mein weinen.", "tokens": ["Der", "re\u00b7gen", "mehrt", "die", "pein", "/", "den", "re\u00b7gen", "mehrt", "mein", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "$(", "ART", "ADJA", "VVFIN", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ich seh und h\u00f6re nichts als klippen und den thon/", "tokens": ["Ich", "seh", "und", "h\u00f6\u00b7re", "nichts", "als", "klip\u00b7pen", "und", "den", "thon", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PIS", "KOKOM", "VVFIN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der von dem seuftzen kommt/ und dann zu meinem hohn", "tokens": ["Der", "von", "dem", "seuft\u00b7zen", "kommt", "/", "und", "dann", "zu", "mei\u00b7nem", "hohn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$(", "KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein felsen widerbillt; ich bin in einer w\u00fcsten/", "tokens": ["Ein", "fel\u00b7sen", "wi\u00b7der\u00b7billt", ";", "ich", "bin", "in", "ei\u00b7ner", "w\u00fcs\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VAFIN", "APPR", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da nichts als bestien und wilde v\u00f6gel nisten;", "tokens": ["Da", "nichts", "als", "be\u00b7sti\u00b7en", "und", "wil\u00b7de", "v\u00f6\u00b7gel", "nis\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KOKOM", "VVFIN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Mit kurtzem: hab ich mich ie deinen knecht genannt/", "tokens": ["Mit", "kurt\u00b7zem", ":", "hab", "ich", "mich", "ie", "dei\u00b7nen", "knecht", "ge\u00b7nannt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$.", "VAFIN", "PPER", "PRF", "ADV", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So bin ich es gewi\u00df hie in der Sclaven land;", "tokens": ["So", "bin", "ich", "es", "ge\u00b7wi\u00df", "hie", "in", "der", "Scla\u00b7ven", "land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und wilstu von der art des volckes etwas wissen/", "tokens": ["Und", "wils\u00b7tu", "von", "der", "art", "des", "vol\u00b7ckes", "et\u00b7was", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "ART", "ADJA", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So sag ich wie es ist/ man wei\u00df hier nichts von k\u00fcssen/", "tokens": ["So", "sag", "ich", "wie", "es", "ist", "/", "man", "wei\u00df", "hier", "nichts", "von", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PWAV", "PPER", "VAFIN", "$(", "PIS", "VVFIN", "ADV", "PIS", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Indem das rauhe land fast keine sch\u00f6nheit kennt/", "tokens": ["In\u00b7dem", "das", "rau\u00b7he", "land", "fast", "kei\u00b7ne", "sch\u00f6n\u00b7heit", "kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die/ so am dicksten ist/ wird Helena genennt:", "tokens": ["Die", "/", "so", "am", "dicks\u00b7ten", "ist", "/", "wird", "He\u00b7le\u00b7na", "ge\u00b7nennt", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ADV", "APPRART", "ADJA", "VAFIN", "$(", "VAFIN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich glaube/ da\u00df man sie nach dem gewichte sch\u00e4tzet.", "tokens": ["Ich", "glau\u00b7be", "/", "da\u00df", "man", "sie", "nach", "dem", "ge\u00b7wich\u00b7te", "sch\u00e4t\u00b7zet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PIS", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die\u00df/ was das wilde volck am kr\u00e4ftigsten ergetzet/", "tokens": ["Die\u00df", "/", "was", "das", "wil\u00b7de", "volck", "am", "kr\u00e4f\u00b7tigs\u00b7ten", "er\u00b7get\u00b7zet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "PWS", "ART", "ADJA", "NN", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.23": {"text": "Ist feuer/ knobloch/ wein/ und endlich ein geschrey/", "tokens": ["Ist", "feu\u00b7er", "/", "kno\u00b7bloch", "/", "wein", "/", "und", "end\u00b7lich", "ein", "ge\u00b7schrey", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "VVFIN", "$(", "PTKVZ", "$(", "KON", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Zu zeigen da\u00df allhier Cyclopen-wohnung sey.", "tokens": ["Zu", "zei\u00b7gen", "da\u00df", "all\u00b7hier", "Cy\u00b7clo\u00b7pen\u00b7woh\u00b7nung", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KOUS", "ADV", "NN", "VAFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "Das brodt/ so man geneust/ tr\u00e4gt steine/ sand und erden/", "tokens": ["Das", "brodt", "/", "so", "man", "ge\u00b7neust", "/", "tr\u00e4gt", "stei\u00b7ne", "/", "sand", "und", "er\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PIS", "VVPP", "$(", "VVFIN", "VVFIN", "$(", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die stube will mit macht zu einer h\u00f6lle werden;", "tokens": ["Die", "stu\u00b7be", "will", "mit", "macht", "zu", "ei\u00b7ner", "h\u00f6l\u00b7le", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "VVFIN", "APPR", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Reucht heftiger als selbst die apothecken nicht/", "tokens": ["Reucht", "hef\u00b7ti\u00b7ger", "als", "selbst", "die", "a\u00b7pot\u00b7hec\u00b7ken", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KOKOM", "ADV", "ART", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Nur da\u00df ihr blo\u00df allein die liebligkeit gebricht/", "tokens": ["Nur", "da\u00df", "ihr", "blo\u00df", "al\u00b7lein", "die", "lieb\u00b7lig\u00b7keit", "ge\u00b7bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und vor zibeth der mist die d\u00fcnne nase f\u00fcllet.", "tokens": ["Und", "vor", "zi\u00b7beth", "der", "mist", "die", "d\u00fcn\u00b7ne", "na\u00b7se", "f\u00fcl\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Wer hier zu bette geht/ der lieget nicht umh\u00fcllet", "tokens": ["Wer", "hier", "zu", "bet\u00b7te", "geht", "/", "der", "lie\u00b7get", "nicht", "um\u00b7h\u00fcl\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PTKZU", "VVFIN", "VVFIN", "$(", "ART", "VVFIN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Mit leinwand von Cambray/ er kriegt an dessen statt", "tokens": ["Mit", "lein\u00b7wand", "von", "Camb\u00b7ray", "/", "er", "kriegt", "an", "des\u00b7sen", "statt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NE", "$(", "PPER", "VVFIN", "APPR", "PRELAT", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.32": {"text": "Ein altes l\u00e4mmerfell/ so tausend g\u00e4ste hat", "tokens": ["Ein", "al\u00b7tes", "l\u00e4m\u00b7mer\u00b7fell", "/", "so", "tau\u00b7send", "g\u00e4s\u00b7te", "hat"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJD", "$(", "ADV", "ADJD", "ADJA", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und st\u00fcndlich reicher wird. Kein bild ist hier zu holen/", "tokens": ["Und", "st\u00fcnd\u00b7lich", "rei\u00b7cher", "wird", ".", "Kein", "bild", "ist", "hier", "zu", "ho\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VAFIN", "$.", "PIAT", "NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So nicht ein starcker knecht mit einer geilen kohlen", "tokens": ["So", "nicht", "ein", "star\u00b7cker", "knecht", "mit", "ei\u00b7ner", "gei\u00b7len", "koh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Den zweck und auch den pfeil des buhlers abgemahlt;", "tokens": ["Den", "zweck", "und", "auch", "den", "pfeil", "des", "buh\u00b7lers", "ab\u00b7ge\u00b7mahlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "In dem er nicht zu viel hat vor den trunck gezahlt/", "tokens": ["In", "dem", "er", "nicht", "zu", "viel", "hat", "vor", "den", "trunck", "ge\u00b7zahlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PTKNEG", "PTKA", "PIS", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Und auf die liebe denckt; an statt der porcellanen", "tokens": ["Und", "auf", "die", "lie\u00b7be", "denckt", ";", "an", "statt", "der", "por\u00b7cel\u00b7la\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "VVFIN", "$.", "APPR", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Da steht ein e\u00dfig-krug/ so von den groben ahnen", "tokens": ["Da", "steht", "ein", "e\u00b7\u00dfig\u00b7krug", "/", "so", "von", "den", "gro\u00b7ben", "ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "APPR", "ART", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Auf grobe kinder stammt; vor ein Venedisch gla\u00df", "tokens": ["Auf", "gro\u00b7be", "kin\u00b7der", "stammt", ";", "vor", "ein", "Ve\u00b7ne\u00b7disch", "gla\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.40": {"text": "Prangt eine k\u00e4se-form/ und denn/ ich wei\u00df nicht was/", "tokens": ["Prangt", "ei\u00b7ne", "k\u00e4\u00b7se\u00b7form", "/", "und", "denn", "/", "ich", "wei\u00df", "nicht", "was", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$(", "KON", "ADV", "$(", "PPER", "VVFIN", "PTKNEG", "PWS", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Schuh/ hechel/ striegel/ strumpf ligt bey den m\u00e4use-fallen;", "tokens": ["Schuh", "/", "he\u00b7chel", "/", "strie\u00b7gel", "/", "strumpf", "ligt", "bey", "den", "m\u00e4u\u00b7se\u00b7fal\u00b7len", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NE", "$(", "NN", "$(", "ADJD", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.42": {"text": "Wiewohl das arme thier gewi\u00df vor andren allen", "tokens": ["Wie\u00b7wohl", "das", "ar\u00b7me", "thier", "ge\u00b7wi\u00df", "vor", "an\u00b7dren", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "APPR", "PIS", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Hier ohne schulden stirbt: Mein eifer reist mir aus/", "tokens": ["Hier", "oh\u00b7ne", "schul\u00b7den", "stirbt", ":", "Mein", "ei\u00b7fer", "reist", "mir", "aus", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Ich schwere/ das privet ist gr\u00f6sser als das hau\u00df.", "tokens": ["Ich", "schwe\u00b7re", "/", "das", "pri\u00b7vet", "ist", "gr\u00f6s\u00b7ser", "als", "das", "hau\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PDS", "VVFIN", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.45": {"text": "Hier schlie\u00df ich Agatha die reimen/ nicht den willen/", "tokens": ["Hier", "schlie\u00df", "ich", "A\u00b7gat\u00b7ha", "die", "rei\u00b7men", "/", "nicht", "den", "wil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "ART", "VVINF", "$(", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Dasselbe was du sprichst mit freuden zu erf\u00fcllen;", "tokens": ["Das\u00b7sel\u00b7be", "was", "du", "sprichst", "mit", "freu\u00b7den", "zu", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "PWS", "PPER", "VVFIN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Nur tadele mir hier die k\u00fcrtze nicht zu sehr/", "tokens": ["Nur", "ta\u00b7de\u00b7le", "mir", "hier", "die", "k\u00fcrt\u00b7ze", "nicht", "zu", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "VVFIN", "PTKNEG", "PTKA", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Denn gantz Sclavonien hat keine dinte mehr.", "tokens": ["Denn", "gantz", "Scla\u00b7vo\u00b7ni\u00b7en", "hat", "kei\u00b7ne", "din\u00b7te", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}