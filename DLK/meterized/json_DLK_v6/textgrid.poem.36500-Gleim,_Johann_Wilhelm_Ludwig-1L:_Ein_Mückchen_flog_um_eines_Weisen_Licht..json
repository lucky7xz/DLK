{"textgrid.poem.36500": {"metadata": {"author": {"name": "Gleim, Johann Wilhelm Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein M\u00fcckchen flog um eines Weisen Licht.", "genre": "verse", "period": "N.A.", "pub_year": 1761, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein M\u00fcckchen flog um eines Weisen Licht.", "tokens": ["Ein", "M\u00fcck\u00b7chen", "flog", "um", "ei\u00b7nes", "Wei\u00b7sen", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bleib von der Sonne! sprach der Weise;", "tokens": ["Bleib", "von", "der", "Son\u00b7ne", "!", "sprach", "der", "Wei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das M\u00fcckchen aber folgte nicht:", "tokens": ["Das", "M\u00fcck\u00b7chen", "a\u00b7ber", "folg\u00b7te", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verwegen that's die k\u00fchne Reise", "tokens": ["Ver\u00b7we\u00b7gen", "that's", "die", "k\u00fch\u00b7ne", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Noch einmal um die Sonn' und fiel hinein.", "tokens": ["Noch", "ein\u00b7mal", "um", "die", "Sonn'", "und", "fiel", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Hab' ich dir's nicht gesagt? Du Sch\u00e4ker! sprach der Weise,", "tokens": ["Hab'", "ich", "dir's", "nicht", "ge\u00b7sagt", "?", "Du", "Sch\u00e4\u00b7ker", "!", "sprach", "der", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "PTKNEG", "VVPP", "$.", "PPER", "NN", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du sollst uns Menschen Warnung sein.", "tokens": ["Du", "sollst", "uns", "Men\u00b7schen", "War\u00b7nung", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Wesen eines Lichts,", "tokens": ["Das", "We\u00b7sen", "ei\u00b7nes", "Lichts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das, glaub' ich, wolltest du ergr\u00fcbeln!", "tokens": ["Das", ",", "glaub'", "ich", ",", "woll\u00b7test", "du", "er\u00b7gr\u00fc\u00b7beln", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wir Menschen gr\u00fcbeln auch in Sonnen und in Bibeln;", "tokens": ["Wir", "Men\u00b7schen", "gr\u00fc\u00b7beln", "auch", "in", "Son\u00b7nen", "und", "in", "Bi\u00b7beln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "ADV", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir gr\u00fcbeln, und ergr\u00fcbeln \u2013 nichts!", "tokens": ["Wir", "gr\u00fc\u00b7beln", ",", "und", "er\u00b7gr\u00fc\u00b7beln", "\u2013", "nichts", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVINF", "$(", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}