{"dta.poem.4433": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Ehe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1727", "urn": "urn:nbn:de:kobv:b4-200905198599", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So viel mir von der Eh bekannt,", "tokens": ["So", "viel", "mir", "von", "der", "Eh", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will ich euch itzt zu wissen s\u00fcgen.", "tokens": ["Will", "ich", "euch", "itzt", "zu", "wis\u00b7sen", "s\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist ein angenemer Stand,", "tokens": ["Es", "ist", "ein", "an\u00b7ge\u00b7ne\u00b7mer", "Stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Stand voll Anmut und Vergn\u00fcgen,", "tokens": ["Ein", "Stand", "voll", "An\u00b7mut", "und", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn Mann und Frau, in ihrer Jahrer Bl\u00fchte,", "tokens": ["Wenn", "Mann", "und", "Frau", ",", "in", "ih\u00b7rer", "Jah\u00b7rer", "Bl\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nebst einem billigen vertr\u00e4glichen Gem\u00fcte,", "tokens": ["Nebst", "ei\u00b7nem", "bil\u00b7li\u00b7gen", "ver\u00b7tr\u00e4g\u00b7li\u00b7chen", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und guten Mitteln, in die Eh", "tokens": ["Und", "gu\u00b7ten", "Mit\u00b7teln", ",", "in", "die", "Eh"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gesunde, wohlgebildete,", "tokens": ["Ge\u00b7sun\u00b7de", ",", "wohl\u00b7ge\u00b7bil\u00b7de\u00b7te", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und starke frische C\u00f6rper bringen,", "tokens": ["Und", "star\u00b7ke", "fri\u00b7sche", "C\u00f6r\u00b7per", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Auch ein von anderer Verbindung freyes Herz", "tokens": ["Auch", "ein", "von", "an\u00b7de\u00b7rer", "Ver\u00b7bin\u00b7dung", "frey\u00b7es", "Herz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "APPR", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Samt einem sanften Geist\u2019 in allen Dingen,", "tokens": ["Samt", "ei\u00b7nem", "sanf\u00b7ten", "Geist'", "in", "al\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Der auch beym Ernst zuweilen Scherz", "tokens": ["Der", "auch", "beym", "Ernst", "zu\u00b7wei\u00b7len", "Scherz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Herf\u00fcr zu bringen wei\u00df, und der die Welt,", "tokens": ["Her\u00b7f\u00fcr", "zu", "brin\u00b7gen", "wei\u00df", ",", "und", "der", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "VVFIN", "$,", "KON", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ohn da\u00df sie ihm zu wol gef\u00e4llt,", "tokens": ["Ohn", "da\u00df", "sie", "ihm", "zu", "wol", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PPER", "APPR", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Kennt, braucht, und gleichwol auch es unterlassen kann.", "tokens": ["Kennt", ",", "braucht", ",", "und", "gleich\u00b7wol", "auch", "es", "un\u00b7ter\u00b7las\u00b7sen", "kann", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "KON", "ADV", "ADV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "In solcher Ehe nun, davon ich sage,", "tokens": ["In", "sol\u00b7cher", "E\u00b7he", "nun", ",", "da\u00b7von", "ich", "sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "$,", "PAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.17": {"text": "Sind alle N\u00e4chte s\u00fc\u00df, und gl\u00fccklich alle Tage.", "tokens": ["Sind", "al\u00b7le", "N\u00e4ch\u00b7te", "s\u00fc\u00df", ",", "und", "gl\u00fcck\u00b7lich", "al\u00b7le", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "$,", "KON", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Kaum bricht der k\u00fcle Morgen an;", "tokens": ["Kaum", "bricht", "der", "k\u00fc\u00b7le", "Mor\u00b7gen", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So kehren Mann und Frau, nach einer sanften Ruh\u2019,", "tokens": ["So", "keh\u00b7ren", "Mann", "und", "Frau", ",", "nach", "ei\u00b7ner", "sanf\u00b7ten", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Jhr l\u00e4chlend Auge schon einander fr\u00f6hlich zu.", "tokens": ["Ihr", "l\u00e4ch\u00b7lend", "Au\u00b7ge", "schon", "ein\u00b7an\u00b7der", "fr\u00f6h\u00b7lich", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "K\u00f6mmt etwas ernstes vor; erw\u00e4g\u2019t mans in der Stille,", "tokens": ["K\u00f6mmt", "et\u00b7was", "erns\u00b7tes", "vor", ";", "er\u00b7w\u00e4g't", "mans", "in", "der", "Stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "PTKVZ", "$.", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und stimmt man etwan einst nicht \u00fcberein;", "tokens": ["Und", "stimmt", "man", "et\u00b7wan", "einst", "nicht", "\u00fc\u00b7be\u00b7re\u00b7in", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.23": {"text": "So mu\u00df nicht die Gewalt, nicht Eigenwille,", "tokens": ["So", "mu\u00df", "nicht", "die", "Ge\u00b7walt", ",", "nicht", "Ei\u00b7gen\u00b7wil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PTKNEG", "ART", "NN", "$,", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "In ihren Sachen Richter seyn.", "tokens": ["In", "ih\u00b7ren", "Sa\u00b7chen", "Rich\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Man unterweiset sich, man leitet,", "tokens": ["Man", "un\u00b7ter\u00b7wei\u00b7set", "sich", ",", "man", "lei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "$,", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Man stellt\u2019s einander vor, erkl\u00e4r\u2019t sich, und bedeutet,", "tokens": ["Man", "stellt's", "ein\u00b7an\u00b7der", "vor", ",", "er\u00b7kl\u00e4r't", "sich", ",", "und", "be\u00b7deu\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "PTKVZ", "$,", "VVFIN", "PRF", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ohn da\u00df man sich dabey zu weise d\u00fcnken lasse.", "tokens": ["Ohn", "da\u00df", "man", "sich", "da\u00b7bey", "zu", "wei\u00b7se", "d\u00fcn\u00b7ken", "las\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "PRF", "PAV", "PTKZU", "VVFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}