{"textgrid.poem.52405": {"metadata": {"author": {"name": "Reuter, Fritz", "birth": "N.A.", "death": "N.A."}, "title": "55. 'ne Geschicht' von minen ollen Fr\u00fcnd Rein ...", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.71", "et:0.28"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Min oll Fr\u00fcnd Rein .... was mal tau Ludwigslust", "tokens": ["Min", "oll", "Fr\u00fcnd", "Rein", "....", "was", "mal", "tau", "Lud\u00b7wigs\u00b7lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "NN", "NN", "$.", "PWS", "ADV", "CARD", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "As Kannedat. \u2013 Nu hett hei just", "tokens": ["As", "Kan\u00b7ne\u00b7dat", ".", "\u2013", "Nu", "hett", "hei", "just"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$.", "$(", "ADV", "VAFIN", "FM", "FM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In sinen braven, leiwen Lewen", "tokens": ["In", "si\u00b7nen", "bra\u00b7ven", ",", "lei\u00b7wen", "Le\u00b7wen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Nich vel up sch\u00f6ne Kleidung gewen:", "tokens": ["Nich", "vel", "up", "sch\u00f6\u00b7ne", "Klei\u00b7dung", "ge\u00b7wen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "NE", "ADJA", "NN", "VVPP", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "En grisen Rock, 'ne grise B\u00fcx,", "tokens": ["En", "gri\u00b7sen", "Rock", ",", "'ne", "gri\u00b7se", "B\u00fcx", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "En gris' Gesicht, doch't Hart noch jung,", "tokens": ["En", "gris'", "Ge\u00b7sicht", ",", "doch't", "Hart", "noch", "jung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "ADV", "NE", "ADV", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Dat was sin Up- un Neddersprung,", "tokens": ["Dat", "was", "sin", "Up", "un", "Ned\u00b7der\u00b7sprung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Wenn hei sick mal eins smet in Wichs.", "tokens": ["Wenn", "hei", "sick", "mal", "eins", "smet", "in", "Wichs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "FM", "FM", "ADV", "PIS", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Doch wer em richtig kennt', de trock", "tokens": ["Doch", "wer", "em", "rich\u00b7tig", "kennt'", ",", "de", "trock"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "PIS", "ADJD", "VVFIN", "$,", "NE", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "De M\u00fctz v\u00f6r sinen grisen Rock", "tokens": ["De", "M\u00fctz", "v\u00f6r", "si\u00b7nen", "gri\u00b7sen", "Rock"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "NE", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Un v\u00f6r sin grises Angesicht;", "tokens": ["Un", "v\u00f6r", "sin", "gri\u00b7ses", "An\u00b7ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Denn dat oll d\u00e4mlich Spr\u00fcchwurt l\u00fcggt:", "tokens": ["Denn", "dat", "oll", "d\u00e4m\u00b7lich", "Spr\u00fcch\u00b7wurt", "l\u00fcggt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJD", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "De Rock makt n\u00fcmmer mihr den Mann,", "tokens": ["De", "Rock", "makt", "n\u00fcm\u00b7mer", "mihr", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "As ick d\u00f6rch em bewisen kann.", "tokens": ["As", "ick", "d\u00f6rch", "em", "be\u00b7wi\u00b7sen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Na, einmal gung hei nah Kabellen,", "tokens": ["Na", ",", "ein\u00b7mal", "gung", "hei", "nah", "Ka\u00b7bel\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "NN", "VAFIN", "ADJD", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Sick 's Abends dor wat tau vertellen", "tokens": ["Sick", "'s", "A\u00b7bends", "dor", "wat", "tau", "ver\u00b7tel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "FM", "FM", "FM", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Un in en muntern lust'gen Swarm", "tokens": ["Un", "in", "en", "mun\u00b7tern", "lust'\u00b7gen", "Swarm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "FM", "FM", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "En Seidel Bier dortau tau drinken,", "tokens": ["En", "Sei\u00b7del", "Bier", "dor\u00b7tau", "tau", "drin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Denn dunn ded'n mit den langen Arm", "tokens": ["Denn", "dunn", "de\u00b7d'n", "mit", "den", "lan\u00b7gen", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Em noch de ollen Kneipen winken.", "tokens": ["Em", "noch", "de", "ol\u00b7len", "Knei\u00b7pen", "win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "NE", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Denn blot so'n Worm von Kannedat,", "tokens": ["Denn", "blot", "so'n", "Worm", "von", "Kan\u00b7ne\u00b7dat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "De't Seminor bes\u00e4uken s\u00fcll,", "tokens": ["De't", "Se\u00b7mi\u00b7nor", "be\u00b7s\u00e4u\u00b7ken", "s\u00fcll", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Dat is de ganze Wirtshusstat.", "tokens": ["Dat", "is", "de", "gan\u00b7ze", "Wirts\u00b7huss\u00b7tat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Kannedaten ward de Tid", "tokens": ["Den", "Kan\u00b7ne\u00b7da\u00b7ten", "ward", "de", "Tid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ok lang, un durt nich lang', so t\u00fcht", "tokens": ["Ok", "lang", ",", "un", "durt", "nich", "lang'", ",", "so", "t\u00fcht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADJD", "$,", "FM", "VVFIN", "PTKNEG", "ADV", "$,", "ADV", "VVFIN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.12": {"text": "Hei sick nah Rein .... en neger ran", "tokens": ["Hei", "sick", "nah", "Rein", "....", "en", "ne\u00b7ger", "ran"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["FM", "FM", "ADJD", "NN", "$(", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.13": {"text": "Un f\u00e4ngt mi em tau snacken an", "tokens": ["Un", "f\u00e4ngt", "mi", "em", "tau", "sna\u00b7cken", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Un redt em an, \u00bbmin leiwe Fr\u00fcnd\u00ab,", "tokens": ["Un", "redt", "em", "an", ",", "\u00bb", "min", "lei\u00b7we", "Fr\u00fcnd", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PIS", "PTKVZ", "$,", "$(", "PPOSAT", "ADJA", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Un fr\u00f6ggt up Plattd\u00fctsch em: \u00bbWer s\u00fcnd", "tokens": ["Un", "fr\u00f6ggt", "up", "Platt\u00b7d\u00fctsch", "em", ":", "\u00bb", "Wer", "s\u00fcnd"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$(", "PWS", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.16": {"text": "Sei, Fr\u00fcndting, wenn ick fragen darw?\u00ab", "tokens": ["Sei", ",", "Fr\u00fcnd\u00b7ting", ",", "wenn", "ick", "fra\u00b7gen", "darw", "?", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "$,", "NN", "$,", "KOUS", "PPER", "VVFIN", "PAV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Na, Rein .... en kettelt dit nu heil.", "tokens": ["Na", ",", "Rein", "....", "en", "ket\u00b7telt", "dit", "nu", "heil", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$.", "FM", "VVFIN", "NE", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "\u00bbick\u00ab, seggt hei, \u00bbb\u00fcn bi B\u00e4cker Breul", "tokens": ["\u00bb", "ick", "\u00ab", ",", "seggt", "hei", ",", "\u00bb", "b\u00fcn", "bi", "B\u00e4\u00b7cker", "Breul"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "$(", "$,", "VVFIN", "PTKVZ", "$,", "$(", "FM", "FM", "NN", "NE"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.19": {"text": "Gesell un driw dor min Gewarw.\u00ab", "tokens": ["Ge\u00b7sell", "un", "driw", "dor", "min", "Ge\u00b7warw", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Na, de Kann'dat, de will sick maken,", "tokens": ["Na", ",", "de", "Kann'\u00b7dat", ",", "de", "will", "sick", "ma\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NE", "NN", "$,", "NE", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Hett hei tauirst blot plattd\u00fctsch spraken,", "tokens": ["Hett", "hei", "tau\u00b7irst", "blot", "platt\u00b7d\u00fctsch", "spra\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "So geht er nun ins Hochdeutsch \u00fcber", "tokens": ["So", "geht", "er", "nun", "ins", "Hoch\u00b7deutsch", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Un nennt den Annern nu \u00bbmein Lieber\u00ab.", "tokens": ["Un", "nennt", "den", "An\u00b7nern", "nu", "\u00bb", "mein", "Lie\u00b7ber", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "ADV", "$(", "PPOSAT", "NN", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Un Rein ...., de antwurt't hochd\u00fctsch wedder.", "tokens": ["Un", "Rein", "....", ",", "de", "ant\u00b7wurt't", "hoch\u00b7d\u00fctsch", "wed\u00b7der", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "$,", "NE", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Na, den Kann'daten wunnert dit,", "tokens": ["Na", ",", "den", "Kann'\u00b7da\u00b7ten", "wun\u00b7nert", "dit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "VVFIN", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.26": {"text": "Dat Rein .... dat kann, un hei treckt mit", "tokens": ["Dat", "Rein", "....", "dat", "kann", ",", "un", "hei", "treckt", "mit"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "PAV", "VMFIN", "$,", "FM", "FM", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Latinsche Brocken von dat Ledder,", "tokens": ["La\u00b7tin\u00b7sche", "Bro\u00b7cken", "von", "dat", "Led\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.28": {"text": "Blot dat de Bur\u00df doch marken sall,", "tokens": ["Blot", "dat", "de", "Bur\u00df", "doch", "mar\u00b7ken", "sall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NE", "NE", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Dat sine Wissenschaftlichkeit", "tokens": ["Dat", "si\u00b7ne", "Wis\u00b7sen\u00b7schaft\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.30": {"text": "Hoch \u00e4wer't B\u00e4ckerhandwark steiht.", "tokens": ["Hoch", "\u00e4\u00b7wer't", "B\u00e4\u00b7cker\u00b7hand\u00b7wark", "steiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.31": {"text": "Doch wat gesch\u00fcht? Dat wohrt nich lang',", "tokens": ["Doch", "wat", "ge\u00b7sch\u00fcht", "?", "Dat", "wohrt", "nich", "lang'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$.", "NN", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Dunn br\u00f6ckelt Rein .... Latinsch ok mang,", "tokens": ["Dunn", "br\u00f6\u00b7ckelt", "Rein", "....", "La\u00b7tin\u00b7sch", "ok", "mang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$(", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Un dat nich f\u00f6r de Langewil:", "tokens": ["Un", "dat", "nich", "f\u00f6r", "de", "Lan\u00b7ge\u00b7wil", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Redt von Horaz un von Virgil", "tokens": ["Redt", "von", "Ho\u00b7raz", "un", "von", "Vir\u00b7gil"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "FM", "APPR", "NE"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.35": {"text": "Un von den oll'n Terenz nich minner,", "tokens": ["Un", "von", "den", "oll'n", "Te\u00b7renz", "nich", "min\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "ADJA", "NN", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "As wir'n de drei sin Annerb\u00e4ulkenkinner,", "tokens": ["As", "wir'n", "de", "drei", "sin", "An\u00b7ner\u00b7b\u00e4ul\u00b7ken\u00b7kin\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "As hadd hei s' \u00fcmmer helpen m\u00fc\u00dft,", "tokens": ["As", "hadd", "hei", "s'", "\u00fcm\u00b7mer", "hel\u00b7pen", "m\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.38": {"text": "Wenn ein von ehr sin Lex nich w\u00fc\u00dft.", "tokens": ["Wenn", "ein", "von", "ehr", "sin", "Lex", "nich", "w\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "NN", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "De Kannedat, de kickt un h\u00fcrt;", "tokens": ["De", "Kan\u00b7ne\u00b7dat", ",", "de", "kickt", "un", "h\u00fcrt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Denn orndlich gruglich f\u00f6r em wir't,", "tokens": ["Denn", "ornd\u00b7lich", "grug\u00b7lich", "f\u00f6r", "em", "wir't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Dat so en Deigap w\u00fc\u00dft Bescheid,", "tokens": ["Dat", "so", "en", "Dei\u00b7gap", "w\u00fc\u00dft", "Be\u00b7scheid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.42": {"text": "Wat in Horazen un Virgilen steiht.", "tokens": ["Wat", "in", "Ho\u00b7ra\u00b7zen", "un", "Vir\u00b7gi\u00b7len", "steiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "FM", "NN", "VVFIN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.43": {"text": "\u00bbmerkw\u00fcrdig\u00ab, seggt'e, \u00bbsehr! Mein Lieber,", "tokens": ["\u00bb", "merk\u00b7w\u00fcr\u00b7dig", "\u00ab", ",", "seggt'e", ",", "\u00bb", "sehr", "!", "Mein", "Lie\u00b7ber", ","], "token_info": ["punct", "word", "punct", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$(", "$,", "VVFIN", "$,", "$(", "ADV", "$.", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.44": {"text": "Ich mu\u00df gestehn, ich wund're mich dar\u00fcber,", "tokens": ["Ich", "mu\u00df", "ge\u00b7stehn", ",", "ich", "wun\u00b7d'\u00b7re", "mich", "da\u00b7r\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "PPER", "VVFIN", "PRF", "PAV", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.45": {"text": "Da\u00df Sie ...\u00ab", "tokens": ["Da\u00df", "Sie", "...", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "$(", "$("], "meter": "-+", "measure": "iambic.single"}, "line.46": {"text": "\u00bbmin Tid\u00ab, seggt Rein ...., \u00bbis nu v\u00f6rbi,", "tokens": ["\u00bb", "min", "Tid", "\u00ab", ",", "seggt", "Rein", "....", ",", "\u00bb", "is", "nu", "v\u00f6r\u00b7bi", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$(", "$,", "VVFIN", "NN", "$.", "$,", "$(", "FM", "FM", "FM", "$,"], "meter": "+---+---", "measure": "dactylic.init"}, "line.47": {"text": "Wi k\u00e4nen sp\u00e4der wider reden,", "tokens": ["Wi", "k\u00e4\u00b7nen", "sp\u00e4\u00b7der", "wi\u00b7der", "re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADJD", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Ick m\u00f6t nu hen un Stuten kneden.\u00ab", "tokens": ["Ick", "m\u00f6t", "nu", "hen", "un", "Stu\u00b7ten", "kne\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "NN", "VVINF", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.49": {"text": "Un nimmt sin M\u00fctz un seggt: \u00bbAdj\u00fc!\u00ab", "tokens": ["Un", "nimmt", "sin", "M\u00fctz", "un", "seggt", ":", "\u00bb", "Ad\u00b7j\u00fc", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$.", "$(", "NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "De Kannedat, de k\u00fcmmt den annern Morg'n", "tokens": ["De", "Kan\u00b7ne\u00b7dat", ",", "de", "k\u00fcmmt", "den", "an\u00b7nern", "Mor\u00b7g'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Tau sin Kam'raden, de in't Seminor", "tokens": ["Tau", "sin", "Kam'\u00b7ra\u00b7den", ",", "de", "in't", "Se\u00b7mi\u00b7nor"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "$,", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Tau't Schaulholl'n dor s\u00fcnd inpaukt word'n,", "tokens": ["Tau't", "Schaul\u00b7holl'n", "dor", "s\u00fcnd", "in\u00b7paukt", "word'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Un weit nu naug nich tau vertellen,", "tokens": ["Un", "weit", "nu", "naug", "nich", "tau", "ver\u00b7tel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADV", "VVFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wo dat hei gistern bi Kabellen", "tokens": ["Wo", "dat", "hei", "gis\u00b7tern", "bi", "Ka\u00b7bel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "FM.nl", "FM.nl", "FM.nl", "FM.nl", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "En ganz gew\u00f6hnlichen Deigapen", "tokens": ["En", "ganz", "ge\u00b7w\u00f6hn\u00b7li\u00b7chen", "Dei\u00b7ga\u00b7pen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "ADJA", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Tauf\u00e4llig in de Wirtsstuw drapen.", "tokens": ["Tau\u00b7f\u00e4l\u00b7lig", "in", "de", "Wirts\u00b7stuw", "dra\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbwenn ich's erz\u00e4hl', Sie sagen: 's ist nich wahr!", "tokens": ["\u00bb", "wenn", "ich's", "er\u00b7z\u00e4hl'", ",", "Sie", "sa\u00b7gen", ":", "'s", "ist", "nich", "wahr", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "VVFIN", "$,", "PPER", "VVINF", "$.", "PPER", "VAFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Denn, denken Sie, der Mensch, der sprach Latein;", "tokens": ["Denn", ",", "den\u00b7ken", "Sie", ",", "der", "Mensch", ",", "der", "sprach", "La\u00b7tein", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "ART", "NN", "$,", "PRELS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Die Bildung mu\u00df durch hies'ges Seminar", "tokens": ["Die", "Bil\u00b7dung", "mu\u00df", "durch", "hies'\u00b7ges", "Se\u00b7mi\u00b7nar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Gewaltig vorgeschritten sein.\u00ab", "tokens": ["Ge\u00b7wal\u00b7tig", "vor\u00b7ge\u00b7schrit\u00b7ten", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVPP", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Un nu beschriwwt hei denn den Gast.", "tokens": ["Un", "nu", "be\u00b7schriwwt", "hei", "denn", "den", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.13": {"text": "\u00bbna\u00ab, lacht denn nu hell up de ein,", "tokens": ["\u00bb", "na", "\u00ab", ",", "lacht", "denn", "nu", "hell", "up", "de", "ein", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$(", "$,", "VVFIN", "ADV", "ADV", "ADJD", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbick wedd dorup, dat was Fr\u00fcnd Rein ....\u00ab", "tokens": ["\u00bb", "ick", "wedd", "do\u00b7rup", ",", "dat", "was", "Fr\u00fcnd", "Rein", "....", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM.la", "FM.la", "FM.la", "$,", "PRELS", "PIS", "NN", "NN", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.15": {"text": "\u00bbja\u00ab, lachen s' all, \u00bbFr\u00fcnd Rein ...., de was't!\u00ab", "tokens": ["\u00bb", "ja", "\u00ab", ",", "la\u00b7chen", "s'", "all", ",", "\u00bb", "Fr\u00fcnd", "Rein", "....", ",", "de", "was't", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$(", "$,", "VVFIN", "NE", "PIAT", "$,", "$(", "NN", "NN", "$.", "$,", "FM", "FM", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Un as em dat verklort nu ward,", "tokens": ["Un", "as", "em", "dat", "ver\u00b7klort", "nu", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Dat hei taum besten hollen wir,", "tokens": ["Dat", "hei", "taum", "bes\u00b7ten", "hol\u00b7len", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Dunn seggt de Kannedat: \u00bbNa, wart'!", "tokens": ["Dunn", "seggt", "de", "Kan\u00b7ne\u00b7dat", ":", "\u00bb", "Na", ",", "wart'", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$.", "$(", "ITJ", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Ob ich mich nicht mal revangier'?\u00ab", "tokens": ["Ob", "ich", "mich", "nicht", "mal", "revan\u00b7gier'", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "ADV", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Den Nahmiddag teihn h\u00fcmpelwis", "tokens": ["Den", "Nah\u00b7mid\u00b7dag", "teihn", "h\u00fcm\u00b7pel\u00b7wis"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De Ludwigsluster tau'n Kanal;", "tokens": ["De", "Lud\u00b7wigs\u00b7lus\u00b7ter", "tau'n", "Ka\u00b7nal", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dat is so'n speigelblankes Is,", "tokens": ["Dat", "is", "so'n", "spei\u00b7gel\u00b7blan\u00b7kes", "Is", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Un allens flitscht dor up un dal.", "tokens": ["Un", "al\u00b7lens", "flitscht", "dor", "up", "un", "dal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ok in den grisen Rock Fr\u00fcnd Rein ....,", "tokens": ["Ok", "in", "den", "gri\u00b7sen", "Rock", "Fr\u00fcnd", "Rein", "....", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "APPR", "ART", "ADJA", "NN", "NN", "NN", "$.", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "De stakt dor r\u00fcm mit sine langen Bein", "tokens": ["De", "stakt", "dor", "r\u00fcm", "mit", "si\u00b7ne", "lan\u00b7gen", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Un l\u00f6ppt dor Schritschauh, dat't so pufft,", "tokens": ["Un", "l\u00f6ppt", "dor", "Schritsc\u00b7hauh", ",", "dat't", "so", "pufft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "NE", "$,", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Sin Hakenn\u00e4s' hoch in de Luft.", "tokens": ["Sin", "Ha\u00b7ken\u00b7n\u00e4s'", "hoch", "in", "de", "Luft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "APPR", "NE", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "Kum hett em de Kann'dat dor seihn,", "tokens": ["Kum", "hett", "em", "de", "Kann'\u00b7dat", "dor", "seihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Dunn r\u00f6nnt hei piplings up em in.", "tokens": ["Dunn", "r\u00f6nnt", "hei", "pip\u00b7lings", "up", "em", "in", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "\u00bbwar'n Sie nicht gestern bei Kabell?", "tokens": ["\u00bb", "wa\u00b7r'n", "Sie", "nicht", "ge\u00b7stern", "bei", "Ka\u00b7bell", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "PTKNEG", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Und sind Sie nicht ein B\u00e4ckergesell?", "tokens": ["Und", "sind", "Sie", "nicht", "ein", "B\u00e4\u00b7cker\u00b7ge\u00b7sell", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.13": {"text": "Nun sag'n ", "tokens": ["Nun", "sag'n"], "token_info": ["word", "word"], "pos": ["ADV", "VVINF"], "meter": "++", "measure": "spondeus"}, "line.14": {"text": "\u00bbje\u00ab, seggt uns' Rein ...., \u00bbwat s\u00fcll'n ", "tokens": ["\u00bb", "je", "\u00ab", ",", "seggt", "un\u00b7s'", "Rein", "....", ",", "\u00bb", "wat", "s\u00fcll'n"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "PPOSAT", "NN", "$.", "$,", "$(", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "So'n Ihrenkannedat villicht?\u00ab", "tokens": ["So'n", "Ih\u00b7ren\u00b7kan\u00b7ne\u00b7dat", "vil\u00b7licht", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbmein lieber Freund, das bin ich nicht,", "tokens": ["\u00bb", "mein", "lie\u00b7ber", "Freund", ",", "das", "bin", "ich", "nicht", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "$,", "PDS", "VAFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Ich bin ein richt'ger Schneidergesell.\u00ab", "tokens": ["Ich", "bin", "ein", "richt'\u00b7ger", "Schnei\u00b7der\u00b7ge\u00b7sell", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "\u00bbdat dacht ick mi\u00ab, seggt uns' Fr\u00fcnd Rein ....", "tokens": ["\u00bb", "dat", "dacht", "ick", "mi", "\u00ab", ",", "seggt", "un\u00b7s'", "Fr\u00fcnd", "Rein", "...."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.la", "FM.la", "FM.la", "FM.la", "$(", "$,", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.19": {"text": "Un swenkt links af mit sine langen Bein,", "tokens": ["Un", "swenkt", "links", "af", "mit", "si\u00b7ne", "lan\u00b7gen", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "NE", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "\u00bbdat heww'ck Sei gistern glik anseihn.\u00ab", "tokens": ["\u00bb", "dat", "hew\u00b7w'ck", "Sei", "gis\u00b7tern", "glik", "an\u00b7seihn", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}