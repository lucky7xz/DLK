{"textgrid.poem.49676": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Spruchweisheit", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Zeiten, da man seine Weisheit nicht", "tokens": ["Zu", "Zei\u00b7ten", ",", "da", "man", "sei\u00b7ne", "Weis\u00b7heit", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "KOUS", "PIS", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Aus Leitartikeln sch\u00f6pfte, wo die Alten,", "tokens": ["Aus", "Leit\u00b7ar\u00b7ti\u00b7keln", "sch\u00f6pf\u00b7te", ",", "wo", "die", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Weil sie das wechselvolle Leben kannten,", "tokens": ["Weil", "sie", "das", "wech\u00b7sel\u00b7vol\u00b7le", "Le\u00b7ben", "kann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fcr sehr viel kl\u00fcger als die Jungen galten,", "tokens": ["F\u00fcr", "sehr", "viel", "kl\u00fc\u00b7ger", "als", "die", "Jun\u00b7gen", "gal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ADJD", "KOKOM", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Zu jenen Zeiten hat sich unser Volk", "tokens": ["Zu", "je\u00b7nen", "Zei\u00b7ten", "hat", "sich", "un\u00b7ser", "Volk"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An guten Regeln einen Schatz gegr\u00fcndet,", "tokens": ["An", "gu\u00b7ten", "Re\u00b7geln", "ei\u00b7nen", "Schatz", "ge\u00b7gr\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hat an der V\u00e4ter Klugheit sich gehalten", "tokens": ["Hat", "an", "der", "V\u00e4\u00b7ter", "Klug\u00b7heit", "sich", "ge\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "PRF", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und nicht an sch\u00f6nen Reden sich entz\u00fcndet.", "tokens": ["Und", "nicht", "an", "sch\u00f6\u00b7nen", "Re\u00b7den", "sich", "ent\u00b7z\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "ADJA", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Das war wohl gut so, und ich m\u00f6chte euch,", "tokens": ["Das", "war", "wohl", "gut", "so", ",", "und", "ich", "m\u00f6ch\u00b7te", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "ADV", "$,", "KON", "PPER", "VMFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr Herrn vom gr\u00fcnen Tisch, ihr Diplomaten,", "tokens": ["Ihr", "Herrn", "vom", "gr\u00fc\u00b7nen", "Tisch", ",", "ihr", "Dip\u00b7lo\u00b7ma\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "ADJA", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Von Herzen bitten, bringt sie ab und zu", "tokens": ["Von", "Her\u00b7zen", "bit\u00b7ten", ",", "bringt", "sie", "ab", "und", "zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVINF", "$,", "VVFIN", "PPER", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zum allerh\u00f6chsten Ohr der Potentaten.", "tokens": ["Zum", "al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "Ohr", "der", "Po\u00b7ten\u00b7ta\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "In allem halte Ma\u00df. Das Wort", "tokens": ["In", "al\u00b7lem", "hal\u00b7te", "Ma\u00df", ".", "Das", "Wort"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist wirklich wert, da\u00df man es oft verwende,", "tokens": ["Ist", "wirk\u00b7lich", "wert", ",", "da\u00df", "man", "es", "oft", "ver\u00b7wen\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJD", "$,", "KOUS", "PIS", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den Kopf behalte k\u00fchl und warm den Fu\u00df,", "tokens": ["Den", "Kopf", "be\u00b7hal\u00b7te", "k\u00fchl", "und", "warm", "den", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn blinder Eifer f\u00fchrt zu schlechtem Ende.", "tokens": ["Denn", "blin\u00b7der", "Ei\u00b7fer", "f\u00fchrt", "zu", "schlech\u00b7tem", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Dann hei\u00dft es weiter: Schweigen ist wie Gold,", "tokens": ["Dann", "hei\u00dft", "es", "wei\u00b7ter", ":", "Schwei\u00b7gen", "ist", "wie", "Gold", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "NN", "VAFIN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Red' ist silbern, manchmal auch von Bleche,", "tokens": ["Die", "Red'", "ist", "sil\u00b7bern", ",", "manch\u00b7mal", "auch", "von", "Ble\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es ist nicht n\u00f6tig und es ist nicht gut,", "tokens": ["Es", "ist", "nicht", "n\u00f6\u00b7tig", "und", "es", "ist", "nicht", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "KON", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df vor dem Handeln man geschwollen spreche.", "tokens": ["Da\u00df", "vor", "dem", "Han\u00b7deln", "man", "ge\u00b7schwol\u00b7len", "spre\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PIS", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Gelingt dir etwas oder scheint es so,", "tokens": ["Ge\u00b7lingt", "dir", "et\u00b7was", "o\u00b7der", "scheint", "es", "so", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dann mu\u00dft du nicht in lauter Freude toben,", "tokens": ["Dann", "mu\u00dft", "du", "nicht", "in", "lau\u00b7ter", "Freu\u00b7de", "to\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Denn nichts Gewisses wei\u00df man nicht, und auch", "tokens": ["Denn", "nichts", "Ge\u00b7wis\u00b7ses", "wei\u00df", "man", "nicht", ",", "und", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIS", "NN", "VVFIN", "PIS", "PTKNEG", "$,", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Soll man den Tag nicht vor dem Abend loben.", "tokens": ["Soll", "man", "den", "Tag", "nicht", "vor", "dem", "A\u00b7bend", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Nichts wird so hei\u00df gegessen wie gekocht,", "tokens": ["Nichts", "wird", "so", "hei\u00df", "ge\u00b7ges\u00b7sen", "wie", "ge\u00b7kocht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "VVPP", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was dich nicht selber brennt, sollst du nicht blasen,", "tokens": ["Was", "dich", "nicht", "sel\u00b7ber", "brennt", ",", "sollst", "du", "nicht", "bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADV", "VVFIN", "$,", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Man mu\u00df nicht \u00fcberall dabei sein, und", "tokens": ["Man", "mu\u00df", "nicht", "\u00fc\u00b7be\u00b7rall", "da\u00b7bei", "sein", ",", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PIS", "VMFIN", "PTKNEG", "ADV", "PAV", "VAINF", "$,", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "In fremde T\u00f6pfe steckt nicht eure Nasen.", "tokens": ["In", "frem\u00b7de", "T\u00f6p\u00b7fe", "steckt", "nicht", "eu\u00b7re", "Na\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ich w\u00fc\u00dfte noch so manches kluge Wort,", "tokens": ["Ich", "w\u00fc\u00df\u00b7te", "noch", "so", "man\u00b7ches", "klu\u00b7ge", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch hab' ich eine Weisheit nicht vergessen,", "tokens": ["Doch", "hab'", "ich", "ei\u00b7ne", "Weis\u00b7heit", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die auch die Alten manchmal schon versp\u00fcrt:", "tokens": ["Die", "auch", "die", "Al\u00b7ten", "manch\u00b7mal", "schon", "ver\u00b7sp\u00fcrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit gro\u00dfen Herrn ist nicht gut Kirschen essen.", "tokens": ["Mit", "gro\u00b7\u00dfen", "Herrn", "ist", "nicht", "gut", "Kir\u00b7schen", "es\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PTKNEG", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}