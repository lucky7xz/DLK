{"textgrid.poem.37810": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Der Ritter und die Magd", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es spielt ein Ritter mit seiner Magd,", "tokens": ["Es", "spielt", "ein", "Rit\u00b7ter", "mit", "sei\u00b7ner", "Magd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bis an den hellen Morgen.", "tokens": ["Bis", "an", "den", "hel\u00b7len", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Bis da\u00df das M\u00e4dchen schwanger war,", "tokens": ["Bis", "da\u00df", "das", "M\u00e4d\u00b7chen", "schwan\u00b7ger", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da fing es an zu weinen;", "tokens": ["Da", "fing", "es", "an", "zu", "wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u00bbwein' nicht, wein' nicht, braun's M\u00e4delein,", "tokens": ["\u00bb", "wein'", "nicht", ",", "wein'", "nicht", ",", "braun's", "M\u00e4\u00b7de\u00b7lein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "$,", "VVFIN", "PTKNEG", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Ehr will ich dir zahlen,", "tokens": ["Dein", "Ehr", "will", "ich", "dir", "zah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich will dir geben den Reitknecht mein,", "tokens": ["Ich", "will", "dir", "ge\u00b7ben", "den", "Reit\u00b7knecht", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dazu f\u00fcnfhundert Thaler.\u00ab", "tokens": ["Da\u00b7zu", "f\u00fcnf\u00b7hun\u00b7dert", "Tha\u00b7ler", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PAV", "CARD", "NN", "$.", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "\u00bbden Reitknecht und den mag ich nicht,", "tokens": ["\u00bb", "den", "Reit\u00b7knecht", "und", "den", "mag", "ich", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "KON", "ART", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will lieber den Herrn selber;", "tokens": ["Will", "lie\u00b7ber", "den", "Herrn", "sel\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Wann ich den Herrn nicht selber krieg,", "tokens": ["Wann", "ich", "den", "Herrn", "nicht", "sel\u00b7ber", "krieg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So geh ich zu meiner Mutter,", "tokens": ["So", "geh", "ich", "zu", "mei\u00b7ner", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "In Freuden bin ich von ihr gangen,", "tokens": ["In", "Freu\u00b7den", "bin", "ich", "von", "ihr", "gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In Trauer wieder zu ihr.\u00ab", "tokens": ["In", "Trau\u00b7er", "wie\u00b7der", "zu", "ihr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "ADV", "APPR", "PPOSAT", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Und da sie vor die Stadt Augsburg kam,", "tokens": ["Und", "da", "sie", "vor", "die", "Stadt", "Augs\u00b7burg", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "Wohl in die enge Gasse,", "tokens": ["Wohl", "in", "die", "en\u00b7ge", "Gas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Da sah sie ihre Mutter stehn,", "tokens": ["Da", "sah", "sie", "ih\u00b7re", "Mut\u00b7ter", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An einem k\u00fchlen Wasser.", "tokens": ["An", "ei\u00b7nem", "k\u00fch\u00b7len", "Was\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u00bbbist du willkommen liebs T\u00f6chterlein,", "tokens": ["\u00bb", "bist", "du", "will\u00b7kom\u00b7men", "liebs", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wie ist es dir ergangen,", "tokens": ["Wie", "ist", "es", "dir", "er\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da\u00df dir dein Rock von vorne so klein,", "tokens": ["Da\u00df", "dir", "dein", "Rock", "von", "vor\u00b7ne", "so", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und hinten viel zu lange?\u00ab", "tokens": ["Und", "hin\u00b7ten", "viel", "zu", "lan\u00b7ge", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "PTKA", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u00bbund wie es mir ergangen ist,", "tokens": ["\u00bb", "und", "wie", "es", "mir", "er\u00b7gan\u00b7gen", "ist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWAV", "PPER", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das darf ich Euch wohl sagen:", "tokens": ["Das", "darf", "ich", "Euch", "wohl", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ich hab mit einem Edelherrn gespielt,", "tokens": ["Ich", "hab", "mit", "ei\u00b7nem", "E\u00b7del\u00b7herrn", "ge\u00b7spielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Kindlein mu\u00df ich tragen.\u00ab", "tokens": ["Ein", "Kin\u00b7dlein", "mu\u00df", "ich", "tra\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bbhast du mit einem Edelherrn gespielt,", "tokens": ["\u00bb", "hast", "du", "mit", "ei\u00b7nem", "E\u00b7del\u00b7herrn", "ge\u00b7spielt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das sollst du niemand sagen.", "tokens": ["Das", "sollst", "du", "nie\u00b7mand", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wenn du dein Kindlein zur Welt gebierst,", "tokens": ["Wenn", "du", "dein", "Kin\u00b7dlein", "zur", "Welt", "ge\u00b7bierst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Ins Wasser wollen wirs tragen.\u00ab", "tokens": ["Ins", "Was\u00b7ser", "wol\u00b7len", "wirs", "tra\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PIS", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbach nein, ach nein, liebe Mutter mein,", "tokens": ["\u00bb", "ach", "nein", ",", "ach", "nein", ",", "lie\u00b7be", "Mut\u00b7ter", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "PTKANT", "$,", "XY", "PTKANT", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Das wollen wir lassen bleiben.", "tokens": ["Das", "wol\u00b7len", "wir", "las\u00b7sen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Wann ich das Kind zur Welt geb\u00e4hr,", "tokens": ["Wann", "ich", "das", "Kind", "zur", "Welt", "ge\u00b7b\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Vater will ich zuschreiben.", "tokens": ["Dem", "Va\u00b7ter", "will", "ich", "zu\u00b7schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Ach Mutter, liebe Mutter mein,", "tokens": ["Ach", "Mut\u00b7ter", ",", "lie\u00b7be", "Mut\u00b7ter", "mein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Machet mir das Bettlein nicht zu klein,", "tokens": ["Ma\u00b7chet", "mir", "das", "Bet\u00b7tlein", "nicht", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.19": {"line.1": {"text": "Darin will ich leiden Schmerz und Pein,", "tokens": ["Da\u00b7rin", "will", "ich", "lei\u00b7den", "Schmerz", "und", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Dazu den bittern Tod.\u00ab", "tokens": ["Da\u00b7zu", "den", "bit\u00b7tern", "Tod", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Und da es war um Mitternacht,", "tokens": ["Und", "da", "es", "war", "um", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Edelherrn tr\u00e4umt es schwer:", "tokens": ["Dem", "E\u00b7del\u00b7herrn", "tr\u00e4umt", "es", "schwer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Als wenn sein herzallerliebster Schatz", "tokens": ["Als", "wenn", "sein", "her\u00b7zal\u00b7ler\u00b7liebs\u00b7ter", "Schatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Im Kindbett gestorben w\u00e4r.", "tokens": ["Im", "Kind\u00b7bett", "ge\u00b7stor\u00b7ben", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "\u00bbsteh auf, steh auf, lieb Reitknecht mein,", "tokens": ["\u00bb", "steh", "auf", ",", "steh", "auf", ",", "lieb", "Reit\u00b7knecht", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "ADJD", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sattle mir und dir zwey Pferd,", "tokens": ["Satt\u00b7le", "mir", "und", "dir", "zwey", "Pferd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "PPER", "CARD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Wir wollen reiten bey Tag und Nacht,", "tokens": ["Wir", "wol\u00b7len", "rei\u00b7ten", "bey", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bis wir den Traum erfahren.\u00ab", "tokens": ["Bis", "wir", "den", "Traum", "er\u00b7fah\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Und als sie \u00fcber die Heid 'naus kamen,", "tokens": ["Und", "als", "sie", "\u00fc\u00b7ber", "die", "Heid", "'naus", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "H\u00f6rten sie ein Gl\u00f6cklein l\u00e4uten.", "tokens": ["H\u00f6r\u00b7ten", "sie", "ein", "Gl\u00f6c\u00b7klein", "l\u00e4u\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.25": {"line.1": {"text": "\u00bbach gro\u00dfer Gott vom Himmel herab,", "tokens": ["\u00bb", "ach", "gro\u00b7\u00dfer", "Gott", "vom", "Him\u00b7mel", "her\u00b7ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "XY", "ADJA", "NN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Was mag doch die\u00df bedeuten.\u00ab", "tokens": ["Was", "mag", "doch", "die\u00df", "be\u00b7deu\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "ADV", "PDS", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Als sie vor die Stadt Augsburg kamen,", "tokens": ["Als", "sie", "vor", "die", "Stadt", "Augs\u00b7burg", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Wohl vor die hohe Thore,", "tokens": ["Wohl", "vor", "die", "ho\u00b7he", "Tho\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Hier sahen sie vier Tr\u00e4ger schwarz,", "tokens": ["Hier", "sa\u00b7hen", "sie", "vier", "Tr\u00e4\u00b7ger", "schwarz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit einer Todenbahre.", "tokens": ["Mit", "ei\u00b7ner", "To\u00b7den\u00b7bah\u00b7re", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "\u00bbstellt ab, stellt ab, ihr Tr\u00e4ger mein,", "tokens": ["\u00bb", "stellt", "ab", ",", "stellt", "ab", ",", "ihr", "Tr\u00e4\u00b7ger", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "PPOSAT", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00dft mir den Todten schauen,", "tokens": ["La\u00dft", "mir", "den", "Tod\u00b7ten", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Es m\u00f6cht meine Herzallerliebste sein", "tokens": ["Es", "m\u00f6cht", "mei\u00b7ne", "Her\u00b7zal\u00b7ler\u00b7liebs\u00b7te", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PPOSAT"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Mit ihren schwarzbraunen Augen.", "tokens": ["Mit", "ih\u00b7ren", "schwarz\u00b7brau\u00b7nen", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}}, "stanza.30": {"line.1": {"text": "Du bist f\u00fcrwahr mein Schatz gewe\u00dft,", "tokens": ["Du", "bist", "f\u00fcr\u00b7wahr", "mein", "Schatz", "ge\u00b7we\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hast es nicht geglaubet.", "tokens": ["Und", "hast", "es", "nicht", "ge\u00b7glau\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "H\u00e4tt dir der liebe Gott das Leben geschenkt,", "tokens": ["H\u00e4tt", "dir", "der", "lie\u00b7be", "Gott", "das", "Le\u00b7ben", "ge\u00b7schenkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "F\u00fcrwahr ich h\u00e4tt dich behalten.", "tokens": ["F\u00fcr\u00b7wahr", "ich", "h\u00e4tt", "dich", "be\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.32": {"line.1": {"text": "Hast du gelitten den bittern Tod,", "tokens": ["Hast", "du", "ge\u00b7lit\u00b7ten", "den", "bit\u00b7tern", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Jezt leid ich gro\u00dfe Schmerzen.\u00ab", "tokens": ["Jezt", "leid", "ich", "gro\u00b7\u00dfe", "Schmer\u00b7zen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Er zog das blanke Schwerdt heraus", "tokens": ["Er", "zog", "das", "blan\u00b7ke", "Schwerdt", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und stach es sich ins Herze.", "tokens": ["Und", "stach", "es", "sich", "ins", "Her\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPRART", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "\u00bbo nein! o nein! o Edelherr, nein,", "tokens": ["\u00bb", "o", "nein", "!", "o", "nein", "!", "o", "E\u00b7del\u00b7herr", ",", "nein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "FM", "PTKANT", "$.", "FM", "PTKANT", "$.", "FM", "NN", "$,", "PTKANT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das sollt ihr lassen bleiben,", "tokens": ["Das", "sollt", "ihr", "las\u00b7sen", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Es hat schon manches liebe Paar,", "tokens": ["Es", "hat", "schon", "man\u00b7ches", "lie\u00b7be", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von einander m\u00fcssen scheiden.\u00ab", "tokens": ["Von", "ein\u00b7an\u00b7der", "m\u00fcs\u00b7sen", "schei\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "VMFIN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "\u00bbmacht uns, macht uns ein tiefes Grab,", "tokens": ["\u00bb", "macht", "uns", ",", "macht", "uns", "ein", "tie\u00b7fes", "Grab", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wohl zwischen zwey hohe Felsen.", "tokens": ["Wohl", "zwi\u00b7schen", "zwey", "ho\u00b7he", "Fel\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.37": {"line.1": {"text": "Da will ich bey meinem herzliebsten Schatz,", "tokens": ["Da", "will", "ich", "bey", "mei\u00b7nem", "herz\u00b7liebs\u00b7ten", "Schatz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In seinem Arm erstehen.\u00ab", "tokens": ["In", "sei\u00b7nem", "Arm", "er\u00b7ste\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Sie begruben sie auf den Kirchhof hin,", "tokens": ["Sie", "be\u00b7gru\u00b7ben", "sie", "auf", "den", "Kirch\u00b7hof", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ihn aber unter den Galgen.", "tokens": ["Ihn", "a\u00b7ber", "un\u00b7ter", "den", "Gal\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.39": {"line.1": {"text": "Es stunde an kein Vierteljahr,", "tokens": ["Es", "stun\u00b7de", "an", "kein", "Vier\u00b7tel\u00b7jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eine Lilie w\u00e4chst auf seinem Grabe.", "tokens": ["Ei\u00b7ne", "Li\u00b7lie", "w\u00e4chst", "auf", "sei\u00b7nem", "Gra\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.40": {"line.1": {"text": "Es stund geschrieben auf den Bl\u00e4ttern da,", "tokens": ["Es", "stund", "ge\u00b7schrie\u00b7ben", "auf", "den", "Bl\u00e4t\u00b7tern", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Beyd w\u00e4ren beysammen im Himmel.", "tokens": ["Beyd", "w\u00e4\u00b7ren", "bey\u00b7sam\u00b7men", "im", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}