{"dta.poem.671": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  \n Letzte rede eines Gelehrten au\u00df seinem  \n Grabe.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Wje eitel ist was wir hoch sch\u00e4tzen! ", "tokens": ["Wie", "ei\u00b7tel", "ist", "was", "wir", "hoch", "sch\u00e4t\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VAFIN", "PWS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ist das eilendts nicht vergeht?", "tokens": ["Was", "ist", "das", "ei\u00b7lendts", "nicht", "ver\u00b7geht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "VVFIN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie fl\u00fcchtig/ was vns kan ergetzen! ", "tokens": ["Wie", "fl\u00fcch\u00b7tig", "/", "was", "vns", "kan", "er\u00b7get\u00b7zen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$(", "PWS", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie bald verf\u00e4llt was jtzundt steht.", "tokens": ["Wie", "bald", "ver\u00b7f\u00e4llt", "was", "jt\u00b7zundt", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PWS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie bald mu\u00df alles fleisch erbleichen! ", "tokens": ["Wie", "bald", "mu\u00df", "al\u00b7les", "fleisch", "er\u00b7blei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie pl\u00f6tzlich wirdt der mensch zur leichen!", "tokens": ["Wie", "pl\u00f6tz\u00b7lich", "wirdt", "der", "mensch", "zur", "lei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Ach", "tokens": ["Ach"], "token_info": ["word"], "pos": ["ITJ"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Vnd f\u00fcr der Welt zum wunder macht!", "tokens": ["Vnd", "f\u00fcr", "der", "Welt", "zum", "wun\u00b7der", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn nun der todt sein recht ausf\u00fchret;", "tokens": ["Wenn", "nun", "der", "todt", "sein", "recht", "aus\u00b7f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJD", "PPOSAT", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd vnser Geist in angst verschmacht.", "tokens": ["Vnd", "vn\u00b7ser", "Geist", "in", "angst", "ver\u00b7schmacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was n\u00fctzt doch aller Menschen wissen: ", "tokens": ["Was", "n\u00fctzt", "doch", "al\u00b7ler", "Men\u00b7schen", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn wir die lassen augen schlissen?", "tokens": ["Wenn", "wir", "die", "las\u00b7sen", "au\u00b7gen", "schlis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Kom wer du bist hier kanst du schawen/", "tokens": ["Kom", "wer", "du", "bist", "hier", "kanst", "du", "scha\u00b7wen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "PPER", "VAFIN", "ADV", "VMFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wo ich noch schawens w\u00fcrdig bin:", "tokens": ["Wo", "ich", "noch", "scha\u00b7wens", "w\u00fcr\u00b7dig", "bin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie di\u00df auff was wir Menschen bawen", "tokens": ["Wie", "di\u00df", "auff", "was", "wir", "Men\u00b7schen", "ba\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PDS", "APPR", "PRELS", "PPER", "NN", "VVINF"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Ein einig augenblick reist hin.", "tokens": ["Ein", "ei\u00b7nig", "au\u00b7gen\u00b7blick", "reist", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich bin ni", "tokens": ["Ich", "bin", "ni"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Den so manch\u2019 hoher sinn geehret.", "tokens": ["Den", "so", "man\u00b7ch'", "ho\u00b7her", "sinn", "ge\u00b7eh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "4. Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Dem Erd\u2019 vnd ", "tokens": ["Dem", "Erd'", "vnd"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "KON"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Vmbsonst ist nun mein weises sorgen.", "tokens": ["Vmbsonst", "ist", "nun", "mein", "wei\u00b7ses", "sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jtzt schweigt der wolberedte mund!", "tokens": ["Jtzt", "schweigt", "der", "wol\u00b7be\u00b7red\u00b7te", "mund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich der vorhin so viel durchlesen: ", "tokens": ["Ich", "der", "vor\u00b7hin", "so", "viel", "durch\u00b7le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Weis jtzt nicht was ich selbst gewesen.", "tokens": ["Weis", "jtzt", "nicht", "was", "ich", "selbst", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "PWS", "PPER", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Die beiden lichter/ die durch sehen/", "tokens": ["Die", "bei\u00b7den", "lich\u00b7ter", "/", "die", "durch", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$(", "ART", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der ewighellen li", "tokens": ["Der", "e\u00b7wig\u00b7hel\u00b7len", "li"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vnd was in Lufft ", "tokens": ["Vnd", "was", "in", "Lufft"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Vnd was nur anzutreffen war.", "tokens": ["Vnd", "was", "nur", "an\u00b7zu\u00b7tref\u00b7fen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVIZU", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die schier was jeder dacht/ erfunden.", "tokens": ["Die", "schier", "was", "je\u00b7der", "dacht", "/", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "PRELS", "PIS", "VVFIN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sindt blind/ vnd todt/ vnd gantz verschwunden. ", "tokens": ["Sindt", "blind", "/", "vnd", "todt", "/", "vnd", "gantz", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "KON", "ADJD", "$(", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Die zunge/ die Hertz/ Geist vnd leben/", "tokens": ["Die", "zun\u00b7ge", "/", "die", "Hertz", "/", "Geist", "vnd", "le\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$(", "NN", "KON", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gleich als ein donnerstrall durch ries: ", "tokens": ["Gleich", "als", "ein", "don\u00b7ner\u00b7strall", "durch", "ries", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die vber sterrnen kont\u2019 erheben:", "tokens": ["Die", "vber", "sterr\u00b7nen", "kont'", "er\u00b7he\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "VVINF", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die in den Abgrund nieder sties:", "tokens": ["Die", "in", "den", "Ab\u00b7grund", "nie\u00b7der", "sties", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die wilde k\u00f6nnen vor bewegen: ", "tokens": ["Die", "wil\u00b7de", "k\u00f6n\u00b7nen", "vor", "be\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Fault jtzt/ vnd kan sich selbst nicht regen. ", "tokens": ["Fault", "jtzt", "/", "vnd", "kan", "sich", "selbst", "nicht", "re\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$(", "KON", "VMFIN", "PRF", "ADV", "PTKNEG", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Die H\u00e4nde starren/ die geschriben/", "tokens": ["Die", "H\u00e4n\u00b7de", "star\u00b7ren", "/", "die", "ge\u00b7schri\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "ART", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was viel ber\u00fchmbter Leuth ergetzt:", "tokens": ["Was", "viel", "be\u00b7r\u00fchmb\u00b7ter", "Leuth", "er\u00b7getzt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die h\u00e4nde die so viel getriben/", "tokens": ["Die", "h\u00e4n\u00b7de", "die", "so", "viel", "ge\u00b7tri\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind durch de\u00df ", "tokens": ["Sind", "durch", "de\u00df"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Hier ist das ende meiner reisen:", "tokens": ["Hier", "ist", "das", "en\u00b7de", "mei\u00b7ner", "rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Alhier verl\u00e4st vns was ", "tokens": ["Al\u00b7hier", "ver\u00b7l\u00e4st", "vns", "was"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PWS"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "8. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Hier hilfft kein kraut: der Mensch ist gras.", "tokens": ["Hier", "hilfft", "kein", "kraut", ":", "der", "Mensch", "ist", "gras", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$.", "ART", "NN", "VAFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hier mu\u00df die sch\u00f6nheit selbst erbleichen.", "tokens": ["Hier", "mu\u00df", "die", "sch\u00f6n\u00b7heit", "selbst", "er\u00b7blei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hier hilft ni", "tokens": ["Hier", "hilft", "ni"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "++-", "measure": "unknown.measure.di"}, "line.5": {"text": "Hier hilft kein Adel; du bist Erden/", "tokens": ["Hier", "hilft", "kein", "A\u00b7del", ";", "du", "bist", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$.", "PPER", "VAFIN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht ruhm: du must zu Aschen werden.", "tokens": ["Nicht", "ruhm", ":", "du", "must", "zu", "A\u00b7schen", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$.", "PPER", "VMFIN", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "9. Hier hilft kein Purpur: kein gepr\u00e4nge.", "tokens": ["Hier", "hilft", "kein", "Pur\u00b7pur", ":", "kein", "ge\u00b7pr\u00e4n\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$.", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die herrligkeit ist nur ein Traum.", "tokens": ["Die", "herr\u00b7lig\u00b7keit", "ist", "nur", "ein", "Traum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd w\u00fcrd vns gleich die welt zue enge:", "tokens": ["Vnd", "w\u00fcrd", "vns", "gleich", "die", "welt", "zue", "en\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir finden doch im grabe raum.", "tokens": ["Wir", "fin\u00b7den", "doch", "im", "gra\u00b7be", "raum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hier gilt nicht gelt: nicht greise haare.", "tokens": ["Hier", "gilt", "nicht", "gelt", ":", "nicht", "grei\u00b7se", "haa\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "VVPP", "$.", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der todt wirfft alles auff die Bahre.", "tokens": ["Der", "todt", "wirfft", "al\u00b7les", "auff", "die", "Bah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "10. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Stand/ ", "tokens": ["Stand", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Vnd trage nichts denn diesen Kittel/", "tokens": ["Vnd", "tra\u00b7ge", "nichts", "denn", "die\u00b7sen", "Kit\u00b7tel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "PDAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd den geringen Sarck mit mir.", "tokens": ["Vnd", "den", "ge\u00b7rin\u00b7gen", "Sarck", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein nahme der noch scheint zue stehen", "tokens": ["Mein", "nah\u00b7me", "der", "noch", "scheint", "zue", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "ADV", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird au", "tokens": ["Wird", "au"], "token_info": ["word", "word"], "pos": ["VAFIN", "NE"], "meter": "-+", "measure": "iambic.single"}}, "stanza.11": {"line.1": {"text": "11. GOTT dem wir rechnung vbergeben/", "tokens": ["GoTT", "dem", "wir", "rech\u00b7nung", "vber\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "PPER", "ADV", "VVINF", "$("], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "Acht mein gelehrtes wissen nicht/", "tokens": ["Acht", "mein", "ge\u00b7lehr\u00b7tes", "wis\u00b7sen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "PPOSAT", "ADJA", "VVFIN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Er fors", "tokens": ["Er", "fors"], "token_info": ["word", "word"], "pos": ["PPER", "NE"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Vnd ob wir was er hies verricht.", "tokens": ["Vnd", "ob", "wir", "was", "er", "hies", "ver\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PWS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er will zwar weisheit mit viel kronen:", "tokens": ["Er", "will", "zwar", "weis\u00b7heit", "mit", "viel", "kro\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nur wenn sie jhm dient belohnen.", "tokens": ["Doch", "nur", "wenn", "sie", "jhm", "dient", "be\u00b7loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOUS", "PPER", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "12. Ade jhr g\u00e4ste dieser Erden.", "tokens": ["A\u00b7de", "jhr", "g\u00e4s\u00b7te", "die\u00b7ser", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "PDAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ich geh euch vor; jhr folget mir.", "tokens": ["Ich", "geh", "euch", "vor", ";", "jhr", "fol\u00b7get", "mir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was ich jtzt bin/ mus jeder werden/", "tokens": ["Was", "ich", "jtzt", "bin", "/", "mus", "je\u00b7der", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$(", "VMFIN", "PIS", "VAINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es galt mir heute; morgen dir/", "tokens": ["Es", "galt", "mir", "heu\u00b7te", ";", "mor\u00b7gen", "dir", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "ADV", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ade/ di\u00df m\u00f6", "tokens": ["A\u00b7de", "/", "di\u00df", "m\u00f6"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$(", "PDS", "VMFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Die gr\u00f6ste kunst ist k\u00f6nnen sterben. ", "tokens": ["Die", "gr\u00f6s\u00b7te", "kunst", "ist", "k\u00f6n\u00b7nen", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}