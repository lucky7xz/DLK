{"dta.poem.18552": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "U ber seinen  Z ustand.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1702", "urn": "urn:nbn:de:kobv:b4-200905197766", "language": ["de:0.99"], "booktitle": "Hunold, Christian Friedrich: Die Edle Bem\u00fchung m\u00fcssiger Stunden. Hamburg, 1702."}, "poem": {"stanza.1": {"line.1": {"text": "Wie lebet doch mein Geist? in Unruh und Vergn\u00fcgen/", "tokens": ["Wie", "le\u00b7bet", "doch", "mein", "Geist", "?", "in", "Un\u00b7ruh", "und", "Ver\u00b7gn\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "PPOSAT", "NN", "$.", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schmertz und Zufriedenheit \u00fcmarmen meine Brust.", "tokens": ["Schmertz", "und", "Zu\u00b7frie\u00b7den\u00b7heit", "\u00fcm\u00b7ar\u00b7men", "mei\u00b7ne", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Die edle Rose will bey harten Dornen liegen/", "tokens": ["Die", "ed\u00b7le", "Ro\u00b7se", "will", "bey", "har\u00b7ten", "Dor\u00b7nen", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Aloe zeigt sich zu Honig s\u00fcsser Lust.", "tokens": ["Die", "A\u00b7loe", "zeigt", "sich", "zu", "Ho\u00b7nig", "s\u00fcs\u00b7ser", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Mich rufft die Freudigkeit zwar offtermahls zu gaste/", "tokens": ["Mich", "rufft", "die", "Freu\u00b7dig\u00b7keit", "zwar", "off\u00b7ter\u00b7mahls", "zu", "gas\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADV", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch Augenblicklich k\u00f6mmt auch die betr\u00fcbte Faste.", "tokens": ["Doch", "Au\u00b7gen\u00b7blick\u00b7lich", "k\u00f6mmt", "auch", "die", "be\u00b7tr\u00fcb\u00b7te", "Fas\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Das heist: mein Gl\u00fccke bleibt in ungewissen Gr\u00e4ntzen/", "tokens": ["Das", "heist", ":", "mein", "Gl\u00fc\u00b7cke", "bleibt", "in", "un\u00b7ge\u00b7wis\u00b7sen", "Gr\u00e4nt\u00b7zen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$.", "PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nimmt bey seinen Schein auch ein Masque f\u00fcr.", "tokens": ["Und", "nimmt", "bey", "sei\u00b7nen", "Schein", "auch", "ein", "Mas\u00b7que", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "ART", "NN", "APPR", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Itzt zeiget sich die Nacht/ nun will die Sonne gl\u00e4ntzen/", "tokens": ["Itzt", "zei\u00b7get", "sich", "die", "Nacht", "/", "nun", "will", "die", "Son\u00b7ne", "gl\u00e4nt\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$(", "ADV", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es st\u00fcrmen Ost und West in Hafen noch auff mir.", "tokens": ["Es", "st\u00fcr\u00b7men", "Ost", "und", "West", "in", "Ha\u00b7fen", "noch", "auff", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Die Ungedult zerreist den F\u00fchrhang der Gedancken/", "tokens": ["Die", "Un\u00b7ge\u00b7dult", "zer\u00b7reist", "den", "F\u00fchr\u00b7hang", "der", "Ge\u00b7dan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und spricht: die Liebe f\u00fchrt den Geist in solche Schrancken.", "tokens": ["Und", "spricht", ":", "die", "Lie\u00b7be", "f\u00fchrt", "den", "Geist", "in", "sol\u00b7che", "Schran\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ART", "NN", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Liebe will sich mir zu einer Sclavin geben/", "tokens": ["Die", "Lie\u00b7be", "will", "sich", "mir", "zu", "ei\u00b7ner", "Scla\u00b7vin", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "PPER", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00e4sselt mich dabey mit steter Dienstbarkeit.", "tokens": ["Und", "f\u00e4s\u00b7selt", "mich", "da\u00b7bey", "mit", "ste\u00b7ter", "Dienst\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich mu\u00df durch sie vergn\u00fcgt in Unvergn\u00fcgen leben/", "tokens": ["Ich", "mu\u00df", "durch", "sie", "ver\u00b7gn\u00fcgt", "in", "Un\u00b7ver\u00b7gn\u00fc\u00b7gen", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die s\u00fcsse Stunden sind mit Wermuth \u00fcberstreut.", "tokens": ["Die", "s\u00fcs\u00b7se", "Stun\u00b7den", "sind", "mit", "Wer\u00b7muth", "\u00fc\u00b7bers\u00b7treut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein hochbeliebter Baum will mich durch Schatten nehren/", "tokens": ["Ein", "hoch\u00b7be\u00b7lieb\u00b7ter", "Baum", "will", "mich", "durch", "Schat\u00b7ten", "neh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PRF", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein sch\u00f6ner Ast davon sucht meine Ruh zust\u00f6hren.", "tokens": ["Ein", "sch\u00f6\u00b7ner", "Ast", "da\u00b7von", "sucht", "mei\u00b7ne", "Ruh", "zu\u00b7st\u00f6h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Das _ _ Hau\u00df/ ein Auszug sch\u00f6ner H\u00e4user", "tokens": ["Das", "_", "_", "Hau\u00df", "/", "ein", "Aus\u00b7zug", "sch\u00f6\u00b7ner", "H\u00e4u\u00b7ser"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "XY", "XY", "NN", "$(", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das auff den festen Grund der Tugend feste steht.", "tokens": ["Das", "auff", "den", "fes\u00b7ten", "Grund", "der", "Tu\u00b7gend", "fes\u00b7te", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "ART", "NN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das gleichet einen Baum/ der durch die sch\u00f6nsten Reisser", "tokens": ["Das", "glei\u00b7chet", "ei\u00b7nen", "Baum", "/", "der", "durch", "die", "sch\u00f6ns\u00b7ten", "Reis\u00b7ser"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weit \u00fcber alle Pracht dergleichen B\u00e4ume geht.", "tokens": ["Weit", "\u00fc\u00b7ber", "al\u00b7le", "Pracht", "derg\u00b7lei\u00b7chen", "B\u00e4u\u00b7me", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PIAT", "NN", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Gl\u00fccke/ welches stets den Meister pflegt zu spielen/", "tokens": ["Das", "Gl\u00fc\u00b7cke", "/", "wel\u00b7ches", "stets", "den", "Meis\u00b7ter", "pflegt", "zu", "spie\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWS", "ADV", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "L\u00e4st mich durch dieses Hau\u00df auch seine K\u00fcsse f\u00fchlen.", "tokens": ["L\u00e4st", "mich", "durch", "die\u00b7ses", "Hau\u00df", "auch", "sei\u00b7ne", "K\u00fcs\u00b7se", "f\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PDAT", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.5": {"line.1": {"text": "Denn so viel Bl\u00e4tter sind an B\u00e4umen nicht zu finden/", "tokens": ["Denn", "so", "viel", "Bl\u00e4t\u00b7ter", "sind", "an", "B\u00e4u\u00b7men", "nicht", "zu", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VAFIN", "APPR", "NN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als seine G\u00fctigkeit auff einen Diener denckt:", "tokens": ["Als", "sei\u00b7ne", "G\u00fc\u00b7tig\u00b7keit", "auff", "ei\u00b7nen", "Die\u00b7ner", "denckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo Gunst und Liebe sich zu meinen Wohl verbinden/", "tokens": ["Wo", "Gunst", "und", "Lie\u00b7be", "sich", "zu", "mei\u00b7nen", "Wohl", "ver\u00b7bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo seine Gnade seet/ und mir die Ernde schenckt.", "tokens": ["Wo", "sei\u00b7ne", "Gna\u00b7de", "seet", "/", "und", "mir", "die", "Ern\u00b7de", "schenckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$(", "KON", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Glied von Riesen weist/ wie gro\u00df er sey gewesen/", "tokens": ["Ein", "Glied", "von", "Rie\u00b7sen", "weist", "/", "wie", "gro\u00df", "er", "sey", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$(", "PWAV", "ADJD", "PPER", "VAFIN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Sohnes Nahme l\u00e4st der G\u00fcte Gr\u00f6sse lesen.", "tokens": ["Des", "Soh\u00b7nes", "Nah\u00b7me", "l\u00e4st", "der", "G\u00fc\u00b7te", "Gr\u00f6s\u00b7se", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "So wil mir unverdient die Liebe st\u00fcndlich dienen/", "tokens": ["So", "wil", "mir", "un\u00b7ver\u00b7di\u00b7ent", "die", "Lie\u00b7be", "st\u00fcnd\u00b7lich", "die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So lachet mich das Gl\u00fcck mit tausend Blicken an/", "tokens": ["So", "la\u00b7chet", "mich", "das", "Gl\u00fcck", "mit", "tau\u00b7send", "Bli\u00b7cken", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "CARD", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So soll zu meiner Lust noch eine Myrthe gr\u00fcnen/", "tokens": ["So", "soll", "zu", "mei\u00b7ner", "Lust", "noch", "ei\u00b7ne", "Myr\u00b7the", "gr\u00fc\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "PPOSAT", "NN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ich Menanders Treu durch Treu geniessen kan.", "tokens": ["Da", "ich", "Me\u00b7nan\u00b7ders", "Treu", "durch", "Treu", "ge\u00b7nies\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Menander/ dessen Hand in meine Brust geschrieben:", "tokens": ["Me\u00b7nan\u00b7der", "/", "des\u00b7sen", "Hand", "in", "mei\u00b7ne", "Brust", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PRELAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer deine Seele liebt/ den solst du wieder lieben.", "tokens": ["Wer", "dei\u00b7ne", "See\u00b7le", "liebt", "/", "den", "solst", "du", "wie\u00b7der", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$(", "ART", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Die reine Freundschafft brennt in so entflammten Kertzen/", "tokens": ["Die", "rei\u00b7ne", "Freund\u00b7schafft", "brennt", "in", "so", "ent\u00b7flamm\u00b7ten", "Kert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die weder Gl\u00fcck noch Zeit zu l\u00f6schen f\u00e4hig ist.", "tokens": ["Die", "we\u00b7der", "Gl\u00fcck", "noch", "Zeit", "zu", "l\u00f6\u00b7schen", "f\u00e4\u00b7hig", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "NN", "ADV", "NN", "PTKZU", "VVINF", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir schertzen bey der Lust/ wir weinen bey den Schmertzen.", "tokens": ["Wir", "schert\u00b7zen", "bey", "der", "Lust", "/", "wir", "wei\u00b7nen", "bey", "den", "Schmert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "PPER", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn sein Vergn\u00fcgen lacht/ so hat es mich gek\u00fcst.", "tokens": ["Wenn", "sein", "Ver\u00b7gn\u00fc\u00b7gen", "lacht", "/", "so", "hat", "es", "mich", "ge\u00b7k\u00fcst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$(", "ADV", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was mein Gem\u00fcthe pflegt vollkommen zu ergetzen/", "tokens": ["Was", "mein", "Ge\u00b7m\u00fc\u00b7the", "pflegt", "voll\u00b7kom\u00b7men", "zu", "er\u00b7get\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wil er vor Bruder/ Freund und vor die Schwester sch\u00e4tzen.", "tokens": ["Wil", "er", "vor", "Bru\u00b7der", "/", "Freund", "und", "vor", "die", "Schwes\u00b7ter", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "$(", "NN", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.8": {"line.1": {"text": "Doch wil mein Gl\u00fccke gleich an einen Orte bl\u00fchen/", "tokens": ["Doch", "wil", "mein", "Gl\u00fc\u00b7cke", "gleich", "an", "ei\u00b7nen", "Or\u00b7te", "bl\u00fc\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja mehr/ da ich zugleich die Fr\u00fcchte brechen kan/", "tokens": ["Ja", "mehr", "/", "da", "ich", "zu\u00b7gleich", "die", "Fr\u00fcch\u00b7te", "bre\u00b7chen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$(", "KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So mu\u00df sein Unbestand mich anderwerts beziehen/", "tokens": ["So", "mu\u00df", "sein", "Un\u00b7be\u00b7stand", "mich", "an\u00b7der\u00b7werts", "be\u00b7zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich schaue bey der Lust auch meine Marter an.", "tokens": ["Ich", "schau\u00b7e", "bey", "der", "Lust", "auch", "mei\u00b7ne", "Mar\u00b7ter", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Itzt scheint der Liebe-Lentz/ nun schlie\u00dft er seinen Schimmer/", "tokens": ["Itzt", "scheint", "der", "Lie\u00b7be\u00b7\u00b7L\u00b7entz", "/", "nun", "schlie\u00dft", "er", "sei\u00b7nen", "Schim\u00b7mer", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Und alles dieses kommt von einen Frauenzimmer.", "tokens": ["Und", "al\u00b7les", "die\u00b7ses", "kommt", "von", "ei\u00b7nen", "Frau\u00b7en\u00b7zim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PDAT", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ein Frauenzimmer? nein/ des Frauenzimmers Sonne/", "tokens": ["Ein", "Frau\u00b7en\u00b7zim\u00b7mer", "?", "nein", "/", "des", "Frau\u00b7en\u00b7zim\u00b7mers", "Son\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PTKANT", "$(", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die offt den Gnaden-Strahl in einen Blitz verkehrt.", "tokens": ["Die", "offt", "den", "Gna\u00b7den\u00b7Strahl", "in", "ei\u00b7nen", "Blitz", "ver\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Ursprung ist zu sch\u00f6n/ der meine Gluth entsponne/", "tokens": ["Der", "Ur\u00b7sprung", "ist", "zu", "sch\u00f6n", "/", "der", "mei\u00b7ne", "Gluth", "ent\u00b7spon\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das sie die Ewigkeitmit ihren Feuer nehrt:", "tokens": ["Das", "sie", "die", "E\u00b7wig\u00b7keit\u00b7mit", "ih\u00b7ren", "Feu\u00b7er", "nehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Ehrerbietung tr\u00e4gt das Oel zu meinen Flammen/", "tokens": ["Die", "Ehr\u00b7er\u00b7bie\u00b7tung", "tr\u00e4gt", "das", "O\u00b7el", "zu", "mei\u00b7nen", "Flam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "So spricht der Himmel selbst: ich sey nicht zu verdammen-", "tokens": ["So", "spricht", "der", "Him\u00b7mel", "selbst", ":", "ich", "sey", "nicht", "zu", "ver\u00b7dam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$.", "PPER", "VAFIN", "PTKNEG", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Ihr sch\u00f6ner Mund will zwar nicht von verdammen sprechen/", "tokens": ["Ihr", "sch\u00f6\u00b7ner", "Mund", "will", "zwar", "nicht", "von", "ver\u00b7dam\u00b7men", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADV", "PTKNEG", "APPR", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie l\u00e4st sich meine Noth noch wohl zu Hertzen gehn.", "tokens": ["Sie", "l\u00e4st", "sich", "mei\u00b7ne", "Noth", "noch", "wohl", "zu", "Hert\u00b7zen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN", "ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie sieht die starcke Gluth aus meinen Augen brechen/", "tokens": ["Sie", "sieht", "die", "star\u00b7cke", "Gluth", "aus", "mei\u00b7nen", "Au\u00b7gen", "bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und jede Mine weist/ es sey \u00fcm mich geschehn.", "tokens": ["Und", "je\u00b7de", "Mi\u00b7ne", "weist", "/", "es", "sey", "\u00fcm", "mich", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$(", "PPER", "VAFIN", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja will ich meine Pein durch tausend Seuftzer klagen/", "tokens": ["Ja", "will", "ich", "mei\u00b7ne", "Pein", "durch", "tau\u00b7send", "Seuft\u00b7zer", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "CARD", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kan ihr geneigtes Ohr auch alles wohl vertragen.", "tokens": ["Kan", "ihr", "ge\u00b7neig\u00b7tes", "Ohr", "auch", "al\u00b7les", "wohl", "ver\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Ein Lied/ ja mehr als eins von meiner Hand gesetzet/", "tokens": ["Ein", "Lied", "/", "ja", "mehr", "als", "eins", "von", "mei\u00b7ner", "Hand", "ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADV", "KOUS", "PIS", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die musten meiner Quaal erst stumme Redner seyn:", "tokens": ["Die", "mus\u00b7ten", "mei\u00b7ner", "Qua\u00b7al", "erst", "stum\u00b7me", "Red\u00b7ner", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Liebe hatte sich nur auf das Blat ge\u00e4tzet/", "tokens": ["Die", "Lie\u00b7be", "hat\u00b7te", "sich", "nur", "auf", "das", "Blat", "ge\u00e4t\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und schreib ihr Conterfait doch in die Brust hinein,", "tokens": ["Und", "schreib", "ihr", "Con\u00b7ter\u00b7fait", "doch", "in", "die", "Brust", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als sich die Wehmuht nun durch Blicke liesse sehen/", "tokens": ["Als", "sich", "die", "Weh\u00b7muht", "nun", "durch", "Bli\u00b7cke", "lies\u00b7se", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So musten Hertz und Mund den Brand zugleich gestehen", "tokens": ["So", "mus\u00b7ten", "Hertz", "und", "Mund", "den", "Brand", "zu\u00b7gleich", "ge\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "NN", "KON", "NN", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ich konte mich vergn\u00fcgt in meiner Liebe schauen/", "tokens": ["Ich", "kon\u00b7te", "mich", "ver\u00b7gn\u00fcgt", "in", "mei\u00b7ner", "Lie\u00b7be", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Himmel wei\u00df es wohl/ und der soll Zeuge seyn:", "tokens": ["Der", "Him\u00b7mel", "wei\u00df", "es", "wohl", "/", "und", "der", "soll", "Zeu\u00b7ge", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$(", "KON", "ART", "PIAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich wolte mir ein Hau\u00df von Zucker Rosen bauen/", "tokens": ["Ich", "wol\u00b7te", "mir", "ein", "Hau\u00df", "von", "Zu\u00b7cker", "Ro\u00b7sen", "bau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "APPR", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So reist die strenge Hand mir alle Hoffnung ein.", "tokens": ["So", "reist", "die", "stren\u00b7ge", "Hand", "mir", "al\u00b7le", "Hoff\u00b7nung", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPER", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mein Mund darff nicht ein Wort wie sonst von Lieben sprechen/", "tokens": ["Mein", "Mund", "darff", "nicht", "ein", "Wort", "wie", "sonst", "von", "Lie\u00b7ben", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "ART", "NN", "KOKOM", "ADV", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Grausamkeit will sich an meiner Unschuld r\u00e4chen.", "tokens": ["Die", "Grau\u00b7sam\u00b7keit", "will", "sich", "an", "mei\u00b7ner", "Un\u00b7schuld", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ach ist denn/ die zuvor mein Himmelreich gewesen/", "tokens": ["Ach", "ist", "denn", "/", "die", "zu\u00b7vor", "mein", "Him\u00b7mel\u00b7reich", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VAFIN", "ADV", "$(", "ART", "ADV", "PPOSAT", "NN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nun Freundin meiner Noht und Feinden meiner Ruh/", "tokens": ["Nun", "Freun\u00b7din", "mei\u00b7ner", "Noht", "und", "Fein\u00b7den", "mei\u00b7ner", "Ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPOSAT", "NN", "KON", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Soll ich aus Liebe denn des Todes-Urtheil lesen?", "tokens": ["Soll", "ich", "aus", "Lie\u00b7be", "denn", "des", "To\u00b7des\u00b7Urt\u00b7heil", "le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So schreib' ich dieses nicht der Tugend W\u00fcrckung zu.", "tokens": ["So", "schreib'", "ich", "die\u00b7ses", "nicht", "der", "Tu\u00b7gend", "W\u00fcr\u00b7ckung", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "PTKNEG", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Sch\u00f6nheit/ welche sonst den h\u00f6chsten Ruhm erworben/", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "/", "wel\u00b7che", "sonst", "den", "h\u00f6chs\u00b7ten", "Ruhm", "er\u00b7wor\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "ADV", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hat denn beliebten Glantz durch Wanckelmuth verdorben.", "tokens": ["Hat", "denn", "be\u00b7lieb\u00b7ten", "Glantz", "durch", "Wan\u00b7ckel\u00b7muth", "ver\u00b7dor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Mein Zustand war nur so: Ich ging mit schweren Hertzen/", "tokens": ["Mein", "Zu\u00b7stand", "war", "nur", "so", ":", "Ich", "ging", "mit", "schwe\u00b7ren", "Hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und hinge meiner Quaal mit stillen Seufftzern nach.", "tokens": ["Und", "hin\u00b7ge", "mei\u00b7ner", "Qua\u00b7al", "mit", "stil\u00b7len", "Seufft\u00b7zern", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Indessen wuste sie dennoch galant zu schertzen/", "tokens": ["In\u00b7des\u00b7sen", "wus\u00b7te", "sie", "den\u00b7noch", "ga\u00b7lant", "zu", "schert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Freundlichkeit war offt das Pflaster meiner Schmach:", "tokens": ["Die", "Freund\u00b7lich\u00b7keit", "war", "offt", "das", "Pflas\u00b7ter", "mei\u00b7ner", "Schmach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bi\u00df ein geheimer Trieb des Zweiffels mich entbunde/", "tokens": ["Bi\u00df", "ein", "ge\u00b7hei\u00b7mer", "Trieb", "des", "Zweif\u00b7fels", "mich", "ent\u00b7bun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ich von neuen ihr die starcke Glut gestunde.", "tokens": ["Und", "ich", "von", "neu\u00b7en", "ihr", "die", "star\u00b7cke", "Glut", "ge\u00b7stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Ich sprach: Galantes Kind/ dem gar nichts zu vergleichen/", "tokens": ["Ich", "sprach", ":", "Ga\u00b7lan\u00b7tes", "Kind", "/", "dem", "gar", "nichts", "zu", "ver\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADJA", "NN", "$(", "ART", "ADV", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Tugend Meisterst\u00fcck! du Engel dieser Stadt!", "tokens": ["Der", "Tu\u00b7gend", "Meis\u00b7ter\u00b7st\u00fcck", "!", "du", "En\u00b7gel", "die\u00b7ser", "Stadt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "PPER", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was sch\u00f6n heist/ mu\u00df dennoch vor deiner Sch\u00f6nheit weichen/", "tokens": ["Was", "sch\u00f6n", "heist", "/", "mu\u00df", "den\u00b7noch", "vor", "dei\u00b7ner", "Sch\u00f6n\u00b7heit", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$(", "VMFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was Wunders da\u00df ein Knecht sich dir ergeben hat.", "tokens": ["Was", "Wun\u00b7ders", "da\u00df", "ein", "Knecht", "sich", "dir", "er\u00b7ge\u00b7ben", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KOUS", "ART", "NN", "PRF", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von deiner Gnade k\u00f6mmt nur eintzig mein Ergetzen/", "tokens": ["Von", "dei\u00b7ner", "Gna\u00b7de", "k\u00f6mmt", "nur", "eint\u00b7zig", "mein", "Er\u00b7get\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich wil dich Lebenslang als unvergleichlich sch\u00e4tzen.", "tokens": ["Ich", "wil", "dich", "Le\u00b7bens\u00b7lang", "als", "un\u00b7ver\u00b7gleich\u00b7lich", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADJD", "KOKOM", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}