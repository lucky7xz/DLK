{"dta.poem.4304": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "An meinem Gebuhrts-Tage  \n  1738 .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Gott Lob! ich sehe heut schon acht und funfzig mahl", "tokens": ["Gott", "Lob", "!", "ich", "se\u00b7he", "heut", "schon", "acht", "und", "funf\u00b7zig", "mahl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "PPER", "VVFIN", "ADV", "ADV", "CARD", "KON", "CARD", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sonnen Licht und Lebens Strahl", "tokens": ["Der", "Son\u00b7nen", "Licht", "und", "Le\u00b7bens", "Strahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Am Tage, da Du mich auf Erden,", "tokens": ["Am", "Ta\u00b7ge", ",", "da", "Du", "mich", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mein GOtt! gebohren lassen werden.", "tokens": ["Mein", "Gott", "!", "ge\u00b7boh\u00b7ren", "las\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVPP", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da heute nun aufs neu ein Jahr dahin,", "tokens": ["Da", "heu\u00b7te", "nun", "aufs", "neu", "ein", "Jahr", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPRART", "ADJD", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ich, GOtt Lob! gesund, vergn\u00fcgt im Segen,", "tokens": ["Und", "ich", ",", "Gott", "Lob", "!", "ge\u00b7sund", ",", "ver\u00b7gn\u00fcgt", "im", "Se\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "NN", "NN", "$.", "ADJD", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Nebst allen meinen Kindern, bin;", "tokens": ["Nebst", "al\u00b7len", "mei\u00b7nen", "Kin\u00b7dern", ",", "bin", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Halt ich mich, mit ger\u00fchrtem Sinn,", "tokens": ["Halt", "ich", "mich", ",", "mit", "ge\u00b7r\u00fchr\u00b7tem", "Sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PRF", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Gnade schuldig zu erwegen,", "tokens": ["Die", "Gna\u00b7de", "schul\u00b7dig", "zu", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und Andacht voll zu \u00fcberlegen,", "tokens": ["Und", "An\u00b7dacht", "voll", "zu", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Was mir in den verflo\u00dfnen Jahren", "tokens": ["Was", "mir", "in", "den", "ver\u00b7flo\u00df\u00b7nen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Von Deiner Gnaden-Hand f\u00fcr Gutes wiederfahren.", "tokens": ["Von", "Dei\u00b7ner", "Gna\u00b7den\u00b7Hand", "f\u00fcr", "Gu\u00b7tes", "wie\u00b7der\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wenn ich, nach meiner Schuldigkeit,", "tokens": ["Wenn", "ich", ",", "nach", "mei\u00b7ner", "Schul\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In fr\u00f6hlicher Erinnerung, erwege,", "tokens": ["In", "fr\u00f6h\u00b7li\u00b7cher", "E\u00b7rin\u00b7ne\u00b7rung", ",", "er\u00b7we\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ernstlich bey mir \u00fcberlege,", "tokens": ["Und", "ernst\u00b7lich", "bey", "mir", "\u00fc\u00b7berl\u00b7e\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was Du im ganzen Lauf\u2019 von meinem Leben", "tokens": ["Was", "Du", "im", "gan\u00b7zen", "Lauf'", "von", "mei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mir f\u00fcr unz\u00e4hlich Guts gegeben,", "tokens": ["Mir", "f\u00fcr", "un\u00b7z\u00e4h\u00b7lich", "Guts", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJD", "NN", "VVPP", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Und was, HErr! Deine Gnaden-Hand", "tokens": ["Und", "was", ",", "Herr", "!", "Dei\u00b7ne", "Gna\u00b7den\u00b7Hand"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "$,", "NN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "F\u00fcr B\u00f6ses von mir abgewandt;", "tokens": ["F\u00fcr", "B\u00f6\u00b7ses", "von", "mir", "ab\u00b7ge\u00b7wandt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So wird, so wie es mir ja wohl geb\u00fchrt,", "tokens": ["So", "wird", ",", "so", "wie", "es", "mir", "ja", "wohl", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "ADV", "KOKOM", "PPER", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "F\u00fcr so viel Gnad und Huld mein ganzes Herz ger\u00fchrt.", "tokens": ["F\u00fcr", "so", "viel", "Gnad", "und", "Huld", "mein", "gan\u00b7zes", "Herz", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "KON", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Was h\u00e4tten doch in so viel Jahren", "tokens": ["Was", "h\u00e4t\u00b7ten", "doch", "in", "so", "viel", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht f\u00fcr Verdrie\u00dflichkeit und f\u00fcr Gefahren", "tokens": ["Nicht", "f\u00fcr", "Ver\u00b7drie\u00df\u00b7lich\u00b7keit", "und", "f\u00fcr", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich treffen, mir begegnen k\u00f6nnen,", "tokens": ["Mich", "tref\u00b7fen", ",", "mir", "be\u00b7geg\u00b7nen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wof\u00fcr Du mich so gn\u00e4diglich,", "tokens": ["Wo\u00b7f\u00fcr", "Du", "mich", "so", "gn\u00e4\u00b7di\u00b7glich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wunderbar gew\u00fcrdigt zu bewahren!", "tokens": ["Und", "wun\u00b7der\u00b7bar", "ge\u00b7w\u00fcr\u00b7digt", "zu", "be\u00b7wah\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Herr! daf\u00fcr lob\u2019 und preis\u2019 ich Dich.", "tokens": ["Herr", "!", "da\u00b7f\u00fcr", "lob'", "und", "preis'", "ich", "Dich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PAV", "PTKVZ", "KON", "VVFIN", "PPER", "PRF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Wenn wir den Stoff, aus welchem wir besteh\u2019n,", "tokens": ["Wenn", "wir", "den", "Stoff", ",", "aus", "wel\u00b7chem", "wir", "be\u00b7steh'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn wir wodurch, worinn, womit, und wie wir leben,", "tokens": ["Wenn", "wir", "wo\u00b7durch", ",", "wo\u00b7rinn", ",", "wo\u00b7mit", ",", "und", "wie", "wir", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PWAV", "$,", "PWAV", "$,", "PWAV", "$,", "KON", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wovon wir die Nahrung heben,", "tokens": ["Und", "wo\u00b7von", "wir", "die", "Nah\u00b7rung", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit einiger Aufmerksamkeit, beseh\u2019n;", "tokens": ["Mit", "ei\u00b7ni\u00b7ger", "Auf\u00b7merk\u00b7sam\u00b7keit", ",", "be\u00b7seh'n", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wird uns ein Schauer \u00fcbergeh\u2019n,", "tokens": ["Wird", "uns", "ein", "Schau\u00b7er", "\u00fc\u00b7ber\u00b7geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Weil es fast unbegreiflich ist,", "tokens": ["Weil", "es", "fast", "un\u00b7be\u00b7greif\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn man die Mischungen ermi\u00dft,", "tokens": ["Wenn", "man", "die", "Misc\u00b7hun\u00b7gen", "er\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Nur einen Augenblick gesund zu bleiben,", "tokens": ["Nur", "ei\u00b7nen", "Au\u00b7gen\u00b7blick", "ge\u00b7sund", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Wenn wir zugleich den grossen Unterscheid", "tokens": ["Wenn", "wir", "zu\u00b7gleich", "den", "gros\u00b7sen", "Un\u00b7ter\u00b7scheid"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Der Neigungen, der Absicht, D\u00fcrftigkeit,", "tokens": ["Der", "Nei\u00b7gun\u00b7gen", ",", "der", "Ab\u00b7sicht", ",", "D\u00fcrf\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Der Uebereilungen, der Unvollkommenheit,", "tokens": ["Der", "Ue\u00b7be\u00b7rei\u00b7lun\u00b7gen", ",", "der", "Un\u00b7voll\u00b7kom\u00b7men\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Von andern Menschen auch beachten,", "tokens": ["Von", "an\u00b7dern", "Men\u00b7schen", "auch", "be\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und ihr stets neidisches, geliebtes Ich betrachten;", "tokens": ["Und", "ihr", "stets", "nei\u00b7di\u00b7sches", ",", "ge\u00b7lieb\u00b7tes", "Ich", "be\u00b7trach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADJA", "$,", "ADJA", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So ist es wohl Bewunderns wehrt,", "tokens": ["So", "ist", "es", "wohl", "Be\u00b7wun\u00b7derns", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Da\u00df auf dem Lebens-Meer, worauf man f\u00e4hrt,", "tokens": ["Da\u00df", "auf", "dem", "Le\u00b7bens\u00b7Meer", ",", "wo\u00b7rauf", "man", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Uns tausend Strudel nicht versenken.", "tokens": ["Uns", "tau\u00b7send", "Stru\u00b7del", "nicht", "ver\u00b7sen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich bin, o HErr! durch Deine G\u00fcte,", "tokens": ["Ich", "bin", ",", "o", "Herr", "!", "durch", "Dei\u00b7ne", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "FM", "NN", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bisher ohn\u2019 Ansto\u00df fortgeschifft,", "tokens": ["Bis\u00b7her", "ohn'", "An\u00b7sto\u00df", "fort\u00b7ge\u00b7schifft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und weil mich noch, GOtt Lob! kein schwehrer Unfall trifft,", "tokens": ["Und", "weil", "mich", "noch", ",", "Gott", "Lob", "!", "kein", "schweh\u00b7rer", "Un\u00b7fall", "trifft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "$,", "NN", "NN", "$.", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So lob\u2019 und preis\u2019 ich dich. Und mein Gem\u00fchte", "tokens": ["So", "lob'", "und", "preis'", "ich", "dich", ".", "Und", "mein", "Ge\u00b7m\u00fch\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PTKVZ", "KON", "VVFIN", "PPER", "PRF", "$.", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wird, in der Gr\u00f6sse der Gefahr,", "tokens": ["Wird", ",", "in", "der", "Gr\u00f6s\u00b7se", "der", "Ge\u00b7fahr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Gr\u00f6sse Deiner Gnad\u2019 und Huld gewahr.", "tokens": ["Die", "Gr\u00f6s\u00b7se", "Dei\u00b7ner", "Gnad'", "und", "Huld", "ge\u00b7wahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Noch mehr, aus ungez\u00e4hlten Gaben,", "tokens": ["Noch", "mehr", ",", "aus", "un\u00b7ge\u00b7z\u00e4hl\u00b7ten", "Ga\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die wir noch ausser dem von Dir erhalten haben,", "tokens": ["Die", "wir", "noch", "aus\u00b7ser", "dem", "von", "Dir", "er\u00b7hal\u00b7ten", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "APPR", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erhellet Deine Lieb\u2019 und Gnaden-reiche Treu,", "tokens": ["Er\u00b7hel\u00b7let", "Dei\u00b7ne", "Lieb'", "und", "Gna\u00b7den\u00b7rei\u00b7che", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die bey mir alle Morgen neu.", "tokens": ["Die", "bey", "mir", "al\u00b7le", "Mor\u00b7gen", "neu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es sind dieselben nicht zu z\u00e4hlen,", "tokens": ["Es", "sind", "die\u00b7sel\u00b7ben", "nicht", "zu", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch mu\u00df ich eine noch von so viel tausend w\u00e4hlen,", "tokens": ["Doch", "mu\u00df", "ich", "ei\u00b7ne", "noch", "von", "so", "viel", "tau\u00b7send", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "ADV", "APPR", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und daf\u00fcr, mit ger\u00fchrter Seelen,", "tokens": ["Und", "da\u00b7f\u00fcr", ",", "mit", "ge\u00b7r\u00fchr\u00b7ter", "See\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dir, HErr! ein Freuden-Opfer bringen.", "tokens": ["Dir", ",", "Herr", "!", "ein", "Freu\u00b7den\u00b7Op\u00b7fer", "brin\u00b7gen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$.", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Zu allem Guten, was Du mir,", "tokens": ["Zu", "al\u00b7lem", "Gu\u00b7ten", ",", "was", "Du", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "$,", "PWS", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O, liebster GOtt! bisher gew\u00e4hret,", "tokens": ["O", ",", "liebs\u00b7ter", "Gott", "!", "bis\u00b7her", "ge\u00b7w\u00e4h\u00b7ret", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$.", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hast Du, Dir, HErr, sey Preis daf\u00fcr!", "tokens": ["Hast", "Du", ",", "Dir", ",", "Herr", ",", "sey", "Preis", "da\u00b7f\u00fcr", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "PPER", "$,", "NN", "$,", "VAFIN", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir etwas neues noch beschehret.", "tokens": ["Mir", "et\u00b7was", "neu\u00b7es", "noch", "be\u00b7scheh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da ich die ohne das, GOtt Lob! begl\u00fcckte Ehe", "tokens": ["Da", "ich", "die", "oh\u00b7ne", "das", ",", "Gott", "Lob", "!", "be\u00b7gl\u00fcck\u00b7te", "E\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ART", "APPR", "ART", "$,", "NN", "NN", "$.", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von meiner Tochter noch begl\u00fcckter sehe,", "tokens": ["Von", "mei\u00b7ner", "Toch\u00b7ter", "noch", "be\u00b7gl\u00fcck\u00b7ter", "se\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und sie mir einen Enkel brachte,", "tokens": ["Und", "sie", "mir", "ei\u00b7nen", "En\u00b7kel", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wof\u00fcr, je weniger wir es gedacht,", "tokens": ["Wo\u00b7f\u00fcr", ",", "je", "we\u00b7ni\u00b7ger", "wir", "es", "ge\u00b7dacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADV", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Je mehr wir schuldig, Deine G\u00fcte,", "tokens": ["Je", "mehr", "wir", "schul\u00b7dig", ",", "Dei\u00b7ne", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mit ganz von Dank und Lust erf\u00fclletem Gem\u00fchte,", "tokens": ["Mit", "ganz", "von", "Dank", "und", "Lust", "er\u00b7f\u00fcl\u00b7le\u00b7tem", "Ge\u00b7m\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "NN", "KON", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Zu loben, r\u00fchmen und zu preisen.", "tokens": ["Zu", "lo\u00b7ben", ",", "r\u00fch\u00b7men", "und", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ach, m\u00f6chten wir doch Dir ein solches Herze weisen,", "tokens": ["Ach", ",", "m\u00f6ch\u00b7ten", "wir", "doch", "Dir", "ein", "sol\u00b7ches", "Her\u00b7ze", "wei\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VMFIN", "PPER", "ADV", "PPER", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Dir gef\u00e4llig w\u00e4r!", "tokens": ["Das", "Dir", "ge\u00b7f\u00e4l\u00b7lig", "w\u00e4r", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was ich von Dir f\u00fcr ihn erbitten kann,", "tokens": ["Was", "ich", "von", "Dir", "f\u00fcr", "ihn", "er\u00b7bit\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "APPR", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ist die\u00df: HErr! siehe doch auch ihn in Gnaden an!", "tokens": ["Ist", "die\u00df", ":", "Herr", "!", "sie\u00b7he", "doch", "auch", "ihn", "in", "Gna\u00b7den", "an", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "$.", "NN", "$.", "VVIMP", "ADV", "ADV", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.5": {"text": "Es lebe, neben uns, auch dieser Dir zur Ehr!", "tokens": ["Es", "le\u00b7be", ",", "ne\u00b7ben", "uns", ",", "auch", "die\u00b7ser", "Dir", "zur", "Ehr", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PPER", "$,", "ADV", "PDAT", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "So lang\u2019 es Dir, o HErr! nun ferner wird gefallen,", "tokens": ["So", "lang'", "es", "Dir", ",", "o", "Herr", "!", "nun", "fer\u00b7ner", "wird", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPER", "$,", "FM", "NN", "$.", "ADV", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mich hier auf dieser Welt zu wallen", "tokens": ["Mich", "hier", "auf", "die\u00b7ser", "Welt", "zu", "wal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "PDAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und meinen Aufenthalt hier seyn zu lassen;", "tokens": ["Und", "mei\u00b7nen", "Auf\u00b7ent\u00b7halt", "hier", "seyn", "zu", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VAINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So lange fleh\u2019 ich Dich inbr\u00fcnstig an!", "tokens": ["So", "lan\u00b7ge", "fleh'", "ich", "Dich", "in\u00b7br\u00fcns\u00b7tig", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ach, la\u00df doch mich, und, durch mich, andre fassen,", "tokens": ["Ach", ",", "la\u00df", "doch", "mich", ",", "und", ",", "durch", "mich", ",", "and\u00b7re", "fas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVIMP", "ADV", "PPER", "$,", "KON", "$,", "APPR", "PPER", "$,", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie man nicht besser leben kann,", "tokens": ["Wie", "man", "nicht", "bes\u00b7ser", "le\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als Deine Weisheit, Lieb\u2019 und Macht,", "tokens": ["Als", "Dei\u00b7ne", "Weis\u00b7heit", ",", "Lieb'", "und", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In Deiner sch\u00f6nen Werke Pracht,", "tokens": ["In", "Dei\u00b7ner", "sch\u00f6\u00b7nen", "Wer\u00b7ke", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "In fr\u00f6hlicher Bewundrung anzuseh\u2019n,", "tokens": ["In", "fr\u00f6h\u00b7li\u00b7cher", "Be\u00b7wund\u00b7rung", "an\u00b7zu\u00b7seh'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Dein herrlich \u00fcberall vorhandnes Wesen", "tokens": ["Dein", "herr\u00b7lich", "\u00fc\u00b7be\u00b7rall", "vor\u00b7hand\u00b7nes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "In jeder Creatur zu lesen,", "tokens": ["In", "je\u00b7der", "Crea\u00b7tur", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Und \u00fcberall Dich zu versteh\u2019n!", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "Dich", "zu", "ver\u00b7steh'n", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ach, la\u00df mich immer mehr und mehr,", "tokens": ["Ach", ",", "la\u00df", "mich", "im\u00b7mer", "mehr", "und", "mehr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVIMP", "PPER", "ADV", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "In froher Zuversicht, mich \u00fcben,", "tokens": ["In", "fro\u00b7her", "Zu\u00b7ver\u00b7sicht", ",", "mich", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Zu Deines Namens Preis und Ehr,", "tokens": ["Zu", "Dei\u00b7nes", "Na\u00b7mens", "Preis", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mich, meinen N\u00e4chsten auch, Dich \u00fcberall zu lieben!", "tokens": ["Mich", ",", "mei\u00b7nen", "N\u00e4chs\u00b7ten", "auch", ",", "Dich", "\u00fc\u00b7be\u00b7rall", "zu", "lie\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "ADV", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Erbarme Dich, o HErr! doch auch der Meinen,", "tokens": ["Er\u00b7bar\u00b7me", "Dich", ",", "o", "Herr", "!", "doch", "auch", "der", "Mei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "FM", "NN", "$.", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und la\u00df auf ihrem Lebens-Pfad,", "tokens": ["Und", "la\u00df", "auf", "ih\u00b7rem", "Le\u00b7bens\u00b7Pfad", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Deines Segens Licht bisher", "tokens": ["Wie", "Dei\u00b7nes", "Se\u00b7gens", "Licht", "bis\u00b7her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie gn\u00e4dig angestrahlet hat,", "tokens": ["Sie", "gn\u00e4\u00b7dig", "an\u00b7ge\u00b7strah\u00b7let", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es ihnen doch auch ferner scheinen!", "tokens": ["Es", "ih\u00b7nen", "doch", "auch", "fer\u00b7ner", "schei\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Damit man, wie von mir, auch mag von ihnen lesen:", "tokens": ["Da\u00b7mit", "man", ",", "wie", "von", "mir", ",", "auch", "mag", "von", "ih\u00b7nen", "le\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PWAV", "APPR", "PPER", "$,", "ADV", "VMFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie sind, auf dieser Welt den Geist zum Sinn zu f\u00fcgen,", "tokens": ["Sie", "sind", ",", "auf", "die\u00b7ser", "Welt", "den", "Geist", "zum", "Sinn", "zu", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "PDAT", "NN", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "An GOttes Werk sich zu vergn\u00fcgen,", "tokens": ["An", "Got\u00b7tes", "Werk", "sich", "zu", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "In allen Wundern Dich zu seh\u2019n,", "tokens": ["In", "al\u00b7len", "Wun\u00b7dern", "Dich", "zu", "seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nach M\u00f6glichkeit Dich zu erh\u00f6h\u2019n,", "tokens": ["Nach", "M\u00f6g\u00b7lich\u00b7keit", "Dich", "zu", "er\u00b7h\u00f6h'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.11": {"text": "Und Deiner sich zu freu\u2019n, bem\u00fcht gewesen.", "tokens": ["Und", "Dei\u00b7ner", "sich", "zu", "freu'n", ",", "be\u00b7m\u00fcht", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "PRF", "PTKZU", "VVINF", "$,", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}