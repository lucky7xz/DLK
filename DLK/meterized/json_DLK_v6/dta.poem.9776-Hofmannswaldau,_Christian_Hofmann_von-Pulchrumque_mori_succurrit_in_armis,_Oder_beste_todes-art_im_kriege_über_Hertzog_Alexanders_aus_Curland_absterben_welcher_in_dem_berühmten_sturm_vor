{"dta.poem.9776": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Pulchrumque mori succurrit in armis,  \n  Oder beste todes-art im kriege/ \u00fcber Hertzog  \n Alexanders aus Curland absterben/ welcher in dem  \n ber\u00fchmten sturm vor Ofen den 26 Jul. 1686 t\u00f6dlich  \n geschossen ward/ und etliche tage darauff an  \n seiner wunde verschied.  \n \u2020 \u2020 \u2020", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Djs ist die nichtigkeit der menschlichen gedancken!", "tokens": ["Djs", "ist", "die", "nich\u00b7tig\u00b7keit", "der", "menschli\u00b7chen", "ge\u00b7dan\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wir nehmen in der welt uns grosse dinge vor;", "tokens": ["Wir", "neh\u00b7men", "in", "der", "welt", "uns", "gros\u00b7se", "din\u00b7ge", "vor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PPER", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die hoffnung reitzet uns und schmeichelt unser ohr;", "tokens": ["Die", "hoff\u00b7nung", "reit\u00b7zet", "uns", "und", "schmei\u00b7chelt", "un\u00b7ser", "ohr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die jugend stecket sich die wei", "tokens": ["Die", "ju\u00b7gend", "ste\u00b7cket", "sich", "die", "wei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die hoheit der geburt/ das gl\u00fccke das uns bl\u00fcht/", "tokens": ["Die", "ho\u00b7heit", "der", "ge\u00b7burt", "/", "das", "gl\u00fc\u00b7cke", "das", "uns", "bl\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$(", "PDS", "VVFIN", "ART", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist selbsten nicht genug die ehrsucht zu vergn\u00fcgen;", "tokens": ["Ist", "selbs\u00b7ten", "nicht", "ge\u00b7nug", "die", "ehr\u00b7sucht", "zu", "ver\u00b7gn\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "ART", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie sucht ein h\u00f6her ziel/ und eh man sichs versieht/", "tokens": ["Sie", "sucht", "ein", "h\u00f6\u00b7her", "ziel", "/", "und", "eh", "man", "sichs", "ver\u00b7sieht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "KON", "KOUS", "PIS", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sieht man nebst unserm wunsch/ uns auf dem r\u00fccken liegen.", "tokens": ["Sieht", "man", "nebst", "un\u00b7serm", "wunsch", "/", "uns", "auf", "dem", "r\u00fc\u00b7cken", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$(", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Dis so verkehrte spiel in allen unsern dingen", "tokens": ["Dis", "so", "ver\u00b7kehr\u00b7te", "spiel", "in", "al\u00b7len", "un\u00b7sern", "din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN", "VVFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ist jedem stande zwar mehr als zu wohl bekandt;", "tokens": ["Ist", "je\u00b7dem", "stan\u00b7de", "zwar", "mehr", "als", "zu", "wohl", "be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "ADV", "PIS", "KOKOM", "APPR", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch kennet meist der krieg desselben unbestand/", "tokens": ["Doch", "ken\u00b7net", "meist", "der", "krieg", "des\u00b7sel\u00b7ben", "un\u00b7be\u00b7stand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allwo wir zu der ehr durch lauter schwerdter dringen.", "tokens": ["All\u00b7wo", "wir", "zu", "der", "ehr", "durch", "lau\u00b7ter", "schwerd\u00b7ter", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "APPR", "PIAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der diesen augenblick auf seinem posten ficht/", "tokens": ["Der", "die\u00b7sen", "au\u00b7gen\u00b7blick", "auf", "sei\u00b7nem", "pos\u00b7ten", "ficht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nebst vermeintem ruhm denckt beute zu erjagen;", "tokens": ["Und", "nebst", "ver\u00b7mein\u00b7tem", "ruhm", "denckt", "beu\u00b7te", "zu", "er\u00b7ja\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "F\u00e4llt selbst durch einen schu\u00df/ indem er schiest und sticht/", "tokens": ["F\u00e4llt", "selbst", "durch", "ei\u00b7nen", "schu\u00df", "/", "in\u00b7dem", "er", "schiest", "und", "sticht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$(", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wird/ wie dessen feind/ auff piquen weggetragen.", "tokens": ["Und", "wird", "/", "wie", "des\u00b7sen", "feind", "/", "auff", "pi\u00b7quen", "weg\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "KOKOM", "PDS", "NN", "$(", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Welch absehn hatt\u2019 ich nicht auff diesem hall der erden!", "tokens": ["Welch", "ab\u00b7sehn", "hatt'", "ich", "nicht", "auff", "die\u00b7sem", "hall", "der", "er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "VVINF", "VAFIN", "PPER", "PTKNEG", "APPR", "PDAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der titel Printz zu seyn/ beschlo\u00df nicht meine ruh.", "tokens": ["Der", "ti\u00b7tel", "Printz", "zu", "seyn", "/", "be\u00b7schlo\u00df", "nicht", "mei\u00b7ne", "ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VAINF", "$(", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der nahme/ den ich trug/ blie\u00df mir was gr\u00f6ssers zu/", "tokens": ["Der", "nah\u00b7me", "/", "den", "ich", "trug", "/", "blie\u00df", "mir", "was", "gr\u00f6s\u00b7sers", "zu", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVFIN", "$(", "VVFIN", "PPER", "PIS", "ADJA", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich wolte gar der welt zum Alexander werden.", "tokens": ["Ich", "wol\u00b7te", "gar", "der", "welt", "zum", "A\u00b7lex\u00b7an\u00b7der", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "APPRART", "NE", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der zug/ der mich bereits nach Pohlen j\u00fcngst gebracht/", "tokens": ["Der", "zug", "/", "der", "mich", "be\u00b7reits", "nach", "Poh\u00b7len", "j\u00fcngst", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "ADV", "APPR", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erweckte meinen geist auch Ungarn zu beschauen;", "tokens": ["Er\u00b7weck\u00b7te", "mei\u00b7nen", "geist", "auch", "Un\u00b7garn", "zu", "be\u00b7schau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und weil uns Ofen selbst den schauplatz auffgemacht/", "tokens": ["Und", "weil", "uns", "O\u00b7fen", "selbst", "den", "schau\u00b7platz", "auff\u00b7ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wolt\u2019 ich da meinen ruhm auff t\u00fcrcken-k\u00f6pffen bauen.", "tokens": ["Wolt'", "ich", "da", "mei\u00b7nen", "ruhm", "auff", "t\u00fcr\u00b7cken\u00b7k\u00f6pf\u00b7fen", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Allein was kan der schlu\u00df des himmels doch nicht st\u00f6hren!", "tokens": ["Al\u00b7lein", "was", "kan", "der", "schlu\u00df", "des", "him\u00b7mels", "doch", "nicht", "st\u00f6h\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VMFIN", "ART", "NN", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein kleines st\u00fcckchen bley bezwang mich vor der zeit.", "tokens": ["Ein", "klei\u00b7nes", "st\u00fcck\u00b7chen", "bley", "be\u00b7zwang", "mich", "vor", "der", "zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die faust/ die tausenden den untergang gedr\u00e4u\u2019t/", "tokens": ["Die", "faust", "/", "die", "tau\u00b7sen\u00b7den", "den", "un\u00b7ter\u00b7gang", "ge\u00b7dr\u00e4u't", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJA", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kont\u2019 einer kugel sich von weiten nicht erwehren.", "tokens": ["Kont'", "ei\u00b7ner", "ku\u00b7gel", "sich", "von", "wei\u00b7ten", "nicht", "er\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PRF", "APPR", "ADJA", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich fiel wie Dohna fiel/ und tausend andre mehr/", "tokens": ["Ich", "fiel", "wie", "Doh\u00b7na", "fiel", "/", "und", "tau\u00b7send", "and\u00b7re", "mehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NE", "VVFIN", "$(", "KON", "CARD", "PIS", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So der ber\u00fchmte sturm vor Ofen auffgerieben;", "tokens": ["So", "der", "be\u00b7r\u00fchm\u00b7te", "sturm", "vor", "O\u00b7fen", "auff\u00b7ge\u00b7rie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir lieffen tapffer an/ vielleicht auch allzusehr/", "tokens": ["Wir", "lief\u00b7fen", "tapf\u00b7fer", "an", "/", "viel\u00b7leicht", "auch", "all\u00b7zu\u00b7sehr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$(", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nachdem es von uns heist: Sie sind davor geblieben.", "tokens": ["Nach\u00b7dem", "es", "von", "uns", "heist", ":", "Sie", "sind", "da\u00b7vor", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Doch sag\u2019 ich dieses nicht/ uns damit zu beklagen.", "tokens": ["Doch", "sag'", "ich", "die\u00b7ses", "nicht", "/", "uns", "da\u00b7mit", "zu", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "PTKNEG", "$(", "PPER", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Was uns betroffen hat/ kan uns nicht fremde seyn.", "tokens": ["Was", "uns", "be\u00b7trof\u00b7fen", "hat", "/", "kan", "uns", "nicht", "frem\u00b7de", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$(", "VMFIN", "PPER", "PTKNEG", "ADJA", "VAINF", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Ein held steht \u00fcberall auff seinem leichen-stein/", "tokens": ["Ein", "held", "steht", "\u00fc\u00b7be\u00b7rall", "auff", "sei\u00b7nem", "lei\u00b7chen\u00b7stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil zwischen sieg und tod wir uns zum kampffe wagen.", "tokens": ["Weil", "zwi\u00b7schen", "sieg", "und", "tod", "wir", "uns", "zum", "kampf\u00b7fe", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "KON", "NN", "PPER", "PRF", "APPRART", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Todt/ oder sieghafft seyn/ ist beydes unser ziel/", "tokens": ["Todt", "/", "o\u00b7der", "sieg\u00b7hafft", "seyn", "/", "ist", "bey\u00b7des", "un\u00b7ser", "ziel", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "VVPP", "VAINF", "$(", "VAFIN", "PIS", "PPOSAT", "NN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Was auch von beyden kommt/ mu\u00df uns doch ehre bringen;", "tokens": ["Was", "auch", "von", "bey\u00b7den", "kommt", "/", "mu\u00df", "uns", "doch", "eh\u00b7re", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "PIS", "VVFIN", "$(", "VMFIN", "PPER", "ADV", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und weil di\u00df unser zweck/ so gilts uns gleiche viel/", "tokens": ["Und", "weil", "di\u00df", "un\u00b7ser", "zweck", "/", "so", "gilts", "uns", "glei\u00b7che", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "PPOSAT", "NN", "$(", "ADV", "VVFIN", "PPER", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ob lebend oder tod wir uns zur selben schwingen.", "tokens": ["Ob", "le\u00b7bend", "o\u00b7der", "tod", "wir", "uns", "zur", "sel\u00b7ben", "schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "KON", "NN", "PPER", "PRF", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Weil man ja sterben mu\u00df/ wer will nicht stehend sterben?", "tokens": ["Weil", "man", "ja", "ster\u00b7ben", "mu\u00df", "/", "wer", "will", "nicht", "ste\u00b7hend", "ster\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "VMFIN", "$(", "PWS", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Di\u00df ist die todes-art/ so k\u00e4yser auch begehrt.", "tokens": ["Di\u00df", "ist", "die", "to\u00b7des\u00b7art", "/", "so", "k\u00e4y\u00b7ser", "auch", "be\u00b7gehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$(", "ADV", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der auff dem bette liegt/ von kranckheit ausgezehrt/", "tokens": ["Der", "auff", "dem", "bet\u00b7te", "liegt", "/", "von", "kran\u00b7ck\u00b7heit", "aus\u00b7ge\u00b7zehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "VVFIN", "$(", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Mu\u00df/ vor dem tode schon/ verwesen und verderben.", "tokens": ["Mu\u00df", "/", "vor", "dem", "to\u00b7de", "schon", "/", "ver\u00b7we\u00b7sen", "und", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$(", "APPR", "ART", "NN", "ADV", "$(", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hingegen ein soldat/ der auff der wahlstatt bleibt/", "tokens": ["Hin\u00b7ge\u00b7gen", "ein", "sol\u00b7dat", "/", "der", "auff", "der", "wahl\u00b7statt", "bleibt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Stirbt mit demselben muth/ mit dem er ausgegangen;", "tokens": ["Stirbt", "mit", "dem\u00b7sel\u00b7ben", "muth", "/", "mit", "dem", "er", "aus\u00b7ge\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDAT", "NN", "$(", "APPR", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und da sein testament er mit dem degen schreibt/", "tokens": ["Und", "da", "sein", "tes\u00b7ta\u00b7ment", "er", "mit", "dem", "de\u00b7gen", "schreibt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.8": {"text": "Will er zugleich bewehrt den letzten feind empfangen.", "tokens": ["Will", "er", "zu\u00b7gleich", "be\u00b7wehrt", "den", "letz\u00b7ten", "feind", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Nicht sch\u00f6ner stirbt ein held/ als in den k\u00fchnen waffen;", "tokens": ["Nicht", "sch\u00f6\u00b7ner", "stirbt", "ein", "held", "/", "als", "in", "den", "k\u00fch\u00b7nen", "waf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVFIN", "ART", "NN", "$(", "KOKOM", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sonderlich ein Printz/ der von der helden-that/", "tokens": ["Und", "son\u00b7der\u00b7lich", "ein", "Printz", "/", "der", "von", "der", "hel\u00b7den\u00b7that", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "$(", "ART", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der ahnen tapfferkeit/ den f\u00fcrsten-purpur hat/", "tokens": ["Der", "ah\u00b7nen", "tapf\u00b7fer\u00b7keit", "/", "den", "f\u00fcrs\u00b7ten\u00b7pur\u00b7pur", "hat", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich/ durch sie auch selbst/ sucht einen glantz zu schaffen.", "tokens": ["Und", "sich", "/", "durch", "sie", "auch", "selbst", "/", "sucht", "ei\u00b7nen", "glantz", "zu", "schaf\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$(", "APPR", "PPER", "ADV", "ADV", "$(", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er stirbt in seiner pracht/ von helm und schild geziert;", "tokens": ["Er", "stirbt", "in", "sei\u00b7ner", "pracht", "/", "von", "helm", "und", "schild", "ge\u00b7ziert", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "APPR", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der tod ergreiffet ihn auf ritterlichen wegen;", "tokens": ["Der", "tod", "er\u00b7greif\u00b7fet", "ihn", "auf", "rit\u00b7ter\u00b7li\u00b7chen", "we\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ADJA", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und weil di\u00df sein gewehr er f\u00fcr die tugend f\u00fchr\u2019t/", "tokens": ["Und", "weil", "di\u00df", "sein", "ge\u00b7wehr", "er", "f\u00fcr", "die", "tu\u00b7gend", "f\u00fchr't", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mu\u00df man es ihm aufs grab zu dessen zeugni\u00df legen.", "tokens": ["Mu\u00df", "man", "es", "ihm", "aufs", "grab", "zu", "des\u00b7sen", "zeug\u00b7ni\u00df", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "PPER", "APPRART", "NN", "APPR", "PRELAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So kan auch unser ruhm/ nach welchem wir hie trachten/", "tokens": ["So", "kan", "auch", "un\u00b7ser", "ruhm", "/", "nach", "wel\u00b7chem", "wir", "hie", "trach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "NN", "$(", "APPR", "PRELS", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch nichts vollkommener/ als solchen todt/ bestehn:", "tokens": ["Durch", "nichts", "voll\u00b7kom\u00b7me\u00b7ner", "/", "als", "sol\u00b7chen", "todt", "/", "be\u00b7stehn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIS", "ADJD", "$(", "KOKOM", "PIAT", "ADJD", "$(", "VVINF", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da\u00df man in einer schlacht Turenne sterben sehn/", "tokens": ["Da\u00df", "man", "in", "ei\u00b7ner", "schlacht", "Tu\u00b7ren\u00b7ne", "ster\u00b7ben", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "ADJA", "NN", "VVINF", "VVINF", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Macht ihn uns mehr bekant/ als alle seine schlachten.", "tokens": ["Macht", "ihn", "uns", "mehr", "be\u00b7kant", "/", "als", "al\u00b7le", "sei\u00b7ne", "schlach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "ADV", "ADJD", "$(", "KOUS", "PIS", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Weil unser leben kurtz in dieser sterbligkeit/", "tokens": ["Weil", "un\u00b7ser", "le\u00b7ben", "kurtz", "in", "die\u00b7ser", "ster\u00b7blig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "ADJD", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist ein ber\u00fchmter tod die ewigkeit im leben.", "tokens": ["Ist", "ein", "be\u00b7r\u00fchm\u00b7ter", "tod", "die", "e\u00b7wig\u00b7keit", "im", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "NN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie aber sterben wir ber\u00fchmter als im streit/", "tokens": ["Wie", "a\u00b7ber", "ster\u00b7ben", "wir", "be\u00b7r\u00fchm\u00b7ter", "als", "im", "streit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ADJD", "KOKOM", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo wir als m\u00e4nner stehn/ und uns der welt begeben?", "tokens": ["Wo", "wir", "als", "m\u00e4n\u00b7ner", "stehn", "/", "und", "uns", "der", "welt", "be\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "KOUS", "ADJA", "VVINF", "$(", "KON", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Jm kriege stirbt man nicht wie sonst die menschen sterben;", "tokens": ["Jm", "krie\u00b7ge", "stirbt", "man", "nicht", "wie", "sonst", "die", "men\u00b7schen", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "PTKNEG", "KOKOM", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht sich und der natur/ aus schuldigkeit und noth:", "tokens": ["Nicht", "sich", "und", "der", "na\u00b7tur", "/", "aus", "schul\u00b7dig\u00b7keit", "und", "noth", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PRF", "KON", "ART", "NN", "$(", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man geht f\u00fcr\u2019s vaterland freywillig in den tod;", "tokens": ["Man", "geht", "f\u00fcr's", "va\u00b7ter\u00b7land", "frey\u00b7wil\u00b7lig", "in", "den", "tod", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und diese willk\u00fchr mu\u00df uns eben ruhm erwerben.", "tokens": ["Und", "die\u00b7se", "will\u00b7k\u00fchr", "mu\u00df", "uns", "e\u00b7ben", "ruhm", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VMFIN", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer f\u00fcr das vaterland und seinen herren f\u00e4llt/", "tokens": ["Wer", "f\u00fcr", "das", "va\u00b7ter\u00b7land", "und", "sei\u00b7nen", "her\u00b7ren", "f\u00e4llt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mag tod und eitelkeit als schattenwerck verlachen;", "tokens": ["Mag", "tod", "und", "ei\u00b7tel\u00b7keit", "als", "schat\u00b7ten\u00b7werck", "ver\u00b7la\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "KON", "ADJD", "KOKOM", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil der/ f\u00fcr den man stirbt/ uns ungestorben h\u00e4lt/", "tokens": ["Weil", "der", "/", "f\u00fcr", "den", "man", "stirbt", "/", "uns", "un\u00b7ge\u00b7stor\u00b7ben", "h\u00e4lt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "APPR", "ART", "PIS", "VVFIN", "$(", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und die gesetze selbst uns unverwe\u00dflich machen.", "tokens": ["Und", "die", "ge\u00b7set\u00b7ze", "selbst", "uns", "un\u00b7ver\u00b7we\u00df\u00b7lich", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADV", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Was vortheil wird denn nicht aus meinem grabe sprossen?", "tokens": ["Was", "vor\u00b7theil", "wird", "denn", "nicht", "aus", "mei\u00b7nem", "gra\u00b7be", "spros\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da f\u00fcr die Christenheit/ des K\u00e4ysers reich und land/", "tokens": ["Da", "f\u00fcr", "die", "Chris\u00b7ten\u00b7heit", "/", "des", "K\u00e4y\u00b7sers", "reich", "und", "land", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$(", "ART", "NN", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die ehre Brandenburgs/ und aller ruhestand/", "tokens": ["Die", "eh\u00b7re", "Bran\u00b7den\u00b7burgs", "/", "und", "al\u00b7ler", "ru\u00b7he\u00b7stand", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "$(", "KON", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich Curlands helden-blut/ das mich beseelt/ vergossen?", "tokens": ["Ich", "Cur\u00b7lands", "hel\u00b7den\u00b7blut", "/", "das", "mich", "be\u00b7seelt", "/", "ver\u00b7gos\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "NE", "NN", "$(", "PRELS", "PPER", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die festung/ so mit sturm noch niemahls \u00fcberging/", "tokens": ["Die", "fes\u00b7tung", "/", "so", "mit", "sturm", "noch", "nie\u00b7mahls", "\u00fc\u00b7ber\u00b7ging", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "APPR", "ADJD", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Versuchten wir dennoch durch waffen zu gewinnen;", "tokens": ["Ver\u00b7such\u00b7ten", "wir", "den\u00b7noch", "durch", "waf\u00b7fen", "zu", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und da an Ofens fall des T\u00fcrcken unfall hing/", "tokens": ["Und", "da", "an", "O\u00b7fens", "fall", "des", "T\u00fcr\u00b7cken", "un\u00b7fall", "hing", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "NN", "ART", "NN", "NN", "VVFIN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Wie starb ich/ als ein Printz/ im edlerem beginnen?", "tokens": ["Wie", "starb", "ich", "/", "als", "ein", "Printz", "/", "im", "ed\u00b7le\u00b7rem", "be\u00b7gin\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$(", "KOUS", "ART", "NN", "$(", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Die Christen musten ja des barbers frevel r\u00e4chen.", "tokens": ["Die", "Chris\u00b7ten", "mus\u00b7ten", "ja", "des", "bar\u00b7bers", "fre\u00b7vel", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wie hier iederman erhitzt zum kampffe war;", "tokens": ["Und", "wie", "hier", "ie\u00b7der\u00b7man", "er\u00b7hitzt", "zum", "kampf\u00b7fe", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PIS", "VVFIN", "APPRART", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erstritt\u2019 ich mir vorher den vorzug der gefahr; ", "tokens": ["Er\u00b7stritt'", "ich", "mir", "vor\u00b7her", "den", "vor\u00b7zug", "der", "ge\u00b7fahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Hertzog wolt\u2019 ich auch zu erst die mauren brechen.", "tokens": ["Als", "Hert\u00b7zog", "wolt'", "ich", "auch", "zu", "erst", "die", "mau\u00b7ren", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VMFIN", "PPER", "ADV", "APPR", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hie stand der ehren-thron der tugend ausgesetzt;", "tokens": ["Hie", "stand", "der", "eh\u00b7ren\u00b7thron", "der", "tu\u00b7gend", "aus\u00b7ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gl\u00fcckselig/ wem der tod den aufftritt wollen g\u00f6nnen!", "tokens": ["Gl\u00fcck\u00b7se\u00b7lig", "/", "wem", "der", "tod", "den", "auf\u00b7ftritt", "wol\u00b7len", "g\u00f6n\u00b7nen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "PWS", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Denn die gelegenheit wird billig werth gesch\u00e4tzt/", "tokens": ["Denn", "die", "ge\u00b7le\u00b7gen\u00b7heit", "wird", "bil\u00b7lig", "werth", "ge\u00b7sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dieweil sie uns so gut nicht wiederkommen k\u00f6nnen.", "tokens": ["Die\u00b7weil", "sie", "uns", "so", "gut", "nicht", "wie\u00b7der\u00b7kom\u00b7men", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADJD", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Was schad\u2019t es/ da\u00df ein Printz im felde sterben m\u00fcssen;", "tokens": ["Was", "schad't", "es", "/", "da\u00df", "ein", "Printz", "im", "fel\u00b7de", "ster\u00b7ben", "m\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$(", "KOUS", "ART", "NN", "APPRART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bl\u00e4st nicht der rauhe wind auch f\u00fcrsten zimmer an?", "tokens": ["Bl\u00e4st", "nicht", "der", "rau\u00b7he", "wind", "auch", "f\u00fcrs\u00b7ten", "zim\u00b7mer", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "VAFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den harnisch/ den ich nicht im anlauf\u2019 angethan/", "tokens": ["Den", "har\u00b7nisch", "/", "den", "ich", "nicht", "im", "an\u00b7lauf'", "an\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$(", "PRELS", "PPER", "PTKNEG", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Braucht\u2019 ich mit grosser pracht zu meinem sterbe-k\u00fcssen.", "tokens": ["Braucht'", "ich", "mit", "gros\u00b7ser", "pracht", "zu", "mei\u00b7nem", "ster\u00b7be\u00b7k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier \u00fcberwand ich erst den menschlichen verdru\u00df;", "tokens": ["Hier", "\u00fc\u00b7ber\u00b7wand", "ich", "erst", "den", "menschli\u00b7chen", "ver\u00b7dru\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Es kont in freyer lufft mein ruhm auch mehr erschallen;", "tokens": ["Es", "kont", "in", "frey\u00b7er", "lufft", "mein", "ruhm", "auch", "mehr", "er\u00b7schal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN", "PPOSAT", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der denn auch in der welt gewi\u00df erschallen mu\u00df/", "tokens": ["Der", "denn", "auch", "in", "der", "welt", "ge\u00b7wi\u00df", "er\u00b7schal\u00b7len", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "ART", "NN", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da mich/ auf dieser bahn/ drey l\u00e4ger sehen fallen.", "tokens": ["Da", "mich", "/", "auf", "die\u00b7ser", "bahn", "/", "drey", "l\u00e4\u00b7ger", "se\u00b7hen", "fal\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "APPR", "PDAT", "NN", "$(", "CARD", "ADJA", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Mein Curland/ das mich liebt/ beklagt zwar mein verblassen;", "tokens": ["Mein", "Cur\u00b7land", "/", "das", "mich", "liebt", "/", "be\u00b7klagt", "zwar", "mein", "ver\u00b7blas\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PRELS", "PPER", "VVFIN", "$(", "VVFIN", "ADV", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch bleibet di\u00df sein trost/ da\u00df ich verewigt bin;", "tokens": ["Doch", "blei\u00b7bet", "di\u00df", "sein", "trost", "/", "da\u00df", "ich", "ve\u00b7re\u00b7wigt", "bin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "PPOSAT", "NN", "$(", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und ihm und Brandenburg zum mercklichen gewinn", "tokens": ["Und", "ihm", "und", "Bran\u00b7den\u00b7burg", "zum", "merck\u00b7li\u00b7chen", "ge\u00b7winn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "KON", "NE", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die helden Casimir und Ferdinand verlassen.", "tokens": ["Die", "hel\u00b7den", "Ca\u00b7si\u00b7mir", "und", "Fer\u00b7di\u00b7nand", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wobey auch selbst das haupt des reiches mich bedaurt;", "tokens": ["Wo\u00b7bey", "auch", "selbst", "das", "haupt", "des", "rei\u00b7ches", "mich", "be\u00b7daurt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "ART", "ADJA", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Brandenburg f\u00fcr mich gar thr\u00e4nen lassen fliessen;", "tokens": ["Und", "Bran\u00b7den\u00b7burg", "f\u00fcr", "mich", "gar", "thr\u00e4\u00b7nen", "las\u00b7sen", "flies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "PPER", "ADV", "VVINF", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Voraus sein Friederich/ der mich noch stets betraurt/", "tokens": ["Vo\u00b7raus", "sein", "Frie\u00b7de\u00b7rich", "/", "der", "mich", "noch", "stets", "be\u00b7traurt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und mein ged\u00e4chtnis sucht in stein und ertz zu schliessen.", "tokens": ["Und", "mein", "ge\u00b7d\u00e4cht\u00b7nis", "sucht", "in", "stein", "und", "ertz", "zu", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "NN", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Es ehren meinen tod auch Brandenburgs carthaunen/", "tokens": ["Es", "eh\u00b7ren", "mei\u00b7nen", "tod", "auch", "Bran\u00b7den\u00b7burgs", "car\u00b7thau\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die durch sein gantzes land man von mir sausen h\u00f6rt/", "tokens": ["Die", "durch", "sein", "gant\u00b7zes", "land", "man", "von", "mir", "sau\u00b7sen", "h\u00f6rt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN", "PIS", "APPR", "PPER", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo nur mein leich-gepr\u00e4ng mit meinem c\u00f6rper f\u00e4hrt.", "tokens": ["Wo", "nur", "mein", "leich\u00b7ge\u00b7pr\u00e4ng", "mit", "mei\u00b7nem", "c\u00f6r\u00b7per", "f\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie bl\u00e4st man meinen ruhm aus helleren posaunen?", "tokens": ["Wie", "bl\u00e4st", "man", "mei\u00b7nen", "ruhm", "aus", "hel\u00b7le\u00b7ren", "po\u00b7sau\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O allzupr\u00e4chtige belohnung meiner treu!", "tokens": ["O", "all\u00b7zu\u00b7pr\u00e4ch\u00b7ti\u00b7ge", "be\u00b7loh\u00b7nung", "mei\u00b7ner", "treu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was kan ich w\u00fcrdigers mit in die grube nehmen?", "tokens": ["Was", "kan", "ich", "w\u00fcr\u00b7di\u00b7gers", "mit", "in", "die", "gru\u00b7be", "neh\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VAFIN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was la\u00df\u2019 ich auch der welt/ das gr\u00f6\u00df- und st\u00e4rcker sey/", "tokens": ["Was", "la\u00df'", "ich", "auch", "der", "welt", "/", "das", "gr\u00f6\u00df", "und", "st\u00e4r\u00b7cker", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "$(", "ART", "TRUNC", "KON", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Tod und vergessenheit auff ewig zu besch\u00e4men?", "tokens": ["Tod", "und", "ver\u00b7ges\u00b7sen\u00b7heit", "auff", "e\u00b7wig", "zu", "be\u00b7sch\u00e4\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.15": {"line.1": {"text": "So wird die nachwelt mich von meinem tode loben;", "tokens": ["So", "wird", "die", "nach\u00b7welt", "mich", "von", "mei\u00b7nem", "to\u00b7de", "lo\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein k\u00e4yserlicher tod verg\u00f6ttert mein ger\u00fccht;", "tokens": ["Ein", "k\u00e4y\u00b7ser\u00b7li\u00b7cher", "tod", "ver\u00b7g\u00f6t\u00b7tert", "mein", "ge\u00b7r\u00fccht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und war ich gleich allhier ein Alexander nicht;", "tokens": ["Und", "war", "ich", "gleich", "all\u00b7hier", "ein", "A\u00b7lex\u00b7an\u00b7der", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ART", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat mich dennoch mein tod ietzt \u00fcber ihn erhoben.", "tokens": ["Hat", "mich", "den\u00b7noch", "mein", "tod", "ietzt", "\u00fc\u00b7ber", "ihn", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er fiel verkleinerlich/ durch gifft und hinterlist;", "tokens": ["Er", "fiel", "ver\u00b7klei\u00b7ner\u00b7lich", "/", "durch", "gifft", "und", "hin\u00b7ter\u00b7list", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$(", "APPR", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich starb/ in einem sturm/ den tod der helden-erben;", "tokens": ["Ich", "starb", "/", "in", "ei\u00b7nem", "sturm", "/", "den", "tod", "der", "hel\u00b7den\u00b7er\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "APPR", "ART", "NN", "$(", "ART", "NN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So/ da\u00df ich ietzo hin/ was er gewesen ist:", "tokens": ["So", "/", "da\u00df", "ich", "iet\u00b7zo", "hin", "/", "was", "er", "ge\u00b7we\u00b7sen", "ist", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPER", "ADV", "PTKVZ", "$(", "PWS", "PPER", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er war im leben gro\u00df/ ich bin es ietzt im sterben.", "tokens": ["Er", "war", "im", "le\u00b7ben", "gro\u00df", "/", "ich", "bin", "es", "ietzt", "im", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "VVFIN", "ADJD", "$(", "PPER", "VAFIN", "PPER", "ADV", "APPRART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}