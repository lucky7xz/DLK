{"dta.poem.19137": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "CxV.  Auf Hrn. Heinrich des 29ten 34ten  \n Geburts-Tag.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Mein Bruder! k\u00f6nnt ich wohl an diesem Tage schwei-\ngen,", "tokens": ["Mein", "Bru\u00b7der", "!", "k\u00f6nnt", "ich", "wohl", "an", "die\u00b7sem", "Ta\u00b7ge", "schwei", "gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN", "TRUNC", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So sehr mein Dichten sonst bisher geruhet hat!", "tokens": ["So", "sehr", "mein", "Dich\u00b7ten", "sonst", "bis\u00b7her", "ge\u00b7ru\u00b7het", "hat", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hie hat kein Stille-seyn, hie hat kein Schweigen statt,", "tokens": ["Hie", "hat", "kein", "Stil\u00b7le\u00b7seyn", ",", "hie", "hat", "kein", "Schwei\u00b7gen", "statt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "ADV", "VAFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vor meinem K\u00f6nige will ich mich sachte neigen:", "tokens": ["Vor", "mei\u00b7nem", "K\u00f6\u00b7ni\u00b7ge", "will", "ich", "mich", "sach\u00b7te", "nei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "PRF", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn Worte machen auch die Sache da nicht aus,", "tokens": ["Denn", "Wor\u00b7te", "ma\u00b7chen", "auch", "die", "Sa\u00b7che", "da", "nicht", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "ART", "NN", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier rede meine That, so wird ein Danck-Lied draus.", "tokens": ["Hier", "re\u00b7de", "mei\u00b7ne", "That", ",", "so", "wird", "ein", "Dan\u00b7ck\u00b7Lied", "draus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Allein erblicke ich der Menschen Trauer-Hauffen,", "tokens": ["Al\u00b7lein", "er\u00b7bli\u00b7cke", "ich", "der", "Men\u00b7schen", "Trau\u00b7e\u00b7rHauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die von der Finsterni\u00df so hart geblendet sind,", "tokens": ["Die", "von", "der", "Fins\u00b7ter\u00b7ni\u00df", "so", "hart", "ge\u00b7blen\u00b7det", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df keins an Christi Krafft was Wesendliches find,", "tokens": ["Da\u00df", "keins", "an", "Chris\u00b7ti", "Krafft", "was", "We\u00b7send\u00b7li\u00b7ches", "find", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "APPR", "NE", "NN", "PWS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die an den Fels des Heyls gewohnt sind anzulauffen;", "tokens": ["Die", "an", "den", "Fels", "des", "Heyls", "ge\u00b7wohnt", "sind", "an\u00b7zu\u00b7lauf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN", "VVPP", "VAFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wird in meiner Brust ein Jammer-Thon gesp\u00fchrt.", "tokens": ["So", "wird", "in", "mei\u00b7ner", "Brust", "ein", "Jam\u00b7mer\u00b7Thon", "ge\u00b7sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was! denck ich, ", "tokens": ["Was", "!", "denck", "ich", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PWS", "$.", "VVIMP", "PPER", "$,"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.3": {"line.1": {"text": "Zwey, drey mahl und noch mehr, allein der Hindernisse,", "tokens": ["Zwey", ",", "drey", "mahl", "und", "noch", "mehr", ",", "al\u00b7lein", "der", "Hin\u00b7der\u00b7nis\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "$,", "CARD", "ADV", "KON", "ADV", "ADV", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist eine solche Zahl, die nicht zu fassen ist.", "tokens": ["Ist", "ei\u00b7ne", "sol\u00b7che", "Zahl", ",", "die", "nicht", "zu", "fas\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PIAT", "NN", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Heyland, w\u00e4rst du nicht so ritterlich ger\u00fcst!", "tokens": ["Mein", "Hey\u00b7land", ",", "w\u00e4rst", "du", "nicht", "so", "rit\u00b7ter\u00b7lich", "ge\u00b7r\u00fcst", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VAFIN", "PPER", "PTKNEG", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein Wunder, da\u00df die Welt dich v\u00f6llig niederrisse.", "tokens": ["Kein", "Wun\u00b7der", ",", "da\u00df", "die", "Welt", "dich", "v\u00f6l\u00b7lig", "nie\u00b7der\u00b7ris\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "ART", "NN", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vor diesen dachte man noch auf Entschuldigung;", "tokens": ["Vor", "die\u00b7sen", "dach\u00b7te", "man", "noch", "auf", "Ent\u00b7schul\u00b7di\u00b7gung", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PIS", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Jtzt ruffst du, niemand kommt, und damit ists genung.", "tokens": ["Jtzt", "ruffst", "du", ",", "nie\u00b7mand", "kommt", ",", "und", "da\u00b7mit", "ists", "ge\u00b7nung", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PIS", "VVFIN", "$,", "KON", "PAV", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Gewi\u00df, die Zeit ist da, die unbegreiflich ist,", "tokens": ["Ge\u00b7wi\u00df", ",", "die", "Zeit", "ist", "da", ",", "die", "un\u00b7be\u00b7greif\u00b7lich", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "ADV", "$,", "PRELS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man hat sich ein Gespenst von Christenthum gestaltet,", "tokens": ["Man", "hat", "sich", "ein", "Ge\u00b7spenst", "von", "Chris\u00b7ten\u00b7thum", "ge\u00b7stal\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PRF", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das der Gerechtigkeit und Heilgung Platz verwaltet,", "tokens": ["Das", "der", "Ge\u00b7rech\u00b7tig\u00b7keit", "und", "Heil\u00b7gung", "Platz", "ver\u00b7wal\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "KON", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wer darauf nicht bleibt, was er im Zeugni\u00df li\u00dft,", "tokens": ["Und", "wer", "da\u00b7rauf", "nicht", "bleibt", ",", "was", "er", "im", "Zeug\u00b7ni\u00df", "li\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PAV", "PTKNEG", "VVFIN", "$,", "PWS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jm Zeugni\u00df, das uns auch vor Satanas verth\u00e4digt,", "tokens": ["Jm", "Zeug\u00b7ni\u00df", ",", "das", "uns", "auch", "vor", "Sa\u00b7ta\u00b7nas", "ver\u00b7th\u00e4\u00b7digt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Der wird an Haupt und Hertz aufs t\u00f6dlichste besch\u00e4digt.", "tokens": ["Der", "wird", "an", "Haupt", "und", "Hertz", "aufs", "t\u00f6d\u00b7lichs\u00b7te", "be\u00b7sch\u00e4\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "KON", "NN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wir haben uns, GOtt lob! zw\u00f6lff Jahr daher gekannt,", "tokens": ["Wir", "ha\u00b7ben", "uns", ",", "Gott", "lob", "!", "zw\u00f6lff", "Jahr", "da\u00b7her", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "NN", "NN", "$.", "CARD", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir wissen was der HErr vor Z\u00fcge an uns bringet,", "tokens": ["Wir", "wis\u00b7sen", "was", "der", "Herr", "vor", "Z\u00fc\u00b7ge", "an", "uns", "brin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "ART", "NN", "APPR", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wie er nach und nach zu seinen F\u00fcssen zwinget,", "tokens": ["Und", "wie", "er", "nach", "und", "nach", "zu", "sei\u00b7nen", "F\u00fcs\u00b7sen", "zwin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "APPR", "KON", "APPR", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was ihm nicht eben ist, und hat die Oberhand.", "tokens": ["Was", "ihm", "nicht", "e\u00b7ben", "ist", ",", "und", "hat", "die", "O\u00b7ber\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADV", "VAFIN", "$,", "KON", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Herrenhutisches bew\u00e4hrtes Pilger-Leben", "tokens": ["Dein", "Her\u00b7ren\u00b7hu\u00b7ti\u00b7sches", "be\u00b7w\u00e4hr\u00b7tes", "Pil\u00b7ger\u00b7Le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kan uns von deinem Sinn erst rechte Nachricht geben.", "tokens": ["Kan", "uns", "von", "dei\u00b7nem", "Sinn", "erst", "rech\u00b7te", "Nach\u00b7richt", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ein Volck, das an der Stirn und Brust gezeichnet geht,", "tokens": ["Ein", "Volck", ",", "das", "an", "der", "Stirn", "und", "Brust", "ge\u00b7zeich\u00b7net", "geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "KON", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das seines Tauff-Bunds Krafft nicht gern verrauchen l\u00e4s-", "tokens": ["Das", "sei\u00b7nes", "Tauff\u00b7Bunds", "Krafft", "nicht", "gern", "ver\u00b7rau\u00b7chen", "l\u00e4s"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "NN", "NN", "PTKNEG", "ADV", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dem andrer Seelen Noth manch Seuffzen ausgepresset,", "tokens": ["Dem", "an\u00b7drer", "See\u00b7len", "Noth", "manch", "Seuff\u00b7zen", "aus\u00b7ge\u00b7pres\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Volck, das nach dem Winck der Liebe geht und steht,", "tokens": ["Ein", "Volck", ",", "das", "nach", "dem", "Win\u00b7ck", "der", "Lie\u00b7be", "geht", "und", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Sonst abgeschieden lebt, bezeuget offenbahr,", "tokens": ["Sonst", "ab\u00b7ge\u00b7schie\u00b7den", "lebt", ",", "be\u00b7zeu\u00b7get", "of\u00b7fen\u00b7bahr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVFIN", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie dein ", "tokens": ["Wie", "dein"], "token_info": ["word", "word"], "pos": ["PWAV", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "So eile denn dahin, wo dich dein HErr gesetzt,", "tokens": ["So", "ei\u00b7le", "denn", "da\u00b7hin", ",", "wo", "dich", "dein", "Herr", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "PAV", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Geh von dem Volck des HErrn viel hundert mahl geseeg-", "tokens": ["Geh", "von", "dem", "Volck", "des", "Herrn", "viel", "hun\u00b7dert", "mahl", "ge\u00b7see\u00b7g"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "ART", "NN", "ADV", "CARD", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Getrost, wenn dir hinfort zuweilen was begegnet,", "tokens": ["Ge\u00b7trost", ",", "wenn", "dir", "hin\u00b7fort", "zu\u00b7wei\u00b7len", "was", "be\u00b7geg\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ADV", "ADV", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das unter Christi Schutz die Leidenden erg\u00f6tzt,", "tokens": ["Das", "un\u00b7ter", "Chris\u00b7ti", "Schutz", "die", "Lei\u00b7den\u00b7den", "er\u00b7g\u00f6tzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NE", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn du dich vor der Welt und Eitelkeit verriegelst,", "tokens": ["Wenn", "du", "dich", "vor", "der", "Welt", "und", "Ei\u00b7tel\u00b7keit", "ver\u00b7rie\u00b7gelst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und die Gedult am Reich mit deiner Treu versiegelst.", "tokens": ["Und", "die", "Ge\u00b7dult", "am", "Reich", "mit", "dei\u00b7ner", "Treu", "ver\u00b7sie\u00b7gelst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.8": {"line.1": {"text": "Natur und Gnade hat uns vielfach angeschn\u00fcrt;", "tokens": ["Na\u00b7tur", "und", "Gna\u00b7de", "hat", "uns", "viel\u00b7fach", "an\u00b7ge\u00b7schn\u00fcrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und w\u00e4r ein Menschen-Kind noch nach dem Fleisch zu ken-", "tokens": ["Und", "w\u00e4r", "ein", "Men\u00b7schen\u00b7Kind", "noch", "nach", "dem", "Fleisch", "zu", "ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So m\u00fcst ich dich gewi\u00df allein dazu ernennen:", "tokens": ["So", "m\u00fcst", "ich", "dich", "ge\u00b7wi\u00df", "al\u00b7lein", "da\u00b7zu", "er\u00b7nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn eines hat bey uns das andre eingef\u00fchrt.", "tokens": ["Denn", "ei\u00b7nes", "hat", "bey", "uns", "das", "and\u00b7re", "ein\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "APPR", "PPER", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich kan mich unsers Bands von aussen nicht erinnern,", "tokens": ["Ich", "kan", "mich", "un\u00b7sers", "Bands", "von", "aus\u00b7sen", "nicht", "e\u00b7rin\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "NE", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es f\u00e4llt mir alsobald sehr vieles ein vom Innern.", "tokens": ["Es", "f\u00e4llt", "mir", "al\u00b7so\u00b7bald", "sehr", "vie\u00b7les", "ein", "vom", "In\u00b7nern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PIS", "ART", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der HErr, der uns gesetzt, da\u00df wir uns nahe seyn,", "tokens": ["Der", "Herr", ",", "der", "uns", "ge\u00b7setzt", ",", "da\u00df", "wir", "uns", "na\u00b7he", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "KOUS", "PPER", "PRF", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der spreche \u00fcber uns aus den Gemeinschaffts-Seegen:", "tokens": ["Der", "spre\u00b7che", "\u00fc\u00b7ber", "uns", "aus", "den", "Ge\u00b7mein\u00b7schaffts\u00b7See\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und will sich eine Krafft der Nacht dazwischen legen,", "tokens": ["Und", "will", "sich", "ei\u00b7ne", "Krafft", "der", "Nacht", "da\u00b7zwi\u00b7schen", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ART", "NN", "ART", "NN", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wolle uns davon sein Gnaden-Strahl befreyn.", "tokens": ["So", "wol\u00b7le", "uns", "da\u00b7von", "sein", "Gna\u00b7den\u00b7Strahl", "be\u00b7freyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PRF", "PAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich will, so lang ich bin, dich und dein Amts-Gesch\u00e4ffte", "tokens": ["Ich", "will", ",", "so", "lang", "ich", "bin", ",", "dich", "und", "dein", "Amts\u00b7Ge\u00b7sch\u00e4ff\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,", "PPER", "KON", "PPOSAT", "NN"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.6": {"text": "Mit br\u00fcderlicher Treu bedienen. HErr, gieb Kr\u00e4ffte.", "tokens": ["Mit", "br\u00fc\u00b7der\u00b7li\u00b7cher", "Treu", "be\u00b7die\u00b7nen", ".", "Herr", ",", "gieb", "Kr\u00e4ff\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$.", "NN", "$,", "VVIMP", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}