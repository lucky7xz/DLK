{"dta.poem.9398": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "An Seiner guten Freunde Einen/  \n Als er von seiner Braut wegen Nothwendiger Ver-  \n richtung in Frembde Lande verreiset; in einem  \n gespr\u00e4che \u00fcbergeben/ woraus sie gezogen  \n und anher gesetzt.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ljebste/ wie seyd jhr so sehre bem\u00fchet/", "tokens": ["Ljebs\u00b7te", "/", "wie", "seyd", "jhr", "so", "seh\u00b7re", "be\u00b7m\u00fc\u00b7het", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "KOKOM", "VAFIN", "PPER", "ADV", "VVFIN", "VVFIN", "$("], "meter": "+---+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Da\u00df ich Euch jtzo mu\u00df la\u00dfen und zihn/", "tokens": ["Da\u00df", "ich", "Euch", "jt\u00b7zo", "mu\u00df", "la\u00b7\u00dfen", "und", "zihn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "KON", "VVINF", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Wisst Jhr nicht unser Gel\u00fccke das bl\u00fchet/", "tokens": ["Wisst", "Ihr", "nicht", "un\u00b7ser", "Ge\u00b7l\u00fc\u00b7cke", "das", "bl\u00fc\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "PDS", "VVFIN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Hertzes Lieb/ g\u00fcldner Schatz/ Sch\u00f6nster Rubien/", "tokens": ["Hert\u00b7zes", "Lieb", "/", "g\u00fcld\u00b7ner", "Schatz", "/", "Sch\u00f6ns\u00b7ter", "Ru\u00b7bi\u00b7en", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ADJA", "NN", "$(", "NN", "NE", "$("], "meter": "+-+---+-+--", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Ach la\u00dfet mich zihen/", "tokens": ["Ach", "la\u00b7\u00dfet", "mich", "zi\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Ich will mich bem\u00fchen", "tokens": ["Ich", "will", "mich", "be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "und schicken dazu/", "tokens": ["und", "schi\u00b7cken", "da\u00b7zu", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Bald widerzukommen", "tokens": ["Bald", "wi\u00b7der\u00b7zu\u00b7kom\u00b7men"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Zu Euerem frommen/", "tokens": ["Zu", "Eu\u00b7e\u00b7rem", "from\u00b7men", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Lebet in dessen in Frieden und Ruh!", "tokens": ["Le\u00b7bet", "in", "des\u00b7sen", "in", "Frie\u00b7den", "und", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDS", "APPR", "NN", "KON", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.2": {"line.1": {"text": "Lebet in dessen ach/ Liebeste/ lebet/", "tokens": ["Le\u00b7bet", "in", "des\u00b7sen", "ach", "/", "Lie\u00b7bes\u00b7te", "/", "le\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "APPR", "PDS", "XY", "$(", "NN", "$(", "VVFIN", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Lebet und dencket im besten an mich/", "tokens": ["Le\u00b7bet", "und", "den\u00b7cket", "im", "bes\u00b7ten", "an", "mich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "APPRART", "ADJA", "APPR", "PPER", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Euer so treues gem\u00fcthe das schwebet", "tokens": ["Eu\u00b7er", "so", "treu\u00b7es", "ge\u00b7m\u00fc\u00b7the", "das", "schwe\u00b7bet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "PDS", "VVFIN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Mir von dem Hertzen und dringet hinnein.", "tokens": ["Mir", "von", "dem", "Hert\u00b7zen", "und", "drin\u00b7get", "hin\u00b7nein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "und schreibet die Treue", "tokens": ["und", "schrei\u00b7bet", "die", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Mit Demand aufs Neue", "tokens": ["Mit", "De\u00b7mand", "aufs", "Neu\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPRART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Zu innerst hinnein/", "tokens": ["Zu", "in\u00b7nerst", "hin\u00b7nein", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "PTKVZ", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.8": {"text": "Macht ener Gesichte", "tokens": ["Macht", "e\u00b7ner", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Nicht also zunichte/", "tokens": ["Nicht", "al\u00b7so", "zu\u00b7nich\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Stillet das Weinen und la\u00dfet es seyn.", "tokens": ["Stil\u00b7let", "das", "Wei\u00b7nen", "und", "la\u00b7\u00dfet", "es", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "VAINF", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}}}}