{"textgrid.poem.60530": {"metadata": {"author": {"name": "Lenau, Nikolaus", "birth": "N.A.", "death": "N.A."}, "title": "1L: Schade, da\u00df des Kreuzes Zeichen,", "genre": "verse", "period": "N.A.", "pub_year": 1838, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schade, da\u00df des Kreuzes Zeichen,", "tokens": ["Scha\u00b7de", ",", "da\u00df", "des", "Kreu\u00b7zes", "Zei\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das auf Golgatha gestanden", "tokens": ["Das", "auf", "Gol\u00b7ga\u00b7tha", "ge\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "APPR", "NE", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zur Erl\u00f6sung aus den Banden,", "tokens": ["Zur", "Er\u00b7l\u00f6\u00b7sung", "aus", "den", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun dem Zensor dient zum Streichen!", "tokens": ["Nun", "dem", "Zen\u00b7sor", "dient", "zum", "Strei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Das Symbol ward uns verkehrt,", "tokens": ["Das", "Sym\u00b7bol", "ward", "uns", "ver\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "H\u00f6hnend steht es da und lehrt,", "tokens": ["H\u00f6h\u00b7nend", "steht", "es", "da", "und", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir lange noch vom B\u00f6sen", "tokens": ["Da\u00df", "wir", "lan\u00b7ge", "noch", "vom", "B\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hoffen d\u00fcrfen kein Erl\u00f6sen.", "tokens": ["Hof\u00b7fen", "d\u00fcr\u00b7fen", "kein", "Er\u00b7l\u00f6\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}