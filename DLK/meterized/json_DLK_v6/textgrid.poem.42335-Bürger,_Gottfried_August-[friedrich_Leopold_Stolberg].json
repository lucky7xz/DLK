{"textgrid.poem.42335": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "[friedrich Leopold Stolberg]", "genre": "verse", "period": "N.A.", "pub_year": 1770, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nicht wei\u00df wie Milch und Blut, gepudert und frisiert,", "tokens": ["Nicht", "wei\u00df", "wie", "Milch", "und", "Blut", ",", "ge\u00b7pu\u00b7dert", "und", "fri\u00b7siert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "KOKOM", "NN", "KON", "NN", "$,", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mit dem reichsten Schmuck von Frankreich ausgeziert,", "tokens": ["Und", "mit", "dem", "reichs\u00b7ten", "Schmuck", "von", "Fran\u00b7kreich", "aus\u00b7ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nein, ruprigt, ledergelb und schmierig wie ein Schwein,", "tokens": ["Nein", ",", "ru\u00b7prigt", ",", "le\u00b7der\u00b7gelb", "und", "schmie\u00b7rig", "wie", "ein", "Schwein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Soll die, die ich mir einst zur Gattin w\u00e4hle, sein.", "tokens": ["Soll", "die", ",", "die", "ich", "mir", "einst", "zur", "Gat\u00b7tin", "w\u00e4h\u00b7le", ",", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "ART", "$,", "PRELS", "PPER", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Mich reizt kein braunes Haar, in Locken sanft gewunden,", "tokens": ["Mich", "reizt", "kein", "brau\u00b7nes", "Haar", ",", "in", "Lo\u00b7cken", "sanft", "ge\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$,", "APPR", "NN", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Worin sich mancher schon im Netz verstrickt, gefunden,", "tokens": ["Wo\u00b7rin", "sich", "man\u00b7cher", "schon", "im", "Netz", "ver\u00b7strickt", ",", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PRF", "PIS", "ADV", "APPRART", "NN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nein, str\u00e4ubig und mit Schorf, mit L\u00e4usen wohl geziert,", "tokens": ["Nein", ",", "str\u00e4u\u00b7big", "und", "mit", "Schorf", ",", "mit", "L\u00e4u\u00b7sen", "wohl", "ge\u00b7ziert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "KON", "APPR", "NE", "$,", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und blutrot sei ihr Haar, mit gelben Talg geschmiert.", "tokens": ["Und", "blut\u00b7rot", "sei", "ihr", "Haar", ",", "mit", "gel\u00b7ben", "Talg", "ge\u00b7schmiert", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nicht schalkhaft l\u00e4chelnde, nicht gro\u00dfe blaue Augen,", "tokens": ["Nicht", "schalk\u00b7haft", "l\u00e4\u00b7cheln\u00b7de", ",", "nicht", "gro\u00b7\u00dfe", "blau\u00b7e", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADJA", "$,", "PTKNEG", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gemacht der Liebe Geist aus ihnen einzusaugen,", "tokens": ["Ge\u00b7macht", "der", "Lie\u00b7be", "Geist", "aus", "ih\u00b7nen", "ein\u00b7zu\u00b7sau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "APPR", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nein, eitern m\u00fcssen sie, wie Drachenaugen gl\u00fchn,", "tokens": ["Nein", ",", "ei\u00b7tern", "m\u00fcs\u00b7sen", "sie", ",", "wie", "Dra\u00b7chen\u00b7au\u00b7gen", "gl\u00fchn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVINF", "VMFIN", "PPER", "$,", "PWAV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hoch am Tr\u00e4nenquell ein gelber Pettig bl\u00fchn.", "tokens": ["Und", "hoch", "am", "Tr\u00e4\u00b7nen\u00b7quell", "ein", "gel\u00b7ber", "Pet\u00b7tig", "bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Nicht griechisch, nicht antik, von Phideas gerissen", "tokens": ["Nicht", "grie\u00b7chisch", ",", "nicht", "an\u00b7tik", ",", "von", "Phi\u00b7de\u00b7as", "ge\u00b7ris\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "$,", "PTKNEG", "NN", "$,", "APPR", "NE", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nein, stumpf und unpoliert, schon faulend und beschissen,", "tokens": ["Nein", ",", "stumpf", "und", "un\u00b7po\u00b7liert", ",", "schon", "fau\u00b7lend", "und", "be\u00b7schis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "KON", "ADJD", "$,", "ADV", "ADJD", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Soll ihre Nase sein, mit Finnen \u00fcbers\u00e4et,", "tokens": ["Soll", "ih\u00b7re", "Na\u00b7se", "sein", ",", "mit", "Fin\u00b7nen", "\u00fc\u00b7bers\u00b7\u00e4et", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VAINF", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und stinkend wie die Pest in einem Lazarett.", "tokens": ["Und", "stin\u00b7kend", "wie", "die", "Pest", "in", "ei\u00b7nem", "La\u00b7za\u00b7rett", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ein langes Ohr, aus dem ein Strom von Unrat flie\u00dft,", "tokens": ["Ein", "lan\u00b7ges", "Ohr", ",", "aus", "dem", "ein", "Strom", "von", "Un\u00b7rat", "flie\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PRELS", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wie aus dem Vesuv die Lava sich ergie\u00dft,", "tokens": ["Und", "wie", "aus", "dem", "Ve\u00b7suv", "die", "La\u00b7va", "sich", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "ART", "NN", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ein leckeres Gemisch von Pettig, Blut und Salz,", "tokens": ["Ein", "le\u00b7cke\u00b7res", "Ge\u00b7misch", "von", "Pet\u00b7tig", ",", "Blut", "und", "Salz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mit Schwei\u00df und Grind vermischt und gelbem Ohrenschmalz.", "tokens": ["Mit", "Schwei\u00df", "und", "Grind", "ver\u00b7mischt", "und", "gel\u00b7bem", "Oh\u00b7ren\u00b7schmalz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ein schiefes Maul, verbaut mit platten Lippen,", "tokens": ["Ein", "schie\u00b7fes", "Maul", ",", "ver\u00b7baut", "mit", "plat\u00b7ten", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "An dessen Eingang her, zwei Reihen gro\u00dfer Klippen", "tokens": ["An", "des\u00b7sen", "Ein\u00b7gang", "her", ",", "zwei", "Rei\u00b7hen", "gro\u00b7\u00dfer", "Klip\u00b7pen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "PTKVZ", "$,", "CARD", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zwei Hauer, sowie dort des Herkul's S\u00e4ulen stehn,", "tokens": ["Zwei", "Hau\u00b7er", ",", "so\u00b7wie", "dort", "des", "Her\u00b7kul's", "S\u00e4u\u00b7len", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "KON", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da den H\u00f6llenpfuhl, hochprangend \u00fcbersehn.", "tokens": ["Und", "da", "den", "H\u00f6l\u00b7len\u00b7pfuhl", ",", "hoch\u00b7pran\u00b7gend", "\u00fc\u00b7ber\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Es kr\u00f6n' ein Hasenschart den Quell von faulen D\u00fcften,", "tokens": ["Es", "kr\u00f6n'", "ein", "Ha\u00b7sen\u00b7schart", "den", "Quell", "von", "fau\u00b7len", "D\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die alles um sich her verheeren und vergiften,", "tokens": ["Die", "al\u00b7les", "um", "sich", "her", "ver\u00b7hee\u00b7ren", "und", "ver\u00b7gif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PRF", "APZR", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der ohne Unterla\u00df in z\u00e4hen Geifer schwimmt,", "tokens": ["Der", "oh\u00b7ne", "Un\u00b7ter\u00b7la\u00df", "in", "z\u00e4\u00b7hen", "Gei\u00b7fer", "schwimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und durch den stets ein Rotz ins Maul den Eingang nimmt.", "tokens": ["Und", "durch", "den", "stets", "ein", "Rotz", "ins", "Maul", "den", "Ein\u00b7gang", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADV", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Es gleiche jeder Zahn verbrannten Palisaden,", "tokens": ["Es", "glei\u00b7che", "je\u00b7der", "Zahn", "ver\u00b7brann\u00b7ten", "Pa\u00b7li\u00b7sa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sei ein Aufenthalt der W\u00fcrmer und der Maden,", "tokens": ["Und", "sei", "ein", "Auf\u00b7ent\u00b7halt", "der", "W\u00fcr\u00b7mer", "und", "der", "Ma\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ganz hohl und kohlenschwarz in Scharbock eingeh\u00fcllt,", "tokens": ["Ganz", "hohl", "und", "koh\u00b7len\u00b7schwarz", "in", "Schar\u00b7bock", "ein\u00b7ge\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und mit verfaultem Fleisch und L\u00e4usen angef\u00fcllt.", "tokens": ["Und", "mit", "ver\u00b7faul\u00b7tem", "Fleisch", "und", "L\u00e4u\u00b7sen", "an\u00b7ge\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ein Hals, geschickt um die Anatomie zu lehren,", "tokens": ["Ein", "Hals", ",", "ge\u00b7schickt", "um", "die", "A\u00b7nat\u00b7o\u00b7mie", "zu", "leh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Kopf und eine Brust, die doch in allen Ehren,", "tokens": ["Ein", "Kopf", "und", "ei\u00b7ne", "Brust", ",", "die", "doch", "in", "al\u00b7len", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den zweien Zitzen gleicht, und schrumpfig hangend platt,", "tokens": ["Den", "zwei\u00b7en", "Zit\u00b7zen", "gleicht", ",", "und", "schrump\u00b7fig", "han\u00b7gend", "platt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "VVFIN", "$,", "KON", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An dieser sitzt der Krebs, wenn die den Fistel hat.", "tokens": ["An", "die\u00b7ser", "sitzt", "der", "Krebs", ",", "wenn", "die", "den", "Fis\u00b7tel", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ART", "NN", "$,", "KOUS", "ART", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Ein schlaffer Bauch geh\u00e4ngt auf zweien spitzen H\u00fcften,", "tokens": ["Ein", "schlaf\u00b7fer", "Bauch", "ge\u00b7h\u00e4ngt", "auf", "zwei\u00b7en", "spit\u00b7zen", "H\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Filzl\u00e4use weiden hier in unz\u00e4hlbaren Triften,", "tokens": ["Filz\u00b7l\u00e4u\u00b7se", "wei\u00b7den", "hier", "in", "un\u00b7z\u00e4hl\u00b7ba\u00b7ren", "Trif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr Puckel gleiche dem, von einem Elefant,", "tokens": ["Ihr", "Pu\u00b7ckel", "glei\u00b7che", "dem", ",", "von", "ei\u00b7nem", "E\u00b7le\u00b7fant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf welchem Rad und Pfahl, und Galgen eingebrannt.", "tokens": ["Auf", "wel\u00b7chem", "Rad", "und", "Pfahl", ",", "und", "Gal\u00b7gen", "ein\u00b7ge\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "$,", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Der Sitz des Schreckens sei die ungeheure Votze,", "tokens": ["Der", "Sitz", "des", "Schre\u00b7ckens", "sei", "die", "un\u00b7ge\u00b7heu\u00b7re", "Vot\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zerschrumpft und ohne Haar, verklebt mit gr\u00fcnem Rotze,", "tokens": ["Zer\u00b7schrumpft", "und", "oh\u00b7ne", "Haar", ",", "ver\u00b7klebt", "mit", "gr\u00fc\u00b7nem", "Rot\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "APPR", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An der seit Jahren schon manch kalter Bauer h\u00e4ngt,", "tokens": ["An", "der", "seit", "Jah\u00b7ren", "schon", "manch", "kal\u00b7ter", "Bau\u00b7er", "h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "NN", "ADV", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit Tripper, wei\u00dfem Flu\u00df und Schanker untermengt.", "tokens": ["Mit", "Trip\u00b7per", ",", "wei\u00b7\u00dfem", "Flu\u00df", "und", "Schan\u00b7ker", "un\u00b7ter\u00b7mengt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJA", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Stets mu\u00df ein dicker Schleim aus dieser Quelle tr\u00e4ufen,", "tokens": ["Stets", "mu\u00df", "ein", "di\u00b7cker", "Schleim", "aus", "die\u00b7ser", "Quel\u00b7le", "tr\u00e4u\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sich zu H\u00e4nden hoch an ihre \u00d6ffnung h\u00e4ufen,", "tokens": ["Und", "sich", "zu", "H\u00e4n\u00b7den", "hoch", "an", "ih\u00b7re", "\u00d6ff\u00b7nung", "h\u00e4u\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bis an den Lenden sich der Strom hin\u00fcbergie\u00dft,", "tokens": ["Bis", "an", "den", "Len\u00b7den", "sich", "der", "Strom", "hin\u00b7\u00fc\u00b7berg\u00b7ie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und halb mit tr\u00e4gern Lauf ins Arschloch \u00fcberflie\u00dft.", "tokens": ["Und", "halb", "mit", "tr\u00e4\u00b7gern", "Lauf", "ins", "A\u00b7rschloch", "\u00fc\u00b7berf\u00b7lie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Zwei eingebogne Knie mit krummen S\u00e4belbeinen,", "tokens": ["Zwei", "ein\u00b7ge\u00b7bog\u00b7ne", "Knie", "mit", "krum\u00b7men", "S\u00e4\u00b7bel\u00b7bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die wie ein r\u00f6misch X sich zu durchkreuzen scheinen,", "tokens": ["Die", "wie", "ein", "r\u00f6\u00b7misch", "X", "sich", "zu", "durch\u00b7kreu\u00b7zen", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "ADJD", "XY", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil das Ende sich zum Anfang reimen mu\u00df,", "tokens": ["Und", "weil", "das", "En\u00b7de", "sich", "zum", "An\u00b7fang", "rei\u00b7men", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Knochenfra\u00df am Bein, und den Verschwind am Fu\u00df.", "tokens": ["Den", "Kno\u00b7chen\u00b7fra\u00df", "am", "Bein", ",", "und", "den", "Ver\u00b7schwind", "am", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "KON", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "So soll die Gattin sein, die ich mir einst erw\u00e4hle,", "tokens": ["So", "soll", "die", "Gat\u00b7tin", "sein", ",", "die", "ich", "mir", "einst", "er\u00b7w\u00e4h\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VAINF", "$,", "PRELS", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "B\u00f6s, eigensinnig, falsch, von teuflerischer Seele,", "tokens": ["B\u00f6s", ",", "ei\u00b7gen\u00b7sin\u00b7nig", ",", "falsch", ",", "von", "teuf\u00b7le\u00b7ri\u00b7scher", "See\u00b7le", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dumm mu\u00df sie wie ein Rind, doch voller T\u00fccke sein.", "tokens": ["Dumm", "mu\u00df", "sie", "wie", "ein", "Rind", ",", "doch", "vol\u00b7ler", "T\u00fc\u00b7cke", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "KOKOM", "ART", "NN", "$,", "ADV", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zerlumpt und bettelarm, doch stets voll Branntewein.", "tokens": ["Zer\u00b7lumpt", "und", "bet\u00b7tel\u00b7arm", ",", "doch", "stets", "voll", "Brann\u00b7te\u00b7wein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "$,", "ADV", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Und soll sie vollends gar mein ganzes Herz besiegen,", "tokens": ["Und", "soll", "sie", "vol\u00b7lends", "gar", "mein", "gan\u00b7zes", "Herz", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mu\u00df sie die Schwerenot des Tages zehnmal kriegen,", "tokens": ["Mu\u00df", "sie", "die", "Schwe\u00b7re\u00b7not", "des", "Ta\u00b7ges", "zehn\u00b7mal", "krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit jedem Hurenwirt und jedem Tambur gehn,", "tokens": ["Mit", "je\u00b7dem", "Hu\u00b7ren\u00b7wirt", "und", "je\u00b7dem", "Tam\u00b7bur", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und immer oben an, auf ihrer Liste stehn.", "tokens": ["Und", "im\u00b7mer", "o\u00b7ben", "an", ",", "auf", "ih\u00b7rer", "Lis\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PTKVZ", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Werd ich dies Urbild einst, auf dieser Runde finden,", "tokens": ["Werd", "ich", "dies", "Ur\u00b7bild", "einst", ",", "auf", "die\u00b7ser", "Run\u00b7de", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "NN", "ADV", "$,", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dann werd ich und nicht eher, auf ewig mich verbinden,", "tokens": ["Dann", "werd", "ich", "und", "nicht", "e\u00b7her", ",", "auf", "e\u00b7wig", "mich", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "KON", "PTKNEG", "ADV", "$,", "APPR", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+--++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Alsdann darf ich mich nicht, noch f\u00fcrs Betr\u00fcgen scheun,", "tokens": ["Als\u00b7dann", "darf", "ich", "mich", "nicht", ",", "noch", "f\u00fcrs", "Be\u00b7tr\u00fc\u00b7gen", "scheun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "PTKNEG", "$,", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und werde gl\u00fccklicher als tausend M\u00e4nner sein.", "tokens": ["Und", "wer\u00b7de", "gl\u00fcck\u00b7li\u00b7cher", "als", "tau\u00b7send", "M\u00e4n\u00b7ner", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "KOKOM", "CARD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Sie tr\u00e4umten Engel sich, und fanden doch mit Schrecken,", "tokens": ["Sie", "tr\u00e4um\u00b7ten", "En\u00b7gel", "sich", ",", "und", "fan\u00b7den", "doch", "mit", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PRF", "$,", "KON", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie unter Engel sich auch Teufel oft verstecken,", "tokens": ["Wie", "un\u00b7ter", "En\u00b7gel", "sich", "auch", "Teu\u00b7fel", "oft", "ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NE", "PRF", "ADV", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ganz anders wird es mir mit dieser Gattin gehn,", "tokens": ["Ganz", "an\u00b7ders", "wird", "es", "mir", "mit", "die\u00b7ser", "Gat\u00b7tin", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PRF", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich tr\u00e4umte Teufel mir, und werde Engel sehn.", "tokens": ["Ich", "tr\u00e4um\u00b7te", "Teu\u00b7fel", "mir", ",", "und", "wer\u00b7de", "En\u00b7gel", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PPER", "$,", "KON", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}