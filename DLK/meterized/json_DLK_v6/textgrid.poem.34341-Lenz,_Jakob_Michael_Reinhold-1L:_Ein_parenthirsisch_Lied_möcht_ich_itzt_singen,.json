{"textgrid.poem.34341": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein parenthirsisch Lied m\u00f6cht ich itzt singen,", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein parenthirsisch Lied m\u00f6cht ich itzt singen,", "tokens": ["Ein", "pa\u00b7ren\u00b7thir\u00b7sisch", "Lied", "m\u00f6cht", "ich", "itzt", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein m\u00e4chtig, ein allm\u00e4chtig Lied,", "tokens": ["Ein", "m\u00e4ch\u00b7tig", ",", "ein", "all\u00b7m\u00e4ch\u00b7tig", "Lied", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Sonn und Mond vom Himmel zieht", "tokens": ["Das", "Sonn", "und", "Mond", "vom", "Him\u00b7mel", "zieht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dem die Stern' entgegen springen.", "tokens": ["Und", "dem", "die", "Stern'", "ent\u00b7ge\u00b7gen", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hoch zum Olymp m\u00f6cht ich mit federlosen Schwingen,", "tokens": ["Hoch", "zum", "O\u00b7lymp", "m\u00f6cht", "ich", "mit", "fe\u00b7der\u00b7lo\u00b7sen", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VMFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "----+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein deutscher Ikar, dringen:", "tokens": ["Ein", "deut\u00b7scher", "I\u00b7kar", ",", "drin\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Allein das Wetter ist zu rauh", "tokens": ["Al\u00b7lein", "das", "Wet\u00b7ter", "ist", "zu", "rauh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und meine Muse, eine Frau,", "tokens": ["Und", "mei\u00b7ne", "Mu\u00b7se", ",", "ei\u00b7ne", "Frau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Erfr\u00f6re dr\u00fcber braun und blau.", "tokens": ["Er\u00b7fr\u00f6\u00b7re", "dr\u00fc\u00b7ber", "braun", "und", "blau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Baroc soll meine Leyer klingen,", "tokens": ["Ba\u00b7roc", "soll", "mei\u00b7ne", "Le\u00b7yer", "klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Flugs reimen will ich, das hei\u00dft singen,", "tokens": ["Flugs", "rei\u00b7men", "will", "ich", ",", "das", "hei\u00dft", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "PPER", "$,", "PDS", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Flugs reimen, so wie der und der;", "tokens": ["Flugs", "rei\u00b7men", ",", "so", "wie", "der", "und", "der", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "ADV", "KOKOM", "ART", "KON", "ART", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Das hebt bis an den gro\u00dfen B\u00e4r", "tokens": ["Das", "hebt", "bis", "an", "den", "gro\u00b7\u00dfen", "B\u00e4r"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Einst unsern Ruhm \u2013 und ist nicht schwer.", "tokens": ["Einst", "un\u00b7sern", "Ruhm", "\u2013", "und", "ist", "nicht", "schwer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$(", "KON", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ich der von allen guten Dingen", "tokens": ["Ich", "der", "von", "al\u00b7len", "gu\u00b7ten", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "In meinem Leben dreymal schied,", "tokens": ["In", "mei\u00b7nem", "Le\u00b7ben", "drey\u00b7mal", "schied", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Dem ehmals leichter als Ovid", "tokens": ["Dem", "eh\u00b7mals", "leich\u00b7ter", "als", "O\u00b7vid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADJD", "KOKOM", "NE"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.18": {"text": "Die Klagen von der Leber giengen,", "tokens": ["Die", "Kla\u00b7gen", "von", "der", "Le\u00b7ber", "gien\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Mir wird doch ein gereimtes Lied", "tokens": ["Mir", "wird", "doch", "ein", "ge\u00b7reim\u00b7tes", "Lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "So gut als dem und dem gelingen.", "tokens": ["So", "gut", "als", "dem", "und", "dem", "ge\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "KON", "ART", "VVINF", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.21": {"text": "Fortuna! G\u00f6ttin! gro\u00dfer Name!", "tokens": ["For\u00b7tu\u00b7na", "!", "G\u00f6t\u00b7tin", "!", "gro\u00b7\u00dfer", "Na\u00b7me", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Leichtfertige, vertrackte Dame,", "tokens": ["Leicht\u00b7fer\u00b7ti\u00b7ge", ",", "ver\u00b7track\u00b7te", "Da\u00b7me", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Die oft die liebsten Buhler h\u00f6rnt,", "tokens": ["Die", "oft", "die", "liebs\u00b7ten", "Buh\u00b7ler", "h\u00f6rnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Von der durch dick und d\u00fcnn zu schwimmen,", "tokens": ["Von", "der", "durch", "dick", "und", "d\u00fcnn", "zu", "schwim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Die Sayten hoch und tief zu stimmen", "tokens": ["Die", "Say\u00b7ten", "hoch", "und", "tief", "zu", "stim\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "So mancher Dichter schon gelernt.", "tokens": ["So", "man\u00b7cher", "Dich\u00b7ter", "schon", "ge\u00b7lernt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "O glaube nicht, vom Guten oder Schlimmen", "tokens": ["O", "glau\u00b7be", "nicht", ",", "vom", "Gu\u00b7ten", "o\u00b7der", "Schlim\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG", "$,", "APPRART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Wovon mich auch dein Arm entfernt,", "tokens": ["Wo\u00b7von", "mich", "auch", "dein", "Arm", "ent\u00b7fernt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Ich werde mich darunter kr\u00fcmmen.", "tokens": ["Ich", "wer\u00b7de", "mich", "da\u00b7run\u00b7ter", "kr\u00fcm\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Nein lachen, das hab ich gelernt,", "tokens": ["Nein", "la\u00b7chen", ",", "das", "hab", "ich", "ge\u00b7lernt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVINF", "$,", "PDS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.31": {"text": "Gelernt dir lachend ins Gesicht", "tokens": ["Ge\u00b7lernt", "dir", "la\u00b7chend", "ins", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Zu ruffen: ", "tokens": ["Zu", "ruf\u00b7fen", ":"], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.33": {"text": "Nur eine kleine Sorge zieht", "tokens": ["Nur", "ei\u00b7ne", "klei\u00b7ne", "Sor\u00b7ge", "zieht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Wie Mittagsw\u00f6lkchen im Gem\u00fcth.", "tokens": ["Wie", "Mit\u00b7tags\u00b7w\u00f6lk\u00b7chen", "im", "Ge\u00b7m\u00fcth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Ich w\u00fcrde mich auch am Cocyth,", "tokens": ["Ich", "w\u00fcr\u00b7de", "mich", "auch", "am", "Co\u00b7cy\u00b7th", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.36": {"text": "Denk ich, mit Vater Orpheus fa\u00dfen.", "tokens": ["Denk", "ich", ",", "mit", "Va\u00b7ter", "Or\u00b7pheus", "fa\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "APPR", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Ich w\u00fcrde selber in den Ga\u00dfen", "tokens": ["Ich", "w\u00fcr\u00b7de", "sel\u00b7ber", "in", "den", "Ga\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Der Residenz des Pluto nicht", "tokens": ["Der", "Re\u00b7si\u00b7denz", "des", "Plu\u00b7to", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Mit traurigen hogarthischen Grima\u00dfen", "tokens": ["Mit", "trau\u00b7ri\u00b7gen", "ho\u00b7gar\u00b7thi\u00b7schen", "Gri\u00b7ma\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+--+-+-++-", "measure": "iambic.penta.relaxed"}, "line.40": {"text": "Bei seiner Fackeln dunklem Licht", "tokens": ["Bei", "sei\u00b7ner", "Fa\u00b7ckeln", "dunk\u00b7lem", "Licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Versteinert stehn, und wie ein Weib erbla\u00dfen:", "tokens": ["Ver\u00b7stei\u00b7nert", "stehn", ",", "und", "wie", "ein", "Weib", "er\u00b7bla\u00b7\u00dfen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVINF", "$,", "KON", "PWAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.42": {"text": "Nein Pluto lie\u00df ich Pluto seyn,", "tokens": ["Nein", "Plu\u00b7to", "lie\u00df", "ich", "Plu\u00b7to", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NE", "VVFIN", "PPER", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Und leyerte wie Orpheus fein", "tokens": ["Und", "ley\u00b7er\u00b7te", "wie", "Or\u00b7pheus", "fein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "NE", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Mich in den Tartarus hinein \u2013", "tokens": ["Mich", "in", "den", "Tar\u00b7ta\u00b7rus", "hin\u00b7ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "Doch \u2013 Freunde, Freunde zu verla\u00dfen,", "tokens": ["Doch", "\u2013", "Freun\u00b7de", ",", "Freun\u00b7de", "zu", "ver\u00b7la\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$(", "NN", "$,", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Dazu war stets mein Muth zu klein.", "tokens": ["Da\u00b7zu", "war", "stets", "mein", "Muth", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "PPOSAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Der Menschenfeind, die Last der Erde,", "tokens": ["Der", "Men\u00b7schen\u00b7feind", ",", "die", "Last", "der", "Er\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Aus Hochmut, oder auch aus Groll", "tokens": ["Aus", "Hoch\u00b7mut", ",", "o\u00b7der", "auch", "aus", "Groll"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "KON", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Zu weise \u2013 oder auch zu toll,", "tokens": ["Zu", "wei\u00b7se", "\u2013", "o\u00b7der", "auch", "zu", "toll", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$(", "KON", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Der werd ein Eremit \u2013 er werde!", "tokens": ["Der", "werd", "ein", "E\u00b7re\u00b7mit", "\u2013", "er", "wer\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$(", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "Ich lobe mir mit seinen M\u00e4ngeln", "tokens": ["Ich", "lo\u00b7be", "mir", "mit", "sei\u00b7nen", "M\u00e4n\u00b7geln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.52": {"text": "Das Mittelding von Vieh und Engeln,", "tokens": ["Das", "Mit\u00b7tel\u00b7ding", "von", "Vieh", "und", "En\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "Herrn Plato ungefiedert Thier.", "tokens": ["Herrn", "Pla\u00b7to", "un\u00b7ge\u00b7fie\u00b7dert", "Thier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "Das sieht mir gleich, das lob ich mir.", "tokens": ["Das", "sieht", "mir", "gleich", ",", "das", "lob", "ich", "mir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "Ein andrer suche sich zu engeln,", "tokens": ["Ein", "an\u00b7drer", "su\u00b7che", "sich", "zu", "en\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Er werd ein Eremit, er zieh", "tokens": ["Er", "werd", "ein", "E\u00b7re\u00b7mit", ",", "er", "zieh"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.57": {"text": "Sich hin und her mit blo\u00dfem Knie", "tokens": ["Sich", "hin", "und", "her", "mit", "blo\u00b7\u00dfem", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "PTKVZ", "KON", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Auf Erbsen oder Ne\u00dfelstengeln.", "tokens": ["Auf", "Erb\u00b7sen", "o\u00b7der", "Ne\u00b7\u00df\u00b7els\u00b7ten\u00b7geln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "O wi\u00dfet, er verliert doch nie", "tokens": ["O", "wi\u00b7\u00dfet", ",", "er", "ver\u00b7liert", "doch", "nie"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Mit Plato federlosem Vieh", "tokens": ["Mit", "Pla\u00b7to", "fe\u00b7der\u00b7lo\u00b7sem", "Vieh"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Die angeborne Sympathie.", "tokens": ["Die", "an\u00b7ge\u00b7bor\u00b7ne", "Sym\u00b7pa\u00b7thie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "In Stille l\u00e4\u00dft er seinem Magen", "tokens": ["In", "Stil\u00b7le", "l\u00e4\u00dft", "er", "sei\u00b7nem", "Ma\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.63": {"text": "Geschenkte Speisen wohl behagen", "tokens": ["Ge\u00b7schenk\u00b7te", "Spei\u00b7sen", "wohl", "be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "Und seinem Schlund geschenkten Wein.", "tokens": ["Und", "sei\u00b7nem", "Schlund", "ge\u00b7schenk\u00b7ten", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "La\u00dft mit Agnesen ihn allein:", "tokens": ["La\u00dft", "mit", "Ag\u00b7ne\u00b7sen", "ihn", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "NE", "PPER", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.66": {"text": "Was wird sein \u2013 ja wie geb ichs fein?", "tokens": ["Was", "wird", "sein", "\u2013", "ja", "wie", "geb", "ichs", "fein", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "$(", "ADV", "KOKOM", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Was wird sein alter Adam sagen?", "tokens": ["Was", "wird", "sein", "al\u00b7ter", "A\u00b7dam", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "Ihr d\u00fcrft nur den Fontaine fragen.", "tokens": ["Ihr", "d\u00fcrft", "nur", "den", "Fon\u00b7tai\u00b7ne", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "Nein, Menschen, Menschen spat und fr\u00fch", "tokens": ["Nein", ",", "Men\u00b7schen", ",", "Men\u00b7schen", "spat", "und", "fr\u00fch"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "NN", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Von meiner Farbe, meinen Mienen,", "tokens": ["Von", "mei\u00b7ner", "Far\u00b7be", ",", "mei\u00b7nen", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.71": {"text": "Von meiner Physiognomie,", "tokens": ["Von", "mei\u00b7ner", "Phy\u00b7si\u00b7og\u00b7no\u00b7mie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "Die will ich um mich haben, ihnen", "tokens": ["Die", "will", "ich", "um", "mich", "ha\u00b7ben", ",", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VMFIN", "PPER", "APPR", "PPER", "VAFIN", "$,", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "Mit allen meinen Kr\u00e4ften dienen;", "tokens": ["Mit", "al\u00b7len", "mei\u00b7nen", "Kr\u00e4f\u00b7ten", "die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.74": {"text": "Sie dulden mich, ich dulde sie.", "tokens": ["Sie", "dul\u00b7den", "mich", ",", "ich", "dul\u00b7de", "sie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Ihr, die ihr ohne mich zu kennen,", "tokens": ["Ihr", ",", "die", "ihr", "oh\u00b7ne", "mich", "zu", "ken\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.76": {"text": "Mich w\u00fcrdigt Euren Freund zu nennen,", "tokens": ["Mich", "w\u00fcr\u00b7digt", "Eu\u00b7ren", "Freund", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.77": {"text": "Ist Eure Wahl auch lobesan?", "tokens": ["Ist", "Eu\u00b7re", "Wahl", "auch", "lo\u00b7be\u00b7san", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Gut ist mein Herz, schwach meine Kenntni\u00df,", "tokens": ["Gut", "ist", "mein", "Herz", ",", "schwach", "mei\u00b7ne", "Kennt\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.79": {"text": "Ich thu euch ehrlich ein Gest\u00e4ndni\u00df,", "tokens": ["Ich", "thu", "euch", "ehr\u00b7lich", "ein", "Ge\u00b7st\u00e4nd\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.80": {"text": "Das nie ein Deutscher noch gethan.", "tokens": ["Das", "nie", "ein", "Deut\u00b7scher", "noch", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.81": {"text": "Ihr habt und werdet dulden m\u00fc\u00dfen,", "tokens": ["Ihr", "habt", "und", "wer\u00b7det", "dul\u00b7den", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "VAFIN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.82": {"text": "Die Freundschaft ist Gutherzigkeit;", "tokens": ["Die", "Freund\u00b7schaft", "ist", "Gu\u00b7ther\u00b7zig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.83": {"text": "Sie wirft dem Nackenden ein Kleid,", "tokens": ["Sie", "wirft", "dem", "Na\u00b7cken\u00b7den", "ein", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.84": {"text": "Gef\u00e4llt er ihr, auch allenfalls", "tokens": ["Ge\u00b7f\u00e4llt", "er", "ihr", ",", "auch", "al\u00b7len\u00b7falls"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.85": {"text": "Ein Dutzend Kleider an den Hals:", "tokens": ["Ein", "Dut\u00b7zend", "Klei\u00b7der", "an", "den", "Hals", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.86": {"text": "Sie tr\u00fcgt sich gern in ihren Schl\u00fc\u00dfen.", "tokens": ["Sie", "tr\u00fcgt", "sich", "gern", "in", "ih\u00b7ren", "Schl\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.87": {"text": "Nennt unser eingeschr\u00e4nktes Wi\u00dfen", "tokens": ["Nennt", "un\u00b7ser", "ein\u00b7ge\u00b7schr\u00e4nk\u00b7tes", "Wi\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "Zu vorschnell oft Gelehrsamkeit,", "tokens": ["Zu", "vor\u00b7schnell", "oft", "Ge\u00b7lehr\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.89": {"text": "Und unser ehrliches Gewi\u00dfen", "tokens": ["Und", "un\u00b7ser", "ehr\u00b7li\u00b7ches", "Ge\u00b7wi\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.90": {"text": "Das nennet sie Bescheidenheit.", "tokens": ["Das", "nen\u00b7net", "sie", "Be\u00b7schei\u00b7den\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.91": {"text": "Ich f\u00fchle mich und bitte sch\u00fcchtern", "tokens": ["Ich", "f\u00fch\u00b7le", "mich", "und", "bit\u00b7te", "sch\u00fcch\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.92": {"text": "Auch noch entfernt um Eure Gunst.", "tokens": ["Auch", "noch", "ent\u00b7fernt", "um", "Eu\u00b7re", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "Ich las euch etwas von der Kunst", "tokens": ["Ich", "las", "euch", "et\u00b7was", "von", "der", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "Und vom Genie und von den Dichtern.", "tokens": ["Und", "vom", "Ge\u00b7nie", "und", "von", "den", "Dich\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.95": {"text": "Ich folgte nicht den Mode Richtern", "tokens": ["Ich", "folg\u00b7te", "nicht", "den", "Mo\u00b7de", "Rich\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.96": {"text": "Mit Wohlgelahrten Angesichtern,", "tokens": ["Mit", "Wohl\u00b7ge\u00b7lahr\u00b7ten", "An\u00b7ge\u00b7sich\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.97": {"text": "Von Dunst berauscht, von Wahrheit n\u00fcchtern.", "tokens": ["Von", "Dunst", "be\u00b7rauscht", ",", "von", "Wahr\u00b7heit", "n\u00fcch\u00b7tern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.98": {"text": "Sie lieben ihren blauen Dunst", "tokens": ["Sie", "lie\u00b7ben", "ih\u00b7ren", "blau\u00b7en", "Dunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.99": {"text": "Doch uns, die frey zu f\u00fchlen wagen,", "tokens": ["Doch", "uns", ",", "die", "frey", "zu", "f\u00fch\u00b7len", "wa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PRELS", "ADJD", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.100": {"text": "Und was sie f\u00fchlen, auch frey sagen,", "tokens": ["Und", "was", "sie", "f\u00fch\u00b7len", ",", "auch", "frey", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.101": {"text": "Gef\u00e4llt die Frau Mama Natur", "tokens": ["Ge\u00b7f\u00e4llt", "die", "Frau", "Ma\u00b7ma", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "In ihrer ", "tokens": ["In", "ih\u00b7rer"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.103": {"text": "Es bl\u00fcht und gl\u00e4nzt auf ihrer Spur", "tokens": ["Es", "bl\u00fcht", "und", "gl\u00e4nzt", "auf", "ih\u00b7rer", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "Von Blumen eine ganze Flur,", "tokens": ["Von", "Blu\u00b7men", "ei\u00b7ne", "gan\u00b7ze", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.105": {"text": "Und tausend holde Stimmen klagen", "tokens": ["Und", "tau\u00b7send", "hol\u00b7de", "Stim\u00b7men", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.106": {"text": "Und scherzen auf einmahl, wenn sie den G\u00f6ttermund", "tokens": ["Und", "scher\u00b7zen", "auf", "ein\u00b7mahl", ",", "wenn", "sie", "den", "G\u00f6t\u00b7ter\u00b7mund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Er\u00f6fnet: unser Herz wird wund,", "tokens": ["Er\u00b7\u00f6f\u00b7net", ":", "un\u00b7ser", "Herz", "wird", "wund", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.108": {"text": "Und unser Puls f\u00e4ngt anders an zu schlagen.", "tokens": ["Und", "un\u00b7ser", "Puls", "f\u00e4ngt", "an\u00b7ders", "an", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.109": {"text": "Schrieb ich vielleicht mir nicht zum Ruhme,", "tokens": ["Schrieb", "ich", "viel\u00b7leicht", "mir", "nicht", "zum", "Ruh\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PPER", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.110": {"text": "So denkt sein Schicksal traf ihn hart:", "tokens": ["So", "denkt", "sein", "Schick\u00b7sal", "traf", "ihn", "hart", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.111": {"text": "Er bl\u00fchte noch, als seine Blume", "tokens": ["Er", "bl\u00fch\u00b7te", "noch", ",", "als", "sei\u00b7ne", "Blu\u00b7me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.112": {"text": "Von einem Blitz getroffen ward.", "tokens": ["Von", "ei\u00b7nem", "Blitz", "ge\u00b7trof\u00b7fen", "ward", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.113": {"text": "Sie senkte tief die bla\u00dfen Wangen", "tokens": ["Sie", "senk\u00b7te", "tief", "die", "bla\u00b7\u00dfen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.114": {"text": "Und Himmelstropfen haben sich", "tokens": ["Und", "Him\u00b7mel\u00b7strop\u00b7fen", "ha\u00b7ben", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.115": {"text": "Seither den Bl\u00e4ttern angehangen,", "tokens": ["Sei\u00b7ther", "den", "Bl\u00e4t\u00b7tern", "an\u00b7ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.116": {"text": "Das denkt \u2013 und dann bedauert mich.", "tokens": ["Das", "denkt", "\u2013", "und", "dann", "be\u00b7dau\u00b7ert", "mich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "KON", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Ich kann aufs h\u00f6chste doch nur l\u00e4cheln,", "tokens": ["Ich", "kann", "aufs", "h\u00f6chs\u00b7te", "doch", "nur", "l\u00e4\u00b7cheln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "ADJA", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.118": {"text": "Mit tr\u00fcben Augen nur mich freun.", "tokens": ["Mit", "tr\u00fc\u00b7ben", "Au\u00b7gen", "nur", "mich", "freun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.119": {"text": "Mein Athem klagt, mein letztes R\u00f6cheln", "tokens": ["Mein", "A\u00b7them", "klagt", ",", "mein", "letz\u00b7tes", "R\u00f6\u00b7cheln"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.120": {"text": "Wird auch noch eine Klage seyn.", "tokens": ["Wird", "auch", "noch", "ei\u00b7ne", "Kla\u00b7ge", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.121": {"text": "Wem unter J\u00fcnglingen und Sch\u00f6nen", "tokens": ["Wem", "un\u00b7ter", "J\u00fcng\u00b7lin\u00b7gen", "und", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "KON", "NN"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.122": {"text": "Ich ohne meine Schuld mi\u00dffiel,", "tokens": ["Ich", "oh\u00b7ne", "mei\u00b7ne", "Schuld", "mi\u00df\u00b7fiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.123": {"text": "Der denk': Er spielt die letzten Scenen", "tokens": ["Der", "denk'", ":", "Er", "spielt", "die", "letz\u00b7ten", "Sce\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.124": {"text": "Von einem fr\u00fchen Trauerspiel.", "tokens": ["Von", "ei\u00b7nem", "fr\u00fc\u00b7hen", "Trau\u00b7er\u00b7spiel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.125": {"text": "Doch warum klag ich? sind die Rollen,", "tokens": ["Doch", "wa\u00b7rum", "klag", "ich", "?", "sind", "die", "Rol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "$.", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.126": {"text": "Die andre spielen, neidenswerth", "tokens": ["Die", "and\u00b7re", "spie\u00b7len", ",", "nei\u00b7dens\u00b7werth"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "PIS", "VVINF", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.127": {"text": "Das Gl\u00fccke, das wir suchen sollen,", "tokens": ["Das", "Gl\u00fc\u00b7cke", ",", "das", "wir", "su\u00b7chen", "sol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.128": {"text": "Wird auf dem Schauplatz nicht gew\u00e4hrt.", "tokens": ["Wird", "auf", "dem", "Schau\u00b7platz", "nicht", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.129": {"text": "Und selber auf dem Schauplatz weinen", "tokens": ["Und", "sel\u00b7ber", "auf", "dem", "Schau\u00b7platz", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.130": {"text": "Ist edler, als wie Arlekin", "tokens": ["Ist", "ed\u00b7ler", ",", "als", "wie", "Ar\u00b7le\u00b7kin"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADJA", "$,", "KOUS", "KOKOM", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.131": {"text": "Im bunten W\u00e4mmschen zu erscheinen:", "tokens": ["Im", "bun\u00b7ten", "W\u00e4mm\u00b7schen", "zu", "er\u00b7schei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.132": {"text": "Er lacht \u2013 und man belachet ihn.", "tokens": ["Er", "lacht", "\u2013", "und", "man", "be\u00b7la\u00b7chet", "ihn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KON", "PIS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.133": {"text": "Ich merk, ich werde zu geschw\u00e4tzig;", "tokens": ["Ich", "merk", ",", "ich", "wer\u00b7de", "zu", "ge\u00b7schw\u00e4t\u00b7zig", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.134": {"text": "Auch dieses werdt ihr mir verzeyhn.", "tokens": ["Auch", "die\u00b7ses", "werdt", "ihr", "mir", "ver\u00b7zeyhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.135": {"text": "Mein gro\u00dfes Lied wird unters\u00e4tzig,", "tokens": ["Mein", "gro\u00b7\u00dfes", "Lied", "wird", "un\u00b7ter\u00b7s\u00e4t\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.136": {"text": "Es wird zu breit und bleibt doch klein.", "tokens": ["Es", "wird", "zu", "breit", "und", "bleibt", "doch", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.137": {"text": "Das ist mein Loo\u00df. Den Wuchs vom Manne", "tokens": ["Das", "ist", "mein", "Loo\u00df", ".", "Den", "Wuchs", "vom", "Man\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$.", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.138": {"text": "Versagte mir bisher das Gl\u00fcck,", "tokens": ["Ver\u00b7sag\u00b7te", "mir", "bis\u00b7her", "das", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.139": {"text": "Und nahm ich zu um eine Spanne,", "tokens": ["Und", "nahm", "ich", "zu", "um", "ei\u00b7ne", "Span\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.140": {"text": "So blieb ich klein \u2013 und wurde dick.", "tokens": ["So", "blieb", "ich", "klein", "\u2013", "und", "wur\u00b7de", "dick", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$(", "KON", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.141": {"text": "Obschon aus Leichtsinn und aus Wehmuth", "tokens": ["Ob\u00b7schon", "aus", "Leicht\u00b7sinn", "und", "aus", "Weh\u00b7muth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.142": {"text": "Mama Natur mein Wesen schmolz,", "tokens": ["Ma\u00b7ma", "Na\u00b7tur", "mein", "We\u00b7sen", "schmolz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.143": {"text": "So hab ich doch bey aller Demuth", "tokens": ["So", "hab", "ich", "doch", "bey", "al\u00b7ler", "De\u00b7muth"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.144": {"text": "Ich mu\u00df es euch gestehn, noch einen seltnen Stolz.", "tokens": ["Ich", "mu\u00df", "es", "euch", "ge\u00b7stehn", ",", "noch", "ei\u00b7nen", "selt\u00b7nen", "Stolz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPER", "VVPP", "$,", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Nun rathet \u2013 mags Oedipus rathen.", "tokens": ["Nun", "ra\u00b7thet", "\u2013", "mags", "O\u00b7e\u00b7di\u00b7pus", "ra\u00b7then", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "VMFIN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.146": {"text": "Ich bin nicht stolz auf Heldenthaten", "tokens": ["Ich", "bin", "nicht", "stolz", "auf", "Hel\u00b7den\u00b7tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.147": {"text": "Und auf Gelehrsamkeit \u2013 das w\u00e4r ein feiner Scherz!", "tokens": ["Und", "auf", "Ge\u00b7lehr\u00b7sam\u00b7keit", "\u2013", "das", "w\u00e4r", "ein", "fei\u00b7ner", "Scherz", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$(", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Von einer Nation, die an dem ", "tokens": ["Von", "ei\u00b7ner", "Na\u00b7tion", ",", "die", "an", "dem"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "APPR", "ART"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.149": {"text": "Wenns lange w\u00e4hrt, wird bersten m\u00fc\u00dfen,", "tokens": ["Wenns", "lan\u00b7ge", "w\u00e4hrt", ",", "wird", "bers\u00b7ten", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "$,", "VAFIN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.150": {"text": "Was meynt ihr wohl, wie viel ein stolzer Mann", "tokens": ["Was", "meynt", "ihr", "wohl", ",", "wie", "viel", "ein", "stol\u00b7zer", "Mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "PWAV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.151": {"text": "Da wi\u00dfen mu\u00df, bevor er bersten kann?", "tokens": ["Da", "wi\u00b7\u00dfen", "mu\u00df", ",", "be\u00b7vor", "er", "bers\u00b7ten", "kann", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.152": {"text": "Stolz bin ich auch nicht auf mein Herz,", "tokens": ["Stolz", "bin", "ich", "auch", "nicht", "auf", "mein", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.153": {"text": "Zufrieden bin ich wohl, allein sein tiefster Schmerz", "tokens": ["Zu\u00b7frie\u00b7den", "bin", "ich", "wohl", ",", "al\u00b7lein", "sein", "tiefs\u00b7ter", "Schmerz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADV", "$,", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Macht mich zuweilen stumm und sauer", "tokens": ["Macht", "mich", "zu\u00b7wei\u00b7len", "stumm", "und", "sau\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.155": {"text": "Und unumg\u00e4nglich wie den Bauer:", "tokens": ["Und", "un\u00b7um\u00b7g\u00e4ng\u00b7lich", "wie", "den", "Bau\u00b7er", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.156": {"text": "Stolz bin ich \u2013 auf den zehnten Merz.", "tokens": ["Stolz", "bin", "ich", "\u2013", "auf", "den", "zehn\u00b7ten", "Merz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$(", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.157": {"text": "Mit diesem Tag, ihr lieben Christen,", "tokens": ["Mit", "die\u00b7sem", "Tag", ",", "ihr", "lie\u00b7ben", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.158": {"text": "Darf ich mich doch wohlweidlich br\u00fcsten.", "tokens": ["Darf", "ich", "mich", "doch", "wohl\u00b7weid\u00b7lich", "br\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.159": {"text": "Er ist, da\u00df ich so sagen mag,", "tokens": ["Er", "ist", ",", "da\u00df", "ich", "so", "sa\u00b7gen", "mag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.160": {"text": "(vergebt es mir!) Mein Namenstag.", "tokens": ["(", "ver\u00b7gebt", "es", "mir", "!", ")", "Mein", "Na\u00b7mens\u00b7tag", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PPER", "$.", "$(", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.161": {"text": "Schon bey der Fibel und beym Donat", "tokens": ["Schon", "bey", "der", "Fi\u00b7bel", "und", "beym", "Do\u00b7nat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "KON", "APPRART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.162": {"text": "Erg\u00f6tzt' ich mich an diesem Monath,", "tokens": ["Er\u00b7g\u00f6tzt'", "ich", "mich", "an", "die\u00b7sem", "Mo\u00b7nath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.163": {"text": "In den in unsre liebe Welt", "tokens": ["In", "den", "in", "uns\u00b7re", "lie\u00b7be", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.164": {"text": "Der rosenrothe Fr\u00fchling f\u00e4llt.", "tokens": ["Der", "ro\u00b7sen\u00b7ro\u00b7the", "Fr\u00fch\u00b7ling", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.165": {"text": "Der Merz ist k\u00fchl, doch ist er freundlich,", "tokens": ["Der", "Merz", "ist", "k\u00fchl", ",", "doch", "ist", "er", "freund\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.166": {"text": "Von Winden rauh, doch niemals feindlich,", "tokens": ["Von", "Win\u00b7den", "rauh", ",", "doch", "nie\u00b7mals", "feind\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.167": {"text": "Sie fahren, wenn ich recht davon berichtet bin,", "tokens": ["Sie", "fah\u00b7ren", ",", "wenn", "ich", "recht", "da\u00b7von", "be\u00b7rich\u00b7tet", "bin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "PAV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Am Himmel reinigend, am Boden schmeichelnd hin.", "tokens": ["Am", "Him\u00b7mel", "rei\u00b7ni\u00b7gend", ",", "am", "Bo\u00b7den", "schmei\u00b7chelnd", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "APPRART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Die jungen Knospen zu erquicken", "tokens": ["Die", "jun\u00b7gen", "Knos\u00b7pen", "zu", "er\u00b7qui\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.170": {"text": "L\u00e4\u00dft sich bisweilen auch die Sonn entw\u00f6lket blicken", "tokens": ["L\u00e4\u00dft", "sich", "bis\u00b7wei\u00b7len", "auch", "die", "Sonn", "ent\u00b7w\u00f6l\u00b7ket", "bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "ART", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Mit einem sch\u00f6nen Eigensinn.", "tokens": ["Mit", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Ei\u00b7gen\u00b7sinn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.172": {"text": "Was dieses Gleichni\u00df hier bedeute,", "tokens": ["Was", "die\u00b7ses", "Gleich\u00b7ni\u00df", "hier", "be\u00b7deu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.173": {"text": "Das rathet auf \u2013 das rathet auf!", "tokens": ["Das", "ra\u00b7thet", "auf", "\u2013", "das", "ra\u00b7thet", "auf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "$(", "PDS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.174": {"text": "Kurz unter uns, ihr lieben Leute,", "tokens": ["Kurz", "un\u00b7ter", "uns", ",", "ihr", "lie\u00b7ben", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.175": {"text": "So wie der Merz, so bis auf heute", "tokens": ["So", "wie", "der", "Merz", ",", "so", "bis", "auf", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "NN", "$,", "ADV", "ADV", "APPR", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.176": {"text": "War auch mein kleiner Lebenslauf.", "tokens": ["War", "auch", "mein", "klei\u00b7ner", "Le\u00b7bens\u00b7lauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}