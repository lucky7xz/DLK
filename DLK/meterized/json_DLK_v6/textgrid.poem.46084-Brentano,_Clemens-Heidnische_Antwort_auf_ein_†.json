{"textgrid.poem.46084": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Heidnische Antwort auf ein \u2020", "genre": "verse", "period": "N.A.", "pub_year": 1835, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nimm f\u00fcr dein \u2020 im Brief, den dir zu Lieb'", "tokens": ["Nimm", "f\u00fcr", "dein", "\u2020", "im", "Brief", ",", "den", "dir", "zu", "Lieb'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "APPR", "PPOSAT", "$(", "APPRART", "NN", "$,", "PRELS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er, der zum Tod dich liebt, mir j\u00fcngst geschrieben,", "tokens": ["Er", ",", "der", "zum", "Tod", "dich", "liebt", ",", "mir", "j\u00fcngst", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPRART", "NN", "PPER", "VVFIN", "$,", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Dichterliebe Bild, das mir noch blieb", "tokens": ["Der", "Dich\u00b7ter\u00b7lie\u00b7be", "Bild", ",", "das", "mir", "noch", "blieb"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Aus all dem Zauber, der mich zwang zu lieben.", "tokens": ["Aus", "all", "dem", "Zau\u00b7ber", ",", "der", "mich", "zwang", "zu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "\u00bbich hab' kein Kreuz \u2013 ich Liebe nicht verlangt", "tokens": ["\u00bb", "ich", "hab'", "kein", "Kreuz", "\u2013", "ich", "Lie\u00b7be", "nicht", "ver\u00b7langt"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "PIAT", "NN", "$(", "PPER", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich mu\u00df mein Kreuz \u2013 ich seine Liebe tragen.\u00ab", "tokens": ["Ich", "mu\u00df", "mein", "Kreuz", "\u2013", "ich", "sei\u00b7ne", "Lie\u00b7be", "tra\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "$(", "PPER", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wir, denen beiden nicht vor beidem bangt,", "tokens": ["Wir", ",", "de\u00b7nen", "bei\u00b7den", "nicht", "vor", "bei\u00b7dem", "bangt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PIS", "PTKNEG", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wir wollen also Schn\u00f6des nimmer sagen.", "tokens": ["Wir", "wol\u00b7len", "al\u00b7so", "Schn\u00f6\u00b7des", "nim\u00b7mer", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wie? Nicht verlangen? \u2013 Bin ich dann kein Weib?", "tokens": ["Wie", "?", "Nicht", "ver\u00b7lan\u00b7gen", "?", "\u2013", "Bin", "ich", "dann", "kein", "Weib", "?"], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PTKNEG", "VVINF", "$.", "$(", "VAFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Verleugne ich die Reize, die mich schm\u00fccken,", "tokens": ["Ver\u00b7leug\u00b7ne", "ich", "die", "Rei\u00b7ze", ",", "die", "mich", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Verleugne ich den Geist, das Herz, den Leib,", "tokens": ["Ver\u00b7leug\u00b7ne", "ich", "den", "Geist", ",", "das", "Herz", ",", "den", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die ich nie andres lehr', als zu entz\u00fccken.", "tokens": ["Die", "ich", "nie", "and\u00b7res", "lehr'", ",", "als", "zu", "ent\u00b7z\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PIS", "VVFIN", "$,", "KOUS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Was mich betrifft, gesteh' ich ein, ich will", "tokens": ["Was", "mich", "be\u00b7tr\u00b7ifft", ",", "ge\u00b7steh'", "ich", "ein", ",", "ich", "will"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VMFIN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Welt noch mehr, als ihrem Herrn gefallen,", "tokens": ["Der", "Welt", "noch", "mehr", ",", "als", "ih\u00b7rem", "Herrn", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und schwiegen auch all meine Reize still,", "tokens": ["Und", "schwie\u00b7gen", "auch", "all", "mei\u00b7ne", "Rei\u00b7ze", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Lehrt' ich doch selbst die Stummen, s\u00fc\u00df zu lallen.", "tokens": ["Lehrt'", "ich", "doch", "selbst", "die", "Stum\u00b7men", ",", "s\u00fc\u00df", "zu", "lal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und sprech' ich nicht, so lallt das Stumme doch,", "tokens": ["Und", "sprech'", "ich", "nicht", ",", "so", "lallt", "das", "Stum\u00b7me", "doch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Verlang' ich nicht, so lehr' ich doch verlangen,", "tokens": ["Ver\u00b7lang'", "ich", "nicht", ",", "so", "lehr'", "ich", "doch", "ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der fesselt auch zum Pflug, der so das Joch", "tokens": ["Der", "fes\u00b7selt", "auch", "zum", "Pflug", ",", "der", "so", "das", "Joch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPRART", "NN", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Aufstellt, da\u00df sich das Ro\u00df darin mu\u00df fangen!", "tokens": ["Auf\u00b7stellt", ",", "da\u00df", "sich", "das", "Ro\u00df", "da\u00b7rin", "mu\u00df", "fan\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PRF", "ART", "NN", "PAV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ein Vogelsteller, der die Netze stellt,", "tokens": ["Ein", "Vo\u00b7gel\u00b7stel\u00b7ler", ",", "der", "die", "Net\u00b7ze", "stellt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mu\u00df auch behalten, was nicht weg will fliegen,", "tokens": ["Mu\u00df", "auch", "be\u00b7hal\u00b7ten", ",", "was", "nicht", "weg", "will", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "$,", "PRELS", "PTKNEG", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er hat zum Fang verlangt, was ihm gef\u00e4llt,", "tokens": ["Er", "hat", "zum", "Fang", "ver\u00b7langt", ",", "was", "ihm", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch bleibt im Netz der kranke L\u00f6we liegen.", "tokens": ["Doch", "bleibt", "im", "Netz", "der", "kran\u00b7ke", "L\u00f6\u00b7we", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Hat mich ein Gott um meine Schuld geliebt,", "tokens": ["Hat", "mich", "ein", "Gott", "um", "mei\u00b7ne", "Schuld", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df er f\u00fcr mich sich lie\u00df als Opfer schlachten,", "tokens": ["Da\u00df", "er", "f\u00fcr", "mich", "sich", "lie\u00df", "als", "Op\u00b7fer", "schlach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PRF", "VVFIN", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was Wunder? da\u00df ein Mensch sein Herz mir giebt,", "tokens": ["Was", "Wun\u00b7der", "?", "da\u00df", "ein", "Mensch", "sein", "Herz", "mir", "giebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "KOUS", "ART", "NN", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von meiner Huld berauschet zu verschmachten.", "tokens": ["Von", "mei\u00b7ner", "Huld", "be\u00b7rau\u00b7schet", "zu", "ver\u00b7schmach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wer Jenem tut, was er den Br\u00fcdern tut,", "tokens": ["Wer", "Je\u00b7nem", "tut", ",", "was", "er", "den", "Br\u00fc\u00b7dern", "tut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "$,", "PWS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ruft: Steig vom Kreuz, dran ich Dich nicht geschlagen,", "tokens": ["Ruft", ":", "Steig", "vom", "Kreuz", ",", "dran", "ich", "Dich", "nicht", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "NN", "APPRART", "NN", "$,", "PAV", "PPER", "PRF", "PTKNEG", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Spricht er zu eines kranken Herzens Glut,", "tokens": ["Spricht", "er", "zu", "ei\u00b7nes", "kran\u00b7ken", "Her\u00b7zens", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich hab' dies nicht verlangt, ich mu\u00df es tragen.", "tokens": ["Ich", "hab'", "dies", "nicht", "ver\u00b7langt", ",", "ich", "mu\u00df", "es", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "PTKNEG", "VVPP", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Jed Opfer mu\u00df ich ehren, das sich bringt", "tokens": ["Jed", "Op\u00b7fer", "mu\u00df", "ich", "eh\u00b7ren", ",", "das", "sich", "bringt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,", "PRELS", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In Liebe sterbend. Nie will ich mich sch\u00e4men,", "tokens": ["In", "Lie\u00b7be", "ster\u00b7bend", ".", "Nie", "will", "ich", "mich", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$.", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein brechend Herz, das auch am Kreuze ringt,", "tokens": ["Ein", "bre\u00b7chend", "Herz", ",", "das", "auch", "am", "Kreu\u00b7ze", "ringt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was Gott vom Menschen nimmt, auch anzunehmen.", "tokens": ["Was", "Gott", "vom", "Men\u00b7schen", "nimmt", ",", "auch", "an\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "APPRART", "NN", "VVFIN", "$,", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Mich kreuzigte die Liebe, die ich fand", "tokens": ["Mich", "kreu\u00b7zig\u00b7te", "die", "Lie\u00b7be", ",", "die", "ich", "fand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du kreuzigest die Liebe, die dich suchet,", "tokens": ["Du", "kreu\u00b7zi\u00b7gest", "die", "Lie\u00b7be", ",", "die", "dich", "su\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sprich, wer von uns dem Kreuze n\u00e4her stand,", "tokens": ["Sprich", ",", "wer", "von", "uns", "dem", "Kreu\u00b7ze", "n\u00e4\u00b7her", "stand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWS", "APPR", "PPER", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich hab' den Kelch geleert, du ihn versuchet.", "tokens": ["Ich", "hab'", "den", "Kelch", "ge\u00b7leert", ",", "du", "ihn", "ver\u00b7su\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}