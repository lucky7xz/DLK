{"textgrid.poem.54126": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Das Pers\u00f6nliche", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schreib, schreib . . .", "tokens": ["Schreib", ",", "schreib", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "$.", "$.", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Schreib von der Unsterblichkeit der Seele,", "tokens": ["Schreib", "von", "der", "U\u00b7nsterb\u00b7lich\u00b7keit", "der", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "vom Liebesleben der Nordsee-Makrele;", "tokens": ["vom", "Lie\u00b7bes\u00b7le\u00b7ben", "der", "Nord\u00b7see\u00b7Ma\u00b7kre\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "schreib von der neuen Hauszinssteuer,", "tokens": ["schreib", "von", "der", "neu\u00b7en", "Haus\u00b7zins\u00b7steu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "vom letzten gro\u00dfen Schadenfeuer;", "tokens": ["vom", "letz\u00b7ten", "gro\u00b7\u00dfen", "Scha\u00b7den\u00b7feu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "gib dir M\u00fche, arbeite alles gut aus,", "tokens": ["gib", "dir", "M\u00fc\u00b7he", ",", "ar\u00b7bei\u00b7te", "al\u00b7les", "gut", "aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "$,", "VVFIN", "PIS", "ADJD", "PTKVZ", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "schreib von dem alten Fuggerhaus;", "tokens": ["schreib", "von", "dem", "al\u00b7ten", "Fug\u00b7ger\u00b7haus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "von der Differenz zwischen Mann und Weib . . .", "tokens": ["von", "der", "Dif\u00b7fe\u00b7renz", "zwi\u00b7schen", "Mann", "und", "Weib", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$.", "$.", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Schreib . . . schreib . . .", "tokens": ["Schreib", ".", ".", ".", "schreib", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["NN", "$.", "$.", "$.", "VVFIN", "$.", "$.", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "Schreib sachlich und schreib dir die Finger krumm:", "tokens": ["Schreib", "sach\u00b7lich", "und", "schreib", "dir", "die", "Fin\u00b7ger", "krumm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "VVFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "kein Aas k\u00fcmmert sich darum.", "tokens": ["kein", "Aas", "k\u00fcm\u00b7mert", "sich", "da\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "schreibst du einmal zwanzig Zeilen", "tokens": ["schreibst", "du", "ein\u00b7mal", "zwan\u00b7zig", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mit Klatsch \u2013 die brauchst du gar nicht zu feilen.", "tokens": ["mit", "Klatsch", "\u2013", "die", "brauchst", "du", "gar", "nicht", "zu", "fei\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "ART", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nenn nur zwei Namen, und es kommen in Haufen", "tokens": ["Nenn", "nur", "zwei", "Na\u00b7men", ",", "und", "es", "kom\u00b7men", "in", "Hau\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "CARD", "NN", "$,", "KON", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Leser und Leserinnen gelaufen.", "tokens": ["Le\u00b7ser", "und", "Le\u00b7se\u00b7rin\u00b7nen", "ge\u00b7lau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "\u00bbwie ist das mit Fr\u00e4ulein Meier gewesen?\u00ab", "tokens": ["\u00bb", "wie", "ist", "das", "mit", "Fr\u00e4u\u00b7lein", "Mei\u00b7er", "ge\u00b7we\u00b7sen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOKOM", "VAFIN", "ART", "APPR", "NN", "NE", "VAPP", "$.", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das haben dann alle Leute gelesen.", "tokens": ["Das", "ha\u00b7ben", "dann", "al\u00b7le", "Leu\u00b7te", "ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbhat Herr Streuselkuchen mit Emma geschlafen?\u00ab", "tokens": ["\u00bb", "hat", "Herr", "Streu\u00b7sel\u00b7ku\u00b7chen", "mit", "Em\u00b7ma", "ge\u00b7schla\u00b7fen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "NN", "NN", "APPR", "NE", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Das lesen Portiers, und das lesen Grafen.", "tokens": ["Das", "le\u00b7sen", "Por\u00b7ti\u00b7ers", ",", "und", "das", "le\u00b7sen", "Gra\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "\u00bbwoher bezieht Stadtrat Mulps seine Gelder?\u00ab", "tokens": ["\u00bb", "wo\u00b7her", "be\u00b7zieht", "Stadt\u00b7rat", "Mulps", "sei\u00b7ne", "Gel\u00b7der", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VVFIN", "NN", "NE", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Das schreib \u2013 und dein Ruhm hallt durch Felder und W\u00e4lder.", "tokens": ["Das", "schreib", "\u2013", "und", "dein", "Ruhm", "hallt", "durch", "Fel\u00b7der", "und", "W\u00e4l\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "KON", "PPOSAT", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.4": {"line.1": {"text": "Die Sache? Interessiert in Paris und in Bentschen", "tokens": ["Die", "Sa\u00b7che", "?", "In\u00b7ter\u00b7es\u00b7siert", "in", "Pa\u00b7ris", "und", "in", "Bent\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "NN", "APPR", "NE", "KON", "APPR", "NN"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "keinen Menschen.", "tokens": ["kei\u00b7nen", "Men\u00b7schen", "."], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dieweil, lieber Freund, zu jeder Frist", "tokens": ["Die\u00b7weil", ",", "lie\u00b7ber", "Freund", ",", "zu", "je\u00b7der", "Frist"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "die Hauptsache das Pers\u00f6nliche ist.", "tokens": ["die", "Haupt\u00b7sa\u00b7che", "das", "Per\u00b7s\u00f6n\u00b7li\u00b7che", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}}}}}