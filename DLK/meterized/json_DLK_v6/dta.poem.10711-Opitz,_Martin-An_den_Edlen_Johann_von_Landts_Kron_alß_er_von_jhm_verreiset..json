{"dta.poem.10711": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "An den Edlen Johann von Landts Kron/  \n al\u00df er von jhm verreiset.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Wann sich der werthe Gast/ die Seele nun soll scheiden/", "tokens": ["Wann", "sich", "der", "wert\u00b7he", "Gast", "/", "die", "See\u00b7le", "nun", "soll", "schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "NN", "$(", "ART", "NN", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vnd jhres leibes Schlo\u00df/ die zarte Wohnung meiden/", "tokens": ["Vnd", "jhres", "lei\u00b7bes", "Schlo\u00df", "/", "die", "zar\u00b7te", "Woh\u00b7nung", "mei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Hilff Gott/ was hebet sich al\u00df dann f\u00fcr jammer an?", "tokens": ["Hilff", "Gott", "/", "was", "he\u00b7bet", "sich", "al\u00df", "dann", "f\u00fcr", "jam\u00b7mer", "an", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$(", "PWS", "VVFIN", "PRF", "ADV", "ADV", "APPR", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie bitter geht es ein/ ehe man sich geben kan?", "tokens": ["Wie", "bit\u00b7ter", "geht", "es", "ein", "/", "e\u00b7he", "man", "sich", "ge\u00b7ben", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ART", "$(", "KOUS", "PIS", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-+-+--", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Die Haare siehestu al\u00dfdan zu berge stehen/", "tokens": ["Die", "Haa\u00b7re", "sie\u00b7hes\u00b7tu", "al\u00df\u00b7dan", "zu", "ber\u00b7ge", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "PTKZU", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Augen in dem Kopff hin vnd herwider gehen/", "tokens": ["Die", "Au\u00b7gen", "in", "dem", "Kopff", "hin", "vnd", "her\u00b7wi\u00b7der", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "KON", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das Hertze schleget starck/ der Mensch sich kl\u00e4glich stellt/", "tokens": ["Das", "Hert\u00b7ze", "schle\u00b7get", "starck", "/", "der", "Mensch", "sich", "kl\u00e4g\u00b7lich", "stellt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "ADJD", "$(", "ART", "NN", "PRF", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Seele fehret au\u00df/ der Todt den Platz behelt.", "tokens": ["Die", "See\u00b7le", "feh\u00b7ret", "au\u00df", "/", "der", "Todt", "den", "Platz", "be\u00b7helt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wann ein vertrautes Hertz das ander mu\u00df verlassen/", "tokens": ["Wann", "ein", "ver\u00b7trau\u00b7tes", "Hertz", "das", "an\u00b7der", "mu\u00df", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ART", "ADJD", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was thut sie dazumahl vor Hertzenleid vmbfassen:", "tokens": ["Was", "thut", "sie", "da\u00b7zu\u00b7mahl", "vor", "Hert\u00b7zen\u00b7leid", "vmb\u00b7fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Threnen quellen vor al\u00df eine weite Flut/", "tokens": ["Die", "Thre\u00b7nen", "quel\u00b7len", "vor", "al\u00df", "ei\u00b7ne", "wei\u00b7te", "Flut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "KOUS", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Geist au\u00df K\u00fcmmernus ohn ende seufftzen thut/", "tokens": ["Der", "Geist", "au\u00df", "K\u00fcm\u00b7mer\u00b7nus", "ohn", "en\u00b7de", "seufft\u00b7zen", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPR", "NN", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das Hertz ist halb dahin/ man kan sich kaum besinnen/", "tokens": ["Das", "Hertz", "ist", "halb", "da\u00b7hin", "/", "man", "kan", "sich", "kaum", "be\u00b7sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PAV", "$(", "PIS", "VMFIN", "PRF", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vnd wei\u00df nit wohinaus/ ja man kan nichts beginnen/", "tokens": ["Vnd", "wei\u00df", "nit", "wo\u00b7hi\u00b7naus", "/", "ja", "man", "kan", "nichts", "be\u00b7gin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "$(", "ADV", "PIS", "VMFIN", "PIS", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Ein Tag ist ein gantz Jahr/ die angenehme Nacht", "tokens": ["Ein", "Tag", "ist", "ein", "gantz", "Jahr", "/", "die", "an\u00b7ge\u00b7neh\u00b7me", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "ADV", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wird mit tr\u00fcbseligkeit ohn Schlaff hinweg gebracht.", "tokens": ["Wird", "mit", "tr\u00fcb\u00b7se\u00b7lig\u00b7keit", "ohn", "Schlaff", "hin\u00b7weg", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "APPR", "NN", "APZR", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So gehet es auch vns/ nach dem wir jetzt mit schmertzen", "tokens": ["So", "ge\u00b7het", "es", "auch", "vns", "/", "nach", "dem", "wir", "jetzt", "mit", "schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPER", "$(", "APPR", "PRELS", "PPER", "ADV", "APPR", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von vns gerissen sein/ so offt ich thue behertzen/", "tokens": ["Von", "vns", "ge\u00b7ris\u00b7sen", "sein", "/", "so", "offt", "ich", "thue", "be\u00b7hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAINF", "$(", "ADV", "ADV", "PPER", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wie wir ohn Arg vnd Falsch gelebet jederzeit/", "tokens": ["Wie", "wir", "ohn", "Arg", "vnd", "Falsch", "ge\u00b7le\u00b7bet", "je\u00b7der\u00b7zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "KON", "NN", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wird mein Gem\u00fcte gantz bewegt zu Trawrigkeit.", "tokens": ["Wird", "mein", "Ge\u00b7m\u00fc\u00b7te", "gantz", "be\u00b7wegt", "zu", "Traw\u00b7rig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So will mir auch mein Leidt nur nicht so vil verg\u00f6nnen/", "tokens": ["So", "will", "mir", "auch", "mein", "Leidt", "nur", "nicht", "so", "vil", "ver\u00b7g\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "ADV", "PTKNEG", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Da\u00df ich ein zierlich Lied dir m\u00f6chte dichten k\u00f6nnen.", "tokens": ["Da\u00df", "ich", "ein", "zier\u00b7lich", "Lied", "dir", "m\u00f6ch\u00b7te", "dich\u00b7ten", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "NN", "PPER", "VMFIN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Den werthen Lorbeerbaum verfluch ich jetzund gantz/", "tokens": ["Den", "wert\u00b7hen", "Lor\u00b7beer\u00b7baum", "ver\u00b7fluch", "ich", "je\u00b7tzund", "gantz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Vnd alle Fr\u00f6lichkeit: Cypressen wird mein Krantz.", "tokens": ["Vnd", "al\u00b7le", "Fr\u00f6\u00b7lich\u00b7keit", ":", "Cyp\u00b7res\u00b7sen", "wird", "mein", "Krantz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$.", "NE", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "Ach da\u00df doch die Natur nicht wollen mir erleuben/", "tokens": ["Ach", "da\u00df", "doch", "die", "Na\u00b7tur", "nicht", "wol\u00b7len", "mir", "er\u00b7leu\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "ADV", "ART", "NN", "PTKNEG", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ein liebliches Gedicht/ wie Naso thet/ zuschreiben/", "tokens": ["Ein", "lieb\u00b7li\u00b7ches", "Ge\u00b7dicht", "/", "wie", "Na\u00b7so", "thet", "/", "zu\u00b7schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KOKOM", "ADV", "VVFIN", "$(", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Oder wie Orpheus vff Hemus Klippen sang/", "tokens": ["O\u00b7der", "wie", "Or\u00b7pheus", "vff", "He\u00b7mus", "Klip\u00b7pen", "sang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "APPR", "NN", "NN", "VVFIN", "$("], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.28": {"text": "Da\u00df davon vberal Walt/ Feld/ vnd Berg erklang.", "tokens": ["Da\u00df", "da\u00b7von", "vbe\u00b7ral", "Walt", "/", "Feld", "/", "vnd", "Berg", "er\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "ADJD", "NN", "$(", "NN", "$(", "KON", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Ich wolte dich sehr hoch/ du Kron vnd Zier der Jugent/", "tokens": ["Ich", "wol\u00b7te", "dich", "sehr", "hoch", "/", "du", "Kron", "vnd", "Zier", "der", "Ju\u00b7gent", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADJD", "$(", "PPER", "NN", "KON", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Bi\u00df an des Himmels Feld erheben/ durch die Tugent", "tokens": ["Bi\u00df", "an", "des", "Him\u00b7mels", "Feld", "er\u00b7he\u00b7ben", "/", "durch", "die", "Tu\u00b7gent"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "NN", "VVINF", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Der sch\u00f6nen Wissenschafft: dein Name solte sein", "tokens": ["Der", "sch\u00f6\u00b7nen", "Wis\u00b7sen\u00b7schafft", ":", "dein", "Na\u00b7me", "sol\u00b7te", "sein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "PPOSAT", "NN", "VMFIN", "PPOSAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "In aller Ewigkeit Stammbuch geschrieben ein.", "tokens": ["In", "al\u00b7ler", "E\u00b7wig\u00b7keit", "Stamm\u00b7buch", "ge\u00b7schrie\u00b7ben", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVPP", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.33": {"text": "Die weil nun dieses nicht in meinen Kr\u00e4fften stehet/", "tokens": ["Die", "weil", "nun", "die\u00b7ses", "nicht", "in", "mei\u00b7nen", "Kr\u00e4ff\u00b7ten", "ste\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOUS", "ADV", "PDS", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Vnd mir die hohe Kunst jetzt nicht von handen gehet/", "tokens": ["Vnd", "mir", "die", "ho\u00b7he", "Kunst", "jetzt", "nicht", "von", "han\u00b7den", "ge\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "ADV", "PTKNEG", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So nimm di\u00df schlechte Pfandt/ die schlechte Vers zu dir/", "tokens": ["So", "nimm", "di\u00df", "schlech\u00b7te", "Pfandt", "/", "die", "schlech\u00b7te", "Vers", "zu", "dir", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PDS", "VVFIN", "NE", "$(", "ART", "ADJA", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Weil zu geleiten dich das Gl\u00fcck nit g\u00f6nnet mir.", "tokens": ["Weil", "zu", "ge\u00b7lei\u00b7ten", "dich", "das", "Gl\u00fcck", "nit", "g\u00f6n\u00b7net", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKZU", "VVINF", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Wann wir vns offtermals auff was gewi\u00df bedencken/", "tokens": ["Wann", "wir", "vns", "off\u00b7ter\u00b7mals", "auff", "was", "ge\u00b7wi\u00df", "be\u00b7den\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "APPR", "PRELS", "ADV", "VVINF", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.38": {"text": "So kompt der so die Welt mit einer Hand kan lencken/", "tokens": ["So", "kompt", "der", "so", "die", "Welt", "mit", "ei\u00b7ner", "Hand", "kan", "len\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADV", "ART", "NN", "APPR", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Der streichet einen strich durch vnser Hertz vnd Sinn/", "tokens": ["Der", "strei\u00b7chet", "ei\u00b7nen", "strich", "durch", "vn\u00b7ser", "Hertz", "vnd", "Sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJD", "APPR", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Vnd f\u00fchret vnverhofft das gantze Datum hin.", "tokens": ["Vnd", "f\u00fch\u00b7ret", "vn\u00b7ver\u00b7hofft", "das", "gant\u00b7ze", "Da\u00b7tum", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Doch wann du werest gleich/ wo Ph", "tokens": ["Doch", "wann", "du", "we\u00b7rest", "gleich", "/", "wo", "Ph"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "PPER", "VAFIN", "ADV", "$(", "PWAV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Vnd Ich in ", "tokens": ["Vnd", "Ich", "in"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.43": {"text": "So wolten dennoch wir nicht abgesondert sein/", "tokens": ["So", "wol\u00b7ten", "den\u00b7noch", "wir", "nicht", "ab\u00b7ge\u00b7son\u00b7dert", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPER", "PTKNEG", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Mein Hertze bleibet dein/ dein Hertze bleibet mein.", "tokens": ["Mein", "Hert\u00b7ze", "blei\u00b7bet", "dein", "/", "dein", "Hert\u00b7ze", "blei\u00b7bet", "mein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPOSAT", "$(", "PPOSAT", "VVFIN", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}