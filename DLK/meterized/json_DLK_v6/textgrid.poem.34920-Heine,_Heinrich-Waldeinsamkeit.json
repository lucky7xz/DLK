{"textgrid.poem.34920": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Waldeinsamkeit", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich hab in meinen Jugendtagen", "tokens": ["Ich", "hab", "in", "mei\u00b7nen", "Ju\u00b7gend\u00b7ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl auf dem Haupt einen Kranz getragen;", "tokens": ["Wohl", "auf", "dem", "Haupt", "ei\u00b7nen", "Kranz", "ge\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Blumen gl\u00e4nzten wunderbar,", "tokens": ["Die", "Blu\u00b7men", "gl\u00e4nz\u00b7ten", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Zauber in dem Kranze war.", "tokens": ["Ein", "Zau\u00b7ber", "in", "dem", "Kran\u00b7ze", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der sch\u00f6ne Kranz gefiel wohl allen,", "tokens": ["Der", "sch\u00f6\u00b7ne", "Kranz", "ge\u00b7fiel", "wohl", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch der ihn trug, hat manchem mi\u00dffallen;", "tokens": ["Doch", "der", "ihn", "trug", ",", "hat", "man\u00b7chem", "mi\u00df\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVFIN", "$,", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich floh den gelben Menschenneid,", "tokens": ["Ich", "floh", "den", "gel\u00b7ben", "Men\u00b7schen\u00b7neid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich floh in die gr\u00fcne Waldeinsamkeit.", "tokens": ["Ich", "floh", "in", "die", "gr\u00fc\u00b7ne", "Wal\u00b7de\u00b7in\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Im Wald, im Wald! da konnt ich f\u00fchren", "tokens": ["Im", "Wald", ",", "im", "Wald", "!", "da", "konnt", "ich", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$.", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein freies Leben mit Geistern und Tieren;", "tokens": ["Ein", "frei\u00b7es", "Le\u00b7ben", "mit", "Geis\u00b7tern", "und", "Tie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Feen und Hochwild von stolzem Geweih,", "tokens": ["Feen", "und", "Hoch\u00b7wild", "von", "stol\u00b7zem", "Ge\u00b7weih", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sie nahten sich mir ganz ohne Scheu.", "tokens": ["Sie", "nah\u00b7ten", "sich", "mir", "ganz", "oh\u00b7ne", "Scheu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Sie nahten sich mir ganz ohne Zagnis,", "tokens": ["Sie", "nah\u00b7ten", "sich", "mir", "ganz", "oh\u00b7ne", "Zag\u00b7nis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie wu\u00dften, das sei kein schreckliches Wagnis;", "tokens": ["Sie", "wu\u00df\u00b7ten", ",", "das", "sei", "kein", "schreck\u00b7li\u00b7ches", "Wag\u00b7nis", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PDS", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da\u00df ich kein J\u00e4ger, wu\u00dfte das Reh,", "tokens": ["Da\u00df", "ich", "kein", "J\u00e4\u00b7ger", ",", "wu\u00df\u00b7te", "das", "Reh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Da\u00df ich kein Vernunftmensch, wu\u00dfte die Fee.", "tokens": ["Da\u00df", "ich", "kein", "Ver\u00b7nunft\u00b7mensch", ",", "wu\u00df\u00b7te", "die", "Fee", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.5": {"line.1": {"text": "Von Feenbeg\u00fcnstigung plaudern nur Toren \u2013", "tokens": ["Von", "Feen\u00b7be\u00b7g\u00fcns\u00b7ti\u00b7gung", "plau\u00b7dern", "nur", "To\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADV", "NN", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch wie die \u00fcbrigen Honoratioren", "tokens": ["Doch", "wie", "die", "\u00fcb\u00b7ri\u00b7gen", "Ho\u00b7no\u00b7ra\u00b7ti\u00b7o\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Des Waldes mir huldreich gewesen, f\u00fcrwahr,", "tokens": ["Des", "Wal\u00b7des", "mir", "huld\u00b7reich", "ge\u00b7we\u00b7sen", ",", "f\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "VAPP", "$,", "ADV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ich darf es bekennen offenbar.", "tokens": ["Ich", "darf", "es", "be\u00b7ken\u00b7nen", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Wie haben mich lieblich die Elfen umflattert!", "tokens": ["Wie", "ha\u00b7ben", "mich", "lieb\u00b7lich", "die", "El\u00b7fen", "um\u00b7flat\u00b7tert", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ein luftiges V\u00f6lkchen! das plaudert und schnattert!", "tokens": ["Ein", "luf\u00b7ti\u00b7ges", "V\u00f6lk\u00b7chen", "!", "das", "plau\u00b7dert", "und", "schnat\u00b7tert", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PDS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Ein bi\u00dfchen stechend ist der Blick,", "tokens": ["Ein", "bi\u00df\u00b7chen", "ste\u00b7chend", "ist", "der", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verhei\u00dfend ein s\u00fc\u00dfes, doch t\u00f6dliches Gl\u00fcck.", "tokens": ["Ver\u00b7hei\u00b7\u00dfend", "ein", "s\u00fc\u00b7\u00dfes", ",", "doch", "t\u00f6d\u00b7li\u00b7ches", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "ADJA", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "Erg\u00f6tzten mich mit Maitanz und Maispiel,", "tokens": ["Er\u00b7g\u00f6tz\u00b7ten", "mich", "mit", "Mai\u00b7tanz", "und", "Mai\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Erz\u00e4hlten mir Hofgeschichten zum Beispiel:", "tokens": ["Er\u00b7z\u00e4hl\u00b7ten", "mir", "Hof\u00b7ge\u00b7schich\u00b7ten", "zum", "Bei\u00b7spiel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die skandalose Chronika", "tokens": ["Die", "skan\u00b7da\u00b7lo\u00b7se", "Chro\u00b7ni\u00b7ka"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der K\u00f6nigin Titania.", "tokens": ["Der", "K\u00f6\u00b7ni\u00b7gin", "Ti\u00b7ta\u00b7nia", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Sa\u00df ich am Bache, so tauchten und sprangen", "tokens": ["Sa\u00df", "ich", "am", "Ba\u00b7che", ",", "so", "tauch\u00b7ten", "und", "spran\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "ADV", "ADJA", "KON", "VVFIN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hervor aus der Flut, mit ihrem langen", "tokens": ["Her\u00b7vor", "aus", "der", "Flut", ",", "mit", "ih\u00b7rem", "lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "ADJA"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Silberschleier und flatterndem Haar,", "tokens": ["Sil\u00b7ber\u00b7schlei\u00b7er", "und", "flat\u00b7tern\u00b7dem", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Die Wasserbacchanten, die Nixenschar.", "tokens": ["Die", "Was\u00b7ser\u00b7bac\u00b7chan\u00b7ten", ",", "die", "Ni\u00b7xen\u00b7schar", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.9": {"line.1": {"text": "Sie schlugen die Zither, sie spielten auf Geigen,", "tokens": ["Sie", "schlu\u00b7gen", "die", "Zi\u00b7ther", ",", "sie", "spiel\u00b7ten", "auf", "Gei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das war der famose Nixenreigen;", "tokens": ["Das", "war", "der", "fa\u00b7mo\u00b7se", "Ni\u00b7xen\u00b7rei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Posituren, die Melodei,", "tokens": ["Die", "Po\u00b7si\u00b7tu\u00b7ren", ",", "die", "Me\u00b7lo\u00b7dei", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "War klingende, springende Raserei.", "tokens": ["War", "klin\u00b7gen\u00b7de", ",", "sprin\u00b7gen\u00b7de", "Ra\u00b7se\u00b7rei", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Jedoch zuzeiten waren sie minder", "tokens": ["Je\u00b7doch", "zu\u00b7zei\u00b7ten", "wa\u00b7ren", "sie", "min\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVIZU", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Tobs\u00fcchtig gelaunt, die sch\u00f6nen Kinder;", "tokens": ["Tob\u00b7s\u00fcch\u00b7tig", "ge\u00b7launt", ",", "die", "sch\u00f6\u00b7nen", "Kin\u00b7der", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu meinen F\u00fc\u00dfen lagerten sie,", "tokens": ["Zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", "la\u00b7ger\u00b7ten", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das K\u00f6pfchen gest\u00fctzt auf meinem Knie.", "tokens": ["Das", "K\u00f6pf\u00b7chen", "ge\u00b7st\u00fctzt", "auf", "mei\u00b7nem", "Knie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "T\u00e4llerten, trillerten welsche Romanzen,", "tokens": ["T\u00e4l\u00b7ler\u00b7ten", ",", "tril\u00b7ler\u00b7ten", "wel\u00b7sche", "Ro\u00b7man\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PWAT", "NN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Zum Beispiel das Lied von den drei Pomeranzen,", "tokens": ["Zum", "Bei\u00b7spiel", "das", "Lied", "von", "den", "drei", "Po\u00b7me\u00b7ran\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ART", "CARD", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Sangen auch wohl ein Lobgedicht", "tokens": ["San\u00b7gen", "auch", "wohl", "ein", "Lob\u00b7ge\u00b7dicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Auf mich und mein nobeles Menschengesicht.", "tokens": ["Auf", "mich", "und", "mein", "no\u00b7be\u00b7les", "Men\u00b7schen\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "+---+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Sie unterbrachen manchmal das Gesinge", "tokens": ["Sie", "un\u00b7ter\u00b7bra\u00b7chen", "manch\u00b7mal", "das", "Ge\u00b7sin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lautlachend, und frugen bedenkliche Dinge,", "tokens": ["Laut\u00b7la\u00b7chend", ",", "und", "fru\u00b7gen", "be\u00b7denk\u00b7li\u00b7che", "Din\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Zum Beispiel: \u00bbSag uns, zu welchem Behuf", "tokens": ["Zum", "Bei\u00b7spiel", ":", "\u00bb", "Sag", "uns", ",", "zu", "wel\u00b7chem", "Be\u00b7huf"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$.", "$(", "NN", "PPER", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der liebe Gott den Menschen schuf?", "tokens": ["Der", "lie\u00b7be", "Gott", "den", "Men\u00b7schen", "schuf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Hat eine unsterbliche Seele ein jeder", "tokens": ["Hat", "ei\u00b7ne", "uns\u00b7terb\u00b7li\u00b7che", "See\u00b7le", "ein", "je\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "PIAT"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Von euch? Ist diese Seele von Leder", "tokens": ["Von", "euch", "?", "Ist", "die\u00b7se", "See\u00b7le", "von", "Le\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$.", "VAFIN", "PDAT", "NN", "APPR", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Oder von steifer Leinwand? Warum", "tokens": ["O\u00b7der", "von", "stei\u00b7fer", "Lein\u00b7wand", "?", "Wa\u00b7rum"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "$.", "PWAV"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Sind eure Leute meistens so dumm?\u00ab", "tokens": ["Sind", "eu\u00b7re", "Leu\u00b7te", "meis\u00b7tens", "so", "dumm", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.14": {"line.1": {"text": "Was ich zur Antwort gab, verhehle", "tokens": ["Was", "ich", "zur", "Ant\u00b7wort", "gab", ",", "ver\u00b7heh\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hier, doch meine unsterbliche Seele,", "tokens": ["Ich", "hier", ",", "doch", "mei\u00b7ne", "uns\u00b7terb\u00b7li\u00b7che", "See\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Glaubt mir's, ward nie davon verletzt,", "tokens": ["Glaubt", "mir's", ",", "ward", "nie", "da\u00b7von", "ver\u00b7letzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "VAFIN", "ADV", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was eine kleine Nixe geschw\u00e4tzt.", "tokens": ["Was", "ei\u00b7ne", "klei\u00b7ne", "Ni\u00b7xe", "ge\u00b7schw\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.15": {"line.1": {"text": "Anmutig und schalkhaft sind Nixen und Elfen;", "tokens": ["An\u00b7mu\u00b7tig", "und", "schalk\u00b7haft", "sind", "Ni\u00b7xen", "und", "El\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VAFIN", "NN", "KON", "NN", "$."], "meter": "+---+-+++-+-", "measure": "dactylic.init"}, "line.2": {"text": "Nicht so die Erdgeister, sie dienen und helfen", "tokens": ["Nicht", "so", "die", "Erd\u00b7geis\u00b7ter", ",", "sie", "die\u00b7nen", "und", "hel\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$,", "PPER", "VVINF", "KON", "VVINF"], "meter": "+--++--+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Treuherzig den Menschen. Ich liebte zumeist", "tokens": ["Treu\u00b7her\u00b7zig", "den", "Men\u00b7schen", ".", "Ich", "lieb\u00b7te", "zu\u00b7meist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ART", "NN", "$.", "PPER", "VVFIN", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Die, welche man Wichtelm\u00e4nnchen hei\u00dft.", "tokens": ["Die", ",", "wel\u00b7che", "man", "Wich\u00b7tel\u00b7m\u00e4nn\u00b7chen", "hei\u00dft", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PIS", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Sie tragen Rotm\u00e4ntelchen, lang und bauschig,", "tokens": ["Sie", "tra\u00b7gen", "Rot\u00b7m\u00e4n\u00b7tel\u00b7chen", ",", "lang", "und", "bau\u00b7schig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Die Miene ist ehrlich, doch bang und lauschig;", "tokens": ["Die", "Mie\u00b7ne", "ist", "ehr\u00b7lich", ",", "doch", "bang", "und", "lau\u00b7schig", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ich lie\u00df nicht merken, da\u00df ich entdeckt,", "tokens": ["Ich", "lie\u00df", "nicht", "mer\u00b7ken", ",", "da\u00df", "ich", "ent\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "VVINF", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Warum sie so \u00e4ngstlich die F\u00fc\u00dfe versteckt.", "tokens": ["Wa\u00b7rum", "sie", "so", "\u00e4ngst\u00b7lich", "die", "F\u00fc\u00b7\u00dfe", "ver\u00b7steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.17": {"line.1": {"text": "Sie haben n\u00e4mlich Entenf\u00fc\u00dfe", "tokens": ["Sie", "ha\u00b7ben", "n\u00e4m\u00b7lich", "En\u00b7ten\u00b7f\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und bilden sich ein, da\u00df niemand es wisse.", "tokens": ["Und", "bil\u00b7den", "sich", "ein", ",", "da\u00df", "nie\u00b7mand", "es", "wis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKVZ", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das ist eine tiefgeheime Wund',", "tokens": ["Das", "ist", "ei\u00b7ne", "tief\u00b7ge\u00b7hei\u00b7me", "Wund'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wor\u00fcber ich nimmermehr sp\u00f6tteln kunnt.", "tokens": ["Wo\u00b7r\u00fc\u00b7ber", "ich", "nim\u00b7mer\u00b7mehr", "sp\u00f6t\u00b7teln", "kunnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Ach Himmel! wir alle, gleich jenen Zwergen,", "tokens": ["Ach", "Him\u00b7mel", "!", "wir", "al\u00b7le", ",", "gleich", "je\u00b7nen", "Zwer\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "PPER", "PIS", "$,", "ADV", "PDAT", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wir haben ja alle etwas zu verbergen;", "tokens": ["Wir", "ha\u00b7ben", "ja", "al\u00b7le", "et\u00b7was", "zu", "ver\u00b7ber\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Kein Christenmensch, w\u00e4hnen wir, h\u00e4tte entdeckt,", "tokens": ["Kein", "Chris\u00b7ten\u00b7mensch", ",", "w\u00e4h\u00b7nen", "wir", ",", "h\u00e4t\u00b7te", "ent\u00b7deckt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "PPER", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Wo unser Entenf\u00fc\u00dfchen steckt.", "tokens": ["Wo", "un\u00b7ser", "En\u00b7ten\u00b7f\u00fc\u00df\u00b7chen", "steckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Niemals verkehrt ich mit Salamandern,", "tokens": ["Nie\u00b7mals", "ver\u00b7kehrt", "ich", "mit", "Sa\u00b7la\u00b7man\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Und \u00fcber ihr Treiben erfuhr ich von andern", "tokens": ["Und", "\u00fc\u00b7ber", "ihr", "Trei\u00b7ben", "er\u00b7fuhr", "ich", "von", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ADJA"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Waldgeistern sehr wenig. Sie huschten mir scheu", "tokens": ["Wald\u00b7geis\u00b7tern", "sehr", "we\u00b7nig", ".", "Sie", "huschten", "mir", "scheu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PIS", "$.", "PPER", "VVFIN", "PPER", "ADJD"], "meter": "++-++--+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Des Nachts wie leuchtende Schatten vorbei.", "tokens": ["Des", "Nachts", "wie", "leuch\u00b7ten\u00b7de", "Schat\u00b7ten", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "KOKOM", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "Sind spindeld\u00fcrre, von Kindesl\u00e4nge,", "tokens": ["Sind", "spin\u00b7del\u00b7d\u00fcr\u00b7re", ",", "von", "Kin\u00b7des\u00b7l\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "$,", "APPR", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "H\u00f6schen und W\u00e4mschen anliegend enge,", "tokens": ["H\u00f6\u00b7schen", "und", "W\u00e4m\u00b7schen", "an\u00b7lie\u00b7gend", "en\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADJD", "ADJA", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Von Scharlachfarbe, goldgestickt;", "tokens": ["Von", "Schar\u00b7lach\u00b7far\u00b7be", ",", "gold\u00b7ge\u00b7stickt", ";"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Antlitz kr\u00e4nklich, vergilbt und bedr\u00fcckt.", "tokens": ["Das", "Ant\u00b7litz", "kr\u00e4nk\u00b7lich", ",", "ver\u00b7gilbt", "und", "be\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "Ein g\u00fcldnes Kr\u00f6nlein, gespickt mit Rubinen,", "tokens": ["Ein", "g\u00fcld\u00b7nes", "Kr\u00f6n\u00b7lein", ",", "ge\u00b7spickt", "mit", "Ru\u00b7bi\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Tr\u00e4gt auf dem K\u00f6pfchen ein jeder von ihnen;", "tokens": ["Tr\u00e4gt", "auf", "dem", "K\u00f6pf\u00b7chen", "ein", "je\u00b7der", "von", "ih\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "PIS", "APPR", "PPER", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Ein jeder von ihnen bildet sich ein,", "tokens": ["Ein", "je\u00b7der", "von", "ih\u00b7nen", "bil\u00b7det", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPER", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein absoluter K\u00f6nig zu sein.", "tokens": ["Ein", "ab\u00b7so\u00b7lu\u00b7ter", "K\u00f6\u00b7nig", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.22": {"line.1": {"text": "Da\u00df sie im Feuer nicht verbrennen,", "tokens": ["Da\u00df", "sie", "im", "Feu\u00b7er", "nicht", "ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist freilich ein Kunstst\u00fcck, ich will es bekennen;", "tokens": ["Ist", "frei\u00b7lich", "ein", "Kunst\u00b7st\u00fcck", ",", "ich", "will", "es", "be\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Jedoch der unentz\u00fcndbare Wicht,", "tokens": ["Je\u00b7doch", "der", "un\u00b7ent\u00b7z\u00fcnd\u00b7ba\u00b7re", "Wicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein wahrer Feuergeist ist er nicht.", "tokens": ["Ein", "wah\u00b7rer", "Feu\u00b7er\u00b7geist", "ist", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "Die kl\u00fcgsten Waldgeister sind die Alr\u00e4unchen,", "tokens": ["Die", "kl\u00fcgs\u00b7ten", "Wald\u00b7geis\u00b7ter", "sind", "die", "Al\u00b7r\u00e4un\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Langb\u00e4rtige M\u00e4nnlein mit kurzen Beinchen,", "tokens": ["Lang\u00b7b\u00e4r\u00b7ti\u00b7ge", "M\u00e4nn\u00b7lein", "mit", "kur\u00b7zen", "Be\u00b7in\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Ein fingerlanges Greisengeschlecht;", "tokens": ["Ein", "fin\u00b7ger\u00b7lan\u00b7ges", "Grei\u00b7sen\u00b7ge\u00b7schlecht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Woher sie stammen, man wei\u00df es nicht recht.", "tokens": ["Wo\u00b7her", "sie", "stam\u00b7men", ",", "man", "wei\u00df", "es", "nicht", "recht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Wenn sie im Mondschein kopf\u00fcber purzeln,", "tokens": ["Wenn", "sie", "im", "Mond\u00b7schein", "kopf\u00b7\u00fc\u00b7ber", "pur\u00b7zeln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das mahnt bedenklich an Pissewurzeln;", "tokens": ["Das", "mahnt", "be\u00b7denk\u00b7lich", "an", "Pis\u00b7se\u00b7wur\u00b7zeln", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch da sie mir nur Gutes getan,", "tokens": ["Doch", "da", "sie", "mir", "nur", "Gu\u00b7tes", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So geht mich nichts ihr Ursprung an.", "tokens": ["So", "geht", "mich", "nichts", "ihr", "Ur\u00b7sprung", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Sie lehrten mir kleine Hexereien,", "tokens": ["Sie", "lehr\u00b7ten", "mir", "klei\u00b7ne", "He\u00b7xe\u00b7rei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Feuer besprechen, V\u00f6gel beschreien,", "tokens": ["Feu\u00b7er", "be\u00b7spre\u00b7chen", ",", "V\u00f6\u00b7gel", "be\u00b7schrei\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "NN", "VVFIN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Auch pfl\u00fccken in der Johannisnacht", "tokens": ["Auch", "pfl\u00fc\u00b7cken", "in", "der", "Jo\u00b7han\u00b7nis\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Kr\u00e4utlein, das unsichtbar macht.", "tokens": ["Das", "Kr\u00e4ut\u00b7lein", ",", "das", "un\u00b7sicht\u00b7bar", "macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.26": {"line.1": {"text": "Sie lehrten mich Sterne und Zeichen deuten,", "tokens": ["Sie", "lehr\u00b7ten", "mich", "Ster\u00b7ne", "und", "Zei\u00b7chen", "deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sattellos auf dem Winde reiten,", "tokens": ["Sat\u00b7tel\u00b7los", "auf", "dem", "Win\u00b7de", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Auch Runenspr\u00fcche, womit man ruft", "tokens": ["Auch", "Ru\u00b7nen\u00b7spr\u00fc\u00b7che", ",", "wo\u00b7mit", "man", "ruft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "$,", "PWAV", "PIS", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Toten hervor aus ihrer Gruft.", "tokens": ["Die", "To\u00b7ten", "her\u00b7vor", "aus", "ih\u00b7rer", "Gruft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.27": {"line.1": {"text": "Sie haben mir auch den Pfiff gelehrt,", "tokens": ["Sie", "ha\u00b7ben", "mir", "auch", "den", "Pfiff", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie man den Vogel Specht bet\u00f6rt", "tokens": ["Wie", "man", "den", "Vo\u00b7gel", "Specht", "be\u00b7t\u00f6rt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ART", "NE", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ihm die Springwurz abgewinnt,", "tokens": ["Und", "ihm", "die", "Spring\u00b7wurz", "ab\u00b7ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die anzeigt, wo Sch\u00e4tze verborgen sind.", "tokens": ["Die", "an\u00b7zeigt", ",", "wo", "Sch\u00e4t\u00b7ze", "ver\u00b7bor\u00b7gen", "sind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PWAV", "NN", "VVPP", "VAFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.28": {"line.1": {"text": "Die Worte, die man beim Sch\u00e4tzegraben", "tokens": ["Die", "Wor\u00b7te", ",", "die", "man", "beim", "Sch\u00e4t\u00b7ze\u00b7gra\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "APPRART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hinmurmelt, lehrten sie mich, sie haben", "tokens": ["Hin\u00b7mur\u00b7melt", ",", "lehr\u00b7ten", "sie", "mich", ",", "sie", "ha\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "PPER", "$,", "PPER", "VAFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mir alles expliziert \u2013 umsunst!", "tokens": ["Mir", "al\u00b7les", "ex\u00b7pli\u00b7ziert", "\u2013", "um\u00b7sunst", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "$(", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab nie begriffen die Schatzgr\u00e4berkunst.", "tokens": ["Hab", "nie", "be\u00b7grif\u00b7fen", "die", "Schatz\u00b7gr\u00e4\u00b7ber\u00b7kunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVPP", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Wohl hatt ich derselben nicht n\u00f6tig dermalen,", "tokens": ["Wohl", "hatt", "ich", "der\u00b7sel\u00b7ben", "nicht", "n\u00f6\u00b7tig", "der\u00b7ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ich brauchte wenig, und konnt es bezahlen,", "tokens": ["Ich", "brauch\u00b7te", "we\u00b7nig", ",", "und", "konnt", "es", "be\u00b7zah\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "KON", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Besa\u00df auch in Spanien manch luftiges Schlo\u00df,", "tokens": ["Be\u00b7sa\u00df", "auch", "in", "Spa\u00b7ni\u00b7en", "manch", "luf\u00b7ti\u00b7ges", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NE", "PIAT", "ADJA", "NN", "$,"], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wovon ich die Revenuen geno\u00df.", "tokens": ["Wo\u00b7von", "ich", "die", "Re\u00b7ve\u00b7nu\u00b7en", "ge\u00b7no\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.30": {"line.1": {"text": "Oh, sch\u00f6ne Zeit! wo voller Geigen", "tokens": ["Oh", ",", "sch\u00f6\u00b7ne", "Zeit", "!", "wo", "vol\u00b7ler", "Gei\u00b7gen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "ADJA", "NN", "$.", "PWAV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Himmel hing, wo Elfenreigen", "tokens": ["Der", "Him\u00b7mel", "hing", ",", "wo", "El\u00b7fen\u00b7rei\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Nixentanz und Koboldscherz", "tokens": ["Und", "Ni\u00b7xen\u00b7tanz", "und", "Ko\u00b7bold\u00b7scherz"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Umgaukelt mein m\u00e4rchentrunkenes Herz!", "tokens": ["Um\u00b7gau\u00b7kelt", "mein", "m\u00e4r\u00b7chen\u00b7trun\u00b7ke\u00b7nes", "Herz", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.31": {"line.1": {"text": "Oh, sch\u00f6ne Zeit! wo sich zu gr\u00fcnen", "tokens": ["Oh", ",", "sch\u00f6\u00b7ne", "Zeit", "!", "wo", "sich", "zu", "gr\u00fc\u00b7nen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADJA", "NN", "$.", "PWAV", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Triumphespforten zu w\u00f6lben schienen", "tokens": ["Tri\u00b7um\u00b7phes\u00b7pfor\u00b7ten", "zu", "w\u00f6l\u00b7ben", "schie\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PTKZU", "VVINF", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die B\u00e4ume des Waldes \u2013 ich ging einher,", "tokens": ["Die", "B\u00e4u\u00b7me", "des", "Wal\u00b7des", "\u2013", "ich", "ging", "ein\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$(", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Bekr\u00e4nzt, als ob ich der Sieger w\u00e4r!", "tokens": ["Be\u00b7kr\u00e4nzt", ",", "als", "ob", "ich", "der", "Sie\u00b7ger", "w\u00e4r", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOKOM", "KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Die sch\u00f6ne Zeit, sie ist verschlendert,", "tokens": ["Die", "sch\u00f6\u00b7ne", "Zeit", ",", "sie", "ist", "ver\u00b7schlen\u00b7dert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und alles hat sich seitdem ver\u00e4ndert,", "tokens": ["Und", "al\u00b7les", "hat", "sich", "seit\u00b7dem", "ver\u00b7\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PRF", "PAV", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und ach! mir ist der Kranz geraubt,", "tokens": ["Und", "ach", "!", "mir", "ist", "der", "Kranz", "ge\u00b7raubt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den ich getragen auf meinem Haupt.", "tokens": ["Den", "ich", "ge\u00b7tra\u00b7gen", "auf", "mei\u00b7nem", "Haupt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.33": {"line.1": {"text": "Der Kranz ist mir vom Haupt genommen,", "tokens": ["Der", "Kranz", "ist", "mir", "vom", "Haupt", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wei\u00df es nicht, wie es gekommen;", "tokens": ["Ich", "wei\u00df", "es", "nicht", ",", "wie", "es", "ge\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch seit der sch\u00f6ne Kranz mir fehlt,", "tokens": ["Doch", "seit", "der", "sch\u00f6\u00b7ne", "Kranz", "mir", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist meine Seele wie entseelt.", "tokens": ["Ist", "mei\u00b7ne", "See\u00b7le", "wie", "ent\u00b7seelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Es glotzen mich an unheimlich bl\u00f6de", "tokens": ["Es", "glot\u00b7zen", "mich", "an", "un\u00b7heim\u00b7lich", "bl\u00f6\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADJD", "ADJA"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Larven der Welt! Der Himmel ist \u00f6de,", "tokens": ["Die", "Lar\u00b7ven", "der", "Welt", "!", "Der", "Him\u00b7mel", "ist", "\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein blauer Kirchhof, entg\u00f6ttert und stumm.", "tokens": ["Ein", "blau\u00b7er", "Kirch\u00b7hof", ",", "ent\u00b7g\u00f6t\u00b7tert", "und", "stumm", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVPP", "KON", "ADJD", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich gehe geb\u00fcckt im Wald herum.", "tokens": ["Ich", "ge\u00b7he", "ge\u00b7b\u00fcckt", "im", "Wald", "he\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.35": {"line.1": {"text": "Im Walde sind die Elfen verschwunden,", "tokens": ["Im", "Wal\u00b7de", "sind", "die", "El\u00b7fen", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Jagdh\u00f6rner h\u00f6r ich, Gekl\u00e4ffe von Hunden;", "tokens": ["Jagd\u00b7h\u00f6r\u00b7ner", "h\u00f6r", "ich", ",", "Ge\u00b7kl\u00e4f\u00b7fe", "von", "Hun\u00b7den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "NN", "APPR", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Im Dickicht ist das Reh versteckt,", "tokens": ["Im", "Di\u00b7ckicht", "ist", "das", "Reh", "ver\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das tr\u00e4nend seine Wunden leckt.", "tokens": ["Das", "tr\u00e4\u00b7nend", "sei\u00b7ne", "Wun\u00b7den", "leckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Wo sind die Alr\u00e4unchen? Ich glaube, sie halten", "tokens": ["Wo", "sind", "die", "Al\u00b7r\u00e4un\u00b7chen", "?", "Ich", "glau\u00b7be", ",", "sie", "hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$.", "PPER", "VVFIN", "$,", "PPER", "VVINF"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sich \u00e4ngstlich verborgen in Felsenspalten.", "tokens": ["Sich", "\u00e4ngst\u00b7lich", "ver\u00b7bor\u00b7gen", "in", "Fel\u00b7sen\u00b7spal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVPP", "APPR", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ihr kleinen Freunde, ich komme zur\u00fcck,", "tokens": ["Ihr", "klei\u00b7nen", "Freun\u00b7de", ",", "ich", "kom\u00b7me", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch ohne Kranz und ohne Gl\u00fcck.", "tokens": ["Doch", "oh\u00b7ne", "Kranz", "und", "oh\u00b7ne", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Wo ist die Fee mit dem langen Goldhaar,", "tokens": ["Wo", "ist", "die", "Fee", "mit", "dem", "lan\u00b7gen", "Gold\u00b7haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-++", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die erste Sch\u00f6nheit, die mir hold war?", "tokens": ["Die", "ers\u00b7te", "Sch\u00f6n\u00b7heit", ",", "die", "mir", "hold", "war", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Eichenbaum, worin sie gehaust,", "tokens": ["Der", "Ei\u00b7chen\u00b7baum", ",", "wo\u00b7rin", "sie", "ge\u00b7haust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Steht traurig entlaubt, vom Winde zerzaust.", "tokens": ["Steht", "trau\u00b7rig", "ent\u00b7laubt", ",", "vom", "Win\u00b7de", "zer\u00b7zaust", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVPP", "$,", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.38": {"line.1": {"text": "Der Bach rauscht trostlos gleich dem Styxe;", "tokens": ["Der", "Bach", "rauscht", "trost\u00b7los", "gleich", "dem", "Sty\u00b7xe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Am einsamen Ufer sitzt eine Nixe,", "tokens": ["Am", "ein\u00b7sa\u00b7men", "U\u00b7fer", "sitzt", "ei\u00b7ne", "Ni\u00b7xe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+---+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Todbla\u00df und stumm, wie 'n Bild von Stein,", "tokens": ["Tod\u00b7bla\u00df", "und", "stumm", ",", "wie", "'n", "Bild", "von", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$,", "PWAV", "ART", "NN", "APPR", "NN", "$,"], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Scheint tief in Kummer versunken zu sein.", "tokens": ["Scheint", "tief", "in", "Kum\u00b7mer", "ver\u00b7sun\u00b7ken", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "NN", "VVINF", "PTKZU", "VAINF", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.39": {"line.1": {"text": "Mitleidig tret ich zu ihr heran \u2013", "tokens": ["Mit\u00b7lei\u00b7dig", "tret", "ich", "zu", "ihr", "he\u00b7ran", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da f\u00e4hrt sie auf und schaut mich an,", "tokens": ["Da", "f\u00e4hrt", "sie", "auf", "und", "schaut", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sie entflieht mit entsetzten Mienen,", "tokens": ["Und", "sie", "ent\u00b7flieht", "mit", "ent\u00b7setz\u00b7ten", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als sei ihr ein Gespenst erschienen.", "tokens": ["Als", "sei", "ihr", "ein", "Ge\u00b7spenst", "er\u00b7schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}