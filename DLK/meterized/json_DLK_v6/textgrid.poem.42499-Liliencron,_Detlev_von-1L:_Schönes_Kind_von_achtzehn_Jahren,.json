{"textgrid.poem.42499": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sch\u00f6nes Kind von achtzehn Jahren,", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sch\u00f6nes Kind von achtzehn Jahren,", "tokens": ["Sch\u00f6\u00b7nes", "Kind", "von", "acht\u00b7zehn", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Weilchen sind wir zusammengefahren", "tokens": ["Ein", "Weil\u00b7chen", "sind", "wir", "zu\u00b7sam\u00b7men\u00b7ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVINF"], "meter": "-+-++-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Durch diese verdammt langweilige Welt;", "tokens": ["Durch", "die\u00b7se", "ver\u00b7dammt", "lang\u00b7wei\u00b7li\u00b7ge", "Welt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Und schon sind uns die Rosen verg\u00e4llt?", "tokens": ["Und", "schon", "sind", "uns", "die", "Ro\u00b7sen", "ver\u00b7g\u00e4llt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Schon lauern G\u00e4hnen und l\u00e4stiger Trug;", "tokens": ["Schon", "lau\u00b7ern", "G\u00e4h\u00b7nen", "und", "l\u00e4s\u00b7ti\u00b7ger", "Trug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Um des Himmels willen, genug, genug,", "tokens": ["Um", "des", "Him\u00b7mels", "wil\u00b7len", ",", "ge\u00b7nug", ",", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUI", "ART", "NN", "NN", "$,", "ADV", "$,", "ADV", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ein toter Docht kann nicht mehr glimmen,", "tokens": ["Ein", "to\u00b7ter", "Docht", "kann", "nicht", "mehr", "glim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein l\u00e4ssiger Arm kein Meer durchschwimmen.", "tokens": ["Ein", "l\u00e4s\u00b7si\u00b7ger", "Arm", "kein", "Meer", "durch\u00b7schwim\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "So geh deinen Weg du, ich gehe den meinen,", "tokens": ["So", "geh", "dei\u00b7nen", "Weg", "du", ",", "ich", "ge\u00b7he", "den", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPER", "$,", "PPER", "VVFIN", "ART", "VVFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Wolln uns nicht gr\u00e4men, wollen nicht greinen;", "tokens": ["Wolln", "uns", "nicht", "gr\u00e4\u00b7men", ",", "wol\u00b7len", "nicht", "grei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "VVINF", "$,", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Und sollten wir sp\u00e4ter uns treffen einmal,", "tokens": ["Und", "soll\u00b7ten", "wir", "sp\u00e4\u00b7ter", "uns", "tref\u00b7fen", "ein\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADJD", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.12": {"text": "Wirds keinem von uns zu Kummer und Qual.", "tokens": ["Wirds", "kei\u00b7nem", "von", "uns", "zu", "Kum\u00b7mer", "und", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Hast schnell einen Schatz, ich find ein Sch\u00e4tzchen,", "tokens": ["Hast", "schnell", "ei\u00b7nen", "Schatz", ",", "ich", "find", "ein", "Sch\u00e4tz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.14": {"text": "Du einen Kater, ich ein K\u00e4tzchen;", "tokens": ["Du", "ei\u00b7nen", "Ka\u00b7ter", ",", "ich", "ein", "K\u00e4tz\u00b7chen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Streichelst dann, eia, ein andres H\u00e4nschen,", "tokens": ["Strei\u00b7chelst", "dann", ",", "ei\u00b7a", ",", "ein", "and\u00b7res", "H\u00e4n\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "FM.la", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.16": {"text": "Und mir schl\u00e4ft im Arm ein andres G\u00e4nschen.", "tokens": ["Und", "mir", "schl\u00e4ft", "im", "Arm", "ein", "and\u00b7res", "G\u00e4n\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "Nur immer frisch das Leben genossen,", "tokens": ["Nur", "im\u00b7mer", "frisch", "das", "Le\u00b7ben", "ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Bald h\u00e4lt uns h\u00f6hnisch der Sarg umschlossen.", "tokens": ["Bald", "h\u00e4lt", "uns", "h\u00f6h\u00b7nisch", "der", "Sarg", "um\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Und nun Lebwohl; Dank sei dir gebracht", "tokens": ["Und", "nun", "Leb\u00b7wohl", ";", "Dank", "sei", "dir", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "NN", "$.", "NN", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "F\u00fcr manche sturmherrliche Liebesnacht.", "tokens": ["F\u00fcr", "man\u00b7che", "sturm\u00b7herr\u00b7li\u00b7che", "Lie\u00b7bes\u00b7nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Noch einmal komm ich morgen fr\u00fch,", "tokens": ["Noch", "ein\u00b7mal", "komm", "ich", "mor\u00b7gen", "fr\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und dann ist die Sache perdauz und perd\u00fc.", "tokens": ["Und", "dann", "ist", "die", "Sa\u00b7che", "per\u00b7dauz", "und", "per\u00b7d\u00fc", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ADJD", "KON", "NE", "$."], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}}}}}