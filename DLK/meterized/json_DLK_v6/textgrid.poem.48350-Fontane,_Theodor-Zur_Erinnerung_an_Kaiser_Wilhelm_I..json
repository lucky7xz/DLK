{"textgrid.poem.48350": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Zur Erinnerung an Kaiser Wilhelm I.", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was unterging in Zeitensturm und Flut", "tokens": ["Was", "un\u00b7ter\u00b7ging", "in", "Zei\u00b7ten\u00b7sturm", "und", "Flut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und was zu Schutt gefegt der Kriegesbesen,", "tokens": ["Und", "was", "zu", "Schutt", "ge\u00b7fegt", "der", "Krie\u00b7ges\u00b7be\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKA", "ADJD", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was, an Idolen und an Martyrblut,", "tokens": ["Was", ",", "an", "I\u00b7do\u00b7len", "und", "an", "Mar\u00b7tyr\u00b7blut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der Inhalt der Jahrtausende gewesen,", "tokens": ["Der", "In\u00b7halt", "der", "Jahr\u00b7tau\u00b7sen\u00b7de", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAPP", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wir suchen es \u2013 und was am tiefsten ruht,", "tokens": ["Wir", "su\u00b7chen", "es", "\u2013", "und", "was", "am", "tiefs\u00b7ten", "ruht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "KON", "PWS", "APPRART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das wird am freudigsten erforscht, gelesen,", "tokens": ["Das", "wird", "am", "freu\u00b7digs\u00b7ten", "er\u00b7forscht", ",", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "ADJA", "VVFIN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Heut aber, statt zur\u00fcck uns zu versenken,", "tokens": ["Heut", "a\u00b7ber", ",", "statt", "zu\u00b7r\u00fcck", "uns", "zu", "ver\u00b7sen\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUI", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gilt's ", "tokens": ["Gilt's"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}}, "stanza.2": {"line.1": {"text": "Wir denken ", "tokens": ["Wir", "den\u00b7ken"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ein Knabe noch, an Preu\u00dfens Grab gestanden", "tokens": ["Ein", "Kna\u00b7be", "noch", ",", "an", "Preu\u00b7\u00dfens", "Grab", "ge\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "APPR", "NE", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und, als Gott selbst uns dann das Zeichen bot,", "tokens": ["Und", ",", "als", "Gott", "selbst", "uns", "dann", "das", "Zei\u00b7chen", "bot", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "NN", "ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Uns mit befreit aus unsrer Ohnmacht Banden;", "tokens": ["Uns", "mit", "be\u00b7freit", "aus", "uns\u00b7rer", "Ohn\u00b7macht", "Ban\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dein Lebensabend war ein Morgenrot,", "tokens": ["Dein", "Le\u00b7bens\u00b7a\u00b7bend", "war", "ein", "Mor\u00b7gen\u00b7rot", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und als des Abends letzte Lichter schwanden,", "tokens": ["Und", "als", "des", "A\u00b7bends", "letz\u00b7te", "Lich\u00b7ter", "schwan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Da lagen Siegeskr\u00e4nze, hochgeschichtet,", "tokens": ["Da", "la\u00b7gen", "Sie\u00b7ges\u00b7kr\u00e4n\u00b7ze", ",", "hoch\u00b7ge\u00b7schich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Um deinen Sarg \u2013 das Reich war aufgerichtet.", "tokens": ["Um", "dei\u00b7nen", "Sarg", "\u2013", "das", "Reich", "war", "auf\u00b7ge\u00b7rich\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und denken ", "tokens": ["Und", "den\u00b7ken"], "token_info": ["word", "word"], "pos": ["KON", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Uns gr\u00fc\u00dfend ansprach, im Vor\u00fcberschweben,", "tokens": ["Uns", "gr\u00fc\u00b7\u00dfend", "an\u00b7sprach", ",", "im", "Vor\u00b7\u00fc\u00b7bersc\u00b7hwe\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch dieser neunundneunzig Tage Spur", "tokens": ["Doch", "die\u00b7ser", "neun\u00b7und\u00b7neun\u00b7zig", "Ta\u00b7ge", "Spur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "CARD", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ist uns als ewig Erbe nun gegeben,", "tokens": ["Ist", "uns", "als", "e\u00b7wig", "Er\u00b7be", "nun", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOUS", "ADJD", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie Balder, blond und leuchtend am Azur,", "tokens": ["Wie", "Bal\u00b7der", ",", "blond", "und", "leuch\u00b7tend", "am", "A\u00b7zur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "ADJD", "KON", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So kamst du, gingst du, Freiheit war dein Leben,", "tokens": ["So", "kamst", "du", ",", "gingst", "du", ",", "Frei\u00b7heit", "war", "dein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Im Reich des Lichtes der Erw\u00e4hlten einer-", "tokens": ["Im", "Reich", "des", "Lich\u00b7tes", "der", "Er\u00b7w\u00e4hl\u00b7ten", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ja, Kaiser Friedrich, wir gedenken deiner.", "tokens": ["Ja", ",", "Kai\u00b7ser", "Fried\u00b7rich", ",", "wir", "ge\u00b7den\u00b7ken", "dei\u00b7ner", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "NE", "$,", "PPER", "VVINF", "PPOSAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Vorbild in Arbeit, Treue, wahr und schlicht,", "tokens": ["Vor\u00b7bild", "in", "Ar\u00b7beit", ",", "Treu\u00b7e", ",", "wahr", "und", "schlicht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In Demut, die der Gr\u00f6\u00dfe sich verb\u00fcndet,", "tokens": ["In", "De\u00b7mut", ",", "die", "der", "Gr\u00f6\u00b7\u00dfe", "sich", "ver\u00b7b\u00fcn\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So war der Eine \u2013 hell und sonnenlicht", "tokens": ["So", "war", "der", "Ei\u00b7ne", "\u2013", "hell", "und", "son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ART", "$(", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hat uns der Andre Kommendes verk\u00fcndet,", "tokens": ["Hat", "uns", "der", "And\u00b7re", "Kom\u00b7men\u00b7des", "ver\u00b7k\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein jeder gro\u00df in seiner F\u00fcrstenpflicht,", "tokens": ["Ein", "je\u00b7der", "gro\u00df", "in", "sei\u00b7ner", "F\u00fcrs\u00b7ten\u00b7pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So ward durch sie die neue Zeit gegr\u00fcndet,", "tokens": ["So", "ward", "durch", "sie", "die", "neu\u00b7e", "Zeit", "ge\u00b7gr\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Uns aber, die wir stehn in ihrem Segen,", "tokens": ["Uns", "a\u00b7ber", ",", "die", "wir", "stehn", "in", "ih\u00b7rem", "Se\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PRELS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Uns ziemet Dank. Gott mit uns allerwegen!", "tokens": ["Uns", "zie\u00b7met", "Dank", ".", "Gott", "mit", "uns", "al\u00b7ler\u00b7we\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$.", "NN", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}