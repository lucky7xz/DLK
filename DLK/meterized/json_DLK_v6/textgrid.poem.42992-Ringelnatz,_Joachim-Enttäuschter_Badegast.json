{"textgrid.poem.42992": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Entt\u00e4uschter Badegast", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn ich im Badeanzug bin", "tokens": ["Wenn", "ich", "im", "Ba\u00b7de\u00b7an\u00b7zug", "bin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und im Familienbade,", "tokens": ["Und", "im", "Fa\u00b7mi\u00b7li\u00b7en\u00b7ba\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Geht die Erotik fort. Wohin", "tokens": ["Geht", "die", "E\u00b7ro\u00b7tik", "fort", ".", "Wo\u00b7hin"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$.", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wei\u00df Gott. Wie schade!", "tokens": ["Wei\u00df", "Gott", ".", "Wie", "scha\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$.", "PWAV", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Und Weiber jederlei Gestalt,", "tokens": ["Und", "Wei\u00b7ber", "je\u00b7der\u00b7lei", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie lassen alle dann mich kalt,", "tokens": ["Sie", "las\u00b7sen", "al\u00b7le", "dann", "mich", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie die verdammte Jauche", "tokens": ["Wie", "die", "ver\u00b7damm\u00b7te", "Jau\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der See, in die ich tauche,", "tokens": ["Der", "See", ",", "in", "die", "ich", "tau\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Kalt macht, speziell am Bauche.", "tokens": ["Kalt", "macht", ",", "spe\u00b7zi\u00b7ell", "am", "Bau\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "ADJD", "APPRART", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.3": {"line.1": {"text": "Von der Kabine bis ans Meer", "tokens": ["Von", "der", "Ka\u00b7bi\u00b7ne", "bis", "ans", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geniere ich mich immer sehr.", "tokens": ["Ge\u00b7nie\u00b7re", "ich", "mich", "im\u00b7mer", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Trotz Spucke und trotz Laufgeschwind", "tokens": ["Trotz", "Spu\u00b7cke", "und", "trotz", "Lauf\u00b7ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Merkt jede Frau und jedes Kind,", "tokens": ["Merkt", "je\u00b7de", "Frau", "und", "je\u00b7des", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df meine F\u00fc\u00dfe dreckig sind.", "tokens": ["Da\u00df", "mei\u00b7ne", "F\u00fc\u00b7\u00dfe", "dre\u00b7ckig", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und niemand fragt woher.", "tokens": ["Und", "nie\u00b7mand", "fragt", "wo\u00b7her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da\u00df jemanden, der nicht gut schwimmt,", "tokens": ["Da\u00df", "je\u00b7man\u00b7den", ",", "der", "nicht", "gut", "schwimmt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man den gar nicht mehr als Mann,", "tokens": ["Da\u00df", "man", "den", "gar", "nicht", "mehr", "als", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "ADV", "PTKNEG", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sondern als Tauchem\u00e4nnchen nimmt \u2013 \u2013", "tokens": ["Son\u00b7dern", "als", "Tau\u00b7che\u00b7m\u00e4nn\u00b7chen", "nimmt", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "NN", "VVFIN", "$(", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "So handeln Weiber, die bestimmt", "tokens": ["So", "han\u00b7deln", "Wei\u00b7ber", ",", "die", "be\u00b7stimmt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4ren, mich aufzuregen.", "tokens": ["W\u00e4\u00b7ren", ",", "mich", "auf\u00b7zu\u00b7re\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PPER", "VVIZU", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.6": {"line.1": {"text": "Mir schmeckt das Badewasser nie.", "tokens": ["Mir", "schmeckt", "das", "Ba\u00b7de\u00b7was\u00b7ser", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich denke immer an Pipi", "tokens": ["Ich", "den\u00b7ke", "im\u00b7mer", "an", "Pi\u00b7pi"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kann das auch belegen.", "tokens": ["Und", "kann", "das", "auch", "be\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PDS", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Es liegt mir fern, hier indiskret", "tokens": ["Es", "liegt", "mir", "fern", ",", "hier", "in\u00b7dis\u00b7kret"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Krampfadern aufzuw\u00fchlen,", "tokens": ["Kramp\u00b7fa\u00b7dern", "auf\u00b7zu\u00b7w\u00fch\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch jede Frau, die baden geht,", "tokens": ["Doch", "je\u00b7de", "Frau", ",", "die", "ba\u00b7den", "geht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wei\u00df nichts von meinen Gef\u00fchlen.", "tokens": ["Wei\u00df", "nichts", "von", "mei\u00b7nen", "Ge\u00b7f\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}