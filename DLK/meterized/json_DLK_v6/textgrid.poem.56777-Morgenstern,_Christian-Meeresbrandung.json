{"textgrid.poem.56777": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Meeresbrandung", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbwarrrrrrrte nur . . . . . . .", "tokens": ["\u00bb", "warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "wie viel schon ri\u00df ich ab von dir", "tokens": ["wie", "viel", "schon", "ri\u00df", "ich", "ab", "von", "dir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "seit den \u00c4onen unsres Kampfs \u2013", "tokens": ["seit", "den", "\u00c4\u00b7o\u00b7nen", "uns\u00b7res", "Kampfs", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "wie viele stolze Festen wird", "tokens": ["wie", "vie\u00b7le", "stol\u00b7ze", "Fes\u00b7ten", "wird"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mein Arm noch in die Tiefe ziehn \u2013", "tokens": ["mein", "Arm", "noch", "in", "die", "Tie\u00b7fe", "ziehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "zur\u00fcck und vor, zur\u00fcck und vor \u2013", "tokens": ["zu\u00b7r\u00fcck", "und", "vor", ",", "zu\u00b7r\u00fcck", "und", "vor", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKVZ", "KON", "PTKVZ", "$,", "PTKVZ", "KON", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "und immer vor mehr denn zur\u00fcck \u2013", "tokens": ["und", "im\u00b7mer", "vor", "mehr", "denn", "zu\u00b7r\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADV", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "und heute mild und morgen wild \u2013", "tokens": ["und", "heu\u00b7te", "mild", "und", "mor\u00b7gen", "wild", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KON", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "doch nimmer schwach und immer wach \u2013", "tokens": ["doch", "nim\u00b7mer", "schwach", "und", "im\u00b7mer", "wach", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.14": {"text": "umsonst dein D\u00e4mmen, Rammen, Baun,", "tokens": ["um\u00b7sonst", "dein", "D\u00e4m\u00b7men", ",", "Ram\u00b7men", ",", "Baun", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "NN", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "dein Wehr zerf\u00e4llt, ich habe Zeit \u2013", "tokens": ["dein", "Wehr", "zer\u00b7f\u00e4llt", ",", "ich", "ha\u00b7be", "Zeit", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "PPER", "VAFIN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "wenn erst der Mensch dich nicht mehr sch\u00fctzt \u2013", "tokens": ["wenn", "erst", "der", "Mensch", "dich", "nicht", "mehr", "sch\u00fctzt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "wer sch\u00fctzt, verloren Land, dich dann?", "tokens": ["wer", "sch\u00fctzt", ",", "ver\u00b7lo\u00b7ren", "Land", ",", "dich", "dann", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVPP", "NN", "$,", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "mein Reich ist nicht von seiner Zeit:", "tokens": ["mein", "Reich", "ist", "nicht", "von", "sei\u00b7ner", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "er stirbt, ich aber werde sein \u2013", "tokens": ["er", "stirbt", ",", "ich", "a\u00b7ber", "wer\u00b7de", "sein", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "ADV", "VAFIN", "PPOSAT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.23": {"text": "und will nicht ruhn, bis da\u00df du ganz", "tokens": ["und", "will", "nicht", "ruhn", ",", "bis", "da\u00df", "du", "ganz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PTKNEG", "VVINF", "$,", "KON", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "in meinen Grund gerissen bist \u2013", "tokens": ["in", "mei\u00b7nen", "Grund", "ge\u00b7ris\u00b7sen", "bist", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.26": {"text": "bis deiner h\u00f6chsten Firnen Schnee", "tokens": ["bis", "dei\u00b7ner", "h\u00f6chs\u00b7ten", "Fir\u00b7nen", "Schnee"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "von meinem Salz zerfressen schmilzt \u2013", "tokens": ["von", "mei\u00b7nem", "Salz", "zer\u00b7fres\u00b7sen", "schmilzt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "warrrrrrrte nur . . . . . . .", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.29": {"text": "und endlich nichts mehr ist als Ich", "tokens": ["und", "end\u00b7lich", "nichts", "mehr", "ist", "als", "Ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIS", "ADV", "VAFIN", "KOKOM", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "und Ich und Ich und Ich und Ich \u2013", "tokens": ["und", "Ich", "und", "Ich", "und", "Ich", "und", "Ich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "KON", "PPER", "KON", "PPER", "KON", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "warrrrrrrte nur . . . . . . .\u00ab", "tokens": ["warrrrrrr\u00b7te", "nur", ".", ".", ".", ".", ".", ".", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}}}}}