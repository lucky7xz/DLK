{"textgrid.poem.60675": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als einst ein Hirsch, verfolgt von scharfen Hunden,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als einst ein Hirsch, verfolgt von scharfen Hunden,", "tokens": ["Als", "einst", "ein", "Hirsch", ",", "ver\u00b7folgt", "von", "schar\u00b7fen", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Laube eines hohen Weinstocks Schutz gefunden", "tokens": ["Im", "Lau\u00b7be", "ei\u00b7nes", "ho\u00b7hen", "Wein\u00b7stocks", "Schutz", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u2013 Man findet solchen starken Rebenwuchs im S\u00fcden \u2013,", "tokens": ["\u2013", "Man", "fin\u00b7det", "sol\u00b7chen", "star\u00b7ken", "Re\u00b7ben\u00b7wuchs", "im", "S\u00fc\u00b7den", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIS", "VVFIN", "PIAT", "ADJA", "NN", "APPRART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vermuteten die J\u00e4ger, da\u00df der R\u00fcden", "tokens": ["Ver\u00b7mu\u00b7te\u00b7ten", "die", "J\u00e4\u00b7ger", ",", "da\u00df", "der", "R\u00fc\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sp\u00fcrende Schar diesmal im Irrtum sei,", "tokens": ["Sp\u00fc\u00b7ren\u00b7de", "Schar", "dies\u00b7mal", "im", "Irr\u00b7tum", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "APPRART", "NN", "VAFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "Und riefen sie, zum Gl\u00fcck", "tokens": ["Und", "rie\u00b7fen", "sie", ",", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Des Hirsches, barsch zur\u00fcck.", "tokens": ["Des", "Hir\u00b7sches", ",", "barsch", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Der nun begann, da er sich frei", "tokens": ["Der", "nun", "be\u00b7gann", ",", "da", "er", "sich", "frei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PRF", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und vor den Feinden sicher wu\u00dfte,", "tokens": ["Und", "vor", "den", "Fein\u00b7den", "si\u00b7cher", "wu\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Alsbald den Lebensretter abzuweiden.", "tokens": ["Als\u00b7bald", "den", "Le\u00b7bens\u00b7ret\u00b7ter", "ab\u00b7zu\u00b7wei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Man h\u00f6rt's und kehrt zur\u00fcck; er mu\u00dfte", "tokens": ["Man", "h\u00f6rt's", "und", "kehrt", "zu\u00b7r\u00fcck", ";", "er", "mu\u00df\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PTKVZ", "$.", "PPER", "VMFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Am selben Ort den Tod erleiden.", "tokens": ["Am", "sel\u00b7ben", "Ort", "den", "Tod", "er\u00b7lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbmich trifft gerechter Lohn,\u00ab rief er verendend aus,", "tokens": ["\u00bb", "mich", "trifft", "ge\u00b7rech\u00b7ter", "Lohn", ",", "\u00ab", "rief", "er", "ver\u00b7en\u00b7dend", "aus", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "NN", "$,", "$(", "VVFIN", "PPER", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u00bbwer Undank \u00fcbt, wie ich, zieh seine Lehre draus!\u00ab", "tokens": ["\u00bb", "wer", "Un\u00b7dank", "\u00fcbt", ",", "wie", "ich", ",", "zieh", "sei\u00b7ne", "Leh\u00b7re", "draus", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "NN", "VVFIN", "$,", "PWAV", "PPER", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "F\u00fcr solche, welche frevelnd ihr Asyl entweihen,", "tokens": ["F\u00fcr", "sol\u00b7che", ",", "wel\u00b7che", "fre\u00b7velnd", "ihr", "A\u00b7syl", "ent\u00b7wei\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "$,", "PRELS", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist dies ein wahres Bild. F\u00fcr sie gibt's kein Verzeihen.", "tokens": ["Ist", "dies", "ein", "wah\u00b7res", "Bild", ".", "F\u00fcr", "sie", "gibt's", "kein", "Ver\u00b7zei\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$.", "APPR", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}