{"textgrid.poem.62193": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "[deutsche Bildung, deutsche Sitte]", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Deutsche Bildung, deutsche Sitte,", "tokens": ["Deut\u00b7sche", "Bil\u00b7dung", ",", "deut\u00b7sche", "Sit\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deutsche Hetze, Kampfkultur,", "tokens": ["Deut\u00b7sche", "Het\u00b7ze", ",", "Kampf\u00b7kul\u00b7tur", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kultivierte K\u00e4mpfe nur,", "tokens": ["Kul\u00b7ti\u00b7vier\u00b7te", "K\u00e4mp\u00b7fe", "nur", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Humanisten, schweigt, ich bitte,", "tokens": ["Hu\u00b7ma\u00b7nis\u00b7ten", ",", "schweigt", ",", "ich", "bit\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn im goldnen Reich der Mitte", "tokens": ["Denn", "im", "gold\u00b7nen", "Reich", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist von Hetze keine Spur,", "tokens": ["Ist", "von", "Het\u00b7ze", "kei\u00b7ne", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und ob solcher Unnatur,", "tokens": ["Und", "ob", "sol\u00b7cher", "Un\u00b7na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Lacht Franzose, D\u00e4ne, Britte.", "tokens": ["Lacht", "Fran\u00b7zo\u00b7se", ",", "D\u00e4\u00b7ne", ",", "Brit\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "NE", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Gro\u00dfer Friedrich, armer Kant,", "tokens": ["Gro\u00b7\u00dfer", "Fried\u00b7rich", ",", "ar\u00b7mer", "Kant", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leibniz, Lessing, Hufeland,", "tokens": ["Leib\u00b7niz", ",", "Les\u00b7sing", ",", "Hu\u00b7fe\u00b7land", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "J\u00e4h vergessen von der Welt,", "tokens": ["J\u00e4h", "ver\u00b7ges\u00b7sen", "von", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn Sophist und K\u00f6ter bellt", "tokens": ["Wenn", "So\u00b7phist", "und", "K\u00f6\u00b7ter", "bellt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wird das deutsche Vaterland", "tokens": ["Wird", "das", "deut\u00b7sche", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gar mit Ru\u00dfland gleichgestellt.", "tokens": ["Gar", "mit", "Ru\u00df\u00b7land", "gleich\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}