{"dta.poem.10800": {"metadata": {"author": {"name": "Ebeling, Johann Justus", "birth": "N.A.", "death": "N.A."}, "title": "Moralische Betrachtung \u00fcber  \n den Schnee.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1747", "urn": "urn:nbn:de:kobv:b4-200905198774", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da ich im lichten Glanz aus der beflok-\nten H\u00f6h,", "tokens": ["Da", "ich", "im", "lich\u00b7ten", "Glanz", "aus", "der", "be\u00b7flo\u00b7k", "ten", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "APPR", "ART", "TRUNC", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Vom Himmels-Strahl bef\u00e4rbt", "tokens": ["Vom", "Him\u00b7mels\u00b7Strahl", "be\u00b7f\u00e4rbt"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der als ein schwarzer Koth, wie", "tokens": ["Der", "als", "ein", "schwar\u00b7zer", "Koth", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "KOUS", "ART", "ADJA", "NN", "$,", "PWAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wird durch dem Wunderblik ein Andachtsfeur er-", "tokens": ["Wird", "durch", "dem", "Wun\u00b7derb\u00b7lik", "ein", "An\u00b7dachts\u00b7feur", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich f\u00fchle einen Trieb da ich vom S\u00fcnden roth,", "tokens": ["Ich", "f\u00fch\u00b7le", "ei\u00b7nen", "Trieb", "da", "ich", "vom", "S\u00fcn\u00b7den", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KOUS", "PPER", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Beflekt an Seel und Leib, vom schwarzen Laster-", "tokens": ["Be\u00b7flekt", "an", "Seel", "und", "Leib", ",", "vom", "schwar\u00b7zen", "Las\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$,", "APPRART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So wei\u00df als Schnee zu seyn. Wie werd ich das", "tokens": ["So", "wei\u00df", "als", "Schnee", "zu", "seyn", ".", "Wie", "werd", "ich", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KOKOM", "NN", "PTKZU", "VAINF", "$.", "PWAV", "VAFIN", "PPER", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df ich mit reinem Herz in Unschuld k\u00f6nne pran-", "tokens": ["Da\u00df", "ich", "mit", "rei\u00b7nem", "Herz", "in", "Un\u00b7schuld", "k\u00f6n\u00b7ne", "pran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "APPR", "NN", "VMFIN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie wasch ich mich gleich jezt mit Schnee Gew\u00e4s-", "tokens": ["Wie", "wasch", "ich", "mich", "gleich", "jezt", "mit", "Schnee", "Ge\u00b7w\u00e4s"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PPER", "PRF", "ADV", "ADV", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "So werd ich doch vor ", "tokens": ["So", "werd", "ich", "doch", "vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "Der S\u00fcnden Aussaz bleibt. Jedoch wenn ich be-", "tokens": ["Der", "S\u00fcn\u00b7den", "Aus\u00b7saz", "bleibt", ".", "Je\u00b7doch", "wenn", "ich", "be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "ADV", "KOUS", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Da\u00df schimmerreicher Schnee ein himmlisches Ge-", "tokens": ["Da\u00df", "schim\u00b7mer\u00b7rei\u00b7cher", "Schnee", "ein", "himm\u00b7li\u00b7sches", "Ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "So lehrt mich dieses auch, da\u00df ich nur werde", "tokens": ["So", "lehrt", "mich", "die\u00b7ses", "auch", ",", "da\u00df", "ich", "nur", "wer\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "$,", "KOUS", "PPER", "ADV", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Von dem Gewissens Schmuz durch ", "tokens": ["Von", "dem", "Ge\u00b7wis\u00b7sens", "Schmuz", "durch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Ich wende mich zu dir, HErr Himmels und der Er-", "tokens": ["Ich", "wen\u00b7de", "mich", "zu", "dir", ",", "Herr", "Him\u00b7mels", "und", "der", "Er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "$,", "NN", "NN", "KON", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Durch dich kan jeder Mensch der Blutroth Schneewei\u00df", "tokens": ["Durch", "dich", "kan", "je\u00b7der", "Mensch", "der", "Blut\u00b7roth", "Schnee\u00b7wei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VMFIN", "PIAT", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Ich traue deinem Wort, ich kom in Bu\u00df zu dir,", "tokens": ["Ich", "trau\u00b7e", "dei\u00b7nem", "Wort", ",", "ich", "kom", "in", "Bu\u00df", "zu", "dir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ich nehme Christi Blut, das reinigt f\u00fcr und f\u00fcr.", "tokens": ["Ich", "neh\u00b7me", "Chris\u00b7ti", "Blut", ",", "das", "rei\u00b7nigt", "f\u00fcr", "und", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "$,", "PDS", "VVFIN", "APPR", "KON", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wollan ich bin nun rein, in der Erl\u00f6\u00dften Or-", "tokens": ["Wol\u00b7lan", "ich", "bin", "nun", "rein", ",", "in", "der", "Er\u00b7l\u00f6\u00df\u00b7ten", "Or"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VAFIN", "ADV", "ADJD", "$,", "APPR", "ART", "ADJA", "TRUNC"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.20": {"text": "Durch deiner Gnaden Licht so weis als Schnee ge-", "tokens": ["Durch", "dei\u00b7ner", "Gna\u00b7den", "Licht", "so", "weis", "als", "Schnee", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "ADV", "PTKVZ", "KOKOM", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Und leb ich ferner from, da die Gerechtigkeit", "tokens": ["Und", "leb", "ich", "fer\u00b7ner", "from", ",", "da", "die", "Ge\u00b7rech\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Des Heilands, mich geschm\u00fckt mit seinem Unschulds-", "tokens": ["Des", "Hei\u00b7lands", ",", "mich", "ge\u00b7schm\u00fckt", "mit", "sei\u00b7nem", "Un\u00b7schulds"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PPER", "VVPP", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "So ist mein ganzes Thun, als unbeflekt zu se-", "tokens": ["So", "ist", "mein", "gan\u00b7zes", "Thun", ",", "als", "un\u00b7be\u00b7flekt", "zu", "se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "ADJD", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So wird mein Tugendschein mich vor der Welt er", "tokens": ["So", "wird", "mein", "Tu\u00b7gend\u00b7schein", "mich", "vor", "der", "Welt", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Allein bewahre mich vor aller Prahlerei,", "tokens": ["Al\u00b7lein", "be\u00b7wah\u00b7re", "mich", "vor", "al\u00b7ler", "Prah\u00b7le\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Fl\u00f6\u00df mir stets in den Sinn da\u00df ich ein Mensche", "tokens": ["Fl\u00f6\u00df", "mir", "stets", "in", "den", "Sinn", "da\u00df", "ich", "ein", "Men\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "APPR", "ART", "NN", "KOUS", "PPER", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.27": {"text": "Ein schwarzer Erdenklos, ein Schneeklump der nicht", "tokens": ["Ein", "schwar\u00b7zer", "Er\u00b7denk\u00b7los", ",", "ein", "Schnee\u00b7klump", "der", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "PTKNEG"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.28": {"text": "Wenn ihn des Himmels Licht mit seinen Schein nicht", "tokens": ["Wenn", "ihn", "des", "Him\u00b7mels", "Licht", "mit", "sei\u00b7nen", "Schein", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Jhr Heuchler die ihr euch bei euren Glanz nicht", "tokens": ["Ihr", "Heuch\u00b7ler", "die", "ihr", "euch", "bei", "eu\u00b7ren", "Glanz", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "PPER", "PRF", "APPR", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Und von gemahlten Licht zwar scheinet, doch nicht", "tokens": ["Und", "von", "ge\u00b7mahl\u00b7ten", "Licht", "zwar", "schei\u00b7net", ",", "doch", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "ADV", "VVFIN", "$,", "ADV", "PTKNEG"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.31": {"text": "Jhr prahlet nur umsonst mit euren Glanz und Ga-", "tokens": ["Ihr", "prah\u00b7let", "nur", "um\u00b7sonst", "mit", "eu\u00b7ren", "Glanz", "und", "Ga"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Bedenkt woher wir das, was gut empfangen ha-", "tokens": ["Be\u00b7denkt", "wo\u00b7her", "wir", "das", ",", "was", "gut", "emp\u00b7fan\u00b7gen", "ha"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PWAV", "PPER", "PDS", "$,", "PRELS", "ADJD", "VVPP", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ist es nicht von dem HErrn dem Vater alles Lichts?", "tokens": ["Ist", "es", "nicht", "von", "dem", "Herrn", "dem", "Va\u00b7ter", "al\u00b7les", "Lichts", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.34": {"text": "Ohn dessen Gnaden-Schein, sind wir ein Dunst,", "tokens": ["Ohn", "des\u00b7sen", "Gna\u00b7den\u00b7Schein", ",", "sind", "wir", "ein", "Dunst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "$,", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Seht euer Ebenbild, das ist im Schnee gedr\u00fckket,", "tokens": ["Seht", "eu\u00b7er", "E\u00b7ben\u00b7bild", ",", "das", "ist", "im", "Schnee", "ge\u00b7dr\u00fck\u00b7ket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Den wir so gleissend sch\u00f6n vor kurzer Zeit erblikket,", "tokens": ["Den", "wir", "so", "gleis\u00b7send", "sch\u00f6n", "vor", "kur\u00b7zer", "Zeit", "er\u00b7blik\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Wie sieht er nunmehr aus, er ist beschmuzt, be-", "tokens": ["Wie", "sieht", "er", "nun\u00b7mehr", "aus", ",", "er", "ist", "be\u00b7schmuzt", ",", "be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "PPER", "VAFIN", "VVPP", "$,", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.38": {"text": "Sein reiner Schweffel Stoff mit schwarzen Koth", "tokens": ["Sein", "rei\u00b7ner", "Schwef\u00b7fel", "Stoff", "mit", "schwar\u00b7zen", "Koth"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Jhr schienet auch so sch\u00f6n, der Glanz der ist ver-", "tokens": ["Ihr", "schie\u00b7net", "auch", "so", "sch\u00f6n", ",", "der", "Glanz", "der", "ist", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "$,", "ART", "NN", "ART", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Eur gl\u00e4nzend Unschulds-Kleid hat Flekken gnug er-", "tokens": ["Eur", "gl\u00e4n\u00b7zend", "Un\u00b7schulds\u00b7Kleid", "hat", "Flek\u00b7ken", "gnug", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "VAFIN", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.41": {"text": "Der Schnee zerschmelzzet leicht, und seine weisse", "tokens": ["Der", "Schnee", "zer\u00b7schmelz\u00b7zet", "leicht", ",", "und", "sei\u00b7ne", "weis\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.42": {"text": "Kommt uns denn wie ein Koth und sch\u00e4umend Un-", "tokens": ["Kommt", "uns", "denn", "wie", "ein", "Koth", "und", "sch\u00e4u\u00b7mend", "Un"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "KOKOM", "ART", "NN", "KON", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "So geht es Heuchlern auch so bald am Licht der", "tokens": ["So", "geht", "es", "Heuch\u00b7lern", "auch", "so", "bald", "am", "Licht", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "APPRART", "NN", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "Der angeschminkte Kalk der Fr\u00f6mmigkeit zerron-", "tokens": ["Der", "an\u00b7ge\u00b7schmink\u00b7te", "Kalk", "der", "Fr\u00f6m\u00b7mig\u00b7keit", "zer\u00b7ron"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}