{"dta.poem.23589": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Papier ohne Ende.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1840", "urn": "urn:nbn:de:kobv:b4-200905192626", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Durch Papier bestehen wir:", "tokens": ["Durch", "Pa\u00b7pier", "be\u00b7ste\u00b7hen", "wir", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Menschenherrschaft ist Papier.", "tokens": ["Men\u00b7schen\u00b7herr\u00b7schaft", "ist", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, Papier sind alle Pacte,", "tokens": ["Ja", ",", "Pa\u00b7pier", "sind", "al\u00b7le", "Pac\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch sogar die Bundesacte,", "tokens": ["Auch", "so\u00b7gar", "die", "Bun\u00b7de\u00b7sac\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alles, alles ist Papier.", "tokens": ["Al\u00b7les", ",", "al\u00b7les", "ist", "Pa\u00b7pier", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PIS", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Durch Papier bestehen wir:", "tokens": ["Durch", "Pa\u00b7pier", "be\u00b7ste\u00b7hen", "wir", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gottes Wort ist auch Papier,", "tokens": ["Got\u00b7tes", "Wort", "ist", "auch", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn Papier ist Glaub' und Fibel,", "tokens": ["Denn", "Pa\u00b7pier", "ist", "Glaub'", "und", "Fi\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Auch sogar die ganze Bibel,", "tokens": ["Auch", "so\u00b7gar", "die", "gan\u00b7ze", "Bi\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alles, alles ist Papier.", "tokens": ["Al\u00b7les", ",", "al\u00b7les", "ist", "Pa\u00b7pier", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PIS", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Durch Papier bestehen wir:", "tokens": ["Durch", "Pa\u00b7pier", "be\u00b7ste\u00b7hen", "wir", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lasst uns achten das Papier,", "tokens": ["Lasst", "uns", "ach\u00b7ten", "das", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seine Ahnen auch die Lumpen", "tokens": ["Sei\u00b7ne", "Ah\u00b7nen", "auch", "die", "Lum\u00b7pen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehr als Gold und Silberklumpen,", "tokens": ["Mehr", "als", "Gold", "und", "Sil\u00b7ber\u00b7klum\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn ohn' End' ist das Papier.", "tokens": ["Denn", "ohn'", "End'", "ist", "das", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch was sind am Ende ", "tokens": ["Doch", "was", "sind", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "APPRART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "W\u00e4ren wir doch nur Papier!", "tokens": ["W\u00e4\u00b7ren", "wir", "doch", "nur", "Pa\u00b7pier", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn der j\u00fcngste Tag sich f\u00e4nde", "tokens": ["Wenn", "der", "j\u00fcngs\u00b7te", "Tag", "sich", "f\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PRF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wenn Alles n\u00e4hm' ein Ende,", "tokens": ["Und", "wenn", "Al\u00b7les", "n\u00e4hm'", "ein", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Blieben doch am Ende wir.", "tokens": ["Blie\u00b7ben", "doch", "am", "En\u00b7de", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}