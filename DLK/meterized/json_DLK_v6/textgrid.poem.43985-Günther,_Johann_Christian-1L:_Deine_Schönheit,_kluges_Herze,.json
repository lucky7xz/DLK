{"textgrid.poem.43985": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Deine Sch\u00f6nheit, kluges Herze,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Deine Sch\u00f6nheit, kluges Herze,", "tokens": ["Dei\u00b7ne", "Sch\u00f6n\u00b7heit", ",", "klu\u00b7ges", "Her\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist kein schlecht und fl\u00fcchtig Gut,", "tokens": ["Ist", "kein", "schlecht", "und", "fl\u00fcch\u00b7tig", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJD", "KON", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das uns mit verbothnem Scherze", "tokens": ["Das", "uns", "mit", "ver\u00b7both\u00b7nem", "Scher\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu den S\u00fcnden Vorschub thut,", "tokens": ["Zu", "den", "S\u00fcn\u00b7den", "Vor\u00b7schub", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn sich unsrer L\u00fcste Kraft", "tokens": ["Wenn", "sich", "uns\u00b7rer", "L\u00fcs\u00b7te", "Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "An geschminckter Haut vergaft.", "tokens": ["An", "ge\u00b7schminck\u00b7ter", "Haut", "ver\u00b7gaft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Da ich dich recht kennen lerne,", "tokens": ["Da", "ich", "dich", "recht", "ken\u00b7nen", "ler\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Klag ich meine Thorheit an,", "tokens": ["Klag", "ich", "mei\u00b7ne", "Thor\u00b7heit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die bey manchem Ungl\u00fcckssterne", "tokens": ["Die", "bey", "man\u00b7chem", "Un\u00b7gl\u00fccks\u00b7ster\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mir die Augen aufgethan", "tokens": ["Mir", "die", "Au\u00b7gen", "auf\u00b7ge\u00b7than"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die Bl\u00fcthen junger Zeit", "tokens": ["Und", "die", "Bl\u00fc\u00b7then", "jun\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Mancher Delila geweiht.", "tokens": ["Man\u00b7cher", "De\u00b7li\u00b7la", "ge\u00b7weiht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Deine rein- und wahre Liebe", "tokens": ["Dei\u00b7ne", "rein", "und", "wah\u00b7re", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "TRUNC", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Macht den Anfang meiner Reu.", "tokens": ["Macht", "den", "An\u00b7fang", "mei\u00b7ner", "Reu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Packt euch fort, ihr b\u00f6sen Triebe", "tokens": ["Packt", "euch", "fort", ",", "ihr", "b\u00f6\u00b7sen", "Trie\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der verbuhlten Tyranney!", "tokens": ["Der", "ver\u00b7buhl\u00b7ten", "Ty\u00b7ran\u00b7ney", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Marianens Tugendglanz", "tokens": ["Ma\u00b7ri\u00b7a\u00b7nens", "Tu\u00b7gend\u00b7glanz"], "token_info": ["word", "word"], "pos": ["NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Windet mir den Unschuldskranz.", "tokens": ["Win\u00b7det", "mir", "den", "Un\u00b7schulds\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Dies Gem\u00fcthe soll auf Erden", "tokens": ["Dies", "Ge\u00b7m\u00fc\u00b7the", "soll", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meines Ehstands Himmel seyn", "tokens": ["Mei\u00b7nes", "Eh\u00b7stands", "Him\u00b7mel", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mir unter viel Beschwerden", "tokens": ["Und", "mir", "un\u00b7ter", "viel", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zuflucht, Rath und Trost verleihn,", "tokens": ["Zu\u00b7flucht", ",", "Rath", "und", "Trost", "ver\u00b7leihn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bis ihr treuer Abschiedsku\u00df", "tokens": ["Bis", "ihr", "treu\u00b7er", "Ab\u00b7schieds\u00b7ku\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch den Tod erleichtern mu\u00df.", "tokens": ["Auch", "den", "Tod", "er\u00b7leich\u00b7tern", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach, was bl\u00fcht mir vor ein Gl\u00fccke,", "tokens": ["Ach", ",", "was", "bl\u00fcht", "mir", "vor", "ein", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da mich so ein ehrlich Kind", "tokens": ["Da", "mich", "so", "ein", "ehr\u00b7lich", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJD", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Unter Feinden, Gram und T\u00fccke", "tokens": ["Un\u00b7ter", "Fein\u00b7den", ",", "Gram", "und", "T\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sonder Eigennuz gewinnt;", "tokens": ["Son\u00b7der", "Ei\u00b7gen\u00b7nuz", "ge\u00b7winnt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da sie mir den Schwur gethan,", "tokens": ["Da", "sie", "mir", "den", "Schwur", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Fang ich erst zu leben an.", "tokens": ["Fang", "ich", "erst", "zu", "le\u00b7ben", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Nehmt, ihr Stunden, nehmt doch Fl\u00fcgel,", "tokens": ["Nehmt", ",", "ihr", "Stun\u00b7den", ",", "nehmt", "doch", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "N\u00e4hert mir das holde Licht,", "tokens": ["N\u00e4\u00b7hert", "mir", "das", "hol\u00b7de", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das mir auf der Lippen Siegel", "tokens": ["Das", "mir", "auf", "der", "Lip\u00b7pen", "Sie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "V\u00f6lligen Besiz verspricht;", "tokens": ["V\u00f6l\u00b7li\u00b7gen", "Be\u00b7siz", "ver\u00b7spricht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Melde dich, gew\u00fcntschter Tag,", "tokens": ["Mel\u00b7de", "dich", ",", "ge\u00b7w\u00fcnt\u00b7schter", "Tag", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da die Keuschheit scherzen mag.", "tokens": ["Da", "die", "Keuschheit", "scher\u00b7zen", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "ART", "NN", "VVFIN", "NE"], "meter": "--++-", "measure": "anapaest.init"}}, "stanza.7": {"line.1": {"text": "Warthe nur, du sch\u00f6ner Engel,", "tokens": ["Wart\u00b7he", "nur", ",", "du", "sch\u00f6\u00b7ner", "En\u00b7gel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit gela\u00dfner Zuversicht!", "tokens": ["Mit", "ge\u00b7la\u00df\u00b7ner", "Zu\u00b7ver\u00b7sicht", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hab ich als ein Mensch gleich M\u00e4ngel", "tokens": ["Hab", "ich", "als", "ein", "Mensch", "gleich", "M\u00e4n\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "KOUS", "ART", "NN", "ADV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab ich doch die Falschheit nicht;", "tokens": ["Hab", "ich", "doch", "die", "Falschheit", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gottes Aug und meine Hand", "tokens": ["Got\u00b7tes", "Aug", "und", "mei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "B\u00fcrgen vor den Unbestand.", "tokens": ["B\u00fcr\u00b7gen", "vor", "den", "Un\u00b7be\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sollt ich auch in schlechten H\u00fctten", "tokens": ["Sollt", "ich", "auch", "in", "schlech\u00b7ten", "H\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mich um Salz und Brodt bem\u00fchn,", "tokens": ["Mich", "um", "Salz", "und", "Brodt", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird der Umgang deiner Sitten", "tokens": ["Wird", "der", "Um\u00b7gang", "dei\u00b7ner", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dennoch mich zur Wollust ziehn;", "tokens": ["Den\u00b7noch", "mich", "zur", "Wol\u00b7lust", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die Gesellschaft deiner Brust", "tokens": ["Die", "Ge\u00b7sell\u00b7schaft", "dei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht die gr\u00f6ste Noth zur Lust.", "tokens": ["Macht", "die", "gr\u00f6s\u00b7te", "Noth", "zur", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Meine Freundin, meine Taube,", "tokens": ["Mei\u00b7ne", "Freun\u00b7din", ",", "mei\u00b7ne", "Tau\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine Schwester, ja mein Ich,", "tokens": ["Mei\u00b7ne", "Schwes\u00b7ter", ",", "ja", "mein", "Ich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "PPOSAT", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liebe, leide, schweig und glaube,", "tokens": ["Lie\u00b7be", ",", "lei\u00b7de", ",", "schweig", "und", "glau\u00b7be", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Verh\u00e4ngn\u00fc\u00df be\u00dfert sich,", "tokens": ["Das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "be\u00b7\u00dfert", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und sein Rathschlu\u00df cr\u00f6nt forthin", "tokens": ["Und", "sein", "Rath\u00b7schlu\u00df", "cr\u00f6nt", "for\u00b7thin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kurze Qual mit viel Gewinn.", "tokens": ["Kur\u00b7ze", "Qual", "mit", "viel", "Ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}