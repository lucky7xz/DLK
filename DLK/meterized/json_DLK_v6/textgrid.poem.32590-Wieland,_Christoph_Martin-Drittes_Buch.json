{"textgrid.poem.32590": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "Drittes Buch", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Sch\u00f6ne lag auf ihrem Ruhebette,", "tokens": ["Die", "Sch\u00f6\u00b7ne", "lag", "auf", "ih\u00b7rem", "Ru\u00b7he\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und hatte (fern, vermutlich, vom Verdacht", "tokens": ["Und", "hat\u00b7te", "(", "fern", ",", "ver\u00b7mut\u00b7lich", ",", "vom", "Ver\u00b7dacht"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "$(", "ADJD", "$,", "ADJD", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df sie bei Phanias sich vorzusehen h\u00e4tte)", "tokens": ["Da\u00df", "sie", "bei", "Pha\u00b7ni\u00b7as", "sich", "vor\u00b7zu\u00b7se\u00b7hen", "h\u00e4t\u00b7te", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "PRF", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr M\u00e4dchen fortgeschickt. Es war nach Mitternacht;", "tokens": ["Ihr", "M\u00e4d\u00b7chen", "fort\u00b7ge\u00b7schickt", ".", "Es", "war", "nach", "Mit\u00b7ter\u00b7nacht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$.", "PPER", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein leicht Gew\u00f6lke brach des Mondes Silberschimmer,", "tokens": ["Ein", "leicht", "Ge\u00b7w\u00f6l\u00b7ke", "brach", "des", "Mon\u00b7des", "Sil\u00b7ber\u00b7schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und alles schlief: als pl\u00f6tzlich, wie ihr deucht,", "tokens": ["Und", "al\u00b7les", "schlief", ":", "als", "pl\u00f6tz\u00b7lich", ",", "wie", "ihr", "deucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "KOUS", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Den Gang herauf zu ihrem kleinen Zimmer", "tokens": ["Den", "Gang", "her\u00b7auf", "zu", "ih\u00b7rem", "klei\u00b7nen", "Zim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Mit leisem Tritt \u2013 ich wei\u00df nicht was sich schleicht.", "tokens": ["Mit", "lei\u00b7sem", "Tritt", "\u2013", "ich", "wei\u00df", "nicht", "was", "sich", "schleicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "PRELS", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sie stutzt. Was kann es sein? Ein Geist, nach seinen Tritten \u2013", "tokens": ["Sie", "stutzt", ".", "Was", "kann", "es", "sein", "?", "Ein", "Geist", ",", "nach", "sei\u00b7nen", "Trit\u00b7ten", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "VMFIN", "PPER", "VAINF", "$.", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Besuch von einem Geist! den wollt ich sehr verbitten,", "tokens": ["Be\u00b7such", "von", "ei\u00b7nem", "Geist", "!", "den", "wollt", "ich", "sehr", "ver\u00b7bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "ART", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Denkt sie. Indem er\u00f6ffnet sich die T\u00fcr,", "tokens": ["Denkt", "sie", ".", "In\u00b7dem", "er\u00b7\u00f6ff\u00b7net", "sich", "die", "T\u00fcr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und eh sie's ausgedacht, steht \u2013 Phanias vor ihr.", "tokens": ["Und", "eh", "sie's", "aus\u00b7ge\u00b7dacht", ",", "steht", "\u2013", "Pha\u00b7ni\u00b7as", "vor", "ihr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "$,", "VVFIN", "$(", "NE", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "\u00bbvergib, Musarion, vergib, (so fing der Bl\u00f6de", "tokens": ["\u00bb", "ver\u00b7gib", ",", "Mu\u00b7sa\u00b7ri\u00b7on", ",", "ver\u00b7gib", ",", "(", "so", "fing", "der", "Bl\u00f6\u00b7de"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVIMP", "$,", "NN", "$,", "VVIMP", "$,", "$(", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu stottern an) die Zeit ist unbequem \u2013", "tokens": ["Zu", "stot\u00b7tern", "an", ")", "die", "Zeit", "ist", "un\u00b7be\u00b7quem", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "PTKVZ", "$(", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Allein\u00ab \u2013 \u00bbWozu\u00ab, fiel ihm die Freundin in die Rede,", "tokens": ["Al\u00b7lein", "\u00ab", "\u2013", "\u00bb", "Wo\u00b7zu", "\u00ab", ",", "fiel", "ihm", "die", "Freun\u00b7din", "in", "die", "Re\u00b7de", ","], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "$(", "$(", "PWAV", "$(", "$,", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u00bbwozu ein Vorbericht? Wenn war ich eine Spr\u00f6de?", "tokens": ["\u00bb", "wo\u00b7zu", "ein", "Vor\u00b7be\u00b7richt", "?", "Wenn", "war", "ich", "ei\u00b7ne", "Spr\u00f6\u00b7de", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ART", "NN", "$.", "KOUS", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Freund ist auch zur Unzeit angenehm:", "tokens": ["Ein", "Freund", "ist", "auch", "zur", "Un\u00b7zeit", "an\u00b7ge\u00b7nehm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Er hat uns immer was, das uns gef\u00e4llt, zu sagen.\u00ab", "tokens": ["Er", "hat", "uns", "im\u00b7mer", "was", ",", "das", "uns", "ge\u00b7f\u00e4llt", ",", "zu", "sa\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PIS", "$,", "PRELS", "PPER", "VVPP", "$,", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "\u00bbdein Ton (erwidert er) beweist,", "tokens": ["\u00bb", "dein", "Ton", "(", "er\u00b7wi\u00b7dert", "er", ")", "be\u00b7weist", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$(", "VVFIN", "PPER", "$(", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie wenig dieser Schein von G\u00fcte meinen Klagen", "tokens": ["Wie", "we\u00b7nig", "die\u00b7ser", "Schein", "von", "G\u00fc\u00b7te", "mei\u00b7nen", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PDAT", "NN", "APPR", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mitleidiges Gef\u00fchl verhei\u00dft.", "tokens": ["Mit\u00b7lei\u00b7di\u00b7ges", "Ge\u00b7f\u00fchl", "ver\u00b7hei\u00dft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du siehst mein Innerstes, und kannst mich l\u00e4chelnd plagen?", "tokens": ["Du", "siehst", "mein", "In\u00b7ners\u00b7tes", ",", "und", "kannst", "mich", "l\u00e4\u00b7chelnd", "pla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VMFIN", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Siehst, da\u00df ein Augenblick mir hundert Jahre scheint,", "tokens": ["Siehst", ",", "da\u00df", "ein", "Au\u00b7gen\u00b7blick", "mir", "hun\u00b7dert", "Jah\u00b7re", "scheint", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PPER", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und findest noch ein grausames Behagen", "tokens": ["Und", "fin\u00b7dest", "noch", "ein", "grau\u00b7sa\u00b7mes", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "An meiner Qual? Du treibst mich zum Verzagen,", "tokens": ["An", "mei\u00b7ner", "Qual", "?", "Du", "treibst", "mich", "zum", "Ver\u00b7za\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Kaltsinnige, und nennst mich deinen Freund?", "tokens": ["Kalts\u00b7in\u00b7ni\u00b7ge", ",", "und", "nennst", "mich", "dei\u00b7nen", "Freund", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wie grausam r\u00e4chst du dich!\u00ab \u2013", "tokens": ["Wie", "grau\u00b7sam", "r\u00e4chst", "du", "dich", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PRF", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbich?\u00ab \u2013 f\u00e4llt sie ein, \u00bbmich r\u00e4chen?", "tokens": ["\u00bb", "ich", "?", "\u00ab", "\u2013", "f\u00e4llt", "sie", "ein", ",", "\u00bb", "mich", "r\u00e4\u00b7chen", "?"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "$.", "$(", "$(", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Tr\u00e4umt Phanias? \u2013 Er liebte mich vordem;", "tokens": ["Tr\u00e4umt", "Pha\u00b7ni\u00b7as", "?", "\u2013", "Er", "lieb\u00b7te", "mich", "vor\u00b7dem", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "$(", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er h\u00f6rte wieder auf! War ", "tokens": ["Er", "h\u00f6r\u00b7te", "wie\u00b7der", "auf", "!", "War"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$.", "VAFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "War's ", "tokens": ["Wa\u00b7r's"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Wir M\u00e4dchen sehn doch immer mit Vergn\u00fcgen", "tokens": ["Wir", "M\u00e4d\u00b7chen", "sehn", "doch", "im\u00b7mer", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VVFIN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Weisheit eines Manns zu unsern F\u00fc\u00dfen liegen.", "tokens": ["Die", "Weis\u00b7heit", "ei\u00b7nes", "Manns", "zu", "un\u00b7sern", "F\u00fc\u00b7\u00dfen", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Allein, als Freundin s\u00e4h ich dich", "tokens": ["Al\u00b7lein", ",", "als", "Freun\u00b7din", "s\u00e4h", "ich", "dich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "NN", "VVFIN", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Noch lieber kalt f\u00fcr mich \u2013 als l\u00e4cherlich.\u00ab", "tokens": ["Noch", "lie\u00b7ber", "kalt", "f\u00fcr", "mich", "\u2013", "als", "l\u00e4\u00b7cher\u00b7lich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPR", "PPER", "$(", "KOUS", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "\u00bbwie du mich martern kannst, Musarion! Viel lieber", "tokens": ["\u00bb", "wie", "du", "mich", "mar\u00b7tern", "kannst", ",", "Mu\u00b7sa\u00b7ri\u00b7on", "!", "Viel", "lie\u00b7ber"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "PWAV", "PPER", "PRF", "VVINF", "VMFIN", "$,", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sto\u00df einen Dolch in dieses Herz, das du", "tokens": ["Sto\u00df", "ei\u00b7nen", "Dolch", "in", "die\u00b7ses", "Herz", ",", "das", "du"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "PDAT", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nicht gl\u00fccklich machen willst!\u00ab \u2013", "tokens": ["Nicht", "gl\u00fcck\u00b7lich", "ma\u00b7chen", "willst", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKNEG", "ADJD", "VVINF", "VMFIN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbnichts tragisches, mein Lieber!", "tokens": ["\u00bb", "nichts", "tra\u00b7gi\u00b7sches", ",", "mein", "Lie\u00b7ber", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PIS", "ADJA", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Komm, setze dich gelassen gegen \u00fcber,", "tokens": ["Komm", ",", "set\u00b7ze", "dich", "ge\u00b7las\u00b7sen", "ge\u00b7gen", "\u00fc\u00b7ber", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "VVPP", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und sag uns im Vertraun, wie viel geh\u00f6rt dazu,", "tokens": ["Und", "sag", "uns", "im", "Ver\u00b7traun", ",", "wie", "viel", "ge\u00b7h\u00f6rt", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$,", "PWAV", "PIS", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Damit ich dich so gl\u00fccklich mache", "tokens": ["Da\u00b7mit", "ich", "dich", "so", "gl\u00fcck\u00b7lich", "ma\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als du verlangst?\u00ab \u2013 \u00bbMich lieben, wie ich dich!\u00ab \u2013", "tokens": ["Als", "du", "ver\u00b7langst", "?", "\u00ab", "\u2013", "\u00bb", "Mich", "lie\u00b7ben", ",", "wie", "ich", "dich", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "$(", "$(", "$(", "PPER", "VVFIN", "$,", "PWAV", "PPER", "PRF", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbso liebt mich Phanias, der noch so k\u00fcrzlich mich", "tokens": ["\u00bb", "so", "liebt", "mich", "Pha\u00b7ni\u00b7as", ",", "der", "noch", "so", "k\u00fcrz\u00b7lich", "mich"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "NE", "$,", "PRELS", "ADV", "ADV", "ADJD", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mit Abscheu von sich warf?\u00ab \u2013 \u00bbIst (ruft er) dies nicht Rache?", "tokens": ["Mit", "Ab\u00b7scheu", "von", "sich", "warf", "?", "\u00ab", "\u2013", "\u00bb", "Ist", "(", "ruft", "er", ")", "dies", "nicht", "Ra\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PRF", "VVFIN", "$.", "$(", "$(", "$(", "VAFIN", "$(", "VVFIN", "PPER", "$(", "PDS", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Du wei\u00dft zu wohl, ich war nicht Ich", "tokens": ["Du", "wei\u00dft", "zu", "wohl", ",", "ich", "war", "nicht", "Ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "$,", "PPER", "VAFIN", "PTKNEG", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "In jener ungl\u00fcckselgen Stunde;", "tokens": ["In", "je\u00b7ner", "un\u00b7gl\u00fcck\u00b7sel\u00b7gen", "Stun\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Gram und Verzweiflung sprach aus meinem irren Munde;", "tokens": ["Gram", "und", "Ver\u00b7zwei\u00b7flung", "sprach", "aus", "mei\u00b7nem", "ir\u00b7ren", "Mun\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.14": {"text": "Ich l\u00e4sterte die Lieb, und f\u00fchlte nie", "tokens": ["Ich", "l\u00e4s\u00b7ter\u00b7te", "die", "Lieb", ",", "und", "f\u00fchl\u00b7te", "nie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Mein Herz so voll von ihr. Ich war zu sehr betroffen,", "tokens": ["Mein", "Herz", "so", "voll", "von", "ihr", ".", "Ich", "war", "zu", "sehr", "be\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "APPR", "PPOSAT", "$.", "PPER", "VAFIN", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Zu wissen was ich sprach, und hielt f\u00fcr Ironie", "tokens": ["Zu", "wis\u00b7sen", "was", "ich", "sprach", ",", "und", "hielt", "f\u00fcr", "I\u00b7ro\u00b7nie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "PWS", "PPER", "VVFIN", "$,", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was du mir sagtest. Konnt ich hoffen,", "tokens": ["Was", "du", "mir", "sag\u00b7test", ".", "Konnt", "ich", "hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "$.", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Da\u00df was Athen von mir, mich von Athen verbannt,", "tokens": ["Da\u00df", "was", "A\u00b7then", "von", "mir", ",", "mich", "von", "A\u00b7then", "ver\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NE", "APPR", "PPER", "$,", "PRF", "APPR", "NE", "VVPP", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.19": {"text": "Erw\u00e4ge dies, und kannst du nicht vergeben", "tokens": ["Er\u00b7w\u00e4\u00b7ge", "dies", ",", "und", "kannst", "du", "nicht", "ver\u00b7ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PDS", "$,", "KON", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Was ich mir selbst zwar nicht vergeben kann,", "tokens": ["Was", "ich", "mir", "selbst", "zwar", "nicht", "ver\u00b7ge\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "ADV", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "So blicke mich noch einmal an,", "tokens": ["So", "bli\u00b7cke", "mich", "noch", "ein\u00b7mal", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und nimm mit diesem Blick mir ein verha\u00dftes Leben.", "tokens": ["Und", "nimm", "mit", "die\u00b7sem", "Blick", "mir", "ein", "ver\u00b7ha\u00df\u00b7tes", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "APPR", "PDAT", "NN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ob ich dich liebe? ach!\u00ab \u2013", "tokens": ["Ob", "ich", "dich", "lie\u00b7be", "?", "ach", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$.", "XY", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbnun, bei Dianen! Freund,", "tokens": ["\u00bb", "nun", ",", "bei", "Di\u00b7a\u00b7nen", "!", "Freund", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$,", "APPR", "NE", "$.", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die Liebe macht bei dir sehr kl\u00e4gliche Geb\u00e4rden:", "tokens": ["Die", "Lie\u00b7be", "macht", "bei", "dir", "sehr", "kl\u00e4g\u00b7li\u00b7che", "Ge\u00b7b\u00e4r\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie spricht so weinerlich, da\u00df mir's unm\u00f6glich scheint", "tokens": ["Sie", "spricht", "so", "wei\u00b7ner\u00b7lich", ",", "da\u00df", "mir's", "un\u00b7m\u00f6g\u00b7lich", "scheint"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "NE", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In diesen Ton jemals gestimmt zu werden.", "tokens": ["In", "die\u00b7sen", "Ton", "je\u00b7mals", "ge\u00b7stimmt", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die hohe Schw\u00e4rmerei taugt meiner Seele nicht,", "tokens": ["Die", "ho\u00b7he", "Schw\u00e4r\u00b7me\u00b7rei", "taugt", "mei\u00b7ner", "See\u00b7le", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So wenig als Theophrons Augenweide:", "tokens": ["So", "we\u00b7nig", "als", "Theo\u00b7phrons", "Au\u00b7gen\u00b7wei\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NE", "NE", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Mein Element ist heitre sanfte Freude,", "tokens": ["Mein", "E\u00b7le\u00b7ment", "ist", "heit\u00b7re", "sanf\u00b7te", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und alles zeigt sich mir in rosenfarbnem Licht.", "tokens": ["Und", "al\u00b7les", "zeigt", "sich", "mir", "in", "ro\u00b7sen\u00b7farb\u00b7nem", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich liebe dich mit diesem sanften Triebe,", "tokens": ["Ich", "lie\u00b7be", "dich", "mit", "die\u00b7sem", "sanf\u00b7ten", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Der, Zephyrn gleich, das Herz in leichte Wellen setzt,", "tokens": ["Der", ",", "Ze\u00b7phyrn", "gleich", ",", "das", "Herz", "in", "leich\u00b7te", "Wel\u00b7len", "setzt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "NN", "ADV", "$,", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nie St\u00fcrm erregt, nie peinigt, stets ergetzt:", "tokens": ["Nie", "St\u00fcrm", "er\u00b7regt", ",", "nie", "pei\u00b7nigt", ",", "stets", "er\u00b7getzt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$,", "ADV", "VVFIN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Wie ich die Grazien, wie ich die Musen liebe,", "tokens": ["Wie", "ich", "die", "Gra\u00b7zi\u00b7en", ",", "wie", "ich", "die", "Mu\u00b7sen", "lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So lieb ich dich. Wenn dies dich gl\u00fccklich machen kann,", "tokens": ["So", "lieb", "ich", "dich", ".", "Wenn", "dies", "dich", "gl\u00fcck\u00b7lich", "ma\u00b7chen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "$.", "KOUS", "PDS", "PRF", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So f\u00e4ngt dein Gl\u00fcck mit diesem Morgen an,", "tokens": ["So", "f\u00e4ngt", "dein", "Gl\u00fcck", "mit", "die\u00b7sem", "Mor\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und wird sich nur mit meinem Leben enden.\u00ab", "tokens": ["Und", "wird", "sich", "nur", "mit", "mei\u00b7nem", "Le\u00b7ben", "en\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PRF", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Welch einen Strahl von unverhofftem Licht", "tokens": ["Welch", "ei\u00b7nen", "Strahl", "von", "un\u00b7ver\u00b7hoff\u00b7tem", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "L\u00e4\u00dft dieses Wort in seine Seele fallen!", "tokens": ["L\u00e4\u00dft", "die\u00b7ses", "Wort", "in", "sei\u00b7ne", "See\u00b7le", "fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er glaubte seinem Ohr den s\u00fc\u00dfen Wechsel nicht;", "tokens": ["Er", "glaub\u00b7te", "sei\u00b7nem", "Ohr", "den", "s\u00fc\u00b7\u00dfen", "Wech\u00b7sel", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein, er sieht das Gl\u00fcck, das ihm ihr Mund verspricht,", "tokens": ["Al\u00b7lein", ",", "er", "sieht", "das", "Gl\u00fcck", ",", "das", "ihm", "ihr", "Mund", "ver\u00b7spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In ihren sch\u00f6nen Augen wallen.", "tokens": ["In", "ih\u00b7ren", "sch\u00f6\u00b7nen", "Au\u00b7gen", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vor Wonne sprachlos sinkt sein Mund auf ihre Hand;", "tokens": ["Vor", "Won\u00b7ne", "sprach\u00b7los", "sinkt", "sein", "Mund", "auf", "ih\u00b7re", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie k\u00fc\u00dft er sie!", "tokens": ["Wie", "k\u00fc\u00dft", "er", "sie", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Sein inniges Entz\u00fccken", "tokens": ["Sein", "in\u00b7ni\u00b7ges", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Entwaffnet ihren Widerstand;", "tokens": ["Ent\u00b7waff\u00b7net", "ih\u00b7ren", "Wi\u00b7der\u00b7stand", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sie g\u00f6nnet ihm und sich die Lust ihn zu begl\u00fccken,", "tokens": ["Sie", "g\u00f6n\u00b7net", "ihm", "und", "sich", "die", "Lust", "ihn", "zu", "be\u00b7gl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PRF", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Lust die so viel Reiz f\u00fcr sch\u00f6ne Seelen hat;", "tokens": ["Die", "Lust", "die", "so", "viel", "Reiz", "f\u00fcr", "sch\u00f6\u00b7ne", "See\u00b7len", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADV", "PIAT", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Selbst da er sich vergi\u00dft, bestraft sie ihn so matt,", "tokens": ["Selbst", "da", "er", "sich", "ver\u00b7gi\u00dft", ",", "be\u00b7straft", "sie", "ihn", "so", "matt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "VVFIN", "$,", "ADJD", "PPER", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da\u00df er es wagt, den Mund an ihre Brust zu dr\u00fccken.", "tokens": ["Da\u00df", "er", "es", "wagt", ",", "den", "Mund", "an", "ih\u00b7re", "Brust", "zu", "dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die Nacht, die Einsamkeit, der Mondschein, die Magie", "tokens": ["Die", "Nacht", ",", "die", "Ein\u00b7sam\u00b7keit", ",", "der", "Mond\u00b7schein", ",", "die", "Ma\u00b7gie"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verliebter Schw\u00e4rmerei, ihr eignes Herz, dem sie", "tokens": ["Ver\u00b7lieb\u00b7ter", "Schw\u00e4r\u00b7me\u00b7rei", ",", "ihr", "eig\u00b7nes", "Herz", ",", "dem", "sie"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nur l\u00e4ssig widersteht, wie vieles kommt zusammen,", "tokens": ["Nur", "l\u00e4s\u00b7sig", "wi\u00b7der\u00b7steht", ",", "wie", "vie\u00b7les", "kommt", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das leichte Blut der Sch\u00f6nen zu entflammen!", "tokens": ["Das", "leich\u00b7te", "Blut", "der", "Sch\u00f6\u00b7nen", "zu", "ent\u00b7flam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Allein Musarion war ihrer selbst gewi\u00df:", "tokens": ["Al\u00b7lein", "Mu\u00b7sa\u00b7ri\u00b7on", "war", "ih\u00b7rer", "selbst", "ge\u00b7wi\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPOSAT", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und als er sich durch das was sie erlaubte,", "tokens": ["Und", "als", "er", "sich", "durch", "das", "was", "sie", "er\u00b7laub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "APPR", "ART", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Nach Art der Liebenden, zu mehr berechtigt glaubte,", "tokens": ["Nach", "Art", "der", "Lie\u00b7ben\u00b7den", ",", "zu", "mehr", "be\u00b7rech\u00b7tigt", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "APPR", "PIS", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie stutzt' er, da sie sich aus seinen Armen ri\u00df!", "tokens": ["Wie", "stutzt'", "er", ",", "da", "sie", "sich", "aus", "sei\u00b7nen", "Ar\u00b7men", "ri\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Da\u00df eine Phyllis sich erkl\u00e4ret", "tokens": ["Da\u00df", "ei\u00b7ne", "Phyl\u00b7lis", "sich", "er\u00b7kl\u00e4\u00b7ret"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NE", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wolle nicht, da\u00df sie mit \u2013 leiser Stimme schreit,", "tokens": ["Sie", "wol\u00b7le", "nicht", ",", "da\u00df", "sie", "mit", "\u2013", "lei\u00b7ser", "Stim\u00b7me", "schreit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "$,", "KOUS", "PPER", "APPR", "$(", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wenn nichts helfen will, euch \u2013 l\u00e4chelnd dr\u00e4ut,", "tokens": ["Und", "wenn", "nichts", "hel\u00b7fen", "will", ",", "euch", "\u2013", "l\u00e4\u00b7chelnd", "dr\u00e4ut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVINF", "VMFIN", "$,", "PPER", "$(", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und sich, so lang es hilft, mit stumpfen N\u00e4geln wehret,", "tokens": ["Und", "sich", ",", "so", "lang", "es", "hilft", ",", "mit", "stump\u00b7fen", "N\u00e4\u00b7geln", "weh\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$,", "ADV", "ADJD", "PPER", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ist nichts befremdliches. Ein Satyr kaum verzeiht", "tokens": ["Ist", "nichts", "be\u00b7fremd\u00b7li\u00b7ches", ".", "Ein", "Sa\u00b7tyr", "kaum", "ver\u00b7zeiht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ADJA", "$.", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den Nymphen, die er hascht, zu viele Willigkeit.", "tokens": ["Den", "Nym\u00b7phen", ",", "die", "er", "hascht", ",", "zu", "vie\u00b7le", "Wil\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie str\u00e4uben sich: gut, dies ist in der Regel;", "tokens": ["Sie", "str\u00e4u\u00b7ben", "sich", ":", "gut", ",", "dies", "ist", "in", "der", "Re\u00b7gel", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$.", "ADJD", "$,", "PDS", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und so verstand es auch der schlaue Phanias.", "tokens": ["Und", "so", "ver\u00b7stand", "es", "auch", "der", "schlau\u00b7e", "Pha\u00b7ni\u00b7as", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er irrte sich, es war nicht das!", "tokens": ["Er", "irr\u00b7te", "sich", ",", "es", "war", "nicht", "das", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "PPER", "VAFIN", "PTKNEG", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Nach mehr als Einem fehl geschlagenen Versuch", "tokens": ["Nach", "mehr", "als", "Ei\u00b7nem", "fehl", "ge\u00b7schla\u00b7ge\u00b7nen", "Ver\u00b7such"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "KOKOM", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00e4ngt unser Held sehr kl\u00e4glich an zu kr\u00e4hen.", "tokens": ["F\u00e4ngt", "un\u00b7ser", "Held", "sehr", "kl\u00e4g\u00b7lich", "an", "zu", "kr\u00e4\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und in der Tat, wer h\u00e4tte sich's versehen?", "tokens": ["Und", "in", "der", "Tat", ",", "wer", "h\u00e4t\u00b7te", "sich's", "ver\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PWS", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Man treibt in einem Ritterbuch", "tokens": ["Man", "treibt", "in", "ei\u00b7nem", "Rit\u00b7ter\u00b7buch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Tugend kaum so weit! \u2013 Doch will er nicht gestehen,", "tokens": ["Die", "Tu\u00b7gend", "kaum", "so", "weit", "!", "\u2013", "Doch", "will", "er", "nicht", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADJD", "$.", "$(", "KON", "VMFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df dies Betragen Tugend sei:", "tokens": ["Da\u00df", "dies", "Be\u00b7tra\u00b7gen", "Tu\u00b7gend", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Er nennt es Eigensinn und Grillenf\u00e4ngerei;", "tokens": ["Er", "nennt", "es", "Ei\u00b7gen\u00b7sinn", "und", "Gril\u00b7len\u00b7f\u00e4n\u00b7ge\u00b7rei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er schilt sie spr\u00f6d, unz\u00e4rtlich, unempfindlich.", "tokens": ["Er", "schilt", "sie", "spr\u00f6d", ",", "un\u00b7z\u00e4rt\u00b7lich", ",", "un\u00b7emp\u00b7find\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die Sch\u00f6ne, die gesteht da\u00df sie uns g\u00fcnstig sei,", "tokens": ["Die", "Sch\u00f6\u00b7ne", ",", "die", "ge\u00b7steht", "da\u00df", "sie", "uns", "g\u00fcns\u00b7tig", "sei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "KOUS", "PPER", "PRF", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Macht, seiner Meinung nach, sich zum Beweis verbindlich.", "tokens": ["Macht", ",", "sei\u00b7ner", "Mei\u00b7nung", "nach", ",", "sich", "zum", "Be\u00b7weis", "ver\u00b7bind\u00b7lich", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "APPR", "$,", "PRF", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "\u00bbund ich, mein Herr, (versetzt sie) die so viel", "tokens": ["\u00bb", "und", "ich", ",", "mein", "Herr", ",", "(", "ver\u00b7setzt", "sie", ")", "die", "so", "viel"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "$,", "PPOSAT", "NN", "$,", "$(", "VVFIN", "PPER", "$(", "PRELS", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Beweisen soll, bin ich, nach eurer Sittenlehre,", "tokens": ["Be\u00b7wei\u00b7sen", "soll", ",", "bin", "ich", ",", "nach", "eu\u00b7rer", "Sit\u00b7ten\u00b7leh\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "VAFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht auch befugt da\u00df ich Beweis begehre?", "tokens": ["Nicht", "auch", "be\u00b7fugt", "da\u00df", "ich", "Be\u00b7weis", "be\u00b7geh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wie, wenn eure Glut ein blo\u00dfes Sinnenspiel,", "tokens": ["Und", "wie", ",", "wenn", "eu\u00b7re", "Glut", "ein", "blo\u00b7\u00dfes", "Sin\u00b7nen\u00b7spiel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$,", "KOUS", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein fl\u00fcchtiger Geschmack, ein kleines Fieber w\u00e4re?", "tokens": ["Ein", "fl\u00fcch\u00b7ti\u00b7ger", "Ge\u00b7schmack", ",", "ein", "klei\u00b7nes", "Fie\u00b7ber", "w\u00e4\u00b7re", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn Phanias mich liebt, so r\u00e4umt er, hoff ich, ein,", "tokens": ["Wenn", "Pha\u00b7ni\u00b7as", "mich", "liebt", ",", "so", "r\u00e4umt", "er", ",", "hoff", "ich", ",", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df ich, eh ich mich selbst verschenke,", "tokens": ["Da\u00df", "ich", ",", "eh", "ich", "mich", "selbst", "ver\u00b7schen\u00b7ke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auf meine Sicherheit vorher ein wenig denke.", "tokens": ["Auf", "mei\u00b7ne", "Si\u00b7cher\u00b7heit", "vor\u00b7her", "ein", "we\u00b7nig", "den\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bei Leuten von so warmem Blut", "tokens": ["Bei", "Leu\u00b7ten", "von", "so", "war\u00b7mem", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ist diese Vorsicht wohl nicht allzu weit getrieben.", "tokens": ["Ist", "die\u00b7se", "Vor\u00b7sicht", "wohl", "nicht", "all\u00b7zu", "weit", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "ADV", "PTKNEG", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verzeihe, wenn sie dir ein wenig Unrecht tut;", "tokens": ["Ver\u00b7zei\u00b7he", ",", "wenn", "sie", "dir", "ein", "we\u00b7nig", "Un\u00b7recht", "tut", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PPER", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Allein du selber willst da\u00df wir im Ernst uns lieben?", "tokens": ["Al\u00b7lein", "du", "sel\u00b7ber", "willst", "da\u00df", "wir", "im", "Ernst", "uns", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VMFIN", "KOUS", "PPER", "APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sonst t\u00e4ndelt ich mit Amors Pfeilen nur:", "tokens": ["Sonst", "t\u00e4n\u00b7delt", "ich", "mit", "A\u00b7mors", "Pfei\u00b7len", "nur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Jetzt, da er mich erhascht, ist's nicht mehr Zeit zum Lachen;", "tokens": ["Jetzt", ",", "da", "er", "mich", "er\u00b7hascht", ",", "ist's", "nicht", "mehr", "Zeit", "zum", "La\u00b7chen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "VVPP", "$,", "VAFIN", "PTKNEG", "PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Es ist darum zu tun da\u00df wir uns gl\u00fccklich machen,", "tokens": ["Es", "ist", "da\u00b7rum", "zu", "tun", "da\u00df", "wir", "uns", "gl\u00fcck\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "PTKZU", "VVINF", "KOUS", "PPER", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und nur vereinigt kann dies Weisheit und Natur.\u00ab", "tokens": ["Und", "nur", "ver\u00b7ei\u00b7nigt", "kann", "dies", "Weis\u00b7heit", "und", "Na\u00b7tur", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVPP", "VMFIN", "PDS", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Unwiderstehlich, sagt man, sei", "tokens": ["Un\u00b7wi\u00b7der\u00b7steh\u00b7lich", ",", "sagt", "man", ",", "sei"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["ADJD", "$,", "VVFIN", "PIS", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Weisheit Reiz aus einem sch\u00f6nen Munde.", "tokens": ["Der", "Weis\u00b7heit", "Reiz", "aus", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wir geben's zu, so fern euch nicht dabei", "tokens": ["Wir", "ge\u00b7ben's", "zu", ",", "so", "fern", "euch", "nicht", "da\u00b7bei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ADV", "ADJD", "PPER", "PTKNEG", "PAV"], "meter": "-----+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Aus einem Nachtgewand mit nelkenfarbnem Grunde", "tokens": ["Aus", "ei\u00b7nem", "Nacht\u00b7ge\u00b7wand", "mit", "nel\u00b7ken\u00b7farb\u00b7nem", "Grun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Busen reizt, der, jugendlich gebl\u00e4ht,", "tokens": ["Ein", "Bu\u00b7sen", "reizt", ",", "der", ",", "ju\u00b7gend\u00b7lich", "ge\u00b7bl\u00e4ht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Augen blendt und niemals stille steht;", "tokens": ["Die", "Au\u00b7gen", "blendt", "und", "nie\u00b7mals", "stil\u00b7le", "steht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ADV", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ein Busen, den die G\u00f6ttin von Cythere,", "tokens": ["Ein", "Bu\u00b7sen", ",", "den", "die", "G\u00f6t\u00b7tin", "von", "Cy\u00b7the\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wenn eine G\u00f6ttin nicht zum Neid zu vornehm w\u00e4re,", "tokens": ["Wenn", "ei\u00b7ne", "G\u00f6t\u00b7tin", "nicht", "zum", "Neid", "zu", "vor\u00b7nehm", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "APPRART", "NN", "PTKA", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Beneiden k\u00f6nnt. In diesem Falle fand", "tokens": ["Be\u00b7nei\u00b7den", "k\u00f6nnt", ".", "In", "die\u00b7sem", "Fal\u00b7le", "fand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$.", "APPR", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sich, leider! unser Held, von zwei verschiednen Kr\u00e4ften", "tokens": ["Sich", ",", "lei\u00b7der", "!", "un\u00b7ser", "Held", ",", "von", "zwei", "ver\u00b7schied\u00b7nen", "Kr\u00e4f\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "$,", "ADV", "$.", "PPOSAT", "NN", "$,", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Gezogen. Mu\u00dft er auch so starr und unverwandt", "tokens": ["Ge\u00b7zo\u00b7gen", ".", "Mu\u00dft", "er", "auch", "so", "starr", "und", "un\u00b7ver\u00b7wandt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$.", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Auf die Gefahr ein l\u00fcstern Auge heften?", "tokens": ["Auf", "die", "Ge\u00b7fahr", "ein", "l\u00fcs\u00b7tern", "Au\u00b7ge", "hef\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Nat\u00fcrlich mu\u00df der st\u00e4rkre Sinn", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "mu\u00df", "der", "st\u00e4r\u00b7kre", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Des schw\u00e4chern Eindruck bald verdringen;", "tokens": ["Des", "schw\u00e4\u00b7chern", "Ein\u00b7druck", "bald", "ver\u00b7drin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und was die Freundin spricht, ihn zu sich selbst zu bringen,", "tokens": ["Und", "was", "die", "Freun\u00b7din", "spricht", ",", "ihn", "zu", "sich", "selbst", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,", "PPER", "APPR", "PRF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Schwebt ungef\u00fchlt an seinen Ohren hin.", "tokens": ["Schwebt", "un\u00b7ge\u00b7f\u00fchlt", "an", "sei\u00b7nen", "Oh\u00b7ren", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Was Amor nur vermag um Spr\u00f6de zu bezwingen,", "tokens": ["Was", "A\u00b7mor", "nur", "ver\u00b7mag", "um", "Spr\u00f6\u00b7de", "zu", "be\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "ADV", "VVFIN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Was, wie man sagt, schon Drachen zahm gemacht,", "tokens": ["Was", ",", "wie", "man", "sagt", ",", "schon", "Dra\u00b7chen", "zahm", "ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWAV", "PIS", "VVFIN", "$,", "ADV", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Die K\u00fcnste, die Ovid in ein System gebracht,", "tokens": ["Die", "K\u00fcns\u00b7te", ",", "die", "O\u00b7vid", "in", "ein", "Sys\u00b7tem", "ge\u00b7bracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "NE", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Die feinsten Wendungen, die unsichtbarsten Schlingen", "tokens": ["Die", "feins\u00b7ten", "Wen\u00b7dun\u00b7gen", ",", "die", "un\u00b7sicht\u00b7bars\u00b7ten", "Schlin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Versucht er gegen sie, und keine will gelingen.", "tokens": ["Ver\u00b7sucht", "er", "ge\u00b7gen", "sie", ",", "und", "kei\u00b7ne", "will", "ge\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$,", "KON", "PIAT", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "\u00bbergib dich (spricht zuletzt die sch\u00f6ne Siegerin)", "tokens": ["\u00bb", "er\u00b7gib", "dich", "(", "spricht", "zu\u00b7letzt", "die", "sch\u00f6\u00b7ne", "Sie\u00b7ge\u00b7rin", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "$(", "VVFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit guter Art! Du siehst, wie nachsichtsvoll ich bin", "tokens": ["Mit", "gu\u00b7ter", "Art", "!", "Du", "siehst", ",", "wie", "nach\u00b7sichts\u00b7voll", "ich", "bin"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPER", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So vielen \u00dcbermut zu tragen:", "tokens": ["So", "vie\u00b7len", "\u00dc\u00b7ber\u00b7mut", "zu", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mehr Eigensinn, erlaube mir's zu sagen,", "tokens": ["Mehr", "Ei\u00b7gen\u00b7sinn", ",", "er\u00b7lau\u00b7be", "mir's", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "VVFIN", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Beleidigt meine Z\u00e4rtlichkeit,", "tokens": ["Be\u00b7lei\u00b7digt", "mei\u00b7ne", "Z\u00e4rt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und dient zu nichts, als deine Pr\u00fcfungszeit", "tokens": ["Und", "dient", "zu", "nichts", ",", "als", "dei\u00b7ne", "Pr\u00fc\u00b7fungs\u00b7zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIS", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Mehr, als ich selbst vielleicht es w\u00fcnsche, zu verl\u00e4ngern.", "tokens": ["Mehr", ",", "als", "ich", "selbst", "viel\u00b7leicht", "es", "w\u00fcn\u00b7sche", ",", "zu", "ver\u00b7l\u00e4n\u00b7gern", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PPER", "ADV", "ADV", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Genug von diesem! Schwatzen wir,", "tokens": ["Ge\u00b7nug", "von", "die\u00b7sem", "!", "Schwat\u00b7zen", "wir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "$.", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wenn dir's gef\u00e4llt, von unsern Grillenf\u00e4ngern.", "tokens": ["Wenn", "dir's", "ge\u00b7f\u00e4llt", ",", "von", "un\u00b7sern", "Gril\u00b7len\u00b7f\u00e4n\u00b7gern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVPP", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ich wei\u00df nicht wie der Einfall mir", "tokens": ["Ich", "wei\u00df", "nicht", "wie", "der", "Ein\u00b7fall", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "KOKOM", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Zu Kopfe steigt \u2013 allein, ich wollte schw\u00f6ren,", "tokens": ["Zu", "Kop\u00b7fe", "steigt", "\u2013", "al\u00b7lein", ",", "ich", "woll\u00b7te", "schw\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$(", "ADV", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Da\u00df diesen Augenblick \u2013 was meinst du, Phanias? \u2013", "tokens": ["Da\u00df", "die\u00b7sen", "Au\u00b7gen\u00b7blick", "\u2013", "was", "meinst", "du", ",", "Pha\u00b7ni\u00b7as", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PDAT", "NN", "$(", "PWS", "VVFIN", "PPER", "$,", "NE", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mein M\u00e4dchen \u2013 rate doch! \u2013 und dein Pythagoras \u2013\u00ab", "tokens": ["Mein", "M\u00e4d\u00b7chen", "\u2013", "ra\u00b7te", "doch", "!", "\u2013", "und", "dein", "Py\u00b7tha\u00b7go\u00b7ras", "\u2013", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$(", "VVFIN", "ADV", "$.", "$(", "KON", "PPOSAT", "NE", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "\u00bbwie? etwa gar die Sph\u00e4ren singen h\u00f6ren?", "tokens": ["\u00bb", "wie", "?", "et\u00b7wa", "gar", "die", "Sph\u00e4\u00b7ren", "sin\u00b7gen", "h\u00f6\u00b7ren", "?"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$.", "ADV", "ADV", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(versetzt mit Lachen Phanias)", "tokens": ["(", "ver\u00b7setzt", "mit", "La\u00b7chen", "Pha\u00b7ni\u00b7as", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "APPR", "NN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das hie\u00dfe mir ein Abenteuer!", "tokens": ["Das", "hie\u00b7\u00dfe", "mir", "ein", "A\u00b7bent\u00b7eu\u00b7er", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und doch, wer wei\u00df? Ich merkte selbst so was:", "tokens": ["Und", "doch", ",", "wer", "wei\u00df", "?", "Ich", "merk\u00b7te", "selbst", "so", "was", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWS", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "ADV", "PWS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Es wallte, deuchte mich, ein ziemlich irdisch Feuer", "tokens": ["Es", "wall\u00b7te", ",", "deuch\u00b7te", "mich", ",", "ein", "ziem\u00b7lich", "ir\u00b7disch", "Feu\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "ART", "ADV", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In seinem Aug, als Chloens lose Hand", "tokens": ["In", "sei\u00b7nem", "Aug", ",", "als", "Chloens", "lo\u00b7se", "Hand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "NE", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Den Blumenkranz um seine Stirne wand.", "tokens": ["Den", "Blu\u00b7men\u00b7kranz", "um", "sei\u00b7ne", "Stir\u00b7ne", "wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wie viel, Musarion, hab ich dir nicht zu danken!", "tokens": ["Wie", "viel", ",", "Mu\u00b7sa\u00b7ri\u00b7on", ",", "hab", "ich", "dir", "nicht", "zu", "dan\u00b7ken", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "$,", "NN", "$,", "VAFIN", "PPER", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was f\u00fcr ein Tor ich war, Gesellen dieser Art,", "tokens": ["Was", "f\u00fcr", "ein", "Tor", "ich", "war", ",", "Ge\u00b7sel\u00b7len", "die\u00b7ser", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PPER", "VAFIN", "$,", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "An denen nichts als Mantel, Stab und Bart", "tokens": ["An", "de\u00b7nen", "nichts", "als", "Man\u00b7tel", ",", "Stab", "und", "Bart"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PRELS", "PIS", "KOKOM", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Sokratisch ist, (wie ha\u00df ich den Gedanken!)", "tokens": ["Sok\u00b7ra\u00b7tisch", "ist", ",", "(", "wie", "ha\u00df", "ich", "den", "Ge\u00b7dan\u00b7ken", "!", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VAFIN", "$,", "$(", "PWAV", "VVFIN", "PPER", "ART", "NN", "$.", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.12": {"text": "Ein Paar, das nur in einem Possenspiel", "tokens": ["Ein", "Paar", ",", "das", "nur", "in", "ei\u00b7nem", "Pos\u00b7sen\u00b7spiel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Bei rohen Satyrn und Bacchanten", "tokens": ["Bei", "ro\u00b7hen", "Sa\u00b7tyrn", "und", "Bac\u00b7chan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.14": {"text": "Zu gl\u00e4nzen w\u00fcrdig ist, f\u00fcr Weise, f\u00fcr Verwandten", "tokens": ["Zu", "gl\u00e4n\u00b7zen", "w\u00fcr\u00b7dig", "ist", ",", "f\u00fcr", "Wei\u00b7se", ",", "f\u00fcr", "Ver\u00b7wand\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKZU", "VVINF", "ADJD", "VAFIN", "$,", "APPR", "NN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der G\u00f6tter anzusehn!\u00ab \u2013", "tokens": ["Der", "G\u00f6t\u00b7ter", "an\u00b7zu\u00b7sehn", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVIZU", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "\u00bbdu tust dir selbst zu viel,", "tokens": ["\u00bb", "du", "tust", "dir", "selbst", "zu", "viel", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "PTKA", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "(f\u00e4llt ihm die Freundin ein) und, wie mich deucht, auch ihnen.", "tokens": ["(", "f\u00e4llt", "ihm", "die", "Freun\u00b7din", "ein", ")", "und", ",", "wie", "mich", "deucht", ",", "auch", "ih\u00b7nen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "ART", "$(", "KON", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "PPER", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Kein \u00dcberma\u00df, mein Freund, ich bitte sehr!", "tokens": ["Kein", "\u00dc\u00b7berm\u00b7a\u00df", ",", "mein", "Freund", ",", "ich", "bit\u00b7te", "sehr", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Du sch\u00e4tztest sie vordem vermutlich mehr,", "tokens": ["Du", "sch\u00e4tz\u00b7test", "sie", "vor\u00b7dem", "ver\u00b7mut\u00b7lich", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Jetzt weniger, als sie vielleicht verdienen.\u00ab", "tokens": ["Jetzt", "we\u00b7ni\u00b7ger", ",", "als", "sie", "viel\u00b7leicht", "ver\u00b7die\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "\u00bbwas h\u00f6r ich! (ruft er) spricht Musarion f\u00fcr sie?", "tokens": ["\u00bb", "was", "h\u00f6r", "ich", "!", "(", "ruft", "er", ")", "spricht", "Mu\u00b7sa\u00b7ri\u00b7on", "f\u00fcr", "sie", "?"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "PPER", "$(", "VVFIN", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du scherzest! H\u00e4ttst du auch (was du gewi\u00dflich nie", "tokens": ["Du", "scher\u00b7zest", "!", "H\u00e4ttst", "du", "auch", "(", "was", "du", "ge\u00b7wi\u00df\u00b7lich", "nie"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PPER", "ADV", "$(", "PWS", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Getan hast) dies Gez\u00fccht so hoch als ich gehalten,", "tokens": ["Ge\u00b7tan", "hast", ")", "dies", "Ge\u00b7z\u00fccht", "so", "hoch", "als", "ich", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$(", "PDS", "NN", "ADV", "ADJD", "KOKOM", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So m\u00fc\u00dfte dir, nach dem was wir gesehn,", "tokens": ["So", "m\u00fc\u00df\u00b7te", "dir", ",", "nach", "dem", "was", "wir", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPR", "ART", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der g\u00fcnstge Wahn so gut als mir vergehn.", "tokens": ["Der", "g\u00fcnst\u00b7ge", "Wahn", "so", "gut", "als", "mir", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "KOKOM", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wie? dieser Stoiker, der nur die Tugend sch\u00f6n", "tokens": ["Wie", "?", "die\u00b7ser", "Stoi\u00b7ker", ",", "der", "nur", "die", "Tu\u00b7gend", "sch\u00f6n"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "PDAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Und gut erkennt, entlarvt in einen alten", "tokens": ["Und", "gut", "er\u00b7kennt", ",", "ent\u00b7larvt", "in", "ei\u00b7nen", "al\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "$,", "VVFIN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bezechten Faun! \u2013 Theophron, der vom Gl\u00fcck", "tokens": ["Be\u00b7zech\u00b7ten", "Faun", "!", "\u2013", "Theo\u00b7phron", ",", "der", "vom", "Gl\u00fcck"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "$(", "NE", "$,", "PRELS", "APPRART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Der Geister singt, indes sein unbescheidner Blick", "tokens": ["Der", "Geis\u00b7ter", "singt", ",", "in\u00b7des", "sein", "un\u00b7be\u00b7scheid\u00b7ner", "Blick"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In Chloens Busen w\u00fchlt \u2013 Was braucht es mehr Beweise?\u00ab \u2013", "tokens": ["In", "Chloens", "Bu\u00b7sen", "w\u00fchlt", "\u2013", "Was", "braucht", "es", "mehr", "Be\u00b7wei\u00b7se", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "$(", "PWS", "VVFIN", "PPER", "PIAT", "NN", "$.", "$(", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.17": {"line.1": {"text": "\u00bbda\u00df sie sehr menschlich sind, (f\u00e4llt ihm die Freundin ein)", "tokens": ["\u00bb", "da\u00df", "sie", "sehr", "menschlich", "sind", ",", "(", "f\u00e4llt", "ihm", "die", "Freun\u00b7din", "ein", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "$(", "VVFIN", "PPER", "ART", "NN", "ART", "$("], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und in der Tat nicht ganz so weise", "tokens": ["Und", "in", "der", "Tat", "nicht", "ganz", "so", "wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PTKNEG", "ADV", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ihr System, das zeigt der Augenschein. \u2013", "tokens": ["Als", "ihr", "Sys\u00b7tem", ",", "das", "zeigt", "der", "Au\u00b7gen\u00b7schein", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "PDS", "VVFIN", "ART", "NN", "$.", "$("], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und dennoch ist nichts m\u00e4chtiger, um Seelen", "tokens": ["Und", "den\u00b7noch", "ist", "nichts", "m\u00e4ch\u00b7ti\u00b7ger", ",", "um", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PIS", "ADJA", "$,", "KOUI", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zu starken Tugenden zu bilden, unsern Mut", "tokens": ["Zu", "star\u00b7ken", "Tu\u00b7gen\u00b7den", "zu", "bil\u00b7den", ",", "un\u00b7sern", "Mut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu dieser Festigkeit zu st\u00e4hlen,", "tokens": ["Zu", "die\u00b7ser", "Fes\u00b7tig\u00b7keit", "zu", "st\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die gro\u00dfen \u00dcbeln trotzt und gro\u00dfe Taten tut,", "tokens": ["Die", "gro\u00b7\u00dfen", "\u00dc\u00b7beln", "trotzt", "und", "gro\u00b7\u00dfe", "Ta\u00b7ten", "tut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als eben dieser Satz, f\u00fcr welchen dein Kleanth", "tokens": ["Als", "e\u00b7ben", "die\u00b7ser", "Satz", ",", "f\u00fcr", "wel\u00b7chen", "dein", "Kle\u00b7an\u00b7th"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PDAT", "NN", "$,", "APPR", "PWAT", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Zum M\u00e4rtyrer sich trank. Die alten Herakliden,", "tokens": ["Zum", "M\u00e4r\u00b7ty\u00b7rer", "sich", "trank", ".", "Die", "al\u00b7ten", "Her\u00b7a\u00b7kli\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "VVFIN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die M\u00e4nner, die ihr Vaterland", "tokens": ["Die", "M\u00e4n\u00b7ner", ",", "die", "ihr", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Mehr als sich selbst geliebt, die Aristiden,", "tokens": ["Mehr", "als", "sich", "selbst", "ge\u00b7liebt", ",", "die", "A\u00b7ris\u00b7ti\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "PRF", "ADV", "VVPP", "$,", "ART", "NN", "$,"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Die Phocion und die Leonidas,", "tokens": ["Die", "Pho\u00b7ci\u00b7on", "und", "die", "Leo\u00b7ni\u00b7das", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Ruhmvolle Namen!\u00ab \u2013 \u00bb Gut! (ruft unser Mann) und waren", "tokens": ["Ruhm\u00b7vol\u00b7le", "Na\u00b7men", "!", "\u00ab", "\u2013", "\u00bb", "Gut", "!", "(", "ruft", "un\u00b7ser", "Mann", ")", "und", "wa\u00b7ren"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "$(", "$(", "$(", "ADJD", "$.", "$(", "VVFIN", "PPOSAT", "NN", "$(", "KON", "VAFIN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.14": {"text": "Sie etwan Stoiker?\u00ab \u2013 \u00bb Sie waren, Phanias,", "tokens": ["Sie", "et\u00b7wan", "Stoi\u00b7ker", "?", "\u00ab", "\u2013", "\u00bb", "Sie", "wa\u00b7ren", ",", "Pha\u00b7ni\u00b7as", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "NN", "$.", "$(", "$(", "$(", "PPER", "VAFIN", "$,", "NE", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Noch etwas mehr! Sie haben das ", "tokens": ["Noch", "et\u00b7was", "mehr", "!", "Sie", "ha\u00b7ben", "das"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$.", "PPER", "VAFIN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Was Zeno spekuliert; sie haben es ", "tokens": ["Was", "Ze\u00b7no", "spe\u00b7ku\u00b7liert", ";", "sie", "ha\u00b7ben", "es"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NE", "VVFIN", "$.", "PPER", "VAFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Warum hat Herkules Alt\u00e4re?", "tokens": ["Wa\u00b7rum", "hat", "Her\u00b7ku\u00b7les", "Al\u00b7t\u00e4\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.18": {"text": "Den Weg, den Prodikus nicht gehn, nur malen kann,", "tokens": ["Den", "Weg", ",", "den", "Pro\u00b7di\u00b7kus", "nicht", "gehn", ",", "nur", "ma\u00b7len", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "PTKNEG", "VVINF", "$,", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.20": {"text": "\u00bbund wem geb\u00fchrt davon die Ehre,", "tokens": ["\u00bb", "und", "wem", "ge\u00b7b\u00fchrt", "da\u00b7von", "die", "Eh\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWS", "VVFIN", "PAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Als der Natur, die ihn, und wer ihm gleicht, gebar", "tokens": ["Als", "der", "Na\u00b7tur", ",", "die", "ihn", ",", "und", "wer", "ihm", "gleicht", ",", "ge\u00b7bar"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "ART", "NN", "$,", "PRELS", "PPER", "$,", "KON", "PWS", "PPER", "VVFIN", "$,", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und auferzog, eh eine ", "tokens": ["Und", "auf\u00b7er\u00b7zog", ",", "eh", "ei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Ein Held wird nicht geformt, er wird geboren.\u00ab", "tokens": ["Ein", "Held", "wird", "nicht", "ge\u00b7formt", ",", "er", "wird", "ge\u00b7bo\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,", "PPER", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "\u00bbindessen hat, weil ihr der erste Preis geb\u00fchrt,", "tokens": ["\u00bb", "in\u00b7des\u00b7sen", "hat", ",", "weil", "ihr", "der", "ers\u00b7te", "Preis", "ge\u00b7b\u00fchrt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "$,", "KOUS", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch Plato nicht sein Recht an Phocion verloren.", "tokens": ["Doch", "Pla\u00b7to", "nicht", "sein", "Recht", "an", "Pho\u00b7ci\u00b7on", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PTKNEG", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was die Natur entwirft, wird von der Kunst vollf\u00fchrt.", "tokens": ["Was", "die", "Na\u00b7tur", "ent\u00b7wirft", ",", "wird", "von", "der", "Kunst", "voll\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Blume, die im Feld sich unbemerkt verliert,", "tokens": ["Die", "Blu\u00b7me", ",", "die", "im", "Feld", "sich", "un\u00b7be\u00b7merkt", "ver\u00b7liert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erzieht des G\u00e4rtners Flei\u00df zum sch\u00f6nsten Kind der Floren.\u00ab", "tokens": ["Er\u00b7zieht", "des", "G\u00e4rt\u00b7ners", "Flei\u00df", "zum", "sch\u00f6ns\u00b7ten", "Kind", "der", "Flo\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "APPRART", "ADJA", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "\u00bbgesetzt\u00ab, spricht Phanias, \u00bbda\u00df dieses richtig sei,", "tokens": ["\u00bb", "ge\u00b7setzt", "\u00ab", ",", "spricht", "Pha\u00b7ni\u00b7as", ",", "\u00bb", "da\u00df", "die\u00b7ses", "rich\u00b7tig", "sei", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "$(", "$,", "VVFIN", "NE", "$,", "$(", "KOUS", "PDAT", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So ist doch was von Zahlen und Ideen", "tokens": ["So", "ist", "doch", "was", "von", "Zah\u00b7len", "und", "I\u00b7deen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PWS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und Dingen, die kein Aug geh\u00f6rt, kein Ohr gesehen,", "tokens": ["Und", "Din\u00b7gen", ",", "die", "kein", "Aug", "ge\u00b7h\u00f6rt", ",", "kein", "Ohr", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Theophron schwatzt, handgreiflich Tr\u00e4umerei?\u00ab", "tokens": ["Theo\u00b7phron", "schwatzt", ",", "hand\u00b7greif\u00b7lich", "Tr\u00e4u\u00b7me\u00b7rei", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "$,", "ADJD", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.20": {"line.1": {"text": "\u00bbund mit den n\u00e4mlichen Ideen", "tokens": ["\u00bb", "und", "mit", "den", "n\u00e4m\u00b7li\u00b7chen", "I\u00b7deen"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War doch Archytas einst ein wirklich gro\u00dfer Mann!", "tokens": ["War", "doch", "Ar\u00b7chy\u00b7tas", "einst", "ein", "wirk\u00b7lich", "gro\u00b7\u00dfer", "Mann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NE", "ADV", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch Seelen dieser Art erzeuget dann und wann", "tokens": ["Auch", "See\u00b7len", "die\u00b7ser", "Art", "er\u00b7zeu\u00b7get", "dann", "und", "wann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "PDAT", "NN", "VVFIN", "ADV", "KON", "PWAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(zwar sparsam) die Natur. Man wird zum Geisterseher", "tokens": ["(", "zwar", "spar\u00b7sam", ")", "die", "Na\u00b7tur", ".", "Man", "wird", "zum", "Geis\u00b7ter\u00b7se\u00b7her"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJD", "$(", "ART", "NN", "$.", "PIS", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Geboren, wie zum Feldherrn Xenophon\u00ab,", "tokens": ["Ge\u00b7bo\u00b7ren", ",", "wie", "zum", "Feld\u00b7herrn", "Xe\u00b7no\u00b7phon", "\u00ab", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "PWAV", "APPRART", "NN", "NN", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wie Zeuxis zum Palett, und Philipps Sohn zum Thron.", "tokens": ["Wie", "Zeu\u00b7xis", "zum", "Pa\u00b7lett", ",", "und", "Phi\u00b7lipps", "Sohn", "zum", "Thron", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPRART", "NN", "$,", "KON", "NE", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und in der Tat, was hebt die Seele h\u00f6her,", "tokens": ["Und", "in", "der", "Tat", ",", "was", "hebt", "die", "See\u00b7le", "h\u00f6\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PWS", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Was n\u00e4hrt die Tugend mehr? erweitert und verfeint", "tokens": ["Was", "n\u00e4hrt", "die", "Tu\u00b7gend", "mehr", "?", "er\u00b7wei\u00b7tert", "und", "ver\u00b7feint"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADV", "$.", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Des Herzens Triebe so, als gl\u00e4nzende Gedanken", "tokens": ["Des", "Her\u00b7zens", "Trie\u00b7be", "so", ",", "als", "gl\u00e4n\u00b7zen\u00b7de", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ADV", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.10": {"text": "Von unsers Daseins Zweck? \u2013 das Weltall ohne Schranken,", "tokens": ["Von", "un\u00b7sers", "Da\u00b7seins", "Zweck", "?", "\u2013", "das", "Wel\u00b7tall", "oh\u00b7ne", "Schran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$.", "$(", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Unendlich Raum und Zeit, die Sonne die uns scheint", "tokens": ["Un\u00b7end\u00b7lich", "Raum", "und", "Zeit", ",", "die", "Son\u00b7ne", "die", "uns", "scheint"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "KON", "NN", "$,", "ART", "NN", "ART", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein Funke nur von einer h\u00f6hern Sonne,", "tokens": ["Ein", "Fun\u00b7ke", "nur", "von", "ei\u00b7ner", "h\u00f6\u00b7hern", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Unsterblich unser Geist, Unsterblichen befreundt,", "tokens": ["U\u00b7nsterb\u00b7lich", "un\u00b7ser", "Geist", ",", "U\u00b7nsterb\u00b7li\u00b7chen", "be\u00b7freundt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$,", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.14": {"text": "Und, ahmt er G\u00f6ttern nach, bestimmt zu G\u00f6tterwonne!\u00ab", "tokens": ["Und", ",", "ahmt", "er", "G\u00f6t\u00b7tern", "nach", ",", "be\u00b7stimmt", "zu", "G\u00f6t\u00b7ter\u00b7won\u00b7ne", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "\u00bbbei allen Grazien! (ruft lachend Phanias)", "tokens": ["\u00bb", "bei", "al\u00b7len", "Gra\u00b7zi\u00b7en", "!", "(", "ruft", "la\u00b7chend", "Pha\u00b7ni\u00b7as", ")"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "$.", "$(", "VVFIN", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du wirst noch mit der Zeit die Sph\u00e4ren singen h\u00f6ren!", "tokens": ["Du", "wirst", "noch", "mit", "der", "Zeit", "die", "Sph\u00e4\u00b7ren", "sin\u00b7gen", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vor wenig Stunden gab dies Galimathias", "tokens": ["Vor", "we\u00b7nig", "Stun\u00b7den", "gab", "dies", "Ga\u00b7li\u00b7ma\u00b7thi\u00b7as"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PDS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dir Stoff zum Spott\u00ab \u2013", "tokens": ["Dir", "Stoff", "zum", "Spott", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "NN", "APPRART", "NN", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "\u00bbder Mann, nicht seine ", "tokens": ["\u00bb", "der", "Mann", ",", "nicht", "sei\u00b7ne"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ART", "NN", "$,", "PTKNEG", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Das Wahre nicht, obgleich (nach aller Schw\u00e4rmer Art)", "tokens": ["Das", "Wah\u00b7re", "nicht", ",", "ob\u00b7gleich", "(", "nach", "al\u00b7ler", "Schw\u00e4r\u00b7mer", "Art", ")"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "$,", "KOUS", "$(", "APPR", "PIAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein gl\u00fchendes Gehirn es mit Schim\u00e4ren paart.", "tokens": ["Sein", "gl\u00fc\u00b7hen\u00b7des", "Ge\u00b7hirn", "es", "mit", "Schi\u00b7m\u00e4\u00b7ren", "paart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Nur diese trifft der Spott. \u2013 Doch stille! wir versteigen", "tokens": ["Nur", "die\u00b7se", "trifft", "der", "Spott", ".", "\u2013", "Doch", "stil\u00b7le", "!", "wir", "ver\u00b7stei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "ART", "NN", "$.", "$(", "KON", "VVFIN", "$.", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Uns allzu hoch. Ich wollte dir nur zeigen,", "tokens": ["Uns", "all\u00b7zu", "hoch", ".", "Ich", "woll\u00b7te", "dir", "nur", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKA", "ADJD", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Da\u00df dich dein Vorurteil f\u00fcr dieses weise Paar", "tokens": ["Da\u00df", "dich", "dein", "Vor\u00b7ur\u00b7teil", "f\u00fcr", "die\u00b7ses", "wei\u00b7se", "Paar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nicht schamrot machen soll. Nichts war", "tokens": ["Nicht", "scham\u00b7rot", "ma\u00b7chen", "soll", ".", "Nichts", "war"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "ADJD", "VVINF", "VMFIN", "$.", "PIS", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Nat\u00fcrlicher in deiner schlimmen Lage.", "tokens": ["Na\u00b7t\u00fcr\u00b7li\u00b7cher", "in", "dei\u00b7ner", "schlim\u00b7men", "La\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der Knospe gleich am kalten M\u00e4rzentage", "tokens": ["Der", "Knos\u00b7pe", "gleich", "am", "kal\u00b7ten", "M\u00e4r\u00b7zen\u00b7ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Schrumpft, wenn des Gl\u00fcckes Sonnenschein", "tokens": ["Schrumpft", ",", "wenn", "des", "Gl\u00fc\u00b7ckes", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.15": {"text": "Sich ihr entzieht, die Seel in sich hinein.", "tokens": ["Sich", "ihr", "ent\u00b7zieht", ",", "die", "Seel", "in", "sich", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPER", "VVFIN", "$,", "ART", "NN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Entfiedert, nackt, von allem ausgeleeret", "tokens": ["Ent\u00b7fie\u00b7dert", ",", "nackt", ",", "von", "al\u00b7lem", "aus\u00b7ge\u00b7lee\u00b7ret"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADJD", "$,", "APPR", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Was sie f\u00fcr wesentlich zu ihrem Wohlsein hielt,", "tokens": ["Was", "sie", "f\u00fcr", "we\u00b7sent\u00b7lich", "zu", "ih\u00b7rem", "Wohl\u00b7sein", "hielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Was Wunder, wenn sich ihr ein Lehrbegriff empfiehlt,", "tokens": ["Was", "Wun\u00b7der", ",", "wenn", "sich", "ihr", "ein", "Lehr\u00b7be\u00b7griff", "emp\u00b7fiehlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "KOUS", "PRF", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der sie die Kunst es zu entbehren lehret?", "tokens": ["Der", "sie", "die", "Kunst", "es", "zu", "ent\u00b7beh\u00b7ren", "leh\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Der ihr beweist, was nicht zu ihr geh\u00f6ret,", "tokens": ["Der", "ihr", "be\u00b7weist", ",", "was", "nicht", "zu", "ihr", "ge\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PRELS", "PTKNEG", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Was sie verlieren kann, sei keinen Seufzer wert;", "tokens": ["Was", "sie", "ver\u00b7lie\u00b7ren", "kann", ",", "sei", "kei\u00b7nen", "Seuf\u00b7zer", "wert", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$,", "VAFIN", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ja, ihren Unmut zu betr\u00fcgen,", "tokens": ["Ja", ",", "ih\u00b7ren", "Un\u00b7mut", "zu", "be\u00b7tr\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Aus der Entbehrung selbst ein k\u00fcnstliches Vergn\u00fcgen", "tokens": ["Aus", "der", "Ent\u00b7beh\u00b7rung", "selbst", "ein", "k\u00fcnst\u00b7li\u00b7ches", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ihr, statt des wahren, schafft? \u2013 Was ist so angenehm", "tokens": ["Ihr", ",", "statt", "des", "wah\u00b7ren", ",", "schafft", "?", "\u2013", "Was", "ist", "so", "an\u00b7ge\u00b7nehm"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "KOUI", "ART", "ADJA", "$,", "VVFIN", "$.", "$(", "PWS", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "F\u00fcr den gekr\u00e4nkten Stolz, als ein System,", "tokens": ["F\u00fcr", "den", "ge\u00b7kr\u00e4nk\u00b7ten", "Stolz", ",", "als", "ein", "Sys\u00b7tem", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Das uns gew\u00f6hnt f\u00fcr Puppenwerk zu achten", "tokens": ["Das", "uns", "ge\u00b7w\u00f6hnt", "f\u00fcr", "Pup\u00b7pen\u00b7werk", "zu", "ach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "VVPP", "APPR", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Was aufgeh\u00f6rt f\u00fcr uns ein Gut zu sein?", "tokens": ["Was", "auf\u00b7ge\u00b7h\u00f6rt", "f\u00fcr", "uns", "ein", "Gut", "zu", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPER", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Was, meinst du, bildete der ", "tokens": ["Was", ",", "meinst", "du", ",", "bil\u00b7de\u00b7te", "der"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWS", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Der, gro\u00df genug Monarchen zu verachten,", "tokens": ["Der", ",", "gro\u00df", "ge\u00b7nug", "Mon\u00b7ar\u00b7chen", "zu", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "ADV", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Von Philipps Sohn nichts bat, als freien Sonnenschein?", "tokens": ["Von", "Phi\u00b7lipps", "Sohn", "nichts", "bat", ",", "als", "frei\u00b7en", "Son\u00b7nen\u00b7schein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "PIS", "VVFIN", "$,", "KOUS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Noch mehr willkommen mu\u00df, im Falle den wir setzen,", "tokens": ["Noch", "mehr", "will\u00b7kom\u00b7men", "mu\u00df", ",", "im", "Fal\u00b7le", "den", "wir", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VMFIN", "$,", "APPRART", "NN", "ART", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die Schw\u00e4rmerei des Platonisten sein,", "tokens": ["Die", "Schw\u00e4r\u00b7me\u00b7rei", "des", "Pla\u00b7to\u00b7nis\u00b7ten", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Der das Geheimnis hat, die Freuden zu ", "tokens": ["Der", "das", "Ge\u00b7heim\u00b7nis", "hat", ",", "die", "Freu\u00b7den", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VAFIN", "$,", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Die Zeno nur ", "tokens": ["Die", "Ze\u00b7no", "nur"], "token_info": ["word", "word", "word"], "pos": ["ART", "NE", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.35": {"text": "Der, statt des tierischen ver\u00e4chtlichen Ergetzen", "tokens": ["Der", ",", "statt", "des", "tie\u00b7ri\u00b7schen", "ver\u00b7\u00e4cht\u00b7li\u00b7chen", "Er\u00b7get\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "KOUI", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.37": {"text": "Wir sehn mit ihm aus leicht erstiegnen H\u00f6hen", "tokens": ["Wir", "sehn", "mit", "ihm", "aus", "leicht", "er\u00b7sti\u00b7eg\u00b7nen", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+--++--+-+-", "measure": "iambic.penta.relaxed"}, "line.38": {"text": "Auf diesen Erdenball als einen Punkt herab;", "tokens": ["Auf", "die\u00b7sen", "Er\u00b7den\u00b7ball", "als", "ei\u00b7nen", "Punkt", "her\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KOKOM", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Ein Schlag mit seinem Zauberstab", "tokens": ["Ein", "Schlag", "mit", "sei\u00b7nem", "Zau\u00b7ber\u00b7stab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Hei\u00dft Welten um uns her bei Tausenden entstehen;", "tokens": ["Hei\u00dft", "Wel\u00b7ten", "um", "uns", "her", "bei", "Tau\u00b7sen\u00b7den", "ent\u00b7ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PRF", "APZR", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Sind's gleich nur Welten aus Ideen,", "tokens": ["Sin\u00b7d's", "gleich", "nur", "Wel\u00b7ten", "aus", "I\u00b7deen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.42": {"text": "So baut man sie so herrlich als man will;", "tokens": ["So", "baut", "man", "sie", "so", "herr\u00b7lich", "als", "man", "will", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "ADV", "ADJD", "KOKOM", "PIS", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Und steht einmal das Rad der \u00e4u\u00dfern Sinne still,", "tokens": ["Und", "steht", "ein\u00b7mal", "das", "Rad", "der", "\u00e4u\u00b7\u00dfern", "Sin\u00b7ne", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Wer sagt uns, da\u00df wir nicht im Traume wirklich sehen?", "tokens": ["Wer", "sagt", "uns", ",", "da\u00df", "wir", "nicht", "im", "Trau\u00b7me", "wirk\u00b7lich", "se\u00b7hen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "APPRART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Ein Traum, der uns zum Gast der G\u00f6tter macht \u2013\u00ab", "tokens": ["Ein", "Traum", ",", "der", "uns", "zum", "Gast", "der", "G\u00f6t\u00b7ter", "macht", "\u2013", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "\u00bbhat seinen Wert \u2013 zumal in einer Winternacht\u00ab,", "tokens": ["\u00bb", "hat", "sei\u00b7nen", "Wert", "\u2013", "zu\u00b7mal", "in", "ei\u00b7ner", "Win\u00b7ter\u00b7nacht", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPOSAT", "NN", "$(", "ADV", "APPR", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ruft Phanias: \u00bballein auch aus den sch\u00f6nsten Tr\u00e4umen", "tokens": ["Ruft", "Pha\u00b7ni\u00b7as", ":", "\u00bb", "al\u00b7lein", "auch", "aus", "den", "sch\u00f6ns\u00b7ten", "Tr\u00e4u\u00b7men"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "$.", "$(", "ADV", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist doch zuletzt Endymion erwacht!", "tokens": ["Ist", "doch", "zu\u00b7letzt", "En\u00b7dy\u00b7mi\u00b7on", "er\u00b7wacht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wozu, Musarion, aus Eigensinn vers\u00e4umen", "tokens": ["Wo\u00b7zu", ",", "Mu\u00b7sa\u00b7ri\u00b7on", ",", "aus", "Ei\u00b7gen\u00b7sinn", "ver\u00b7s\u00e4u\u00b7men"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "$,", "NN", "$,", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was wachend uns zu G\u00f6ttern macht?\u00ab", "tokens": ["Was", "wa\u00b7chend", "uns", "zu", "G\u00f6t\u00b7tern", "macht", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADJD", "PPER", "APPR", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "An Antworts Statt reicht sie, zum stillen Pfand", "tokens": ["An", "Ant\u00b7worts", "Statt", "reicht", "sie", ",", "zum", "stil\u00b7len", "Pfand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "VVFIN", "PPER", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Sympathie, ihm ihre sch\u00f6ne Hand.", "tokens": ["Der", "Sym\u00b7pa\u00b7thie", ",", "ihm", "ih\u00b7re", "sch\u00f6\u00b7ne", "Hand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er dr\u00fcckt mit sch\u00fcchternem Entz\u00fccken", "tokens": ["Er", "dr\u00fcckt", "mit", "sch\u00fcch\u00b7ter\u00b7nem", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie an sein schwellend Herz, und sucht in ihren Blicken", "tokens": ["Sie", "an", "sein", "schwel\u00b7lend", "Herz", ",", "und", "sucht", "in", "ih\u00b7ren", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "ADJD", "NN", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ob sie sein Klopfen f\u00fchlt. Ein sanftes Wiederdr\u00fccken", "tokens": ["Ob", "sie", "sein", "Klop\u00b7fen", "f\u00fchlt", ".", "Ein", "sanf\u00b7tes", "Wie\u00b7der\u00b7dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Beweist es ihm. Mit manchem s\u00fc\u00dfen Ach,", "tokens": ["Be\u00b7weist", "es", "ihm", ".", "Mit", "man\u00b7chem", "s\u00fc\u00b7\u00dfen", "Ach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$.", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Das ihr im Busen zu ersticken", "tokens": ["Das", "ihr", "im", "Bu\u00b7sen", "zu", "er\u00b7sti\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "APPRART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Unm\u00f6glich ist, bek\u00e4mpft sie allzu schwach", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "ist", ",", "be\u00b7k\u00e4mpft", "sie", "all\u00b7zu", "schwach"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "$,", "VVFIN", "PPER", "PTKA", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Die Macht des s\u00fc\u00dfesten der Triebe,", "tokens": ["Die", "Macht", "des", "s\u00fc\u00b7\u00dfes\u00b7ten", "der", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und k\u00e4mpfend noch bekennt ihr Herz den Sieg der Liebe.", "tokens": ["Und", "k\u00e4mp\u00b7fend", "noch", "be\u00b7kennt", "ihr", "Herz", "den", "Sieg", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Der sch\u00f6nste Tag folgt dieser sch\u00f6nen Nacht.", "tokens": ["Der", "sch\u00f6ns\u00b7te", "Tag", "folgt", "die\u00b7ser", "sch\u00f6\u00b7nen", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit jedem neuen f\u00fchlt sich unser Paar begl\u00fcckter", "tokens": ["Mit", "je\u00b7dem", "neu\u00b7en", "f\u00fchlt", "sich", "un\u00b7ser", "Paar", "be\u00b7gl\u00fcck\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "VVFIN", "PRF", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indem sich jedes selbst im andern gl\u00fccklich macht.", "tokens": ["In\u00b7dem", "sich", "je\u00b7des", "selbst", "im", "an\u00b7dern", "gl\u00fcck\u00b7lich", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PIAT", "ADV", "APPRART", "ADJA", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch \u00fcberstandne Not geschickter", "tokens": ["Durch", "\u00fc\u00b7bers\u00b7tand\u00b7ne", "Not", "ge\u00b7schick\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zum weiseren Gebrauch, zum reizendern Genu\u00df", "tokens": ["Zum", "wei\u00b7se\u00b7ren", "Ge\u00b7brauch", ",", "zum", "rei\u00b7zen\u00b7dern", "Ge\u00b7nu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Gl\u00fcckes, das sich ihm so unverhofft vers\u00f6hnte,", "tokens": ["Des", "Gl\u00fc\u00b7ckes", ",", "das", "sich", "ihm", "so", "un\u00b7ver\u00b7hofft", "ver\u00b7s\u00f6hn\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gleich fern von D\u00fcrftigkeit und stolzem \u00dcberflu\u00df,", "tokens": ["Gleich", "fern", "von", "D\u00fcrf\u00b7tig\u00b7keit", "und", "stol\u00b7zem", "\u00dc\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Gl\u00fcckselig, weil er's war, nicht weil die Welt es w\u00e4hnte,", "tokens": ["Gl\u00fcck\u00b7se\u00b7lig", ",", "weil", "er's", "war", ",", "nicht", "weil", "die", "Welt", "es", "w\u00e4hn\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PIS", "VAFIN", "$,", "PTKNEG", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bringt Phanias in neidenswerter Ruh", "tokens": ["Bringt", "Pha\u00b7ni\u00b7as", "in", "nei\u00b7dens\u00b7wer\u00b7ter", "Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ein unbeneidet Leben zu;", "tokens": ["Ein", "un\u00b7be\u00b7nei\u00b7det", "Le\u00b7ben", "zu", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "In Freuden, die der unverf\u00e4lschte Stempel", "tokens": ["In", "Freu\u00b7den", ",", "die", "der", "un\u00b7ver\u00b7f\u00e4lschte", "Stem\u00b7pel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Der Unschuld und Natur zu echten Freuden pr\u00e4gt.", "tokens": ["Der", "Un\u00b7schuld", "und", "Na\u00b7tur", "zu", "ech\u00b7ten", "Freu\u00b7den", "pr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der b\u00fcrgerliche Sturm, der stets Athen bewegt,", "tokens": ["Der", "b\u00fcr\u00b7ger\u00b7li\u00b7che", "Sturm", ",", "der", "stets", "A\u00b7then", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Trifft seine H\u00fctte nicht \u2013 den Tempel", "tokens": ["Trifft", "sei\u00b7ne", "H\u00fct\u00b7te", "nicht", "\u2013", "den", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Der Grazien, seitdem Musarion sie ziert.", "tokens": ["Der", "Gra\u00b7zi\u00b7en", ",", "seit\u00b7dem", "Mu\u00b7sa\u00b7ri\u00b7on", "sie", "ziert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bescheidne Kunst, durch ihren Witz geleitet,", "tokens": ["Be\u00b7scheid\u00b7ne", "Kunst", ",", "durch", "ih\u00b7ren", "Witz", "ge\u00b7lei\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Gibt der Natur, so weit sein Landgut sich verbreitet,", "tokens": ["Gibt", "der", "Na\u00b7tur", ",", "so", "weit", "sein", "Land\u00b7gut", "sich", "ver\u00b7brei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "PPOSAT", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den stillen Reiz, der ohne Schimmer r\u00fchrt.", "tokens": ["Den", "stil\u00b7len", "Reiz", ",", "der", "oh\u00b7ne", "Schim\u00b7mer", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Ein Garten, den mit Zephyrn und mit Floren", "tokens": ["Ein", "Gar\u00b7ten", ",", "den", "mit", "Ze\u00b7phyrn", "und", "mit", "Flo\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Pomona sich zum Aufenthalt erkoren;", "tokens": ["Po\u00b7mo\u00b7na", "sich", "zum", "Auf\u00b7ent\u00b7halt", "er\u00b7ko\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Ein Hain, worin sich Amor gern verliert,", "tokens": ["Ein", "Hain", ",", "wo\u00b7rin", "sich", "A\u00b7mor", "gern", "ver\u00b7liert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PRF", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Wo ernstes Denken oft mit leichtem Scherz sich gattet;", "tokens": ["Wo", "erns\u00b7tes", "Den\u00b7ken", "oft", "mit", "leich\u00b7tem", "Scherz", "sich", "gat\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ein kleiner Bach von Ulmen \u00fcberschattet,", "tokens": ["Ein", "klei\u00b7ner", "Bach", "von", "Ul\u00b7men", "\u00fc\u00b7bersc\u00b7hat\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "An dem der Mittagsschlaf ihn ungesucht beschleicht;", "tokens": ["An", "dem", "der", "Mit\u00b7tags\u00b7schlaf", "ihn", "un\u00b7ge\u00b7sucht", "be\u00b7schleicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Im Garten eine Sommerlaube,", "tokens": ["Im", "Gar\u00b7ten", "ei\u00b7ne", "Som\u00b7mer\u00b7lau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Wo, zu der Freundin Ku\u00df, der Saft der Purpurtraube,", "tokens": ["Wo", ",", "zu", "der", "Freun\u00b7din", "Ku\u00df", ",", "der", "Saft", "der", "Pur\u00b7pur\u00b7trau\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ART", "NN", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Den Thasos schickt, ihm wahrer Nektar deucht;", "tokens": ["Den", "Tha\u00b7sos", "schickt", ",", "ihm", "wah\u00b7rer", "Nek\u00b7tar", "deucht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Ein Nachbar, der Horazens Nachbarn gleicht,", "tokens": ["Ein", "Nach\u00b7bar", ",", "der", "Ho\u00b7ra\u00b7zens", "Nach\u00b7barn", "gleicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.29": {"text": "Gesundes Blut, ein unbew\u00f6lkt Gehirne,", "tokens": ["Ge\u00b7sun\u00b7des", "Blut", ",", "ein", "un\u00b7be\u00b7w\u00f6lkt", "Ge\u00b7hir\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Ein ruhig Herz und eine heitre Stirne,", "tokens": ["Ein", "ru\u00b7hig", "Herz", "und", "ei\u00b7ne", "heit\u00b7re", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Wie vieles macht ihn reich! Denkt noch Musarion", "tokens": ["Wie", "vie\u00b7les", "macht", "ihn", "reich", "!", "Denkt", "noch", "Mu\u00b7sa\u00b7ri\u00b7on"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "ADJD", "$.", "VVFIN", "ADV", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Hinzu, und sagt, was kann zum frohen Leben", "tokens": ["Hin\u00b7zu", ",", "und", "sagt", ",", "was", "kann", "zum", "fro\u00b7hen", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKVZ", "$,", "KON", "VVFIN", "$,", "PWS", "VMFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Der G\u00f6tter Gunst ihm mehr und bessers geben?", "tokens": ["Der", "G\u00f6t\u00b7ter", "Gunst", "ihm", "mehr", "und", "bes\u00b7sers", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "ADV", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Die Weisheit nur, den ganzen Wert davon", "tokens": ["Die", "Weis\u00b7heit", "nur", ",", "den", "gan\u00b7zen", "Wert", "da\u00b7von"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Zu f\u00fchlen, immer ihn zu f\u00fchlen,", "tokens": ["Zu", "f\u00fch\u00b7len", ",", "im\u00b7mer", "ihn", "zu", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Und, seines Gl\u00fcckes froh, kein andres zu erzielen!", "tokens": ["Und", ",", "sei\u00b7nes", "Gl\u00fc\u00b7ckes", "froh", ",", "kein", "and\u00b7res", "zu", "er\u00b7zie\u00b7len", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "NN", "ADJD", "$,", "PIAT", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Auch diese gab sie ihm. Sein Mentor war", "tokens": ["Auch", "die\u00b7se", "gab", "sie", "ihm", ".", "Sein", "Men\u00b7tor", "war"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "PPER", "$.", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Kein Cyniker mit ungek\u00e4mmtem Haar,", "tokens": ["Kein", "Cy\u00b7ni\u00b7ker", "mit", "un\u00b7ge\u00b7k\u00e4mm\u00b7tem", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Kein runzligter Kleanth, der, wenn die Flasche blinkt,", "tokens": ["Kein", "runz\u00b7lig\u00b7ter", "Kle\u00b7an\u00b7th", ",", "der", ",", "wenn", "die", "Fla\u00b7sche", "blinkt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PRELS", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.40": {"text": "Wie Zeno spricht und wie Silenus trinkt:", "tokens": ["Wie", "Ze\u00b7no", "spricht", "und", "wie", "Si\u00b7le\u00b7nus", "trinkt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "KON", "PWAV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.42": {"text": "Auch lernt' er gern, und schnell, und sonder M\u00fch,", "tokens": ["Auch", "lernt'", "er", "gern", ",", "und", "schnell", ",", "und", "son\u00b7der", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "ADJD", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Die reizende Philosophie,", "tokens": ["Die", "rei\u00b7zen\u00b7de", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.44": {"text": "Die, was Natur und Schicksal uns gew\u00e4hrt,", "tokens": ["Die", ",", "was", "Na\u00b7tur", "und", "Schick\u00b7sal", "uns", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWS", "NN", "KON", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Vergn\u00fcgt genie\u00dft, und gern den Rest entbehrt;", "tokens": ["Ver\u00b7gn\u00fcgt", "ge\u00b7nie\u00dft", ",", "und", "gern", "den", "Rest", "ent\u00b7behrt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "$,", "KON", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Die Dinge dieser Welt gern von der sch\u00f6nen Seite", "tokens": ["Die", "Din\u00b7ge", "die\u00b7ser", "Welt", "gern", "von", "der", "sch\u00f6\u00b7nen", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PDAT", "NN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Betrachtet; dem Geschick sich unterw\u00fcrfig macht,", "tokens": ["Be\u00b7trach\u00b7tet", ";", "dem", "Ge\u00b7schick", "sich", "un\u00b7ter\u00b7w\u00fcr\u00b7fig", "macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "ART", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Nicht wissen will was alles das bedeute,", "tokens": ["Nicht", "wis\u00b7sen", "will", "was", "al\u00b7les", "das", "be\u00b7deu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VMFIN", "PWS", "PIS", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.49": {"text": "Was Zeus aus Huld in r\u00e4tselhafte Nacht", "tokens": ["Was", "Zeus", "aus", "Huld", "in", "r\u00e4t\u00b7sel\u00b7haf\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NE", "APPR", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.50": {"text": "Vor uns verbarg, und auf die guten Leute", "tokens": ["Vor", "uns", "ver\u00b7barg", ",", "und", "auf", "die", "gu\u00b7ten", "Leu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "Der Unterwelt, so sehr sie Toren sind,", "tokens": ["Der", "Un\u00b7ter\u00b7welt", ",", "so", "sehr", "sie", "To\u00b7ren", "sind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADV", "PPER", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.52": {"text": "Nie b\u00f6se wird, nur l\u00e4cherlich sie findt", "tokens": ["Nie", "b\u00f6\u00b7se", "wird", ",", "nur", "l\u00e4\u00b7cher\u00b7lich", "sie", "findt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "ADV", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.53": {"text": "Und sich dazu, sie drum nicht minder liebet,", "tokens": ["Und", "sich", "da\u00b7zu", ",", "sie", "drum", "nicht", "min\u00b7der", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PAV", "$,", "PPER", "PAV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.54": {"text": "Den Irrenden bedaurt, und nur den Gleisner flieht;", "tokens": ["Den", "Ir\u00b7ren\u00b7den", "be\u00b7daurt", ",", "und", "nur", "den", "Gleis\u00b7ner", "flieht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Nicht stets von Tugend ", "tokens": ["Nicht", "stets", "von", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.56": {"text": "Doch, ohne Sold und aus Geschmack, sie ", "tokens": ["Doch", ",", "oh\u00b7ne", "Sold", "und", "aus", "Ge\u00b7schmack", ",", "sie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "$,", "KOUI", "NN", "KON", "APPR", "NN", "$,", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "Und, gl\u00fccklich oder nicht, die Welt", "tokens": ["Und", ",", "gl\u00fcck\u00b7lich", "o\u00b7der", "nicht", ",", "die", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ADJD", "KON", "PTKNEG", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "F\u00fcr kein Elysium, f\u00fcr keine H\u00f6lle h\u00e4lt,", "tokens": ["F\u00fcr", "kein", "E\u00b7ly\u00b7si\u00b7um", ",", "f\u00fcr", "kei\u00b7ne", "H\u00f6l\u00b7le", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Nie so verderbt, als sie der Sittenrichter", "tokens": ["Nie", "so", "ver\u00b7derbt", ",", "als", "sie", "der", "Sit\u00b7ten\u00b7rich\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.60": {"text": "Von seinem Thron \u2013 im sechsten Stockwerk sieht,", "tokens": ["Von", "sei\u00b7nem", "Thron", "\u2013", "im", "sechs\u00b7ten", "Stock\u00b7werk", "sieht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.61": {"text": "So lustig nie als jugendliche Dichter", "tokens": ["So", "lus\u00b7tig", "nie", "als", "ju\u00b7gend\u00b7li\u00b7che", "Dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.62": {"text": "Sie malen, wenn ihr Hirn von Wein und Phyllis gl\u00fcht.", "tokens": ["Sie", "ma\u00b7len", ",", "wenn", "ihr", "Hirn", "von", "Wein", "und", "Phyl\u00b7lis", "gl\u00fcht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "KOUS", "PPOSAT", "NN", "APPR", "NN", "KON", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "So war, so dacht und lebte Phanias,", "tokens": ["So", "war", ",", "so", "dacht", "und", "leb\u00b7te", "Pha\u00b7ni\u00b7as", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "ADV", "VVFIN", "KON", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und weil ", "tokens": ["Und", "weil"], "token_info": ["word", "word"], "pos": ["KON", "KOUS"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "So tat er wohl, zu sein, zu denken und zu leben,", "tokens": ["So", "tat", "er", "wohl", ",", "zu", "sein", ",", "zu", "den\u00b7ken", "und", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PTKZU", "VAINF", "$,", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ward aus dem Manne, der so gerne \u2013 Sph\u00e4ren ma\u00df?\u00ab", "tokens": ["Ward", "aus", "dem", "Man\u00b7ne", ",", "der", "so", "ger\u00b7ne", "\u2013", "Sph\u00e4\u00b7ren", "ma\u00df", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "$(", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gut, da\u00df ihr fragt, den h\u00e4tt ich rein vergessen", "tokens": ["Gut", ",", "da\u00df", "ihr", "fragt", ",", "den", "h\u00e4tt", "ich", "rein", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "PPER", "VVFIN", "$,", "ART", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Er ward in einer einzgen Nacht", "tokens": ["Er", "ward", "in", "ei\u00b7ner", "einz\u00b7gen", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zum \u03b3\u03bd\u03c9\u03d1\u03b9 \u03c3\u03b5\u03b1\u03c5\u03c4\u03bf\u03bd in Chloens Arm gebracht;", "tokens": ["Zum", "\u03b3\u03bd\u03c9\u03d1\u03b9", "\u03c3\u03b5\u03b1\u03c5\u03c4\u03bf\u03bd", "in", "Chloens", "Arm", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er fand er sei nicht klug, und lernte Bohnen essen.", "tokens": ["Er", "fand", "er", "sei", "nicht", "klug", ",", "und", "lern\u00b7te", "Boh\u00b7nen", "es\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "KON", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u00bbund Herr Kleanth?\u00ab \u2013 Der kroch, so bald die Mittagssonne", "tokens": ["\u00bb", "und", "Herr", "Kle\u00b7an\u00b7th", "?", "\u00ab", "\u2013", "Der", "kroch", ",", "so", "bald", "die", "Mit\u00b7tags\u00b7son\u00b7ne"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KON", "NN", "NE", "$.", "$(", "$(", "ART", "NN", "$,", "ADV", "ADV", "ART", "NN"], "meter": "-++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.10": {"text": "Ihn aufgeweckt, ganz leise auf den Zehn", "tokens": ["Ihn", "auf\u00b7ge\u00b7weckt", ",", "ganz", "lei\u00b7se", "auf", "den", "Zehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVPP", "$,", "ADV", "ADJD", "APPR", "ART", "CARD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Aus seinem Stall \u2013 vielleicht in eine ", "tokens": ["Aus", "sei\u00b7nem", "Stall", "\u2013", "viel\u00b7leicht", "in", "ei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ADV", "APPR", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Kurz, er verschwand, und ward nicht mehr gesehn.", "tokens": ["Kurz", ",", "er", "ver\u00b7schwand", ",", "und", "ward", "nicht", "mehr", "ge\u00b7sehn", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVFIN", "$,", "KON", "VAFIN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}