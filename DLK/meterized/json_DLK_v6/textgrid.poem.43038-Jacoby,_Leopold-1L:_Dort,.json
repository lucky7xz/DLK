{"textgrid.poem.43038": {"metadata": {"author": {"name": "Jacoby, Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dort,", "genre": "verse", "period": "N.A.", "pub_year": 1867, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dort,", "tokens": ["Dort", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "An der beiden Stadttheile Vereinigungsort,", "tokens": ["An", "der", "bei\u00b7den", "Stadt\u00b7thei\u00b7le", "Ver\u00b7ei\u00b7ni\u00b7gungs\u00b7ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "PTKVZ", "$,"], "meter": "--+-+---+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Wo mittendurch die Spree sich ergie\u00dft,", "tokens": ["Wo", "mit\u00b7ten\u00b7durch", "die", "Spree", "sich", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NE", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die nun in einem Strombett flie\u00dft,", "tokens": ["Die", "nun", "in", "ei\u00b7nem", "Strom\u00b7bett", "flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das eingeengt ist", "tokens": ["Das", "ein\u00b7ge\u00b7engt", "ist"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VVPP", "VAFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und eingeschr\u00e4nkt ist,", "tokens": ["Und", "ein\u00b7ge\u00b7schr\u00e4nkt", "ist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Doch damals war es breit und frei", "tokens": ["Doch", "da\u00b7mals", "war", "es", "breit", "und", "frei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und hatte dort der Arme zwei,", "tokens": ["Und", "hat\u00b7te", "dort", "der", "Ar\u00b7me", "zwei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die zwischen sich lie\u00dfen eine L\u00fccke", "tokens": ["Die", "zwi\u00b7schen", "sich", "lie\u00b7\u00dfen", "ei\u00b7ne", "L\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PRF", "VVFIN", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Als Insel, da stand am Ende der Br\u00fccke,", "tokens": ["Als", "In\u00b7sel", ",", "da", "stand", "am", "En\u00b7de", "der", "Br\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ADV", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Die heute kurz ist und damals lang war", "tokens": ["Die", "heu\u00b7te", "kurz", "ist", "und", "da\u00b7mals", "lang", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "KON", "ADV", "ADJD", "VAFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Und ein Hauptverbindungsgang war,", "tokens": ["Und", "ein", "Haupt\u00b7ver\u00b7bin\u00b7dungs\u00b7gang", "war", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "$,"], "meter": "--+-++-+", "measure": "anapaest.init"}, "line.13": {"text": "Ein Haus,", "tokens": ["Ein", "Haus", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "Mit dem Giebel gebaut zur Spree hinaus,", "tokens": ["Mit", "dem", "Gie\u00b7bel", "ge\u00b7baut", "zur", "Spree", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "APPRART", "NE", "APZR", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.15": {"text": "Aus Holzwerk aufgef\u00fchrt,", "tokens": ["Aus", "Holz\u00b7werk", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Mit Schnitzwerk ausgeziert,", "tokens": ["Mit", "Schnitz\u00b7werk", "aus\u00b7ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Das war vom alten Berlin das Rathaus,", "tokens": ["Das", "war", "vom", "al\u00b7ten", "Ber\u00b7lin", "das", "Rat\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "ADJA", "NE", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Der Republik Stadthaus und Staathaus.", "tokens": ["Der", "Re\u00b7pub\u00b7lik", "Stadt\u00b7haus", "und", "Staat\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Es war", "tokens": ["Es", "war"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Ein nebliger Tag im Februar,", "tokens": ["Ein", "neb\u00b7li\u00b7ger", "Tag", "im", "Feb\u00b7ru\u00b7ar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da zogen dorthin im Amtsornat", "tokens": ["Da", "zo\u00b7gen", "dor\u00b7thin", "im", "Amt\u00b7sor\u00b7nat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Herren vom Rath", "tokens": ["Die", "Her\u00b7ren", "vom", "Rath"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Und zum guten Berathungswerke", "tokens": ["Und", "zum", "gu\u00b7ten", "Be\u00b7ra\u00b7thungs\u00b7wer\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Auch die Vertreter der Gewerke.", "tokens": ["Auch", "die", "Ver\u00b7tre\u00b7ter", "der", "Ge\u00b7wer\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als nun im Rathauszimmer allm\u00e4hlig", "tokens": ["Als", "nun", "im", "Rat\u00b7haus\u00b7zim\u00b7mer", "all\u00b7m\u00e4h\u00b7lig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPRART", "NN", "ADJD"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Die Versammlung ward vollz\u00e4hlig, \u2013", "tokens": ["Die", "Ver\u00b7samm\u00b7lung", "ward", "voll\u00b7z\u00e4h\u00b7lig", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Die Rathm\u00e4nner weiche Sitzpl\u00e4tze fanden,", "tokens": ["Die", "Rath\u00b7m\u00e4n\u00b7ner", "wei\u00b7che", "Sitz\u00b7pl\u00e4t\u00b7ze", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Die Werkm\u00e4nner gesondert dagegenstanden \u2013", "tokens": ["Die", "Werk\u00b7m\u00e4n\u00b7ner", "ge\u00b7son\u00b7dert", "da\u00b7ge\u00b7gen\u00b7stan\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAINF", "$("], "meter": "-++--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Da nahm der im Chorsitz", "tokens": ["Da", "nahm", "der", "im", "Chor\u00b7sitz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "APPRART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "Von den Rathm\u00e4nnern f\u00fchrte den Vorsitz,", "tokens": ["Von", "den", "Rath\u00b7m\u00e4n\u00b7nern", "f\u00fchr\u00b7te", "den", "Vor\u00b7sitz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "--++-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Mit Husten und R\u00e4uspern, ein wenig zag,", "tokens": ["Mit", "Hus\u00b7ten", "und", "R\u00e4us\u00b7pern", ",", "ein", "we\u00b7nig", "zag", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ART", "PIAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Das Wort und sprach:", "tokens": ["Das", "Wort", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Meine werthen Herrn, meine guten und huldigen,", "tokens": ["Mei\u00b7ne", "wert\u00b7hen", "Herrn", ",", "mei\u00b7ne", "gu\u00b7ten", "und", "hul\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "KON", "VVFIN", "$,"], "meter": "+-+-+--+--+--", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "Der Herr B\u00fcrgermeister ist krank und l\u00e4\u00dft sich entschuldigen.", "tokens": ["Der", "Herr", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter", "ist", "krank", "und", "l\u00e4\u00dft", "sich", "ent\u00b7schul\u00b7di\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "KON", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+--+--+-+--+--", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Sogleich begann unter den Werkm\u00e4nnern ein Schurren", "tokens": ["Sog\u00b7leich", "be\u00b7gann", "un\u00b7ter", "den", "Werk\u00b7m\u00e4n\u00b7nern", "ein", "Schur\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+---++--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und lautes Murren,", "tokens": ["Und", "lau\u00b7tes", "Mur\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und einer trat vor, der war breitknochig", "tokens": ["Und", "ei\u00b7ner", "trat", "vor", ",", "der", "war", "breit\u00b7kno\u00b7chig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PTKVZ", "$,", "PRELS", "VAFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und aufpochig,", "tokens": ["Und", "auf\u00b7po\u00b7chig", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Klopfte mit den Kn\u00f6cheln der Faust auf den Tisch", "tokens": ["Klopf\u00b7te", "mit", "den", "Kn\u00f6\u00b7cheln", "der", "Faust", "auf", "den", "Tisch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und rief mit dr\u00f6hnender Stimme frisch:", "tokens": ["Und", "rief", "mit", "dr\u00f6h\u00b7nen\u00b7der", "Stim\u00b7me", "frisch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ist er krank?", "tokens": ["Ist", "er", "krank", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Sa\u00df wohl beim letzten Festmahl zu lang?", "tokens": ["Sa\u00df", "wohl", "beim", "letz\u00b7ten", "Fest\u00b7mahl", "zu", "lang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "ADJA", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Solch unsichtbares Licht,", "tokens": ["Solch", "un\u00b7sicht\u00b7ba\u00b7res", "Licht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PPOSAT", "NN", "$,"], "meter": "+----+", "measure": "dactylic.init"}, "line.10": {"text": "Einen solchen B\u00fcrgermeister brauchen wir nicht!", "tokens": ["Ei\u00b7nen", "sol\u00b7chen", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter", "brau\u00b7chen", "wir", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.11": {"text": "Wenn all' die G\u00e4uche", "tokens": ["Wenn", "all'", "die", "G\u00e4u\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Und dicken B\u00e4uche", "tokens": ["Und", "di\u00b7cken", "B\u00e4u\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "Ihr faules Regiment hier so weiter f\u00fchren,", "tokens": ["Ihr", "fau\u00b7les", "Re\u00b7gi\u00b7ment", "hier", "so", "wei\u00b7ter", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "So werden wir's bald einmal probiren,", "tokens": ["So", "wer\u00b7den", "wir's", "bald", "ein\u00b7mal", "pro\u00b7bi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAINF", "VAFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Uns ohne sie selbst zu regieren! \u2013", "tokens": ["Uns", "oh\u00b7ne", "sie", "selbst", "zu", "re\u00b7gie\u00b7ren", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "APPR", "PPER", "ADV", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Da rief ihm Beifall sein ganzer Chor.", "tokens": ["Da", "rief", "ihm", "Bei\u00b7fall", "sein", "gan\u00b7zer", "Chor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Dem Stadtschreiber aber raunt einer in's Ohr:", "tokens": ["Dem", "Stadt\u00b7schrei\u00b7ber", "a\u00b7ber", "raunt", "ei\u00b7ner", "in's", "Ohr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "ART", "APPRART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.18": {"text": "Das ist ein Grobschmied, der kann's geh\u00f6rig.", "tokens": ["Das", "ist", "ein", "Grob\u00b7schmied", ",", "der", "kann's", "ge\u00b7h\u00f6\u00b7rig", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Und der erwidert ihm: das h\u00f6r' ich.", "tokens": ["Und", "der", "er\u00b7wi\u00b7dert", "ihm", ":", "das", "h\u00f6r'", "ich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "PPER", "$.", "PDS", "VVFIN", "PPER", "$."], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}}, "stanza.4": {"line.1": {"text": "Der im Vorsitz aber, ungest\u00f6rt,", "tokens": ["Der", "im", "Vor\u00b7sitz", "a\u00b7ber", ",", "un\u00b7ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ADV", "$,", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Fuhr fort, als h\u00e4tt' er gar nichts geh\u00f6rt:", "tokens": ["Fuhr", "fort", ",", "als", "h\u00e4tt'", "er", "gar", "nichts", "ge\u00b7h\u00f6rt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Warum wir unserer Stadt zum Frommen", "tokens": ["Wa\u00b7rum", "wir", "un\u00b7se\u00b7rer", "Stadt", "zum", "From\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Heute sind hierhergekommen,", "tokens": ["Heu\u00b7te", "sind", "hier\u00b7her\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das ist wohl Allen bekannt genug.", "tokens": ["Das", "ist", "wohl", "Al\u00b7len", "be\u00b7kannt", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PIS", "ADJD", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wir erwarten demn\u00e4chst gar hohen Besuch", "tokens": ["Wir", "er\u00b7war\u00b7ten", "dem\u00b7n\u00e4chst", "gar", "ho\u00b7hen", "Be\u00b7such"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJA", "NN"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Von seiner Durchlaucht, dem jungen F\u00fcrsten,", "tokens": ["Von", "sei\u00b7ner", "Durch\u00b7laucht", ",", "dem", "jun\u00b7gen", "F\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Nach dessen Gunst und Gnade zu d\u00fcrsten", "tokens": ["Nach", "des\u00b7sen", "Gunst", "und", "Gna\u00b7de", "zu", "d\u00fcrs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Diese gute, getreue Stadt", "tokens": ["Die\u00b7se", "gu\u00b7te", ",", "ge\u00b7treu\u00b7e", "Stadt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "Ursache haben mu\u00df und hat,", "tokens": ["Ur\u00b7sa\u00b7che", "ha\u00b7ben", "mu\u00df", "und", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAINF", "VMFIN", "KON", "VAFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Weil er vom Kaiser ein Abgesandter ist", "tokens": ["Weil", "er", "vom", "Kai\u00b7ser", "ein", "Ab\u00b7ge\u00b7sand\u00b7ter", "ist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Und noch dazu sein Verwandter ist.", "tokens": ["Und", "noch", "da\u00b7zu", "sein", "Ver\u00b7wand\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PAV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.13": {"text": "Mit seiner Braut kommt er vom S\u00fcden her,", "tokens": ["Mit", "sei\u00b7ner", "Braut", "kommt", "er", "vom", "S\u00fc\u00b7den", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Der Stadt Berlin zur gewaltigen Ehr'.", "tokens": ["Der", "Stadt", "Ber\u00b7lin", "zur", "ge\u00b7wal\u00b7ti\u00b7gen", "Ehr'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Mithin handelt es sich, dazu zu gelangen,", "tokens": ["Mi\u00b7thin", "han\u00b7delt", "es", "sich", ",", "da\u00b7zu", "zu", "ge\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Ihn unterth\u00e4nigst fein zu empfangen,", "tokens": ["Ihn", "un\u00b7ter\u00b7th\u00e4\u00b7nigst", "fein", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Auf da\u00df er Ursach zum Tadeln mit nichten habe", "tokens": ["Auf", "da\u00df", "er", "Ur\u00b7sach", "zum", "Ta\u00b7deln", "mit", "nich\u00b7ten", "ha\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "NN", "APPRART", "NN", "APPR", "PIS", "VAFIN"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.18": {"text": "Und dem Kaiser nur Lob zu berichten habe.", "tokens": ["Und", "dem", "Kai\u00b7ser", "nur", "Lob", "zu", "be\u00b7rich\u00b7ten", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.19": {"text": "Also schlage zun\u00e4chst ich f\u00fcr,", "tokens": ["Al\u00b7so", "schla\u00b7ge", "zu\u00b7n\u00e4chst", "ich", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPR", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.20": {"text": "Da\u00df man vom Rath hier einen erk\u00fcr',", "tokens": ["Da\u00df", "man", "vom", "Rath", "hier", "ei\u00b7nen", "er\u00b7k\u00fcr'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "ADV", "ART", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "Der in wohlgesetztem Redeflu\u00df", "tokens": ["Der", "in", "wohl\u00b7ge\u00b7setz\u00b7tem", "Re\u00b7de\u00b7flu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.22": {"text": "Den F\u00fcrsten am Thor empfangen mu\u00df,", "tokens": ["Den", "F\u00fcrs\u00b7ten", "am", "Thor", "emp\u00b7fan\u00b7gen", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Der Stadt zum Heil, den H\u00f6rern aber zum Hochgenu\u00df.", "tokens": ["Der", "Stadt", "zum", "Heil", ",", "den", "H\u00f6\u00b7rern", "a\u00b7ber", "zum", "Hoch\u00b7ge\u00b7nu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Darauf trat ein andrer vom Chor", "tokens": ["Da\u00b7rauf", "trat", "ein", "an\u00b7drer", "vom", "Chor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "APPRART", "NN"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Der Gewerke vor,", "tokens": ["Der", "Ge\u00b7wer\u00b7ke", "vor", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.26": {"text": "Das war ein Wollenweber", "tokens": ["Das", "war", "ein", "Wol\u00b7len\u00b7we\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "Und redete gradweg von der Leber:", "tokens": ["Und", "re\u00b7de\u00b7te", "grad\u00b7weg", "von", "der", "Le\u00b7ber", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-----+--+-", "measure": "iambic.di.relaxed"}, "line.28": {"text": "Da\u00df einer von euch dort spricht,", "tokens": ["Da\u00df", "ei\u00b7ner", "von", "euch", "dort", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.29": {"text": "Offen gesagt, das gef\u00e4llt mir nicht,", "tokens": ["Of\u00b7fen", "ge\u00b7sagt", ",", "das", "ge\u00b7f\u00e4llt", "mir", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.30": {"text": "Der, wenn er ein f\u00fcrstlich Haupt erblickt,", "tokens": ["Der", ",", "wenn", "er", "ein", "f\u00fcrst\u00b7lich", "Haupt", "er\u00b7blickt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "ART", "ADJD", "NN", "VVPP", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.31": {"text": "Wie ein Taschenmesser zusammenknickt,", "tokens": ["Wie", "ein", "Ta\u00b7schen\u00b7mes\u00b7ser", "zu\u00b7sam\u00b7men\u00b7knickt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.32": {"text": "Und wollt er vorher sich hart erweisen", "tokens": ["Und", "wollt", "er", "vor\u00b7her", "sich", "hart", "er\u00b7wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "PRF", "ADJD", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Als Eisen,", "tokens": ["Als", "Ei\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.34": {"text": "Dann wird er stracks", "tokens": ["Dann", "wird", "er", "stracks"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.35": {"text": "Weich wie Wachs,", "tokens": ["Weich", "wie", "Wachs", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.36": {"text": "Da\u00df ihm gleich vor Ehrfurcht die Kniee knacken, \u2013", "tokens": ["Da\u00df", "ihm", "gleich", "vor", "Ehr\u00b7furcht", "die", "Kni\u00b7ee", "kna\u00b7cken", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "ART", "NN", "VVINF", "$,", "$("], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "Aus solchem Teig sind wir nicht gebacken.", "tokens": ["Aus", "sol\u00b7chem", "Teig", "sind", "wir", "nicht", "ge\u00b7ba\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "Diese Stadt,", "tokens": ["Die\u00b7se", "Stadt", ","], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.39": {"text": "Die annoch keinen Herrn \u00fcber sich hat,", "tokens": ["Die", "an\u00b7noch", "kei\u00b7nen", "Herrn", "\u00fc\u00b7ber", "sich", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "APPR", "PRF", "VAFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "Die hat immer darauf gehalten stolz,", "tokens": ["Die", "hat", "im\u00b7mer", "da\u00b7rauf", "ge\u00b7hal\u00b7ten", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PAV", "VVPP", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Geschnitzt zu sein aus hartem Holz,", "tokens": ["Ge\u00b7schnitzt", "zu", "sein", "aus", "har\u00b7tem", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PTKZU", "VAINF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Zu sprechen k\u00fchn und sich nicht zu schmiegen", "tokens": ["Zu", "spre\u00b7chen", "k\u00fchn", "und", "sich", "nicht", "zu", "schmie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADJD", "KON", "PRF", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.43": {"text": "Und lieber zu brechen als sich zu biegen.", "tokens": ["Und", "lie\u00b7ber", "zu", "bre\u00b7chen", "als", "sich", "zu", "bie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "KOKOM", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.44": {"text": "Es sind aber des Volkes Klagen", "tokens": ["Es", "sind", "a\u00b7ber", "des", "Vol\u00b7kes", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.45": {"text": "Genug vor aller Welt zu sagen,", "tokens": ["Ge\u00b7nug", "vor", "al\u00b7ler", "Welt", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Braucht nur mal bei uns herumzufragen. \u2013", "tokens": ["Braucht", "nur", "mal", "bei", "uns", "her\u00b7um\u00b7zu\u00b7fra\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.47": {"text": "Dann dreht er sich wieder um und ging,", "tokens": ["Dann", "dreht", "er", "sich", "wie\u00b7der", "um", "und", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.48": {"text": "Und lauter Zuruf ihn empfing.", "tokens": ["Und", "lau\u00b7ter", "Zu\u00b7ruf", "ihn", "emp\u00b7fing", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}}, "stanza.5": {"line.1": {"text": "Darnach", "tokens": ["Dar\u00b7nach"], "token_info": ["word"], "pos": ["PAV"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Einer vom Rath sich erhob und sprach:", "tokens": ["Ei\u00b7ner", "vom", "Rath", "sich", "er\u00b7hob", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPRART", "NN", "PRF", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Alsdann nunmehro", "tokens": ["Als\u00b7dann", "nun\u00b7meh\u00b7ro"], "token_info": ["word", "word"], "pos": ["ADV", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Schlag' ich vor zur Begr\u00fc\u00dfung von Dero", "tokens": ["Schlag'", "ich", "vor", "zur", "Be\u00b7gr\u00fc\u00b7\u00dfung", "von", "De\u00b7ro"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "APPRART", "NN", "APPR", "PDS"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Hohe Gnaden und F\u00fcrstlichkeit", "tokens": ["Ho\u00b7he", "Gna\u00b7den", "und", "F\u00fcrst\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Eine Jungfrau in wei\u00dfem Kleid.", "tokens": ["Ei\u00b7ne", "Jung\u00b7frau", "in", "wei\u00b7\u00dfem", "Kleid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Mit ihren Kolleginnen", "tokens": ["Mit", "ih\u00b7ren", "Kol\u00b7le\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wird sie sicherlich Huld gewinnen.", "tokens": ["Wird", "sie", "si\u00b7cher\u00b7lich", "Huld", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "NE", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Alsofort", "tokens": ["Al\u00b7so\u00b7fort"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Fiel der Stadtschreiber ihm ins Wort:", "tokens": ["Fiel", "der", "Stadt\u00b7schrei\u00b7ber", "ihm", "ins", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "APPRART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Wir haben Sch\u00f6nheiten ein ganzes Heer,", "tokens": ["Wir", "ha\u00b7ben", "Sch\u00f6n\u00b7hei\u00b7ten", "ein", "gan\u00b7zes", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Doch eben darum die Wahl ist schwer.", "tokens": ["Doch", "e\u00b7ben", "da\u00b7rum", "die", "Wahl", "ist", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PAV", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Erst wird gehadert hin und her,", "tokens": ["Erst", "wird", "ge\u00b7ha\u00b7dert", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der will seine Tochter im Glanze sehn,", "tokens": ["Der", "will", "sei\u00b7ne", "Toch\u00b7ter", "im", "Glan\u00b7ze", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Und der andere giebt zu verstehn,", "tokens": ["Und", "der", "an\u00b7de\u00b7re", "giebt", "zu", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.8": {"text": "Seine w\u00e4r nicht minder sch\u00f6n;", "tokens": ["Sei\u00b7ne", "w\u00e4r", "nicht", "min\u00b7der", "sch\u00f6n", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Und zum Schlu\u00df kommt heraus nach all dem Streiten", "tokens": ["Und", "zum", "Schlu\u00df", "kommt", "he\u00b7raus", "nach", "all", "dem", "Strei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "ADV", "APPR", "PIAT", "ART", "NN"], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.10": {"text": "Eine Auswahl von H\u00e4\u00dflichkeiten. \u2013", "tokens": ["Ei\u00b7ne", "Aus\u00b7wahl", "von", "H\u00e4\u00df\u00b7lich\u00b7kei\u00b7ten", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$.", "$("], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.11": {"text": "Da lachten Alle rings,", "tokens": ["Da", "lach\u00b7ten", "Al\u00b7le", "rings", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Und viele meinten, so w\u00e4r's allerdings.", "tokens": ["Und", "vie\u00b7le", "mein\u00b7ten", ",", "so", "w\u00e4r's", "al\u00b7ler\u00b7dings", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "ADV", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Aber der Lehrer der Stadt,", "tokens": ["A\u00b7ber", "der", "Leh\u00b7rer", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Der zwischen den Werkm\u00e4nnern sa\u00df und dem Rath,", "tokens": ["Der", "zwi\u00b7schen", "den", "Werk\u00b7m\u00e4n\u00b7nern", "sa\u00df", "und", "dem", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "KON", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Also sich das Wort erbat:", "tokens": ["Al\u00b7so", "sich", "das", "Wort", "er\u00b7bat", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr wollt euch was M\u00e4nnliches zu sagen bequemen,", "tokens": ["Ihr", "wollt", "euch", "was", "M\u00e4nn\u00b7li\u00b7ches", "zu", "sa\u00b7gen", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "NN", "PTKZU", "VVINF", "ADJA", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und dazu wollt Ihr ein Fr\u00e4ulein nehmen?", "tokens": ["Und", "da\u00b7zu", "wollt", "Ihr", "ein", "Fr\u00e4u\u00b7lein", "neh\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein solcher Beschlu\u00df, mit Verlaub zu sagen,", "tokens": ["Ein", "sol\u00b7cher", "Be\u00b7schlu\u00df", ",", "mit", "Ver\u00b7laub", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$,", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Der hie\u00dfe den Gedanken todt durch die That schlagen,", "tokens": ["Der", "hie\u00b7\u00dfe", "den", "Ge\u00b7dan\u00b7ken", "todt", "durch", "die", "That", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Der w\u00e4r' mehr zum Radschlagen als zum Rathschlagen.", "tokens": ["Der", "w\u00e4r'", "mehr", "zum", "Rad\u00b7schla\u00b7gen", "als", "zum", "Rath\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPRART", "NN", "KOKOM", "APPRART", "NN", "$."], "meter": "-+--+--+-+--", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Ich w\u00fc\u00dft aber Einen,", "tokens": ["Ich", "w\u00fc\u00dft", "a\u00b7ber", "Ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Sollt' ich meinen,", "tokens": ["Sollt'", "ich", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "Der dies Unternehmen", "tokens": ["Der", "dies", "Un\u00b7ter\u00b7neh\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["ART", "PDS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.12": {"text": "Wohl kann unternehmen,", "tokens": ["Wohl", "kann", "un\u00b7ter\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Da\u00df ihr euch braucht des Erfolges nimmer zu sch\u00e4men.", "tokens": ["Da\u00df", "ihr", "euch", "braucht", "des", "Er\u00b7fol\u00b7ges", "nim\u00b7mer", "zu", "sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Ein andrer vom Rath sprach: Mit Vernunft", "tokens": ["Ein", "an\u00b7drer", "vom", "Rath", "sprach", ":", "Mit", "Ver\u00b7nunft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "APPRART", "NN", "VVFIN", "$.", "APPR", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wende man sich an die Sangeszunft,", "tokens": ["Wen\u00b7de", "man", "sich", "an", "die", "San\u00b7ges\u00b7zunft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Die bei solchem Ereigni\u00df nie bleibt stumm.", "tokens": ["Die", "bei", "sol\u00b7chem", "Er\u00b7eig\u00b7ni\u00df", "nie", "bleibt", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "ADV", "VVFIN", "ADJD", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Aber der Lehrer sprach wiederum:", "tokens": ["A\u00b7ber", "der", "Leh\u00b7rer", "sprach", "wie\u00b7de\u00b7rum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Ihr meint die heutigen Zunfts\u00e4ngerkreise?", "tokens": ["Ihr", "meint", "die", "heu\u00b7ti\u00b7gen", "Zunf\u00b7ts\u00e4n\u00b7ger\u00b7krei\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dies ist ihr Werk und dies ihre Weise:", "tokens": ["Dies", "ist", "ihr", "Werk", "und", "dies", "ih\u00b7re", "Wei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "KON", "PDS", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie lassen sich bis zum Ueberdru\u00df h\u00f6ren", "tokens": ["Sie", "las\u00b7sen", "sich", "bis", "zum", "Ue\u00b7berd\u00b7ru\u00df", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPRART", "NN", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Mit ihren h\u00f6chst wohllauten Lehren.", "tokens": ["Mit", "ih\u00b7ren", "h\u00f6chst", "wohl\u00b7lau\u00b7ten", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Doch ist darinnen mehr Leere als Lehre.", "tokens": ["Doch", "ist", "da\u00b7rin\u00b7nen", "mehr", "Lee\u00b7re", "als", "Leh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "KOUS", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Mehr Hohllaut als Wohllaut.", "tokens": ["Mehr", "Hohl\u00b7laut", "als", "Wohl\u00b7laut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KOUS", "NN", "$."], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.8": {"text": "Aus Dummheit gewoben, aus Trug und List,", "tokens": ["Aus", "Dumm\u00b7heit", "ge\u00b7wo\u00b7ben", ",", "aus", "Trug", "und", "List", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Sie reden stolze Worte, da nichts hinter ist.", "tokens": ["Sie", "re\u00b7den", "stol\u00b7ze", "Wor\u00b7te", ",", "da", "nichts", "hin\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,", "KOUS", "PIS", "APPR", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Es h\u00f6rt sich sch\u00f6n an und ist nicht sch\u00f6n,", "tokens": ["Es", "h\u00f6rt", "sich", "sch\u00f6n", "an", "und", "ist", "nicht", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "KON", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Es ist ein th\u00f6nernes Get\u00f6n,", "tokens": ["Es", "ist", "ein", "th\u00f6\u00b7ner\u00b7nes", "Ge\u00b7t\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das poltert, wie wenn man T\u00f6pfe zerbricht,", "tokens": ["Das", "pol\u00b7tert", ",", "wie", "wenn", "man", "T\u00f6p\u00b7fe", "zer\u00b7bricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOKOM", "KOUS", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Aber den Topf der Weisheit nicht.", "tokens": ["A\u00b7ber", "den", "Topf", "der", "Weis\u00b7heit", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "PTKNEG", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.14": {"text": "Das sind die Po\u00ebten,", "tokens": ["Das", "sind", "die", "Po\u00ebten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Das sind die Propheten,", "tokens": ["Das", "sind", "die", "Pro\u00b7phe\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.16": {"text": "Zu denen die echten geh\u00f6ren so", "tokens": ["Zu", "de\u00b7nen", "die", "ech\u00b7ten", "ge\u00b7h\u00f6\u00b7ren", "so"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ART", "ADJA", "VVFIN", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.17": {"text": "Wie sich zusammenreimt Weizen und Stroh.", "tokens": ["Wie", "sich", "zu\u00b7sam\u00b7men\u00b7reimt", "Wei\u00b7zen", "und", "Stroh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Sie werden euch wahrsagen", "tokens": ["Sie", "wer\u00b7den", "euch", "wahr\u00b7sa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Und alles Falsche euch richtig auf ein Haar sagen.", "tokens": ["Und", "al\u00b7les", "Fal\u00b7sche", "euch", "rich\u00b7tig", "auf", "ein", "Haar", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Eine Pause hiernach entstund,", "tokens": ["Ei\u00b7ne", "Pau\u00b7se", "hier\u00b7nach", "ent\u00b7stund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.21": {"text": "Und einer der Werkmannen sprach jetzund:", "tokens": ["Und", "ei\u00b7ner", "der", "Werk\u00b7man\u00b7nen", "sprach", "je\u00b7tzund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Es ist heuer eine Zeit,", "tokens": ["Es", "ist", "heu\u00b7er", "ei\u00b7ne", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Voll Tr\u00fcbsal und Leid,", "tokens": ["Voll", "Tr\u00fcb\u00b7sal", "und", "Leid", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Man kann sich kaum davor erwehren,", "tokens": ["Man", "kann", "sich", "kaum", "da\u00b7vor", "er\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und \u00fcberall thut es rumoren und g\u00e4hren,", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "thut", "es", "ru\u00b7mo\u00b7ren", "und", "g\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Als m\u00fc\u00dfte die Welt was ganz Neues geb\u00e4hren.", "tokens": ["Als", "m\u00fc\u00df\u00b7te", "die", "Welt", "was", "ganz", "Neu\u00b7es", "ge\u00b7b\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "ART", "NN", "PWS", "ADV", "NN", "VVPP", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.6": {"text": "Da mein' ich nun,", "tokens": ["Da", "mein'", "ich", "nun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Es lie\u00dfe sich weislich etwas thun,", "tokens": ["Es", "lie\u00b7\u00dfe", "sich", "weis\u00b7lich", "et\u00b7was", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PIS", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wenn wir, uns selber fr\u00f6hlich zu machen,", "tokens": ["Wenn", "wir", ",", "uns", "sel\u00b7ber", "fr\u00f6h\u00b7lich", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Auch was bringen zur Lust und zum Lachen,", "tokens": ["Auch", "was", "brin\u00b7gen", "zur", "Lust", "und", "zum", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.10": {"text": "So was von Mummenschanz und Narrentheidung.", "tokens": ["So", "was", "von", "Mum\u00b7men\u00b7schanz", "und", "Nar\u00b7ren\u00b7thei\u00b7dung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und dies wollt ich vorlegen zur Entscheidung. \u2013", "tokens": ["Und", "dies", "wollt", "ich", "vor\u00b7le\u00b7gen", "zur", "Ent\u00b7schei\u00b7dung", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PDS", "VMFIN", "PPER", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Ein lauter Beifall folgte den Worten nach.", "tokens": ["Ein", "lau\u00b7ter", "Bei\u00b7fall", "folg\u00b7te", "den", "Wor\u00b7ten", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Und der im Vorsitz also sprach:", "tokens": ["Und", "der", "im", "Vor\u00b7sitz", "al\u00b7so", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist sichere Zeitung,", "tokens": ["Es", "ist", "si\u00b7che\u00b7re", "Zei\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df in des f\u00fcrstlichen Paares Begleitung", "tokens": ["Da\u00df", "in", "des", "f\u00fcrst\u00b7li\u00b7chen", "Paa\u00b7res", "Be\u00b7glei\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Der Bischof, ein Vetter der hohen Braut,", "tokens": ["Der", "Bi\u00b7schof", ",", "ein", "Vet\u00b7ter", "der", "ho\u00b7hen", "Braut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Mit werde geschaut.", "tokens": ["Mit", "wer\u00b7de", "ge\u00b7schaut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "VAFIN", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Von dem thut man \u00fcberall sagen und singen,", "tokens": ["Von", "dem", "thut", "man", "\u00fc\u00b7be\u00b7rall", "sa\u00b7gen", "und", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "PIS", "ADV", "VVINF", "KON", "VVFIN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Da\u00df er an Scherz und komischen Dingen", "tokens": ["Da\u00df", "er", "an", "Scherz", "und", "ko\u00b7mi\u00b7schen", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Schier so viel Gefallen habe", "tokens": ["Schier", "so", "viel", "Ge\u00b7fal\u00b7len", "ha\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PIAT", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Als an seinem Bischofsstabe.", "tokens": ["Als", "an", "sei\u00b7nem", "Bi\u00b7schofs\u00b7sta\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Mithin so meinet der Rath und spricht,", "tokens": ["Mi\u00b7thin", "so", "mei\u00b7net", "der", "Rath", "und", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "W\u00e4r's f\u00fcr die Stadt uneben nicht,", "tokens": ["W\u00e4r's", "f\u00fcr", "die", "Stadt", "un\u00b7e\u00b7ben", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADJD", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wenn derartiges auch geschicht.", "tokens": ["Wenn", "der\u00b7ar\u00b7ti\u00b7ges", "auch", "ge\u00b7schicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "VVPP", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.13": {"text": "Der Stadtschreiber hierauf das Wort empfing", "tokens": ["Der", "Stadt\u00b7schrei\u00b7ber", "hier\u00b7auf", "das", "Wort", "emp\u00b7fing"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PAV", "ART", "NN", "VVFIN"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.14": {"text": "Und sprach: Es ist mit dem Schelten ein eigen Ding.", "tokens": ["Und", "sprach", ":", "Es", "ist", "mit", "dem", "Schel\u00b7ten", "ein", "ei\u00b7gen", "Ding", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VAFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Wer andere tadelt keck und klug,", "tokens": ["Wer", "an\u00b7de\u00b7re", "ta\u00b7delt", "keck", "und", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Von dem verlangt die Welt mit Fug,", "tokens": ["Von", "dem", "ver\u00b7langt", "die", "Welt", "mit", "Fug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Da\u00df er zeige, ob er es besser kann,", "tokens": ["Da\u00df", "er", "zei\u00b7ge", ",", "ob", "er", "es", "bes\u00b7ser", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PPER", "ADJD", "VMFIN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Sonst bleibt er ein verlorener Mann.", "tokens": ["Sonst", "bleibt", "er", "ein", "ver\u00b7lo\u00b7re\u00b7ner", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "Also m\u00f6cht' ich fragen,", "tokens": ["Al\u00b7so", "m\u00f6cht'", "ich", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.20": {"text": "Ob uns der Lehrer der Stadt will sagen,", "tokens": ["Ob", "uns", "der", "Leh\u00b7rer", "der", "Stadt", "will", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Wen ", "tokens": ["Wen"], "token_info": ["word"], "pos": ["PWS"], "meter": "+", "measure": "single.up"}, "line.22": {"text": "Wer etwa, denen er Lehre giebt,", "tokens": ["Wer", "et\u00b7wa", ",", "de\u00b7nen", "er", "Leh\u00b7re", "giebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Also ist sang- und wortge\u00fcbt,", "tokens": ["Al\u00b7so", "ist", "sang", "und", "wort\u00b7ge\u00b7\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "TRUNC", "KON", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "Da\u00df er uns guten Erfolg verhie\u00df.", "tokens": ["Da\u00df", "er", "uns", "gu\u00b7ten", "Er\u00b7folg", "ver\u00b7hie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Der Lehrer sprach: darauf sage ich dies:", "tokens": ["Der", "Leh\u00b7rer", "sprach", ":", "da\u00b7rauf", "sa\u00b7ge", "ich", "dies", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PAV", "VVFIN", "PPER", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Es sind ihrer Dreie, doch Einer davon", "tokens": ["Es", "sind", "ih\u00b7rer", "Drei\u00b7e", ",", "doch", "Ei\u00b7ner", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "ADV", "PIS", "PAV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ist wie die auserw\u00e4hlten Tannen vom Libanon.", "tokens": ["Ist", "wie", "die", "au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "Tan\u00b7nen", "vom", "Li\u00b7ba\u00b7non", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "In seinen Worten ist eine Tiefe,", "tokens": ["In", "sei\u00b7nen", "Wor\u00b7ten", "ist", "ei\u00b7ne", "Tie\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Von der man nicht glauben sollt', da\u00df sie dort schliefe.", "tokens": ["Von", "der", "man", "nicht", "glau\u00b7ben", "sollt'", ",", "da\u00df", "sie", "dort", "schlie\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "PTKNEG", "VVINF", "VMFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Ich sag' euch, wahrlich", "tokens": ["Ich", "sag'", "euch", ",", "wahr\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Seiner Sprache Gewalt ist wunderbarlich.", "tokens": ["Sei\u00b7ner", "Spra\u00b7che", "Ge\u00b7walt", "ist", "wun\u00b7der\u00b7bar\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Es ist mir da ein Genie geboren,", "tokens": ["Es", "ist", "mir", "da", "ein", "Ge\u00b7nie", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ich wei\u00df nicht, ist er zu sp\u00e4t oder zu fr\u00fch geboren.", "tokens": ["Ich", "wei\u00df", "nicht", ",", "ist", "er", "zu", "sp\u00e4t", "o\u00b7der", "zu", "fr\u00fch", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "VAFIN", "PPER", "PTKA", "ADJD", "KON", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Er ist aber von den fahrenden Sch\u00fclern Einer,", "tokens": ["Er", "ist", "a\u00b7ber", "von", "den", "fah\u00b7ren\u00b7den", "Sch\u00fc\u00b7lern", "Ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "ADJA", "NN", "PIS", "$,"], "meter": "--+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Wo er her und wo er geschult ist, wei\u00df keiner. \u2013", "tokens": ["Wo", "er", "her", "und", "wo", "er", "ge\u00b7schult", "ist", ",", "wei\u00df", "kei\u00b7ner", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "PTKVZ", "KON", "PWAV", "PPER", "VVPP", "VAFIN", "$,", "VVFIN", "PIS", "$.", "$("], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Von den andern beiden ist der eine vom Rhein", "tokens": ["Von", "den", "an\u00b7dern", "bei\u00b7den", "ist", "der", "ei\u00b7ne", "vom", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "PIAT", "VAFIN", "ART", "ART", "APPRART", "NE"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.2": {"text": "Im Vortrag zierlich, anmuthig und fein.", "tokens": ["Im", "Vor\u00b7trag", "zier\u00b7lich", ",", "an\u00b7mut\u00b7hig", "und", "fein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie eine Goldammer", "tokens": ["Wie", "ei\u00b7ne", "Gold\u00b7am\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Lieblich schl\u00e4gt mit ihrer Stimme Goldhammer,", "tokens": ["Lieb\u00b7lich", "schl\u00e4gt", "mit", "ih\u00b7rer", "Stim\u00b7me", "Gold\u00b7ham\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "So ist er im Sang' fr\u00f6hlich immer", "tokens": ["So", "ist", "er", "im", "Sang'", "fr\u00f6h\u00b7lich", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "ADJD", "ADV"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und traurig nimmer;", "tokens": ["Und", "trau\u00b7rig", "nim\u00b7mer", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Wie Schaumwein, der \u00fcberquoll,", "tokens": ["Wie", "Schaum\u00b7wein", ",", "der", "\u00fc\u00b7berq\u00b7uoll", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "PRELS", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Prickelnd-lustig-\u00fcbertoll", "tokens": ["Pri\u00b7ckeln\u00b7dlus\u00b7tig\u00b7\u00fcber\u00b7toll"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Und von Wortspiel und s\u00fc\u00dfen Reimen voll. \u2013", "tokens": ["Und", "von", "Wort\u00b7spiel", "und", "s\u00fc\u00b7\u00dfen", "Rei\u00b7men", "voll", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "NN", "KON", "ADJA", "NN", "ADJD", "$.", "$("], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.15": {"line.1": {"text": "Der andre aber, immer voll Tadel und Zweifel,", "tokens": ["Der", "and\u00b7re", "a\u00b7ber", ",", "im\u00b7mer", "voll", "Ta\u00b7del", "und", "Zwei\u00b7fel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "$,", "ADV", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "F\u00fcrchtet nicht Himmel, noch H\u00f6lle, noch Teufel,", "tokens": ["F\u00fcrch\u00b7tet", "nicht", "Him\u00b7mel", ",", "noch", "H\u00f6l\u00b7le", ",", "noch", "Teu\u00b7fel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "NN", "$,", "ADV", "NN", "$,", "ADV", "NN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Mag sich einem Machtgebot nicht bequemen,", "tokens": ["Mag", "sich", "ei\u00b7nem", "Macht\u00b7ge\u00b7bot", "nicht", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "PTKNEG", "ADJA", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "L\u00e4\u00dft sich vom Brod die Butter nicht nehmen,", "tokens": ["L\u00e4\u00dft", "sich", "vom", "Brod", "die", "But\u00b7ter", "nicht", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sagt lieber zehnmal nein als einmal ja,", "tokens": ["Sagt", "lie\u00b7ber", "zehn\u00b7mal", "nein", "als", "ein\u00b7mal", "ja", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PTKANT", "KOKOM", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wo was los ist, ist er da,", "tokens": ["Wo", "was", "los", "ist", ",", "ist", "er", "da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PWS", "ADJD", "VAFIN", "$,", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Mit der Zunge bei der Hand und mit der Hand geschwind,", "tokens": ["Mit", "der", "Zun\u00b7ge", "bei", "der", "Hand", "und", "mit", "der", "Hand", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.8": {"text": "Kurz, wie nun einmal die Berliner sind,", "tokens": ["Kurz", ",", "wie", "nun", "ein\u00b7mal", "die", "Ber\u00b7li\u00b7ner", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ADV", "ADV", "ART", "ADJA", "VAFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Ein richtiges Berliner Kind.", "tokens": ["Ein", "rich\u00b7ti\u00b7ges", "Ber\u00b7li\u00b7ner", "Kind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Doch wenn er spricht so trifft der Tropf", "tokens": ["Doch", "wenn", "er", "spricht", "so", "trifft", "der", "Tropf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Euch sicher den Nagel auf eurem Kopf. \u2013", "tokens": ["Euch", "si\u00b7cher", "den", "Na\u00b7gel", "auf", "eu\u00b7rem", "Kopf", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PRF", "ART", "NE", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.16": {"line.1": {"text": "So sprach er, und der ganze Hauf", "tokens": ["So", "sprach", "er", ",", "und", "der", "gan\u00b7ze", "Hauf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jauchzte mit hellem Jubel auf.", "tokens": ["Jauchz\u00b7te", "mit", "hel\u00b7lem", "Ju\u00b7bel", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}