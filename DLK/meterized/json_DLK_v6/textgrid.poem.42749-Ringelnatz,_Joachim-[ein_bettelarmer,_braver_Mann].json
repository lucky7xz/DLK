{"textgrid.poem.42749": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "[ein bettelarmer, braver Mann]", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein bettelarmer, braver Mann,", "tokens": ["Ein", "bet\u00b7tel\u00b7ar\u00b7mer", ",", "bra\u00b7ver", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tag und Nacht nur Gutes sann", "tokens": ["Der", "Tag", "und", "Nacht", "nur", "Gu\u00b7tes", "sann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und gar nichts mehr zu essen hatte", "tokens": ["Und", "gar", "nichts", "mehr", "zu", "es\u00b7sen", "hat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIS", "PIS", "PTKZU", "VVINF", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als eine halbverweste Ratte,", "tokens": ["Als", "ei\u00b7ne", "halb\u00b7ver\u00b7wes\u00b7te", "Rat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der auch kein Bett besa\u00df zum Schlafen,", "tokens": ["Der", "auch", "kein", "Bett", "be\u00b7sa\u00df", "zum", "Schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der ging in seiner h\u00f6chsten Not", "tokens": ["Der", "ging", "in", "sei\u00b7ner", "h\u00f6chs\u00b7ten", "Not"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu einem reichen, stolzen Grafen", "tokens": ["Zu", "ei\u00b7nem", "rei\u00b7chen", ",", "stol\u00b7zen", "Gra\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und bat ihn um ein St\u00fcckchen Brot.", "tokens": ["Und", "bat", "ihn", "um", "ein", "St\u00fcck\u00b7chen", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Graf nahm das gewaltig \u00fcbel", "tokens": ["Der", "Graf", "nahm", "das", "ge\u00b7wal\u00b7tig", "\u00fc\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJD", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und schlug mit dem Champagnerk\u00fcbel", "tokens": ["Und", "schlug", "mit", "dem", "Cham\u00b7pag\u00b7ner\u00b7k\u00fc\u00b7bel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Den braven Bettler l\u00e4chelnd tot.", "tokens": ["Den", "bra\u00b7ven", "Bett\u00b7ler", "l\u00e4\u00b7chelnd", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Doch niemand wagte es, den Grafen", "tokens": ["Doch", "nie\u00b7mand", "wag\u00b7te", "es", ",", "den", "Gra\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PPER", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "F\u00fcr solche Freveltat zu strafen.", "tokens": ["F\u00fcr", "sol\u00b7che", "Fre\u00b7vel\u00b7tat", "zu", "stra\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und deshalb wurde sein Betragen", "tokens": ["Und", "des\u00b7halb", "wur\u00b7de", "sein", "Be\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Dann mit den Jahren noch viel schlimmer. \u2013", "tokens": ["Dann", "mit", "den", "Jah\u00b7ren", "noch", "viel", "schlim\u00b7mer", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "ADV", "ADJD", "$.", "$("], "meter": "++-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So manchen Leser h\u00f6r' ich sagen:", "tokens": ["So", "man\u00b7chen", "Le\u00b7ser", "h\u00f6r'", "ich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ja, ja! \u2013 ja, ja! \u2013 So ist das immer!", "tokens": ["Ja", ",", "ja", "!", "\u2013", "ja", ",", "ja", "!", "\u2013", "So", "ist", "das", "im\u00b7mer", "!"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$(", "PTKANT", "$,", "ADV", "$.", "$(", "ADV", "VAFIN", "ART", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich aber denke still f\u00fcr mich:", "tokens": ["Ich", "a\u00b7ber", "den\u00b7ke", "still", "f\u00fcr", "mich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Leser ist ein G\u00e4nserich.", "tokens": ["Der", "Le\u00b7ser", "ist", "ein", "G\u00e4n\u00b7se\u00b7rich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}