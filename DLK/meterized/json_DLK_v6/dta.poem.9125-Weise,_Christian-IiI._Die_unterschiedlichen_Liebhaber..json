{"dta.poem.9125": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "IiI.  \n Die unterschiedlichen Liebhaber.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ich schwatzte neulich von galanen/", "tokens": ["Ich", "schwatz\u00b7te", "neu\u00b7lich", "von", "ga\u00b7la\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als ich bey meinen m\u00e4dgen stund;", "tokens": ["Als", "ich", "bey", "mei\u00b7nen", "m\u00e4d\u00b7gen", "stund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da lie\u00df sie mich hernach vermahnen/", "tokens": ["Da", "lie\u00df", "sie", "mich", "her\u00b7nach", "ver\u00b7mah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die sachen w\u00e4ren ihr nicht kund;", "tokens": ["Die", "sa\u00b7chen", "w\u00e4\u00b7ren", "ihr", "nicht", "kund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie m\u00f6chte mich wol gerne fragen/", "tokens": ["Sie", "m\u00f6ch\u00b7te", "mich", "wol", "ger\u00b7ne", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "ADV", "VVINF", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Was ein galan ausdr\u00fccklich sey?", "tokens": ["Was", "ein", "ga\u00b7lan", "aus\u00b7dr\u00fcck\u00b7lich", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da lie\u00df ich ihr zur antwort sagen/", "tokens": ["Da", "lie\u00df", "ich", "ihr", "zur", "ant\u00b7wort", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die leutgen w\u00e4ren vielerley.", "tokens": ["Die", "leut\u00b7gen", "w\u00e4\u00b7ren", "vie\u00b7ler\u00b7ley", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Dann sagt ich/ wer sich aller orten", "tokens": ["Dann", "sagt", "ich", "/", "wer", "sich", "al\u00b7ler", "or\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWS", "PRF", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zum lieben frauenzimmer macht/", "tokens": ["Zum", "lie\u00b7ben", "frau\u00b7en\u00b7zim\u00b7mer", "macht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ist doch kalt in seinen worten", "tokens": ["Und", "ist", "doch", "kalt", "in", "sei\u00b7nen", "wor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ob er gleich noch so freundlich lacht:", "tokens": ["Ob", "er", "gleich", "noch", "so", "freund\u00b7lich", "lacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer alle wochen eine neue", "tokens": ["Wer", "al\u00b7le", "wo\u00b7chen", "ei\u00b7ne", "neu\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PIS", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zum zeitvertreib erw\u00e4hlen kan/", "tokens": ["Zum", "zeit\u00b7ver\u00b7treib", "er\u00b7w\u00e4h\u00b7len", "kan", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und fragt nach keiner liebes-treue/", "tokens": ["Und", "fragt", "nach", "kei\u00b7ner", "lie\u00b7bes\u00b7treue", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "ADJA", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der ist ein blosser spa\u00df-galan.", "tokens": ["Der", "ist", "ein", "blos\u00b7ser", "spa\u00df\u00b7ga\u00b7lan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Und wer sich l\u00e4st die grillen treiben/", "tokens": ["Und", "wer", "sich", "l\u00e4st", "die", "gril\u00b7len", "trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "VVFIN", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er die gassen nunter schw\u00e4ntzt/", "tokens": ["Da\u00df", "er", "die", "gas\u00b7sen", "nun\u00b7ter", "schw\u00e4ntzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob etwan durch die fenster-scheiben", "tokens": ["Ob", "et\u00b7wan", "durch", "die", "fens\u00b7ter\u00b7schei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein weisses jungfer-h\u00e4ubgen gl\u00e4ntzt/", "tokens": ["Ein", "weis\u00b7ses", "jung\u00b7fer\u00b7h\u00e4ub\u00b7gen", "gl\u00e4ntzt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und meint er habe durch den tempel", "tokens": ["Und", "meint", "er", "ha\u00b7be", "durch", "den", "tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der liebes-pflicht genug gethan/", "tokens": ["Der", "lie\u00b7bes\u00b7pflicht", "ge\u00b7nug", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der heist den andern zum exempel", "tokens": ["Der", "heist", "den", "an\u00b7dern", "zum", "ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "APPRART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ein lauff-und pflasterstein galan.", "tokens": ["Ein", "lauff\u00b7\u00b7und", "pflas\u00b7ter\u00b7stein", "ga\u00b7lan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Wann auch ein junger gelber schnabel", "tokens": ["Wann", "auch", "ein", "jun\u00b7ger", "gel\u00b7ber", "schna\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich im processe selbst verf\u00fchrt/", "tokens": ["Sich", "im", "pro\u00b7ces\u00b7se", "selbst", "ver\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles mit der silbern gabel", "tokens": ["Und", "al\u00b7les", "mit", "der", "sil\u00b7bern", "ga\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fein fromm und sittsam embrochirt/", "tokens": ["Fein", "fromm", "und", "sitt\u00b7sam", "em\u00b7bro\u00b7chirt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "VVPP", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Auch nichts in seinen complimenten", "tokens": ["Auch", "nichts", "in", "sei\u00b7nen", "com\u00b7pli\u00b7men\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als ehren tugend sprechen kan/", "tokens": ["Als", "eh\u00b7ren", "tu\u00b7gend", "spre\u00b7chen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So heisset er bey uns studenten", "tokens": ["So", "heis\u00b7set", "er", "bey", "uns", "stu\u00b7den\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Nur ein devotion-galan.", "tokens": ["Nur", "ein", "de\u00b7vo\u00b7ti\u00b7o\u00b7nga\u00b7lan", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Und wer mit allerhand spendaschen", "tokens": ["Und", "wer", "mit", "al\u00b7ler\u00b7hand", "spen\u00b7da\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "PIAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der liebsten ihre k\u00f6the schm\u00fcckt/", "tokens": ["Der", "liebs\u00b7ten", "ih\u00b7re", "k\u00f6\u00b7the", "schm\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alle tage seinen pagen", "tokens": ["Und", "al\u00b7le", "ta\u00b7ge", "sei\u00b7nen", "pa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nach zucker und citronen schickt/", "tokens": ["Nach", "zu\u00b7cker", "und", "cit\u00b7ro\u00b7nen", "schickt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer offtermahls spatziren f\u00e4hret/", "tokens": ["Wer", "off\u00b7ter\u00b7mahls", "spat\u00b7zi\u00b7ren", "f\u00e4h\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zur hochzeit gehet/ wenn er kan/", "tokens": ["Zur", "hoch\u00b7zeit", "ge\u00b7het", "/", "wenn", "er", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$(", "KOUS", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und seine pfennge so verzehret/", "tokens": ["Und", "sei\u00b7ne", "pfenn\u00b7ge", "so", "ver\u00b7zeh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist ein discretion-galan.", "tokens": ["Ist", "ein", "dis\u00b7creti\u00b7o\u00b7nga\u00b7lan", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "6. Doch welchen das geneigte gl\u00fccke", "tokens": ["Doch", "wel\u00b7chen", "das", "ge\u00b7neig\u00b7te", "gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu der vollkommenheit bestimmt/", "tokens": ["Zu", "der", "voll\u00b7kom\u00b7men\u00b7heit", "be\u00b7stimmt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er durch seine liebes-blicke", "tokens": ["Da\u00df", "er", "durch", "sei\u00b7ne", "lie\u00b7bes\u00b7bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den m\u00e4dgen auch das hertze nimmt/", "tokens": ["Den", "m\u00e4d\u00b7gen", "auch", "das", "hert\u00b7ze", "nimmt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer mit vermischten wechselk\u00fcssen", "tokens": ["Wer", "mit", "ver\u00b7mischten", "wech\u00b7sel\u00b7k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Den stillen bund erhalten kan/", "tokens": ["Den", "stil\u00b7len", "bund", "er\u00b7hal\u00b7ten", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Obs gleich die leute wenig wissen/", "tokens": ["Obs", "gleich", "die", "leu\u00b7te", "we\u00b7nig", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist ein affection-galan.", "tokens": ["Ist", "ein", "af\u00b7fec\u00b7ti\u00b7o\u00b7nga\u00b7lan", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Wiewol die schlimmsten l\u00f6ffelknechte", "tokens": ["Wie\u00b7wol", "die", "schlimms\u00b7ten", "l\u00f6f\u00b7fel\u00b7knech\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geniessen manchmal treflich viel/", "tokens": ["Ge\u00b7nies\u00b7sen", "manch\u00b7mal", "tref\u00b7lich", "viel", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur dessentwegen weil der rechte", "tokens": ["Nur", "des\u00b7sent\u00b7we\u00b7gen", "weil", "der", "rech\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "KOUS", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht ins geh\u00e4ge kommen will:", "tokens": ["Nicht", "ins", "ge\u00b7h\u00e4\u00b7ge", "kom\u00b7men", "will", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Inzwischen weil sie solches wissen", "tokens": ["I\u00b7nzwi\u00b7schen", "weil", "sie", "sol\u00b7ches", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gehn sie mit allen freuden dran/", "tokens": ["Gehn", "sie", "mit", "al\u00b7len", "freu\u00b7den", "dran", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und unter solchen l\u00fccke b\u00fcssen", "tokens": ["Und", "un\u00b7ter", "sol\u00b7chen", "l\u00fc\u00b7cke", "b\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird mancher noch ein noth-galan.", "tokens": ["Wird", "man\u00b7cher", "noch", "ein", "noth\u00b7ga\u00b7lan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "8. N\u00e4chst diesem bildt sich mancher immer", "tokens": ["N\u00e4chst", "die\u00b7sem", "bildt", "sich", "man\u00b7cher", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "VVFIN", "PRF", "PIS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die allersch\u00f6nsten sachen ein/", "tokens": ["Die", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "sa\u00b7chen", "ein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mu\u00df doch bey dem frauenzimmer", "tokens": ["Und", "mu\u00df", "doch", "bey", "dem", "frau\u00b7en\u00b7zim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jm spiele pickelh\u00e4ring seyn/", "tokens": ["Jm", "spie\u00b7le", "pi\u00b7ckel\u00b7h\u00e4\u00b7ring", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er kan sich zwar vor selig sch\u00e4tzen", "tokens": ["Er", "kan", "sich", "zwar", "vor", "se\u00b7lig", "sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPR", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und nimmt den schertz mit willen an;", "tokens": ["Und", "nimmt", "den", "schertz", "mit", "wil\u00b7len", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch sag ich/ wer sich l\u00e4sset h\u00e4tzen/", "tokens": ["Doch", "sag", "ich", "/", "wer", "sich", "l\u00e4s\u00b7set", "h\u00e4t\u00b7zen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "PWS", "PRF", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist ein vexation-galan.", "tokens": ["Ist", "ein", "vexa\u00b7ti\u00b7o\u00b7nga\u00b7lan", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "9. Hieran ihr herren junggesellen", "tokens": ["Hie\u00b7ran", "ihr", "her\u00b7ren", "jung\u00b7ge\u00b7sel\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PPOSAT", "NN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich habe mich allhier bem\u00fcht", "tokens": ["Ich", "ha\u00b7be", "mich", "all\u00b7hier", "be\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Euch in der liebe vorzustellen/", "tokens": ["Euch", "in", "der", "lie\u00b7be", "vor\u00b7zu\u00b7stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo jemand seines gleichen sieht/", "tokens": ["Wo", "je\u00b7mand", "sei\u00b7nes", "glei\u00b7chen", "sieht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der gehe nur in sein gewissen", "tokens": ["Der", "ge\u00b7he", "nur", "in", "sein", "ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und zieh sich selber vor gericht.", "tokens": ["Und", "zieh", "sich", "sel\u00b7ber", "vor", "ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich werde diesen loben m\u00fcssen", "tokens": ["Ich", "wer\u00b7de", "die\u00b7sen", "lo\u00b7ben", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "VVINF", "VMFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der hefftig liebt und meynt es nicht.", "tokens": ["Der", "heff\u00b7tig", "liebt", "und", "meynt", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}