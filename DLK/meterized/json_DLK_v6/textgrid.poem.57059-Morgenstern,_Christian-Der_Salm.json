{"textgrid.poem.57059": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Der Salm", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Rheinsalm schwamm den Rhein", "tokens": ["Ein", "Rhein\u00b7salm", "schwamm", "den", "Rhein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "ART", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "bis in die Schweiz hinein.", "tokens": ["bis", "in", "die", "Schweiz", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NE", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und sprang den Oberlauf", "tokens": ["Und", "sprang", "den", "O\u00b7berl\u00b7auf"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "von Fall zu Fall hinauf.", "tokens": ["von", "Fall", "zu", "Fall", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Er war schon wei\u00dfgottwo,", "tokens": ["Er", "war", "schon", "wei\u00df\u00b7gott\u00b7wo", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "doch eines Tages \u2013 oh! \u2013", "tokens": ["doch", "ei\u00b7nes", "Ta\u00b7ges", "\u2013", "oh", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "$(", "FM", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "da kam er an ein Wehr:", "tokens": ["da", "kam", "er", "an", "ein", "Wehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "das ma\u00df zw\u00f6lf Fu\u00df und mehr!", "tokens": ["das", "ma\u00df", "zw\u00f6lf", "Fu\u00df", "und", "mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "NN", "KON", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Zehn Fu\u00df \u2013 die sprang er gut!", "tokens": ["Zehn", "Fu\u00df", "\u2013", "die", "sprang", "er", "gut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$(", "ART", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Doch hier zerbrach sein Mut.", "tokens": ["Doch", "hier", "zer\u00b7brach", "sein", "Mut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Drei Wochen stand der Salm", "tokens": ["Drei", "Wo\u00b7chen", "stand", "der", "Salm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "am Fu\u00df der Wasser-Alm.", "tokens": ["am", "Fu\u00df", "der", "Was\u00b7ser\u00b7Alm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und kehrte schlie\u00dflich stumm", "tokens": ["Und", "kehr\u00b7te", "schlie\u00df\u00b7lich", "stumm"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "nach Deutsch- und Holland um.", "tokens": ["nach", "Deut\u00b7sch", "und", "Hol\u00b7land", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}