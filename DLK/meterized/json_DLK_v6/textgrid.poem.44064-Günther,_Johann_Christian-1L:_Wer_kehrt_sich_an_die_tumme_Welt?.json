{"textgrid.poem.44064": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer kehrt sich an die tumme Welt?", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer kehrt sich an die tumme Welt?", "tokens": ["Wer", "kehrt", "sich", "an", "die", "tum\u00b7me", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie kan doch nichts als tadeln.", "tokens": ["Sie", "kan", "doch", "nichts", "als", "ta\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "KOKOM", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wem Treu und Warheit nur gef\u00e4llt,", "tokens": ["Wem", "Treu", "und", "War\u00b7heit", "nur", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der kan sich selber adeln", "tokens": ["Der", "kan", "sich", "sel\u00b7ber", "a\u00b7deln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und \u00fcberwindet nach und nach", "tokens": ["Und", "\u00fc\u00b7berw\u00b7in\u00b7det", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die ohne Schuld erlidtne Schmach.", "tokens": ["Die", "oh\u00b7ne", "Schuld", "er\u00b7lidt\u00b7ne", "Schmach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kein Handwerck geht doch jezt so gut", "tokens": ["Kein", "Hand\u00b7werck", "geht", "doch", "jezt", "so", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als blos das Hechelmachen.", "tokens": ["Als", "blos", "das", "He\u00b7chel\u00b7ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Narr, der sonst nichts kan und thut,", "tokens": ["Ein", "Narr", ",", "der", "sonst", "nichts", "kan", "und", "thut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PIS", "VMFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der legt sich aufs Verlachen.", "tokens": ["Der", "legt", "sich", "aufs", "Ver\u00b7la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da ist kein Ding so schlecht und klein,", "tokens": ["Da", "ist", "kein", "Ding", "so", "schlecht", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein loses Maul mu\u00df dr\u00fcber seyn.", "tokens": ["Ein", "lo\u00b7ses", "Maul", "mu\u00df", "dr\u00fc\u00b7ber", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PAV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Unschuld geht nicht ledig aus,", "tokens": ["Die", "Un\u00b7schuld", "geht", "nicht", "le\u00b7dig", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Spott trift auch den Besten.", "tokens": ["Der", "Spott", "trift", "auch", "den", "Bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Brautgelach, ein Kindelschmaus", "tokens": ["Ein", "Braut\u00b7ge\u00b7lach", ",", "ein", "Kin\u00b7del\u00b7schmaus"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schwermt \u00fcberall von G\u00e4sten,", "tokens": ["Schwermt", "\u00fc\u00b7be\u00b7rall", "von", "G\u00e4s\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Bey welchen jeder in der Stadt", "tokens": ["Bey", "wel\u00b7chen", "je\u00b7der", "in", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Urtheil zu gewarthen hat.", "tokens": ["Sein", "Ur\u00b7theil", "zu", "ge\u00b7wart\u00b7hen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Stra\u00dfe sey so breit sie will,", "tokens": ["Die", "Stra\u00b7\u00dfe", "sey", "so", "breit", "sie", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man geht nicht ungesto\u00dfen.", "tokens": ["Man", "geht", "nicht", "un\u00b7ge\u00b7sto\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da h\u00f6r ich oftmahls in der Still", "tokens": ["Da", "h\u00f6r", "ich", "oft\u00b7mahls", "in", "der", "Still"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Kleinen und von Gro\u00dfen,", "tokens": ["Von", "Klei\u00b7nen", "und", "von", "Gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie da und dort ein V\u00f6lckchen sizt,", "tokens": ["Wie", "da", "und", "dort", "ein", "V\u00f6l\u00b7ck\u00b7chen", "sizt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "KON", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Das Mienen, Kleid und Gang beschmizt.", "tokens": ["Das", "Mie\u00b7nen", ",", "Kleid", "und", "Gang", "be\u00b7schmizt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Br\u00fcder bey dem Aquavit", "tokens": ["Die", "Br\u00fc\u00b7der", "bey", "dem", "A\u00b7qua\u00b7vit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind Meister in dem K\u00fcgeln", "tokens": ["Sind", "Meis\u00b7ter", "in", "dem", "K\u00fc\u00b7geln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wi\u00dfen alles, was geschieht,", "tokens": ["Und", "wi\u00b7\u00dfen", "al\u00b7les", ",", "was", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "$,", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So unversch\u00e4mt zu striegeln,", "tokens": ["So", "un\u00b7ver\u00b7sch\u00e4mt", "zu", "strie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df einer, der den Nechsten liebt,", "tokens": ["Da\u00df", "ei\u00b7ner", ",", "der", "den", "Nechs\u00b7ten", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich schon vom H\u00f6ren \u00fcbergiebt.", "tokens": ["Sich", "schon", "vom", "H\u00f6\u00b7ren", "\u00fc\u00b7berg\u00b7iebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich habe meine Richterbanck", "tokens": ["Ich", "ha\u00b7be", "mei\u00b7ne", "Rich\u00b7ter\u00b7banck"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An mehr als tausend Orten;", "tokens": ["An", "mehr", "als", "tau\u00b7send", "Or\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KOKOM", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da zieht man mich so kurz als lang", "tokens": ["Da", "zieht", "man", "mich", "so", "kurz", "als", "lang"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "ADV", "ADJD", "KOKOM", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Mienen und mit Worten.", "tokens": ["Mit", "Mie\u00b7nen", "und", "mit", "Wor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch werd ich dadurch schlecht bewegt;", "tokens": ["Doch", "werd", "ich", "da\u00b7durch", "schlecht", "be\u00b7wegt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PAV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer z\u00fcrnt wohl, den ein Esel schl\u00e4gt?", "tokens": ["Wer", "z\u00fcrnt", "wohl", ",", "den", "ein", "E\u00b7sel", "schl\u00e4gt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Man spricht: Es ist die Mode so,", "tokens": ["Man", "spricht", ":", "Es", "ist", "die", "Mo\u00b7de", "so", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man mu\u00df es mit ihr halten;", "tokens": ["Man", "mu\u00df", "es", "mit", "ihr", "hal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein geistlich dulci jubilo", "tokens": ["Ein", "geist\u00b7lich", "dul\u00b7ci", "ju\u00b7bi\u00b7lo"], "token_info": ["word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geh\u00f6rt den tummen Alten;", "tokens": ["Ge\u00b7h\u00f6rt", "den", "tum\u00b7men", "Al\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der neuen Zeiten be\u00dfrer Thon", "tokens": ["Der", "neu\u00b7en", "Zei\u00b7ten", "be\u00df\u00b7rer", "Thon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Klingt recht galant und sch\u00f6n nach Hohn.", "tokens": ["Klingt", "recht", "ga\u00b7lant", "und", "sch\u00f6n", "nach", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Herodes danck euch vor dies Lied,", "tokens": ["He\u00b7ro\u00b7des", "danck", "euch", "vor", "dies", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "PDS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich mag's so leicht nicht singen.", "tokens": ["Ich", "mag's", "so", "leicht", "nicht", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch wo mich eure Fistel zieht,", "tokens": ["Doch", "wo", "mich", "eu\u00b7re", "Fis\u00b7tel", "zieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So lernt vorher gut springen;", "tokens": ["So", "lernt", "vor\u00b7her", "gut", "sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sonst heult mein Satyr und sein Chor", "tokens": ["Sonst", "heult", "mein", "Sa\u00b7tyr", "und", "sein", "Chor"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Euch ganz gewis erschr\u00f6cklich vor.", "tokens": ["Euch", "ganz", "ge\u00b7wis", "er\u00b7schr\u00f6ck\u00b7lich", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Denn seyd ihr gar so schlimm und grob,", "tokens": ["Denn", "seyd", "ihr", "gar", "so", "schlimm", "und", "grob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich ohne Noth zu st\u00f6ren,", "tokens": ["Mich", "oh\u00b7ne", "Noth", "zu", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So sollt auch ihr dies sch\u00f6ne Lob", "tokens": ["So", "sollt", "auch", "ihr", "dies", "sch\u00f6\u00b7ne", "Lob"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "PPER", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von eurem Wandel h\u00f6ren;", "tokens": ["Von", "eu\u00b7rem", "Wan\u00b7del", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn dieser geht so rein und nett", "tokens": ["Denn", "die\u00b7ser", "geht", "so", "rein", "und", "nett"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als kaum ein Lumpenquodlibet.", "tokens": ["Als", "kaum", "ein", "Lum\u00b7pen\u00b7quod\u00b7li\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Da soll Magister Lobesan", "tokens": ["Da", "soll", "Ma\u00b7gis\u00b7ter", "Lo\u00b7be\u00b7san"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mitsamt den klugen Schwestern", "tokens": ["Mit\u00b7samt", "den", "klu\u00b7gen", "Schwes\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mancher bunte Nothgalan", "tokens": ["Und", "man\u00b7cher", "bun\u00b7te", "Noth\u00b7ga\u00b7lan"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Blos in den Schubsack l\u00e4stern.", "tokens": ["Blos", "in", "den", "Schub\u00b7sack", "l\u00e4s\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Denn scheeren sie nur ofenbahr,", "tokens": ["Denn", "schee\u00b7ren", "sie", "nur", "o\u00b7fen\u00b7bahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So kommen sie gewis ums Haar.", "tokens": ["So", "kom\u00b7men", "sie", "ge\u00b7wis", "ums", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ein Kluger schnizt und hobelt zwar", "tokens": ["Ein", "Klu\u00b7ger", "schnizt", "und", "ho\u00b7belt", "zwar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am ersten seinen Balcken;", "tokens": ["Am", "ers\u00b7ten", "sei\u00b7nen", "Bal\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch sch\u00e4ndet man ihn ganz und gar,", "tokens": ["Doch", "sch\u00e4n\u00b7det", "man", "ihn", "ganz", "und", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So kan er auch den Falcken,", "tokens": ["So", "kan", "er", "auch", "den", "Fal\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die jedes Nechsten Splitter sehn,", "tokens": ["Die", "je\u00b7des", "Nechs\u00b7ten", "Split\u00b7ter", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Recht die Spiz entgegendrehn.", "tokens": ["Mit", "Recht", "die", "Spiz", "ent\u00b7ge\u00b7gen\u00b7drehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}