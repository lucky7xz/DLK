{"dta.poem.11382": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Als Herr Christoph Ferdinand Kamper  \n  an.  1706 den  gradum Doctoris  beyder Rechten  \n erhielt, im nahmen der in Jena  \n studierenden Schlesier.  \n E. G.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Begl\u00fcckte Themis-burg! dein grund mu\u00df ewig stehn,", "tokens": ["Be\u00b7gl\u00fcck\u00b7te", "The\u00b7mi\u00b7sburg", "!", "dein", "grund", "mu\u00df", "e\u00b7wig", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$.", "PPOSAT", "NN", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wird durch keinen sturm der zeiten umgerissen,", "tokens": ["Und", "wird", "durch", "kei\u00b7nen", "sturm", "der", "zei\u00b7ten", "um\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lang als r\u00e4the noch in deinen thoren gehn,", "tokens": ["So", "lang", "als", "r\u00e4\u00b7the", "noch", "in", "dei\u00b7nen", "tho\u00b7ren", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die recht und billichkeit geschickt zu handeln wissen.", "tokens": ["Die", "recht", "und", "bil\u00b7lich\u00b7keit", "ge\u00b7schickt", "zu", "han\u00b7deln", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "NN", "VVPP", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ob ein Lycurgus schon vorl\u00e4ngst vermodert ist,", "tokens": ["Ob", "ein", "Ly\u00b7cur\u00b7gus", "schon", "vor\u00b7l\u00e4ngst", "ver\u00b7mo\u00b7dert", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NE", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Numa seinen glantz in asch und staub verschliest:", "tokens": ["Und", "Nu\u00b7ma", "sei\u00b7nen", "glantz", "in", "asch", "und", "staub", "ver\u00b7schliest", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PPOSAT", "NN", "APPR", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So tr\u00e4gt doch unsre zeit noch kluge Labeonen,", "tokens": ["So", "tr\u00e4gt", "doch", "uns\u00b7re", "zeit", "noch", "klu\u00b7ge", "La\u00b7be\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bey denen recht und licht, als treue schwestern, wohnen.", "tokens": ["Bey", "de\u00b7nen", "recht", "und", "licht", ",", "als", "treu\u00b7e", "schwes\u00b7tern", ",", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "ADJD", "KON", "NN", "$,", "KOUS", "ADJA", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es will das theure recht nicht blind gewogen seyn:", "tokens": ["Es", "will", "das", "theu\u00b7re", "recht", "nicht", "blind", "ge\u00b7wo\u00b7gen", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PTKNEG", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man mu\u00df hier gantz genau das gleich-gewichte kennen;", "tokens": ["Man", "mu\u00df", "hier", "gantz", "ge\u00b7nau", "das", "gleich\u00b7ge\u00b7wich\u00b7te", "ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "ADJD", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum stimmt ein kluger nicht in schlu\u00df und urtheil ein,", "tokens": ["Drum", "stimmt", "ein", "klu\u00b7ger", "nicht", "in", "schlu\u00df", "und", "ur\u00b7theil", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "PTKNEG", "APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo statt des rechten lichts geborgte lampen brennen.", "tokens": ["Wo", "statt", "des", "rech\u00b7ten", "lichts", "ge\u00b7borg\u00b7te", "lam\u00b7pen", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "VVFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die wahrheit, so man nur mit fremden augen sieht,", "tokens": ["Die", "wahr\u00b7heit", ",", "so", "man", "nur", "mit", "frem\u00b7den", "au\u00b7gen", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PIS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gleicht sch\u00e4tzen, die ein traum aus falschen bergen zieht;", "tokens": ["Gleicht", "sch\u00e4t\u00b7zen", ",", "die", "ein", "traum", "aus", "fal\u00b7schen", "ber\u00b7gen", "zieht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "PRELS", "ART", "NN", "APPR", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und die, wie Capito, blos auf die alten trauen,", "tokens": ["Und", "die", ",", "wie", "Ca\u00b7pi\u00b7to", ",", "blos", "auf", "die", "al\u00b7ten", "trau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PWAV", "NE", "$,", "ADV", "APPR", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bekommen nur den schaum der rechte zu beschauen.", "tokens": ["Be\u00b7kom\u00b7men", "nur", "den", "schaum", "der", "rech\u00b7te", "zu", "be\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wer die gelehrsamkeit nicht blos nach brode mi\u00dft,", "tokens": ["Wer", "die", "ge\u00b7lehr\u00b7sam\u00b7keit", "nicht", "blos", "nach", "bro\u00b7de", "mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PTKNEG", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sucht tieffer in die klufft derselben einzudringen:", "tokens": ["Sucht", "tief\u00b7fer", "in", "die", "klufft", "der\u00b7sel\u00b7ben", "ein\u00b7zu\u00b7drin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "PDAT", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil man sonsten leicht den rechten grund vergi\u00dft,", "tokens": ["Und", "weil", "man", "sons\u00b7ten", "leicht", "den", "rech\u00b7ten", "grund", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "ADJD", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So mu\u00df sich der verstand zuerst in ordnung bringen.", "tokens": ["So", "mu\u00df", "sich", "der", "ver\u00b7stand", "zu\u00b7erst", "in", "ord\u00b7nung", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PRF", "ART", "VVFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das zeigt der weisen kunst, so regeln ausgedacht,", "tokens": ["Das", "zeigt", "der", "wei\u00b7sen", "kunst", ",", "so", "re\u00b7geln", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nach denen unser geist bew\u00e4hrte schl\u00fcsse macht:", "tokens": ["Nach", "de\u00b7nen", "un\u00b7ser", "geist", "be\u00b7w\u00e4hr\u00b7te", "schl\u00fcs\u00b7se", "macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die \u00f6ffnet ihm das thor in den entfernten thronen,", "tokens": ["Die", "\u00f6ff\u00b7net", "ihm", "das", "thor", "in", "den", "ent\u00b7fern\u00b7ten", "thro\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo die vernunfft regiert, und recht und wahrheit wohnen.", "tokens": ["Wo", "die", "ver\u00b7nunfft", "re\u00b7giert", ",", "und", "recht", "und", "wahr\u00b7heit", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "KON", "ADJD", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch kan die wahrheit nicht entbl\u00f6\u00dft von tugend seyn;", "tokens": ["Doch", "kan", "die", "wahr\u00b7heit", "nicht", "ent\u00b7bl\u00f6\u00dft", "von", "tu\u00b7gend", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PTKNEG", "VVFIN", "APPR", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn wer die laster soll mit strengen strafen r\u00e4chen,", "tokens": ["Denn", "wer", "die", "las\u00b7ter", "soll", "mit", "stren\u00b7gen", "stra\u00b7fen", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und das gedr\u00fcckte volck mit h\u00fclff und rath erfreun,", "tokens": ["Und", "das", "ge\u00b7dr\u00fcck\u00b7te", "volck", "mit", "h\u00fclff", "und", "rath", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mu\u00df denen neigungen zuvor den willen brechen.", "tokens": ["Mu\u00df", "de\u00b7nen", "nei\u00b7gun\u00b7gen", "zu\u00b7vor", "den", "wil\u00b7len", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Wer seiner urtheil grund auf tollen vorwitz setzt,", "tokens": ["Wer", "sei\u00b7ner", "ur\u00b7theil", "grund", "auf", "tol\u00b7len", "vor\u00b7witz", "setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nach geschencken spricht, wird selten hochgesch\u00e4tzt;", "tokens": ["Und", "nach", "ge\u00b7schen\u00b7cken", "spricht", ",", "wird", "sel\u00b7ten", "hoch\u00b7ge\u00b7sch\u00e4tzt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch wissen darff nicht frey von dem gewissen bleiben:", "tokens": ["Doch", "wis\u00b7sen", "darff", "nicht", "frey", "von", "dem", "ge\u00b7wis\u00b7sen", "blei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PTKNEG", "ADJD", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Drum mu\u00df ein Seneca sich selbst gesetze schreiben.", "tokens": ["Drum", "mu\u00df", "ein", "Se\u00b7ne\u00b7ca", "sich", "selbst", "ge\u00b7set\u00b7ze", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ART", "NE", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Drauf wird die g\u00f6ldne burg der Themis aufgethan:", "tokens": ["Drauf", "wird", "die", "g\u00f6ld\u00b7ne", "burg", "der", "The\u00b7mis", "auf\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wen ein kluger zweck auf diesen weg getrieben,", "tokens": ["Und", "wen", "ein", "klu\u00b7ger", "zweck", "auf", "die\u00b7sen", "weg", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "APPR", "PDAT", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der greifft, wie Grotius, das recht des himmels an,", "tokens": ["Der", "greifft", ",", "wie", "Gro\u00b7ti\u00b7us", ",", "das", "recht", "des", "him\u00b7mels", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "NE", "$,", "PRELS", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das unser Sch\u00f6pfer selbst in unsre brust geschrieben:", "tokens": ["Das", "un\u00b7ser", "Sch\u00f6p\u00b7fer", "selbst", "in", "uns\u00b7re", "brust", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Di\u00df zeigt den festen grund und das gewisse licht,", "tokens": ["Di\u00df", "zeigt", "den", "fes\u00b7ten", "grund", "und", "das", "ge\u00b7wis\u00b7se", "licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das grossen k\u00f6nigen und v\u00f6lckern urtheil spricht:", "tokens": ["Das", "gros\u00b7sen", "k\u00f6\u00b7ni\u00b7gen", "und", "v\u00f6l\u00b7ckern", "ur\u00b7theil", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es heist den tieffen quell uns klar vor augen kommen,", "tokens": ["Es", "heist", "den", "tief\u00b7fen", "quell", "uns", "klar", "vor", "au\u00b7gen", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PPER", "ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Aus dem Athen und Rom ihr erstes recht genommen.", "tokens": ["Aus", "dem", "A\u00b7then", "und", "Rom", "ihr", "ers\u00b7tes", "recht", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "KON", "NE", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "So denn versteht man erst, was ein Justinian", "tokens": ["So", "denn", "ver\u00b7steht", "man", "erst", ",", "was", "ein", "Jus\u00b7ti\u00b7ni\u00b7an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "ADV", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Aus st\u00fccken alter zeit der nach-welt aufgehoben:", "tokens": ["Aus", "st\u00fc\u00b7cken", "al\u00b7ter", "zeit", "der", "nach\u00b7welt", "auf\u00b7ge\u00b7ho\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man sieht, was recht und fleis, betrug und list gethan:", "tokens": ["Man", "sieht", ",", "was", "recht", "und", "fleis", ",", "be\u00b7trug", "und", "list", "ge\u00b7than", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PRELS", "ADJD", "KON", "PTKVZ", "$,", "VVFIN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man tadelt nicht, was recht; man lernt nicht laster loben.", "tokens": ["Man", "ta\u00b7delt", "nicht", ",", "was", "recht", ";", "man", "lernt", "nicht", "las\u00b7ter", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "$,", "PRELS", "ADJD", "$.", "PIS", "VVFIN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was ein Pomponius und Ulpian gelehrt,", "tokens": ["Was", "ein", "Pom\u00b7po\u00b7ni\u00b7us", "und", "Ul\u00b7pi\u00b7an", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NE", "KON", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird, wie sie selbst begehrt, verst\u00e4ndig angeh\u00f6rt:", "tokens": ["Wird", ",", "wie", "sie", "selbst", "be\u00b7gehrt", ",", "ver\u00b7st\u00e4n\u00b7dig", "an\u00b7ge\u00b7h\u00f6rt", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "ADV", "VVPP", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wer das alte Rom sich wohl beschreiben lassen,", "tokens": ["Und", "wer", "das", "al\u00b7te", "Rom", "sich", "wohl", "be\u00b7schrei\u00b7ben", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NE", "PRF", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kan ihrer spr\u00fcche krafft offt von sich selbsten fassen.", "tokens": ["Kan", "ih\u00b7rer", "spr\u00fc\u00b7che", "krafft", "offt", "von", "sich", "selbs\u00b7ten", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Das alte Teutschland reicht zugleich gesetze dar,", "tokens": ["Das", "al\u00b7te", "Teutschland", "reicht", "zu\u00b7gleich", "ge\u00b7set\u00b7ze", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So viel die schrifften uns von jenen zeiten g\u00f6nnen:", "tokens": ["So", "viel", "die", "schriff\u00b7ten", "uns", "von", "je\u00b7nen", "zei\u00b7ten", "g\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "VVFIN", "PPER", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und die erfahrung macht den schlu\u00df noch t\u00e4glich wahr,", "tokens": ["Und", "die", "er\u00b7fah\u00b7rung", "macht", "den", "schlu\u00df", "noch", "t\u00e4g\u00b7lich", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "NN", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df unsre grentzen auch juristen zeigen k\u00f6nnen.", "tokens": ["Da\u00df", "uns\u00b7re", "grent\u00b7zen", "auch", "ju\u00b7ris\u00b7ten", "zei\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJA", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum wer sich Byzantz blos mit Rom zum zwecke stellt,", "tokens": ["Drum", "wer", "sich", "By\u00b7zantz", "blos", "mit", "Rom", "zum", "zwe\u00b7cke", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PWS", "PRF", "NE", "ADV", "APPR", "NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und den Tribonian vor seinen abgott h\u00e4lt,", "tokens": ["Und", "den", "Tri\u00b7bo\u00b7ni\u00b7an", "vor", "sei\u00b7nen", "ab\u00b7gott", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kennt Teutschlands gaben nicht, und hat noch nie gelesen,", "tokens": ["Kennt", "Teutschlands", "ga\u00b7ben", "nicht", ",", "und", "hat", "noch", "nie", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "PTKNEG", "$,", "KON", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Wie Lyncker, Schilter, Stryck ums recht bem\u00fcht gewesen.", "tokens": ["Wie", "Lyn\u00b7cker", ",", "Schil\u00b7ter", ",", "Stryck", "ums", "recht", "be\u00b7m\u00fcht", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "NN", "$,", "NN", "APPRART", "ADJD", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Begl\u00fccktes Saal-Athen! wo ein erw\u00fcnschtes fest", "tokens": ["Be\u00b7gl\u00fcck\u00b7tes", "Saa\u00b7lA\u00b7then", "!", "wo", "ein", "er\u00b7w\u00fcnschtes", "fest"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Den weg zur Themis-burg uns in exempeln zeiget:", "tokens": ["Den", "weg", "zur", "The\u00b7mi\u00b7sburg", "uns", "in", "ex\u00b7em\u00b7peln", "zei\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die deiner lehrer schlu\u00df als lehrer schauen l\u00e4st:", "tokens": ["Die", "dei\u00b7ner", "leh\u00b7rer", "schlu\u00df", "als", "leh\u00b7rer", "schau\u00b7en", "l\u00e4st", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "KOUS", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie klugheit, kunst und flei\u00df zum ehren-gipfel steiget.", "tokens": ["Wie", "klug\u00b7heit", ",", "kunst", "und", "flei\u00df", "zum", "eh\u00b7ren\u00b7gip\u00b7fel", "stei\u00b7get", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "ADV", "KON", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die freude, die man hier bey deinem flore sp\u00fcrt,", "tokens": ["Die", "freu\u00b7de", ",", "die", "man", "hier", "bey", "dei\u00b7nem", "flo\u00b7re", "sp\u00fcrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ADV", "APPR", "PPOSAT", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird durch der l\u00fcffte gunst weit in die welt gef\u00fchrt:", "tokens": ["Wird", "durch", "der", "l\u00fcff\u00b7te", "gunst", "weit", "in", "die", "welt", "ge\u00b7f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und unser Schlesien l\u00e4st auf den breiten auen,", "tokens": ["Und", "un\u00b7ser", "Schle\u00b7si\u00b7en", "l\u00e4st", "auf", "den", "brei\u00b7ten", "au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Guttalus benetzt, auch sein vergn\u00fcgen schauen.", "tokens": ["Die", "Gut\u00b7ta\u00b7lus", "be\u00b7netzt", ",", "auch", "sein", "ver\u00b7gn\u00fc\u00b7gen", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ADV", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Begl\u00fccktes Schlesien! das solche s\u00f6hne zeugt,", "tokens": ["Be\u00b7gl\u00fcck\u00b7tes", "Schle\u00b7si\u00b7en", "!", "das", "sol\u00b7che", "s\u00f6h\u00b7ne", "zeugt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ART", "PIAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die licht und recht zugleich aus welt und b\u00fcchern lernen.", "tokens": ["Die", "licht", "und", "recht", "zu\u00b7gleich", "aus", "welt", "und", "b\u00fc\u00b7chern", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "ADV", "APPR", "NN", "KON", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So kan der alte ruhm, der an die wolcken steigt,", "tokens": ["So", "kan", "der", "al\u00b7te", "ruhm", ",", "der", "an", "die", "wol\u00b7cken", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey der gelehrten welt sich nie von dir entfernen;", "tokens": ["Bey", "der", "ge\u00b7lehr\u00b7ten", "welt", "sich", "nie", "von", "dir", "ent\u00b7fer\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PRF", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Kamper stellet dir itzt sein exempel dar,", "tokens": ["Dein", "Kam\u00b7per", "stel\u00b7let", "dir", "itzt", "sein", "ex\u00b7em\u00b7pel", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und macht den reiffen schlu\u00df des weisen Hanckens wahr:", "tokens": ["Und", "macht", "den", "reif\u00b7fen", "schlu\u00df", "des", "wei\u00b7sen", "Han\u00b7ckens", "wahr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja was der kluge Krantz vorl\u00e4ngst an ihm erblicket,", "tokens": ["Ja", "was", "der", "klu\u00b7ge", "Krantz", "vor\u00b7l\u00e4ngst", "an", "ihm", "er\u00b7bli\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PRELS", "ART", "ADJA", "NN", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Das wird auf diesen tag vortrefflich ausgedr\u00fccket.", "tokens": ["Das", "wird", "auf", "die\u00b7sen", "tag", "vor\u00b7treff\u00b7lich", "aus\u00b7ge\u00b7dr\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PDAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Dein Kamper hat den weg vern\u00fcnfftig angestellt:", "tokens": ["Dein", "Kam\u00b7per", "hat", "den", "weg", "ver\u00b7n\u00fcnff\u00b7tig", "an\u00b7ge\u00b7stellt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erst muste Treuner ihn den grund der wei\u00dfheit zeigen,", "tokens": ["Erst", "mus\u00b7te", "Treu\u00b7ner", "ihn", "den", "grund", "der", "wei\u00df\u00b7heit", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der wei\u00dfheit, die vernunfft und nutzen in sich h\u00e4lt:", "tokens": ["Der", "wei\u00df\u00b7heit", ",", "die", "ver\u00b7nunfft", "und", "nut\u00b7zen", "in", "sich", "h\u00e4lt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "VVFIN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dann kunte sein verstand zur rechts-gelahrheit zeigen,", "tokens": ["Dann", "kun\u00b7te", "sein", "ver\u00b7stand", "zur", "rechts\u00b7ge\u00b7lahr\u00b7heit", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VAINF", "VVFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo Beyer, Bohse, Fl\u00f6rck, die fackeln aufgesteckt,", "tokens": ["Wo", "Be\u00b7yer", ",", "Boh\u00b7se", ",", "Fl\u00f6rck", ",", "die", "fa\u00b7ckeln", "auf\u00b7ge\u00b7steckt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "NN", "$,", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Roms und Teutschlands recht ihm mit vernunfft entdeckt:", "tokens": ["Die", "Roms", "und", "Teutschlands", "recht", "ihm", "mit", "ver\u00b7nunfft", "ent\u00b7deckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NN", "ADV", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Darauf Wildvogels fleis und Slevogts kluge glossen", "tokens": ["Da\u00b7rauf", "Wild\u00b7vo\u00b7gels", "fleis", "und", "Sle\u00b7vogts", "klu\u00b7ge", "glos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "NN", "PTKVZ", "KON", "NE", "ADJA", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Jhm noch dazu das recht der kirchen aufgeschlossen.", "tokens": ["Jhm", "noch", "da\u00b7zu", "das", "recht", "der", "kir\u00b7chen", "auf\u00b7ge\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PAV", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Erlaube, werther freund! da\u00df unsre liebes-pflicht,", "tokens": ["Er\u00b7lau\u00b7be", ",", "wert\u00b7her", "freund", "!", "da\u00df", "uns\u00b7re", "lie\u00b7bes\u00b7pflicht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$.", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu der die tugend uns sam\u0303t der vernunfft verbindet,", "tokens": ["Zu", "der", "die", "tu\u00b7gend", "uns", "sam\u0303t", "der", "ver\u00b7nunfft", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Anitzt mit dir zugleich die freuden-rosen bricht,", "tokens": ["A\u00b7nitzt", "mit", "dir", "zu\u00b7gleich", "die", "freu\u00b7den\u00b7ro\u00b7sen", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die dein gelehrter flei\u00df auf schnee und eise findet.", "tokens": ["Die", "dein", "ge\u00b7lehr\u00b7ter", "flei\u00df", "auf", "schnee", "und", "ei\u00b7se", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "La\u00df den getreuen wunsch von unsrer hand bestehn:", "tokens": ["La\u00df", "den", "ge\u00b7treu\u00b7en", "wunsch", "von", "uns\u00b7rer", "hand", "be\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der himmel, der dich hei\u00dft in lehrer-orden gehn,", "tokens": ["Der", "him\u00b7mel", ",", "der", "dich", "hei\u00dft", "in", "leh\u00b7rer\u00b7or\u00b7den", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der schaffe, da\u00df dein flei\u00df auf der gelehrten reise,", "tokens": ["Der", "schaf\u00b7fe", ",", "da\u00df", "dein", "flei\u00df", "auf", "der", "ge\u00b7lehr\u00b7ten", "rei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Viel andern diesen weg zur rechts-gelahrheit weise!", "tokens": ["Viel", "an\u00b7dern", "die\u00b7sen", "weg", "zur", "rechts\u00b7ge\u00b7lahr\u00b7heit", "wei\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "PDAT", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}