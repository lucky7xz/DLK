{"textgrid.poem.48253": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Sp\u00e4tes Ehestandsgl\u00fcck", "genre": "verse", "period": "N.A.", "pub_year": 1893, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Neben mir an, ein Mann im Staat,", "tokens": ["Ne\u00b7ben", "mir", "an", ",", "ein", "Mann", "im", "Staat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wohnt ein alter Geheimerat.", "tokens": ["Wohnt", "ein", "al\u00b7ter", "Ge\u00b7hei\u00b7me\u00b7rat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Er hat, nachdem er durch St\u00fcrme gesteuert,", "tokens": ["Er", "hat", ",", "nach\u00b7dem", "er", "durch", "St\u00fcr\u00b7me", "ge\u00b7steu\u00b7ert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit sechzig noch eine Witwe geheuert,", "tokens": ["Mit", "sech\u00b7zig", "noch", "ei\u00b7ne", "Wit\u00b7we", "ge\u00b7heu\u00b7ert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Wirtin und Pl\u00e4ttfrau war sie gewesen,", "tokens": ["Wir\u00b7tin", "und", "Pl\u00e4tt\u00b7frau", "war", "sie", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "VAPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Es geht nun schon ins dritte Jahr, \u2013", "tokens": ["Es", "geht", "nun", "schon", "ins", "drit\u00b7te", "Jahr", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nie zuvor er so gl\u00fccklich war.", "tokens": ["Nie", "zu\u00b7vor", "er", "so", "gl\u00fcck\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Briefe zu Neujahr will heut er schreiben.", "tokens": ["Brie\u00b7fe", "zu", "Neu\u00b7jahr", "will", "heut", "er", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VMFIN", "ADV", "PPER", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Eisblumen bl\u00fchen ihm an den Scheiben,", "tokens": ["Eis\u00b7blu\u00b7men", "bl\u00fc\u00b7hen", "ihm", "an", "den", "Schei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "++-+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Drau\u00dfen ein helles Silvesterwetter,", "tokens": ["Drau\u00b7\u00dfen", "ein", "hel\u00b7les", "Sil\u00b7ves\u00b7ter\u00b7wet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und er schreibt in Kursivschrift: \u00bbLieber Vetter,", "tokens": ["Und", "er", "schreibt", "in", "Kur\u00b7siv\u00b7schrift", ":", "\u00bb", "Lie\u00b7ber", "Vet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$.", "$(", "ADJD", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Du hast dich, gleich mir, aus Wellen und Wogen", "tokens": ["Du", "hast", "dich", ",", "gleich", "mir", ",", "aus", "Wel\u00b7len", "und", "Wo\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "$,", "ADV", "PPER", "$,", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Der \u203ah\u00f6h'ren Justiz\u2039 zur\u00fcckgezogen,", "tokens": ["Der", "\u203a", "h\u00f6h'\u00b7ren", "Jus\u00b7tiz", "\u2039", "zu\u00b7r\u00fcck\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "$(", "ADJA", "NN", "$(", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Von deinem K\u00f6nigsstuhle zu Rhense", "tokens": ["Von", "dei\u00b7nem", "K\u00f6\u00b7nigs\u00b7stuh\u00b7le", "zu", "Rhen\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NE"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Zogst du nach Treptow an der Tollense,", "tokens": ["Zogst", "du", "nach", "Trep\u00b7tow", "an", "der", "Tol\u00b7len\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Hinter dir liegt die Welt des Scheins,", "tokens": ["Hin\u00b7ter", "dir", "liegt", "die", "Welt", "des", "Scheins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Und so fehlt deinem Gl\u00fccke nur noch eins:", "tokens": ["Und", "so", "fehlt", "dei\u00b7nem", "Gl\u00fc\u00b7cke", "nur", "noch", "eins", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "PIS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Nimm auch ein Weib (aber von den gelinden,", "tokens": ["Nimm", "auch", "ein", "Weib", "(", "a\u00b7ber", "von", "den", "ge\u00b7lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "$(", "ADV", "APPR", "ART", "ADJA", "$,"], "meter": "+--++-+--+-", "measure": "trochaic.penta.relaxed"}, "line.12": {"text": "In Treptow wirst du dergleichen finden).", "tokens": ["In", "Trep\u00b7tow", "wirst", "du", "derg\u00b7lei\u00b7chen", "fin\u00b7den", ")", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PIS", "VVINF", "$(", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Ich bin dir in solchem Unterfangen", "tokens": ["Ich", "bin", "dir", "in", "sol\u00b7chem", "Un\u00b7ter\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.14": {"text": "Mit gutem Beispiel vorangegangen.", "tokens": ["Mit", "gu\u00b7tem", "Bei\u00b7spiel", "vor\u00b7an\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Und glaube mir \u2013 kann ich doch jetzt vergleichen \u2013,", "tokens": ["Und", "glau\u00b7be", "mir", "\u2013", "kann", "ich", "doch", "jetzt", "ver\u00b7glei\u00b7chen", "\u2013", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Man siegt nur noch in diesem Zeichen.", "tokens": ["Man", "siegt", "nur", "noch", "in", "die\u00b7sem", "Zei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Gestatte mir, dir ein Bild zu geben", "tokens": ["Ge\u00b7stat\u00b7te", "mir", ",", "dir", "ein", "Bild", "zu", "ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "PPER", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von meinem fr\u00fch'ren und jetzigen Leben.", "tokens": ["Von", "mei\u00b7nem", "fr\u00fch'\u00b7ren", "und", "jet\u00b7zi\u00b7gen", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich hielt es aufrichtig mit Schelling und Hegel,", "tokens": ["Ich", "hielt", "es", "auf\u00b7rich\u00b7tig", "mit", "Schel\u00b7ling", "und", "He\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Jetzt bin ich f\u00fcr Pankow, Sch\u00f6nhausen, Tegel,", "tokens": ["Jetzt", "bin", "ich", "f\u00fcr", "Pan\u00b7kow", ",", "Sch\u00f6n\u00b7hau\u00b7sen", ",", "Te\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NE", "$,", "NN", "$,", "NN", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich hielt es fr\u00fcher mit Wieland und Herder,", "tokens": ["Ich", "hielt", "es", "fr\u00fc\u00b7her", "mit", "Wie\u00b7land", "und", "Her\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Jetzt bin ich f\u00fcr Sacrow und Pichelswerder,", "tokens": ["Jetzt", "bin", "ich", "f\u00fcr", "Sa\u00b7crow", "und", "Pi\u00b7chels\u00b7wer\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sonst macht' ich vor Goethe die tiefsten Diener,", "tokens": ["Sonst", "macht'", "ich", "vor", "Goe\u00b7the", "die", "tiefs\u00b7ten", "Die\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Jetzt bin ich f\u00fcr Putlitz, Moser, Lubliner.", "tokens": ["Jetzt", "bin", "ich", "f\u00fcr", "Put\u00b7litz", ",", "Mo\u00b7ser", ",", "Lub\u00b7li\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NE", "$,", "NE", "$,", "NE", "$."], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.7": {"text": "O lern' auch du hinter derlei Sachen", "tokens": ["O", "lern'", "auch", "du", "hin\u00b7ter", "der\u00b7lei", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "PPER", "APPR", "PIAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ein gro\u00dfes Fragezeichen machen", "tokens": ["Ein", "gro\u00b7\u00dfes", "Fra\u00b7ge\u00b7zei\u00b7chen", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und empfang am Tage der Grogs und P\u00fcnsche", "tokens": ["Und", "emp\u00b7fang", "am", "Ta\u00b7ge", "der", "Grogs", "und", "P\u00fcn\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "NN", "KON", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Zun\u00e4chst meine herzlichsten Neujahrsw\u00fcnsche,", "tokens": ["Zu\u00b7n\u00e4chst", "mei\u00b7ne", "herz\u00b7lichs\u00b7ten", "Neu\u00b7jahrs\u00b7w\u00fcn\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Dazu den Zuruf, der immer frommt:", "tokens": ["Da\u00b7zu", "den", "Zu\u00b7ruf", ",", "der", "im\u00b7mer", "frommt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "\u203aisolan, Ihr kommt sp\u00e4t, jedoch Ihr kommt.\u2039\u00ab", "tokens": ["\u203a", "i\u00b7so\u00b7lan", ",", "Ihr", "kommt", "sp\u00e4t", ",", "je\u00b7doch", "Ihr", "kommt", ".", "\u2039", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "$,", "PPER", "VVFIN", "ADJD", "$,", "ADV", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}}}}