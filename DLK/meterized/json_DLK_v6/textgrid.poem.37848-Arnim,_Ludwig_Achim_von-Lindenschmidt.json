{"textgrid.poem.37848": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Lindenschmidt", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist nicht lange da\u00df es geschah,", "tokens": ["Es", "ist", "nicht", "lan\u00b7ge", "da\u00df", "es", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da\u00df man den Lindenschmidt reiten sah,", "tokens": ["Da\u00df", "man", "den", "Lin\u00b7den\u00b7schmidt", "rei\u00b7ten", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Auf einem hohen Rosse.", "tokens": ["Auf", "ei\u00b7nem", "ho\u00b7hen", "Ros\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er reitet den Rheinstrom auf und ab;", "tokens": ["Er", "rei\u00b7tet", "den", "Rhein\u00b7strom", "auf", "und", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Er hat ihn gar wohl genossen.", "tokens": ["Er", "hat", "ihn", "gar", "wohl", "ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "\u00bbfrisch her ihr lieben Gesellen mein!", "tokens": ["\u00bb", "frisch", "her", "ihr", "lie\u00b7ben", "Ge\u00b7sel\u00b7len", "mein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "ADV", "PPOSAT", "ADJA", "NN", "PPOSAT", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es mu\u00df jezt nur gewaget seyn,", "tokens": ["Es", "mu\u00df", "jezt", "nur", "ge\u00b7wa\u00b7get", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wagen das thut gewinnen,", "tokens": ["Wa\u00b7gen", "das", "thut", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "VVFIN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Wir wollen reiten Tag und Nacht,", "tokens": ["Wir", "wol\u00b7len", "rei\u00b7ten", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis wir die Beute gewinnen!\u00ab", "tokens": ["Bis", "wir", "die", "Beu\u00b7te", "ge\u00b7win\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Dem Marggrafen von Baden kam neue M\u00e4hr,", "tokens": ["Dem", "Marg\u00b7gra\u00b7fen", "von", "Ba\u00b7den", "kam", "neu\u00b7e", "M\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Wie man ihm ins Geleit gefallen w\u00e4r,", "tokens": ["Wie", "man", "ihm", "ins", "Ge\u00b7leit", "ge\u00b7fal\u00b7len", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das th\u00e4t ihm sehr verdrie\u00dfen.", "tokens": ["Das", "th\u00e4t", "ihm", "sehr", "ver\u00b7drie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie bald er Junkern Kasparn schrieb:", "tokens": ["Wie", "bald", "er", "Jun\u00b7kern", "Kas\u00b7parn", "schrieb", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sollt ihm ein Rei\u00dflein dienen.", "tokens": ["Er", "sollt", "ihm", "ein", "Rei\u00df\u00b7lein", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Junker Kaspar zog'n B\u00e4uerlein eine Kappe an;", "tokens": ["Jun\u00b7ker", "Kas\u00b7par", "zo\u00b7g'n", "B\u00e4u\u00b7er\u00b7lein", "ei\u00b7ne", "Kap\u00b7pe", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Er schickt ihn allezeit vorn dran,", "tokens": ["Er", "schickt", "ihn", "al\u00b7le\u00b7zeit", "vorn", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl auf die freie Stra\u00dfen,", "tokens": ["Wohl", "auf", "die", "frei\u00b7e", "Stra\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ob er den edlen Lindenschmidt findt,", "tokens": ["Ob", "er", "den", "ed\u00b7len", "Lin\u00b7den\u00b7schmidt", "findt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Denselben sollt er verrathen.", "tokens": ["Den\u00b7sel\u00b7ben", "sollt", "er", "ver\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Das B\u00e4uerlein schiffet \u00fcber den Rhein,", "tokens": ["Das", "B\u00e4u\u00b7er\u00b7lein", "schif\u00b7fet", "\u00fc\u00b7ber", "den", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NE", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er kehret zu Frankenthal ins Wirthshaus ein:", "tokens": ["Er", "keh\u00b7ret", "zu", "Fran\u00b7ken\u00b7thal", "ins", "Wirths\u00b7haus", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u00bbwirth, haben wir nichts zu essen?", "tokens": ["\u00bb", "wirth", ",", "ha\u00b7ben", "wir", "nichts", "zu", "es\u00b7sen", "?"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Es kommen drey Wagen, sind wohl beladen,", "tokens": ["Es", "kom\u00b7men", "drey", "Wa\u00b7gen", ",", "sind", "wohl", "be\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "$,", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Von Frankfurt aus der Messen.\u00ab", "tokens": ["Von", "Frank\u00b7furt", "aus", "der", "Mes\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der Wirth der sprach dem B\u00e4uerlein zu:", "tokens": ["Der", "Wirth", "der", "sprach", "dem", "B\u00e4u\u00b7er\u00b7lein", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbja, Wein und Brod hab ich genug!", "tokens": ["\u00bb", "ja", ",", "Wein", "und", "Brod", "hab", "ich", "ge\u00b7nug", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "NN", "KON", "NN", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Stalle da stehen drey Rosse,", "tokens": ["Im", "Stal\u00b7le", "da", "ste\u00b7hen", "drey", "Ros\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVFIN", "CARD", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Die sind des edlen Lindenschmidts,", "tokens": ["Die", "sind", "des", "ed\u00b7len", "Lin\u00b7den\u00b7schmidts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er n\u00e4hrt sich auf freyer Stra\u00dfen.\u00ab", "tokens": ["Er", "n\u00e4hrt", "sich", "auf", "frey\u00b7er", "Stra\u00b7\u00dfen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Das B\u00e4uerlein gedacht in seinem Muth,", "tokens": ["Das", "B\u00e4u\u00b7er\u00b7lein", "ge\u00b7dacht", "in", "sei\u00b7nem", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Sache wird noch werden gut,", "tokens": ["Die", "Sa\u00b7che", "wird", "noch", "wer\u00b7den", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Feind hab ich vernommen.", "tokens": ["Den", "Feind", "hab", "ich", "ver\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Alsbald er Junkern Kaspar schrieb,", "tokens": ["Als\u00b7bald", "er", "Jun\u00b7kern", "Kas\u00b7par", "schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df er sollt eilends kommen.", "tokens": ["Da\u00df", "er", "sollt", "ei\u00b7lends", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Der Lindenschmidt h\u00e4tt einen Sohn,", "tokens": ["Der", "Lin\u00b7den\u00b7schmidt", "h\u00e4tt", "ei\u00b7nen", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der sollt den Rossen das Futter thun,", "tokens": ["Der", "sollt", "den", "Ros\u00b7sen", "das", "Fut\u00b7ter", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den Haber th\u00e4t er schwingen:", "tokens": ["Den", "Ha\u00b7ber", "th\u00e4t", "er", "schwin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbsteht auf, herzlieber Vater mein!", "tokens": ["\u00bb", "steht", "auf", ",", "herz\u00b7lie\u00b7ber", "Va\u00b7ter", "mein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "ADV", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich h\u00f6r die Harnische klingen.\u00ab", "tokens": ["Ich", "h\u00f6r", "die", "Har\u00b7ni\u00b7sche", "klin\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Der Lindenschmidt lag hinterm Tisch und schlief,", "tokens": ["Der", "Lin\u00b7den\u00b7schmidt", "lag", "hin\u00b7term", "Tisch", "und", "schlief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sein Sohn der th\u00e4t so manchen Rief,", "tokens": ["Sein", "Sohn", "der", "th\u00e4t", "so", "man\u00b7chen", "Rief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Schlaf hat ihn bezwungen:", "tokens": ["Der", "Schlaf", "hat", "ihn", "be\u00b7zwun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbsteht auf, herzliebster Vater mein!", "tokens": ["\u00bb", "steht", "auf", ",", "herz\u00b7liebs\u00b7ter", "Va\u00b7ter", "mein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "ADJA", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Verr\u00e4ther ist schon gekommen.\u00ab", "tokens": ["Der", "Ver\u00b7r\u00e4\u00b7ther", "ist", "schon", "ge\u00b7kom\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$.", "$("], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Junker Kaspar zu der Stuben eintrat,", "tokens": ["Jun\u00b7ker", "Kas\u00b7par", "zu", "der", "Stu\u00b7ben", "ein\u00b7trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Der Lindenschmidt von Herzen sehr erschrack:", "tokens": ["Der", "Lin\u00b7den\u00b7schmidt", "von", "Her\u00b7zen", "sehr", "er\u00b7schrack", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bblindenschmidt gieb dich gefangen!", "tokens": ["\u00bb", "lin\u00b7den\u00b7schmidt", "gieb", "dich", "ge\u00b7fan\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVIMP", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu Baden, an den Galgen hoch,", "tokens": ["Zu", "Ba\u00b7den", ",", "an", "den", "Gal\u00b7gen", "hoch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Daran sollst du bald hangen.\u00ab", "tokens": ["Da\u00b7ran", "sollst", "du", "bald", "han\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Der Lindenschmidt war ein freier Reitersmann,", "tokens": ["Der", "Lin\u00b7den\u00b7schmidt", "war", "ein", "frei\u00b7er", "Rei\u00b7ters\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie bald er zu der Klingen sprang:", "tokens": ["Wie", "bald", "er", "zu", "der", "Klin\u00b7gen", "sprang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwir wollen erst ritterlich fechten!\u00ab", "tokens": ["\u00bb", "wir", "wol\u00b7len", "erst", "rit\u00b7ter\u00b7lich", "fech\u00b7ten", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Es waren der Bluthund allzuviel,", "tokens": ["Es", "wa\u00b7ren", "der", "Blut\u00b7hund", "all\u00b7zu\u00b7viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PIAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie schlugen ihn zu der Erden.", "tokens": ["Sie", "schlu\u00b7gen", "ihn", "zu", "der", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "\u00bbkann und mag es dann nicht anders seyn,", "tokens": ["\u00bb", "kann", "und", "mag", "es", "dann", "nicht", "an\u00b7ders", "seyn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "KON", "VMFIN", "PPER", "ADV", "PTKNEG", "ADV", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "So bitt' ich um den liebsten Sohn mein,", "tokens": ["So", "bitt'", "ich", "um", "den", "liebs\u00b7ten", "Sohn", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch um meinen Reutersjungen,", "tokens": ["Auch", "um", "mei\u00b7nen", "Reu\u00b7ters\u00b7jun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Haben sie jemanden Leid's gethan,", "tokens": ["Ha\u00b7ben", "sie", "je\u00b7man\u00b7den", "Lei\u00b7d's", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "Dazu hab ich sie gezwungen.\u00ab", "tokens": ["Da\u00b7zu", "hab", "ich", "sie", "ge\u00b7zwun\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPER", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Junker Kaspar, der sprach nein dazu:", "tokens": ["Jun\u00b7ker", "Kas\u00b7par", ",", "der", "sprach", "nein", "da\u00b7zu", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "VVFIN", "PTKANT", "PAV", "$."], "meter": "+-+--++-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "\u00bbdas Kalb mu\u00df entgelten der Kuh,", "tokens": ["\u00bb", "das", "Kalb", "mu\u00df", "ent\u00b7gel\u00b7ten", "der", "Kuh", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Es soll dir nicht gelingen!", "tokens": ["Es", "soll", "dir", "nicht", "ge\u00b7lin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu Baden, in der werthen Stadt,", "tokens": ["Zu", "Ba\u00b7den", ",", "in", "der", "wert\u00b7hen", "Stadt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mu\u00df ihm sein Haupt abspringen!\u00ab", "tokens": ["Mu\u00df", "ihm", "sein", "Haupt", "ab\u00b7sprin\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Sie wurden alle drey nach Baden gebracht,", "tokens": ["Sie", "wur\u00b7den", "al\u00b7le", "drey", "nach", "Ba\u00b7den", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "CARD", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Sie sa\u00dfen nicht l\u00e4nger als eine Nacht;", "tokens": ["Sie", "sa\u00b7\u00dfen", "nicht", "l\u00e4n\u00b7ger", "als", "ei\u00b7ne", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wohl zu derselben Stunde,", "tokens": ["Wohl", "zu", "der\u00b7sel\u00b7ben", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ward der Lindenschmidt gericht,", "tokens": ["Da", "ward", "der", "Lin\u00b7den\u00b7schmidt", "ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein Sohn und Reutersjunge.", "tokens": ["Sein", "Sohn", "und", "Reu\u00b7ters\u00b7jun\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}