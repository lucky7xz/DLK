{"textgrid.poem.53137": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wenn ich in dem Wiesen-Schnee", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn ich in dem Wiesen-Schnee", "tokens": ["Wenn", "ich", "in", "dem", "Wie\u00b7sen\u00b7Schnee"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "An des Pregels Rande geh',", "tokens": ["An", "des", "Pre\u00b7gels", "Ran\u00b7de", "geh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen gutten Reim zu fassen,", "tokens": ["Ei\u00b7nen", "gut\u00b7ten", "Reim", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd den N\u00f6rdlich-kalten Ost,", "tokens": ["Vnd", "den", "N\u00f6rd\u00b7lich\u00b7kal\u00b7ten", "Ost", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jetzt den Stadt- vnd Landes-Trost,", "tokens": ["Jetzt", "den", "Stadt", "vnd", "Lan\u00b7des\u00b7Trost", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zimlich mich durchwehen lassen,", "tokens": ["Zim\u00b7lich", "mich", "durch\u00b7we\u00b7hen", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Steckt denn sp\u00e4t des Himmels Hau\u00df", "tokens": ["Steckt", "denn", "sp\u00e4t", "des", "Him\u00b7mels", "Hau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sein bew\u00f6lcktes Nacht-Licht aus.", "tokens": ["Sein", "be\u00b7w\u00f6lck\u00b7tes", "Nacht\u00b7Licht", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das mich heim zu gehen zwinget,", "tokens": ["Das", "mich", "heim", "zu", "ge\u00b7hen", "zwin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PTKVZ", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wer begreifft die Lieb vnd Zier,", "tokens": ["Wer", "be\u00b7greifft", "die", "Lieb", "vnd", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die durch meine Kinder mir,", "tokens": ["Die", "durch", "mei\u00b7ne", "Kin\u00b7der", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn ich komm, entgegen springet?", "tokens": ["Wenn", "ich", "komm", ",", "ent\u00b7ge\u00b7gen", "sprin\u00b7get", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PTKVZ", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Dieses krahlt nach aller Lust", "tokens": ["Die\u00b7ses", "krahlt", "nach", "al\u00b7ler", "Lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "An der M\u00fctterlichen Brust,", "tokens": ["An", "der", "M\u00fct\u00b7ter\u00b7li\u00b7chen", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses reitet auff dem Stecken,", "tokens": ["Die\u00b7ses", "rei\u00b7tet", "auff", "dem", "Ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jenes tantzt vnd jauchtzt mir zu.", "tokens": ["Je\u00b7nes", "tantzt", "vnd", "jauchtzt", "mir", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Steinern ist, dem dies nicht Rhue", "tokens": ["Stei\u00b7nern", "ist", ",", "dem", "dies", "nicht", "Rhue"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "PRELS", "PDS", "PTKNEG", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Oder Frewde kan erwecken.", "tokens": ["O\u00b7der", "Frew\u00b7de", "kan", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sonst ist, der an Kinder stat", "tokens": ["Sonst", "ist", ",", "der", "an", "Kin\u00b7der", "stat"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "PRELS", "APPR", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Seine Lust am Weibe hat,", "tokens": ["Sei\u00b7ne", "Lust", "am", "Wei\u00b7be", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das sein Hertz jhm eingenommen,", "tokens": ["Das", "sein", "Hertz", "jhm", "ein\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was hat Euch ergetzt bisher,", "tokens": ["Was", "hat", "Euch", "er\u00b7getzt", "bis\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Freund, wenn Ihr von vnlust schwer", "tokens": ["Freund", ",", "wenn", "Ihr", "von", "vn\u00b7lust", "schwer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aus der Cantzeley seyd kommen?", "tokens": ["Aus", "der", "Cant\u00b7ze\u00b7ley", "seyd", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Zwar nach grosser Arbeit Last", "tokens": ["Zwar", "nach", "gros\u00b7ser", "Ar\u00b7beit", "Last"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan man anderweit auch Rast,", "tokens": ["Kan", "man", "an\u00b7der\u00b7weit", "auch", "Rast", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht nur bloh\u00df in Heyraht, finden:", "tokens": ["Nicht", "nur", "bloh\u00df", "in", "Hey\u00b7raht", ",", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "APPR", "NN", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00fccher, Freunde, Spiel vnd Wein", "tokens": ["B\u00fc\u00b7cher", ",", "Freun\u00b7de", ",", "Spiel", "vnd", "Wein"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "K\u00f6nnen auch wol Mittel seyn,", "tokens": ["K\u00f6n\u00b7nen", "auch", "wol", "Mit\u00b7tel", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "NN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wodurch Gram vnd Vnmuth schwinden.", "tokens": ["Wo\u00b7durch", "Gram", "vnd", "Vn\u00b7muth", "schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Vnd Catull ist einig froh", "tokens": ["Vnd", "Ca\u00b7tull", "ist", "ei\u00b7nig", "froh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VAFIN", "ADJD", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Vber seinen Sirmio,", "tokens": ["Vber", "sei\u00b7nen", "Sir\u00b7mio", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wenn er es in Wolfahrt schawen", "tokens": ["Wenn", "er", "es", "in", "Wol\u00b7fahrt", "scha\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Vnd ohn Sorg hie schlaffen kan,", "tokens": ["Vnd", "ohn", "Sorg", "hie", "schlaf\u00b7fen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auff den Weg, den er gethan", "tokens": ["Auff", "den", "Weg", ",", "den", "er", "ge\u00b7than"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Fern in die Bithyner-Awen.", "tokens": ["Fern", "in", "die", "Bi\u00b7thy\u00b7ner\u00b7A\u00b7wen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "++-+--+", "measure": "iambic.tetra.chol"}}, "stanza.7": {"line.1": {"text": "Aber nichts, auch was es sey,", "tokens": ["A\u00b7ber", "nichts", ",", "auch", "was", "es", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "ADV", "PWS", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6mpt gew\u00fcnschter Heyraht bey,", "tokens": ["K\u00f6mpt", "ge\u00b7w\u00fcnschter", "Hey\u00b7raht", "bey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sie kan vns der M\u00fch gelosen,", "tokens": ["Sie", "kan", "vns", "der", "M\u00fch", "ge\u00b7lo\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ist ein Bild der Ewigheit,", "tokens": ["Ist", "ein", "Bild", "der", "E\u00b7wig\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hegt sie Dornen jederzeit,", "tokens": ["Hegt", "sie", "Dor\u00b7nen", "je\u00b7der\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ey, sie tr\u00e4gt auch sch\u00f6ne Rosen.", "tokens": ["Ey", ",", "sie", "tr\u00e4gt", "auch", "sch\u00f6\u00b7ne", "Ro\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Die nimpt nun durch keusche Brunst", "tokens": ["Die", "nimpt", "nun", "durch", "keu\u00b7sche", "Brunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Euch auch, Freund, in jhre Gunst,", "tokens": ["Euch", "auch", ",", "Freund", ",", "in", "jhre", "Gunst", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wil Euch endlich Rhue verschaffen,", "tokens": ["Wil", "Euch", "end\u00b7lich", "Rhue", "ver\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NE", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Legt Euch in gew\u00fcnschter Trew", "tokens": ["Legt", "Euch", "in", "ge\u00b7w\u00fcnschter", "Trew"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "+----+", "measure": "dactylic.init"}, "line.5": {"text": "Einen Bettgenossen bey,", "tokens": ["Ei\u00b7nen", "Bett\u00b7ge\u00b7nos\u00b7sen", "bey", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df Ihr nicht allein solt schlaffen.", "tokens": ["Da\u00df", "Ihr", "nicht", "al\u00b7lein", "solt", "schlaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Ist es etwas sp\u00e4t geschehn,", "tokens": ["Ist", "es", "et\u00b7was", "sp\u00e4t", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Also hat es Gott versehn,", "tokens": ["Al\u00b7so", "hat", "es", "Gott", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der die Hertzen pflegt zu paaren.", "tokens": ["Der", "die", "Hert\u00b7zen", "pflegt", "zu", "paa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Greifft euch desto besser an,", "tokens": ["Greifft", "euch", "des\u00b7to", "bes\u00b7ser", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df man k\u00fcrtzlich sehen kan", "tokens": ["Da\u00df", "man", "k\u00fcrtz\u00b7lich", "se\u00b7hen", "kan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADJD", "VVINF", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hungern sey nicht Brodt besparen.", "tokens": ["Hun\u00b7gern", "sey", "nicht", "Brodt", "be\u00b7spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}