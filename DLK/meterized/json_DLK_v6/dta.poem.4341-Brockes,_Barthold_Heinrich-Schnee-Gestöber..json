{"dta.poem.4341": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Schnee-Gest\u00f6ber.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jm vierzigsten nach siebzehn hundert Jahr,", "tokens": ["Jm", "vier\u00b7zigs\u00b7ten", "nach", "sieb\u00b7zehn", "hun\u00b7dert", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "APPR", "CARD", "CARD", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Da ein recht strenger Winter war,", "tokens": ["Da", "ein", "recht", "stren\u00b7ger", "Win\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Am sechsten Tag\u2019 im Februar", "tokens": ["Am", "sechs\u00b7ten", "Tag'", "im", "Feb\u00b7ru\u00b7ar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab ich halb f\u00fcrchterlich, halb sch\u00f6n,", "tokens": ["Hab", "ich", "halb", "f\u00fcrch\u00b7ter\u00b7lich", ",", "halb", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ADJD", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Des strengen Winters weisse Pracht", "tokens": ["Des", "stren\u00b7gen", "Win\u00b7ters", "weis\u00b7se", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht sonder Anmuht, mit Bedacht,", "tokens": ["Nicht", "son\u00b7der", "An\u00b7muht", ",", "mit", "Be\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "KON", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Schnee-Gest\u00f6ber, angesehn.", "tokens": ["Ein", "Schnee\u00b7Ge\u00b7st\u00f6\u00b7ber", ",", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und da\u00df ichs nicht vergessen m\u00f6gte,", "tokens": ["Und", "da\u00df", "ichs", "nicht", "ver\u00b7ges\u00b7sen", "m\u00f6g\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auch damit andern es auch ein Vergn\u00fcgen br\u00e4chte,", "tokens": ["Auch", "da\u00b7mit", "an\u00b7dern", "es", "auch", "ein", "Ver\u00b7gn\u00fc\u00b7gen", "br\u00e4ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie folget, zu Papier gebracht:", "tokens": ["Wie", "fol\u00b7get", ",", "zu", "Pa\u00b7pier", "ge\u00b7bracht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Es cirkelten die Wirbel-Winde", "tokens": ["Es", "cir\u00b7kel\u00b7ten", "die", "Wir\u00b7bel\u00b7Win\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Schnee, wie einen weissen Rauch,", "tokens": ["Den", "Schnee", ",", "wie", "ei\u00b7nen", "weis\u00b7sen", "Rauch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie rissen, recht als einen Schmauch,", "tokens": ["Sie", "ris\u00b7sen", ",", "recht", "als", "ei\u00b7nen", "Schmauch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der L\u00fcfte Schaum so heftig, so geschwinde,", "tokens": ["Der", "L\u00fcf\u00b7te", "Schaum", "so", "hef\u00b7tig", ",", "so", "ge\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADJD", "$,", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auf eine sonst nicht leicht gesehne Weise,", "tokens": ["Auf", "ei\u00b7ne", "sonst", "nicht", "leicht", "ge\u00b7seh\u00b7ne", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PTKNEG", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In langen Strichen bald, und bald im Kreise,", "tokens": ["In", "lan\u00b7gen", "Stri\u00b7chen", "bald", ",", "und", "bald", "im", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,", "KON", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Von allen Orten her, nach allen Orten hin,", "tokens": ["Von", "al\u00b7len", "Or\u00b7ten", "her", ",", "nach", "al\u00b7len", "Or\u00b7ten", "hin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$,", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Von oben, unterwerts, von unten, \u00fcber sich.", "tokens": ["Von", "o\u00b7ben", ",", "un\u00b7ter\u00b7werts", ",", "von", "un\u00b7ten", ",", "\u00fc\u00b7ber", "sich", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "ADV", "$,", "APPR", "ADV", "$,", "APPR", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hier flo\u00df ein weisser Strohm, dort scho\u00df ein strenger Strich,", "tokens": ["Hier", "flo\u00df", "ein", "weis\u00b7ser", "Strohm", ",", "dort", "scho\u00df", "ein", "stren\u00b7ger", "Strich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch einen andern hin.", "tokens": ["Durch", "ei\u00b7nen", "an\u00b7dern", "hin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Was in dem Augenblick den Gegner pre\u00dfte, wich", "tokens": ["Was", "in", "dem", "Au\u00b7gen\u00b7blick", "den", "Geg\u00b7ner", "pre\u00df\u00b7te", ",", "wich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Jm Augenblick zur\u00fcck, von ihm gedrengt. Es schien", "tokens": ["Jm", "Au\u00b7gen\u00b7blick", "zu\u00b7r\u00fcck", ",", "von", "ihm", "ge\u00b7drengt", ".", "Es", "schien"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "APPR", "PPER", "VVPP", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sich alles in der Luft zu jagen und zu fliehn.", "tokens": ["Sich", "al\u00b7les", "in", "der", "Luft", "zu", "ja\u00b7gen", "und", "zu", "fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIS", "APPR", "ART", "NN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Eh\u2019 jedes St\u00e4ubchen Schnee den Grund,", "tokens": ["Eh'", "je\u00b7des", "St\u00e4ub\u00b7chen", "Schnee", "den", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Worauf es doch nicht ruhen kunnt,", "tokens": ["Wo\u00b7rauf", "es", "doch", "nicht", "ru\u00b7hen", "kunnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "PTKNEG", "VVINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wie sehr es ihn gesucht, ber\u00fchret;", "tokens": ["Wie", "sehr", "es", "ihn", "ge\u00b7sucht", ",", "be\u00b7r\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PPER", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "War es viel hundertmahl vorher empor gef\u00fchret,", "tokens": ["War", "es", "viel", "hun\u00b7dert\u00b7mahl", "vor\u00b7her", "em\u00b7por", "ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Gesenkt, erh\u00f6ht, gest\u00fcrzt, und in die H\u00f6h\u2019 gerissen,", "tokens": ["Ge\u00b7senkt", ",", "er\u00b7h\u00f6ht", ",", "ge\u00b7st\u00fcrzt", ",", "und", "in", "die", "H\u00f6h'", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP", "$,", "KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und hatte tausendfach sich drehen lassen m\u00fcssen.", "tokens": ["Und", "hat\u00b7te", "tau\u00b7send\u00b7fach", "sich", "dre\u00b7hen", "las\u00b7sen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVFIN", "PRF", "VVINF", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zuweilen st\u00fcrzt und fiel ein Meer von Schnee so dicht,", "tokens": ["Zu\u00b7wei\u00b7len", "st\u00fcrzt", "und", "fiel", "ein", "Meer", "von", "Schnee", "so", "dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So dick von oben ab, es schien fast dem Gesicht", "tokens": ["So", "dick", "von", "o\u00b7ben", "ab", ",", "es", "schien", "fast", "dem", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ADV", "PTKVZ", "$,", "PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Wolken-Bruch von Schnee, es schien die ganze Luft", "tokens": ["Ein", "Wol\u00b7ken\u00b7Bruch", "von", "Schnee", ",", "es", "schien", "die", "gan\u00b7ze", "Luft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein ungetrennter Dampf, ein weisser Nebel-Duft.", "tokens": ["Ein", "un\u00b7ge\u00b7trenn\u00b7ter", "Dampf", ",", "ein", "weis\u00b7ser", "Ne\u00b7bel\u00b7Duft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So heftig war das heftige Bewegen:", "tokens": ["So", "hef\u00b7tig", "war", "das", "hef\u00b7ti\u00b7ge", "Be\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "F\u00fcr grosser Schnelligkeit schien sich fast nichts zu regen,", "tokens": ["F\u00fcr", "gros\u00b7ser", "Schnel\u00b7lig\u00b7keit", "schien", "sich", "fast", "nichts", "zu", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PRF", "ADV", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Bis hie und da von Sturm getroffne Theile,", "tokens": ["Bis", "hie", "und", "da", "von", "Sturm", "ge\u00b7troff\u00b7ne", "Thei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "KON", "ADV", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "In noch vermehrter Eile,", "tokens": ["In", "noch", "ver\u00b7mehr\u00b7ter", "Ei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "In sichtbarn Linien noch heftiger gedrungen,", "tokens": ["In", "sicht\u00b7barn", "Li\u00b7ni\u00b7en", "noch", "hef\u00b7ti\u00b7ger", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit gr\u00f6\u00dfrer Wut sich durch die andern schwungen,", "tokens": ["Mit", "gr\u00f6\u00df\u00b7rer", "Wut", "sich", "durch", "die", "an\u00b7dern", "schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und da sie sich bald hie, bald dorthin neigten,", "tokens": ["Und", "da", "sie", "sich", "bald", "hie", ",", "bald", "dor\u00b7thin", "neig\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "ADV", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die heftige Bewegung deutlich zeigten.", "tokens": ["Die", "hef\u00b7ti\u00b7ge", "Be\u00b7we\u00b7gung", "deut\u00b7lich", "zeig\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wer dieses, dacht\u2019 ich, so bequehm,", "tokens": ["Wer", "die\u00b7ses", ",", "dacht'", "ich", ",", "so", "be\u00b7quehm", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PDAT", "$,", "VVFIN", "PPER", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ich, aus einem Zimmer sieht,", "tokens": ["Als", "ich", ",", "aus", "ei\u00b7nem", "Zim\u00b7mer", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem ist die\u00df Schauspiel angenehm.", "tokens": ["Dem", "ist", "die\u00df", "Schau\u00b7spiel", "an\u00b7ge\u00b7nehm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PDS", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich dankt\u2019 auch, mit erkenntlichem Gem\u00fcht,", "tokens": ["Ich", "dankt'", "auch", ",", "mit", "er\u00b7kennt\u00b7li\u00b7chem", "Ge\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wie billig, GOtt daf\u00fcr. Doch dacht\u2019 ich auch dabey:", "tokens": ["Wie", "bil\u00b7lig", ",", "Gott", "da\u00b7f\u00fcr", ".", "Doch", "dacht'", "ich", "auch", "da\u00b7bey", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "NN", "PAV", "$.", "KON", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie hart die Witterung den Reisenden wohl sey!", "tokens": ["Wie", "hart", "die", "Wit\u00b7te\u00b7rung", "den", "Rei\u00b7sen\u00b7den", "wohl", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "ART", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da, ausser dem, was sie von scharfer Winde Schneiden", "tokens": ["Da", ",", "aus\u00b7ser", "dem", ",", "was", "sie", "von", "schar\u00b7fer", "Win\u00b7de", "Schnei\u00b7den"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "APPR", "ART", "$,", "PRELS", "PPER", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "An ihrer Haut und am Gesicht erleiden,", "tokens": ["An", "ih\u00b7rer", "Haut", "und", "am", "Ge\u00b7sicht", "er\u00b7lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Vom aufgeth\u00fcrmten Schnee, im Gehn, so Pfad als Steg,", "tokens": ["Vom", "auf\u00b7ge\u00b7th\u00fcrm\u00b7ten", "Schnee", ",", "im", "Gehn", ",", "so", "Pfad", "als", "Steg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "ADV", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie auch zum Fahren Bahn und Weg,", "tokens": ["Wie", "auch", "zum", "Fah\u00b7ren", "Bahn", "und", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPRART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ver\u00e4ndert, ganz bedeckt,", "tokens": ["Ver\u00b7\u00e4n\u00b7dert", ",", "ganz", "be\u00b7deckt", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Unsichtbar, unbekannt, versteckt,", "tokens": ["Un\u00b7sicht\u00b7bar", ",", "un\u00b7be\u00b7kannt", ",", "ver\u00b7steckt", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und gleichsam recht verschlungen wird.", "tokens": ["Und", "gleich\u00b7sam", "recht", "ver\u00b7schlun\u00b7gen", "wird", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Fast, was man sieht, versinkt in eine helle Nacht,", "tokens": ["Fast", ",", "was", "man", "sieht", ",", "ver\u00b7sinkt", "in", "ei\u00b7ne", "hel\u00b7le", "Nacht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "PIS", "VVFIN", "$,", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So da\u00df, wer sonst des Wegs ganz kundig, leicht verirrt,", "tokens": ["So", "da\u00df", ",", "wer", "sonst", "des", "Wegs", "ganz", "kun\u00b7dig", ",", "leicht", "ver\u00b7irrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "KOUS", "$,", "PWS", "ADV", "ART", "NN", "ADV", "ADJD", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und oft nach langer Zeit erst wird zurecht gebracht.", "tokens": ["Und", "oft", "nach", "lan\u00b7ger", "Zeit", "erst", "wird", "zu\u00b7recht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Weil ich f\u00fcr selbe nun nichts, als nur w\u00fcnschen kann;", "tokens": ["Weil", "ich", "f\u00fcr", "sel\u00b7be", "nun", "nichts", ",", "als", "nur", "w\u00fcn\u00b7schen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADV", "PIS", "$,", "KOUS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So w\u00fcnsch ich, da\u00df doch jedermann,", "tokens": ["So", "w\u00fcnsch", "ich", ",", "da\u00df", "doch", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Den die\u00df betrifft, sich bald zurechte finde,", "tokens": ["Den", "die\u00df", "be\u00b7tr\u00b7ifft", ",", "sich", "bald", "zu\u00b7rech\u00b7te", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "VVFIN", "$,", "PRF", "ADV", "VVFIN", "VVFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und, wenn er von der Unbequehmlichkeit,", "tokens": ["Und", ",", "wenn", "er", "von", "der", "Un\u00b7be\u00b7quehm\u00b7lich\u00b7keit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und von Gefahr befreit,", "tokens": ["Und", "von", "Ge\u00b7fahr", "be\u00b7freit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Jhm das Erinnern nicht so bald verschwinde,", "tokens": ["Jhm", "das", "E\u00b7rin\u00b7nern", "nicht", "so", "bald", "ver\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PTKNEG", "ADV", "ADV", "ADJA", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Vielmehr, da\u00df er sodann daran gedenke,", "tokens": ["Viel\u00b7mehr", ",", "da\u00df", "er", "so\u00b7dann", "da\u00b7ran", "ge\u00b7den\u00b7ke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und, durch Erkenntlichkeit ger\u00fchrt,", "tokens": ["Und", ",", "durch", "Er\u00b7kennt\u00b7lich\u00b7keit", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Er Dem, Der ihn aus der Gefahr gef\u00fchrt,", "tokens": ["Er", "Dem", ",", "Der", "ihn", "aus", "der", "Ge\u00b7fahr", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "$,", "ART", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Nach \u00fcberstandner Plag\u2019, ein frohes Dank-Lied schenke!", "tokens": ["Nach", "\u00fc\u00b7bers\u00b7tand\u00b7ner", "Plag'", ",", "ein", "fro\u00b7hes", "Dank\u00b7Lied", "schen\u00b7ke", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}}}}}