{"textgrid.poem.26691": {"metadata": {"author": {"name": "Schiller, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: In Juda \u2013 schreibt die Chronika \u2013", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In Juda \u2013 schreibt die Chronika \u2013", "tokens": ["In", "Ju\u00b7da", "\u2013", "schreibt", "die", "Chro\u00b7ni\u00b7ka", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$(", "VVFIN", "ART", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War olim schon ein K\u00f6nig,", "tokens": ["War", "o\u00b7lim", "schon", "ein", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "ART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Dem war von Dan bis Berseba", "tokens": ["Dem", "war", "von", "Dan", "bis", "Ber\u00b7se\u00b7ba"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR", "ADV", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bald alles untert\u00e4nig.", "tokens": ["Bald", "al\u00b7les", "un\u00b7ter\u00b7t\u00e4\u00b7nig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und war dabei ein wackrer F\u00fcrst,", "tokens": ["Und", "war", "da\u00b7bei", "ein", "wack\u00b7rer", "F\u00fcrst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Desgleichen selten finden wirst.", "tokens": ["Des\u00b7glei\u00b7chen", "sel\u00b7ten", "fin\u00b7den", "wirst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der war nun k\u00fcrzlich, wie bekannt,", "tokens": ["Der", "war", "nun", "k\u00fcrz\u00b7lich", ",", "wie", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Freien heimgekommen", "tokens": ["Vom", "Frei\u00b7en", "heim\u00b7ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und hatte vom Chald\u00e4erland", "tokens": ["Und", "hat\u00b7te", "vom", "Chal\u00b7d\u00e4\u00b7er\u00b7land"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPRART", "NN"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Weibchen mitgenommen.", "tokens": ["Ein", "Weib\u00b7chen", "mit\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Im Herzen Himmel \u2013 und im Blick;", "tokens": ["Im", "Her\u00b7zen", "Him\u00b7mel", "\u2013", "und", "im", "Blick", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "$(", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich k\u00fc\u00dfte sie den Augenblick.", "tokens": ["Ich", "k\u00fc\u00df\u00b7te", "sie", "den", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Trauung war schon angestellt,", "tokens": ["Die", "Trau\u00b7ung", "war", "schon", "an\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Hochzeitkleider fertig,", "tokens": ["Die", "Hoch\u00b7zeit\u00b7klei\u00b7der", "fer\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Br\u00e4utigam, frisch wie ein Held,", "tokens": ["Der", "Br\u00e4u\u00b7ti\u00b7gam", ",", "frisch", "wie", "ein", "Held", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Wonnetags gew\u00e4rtig \u2013", "tokens": ["Des", "Won\u00b7ne\u00b7tags", "ge\u00b7w\u00e4r\u00b7tig", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Als pl\u00f6tzlich \u2013 zitternd schreibts mein Kiel \u2013", "tokens": ["Als", "pl\u00f6tz\u00b7lich", "\u2013", "zit\u00b7ternd", "schreibts", "mein", "Kiel", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$(", "ADJD", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Fieber diesen Herrn befiel.", "tokens": ["Ein", "Fie\u00b7ber", "die\u00b7sen", "Herrn", "be\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein gro\u00dfer Herre, wie man wei\u00dft,", "tokens": ["Ein", "gro\u00b7\u00dfer", "Her\u00b7re", ",", "wie", "man", "wei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist nicht wie unsereiner \u2013", "tokens": ["Ist", "nicht", "wie", "un\u00b7ser\u00b7ei\u00b7ner", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "KOKOM", "PPOSAT", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Drob k\u00fcmmert sich wohl keiner \u2013", "tokens": ["Drob", "k\u00fcm\u00b7mert", "sich", "wohl", "kei\u00b7ner", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "PIS", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein Schnuppen, den ein Gro\u00dfer klagt,", "tokens": ["Ein", "Schnup\u00b7pen", ",", "den", "ein", "Gro\u00b7\u00dfer", "klagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird in der Welt herumgesagt.", "tokens": ["Wird", "in", "der", "Welt", "her\u00b7um\u00b7ge\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Drum nimmt Frau Fama, nimmerfaul,", "tokens": ["Drum", "nimmt", "Frau", "Fa\u00b7ma", ",", "nim\u00b7mer\u00b7faul", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "NE", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Hifthorn von dem Nacken", "tokens": ["Das", "Hif\u00b7thorn", "von", "dem", "Na\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "(man kennt ja schon ihr gro\u00dfes Maul", "tokens": ["(", "man", "kennt", "ja", "schon", "ihr", "gro\u00b7\u00dfes", "Maul"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PIS", "VVFIN", "ADV", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihre dicken Backen):", "tokens": ["Und", "ih\u00b7re", "di\u00b7cken", "Ba\u00b7cken", ")", ":"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbf\u00fcrst Josaphat liegt todkrank da\u00ab,", "tokens": ["\u00bb", "f\u00fcrst", "Jo\u00b7sa\u00b7phat", "liegt", "tod\u00b7krank", "da", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "NE", "VVFIN", "ADJD", "ADV", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Posaunt sie durch ganz Asia.", "tokens": ["Po\u00b7saunt", "sie", "durch", "ganz", "A\u00b7sia", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADV", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Sogleich vernahm den Trauerton", "tokens": ["Sog\u00b7leich", "ver\u00b7nahm", "den", "Trau\u00b7er\u00b7ton"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcrst Sanherib, sein Vetter, \u2013", "tokens": ["F\u00fcrst", "San\u00b7he\u00b7rib", ",", "sein", "Vet\u00b7ter", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "$,", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zu Assur hat er seinen Thron", "tokens": ["Zu", "As\u00b7sur", "hat", "er", "sei\u00b7nen", "Thron"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ehret fremde G\u00f6tter.", "tokens": ["Und", "eh\u00b7ret", "frem\u00b7de", "G\u00f6t\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Balle L\u00fcge kommt so recht", "tokens": ["Die", "Bal\u00b7le", "L\u00fc\u00b7ge", "kommt", "so", "recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zustatten meinem G\u00f6tzenknecht.", "tokens": ["Zu\u00b7stat\u00b7ten", "mei\u00b7nem", "G\u00f6t\u00b7zen\u00b7knecht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbda fischt sich was \u2013 Hol mich der Dachs!\u00ab \u2013", "tokens": ["\u00bb", "da", "fischt", "sich", "was", "\u2013", "Hol", "mich", "der", "Dachs", "!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PRF", "PWS", "$(", "NN", "PPER", "ART", "NN", "$.", "$(", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Und hui! spitzt er die Ohren.", "tokens": ["Und", "hui", "!", "spitzt", "er", "die", "Oh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbstirbt Josaphat, so zieh ich stracks", "tokens": ["\u00bb", "stirbt", "Jo\u00b7sa\u00b7phat", ",", "so", "zieh", "ich", "stracks"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "NE", "$,", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hinein zu Hebrons Toren.", "tokens": ["Hin\u00b7ein", "zu", "Heb\u00b7rons", "To\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Er braucht Arznei \u2013 er treibts nicht lang!", "tokens": ["Er", "braucht", "Arz\u00b7nei", "\u2013", "er", "treibts", "nicht", "lang", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Juda ist ein fetter Fang.\u00ab", "tokens": ["Und", "Ju\u00b7da", "ist", "ein", "fet\u00b7ter", "Fang", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VAFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Gleich l\u00e4uft die Ordre aus dem Schlo\u00df", "tokens": ["Gleich", "l\u00e4uft", "die", "Ord\u00b7re", "aus", "dem", "Schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Stadt und Wachparade,", "tokens": ["Durch", "Stadt", "und", "Wach\u00b7pa\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Junggesellen faulen Tro\u00df", "tokens": ["Der", "Jung\u00b7ge\u00b7sel\u00b7len", "fau\u00b7len", "Tro\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu werben ohne Gnade.", "tokens": ["Zu", "wer\u00b7ben", "oh\u00b7ne", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Schon springen Bomben aus dem Gu\u00df", "tokens": ["Schon", "sprin\u00b7gen", "Bom\u00b7ben", "aus", "dem", "Gu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und freun sich auf den n\u00e4chsten Schu\u00df.", "tokens": ["Und", "freun", "sich", "auf", "den", "n\u00e4chs\u00b7ten", "Schu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Die Wache vor dem Tor bekommt", "tokens": ["Die", "Wa\u00b7che", "vor", "dem", "Tor", "be\u00b7kommt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gemessene Befehle,", "tokens": ["Ge\u00b7mes\u00b7se\u00b7ne", "Be\u00b7feh\u00b7le", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Da\u00df undurchsucht \u2013 unangebrummt", "tokens": ["Da\u00df", "un\u00b7durch\u00b7sucht", "\u2013", "un\u00b7an\u00b7ge\u00b7brummt"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "NN", "$(", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entwische keine Seele.", "tokens": ["Ent\u00b7wi\u00b7sche", "kei\u00b7ne", "See\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Brieftaschen und Patent heraus \u2013", "tokens": ["Brief\u00b7ta\u00b7schen", "und", "Pa\u00b7tent", "he\u00b7raus", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sonst \u2013 Marsch, ihr Herrn, ins Narrenhaus.", "tokens": ["Sonst", "\u2013", "Marsch", ",", "ihr", "Herrn", ",", "ins", "Nar\u00b7ren\u00b7haus", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$(", "NE", "$,", "PPOSAT", "NN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00bbwoher, mein Freund?\u00ab br\u00fcllt auf und ab", "tokens": ["\u00bb", "wo\u00b7her", ",", "mein", "Freund", "?", "\u00ab", "br\u00fcllt", "auf", "und", "ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "$,", "PPOSAT", "NN", "$.", "$(", "VVFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Schildwach an die Fremde.", "tokens": ["Die", "Schild\u00b7wach", "an", "die", "Frem\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwohin die Reis? Wo steigt Ihr ab?", "tokens": ["\u00bb", "wo\u00b7hin", "die", "Reis", "?", "Wo", "steigt", "Ihr", "ab", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ART", "NN", "$.", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was f\u00fchrt Ihr unterm Hemde?", "tokens": ["Was", "f\u00fchrt", "Ihr", "un\u00b7term", "Hem\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Torschreiber raus! \u2013 Der Herr bleibt stehn!", "tokens": ["Tor\u00b7schrei\u00b7ber", "raus", "!", "\u2013", "Der", "Herr", "bleibt", "stehn", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "$(", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Man wird ihn hei\u00dfen weitergehn.\u00ab", "tokens": ["Man", "wird", "ihn", "hei\u00b7\u00dfen", "wei\u00b7ter\u00b7gehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Da war nun mancher ", "tokens": ["Da", "war", "nun", "man\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PIAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Dem Korporal verd\u00e4chtig,", "tokens": ["Dem", "Kor\u00b7po\u00b7ral", "ver\u00b7d\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Fragen gehn zur Folter schier,", "tokens": ["Die", "Fra\u00b7gen", "gehn", "zur", "Fol\u00b7ter", "schier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gott aber ist allm\u00e4chtig:", "tokens": ["Gott", "a\u00b7ber", "ist", "all\u00b7m\u00e4ch\u00b7tig", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Man visitiert von Pack zu Pack,", "tokens": ["Man", "vi\u00b7si\u00b7tiert", "von", "Pack", "zu", "Pack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch zeigt sich nichts \u2013 als Schnupftobak.", "tokens": ["Doch", "zeigt", "sich", "nichts", "\u2013", "als", "Schnupf\u00b7to\u00b7bak", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PIS", "$(", "KOUS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Indessen schickt der Werber Flei\u00df", "tokens": ["In\u00b7des\u00b7sen", "schickt", "der", "Wer\u00b7ber", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rekruten, Sand am Meere,", "tokens": ["Rek\u00b7ru\u00b7ten", ",", "Sand", "am", "Mee\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie stehen blau und rot und wei\u00df", "tokens": ["Sie", "ste\u00b7hen", "blau", "und", "rot", "und", "wei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ordnen sich in Heere.", "tokens": ["Und", "ord\u00b7nen", "sich", "in", "Hee\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das Kriegsger\u00e4te \u2013 glaubt mir keck \u2013", "tokens": ["Das", "Kriegs\u00b7ge\u00b7r\u00e4\u00b7te", "\u2013", "glaubt", "mir", "keck", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fra\u00df ", "tokens": ["Fra\u00df"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.13": {"line.1": {"text": "F\u00fcrst Sanherib erz\u00e4hlte schon", "tokens": ["F\u00fcrst", "San\u00b7he\u00b7rib", "er\u00b7z\u00e4hl\u00b7te", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NE", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Damen seine Siege,", "tokens": ["Den", "Da\u00b7men", "sei\u00b7ne", "Sie\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Aufs Wohl des neuen Landes flohn", "tokens": ["Aufs", "Wohl", "des", "neu\u00b7en", "Lan\u00b7des", "flohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Tisch zu Tisch die Kr\u00fcge,", "tokens": ["Von", "Tisch", "zu", "Tisch", "die", "Kr\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Schon m\u00f6belt' man das neue Schlo\u00df \u2013", "tokens": ["Schon", "m\u00f6\u00b7belt'", "man", "das", "neu\u00b7e", "Schlo\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Je gl\u00e4tter der Burgunder flo\u00df.", "tokens": ["Je", "gl\u00e4t\u00b7ter", "der", "Bur\u00b7gun\u00b7der", "flo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie pr\u00e4chtig K\u00f6nig Sanherib", "tokens": ["Wie", "pr\u00e4ch\u00b7tig", "K\u00f6\u00b7nig", "San\u00b7he\u00b7rib"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im reichen Galakleide", "tokens": ["Im", "rei\u00b7chen", "Ga\u00b7la\u00b7klei\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Herum den stolzen Schimmel trieb", "tokens": ["He\u00b7rum", "den", "stol\u00b7zen", "Schim\u00b7mel", "trieb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und durch Jud\u00e4a reite;", "tokens": ["Und", "durch", "Ju\u00b7d\u00e4a", "rei\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Die Damen in Karossen nach,", "tokens": ["Die", "Da\u00b7men", "in", "Ka\u00b7ros\u00b7sen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df bald schon Rad und Deichsel brach.", "tokens": ["Da\u00df", "bald", "schon", "Rad", "und", "Deich\u00b7sel", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Wie stolz von seinem Thron herab", "tokens": ["Wie", "stolz", "von", "sei\u00b7nem", "Thron", "her\u00b7ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er Judas Schriftgelehrten", "tokens": ["Er", "Ju\u00b7das", "Schrift\u00b7ge\u00b7lehr\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PPER", "NE", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Erlaubnis zu dem Handku\u00df gab", "tokens": ["Er\u00b7laub\u00b7nis", "zu", "dem", "Hand\u00b7ku\u00df", "gab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sie ihm Treue schw\u00f6rten \u2013", "tokens": ["Und", "sie", "ihm", "Treu\u00b7e", "schw\u00f6r\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPER", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und alles Volk im Staube tief", "tokens": ["Und", "al\u00b7les", "Volk", "im", "Stau\u00b7be", "tief"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPRART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hosianna dem Gesalbten! rief.", "tokens": ["Ho\u00b7si\u00b7an\u00b7na", "dem", "Ge\u00b7salb\u00b7ten", "!", "rief", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ART", "NN", "$.", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.16": {"line.1": {"text": "Doch w\u00e4hrend da\u00df der Vetter schon", "tokens": ["Doch", "w\u00e4h\u00b7rend", "da\u00df", "der", "Vet\u00b7ter", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "KOUS", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach deiner Krone schielte,", "tokens": ["Nach", "dei\u00b7ner", "Kro\u00b7ne", "schiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und auf dem ", "tokens": ["Und", "auf", "dem"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Schon Davids Harfe spielte,", "tokens": ["Schon", "Da\u00b7vids", "Har\u00b7fe", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Lagst du- \u2013 o F\u00fcrst \u2013 beweint vom Land,", "tokens": ["Lagst", "du", "\u2013", "o", "F\u00fcrst", "\u2013", "be\u00b7weint", "vom", "Land", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "$(", "FM", "NN", "$(", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch unversehrt \u2013 in Gottes Hand.", "tokens": ["Noch", "un\u00b7ver\u00b7sehrt", "\u2013", "in", "Got\u00b7tes", "Hand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Gott stand auf H\u00f6hen Sinais", "tokens": ["Gott", "stand", "auf", "H\u00f6\u00b7hen", "Si\u00b7nais"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "NN", "NE"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Und schaute nach der Erden,", "tokens": ["Und", "schau\u00b7te", "nach", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sahe schon ein Paradies", "tokens": ["Und", "sa\u00b7he", "schon", "ein", "Pa\u00b7ra\u00b7dies"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch deinen Zepter werden,", "tokens": ["Durch", "dei\u00b7nen", "Zep\u00b7ter", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und sahe mit erhabner Ruh", "tokens": ["Und", "sa\u00b7he", "mit", "er\u00b7hab\u00b7ner", "Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Unfug deines Vetters zu.", "tokens": ["Dem", "Un\u00b7fug", "dei\u00b7nes", "Vet\u00b7ters", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Schnell schickt er einen Cherub fort", "tokens": ["Schnell", "schickt", "er", "ei\u00b7nen", "Che\u00b7rub", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NE", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und spricht mit sanftem L\u00e4cheln:", "tokens": ["Und", "spricht", "mit", "sanf\u00b7tem", "L\u00e4\u00b7cheln", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbgeh, Raphael \u2013 dem F\u00fcrsten dort", "tokens": ["\u00bb", "geh", ",", "Ra\u00b7phael", "\u2013", "dem", "F\u00fcrs\u00b7ten", "dort"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "NE", "$(", "ART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Erfrischung zuzuf\u00e4cheln.", "tokens": ["Er\u00b7fri\u00b7schung", "zu\u00b7zu\u00b7f\u00e4\u00b7cheln", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Er ist mein Sohn \u2013 mein treuer Knecht!", "tokens": ["Er", "ist", "mein", "Sohn", "\u2013", "mein", "treu\u00b7er", "Knecht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$(", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er lebe! \u2013 denn ich bin gerecht.\u00ab", "tokens": ["Er", "le\u00b7be", "!", "\u2013", "denn", "ich", "bin", "ge\u00b7recht", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "KON", "PPER", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Dem Willen Gottes untertan,", "tokens": ["Dem", "Wil\u00b7len", "Got\u00b7tes", "un\u00b7ter\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Steigt Raphael herunter,", "tokens": ["Steigt", "Ra\u00b7phael", "her\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nimmt eines Arztes Bildung an", "tokens": ["Nimmt", "ei\u00b7nes", "Arz\u00b7tes", "Bil\u00b7dung", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und heilt dich durch ein Wunder.", "tokens": ["Und", "heilt", "dich", "durch", "ein", "Wun\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dein F\u00fcrst ersteht \u2013 jauchz, Vaterland!", "tokens": ["Dein", "F\u00fcrst", "er\u00b7steht", "\u2013", "jauchz", ",", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "PTKANT", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gerettet durch des Himmels Hand.", "tokens": ["Ge\u00b7ret\u00b7tet", "durch", "des", "Him\u00b7mels", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Die Post schleicht nach Assyrien,", "tokens": ["Die", "Post", "schleicht", "nach", "As\u00b7sy\u00b7ri\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo Sanherib regieret", "tokens": ["Wo", "San\u00b7he\u00b7rib", "re\u00b7gie\u00b7ret"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NE", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und eben seine K\u00f6nigin", "tokens": ["Und", "e\u00b7ben", "sei\u00b7ne", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Schlitten heimgef\u00fchret. \u2013", "tokens": ["Vom", "Schlit\u00b7ten", "heim\u00b7ge\u00b7f\u00fch\u00b7ret", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbihr Durchlaucht! Ein Kurier!\u00ab \u2013 \u00bbHerein!", "tokens": ["\u00bb", "ihr", "Durch\u00b7laucht", "!", "Ein", "Ku\u00b7rier", "!", "\u00ab", "\u2013", "\u00bb", "Her\u00b7ein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$.", "ART", "NN", "$.", "$(", "$(", "$(", "PTKVZ", "$."], "meter": "-++-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Es werden Trauerbriefe sein.\u00ab", "tokens": ["Es", "wer\u00b7den", "Trau\u00b7er\u00b7brie\u00b7fe", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Schnell \u00f6ffnet er den Brief und liest,", "tokens": ["Schnell", "\u00f6ff\u00b7net", "er", "den", "Brief", "und", "liest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Liest \u2013 ach! der Posten tr\u00fcbste \u2013", "tokens": ["Liest", "\u2013", "ach", "!", "der", "Pos\u00b7ten", "tr\u00fcbs\u00b7te", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ITJ", "$.", "ART", "NN", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df Josaphat am Leben ist \u2013", "tokens": ["Da\u00df", "Jo\u00b7sa\u00b7phat", "am", "Le\u00b7ben", "ist", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPRART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und flucht an seine Liebste:", "tokens": ["Und", "flucht", "an", "sei\u00b7ne", "Liebs\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbder Krieg ist aus! \u2013 Pest \u00fcber dich!", "tokens": ["\u00bb", "der", "Krieg", "ist", "aus", "!", "\u2013", "Pest", "\u00fc\u00b7ber", "dich", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PTKVZ", "$.", "$(", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zweitausend Taler schmerzen mich!!\u00ab", "tokens": ["Zweit\u00b7au\u00b7send", "Ta\u00b7ler", "schmer\u00b7zen", "mich", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}