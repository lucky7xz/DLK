{"textgrid.poem.48358": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Sir Patrick Spens", "genre": "verse", "period": "N.A.", "pub_year": 1852, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der K\u00f6nig sitzt in Dumferlin-Schlo\u00df,", "tokens": ["Der", "K\u00f6\u00b7nig", "sitzt", "in", "Dum\u00b7fer\u00b7lin\u00b7Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Er trinkt blutroten Wein:", "tokens": ["Er", "trinkt", "blut\u00b7ro\u00b7ten", "Wein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwer ist mein bester Segler?", "tokens": ["\u00bb", "wer", "ist", "mein", "bes\u00b7ter", "Seg\u00b7ler", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Er mu\u00df in See hinein!\u00ab", "tokens": ["Er", "mu\u00df", "in", "See", "hin\u00b7ein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Sprach da ein schottischer Ritter", "tokens": ["Sprach", "da", "ein", "schot\u00b7ti\u00b7scher", "Rit\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "(er stand an des K\u00f6nigs Seit'):", "tokens": ["(", "er", "stand", "an", "des", "K\u00f6\u00b7nigs", "Seit'", ")", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$(", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbder beste, das ist Sir Patrick", "tokens": ["\u00bb", "der", "bes\u00b7te", ",", "das", "ist", "Sir", "Pat\u00b7rick"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "$,", "PDS", "VAFIN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Lande weit und breit.\u00ab", "tokens": ["Im", "Lan\u00b7de", "weit", "und", "breit", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Der K\u00f6nig schrieb einen offenen Brief,", "tokens": ["Der", "K\u00f6\u00b7nig", "schrieb", "ei\u00b7nen", "of\u00b7fe\u00b7nen", "Brief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+----+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Einen Brief mit eigner Hand \u2013", "tokens": ["Ei\u00b7nen", "Brief", "mit", "eig\u00b7ner", "Hand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sir Patrick schritt am Meere", "tokens": ["Sir", "Pat\u00b7rick", "schritt", "am", "Mee\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "APPRART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Hin \u00fcber den knirschenden Sand.", "tokens": ["Hin", "\u00fc\u00b7ber", "den", "knir\u00b7schen\u00b7den", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Er sah auf die erste Zeile", "tokens": ["Er", "sah", "auf", "die", "ers\u00b7te", "Zei\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und lachte, als er sie sah,", "tokens": ["Und", "lach\u00b7te", ",", "als", "er", "sie", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Er las die zweite Zeile,", "tokens": ["Er", "las", "die", "zwei\u00b7te", "Zei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht weiter las er da.", "tokens": ["Nicht", "wei\u00b7ter", "las", "er", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Sein Auge stund in Tr\u00e4nen:", "tokens": ["Sein", "Au\u00b7ge", "stund", "in", "Tr\u00e4\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbwem tat ich also weh,", "tokens": ["\u00bb", "wem", "tat", "ich", "al\u00b7so", "weh", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu schicken in dieser Sturmzeit", "tokens": ["Zu", "schi\u00b7cken", "in", "die\u00b7ser", "Sturm\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "APPR", "PDAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mich \u00fcber die wei\u00dfe See?", "tokens": ["Mich", "\u00fc\u00b7ber", "die", "wei\u00b7\u00dfe", "See", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Zu Schiff nun, liebe Mannen,", "tokens": ["Zu", "Schiff", "nun", ",", "lie\u00b7be", "Man\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wir segeln vor Tagesschein!\u00ab", "tokens": ["Wir", "se\u00b7geln", "vor", "Ta\u00b7ges\u00b7schein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da sprach ein alter Matrose:", "tokens": ["Da", "sprach", "ein", "al\u00b7ter", "Mat\u00b7ro\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "\u00bbsir Patrick, das kann nicht sein.", "tokens": ["\u00bb", "sir", "Pat\u00b7rick", ",", "das", "kann", "nicht", "sein", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "NN", "$,", "PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich h\u00f6rt' in meiner Koje", "tokens": ["Ich", "h\u00f6rt'", "in", "mei\u00b7ner", "Ko\u00b7je"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Die Windsbraut, wie sie gelacht,", "tokens": ["Die", "Winds\u00b7braut", ",", "wie", "sie", "ge\u00b7lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und der neue Mond hielt den alten", "tokens": ["Und", "der", "neu\u00b7e", "Mond", "hielt", "den", "al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ART", "ADJA"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Im Arme die letzte Nacht.\u00ab", "tokens": ["Im", "Ar\u00b7me", "die", "letz\u00b7te", "Nacht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Es kam der n\u00e4chste Morgen,", "tokens": ["Es", "kam", "der", "n\u00e4chs\u00b7te", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie gingen all an Bord,", "tokens": ["Sie", "gin\u00b7gen", "all", "an", "Bord", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sir Patrick und die Seinen", "tokens": ["Sir", "Pat\u00b7rick", "und", "die", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "KON", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und mancher schottische Lord.", "tokens": ["Und", "man\u00b7cher", "schot\u00b7ti\u00b7sche", "Lord", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Im Winde flaggten die Wimpel,", "tokens": ["Im", "Win\u00b7de", "flagg\u00b7ten", "die", "Wim\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hoch tanzten Schiff und Flut-", "tokens": ["Hoch", "tanz\u00b7ten", "Schiff", "und", "Flut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ADJA", "NN", "KON", "TRUNC"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Drei Tage, da schwamm auf dem Meere", "tokens": ["Drei", "Ta\u00b7ge", ",", "da", "schwamm", "auf", "dem", "Mee\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "$,", "ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Nur noch ein beb\u00e4nderter Hut.", "tokens": ["Nur", "noch", "ein", "be\u00b7b\u00e4n\u00b7der\u00b7ter", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.10": {"line.1": {"text": "Nun sitzen viel sch\u00f6ne Frauen", "tokens": ["Nun", "sit\u00b7zen", "viel", "sch\u00f6\u00b7ne", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit ihren F\u00e4chern am Strand", "tokens": ["Mit", "ih\u00b7ren", "F\u00e4\u00b7chern", "am", "Strand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und warten auf Sir Patrick,", "tokens": ["Und", "war\u00b7ten", "auf", "Sir", "Pat\u00b7rick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und da\u00df er steig' an Land.", "tokens": ["Und", "da\u00df", "er", "steig'", "an", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Alle tragen sie K\u00e4mme mit Goldschmuck", "tokens": ["Al\u00b7le", "tra\u00b7gen", "sie", "K\u00e4m\u00b7me", "mit", "Gold\u00b7schmuck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "NN", "APPR", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und blicken hinaus aufs Meer,", "tokens": ["Und", "bli\u00b7cken", "hin\u00b7aus", "aufs", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch sie erharren keinen", "tokens": ["Doch", "sie", "er\u00b7har\u00b7ren", "kei\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sehen keinen mehr.", "tokens": ["Und", "se\u00b7hen", "kei\u00b7nen", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "F\u00fcnfzig Faden tief und tiefer,", "tokens": ["F\u00fcnf\u00b7zig", "Fa\u00b7den", "tief", "und", "tie\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da pflegen sie all der Ruh:", "tokens": ["Da", "pfle\u00b7gen", "sie", "all", "der", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sir Patrick und die Seinen", "tokens": ["Sir", "Pat\u00b7rick", "und", "die", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "KON", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und die schottischen Lords dazu.", "tokens": ["Und", "die", "schot\u00b7ti\u00b7schen", "Lords", "da\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}}}}