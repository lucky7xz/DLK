{"textgrid.poem.49123": {"metadata": {"author": {"name": "R\u00f6ling, Johann", "birth": "N.A.", "death": "N.A."}, "title": "\u00dcber den Himmel", "genre": "verse", "period": "N.A.", "pub_year": 1656, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "S\u00fcsser Himmel, heilger Heerd", "tokens": ["S\u00fcs\u00b7ser", "Him\u00b7mel", ",", "heil\u00b7ger", "Heerd"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gottes Pracht-Hau\u00df, Engel-Wohnung,", "tokens": ["Got\u00b7tes", "Pracht\u00b7Hau\u00df", ",", "En\u00b7gel\u00b7Woh\u00b7nung", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aller Frommen End-Belohnung,", "tokens": ["Al\u00b7ler", "From\u00b7men", "En\u00b7dBe\u00b7loh\u00b7nung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denk, wie mir zu Muthe werd,", "tokens": ["Denk", ",", "wie", "mir", "zu", "Mu\u00b7the", "werd", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ich deine sch\u00f6ne H\u00f6h", "tokens": ["Wenn", "ich", "dei\u00b7ne", "sch\u00f6\u00b7ne", "H\u00f6h"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aus der Erden Grufft anseh.", "tokens": ["Aus", "der", "Er\u00b7den", "Grufft", "an\u00b7seh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Deine Stern und was sonst dein,", "tokens": ["Dei\u00b7ne", "Stern", "und", "was", "sonst", "dein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PWS", "ADV", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bleiben immer frisch und munter;", "tokens": ["Blei\u00b7ben", "im\u00b7mer", "frisch", "und", "mun\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr geht auff und wieder unter,", "tokens": ["Ihr", "geht", "auff", "und", "wie\u00b7der", "un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "ADV", "APPR", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr verwechselt Nacht und Schein,", "tokens": ["Ihr", "ver\u00b7wech\u00b7selt", "Nacht", "und", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und es fehlt je Keinem ichts,", "tokens": ["Und", "es", "fehlt", "je", "Kei\u00b7nem", "ichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "PIS", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch an dem geringsten nichts.", "tokens": ["Auch", "an", "dem", "ge\u00b7rings\u00b7ten", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "PIS", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Ach, auch ich war gleich wie ihr", "tokens": ["Ach", ",", "auch", "ich", "war", "gleich", "wie", "ihr"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "PPER", "VAFIN", "ADV", "KOKOM", "PPOSAT"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Und wie eure reinen Geister,", "tokens": ["Und", "wie", "eu\u00b7re", "rei\u00b7nen", "Geis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unser hocherhabner Meister", "tokens": ["Un\u00b7ser", "ho\u00b7cher\u00b7hab\u00b7ner", "Meis\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lie\u00df euch stehn und war bey mir,", "tokens": ["Lie\u00df", "euch", "stehn", "und", "war", "bey", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "KON", "VAFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Euch hat er zum Sitz erw\u00e4hlt,", "tokens": ["Euch", "hat", "er", "zum", "Sitz", "er\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Mich mit seinem Bild beseelt.", "tokens": ["Mich", "mit", "sei\u00b7nem", "Bild", "be\u00b7seelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "So ging ich euch noch weit f\u00fcr;", "tokens": ["So", "ging", "ich", "euch", "noch", "weit", "f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "APPR", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Aber, o den schn\u00f6den Bissen,", "tokens": ["A\u00b7ber", ",", "o", "den", "schn\u00f6\u00b7den", "Bis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der uns diesen Schatz entrissen,", "tokens": ["Der", "uns", "die\u00b7sen", "Schatz", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weg ist alle meine Zier,", "tokens": ["Weg", "ist", "al\u00b7le", "mei\u00b7ne", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIS", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "F\u00fcr des H\u00f6chsten Conterfeyt", "tokens": ["F\u00fcr", "des", "H\u00f6chs\u00b7ten", "Con\u00b7ter\u00b7feyt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nahm ich an ein Feigen-Kleid.", "tokens": ["Nahm", "ich", "an", "ein", "Fei\u00b7gen\u00b7Kleid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was f\u00fcr Sorge, M\u00fch' und Pein", "tokens": ["Was", "f\u00fcr", "Sor\u00b7ge", ",", "M\u00fch'", "und", "Pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat mich gleich hiemit umgeben,", "tokens": ["Hat", "mich", "gleich", "hie\u00b7mit", "um\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Immer sterben ist mein Leben!", "tokens": ["Im\u00b7mer", "ster\u00b7ben", "ist", "mein", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Himmel, du bleibst dennoch mein,", "tokens": ["Him\u00b7mel", ",", "du", "bleibst", "den\u00b7noch", "mein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "ADV", "PPOSAT", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Wenn die Erde mich vertreibt,", "tokens": ["Wenn", "die", "Er\u00b7de", "mich", "ver\u00b7treibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Werd' ich dir doch einverleibt.", "tokens": ["Werd'", "ich", "dir", "doch", "ein\u00b7ver\u00b7leibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Dies hat mir durch theuren Kauff", "tokens": ["Dies", "hat", "mir", "durch", "theu\u00b7ren", "Kauff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Er, dein Erb-Printz, neu erworben;", "tokens": ["Er", ",", "dein", "Er\u00b7bPrintz", ",", "neu", "er\u00b7wor\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Da er ist f\u00fcr mich gestorben", "tokens": ["Da", "er", "ist", "f\u00fcr", "mich", "ge\u00b7stor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VAFIN", "APPR", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schlo\u00df er mir dich wieder auff,", "tokens": ["Schlo\u00df", "er", "mir", "dich", "wie\u00b7der", "auff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "PRF", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und da\u00df ich nicht irrte hier,", "tokens": ["Und", "da\u00df", "ich", "nicht", "irr\u00b7te", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "VVFIN", "ADV", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "Macht' er selber sich zur Th\u00fcr.", "tokens": ["Macht'", "er", "sel\u00b7ber", "sich", "zur", "Th\u00fcr."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "PPER", "ADV", "PRF", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Wie lockt dies zu dir mich ein,", "tokens": ["Wie", "lockt", "dies", "zu", "dir", "mich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PDS", "APPR", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mehr noch, wenn du scheinst zu winken,", "tokens": ["Mehr", "noch", ",", "wenn", "du", "scheinst", "zu", "win\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn was kan der Sternen Blinken", "tokens": ["Denn", "was", "kan", "der", "Ster\u00b7nen", "Blin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VMFIN", "ART", "NN", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Anders doch, als dieses seyn?", "tokens": ["An\u00b7ders", "doch", ",", "als", "die\u00b7ses", "seyn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PDAT", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und was thustu immermehr,", "tokens": ["Und", "was", "thu\u00b7stu", "im\u00b7mer\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Das mich nicht zu dir stets kehr?", "tokens": ["Das", "mich", "nicht", "zu", "dir", "stets", "kehr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PTKNEG", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Donnerst du und schreckest mich,", "tokens": ["Don\u00b7nerst", "du", "und", "schre\u00b7ckest", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was heist eh zu dir mich gehen?", "tokens": ["Was", "heist", "eh", "zu", "dir", "mich", "ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KOUS", "APPR", "PPER", "PRF", "VVINF", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Bistu unbewolkt zu sehen,", "tokens": ["Bis\u00b7tu", "un\u00b7be\u00b7wolkt", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So verlieb' ich mich in dich,", "tokens": ["So", "ver\u00b7lieb'", "ich", "mich", "in", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Regnest, thaust und schneiest du,", "tokens": ["Reg\u00b7nest", ",", "thaust", "und", "schnei\u00b7est", "du", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00e4llt dein Gut mir, sag' ich, zu.", "tokens": ["F\u00e4llt", "dein", "Gut", "mir", ",", "sag'", "ich", ",", "zu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "$,", "VVFIN", "PPER", "$,", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Also hab' ich allezeit", "tokens": ["Al\u00b7so", "hab'", "ich", "al\u00b7le\u00b7zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das mich auff zu dir mu\u00df heben,", "tokens": ["Das", "mich", "auff", "zu", "dir", "mu\u00df", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "APPR", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch noch mehr nach dem heist streben,", "tokens": ["Doch", "noch", "mehr", "nach", "dem", "heist", "stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der mir dies durch dich bereit.", "tokens": ["Der", "mir", "dies", "durch", "dich", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PDS", "APPR", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Herrlich bistu, was du bist;", "tokens": ["Herr\u00b7lich", "bis\u00b7tu", ",", "was", "du", "bist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Was ist der, durch den dies ist?", "tokens": ["Was", "ist", "der", ",", "durch", "den", "dies", "ist", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "$,", "APPR", "ART", "PDS", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Au\u00dferwehltes, seelges Zelt,", "tokens": ["Au\u00b7\u00dfer\u00b7wehl\u00b7tes", ",", "seel\u00b7ges", "Zelt", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df mich so mit dir stets sprechen", "tokens": ["La\u00df", "mich", "so", "mit", "dir", "stets", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und au\u00df mir zu dir mich brechen;", "tokens": ["Und", "au\u00df", "mir", "zu", "dir", "mich", "bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "APPR", "PPER", "PRF", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Auch wie k\u00f6stlich, da\u00df die Welt,", "tokens": ["Auch", "wie", "k\u00f6st\u00b7lich", ",", "da\u00df", "die", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADJD", "$,", "KOUS", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gibt sie nichts, als M\u00fch' und Pein,", "tokens": ["Gibt", "sie", "nichts", ",", "als", "M\u00fch'", "und", "Pein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "$,", "KOUS", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Soll sie uns nicht sch\u00e4dlich seyn.", "tokens": ["Soll", "sie", "uns", "nicht", "sch\u00e4d\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Knirsch mit steter Reu mich hier", "tokens": ["Knirsch", "mit", "ste\u00b7ter", "Reu", "mich", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "NN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und mach mich so weich und m\u00fcrbe;", "tokens": ["Und", "mach", "mich", "so", "weich", "und", "m\u00fcr\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJA", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "W\u00fcrd' ich nicht zu Asch' und st\u00fcrbe,", "tokens": ["W\u00fcrd'", "ich", "nicht", "zu", "Asch'", "und", "st\u00fcr\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "APPR", "NE", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00e4m' ich Tr\u00e4ger nicht zu dir.", "tokens": ["K\u00e4m'", "ich", "Tr\u00e4\u00b7ger", "nicht", "zu", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PTKNEG", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn wie steigt sonst auf die Erd',", "tokens": ["Denn", "wie", "steigt", "sonst", "auf", "die", "Erd'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als wenn sie in Staub verkehrt?", "tokens": ["Als", "wenn", "sie", "in", "Staub", "ver\u00b7kehrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}}}}