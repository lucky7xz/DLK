{"textgrid.poem.64772": {"metadata": {"author": {"name": "K\u00e4stner, Abraham Gotthelf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nicht schlaue F\u00fcchse, wilde Stiere,", "genre": "verse", "period": "N.A.", "pub_year": 1745, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nicht schlaue F\u00fcchse, wilde Stiere,", "tokens": ["Nicht", "schlau\u00b7e", "F\u00fcch\u00b7se", ",", "wil\u00b7de", "Stie\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Menschen allzugleiche Thiere,", "tokens": ["Nicht", "Men\u00b7schen", "all\u00b7zu\u00b7glei\u00b7che", "Thie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht M\u00e4hrchen, wie ", "tokens": ["Nicht", "M\u00e4hr\u00b7chen", ",", "wie"], "token_info": ["word", "word", "punct", "word"], "pos": ["PTKNEG", "NN", "$,", "PWAV"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sind meines Dichtens Gegenstand;", "tokens": ["Sind", "mei\u00b7nes", "Dich\u00b7tens", "Ge\u00b7gen\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Karten will ich jetzt beleben,", "tokens": ["Die", "Kar\u00b7ten", "will", "ich", "jetzt", "be\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und ihnen Witz und Denken geben.", "tokens": ["Und", "ih\u00b7nen", "Witz", "und", "Den\u00b7ken", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr Sp\u00f6tter, eh' ihr den verlacht,", "tokens": ["Ihr", "Sp\u00f6t\u00b7ter", ",", "eh'", "ihr", "den", "ver\u00b7lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Der todte Karten redend macht,", "tokens": ["Der", "tod\u00b7te", "Kar\u00b7ten", "re\u00b7dend", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So lernt, wie das, was ich erfinde,", "tokens": ["So", "lernt", ",", "wie", "das", ",", "was", "ich", "er\u00b7fin\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "PDS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sich auf Natur und Wahrheit gr\u00fcnde.", "tokens": ["Sich", "auf", "Na\u00b7tur", "und", "Wahr\u00b7heit", "gr\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Was macht, da\u00df ", "tokens": ["Was", "macht", ",", "da\u00df"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "$,", "KOUS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.12": {"text": "Und da\u00df ", "tokens": ["Und", "da\u00df"], "token_info": ["word", "word"], "pos": ["KON", "KOUS"], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Die Karten m\u00fcssen sie beleben,", "tokens": ["Die", "Kar\u00b7ten", "m\u00fcs\u00b7sen", "sie", "be\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und ihnen Witz und Denken geben:", "tokens": ["Und", "ih\u00b7nen", "Witz", "und", "Den\u00b7ken", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Wenn sie nun Andern das verleihn,", "tokens": ["Wenn", "sie", "nun", "An\u00b7dern", "das", "ver\u00b7leihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "So kann es wohl ihr eigen seyn.", "tokens": ["So", "kann", "es", "wohl", "ihr", "ei\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "In jenen streitbaren Papieren,", "tokens": ["In", "je\u00b7nen", "streit\u00b7ba\u00b7ren", "Pa\u00b7pie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Damit die Sch\u00f6nen Kriege f\u00fchren,", "tokens": ["Da\u00b7mit", "die", "Sch\u00f6\u00b7nen", "Krie\u00b7ge", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Stutzer selbst zu Felde ziehn,", "tokens": ["Und", "Stut\u00b7zer", "selbst", "zu", "Fel\u00b7de", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weicht Alles vor dem schwarzen Sieger;", "tokens": ["Weicht", "Al\u00b7les", "vor", "dem", "schwar\u00b7zen", "Sie\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Stets w\u00fcrgt er zween ber\u00fchmte Krieger,", "tokens": ["Stets", "w\u00fcrgt", "er", "zween", "be\u00b7r\u00fchm\u00b7te", "Krie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gemeines Volk l\u00e4\u00dft er entfliehn.", "tokens": ["Ge\u00b7mei\u00b7nes", "Volk", "l\u00e4\u00dft", "er", "ent\u00b7fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "An Farbe gleicher, als an St\u00e4rke,", "tokens": ["An", "Far\u00b7be", "glei\u00b7cher", ",", "als", "an", "St\u00e4r\u00b7ke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "$,", "KOUS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch stark zu manchem gro\u00dfen Werke,", "tokens": ["Doch", "stark", "zu", "man\u00b7chem", "gro\u00b7\u00dfen", "Wer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist ihm der zweyte K\u00e4mpfer nah,", "tokens": ["Ist", "ihm", "der", "zwey\u00b7te", "K\u00e4mp\u00b7fer", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf dessen Schild, nie ohne Zittern,", "tokens": ["Auf", "des\u00b7sen", "Schild", ",", "nie", "oh\u00b7ne", "Zit\u00b7tern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der k\u00fchnste von den bunten Rittern", "tokens": ["Der", "k\u00fchns\u00b7te", "von", "den", "bun\u00b7ten", "Rit\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das schwarze Kreuze blicken sah.", "tokens": ["Das", "schwar\u00b7ze", "Kreu\u00b7ze", "bli\u00b7cken", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Den dritten Platz hat er im Heere.", "tokens": ["Den", "drit\u00b7ten", "Platz", "hat", "er", "im", "Hee\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der zweyten Stelle Macht und Ehre", "tokens": ["Der", "zwey\u00b7ten", "Stel\u00b7le", "Macht", "und", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bleibt nicht stets Einem ganz allein;", "tokens": ["Bleibt", "nicht", "stets", "Ei\u00b7nem", "ganz", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ART", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil zweymal zween gemeine Knechte", "tokens": ["Weil", "zwey\u00b7mal", "zween", "ge\u00b7mei\u00b7ne", "Knech\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Auf diesen Rang mit gleichem Rechte", "tokens": ["Auf", "die\u00b7sen", "Rang", "mit", "glei\u00b7chem", "Rech\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sich einer um den andern freun.", "tokens": ["Sich", "ei\u00b7ner", "um", "den", "an\u00b7dern", "freun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Einst ward ein Blatt dazu erhoben,", "tokens": ["Einst", "ward", "ein", "Blatt", "da\u00b7zu", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das uns als seiner K\u00fchnheit Proben", "tokens": ["Das", "uns", "als", "sei\u00b7ner", "K\u00fchn\u00b7heit", "Pro\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sechs Herzen und noch eines zeigt,", "tokens": ["Sechs", "Her\u00b7zen", "und", "noch", "ei\u00b7nes", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und bey der andern Bl\u00e4tter Neide,", "tokens": ["Und", "bey", "der", "an\u00b7dern", "Bl\u00e4t\u00b7ter", "Nei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Berauscht von stolzerf\u00fcllter Freude,", "tokens": ["Be\u00b7rauscht", "von", "stol\u00b7zer\u00b7f\u00fcll\u00b7ter", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nun seinen K\u00f6nig \u00fcbersteigt.", "tokens": ["Nun", "sei\u00b7nen", "K\u00f6\u00b7nig", "\u00fc\u00b7bers\u00b7teigt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die Basta selber mu\u00df mich ehren!", "tokens": ["Die", "Bas\u00b7ta", "sel\u00b7ber", "mu\u00df", "mich", "eh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So lie\u00df es sich voll Hochmuth h\u00f6ren,", "tokens": ["So", "lie\u00df", "es", "sich", "voll", "Hoch\u00b7muth", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein einzig Blatt ist \u00fcber mir.", "tokens": ["Ein", "ein\u00b7zig", "Blatt", "ist", "\u00fc\u00b7ber", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Basta, durch den Stolz verletzet,", "tokens": ["Die", "Bas\u00b7ta", ",", "durch", "den", "Stolz", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sprach: wenn dein Rang dich so ergetzet,", "tokens": ["Sprach", ":", "wenn", "dein", "Rang", "dich", "so", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "PPOSAT", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So glaube doch, ich g\u00f6nn' ihn dir.", "tokens": ["So", "glau\u00b7be", "doch", ",", "ich", "g\u00f6nn'", "ihn", "dir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Best\u00e4ndig kann mein Beystand n\u00fctzen;", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "kann", "mein", "Beys\u00b7tand", "n\u00fct\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stets w\u00fcnschet man mich zu besitzen:", "tokens": ["Stets", "w\u00fcn\u00b7schet", "man", "mich", "zu", "be\u00b7sit\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dich macht nur blinder Zufall werth.", "tokens": ["Dich", "macht", "nur", "blin\u00b7der", "Zu\u00b7fall", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So eile, recht dein Gl\u00fcck zu f\u00fchlen,", "tokens": ["So", "ei\u00b7le", ",", "recht", "dein", "Gl\u00fcck", "zu", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Eh' durch dich in den n\u00e4chsten Spielen", "tokens": ["Eh'", "durch", "dich", "in", "den", "n\u00e4chs\u00b7ten", "Spie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Verworfner Bl\u00e4tter Zahl sich mehrt.", "tokens": ["Ver\u00b7worf\u00b7ner", "Bl\u00e4t\u00b7ter", "Zahl", "sich", "mehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der Leser mag es selbst ergr\u00fcnden,", "tokens": ["Der", "Le\u00b7ser", "mag", "es", "selbst", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Worauf der Fabel Inhalt zielt.", "tokens": ["Wo\u00b7rauf", "der", "Fa\u00b7bel", "In\u00b7halt", "zielt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er braucht vielleicht, es auszufinden,", "tokens": ["Er", "braucht", "viel\u00b7leicht", ",", "es", "aus\u00b7zu\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht halb den Witz, damit er L'hombre spielt.", "tokens": ["Nicht", "halb", "den", "Witz", ",", "da\u00b7mit", "er", "L'\u00b7hom\u00b7bre", "spielt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ART", "NN", "$,", "KOUS", "PPER", "NE", "VVFIN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}