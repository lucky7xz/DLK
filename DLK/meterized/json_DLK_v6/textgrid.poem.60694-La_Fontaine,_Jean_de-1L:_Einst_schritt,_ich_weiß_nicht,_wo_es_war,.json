{"textgrid.poem.60694": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Einst schritt, ich wei\u00df nicht, wo es war,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einst schritt, ich wei\u00df nicht, wo es war,", "tokens": ["Einst", "schritt", ",", "ich", "wei\u00df", "nicht", ",", "wo", "es", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Reiher her mit langem Schnabel, langem Hals.", "tokens": ["Ein", "Rei\u00b7her", "her", "mit", "lan\u00b7gem", "Schna\u00b7bel", ",", "lan\u00b7gem", "Hals", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APZR", "APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Luft war hell, der Himmel klar,", "tokens": ["Die", "Luft", "war", "hell", ",", "der", "Him\u00b7mel", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Welle ebenfalls.", "tokens": ["Die", "Wel\u00b7le", "e\u00b7ben\u00b7falls", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gevatter Karpfen neckte mit Gevatter Hecht,", "tokens": ["Ge\u00b7vat\u00b7ter", "Karp\u00b7fen", "neck\u00b7te", "mit", "Ge\u00b7vat\u00b7ter", "Hecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie tummelten sich nah am Rand des Ufers hin;", "tokens": ["Sie", "tum\u00b7mel\u00b7ten", "sich", "nah", "am", "Rand", "des", "U\u00b7fers", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "APPRART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.7": {"text": "Ein Sto\u00df vom Reiher nur, so hatte er Gewinn \u2013", "tokens": ["Ein", "Sto\u00df", "vom", "Rei\u00b7her", "nur", ",", "so", "hat\u00b7te", "er", "Ge\u00b7winn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "$,", "ADV", "VAFIN", "PPER", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch war es ihm zurzeit nicht recht,", "tokens": ["Doch", "war", "es", "ihm", "zur\u00b7zeit", "nicht", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da seine Vesperstund noch nicht geschlagen.", "tokens": ["Da", "sei\u00b7ne", "Ves\u00b7per\u00b7stund", "noch", "nicht", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Er hielt auf Ordnung, darum schien's ihm besser,", "tokens": ["Er", "hielt", "auf", "Ord\u00b7nung", ",", "da\u00b7rum", "schien's", "ihm", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "PAV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Zu warten, bis noch leerer ihm der Magen.", "tokens": ["Zu", "war\u00b7ten", ",", "bis", "noch", "lee\u00b7rer", "ihm", "der", "Ma\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "ADV", "ADJA", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Der Hunger kam. Da trat er ans Gew\u00e4sser", "tokens": ["Der", "Hun\u00b7ger", "kam", ".", "Da", "trat", "er", "ans", "Ge\u00b7w\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und sah die Schleie jetzt empor vom Grunde ziehn:", "tokens": ["Und", "sah", "die", "Schlei\u00b7e", "jetzt", "em\u00b7por", "vom", "Grun\u00b7de", "ziehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein Mahl, das ihm nicht eben sehr lukullisch schien.", "tokens": ["Ein", "Mahl", ",", "das", "ihm", "nicht", "e\u00b7ben", "sehr", "lu\u00b7kul\u00b7lisch", "schien", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er hatte Besseres erwartet, denn er hatte", "tokens": ["Er", "hat\u00b7te", "Bes\u00b7se\u00b7res", "er\u00b7war\u00b7tet", ",", "denn", "er", "hat\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "VVPP", "$,", "KON", "PPER", "VAFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So heikelen Geschmack wie des Horatius Ratte.", "tokens": ["So", "hei\u00b7ke\u00b7len", "Ge\u00b7schmack", "wie", "des", "Ho\u00b7ra\u00b7ti\u00b7us", "Rat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KOKOM", "ART", "NE", "NN", "$."], "meter": "-+---+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "\u00bbich \u2013 Schleie?\u00ab sagte er; \u00bbnein, euch verachte ich.", "tokens": ["\u00bb", "ich", "\u2013", "Schlei\u00b7e", "?", "\u00ab", "sag\u00b7te", "er", ";", "\u00bb", "nein", ",", "euch", "ver\u00b7ach\u00b7te", "ich", "."], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$(", "NN", "$.", "$(", "VVFIN", "PPER", "$.", "$(", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Welch ein gemeiner Fra\u00df! Wof\u00fcr denn h\u00e4lt man mich?\u00ab", "tokens": ["Welch", "ein", "ge\u00b7mei\u00b7ner", "Fra\u00df", "!", "Wo\u00b7f\u00fcr", "denn", "h\u00e4lt", "man", "mich", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "ART", "ADJA", "NN", "$.", "NN", "KON", "VVFIN", "PIS", "PRF", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Schleie fort \u2013 Gr\u00fcndlinge kommen.", "tokens": ["Die", "Schlei\u00b7e", "fort", "\u2013", "Gr\u00fcnd\u00b7lin\u00b7ge", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$(", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbein Reiher, der mit Gr\u00fcndlingen f\u00fcrlieb genommen \u2013", "tokens": ["\u00bb", "ein", "Rei\u00b7her", ",", "der", "mit", "Gr\u00fcnd\u00b7lin\u00b7gen", "f\u00fcr\u00b7lieb", "ge\u00b7nom\u00b7men", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "VVPP", "$("], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Ein Unding w\u00e4r's! F\u00fcr solche Kleinigkeiten sperr", "tokens": ["Ein", "Un\u00b7ding", "w\u00e4r's", "!", "F\u00fcr", "sol\u00b7che", "Klei\u00b7nig\u00b7kei\u00b7ten", "sperr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$.", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich nicht den Schnabel auf. Bewahre mich der Herr!\u00ab", "tokens": ["Ich", "nicht", "den", "Schna\u00b7bel", "auf", ".", "Be\u00b7wah\u00b7re", "mich", "der", "Herr", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKNEG", "ART", "NN", "PTKVZ", "$.", "VVFIN", "PPER", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er hat ihn aufgesperrt f\u00fcr weniger als dies!", "tokens": ["Er", "hat", "ihn", "auf\u00b7ge\u00b7sperrt", "f\u00fcr", "we\u00b7ni\u00b7ger", "als", "dies", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "APPR", "PIS", "KOKOM", "PDS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es kam so weit, da\u00df sich kein Fisch mehr sehen lie\u00df.", "tokens": ["Es", "kam", "so", "weit", ",", "da\u00df", "sich", "kein", "Fisch", "mehr", "se\u00b7hen", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "PRF", "PIAT", "NN", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Hunger wuchs. Er war zuletzt zufrieden,", "tokens": ["Der", "Hun\u00b7ger", "wuchs", ".", "Er", "war", "zu\u00b7letzt", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df ihm ein kleines Schneckchen ward beschieden.", "tokens": ["Da\u00df", "ihm", "ein", "klei\u00b7nes", "Schneck\u00b7chen", "ward", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Wer zu viel haben m\u00f6cht,", "tokens": ["Wer", "zu", "viel", "ha\u00b7ben", "m\u00f6cht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKA", "PIS", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der wird riskieren,", "tokens": ["Der", "wird", "ris\u00b7kie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Das, was ihm minder recht,", "tokens": ["Das", ",", "was", "ihm", "min\u00b7der", "recht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Auch zu verlieren.", "tokens": ["Auch", "zu", "ver\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Schwimmt euch kein Taler her,", "tokens": ["Schwimmt", "euch", "kein", "Ta\u00b7ler", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "PTKVZ", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Greift nach dem Dreier,", "tokens": ["Greift", "nach", "dem", "Drei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Denkt an die gute Lehr", "tokens": ["Denkt", "an", "die", "gu\u00b7te", "Lehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Von unserm Reiher.", "tokens": ["Von", "un\u00b7serm", "Rei\u00b7her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}