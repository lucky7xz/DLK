{"textgrid.poem.49728": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Breslauer Katholikentag", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "An dem Oderstromgestade", "tokens": ["An", "dem", "O\u00b7der\u00b7strom\u00b7ge\u00b7sta\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist der Glaube neu erstarkt,", "tokens": ["Ist", "der", "Glau\u00b7be", "neu", "er\u00b7starkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn hier war die Herbstparade,", "tokens": ["Denn", "hier", "war", "die", "Herbst\u00b7pa\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Scilicet, der Ochsenmarkt.", "tokens": ["Sci\u00b7li\u00b7cet", ",", "der", "Och\u00b7sen\u00b7markt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Alle sind sie dagewesen,", "tokens": ["Al\u00b7le", "sind", "sie", "da\u00b7ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "PAV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fern von ihrem Heimatsort;", "tokens": ["Fern", "von", "ih\u00b7rem", "Hei\u00b7mat\u00b7sort", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ungeacht' der Reisespesen", "tokens": ["Un\u00b7ge\u00b7acht'", "der", "Rei\u00b7se\u00b7spe\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zog der Geist des Herrn sie fort.", "tokens": ["Zog", "der", "Geist", "des", "Herrn", "sie", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Mit den Platt- und B\u00fcrgerf\u00fc\u00dfen", "tokens": ["Mit", "den", "Plat\u00b7t", "und", "B\u00fcr\u00b7ger\u00b7f\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "TRUNC", "KON", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ist man stolz vorbeimarschiert,", "tokens": ["Ist", "man", "stolz", "vor\u00b7bei\u00b7mar\u00b7schiert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Um den Bischof zu begr\u00fc\u00dfen,", "tokens": ["Um", "den", "Bi\u00b7schof", "zu", "be\u00b7gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der hiebei ein Wort verliert.", "tokens": ["Der", "hie\u00b7bei", "ein", "Wort", "ver\u00b7liert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auch der Papst gab seinen Segen,", "tokens": ["Auch", "der", "Papst", "gab", "sei\u00b7nen", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oho \u2013 ho, und gern dazu.", "tokens": ["O\u00b7ho", "\u2013", "ho", ",", "und", "gern", "da\u00b7zu", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["XY", "$(", "ITJ", "$,", "KON", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist euch was daran gelegen,", "tokens": ["Ist", "euch", "was", "da\u00b7ran", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn ich jetzt das N\u00e4mlich tu?", "tokens": ["Wenn", "ich", "jetzt", "das", "N\u00e4m\u00b7lich", "tu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}