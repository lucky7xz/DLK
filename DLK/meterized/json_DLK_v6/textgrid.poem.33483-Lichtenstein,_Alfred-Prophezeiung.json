{"textgrid.poem.33483": {"metadata": {"author": {"name": "Lichtenstein, Alfred", "birth": "N.A.", "death": "N.A."}, "title": "Prophezeiung", "genre": "verse", "period": "N.A.", "pub_year": 1913, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einmal kommt \u2013 ich habe Zeichen \u2013", "tokens": ["Ein\u00b7mal", "kommt", "\u2013", "ich", "ha\u00b7be", "Zei\u00b7chen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "PPER", "VAFIN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sterbesturm aus fernem Norden.", "tokens": ["Ster\u00b7be\u00b7sturm", "aus", "fer\u00b7nem", "Nor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00dcberall stinkt es nach Leichen.", "tokens": ["\u00dc\u00b7be\u00b7rall", "stinkt", "es", "nach", "Lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Es beginnt das gro\u00dfe Morden.", "tokens": ["Es", "be\u00b7ginnt", "das", "gro\u00b7\u00dfe", "Mor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Finster wird der Himmelsklumpen,", "tokens": ["Fins\u00b7ter", "wird", "der", "Him\u00b7mels\u00b7klum\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sturmtod hebt die Klauentatzen:", "tokens": ["Sturm\u00b7tod", "hebt", "die", "Klau\u00b7en\u00b7tat\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nieder st\u00fcrzen alle Lumpen,", "tokens": ["Nie\u00b7der", "st\u00fcr\u00b7zen", "al\u00b7le", "Lum\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mimen bersten. M\u00e4dchen platzen.", "tokens": ["Mi\u00b7men", "bers\u00b7ten", ".", "M\u00e4d\u00b7chen", "plat\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$.", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Polternd fallen Pferdest\u00e4lle.", "tokens": ["Pol\u00b7ternd", "fal\u00b7len", "Pfer\u00b7de\u00b7st\u00e4l\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keine Fliege kann sich retten.", "tokens": ["Kei\u00b7ne", "Flie\u00b7ge", "kann", "sich", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00f6ne homosexuelle", "tokens": ["Sch\u00f6\u00b7ne", "ho\u00b7mo\u00b7se\u00b7xu\u00b7el\u00b7le"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00e4nner kullern aus den Betten.", "tokens": ["M\u00e4n\u00b7ner", "kul\u00b7lern", "aus", "den", "Bet\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Rissig werden H\u00e4userw\u00e4nde.", "tokens": ["Ris\u00b7sig", "wer\u00b7den", "H\u00e4u\u00b7ser\u00b7w\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fische faulen in dem Flusse.", "tokens": ["Fi\u00b7sche", "fau\u00b7len", "in", "dem", "Flus\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles nimmt sein ekles Ende.", "tokens": ["Al\u00b7les", "nimmt", "sein", "ek\u00b7les", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kr\u00e4chzend kippen Omnibusse.", "tokens": ["Kr\u00e4ch\u00b7zend", "kip\u00b7pen", "Om\u00b7ni\u00b7bus\u00b7se", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}