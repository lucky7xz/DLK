{"textgrid.poem.39144": {"metadata": {"author": {"name": "Strachwitz, Moritz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich wei\u00df eine M\u00e4re, gut und k\u00fchn,", "genre": "verse", "period": "N.A.", "pub_year": 1834, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich wei\u00df eine M\u00e4re, gut und k\u00fchn,", "tokens": ["Ich", "wei\u00df", "ei\u00b7ne", "M\u00e4\u00b7re", ",", "gut", "und", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von keckem Ritterwerk:", "tokens": ["Von", "ke\u00b7ckem", "Rit\u00b7ter\u00b7werk", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es fingen den Junkherrn Ebbelin", "tokens": ["Es", "fin\u00b7gen", "den", "Junk\u00b7herrn", "Eb\u00b7be\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Herren von N\u00fcrenberg.", "tokens": ["Die", "Her\u00b7ren", "von", "N\u00fc\u00b7ren\u00b7berg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Sie fingen ihn mit Hinterlist,", "tokens": ["Sie", "fin\u00b7gen", "ihn", "mit", "Hin\u00b7ter\u00b7list", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie schn\u00fcrten ihm Hand und Fu\u00df:", "tokens": ["Sie", "schn\u00fcr\u00b7ten", "ihm", "Hand", "und", "Fu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbnun haben wir dich, du schlimmer Christ,", "tokens": ["\u00bb", "nun", "ha\u00b7ben", "wir", "dich", ",", "du", "schlim\u00b7mer", "Christ", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PRF", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Galgen dir werden mu\u00df.\u00ab", "tokens": ["Der", "Gal\u00b7gen", "dir", "wer\u00b7den", "mu\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPER", "VAINF", "VMFIN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Und jeder Ritter von Wag' und Ell',", "tokens": ["Und", "je\u00b7der", "Rit\u00b7ter", "von", "Wag'", "und", "Ell'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "KON", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der machte ein stolz Geschrei,", "tokens": ["Der", "mach\u00b7te", "ein", "stolz", "Ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und jeder Schuster- und Schneidergesell,", "tokens": ["Und", "je\u00b7der", "Schus\u00b7ter", "und", "Schnei\u00b7der\u00b7ge\u00b7sell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der hatte sein Wort dabei.", "tokens": ["Der", "hat\u00b7te", "sein", "Wort", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "PAV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "F\u00fcnf Schneider schleppten des Ritters Speer,", "tokens": ["F\u00fcnf", "Schnei\u00b7der", "schlepp\u00b7ten", "des", "Rit\u00b7ters", "Speer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NE", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie Goliaths Weberbaum,", "tokens": ["Wie", "Go\u00b7li\u00b7aths", "We\u00b7ber\u00b7baum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie keuchten gewaltig und schwitzten sehr", "tokens": ["Sie", "keuch\u00b7ten", "ge\u00b7wal\u00b7tig", "und", "schwitz\u00b7ten", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "VVFIN", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und brachten ihn vorw\u00e4rts kaum.", "tokens": ["Und", "brach\u00b7ten", "ihn", "vor\u00b7w\u00e4rts", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Die Sporen ein tapferer Fleischer hob,", "tokens": ["Die", "Spo\u00b7ren", "ein", "tap\u00b7fe\u00b7rer", "Flei\u00b7scher", "hob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Zwei Schreiner den Helm zugleich,", "tokens": ["Zwei", "Schrei\u00b7ner", "den", "Helm", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und wenn der Helmbusch im Winde stob,", "tokens": ["Und", "wenn", "der", "Helm\u00b7busch", "im", "Win\u00b7de", "stob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da wurden sie bla\u00df und bleich.", "tokens": ["Da", "wur\u00b7den", "sie", "bla\u00df", "und", "bleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Und zwischen Mauer, Graben und Tor,", "tokens": ["Und", "zwi\u00b7schen", "Mau\u00b7er", ",", "Gra\u00b7ben", "und", "Tor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da wollten sie h\u00e4ngen ihn;", "tokens": ["Da", "woll\u00b7ten", "sie", "h\u00e4n\u00b7gen", "ihn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da sprach zu dem mannlichen B\u00fcrgerchor", "tokens": ["Da", "sprach", "zu", "dem", "mann\u00b7li\u00b7chen", "B\u00fcr\u00b7ger\u00b7chor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Der Junkherr Ebbelin:", "tokens": ["Der", "Junk\u00b7herr", "Eb\u00b7be\u00b7lin", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u00bbihr Herrn, nehmt mir das Wort nicht krumm!", "tokens": ["\u00bb", "ihr", "Herrn", ",", "nehmt", "mir", "das", "Wort", "nicht", "krumm", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es sei meine letzte Bitt':", "tokens": ["Es", "sei", "mei\u00b7ne", "letz\u00b7te", "Bitt'", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "La\u00dft reiten mich im Zwinger herum", "tokens": ["La\u00dft", "rei\u00b7ten", "mich", "im", "Zwin\u00b7ger", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "VVFIN", "PPER", "APPRART", "NN", "APZR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Meinen allerletzten Ritt.", "tokens": ["Mei\u00b7nen", "al\u00b7ler\u00b7letz\u00b7ten", "Ritt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Rundum ist Schanze, Tor und Schlo\u00df,", "tokens": ["Run\u00b7dum", "ist", "Schan\u00b7ze", ",", "Tor", "und", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "$,", "NE", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ich kann euch nicht entgehn,", "tokens": ["Ich", "kann", "euch", "nicht", "ent\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "La\u00dft mich mein Ro\u00df, mein tapfres Ro\u00df,", "tokens": ["La\u00dft", "mich", "mein", "Ro\u00df", ",", "mein", "tapf\u00b7res", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum letzten Male sehn.\u00ab", "tokens": ["Zum", "letz\u00b7ten", "Ma\u00b7le", "sehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Es brachten das Ro\u00df Gesellen vier,", "tokens": ["Es", "brach\u00b7ten", "das", "Ro\u00df", "Ge\u00b7sel\u00b7len", "vier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "CARD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den Junkherrn banden sie los;", "tokens": ["Den", "Junk\u00b7herrn", "ban\u00b7den", "sie", "los", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wie schwang sich auf das schlanke Tier", "tokens": ["Wie", "schwang", "sich", "auf", "das", "schlan\u00b7ke", "Tier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Degen, k\u00fchn und gro\u00df!", "tokens": ["Der", "De\u00b7gen", ",", "k\u00fchn", "und", "gro\u00df", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und wie er es trieb mit Hieb und Ruf,", "tokens": ["Und", "wie", "er", "es", "trieb", "mit", "Hieb", "und", "Ruf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Zunge, Schenkel und Hand,", "tokens": ["Mit", "Zun\u00b7ge", ",", "Schen\u00b7kel", "und", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da flogen ringsum von des Renners Huf", "tokens": ["Da", "flo\u00b7gen", "ring\u00b7sum", "von", "des", "Ren\u00b7ners", "Huf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da M\u00e4nnlein in den Sand.", "tokens": ["Da", "M\u00e4nn\u00b7lein", "in", "den", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wild stampfte der Hengst und tanzte keck,", "tokens": ["Wild", "stampf\u00b7te", "der", "Hengst", "und", "tanz\u00b7te", "keck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADJD", "$,"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Zum Graben sprengt' er herum;", "tokens": ["Zum", "Gra\u00b7ben", "sprengt'", "er", "he\u00b7rum", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Die Herren befiel ein grimmer Schreck,", "tokens": ["Die", "Her\u00b7ren", "be\u00b7fiel", "ein", "grim\u00b7mer", "Schreck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie standen bet\u00e4ubt und dumm.", "tokens": ["Sie", "stan\u00b7den", "be\u00b7t\u00e4ubt", "und", "dumm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "KON", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Und \u00fcber Graben, Schanz' und Wall", "tokens": ["Und", "\u00fc\u00b7ber", "Gra\u00b7ben", ",", "Schanz'", "und", "Wall"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "$,", "NN", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hinsprang er wild und toll,", "tokens": ["Hin\u00b7sprang", "er", "wild", "und", "toll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Indes her\u00fcber mit Donnerschall", "tokens": ["In\u00b7des", "her\u00b7\u00fc\u00b7ber", "mit", "Don\u00b7ner\u00b7schall"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Des Ritters Gel\u00e4chter scholl:", "tokens": ["Des", "Rit\u00b7ters", "Ge\u00b7l\u00e4ch\u00b7ter", "scholl", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "\u00bbeh' zw\u00e4ngt der Maulwurf in sein Loch", "tokens": ["\u00bb", "eh'", "zw\u00e4ngt", "der", "Maul\u00b7wurf", "in", "sein", "Loch"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Adler, stolz beschwingt,", "tokens": ["Den", "Ad\u00b7ler", ",", "stolz", "be\u00b7schwingt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Eh' Kr\u00e4merwitz und Kr\u00e4merjoch", "tokens": ["Eh'", "Kr\u00e4\u00b7mer\u00b7witz", "und", "Kr\u00e4\u00b7mer\u00b7joch"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Ritternacken zwingt.\u00ab", "tokens": ["Den", "Rit\u00b7ter\u00b7na\u00b7cken", "zwingt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "So rief der freudige Rittersmann", "tokens": ["So", "rief", "der", "freu\u00b7di\u00b7ge", "Rit\u00b7ters\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und wandte den wilden Gaul,", "tokens": ["Und", "wand\u00b7te", "den", "wil\u00b7den", "Gaul", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Herren sahen einander an", "tokens": ["Die", "Her\u00b7ren", "sa\u00b7hen", "ein\u00b7an\u00b7der", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und machten ein gro\u00dfes Maul.", "tokens": ["Und", "mach\u00b7ten", "ein", "gro\u00b7\u00dfes", "Maul", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Wohl oftmals schon mir's widerfuhr,", "tokens": ["Wohl", "oft\u00b7mals", "schon", "mir's", "wi\u00b7der\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn ich zu sehr getollt,", "tokens": ["Wenn", "ich", "zu", "sehr", "ge\u00b7tollt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df Philistertum und Philisternatur", "tokens": ["Da\u00df", "Phi\u00b7lis\u00b7ter\u00b7tum", "und", "Phi\u00b7lis\u00b7ter\u00b7na\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NE", "KON", "NN"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Mich fangen und h\u00e4ngen gewollt.", "tokens": ["Mich", "fan\u00b7gen", "und", "h\u00e4n\u00b7gen", "ge\u00b7wollt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "VMPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.16": {"line.1": {"text": "Da sprang ich auf mein schnelles Ro\u00df,", "tokens": ["Da", "sprang", "ich", "auf", "mein", "schnel\u00b7les", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aufs Ro\u00df der Phantasie,", "tokens": ["Aufs", "Ro\u00df", "der", "Phan\u00b7ta\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sein Huf zerschmetterte Tor und Schlo\u00df,", "tokens": ["Sein", "Huf", "zer\u00b7schmet\u00b7ter\u00b7te", "Tor", "und", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NE", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Guten fingen mich nie.", "tokens": ["Die", "Gu\u00b7ten", "fin\u00b7gen", "mich", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.17": {"line.1": {"text": "Hei, Lumpengesindel, gib mir Platz,", "tokens": ["Hei", ",", "Lum\u00b7pen\u00b7ge\u00b7sin\u00b7del", ",", "gib", "mir", "Platz", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "VVIMP", "PPER", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hin\u00fcber, mein Ro\u00df, hinaus!", "tokens": ["Hin\u00b7\u00fc\u00b7ber", ",", "mein", "Ro\u00df", ",", "hin\u00b7aus", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hei, Schenkeldruck und Sprung und Satz,", "tokens": ["Hei", ",", "Schen\u00b7kel\u00b7druck", "und", "Sprung", "und", "Satz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ade, Philisterhaus!", "tokens": ["A\u00b7de", ",", "Phi\u00b7lis\u00b7ter\u00b7haus", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.18": {"line.1": {"text": "Eh' zw\u00e4ngt der Maulwurf in sein Loch", "tokens": ["Eh'", "zw\u00e4ngt", "der", "Maul\u00b7wurf", "in", "sein", "Loch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Adler, stolz beschwingt,", "tokens": ["Den", "Ad\u00b7ler", ",", "stolz", "be\u00b7schwingt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Eh' Philisterwitz und Philisterjoch", "tokens": ["Eh'", "Phi\u00b7lis\u00b7ter\u00b7witz", "und", "Phi\u00b7lis\u00b7ter\u00b7joch"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "KON", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Den Dichternacken zwingt.", "tokens": ["Den", "Dich\u00b7ter\u00b7na\u00b7cken", "zwingt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}