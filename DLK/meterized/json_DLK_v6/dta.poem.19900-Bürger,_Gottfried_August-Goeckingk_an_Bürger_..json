{"dta.poem.19900": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Goeckingk an B\u00fcrger .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1778", "urn": "urn:nbn:de:kobv:b4-20090519672", "language": ["de:0.99"], "booktitle": "B\u00fcrger, Gottfried August: Gedichte. G\u00f6ttingen, 1778."}, "poem": {"stanza.1": {"line.1": {"text": "Verdamte Versemacherei!               ", "tokens": ["Ver\u00b7dam\u00b7te", "Ver\u00b7se\u00b7ma\u00b7che\u00b7rei", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was hast du angerichtet?", "tokens": ["Was", "hast", "du", "an\u00b7ge\u00b7rich\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Uns unsers Lebens einzgen Mai", "tokens": ["Uns", "un\u00b7sers", "Le\u00b7bens", "einz\u00b7gen", "Mai"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum Kukuk hingedichtet?", "tokens": ["Zum", "Ku\u00b7kuk", "hin\u00b7ge\u00b7dich\u00b7tet", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Gevatter B\u00fcrger, sag\u2019 er mal,", "tokens": ["Ge\u00b7vat\u00b7ter", "B\u00fcr\u00b7ger", ",", "sag'", "er", "mal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind wir nicht brave Thoren,", "tokens": ["Sind", "wir", "nicht", "bra\u00b7ve", "Tho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df wir mit selbst gemachter Qual", "tokens": ["Da\u00df", "wir", "mit", "selbst", "ge\u00b7mach\u00b7ter", "Qual"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den sch\u00f6nen Mai verloren?", "tokens": ["Den", "sch\u00f6\u00b7nen", "Mai", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Was hat man von dem Dichten? hum!", "tokens": ["Was", "hat", "man", "von", "dem", "Dich\u00b7ten", "?", "hum", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VAFIN", "PIS", "APPR", "ART", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wandelbare Ehre", "tokens": ["Die", "wan\u00b7del\u00b7ba\u00b7re", "Eh\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gekant zu seyn vom Publikum? \u2014", "tokens": ["Ge\u00b7kant", "zu", "seyn", "vom", "Pub\u00b7li\u00b7kum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "PTKZU", "VAINF", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich dachte was mir w\u00e4re!", "tokens": ["Ich", "dach\u00b7te", "was", "mir", "w\u00e4\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Exempli gratia, es spricht,               ", "tokens": ["Ex\u00b7emp\u00b7li", "gra\u00b7tia", ",", "es", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["FM", "FM", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wann grosse Herren schmausen,", "tokens": ["Wann", "gros\u00b7se", "Her\u00b7ren", "schmau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wol Einer: Ist der B\u00fcrger nicht", "tokens": ["Wol", "Ei\u00b7ner", ":", "Ist", "der", "B\u00fcr\u00b7ger", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "$.", "VAFIN", "ART", "NN", "PTKNEG"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Amtman zu W\u00f6lmershausen?", "tokens": ["Amt\u00b7man", "zu", "W\u00f6l\u00b7mers\u00b7hau\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ein Fr\u00e4ulein thut dir wol sogar", "tokens": ["Ein", "Fr\u00e4u\u00b7lein", "thut", "dir", "wol", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Gnad\u2019 und fr\u00e4gt nicht minder:", "tokens": ["Die", "Gnad'", "und", "fr\u00e4gt", "nicht", "min\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Tr\u00e4gt denn der B\u00fcrger eigen Haar?", "tokens": ["Tr\u00e4gt", "denn", "der", "B\u00fcr\u00b7ger", "ei\u00b7gen", "Haar", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat er schon Frau und Kinder?", "tokens": ["Hat", "er", "schon", "Frau", "und", "Kin\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Dort r\u00e4uspert sich ein zarter Herr,", "tokens": ["Dort", "r\u00e4us\u00b7pert", "sich", "ein", "zar\u00b7ter", "Herr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Zirkel spizt die Ohren!", "tokens": ["Der", "Zir\u00b7kel", "spizt", "die", "Oh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ach! mit scheuslichem Gepl\u00e4rr", "tokens": ["Und", "ach", "!", "mit", "scheus\u00b7li\u00b7chem", "Ge\u00b7pl\u00e4rr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Notz\u00fcchtigt er Lenoren.", "tokens": ["Not\u00b7z\u00fcch\u00b7tigt", "er", "Le\u00b7no\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u201eha! bravo! wie Lenore schreit!", "tokens": ["\u201e", "ha", "!", "bra\u00b7vo", "!", "wie", "Le\u00b7no\u00b7re", "schreit", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "ITJ", "$.", "PWAV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eh\u00f6r\u2019 Einer nur das Fluchen!", "tokens": ["\u201e", "h\u00f6r'", "Ei\u00b7ner", "nur", "das", "Flu\u00b7chen", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eden Man \u2014 ist W\u00f6lmershausen weit? \u2014", "tokens": ["\u201e", "den", "Man", "ist", "W\u00f6l\u00b7mers\u00b7hau\u00b7sen", "weit", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "PIS", "$(", "VAFIN", "NN", "ADJD", "$.", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "\u201eden Man mus ich besuchen!\u201e", "tokens": ["\u201e", "den", "Man", "mus", "ich", "be\u00b7su\u00b7chen", "!", "\u201e"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "PIS", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und eh\u2019 Herr B\u00fcrger sich\u2019s versehn,", "tokens": ["Und", "eh'", "Herr", "B\u00fcr\u00b7ger", "sich's", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6mt mein Signor geritten,", "tokens": ["K\u00f6mt", "mein", "Sig\u00b7nor", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Begaft ihn, freuet sich gar sch\u00f6n,", "tokens": ["Be\u00b7gaft", "ihn", ",", "freu\u00b7et", "sich", "gar", "sch\u00f6n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "VVFIN", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4st sich zum Essen bitten,", "tokens": ["L\u00e4st", "sich", "zum", "Es\u00b7sen", "bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "++-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Kritiket M\u00e4nner, gros und klein,", "tokens": ["Kri\u00b7ti\u00b7ket", "M\u00e4n\u00b7ner", ",", "gros", "und", "klein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Thut greulich hochgelahret,", "tokens": ["Thut", "greu\u00b7lich", "hoch\u00b7ge\u00b7lah\u00b7ret", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und trinkt \u2014 hol\u2019 ihn der Fuchs! \u2014 den Wein,", "tokens": ["Und", "trinkt", "hol'", "ihn", "der", "Fuchs", "!", "den", "Wein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "VVFIN", "PPER", "ART", "NE", "$.", "$(", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Den du f\u00fcr mich gesparet;", "tokens": ["Den", "du", "f\u00fcr", "mich", "ge\u00b7spa\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Lobt m\u00e4chtig dir sein gutes Herz,", "tokens": ["Lobt", "m\u00e4ch\u00b7tig", "dir", "sein", "gu\u00b7tes", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wil Freundschaft mit dir treiben,", "tokens": ["Wil", "Freund\u00b7schaft", "mit", "dir", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und droht sogar \u2014 o H\u00f6llenschmerz! \u2014", "tokens": ["Und", "droht", "so\u00b7gar", "o", "H\u00f6l\u00b7len\u00b7schmerz", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "$(", "FM", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Recht oft an dich zu schreiben.", "tokens": ["Recht", "oft", "an", "dich", "zu", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Das macht, manch ehrliches Journal", "tokens": ["Das", "macht", ",", "manch", "ehr\u00b7li\u00b7ches", "Jour\u00b7nal"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lies bas dein Lob erschallen;", "tokens": ["Lies", "bas", "dein", "Lob", "er\u00b7schal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein, wann las denn wol einmal", "tokens": ["Al\u00b7lein", ",", "wann", "las", "denn", "wol", "ein\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Herr B\u00fcrger Eins von allen?", "tokens": ["Herr", "B\u00fcr\u00b7ger", "Eins", "von", "al\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "NN", "APPR", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wenn, vor den Almanach, ich schier", "tokens": ["Wenn", ",", "vor", "den", "Al\u00b7ma\u00b7nach", ",", "ich", "schier"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "$,", "APPR", "ART", "NN", "$,", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich liess\u2019 in Kupfer stechen:", "tokens": ["Dich", "liess'", "in", "Kup\u00b7fer", "ste\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was hilft\u2019s? was h\u00f6rst du? wenn von dir", "tokens": ["Was", "hilft's", "?", "was", "h\u00f6rst", "du", "?", "wenn", "von", "dir"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "PWS", "VVFIN", "PPER", "$.", "KOUS", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Leut\u2019 ein Weilchen sprechen?", "tokens": ["Die", "Leut'", "ein", "Weil\u00b7chen", "spre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Was hast du von dem allen? Sklav!", "tokens": ["Was", "hast", "du", "von", "dem", "al\u00b7len", "?", "Sklav", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "PIAT", "$.", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn ich\u2019s zusammen presse,", "tokens": ["Wenn", "ich's", "zu\u00b7sam\u00b7men", "pres\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ist\u2019s k\u00fcrzlich dies: Despotenschlaf,", "tokens": ["Ist's", "k\u00fcrz\u00b7lich", "dies", ":", "Des\u00b7po\u00b7ten\u00b7schlaf", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "PDS", "$.", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Inquisitenbl\u00e4sse.", "tokens": ["Und", "In\u00b7qui\u00b7si\u00b7ten\u00b7bl\u00e4s\u00b7se", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "H\u00f6r\u2019 auf! Ich gab mein Herz dir hin", "tokens": ["H\u00f6r'", "auf", "!", "Ich", "gab", "mein", "Herz", "dir", "hin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PTKVZ", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eh du ein Blat geschrieben;", "tokens": ["Eh", "du", "ein", "Blat", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "H\u00f6r\u2019 auf! und die Frau Amtmannin", "tokens": ["H\u00f6r'", "auf", "!", "und", "die", "Frau", "Amt\u00b7man\u00b7nin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PTKVZ", "$.", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird dich noch lieber lieben.", "tokens": ["Wird", "dich", "noch", "lie\u00b7ber", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "H\u00f6r\u2019 auf! Als Dichter kent man dich,", "tokens": ["H\u00f6r'", "auf", "!", "Als", "Dich\u00b7ter", "kent", "man", "dich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$.", "KOUS", "NN", "VVFIN", "PIS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Mensch lebst du verborgen;", "tokens": ["Als", "Mensch", "lebst", "du", "ver\u00b7bor\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kein Christenkind bek\u00fcmmert sich", "tokens": ["Kein", "Chris\u00b7ten\u00b7kind", "be\u00b7k\u00fcm\u00b7mert", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um alle deine Sorgen.", "tokens": ["Um", "al\u00b7le", "dei\u00b7ne", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Ja! Herr! und solt\u2019 er den Homer", "tokens": ["Ja", "!", "Herr", "!", "und", "solt'", "er", "den", "Ho\u00b7mer"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "NN", "$.", "KON", "VMFIN", "PPER", "ART", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "In Versen \u00fcbersezen:", "tokens": ["In", "Ver\u00b7sen", "\u00fc\u00b7ber\u00b7se\u00b7zen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Drob werden ihn kein Haarbreit mehr", "tokens": ["Drob", "wer\u00b7den", "ihn", "kein", "Haar\u00b7breit", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Herrn Minister sch\u00e4zen.", "tokens": ["Die", "Herrn", "Mi\u00b7nis\u00b7ter", "sch\u00e4\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Der Herr bleibt dennoch, nach wie vor,", "tokens": ["Der", "Herr", "bleibt", "den\u00b7noch", ",", "nach", "wie", "vor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "APPR", "KOKOM", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Amtman zu W\u00f6lmershausen.", "tokens": ["Amt\u00b7man", "zu", "W\u00f6l\u00b7mers\u00b7hau\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Drum, trauter B\u00fcrger, sey kein Thor,", "tokens": ["Drum", ",", "trau\u00b7ter", "B\u00fcr\u00b7ger", ",", "sey", "kein", "Thor", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADJA", "NN", "$,", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kom her und las uns schmausen!", "tokens": ["Kom", "her", "und", "las", "uns", "schmau\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}