{"dta.poem.23622": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Der Litteratenorden.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1840", "urn": "urn:nbn:de:kobv:b4-200905192626", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es hangen Orden aller Sorten", "tokens": ["Es", "han\u00b7gen", "Or\u00b7den", "al\u00b7ler", "Sor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In jedem Goldschmidsladen aus,", "tokens": ["In", "je\u00b7dem", "Gold\u00b7schmids\u00b7la\u00b7den", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch finden wir an allen Orten", "tokens": ["Doch", "fin\u00b7den", "wir", "an", "al\u00b7len", "Or\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nichts was da passt f\u00fcr uns heraus.", "tokens": ["Nichts", "was", "da", "passt", "f\u00fcr", "uns", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PWS", "ADV", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Noch nie zu viel belohnet worden", "tokens": ["Noch", "nie", "zu", "viel", "be\u00b7loh\u00b7net", "wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKA", "PIS", "VVFIN", "VAPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist unser geistig Eigenthum:", "tokens": ["Ist", "un\u00b7ser", "geis\u00b7tig", "Ei\u00b7gen\u00b7thum", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So lasst uns stiften einen Orden", "tokens": ["So", "lasst", "uns", "stif\u00b7ten", "ei\u00b7nen", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu unsrer Freud' und unserm Ruhm.", "tokens": ["Zu", "uns\u00b7rer", "Freud'", "und", "un\u00b7serm", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein rother Krebs am schwarzen Bande", "tokens": ["Ein", "ro\u00b7ther", "Krebs", "am", "schwar\u00b7zen", "Ban\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit goldenen Vergi\u00dfnichtmein,", "tokens": ["Mit", "gol\u00b7de\u00b7nen", "Ver\u00b7gi\u00df\u00b7nicht\u00b7mein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das soll im ganzen deutschen Lande", "tokens": ["Das", "soll", "im", "gan\u00b7zen", "deut\u00b7schen", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "APPRART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Litteratenorden sein.", "tokens": ["Der", "Lit\u00b7te\u00b7ra\u00b7te\u00b7nor\u00b7den", "sein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die erste Klasse wird bescheret,", "tokens": ["Die", "ers\u00b7te", "Klas\u00b7se", "wird", "be\u00b7sche\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn einer weit auf Reisen war", "tokens": ["Wenn", "ei\u00b7ner", "weit", "auf", "Rei\u00b7sen", "war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "APPR", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u00fcber Leipzig wiederkehret", "tokens": ["Und", "\u00fc\u00b7ber", "Leip\u00b7zig", "wie\u00b7der\u00b7keh\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gesund und frisch das n\u00e4chste Jahr.", "tokens": ["Ge\u00b7sund", "und", "frisch", "das", "n\u00e4chs\u00b7te", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "So oft er fort war und vollendet", "tokens": ["So", "oft", "er", "fort", "war", "und", "voll\u00b7en\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "PTKVZ", "VAFIN", "KON", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Heimweg unversehrt zur\u00fcck,", "tokens": ["Den", "Heim\u00b7weg", "un\u00b7ver\u00b7sehrt", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So oft wird ihm daf\u00fcr gespendet", "tokens": ["So", "oft", "wird", "ihm", "da\u00b7f\u00fcr", "ge\u00b7spen\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PAV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein neues h\u00f6hres Ordensgl\u00fcck.", "tokens": ["Ein", "neu\u00b7es", "h\u00f6h\u00b7res", "Or\u00b7dens\u00b7gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und wer zuletzt nach \u00f6fterm Wandern", "tokens": ["Und", "wer", "zu\u00b7letzt", "nach", "\u00f6f\u00b7term", "Wan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nie mehr verfehlt den Weg nach Haus,", "tokens": ["Nie", "mehr", "ver\u00b7fehlt", "den", "Weg", "nach", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den ehren wir vor allen andern", "tokens": ["Den", "eh\u00b7ren", "wir", "vor", "al\u00b7len", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "APPR", "PIAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und zeichnen ihn als Hummer aus.", "tokens": ["Und", "zeich\u00b7nen", "ihn", "als", "Hum\u00b7mer", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}