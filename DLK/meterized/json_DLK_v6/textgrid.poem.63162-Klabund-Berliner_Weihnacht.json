{"textgrid.poem.63162": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Berliner Weihnacht", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Am Kurf\u00fcrstendamm da hocken zusamm", "tokens": ["Am", "Kur\u00b7f\u00fcrs\u00b7ten\u00b7damm", "da", "ho\u00b7cken", "zu\u00b7samm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "ADJD", "APPRART"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die Leute von heute mit grossem Tamtam.", "tokens": ["Die", "Leu\u00b7te", "von", "heu\u00b7te", "mit", "gros\u00b7sem", "Tam\u00b7tam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Brillanten mit Tanten, ein Frack mit was drin,", "tokens": ["Bril\u00b7lan\u00b7ten", "mit", "Tan\u00b7ten", ",", "ein", "Frack", "mit", "was", "drin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "PRELS", "ADV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ein Nerzpelz, ein Steinherz, ein Doppelkinn.", "tokens": ["Ein", "Nerz\u00b7pelz", ",", "ein", "Stein\u00b7herz", ",", "ein", "Dop\u00b7pel\u00b7kinn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Perlen perlen, es perlt der Champagner.", "tokens": ["Per\u00b7len", "per\u00b7len", ",", "es", "perlt", "der", "Cham\u00b7pag\u00b7ner", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Kokotten spotten: Wer will, der kann ja", "tokens": ["Ko\u00b7kot\u00b7ten", "spot\u00b7ten", ":", "Wer", "will", ",", "der", "kann", "ja"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "PWS", "VMFIN", "$,", "PRELS", "VMFIN", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "F\u00fcnf Braune f\u00fcr mich auf das Tischtuch z\u00e4hlen ...", "tokens": ["F\u00fcnf", "Brau\u00b7ne", "f\u00fcr", "mich", "auf", "das", "Tischtuch", "z\u00e4h\u00b7len", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "PPER", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Na, Schieber, mein Lieber? \u2013 Nee, uns kanns nich fehlen,", "tokens": ["Na", ",", "Schie\u00b7ber", ",", "mein", "Lie\u00b7ber", "?", "\u2013", "Nee", ",", "uns", "kanns", "nich", "feh\u00b7len", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "PPOSAT", "NN", "$.", "$(", "NN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und wenn Millionen vor Hunger krepieren:", "tokens": ["Und", "wenn", "Mil\u00b7lion\u00b7en", "vor", "Hun\u00b7ger", "kre\u00b7pie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Wir wolln uns mal wieder am\u00fcsieren.", "tokens": ["Wir", "wolln", "uns", "mal", "wie\u00b7der", "a\u00b7m\u00fc\u00b7sie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Am Wedding ists totenstill und dunkel.", "tokens": ["Am", "Wed\u00b7ding", "ists", "to\u00b7tens\u00b7till", "und", "dun\u00b7kel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Keines Baumes Gefunkel, keines Traumes Gefunkel.", "tokens": ["Kei\u00b7nes", "Bau\u00b7mes", "Ge\u00b7fun\u00b7kel", ",", "kei\u00b7nes", "Trau\u00b7mes", "Ge\u00b7fun\u00b7kel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$,", "PIAT", "NN", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Keine Kohle, kein Licht ... im Zimmereck", "tokens": ["Kei\u00b7ne", "Koh\u00b7le", ",", "kein", "Licht", "...", "im", "Zim\u00b7me\u00b7reck"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$(", "APPRART", "NN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Liegt der Mann besoffen im Dreck.", "tokens": ["Liegt", "der", "Mann", "be\u00b7sof\u00b7fen", "im", "Dreck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Kein Geld \u2013 keine Welt, kein Held zum lieben ...", "tokens": ["Kein", "Geld", "\u2013", "kei\u00b7ne", "Welt", ",", "kein", "Held", "zum", "lie\u00b7ben", "..."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "PIAT", "NN", "$,", "PIAT", "NN", "APPRART", "ADJA", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Von sieben Kindern sind zwei geblieben,", "tokens": ["Von", "sie\u00b7ben", "Kin\u00b7dern", "sind", "zwei", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "CARD", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ohne Hemd auf der Streu, rachitisch und b\u00f6se.", "tokens": ["Oh\u00b7ne", "Hemd", "auf", "der", "Streu", ",", "ra\u00b7chi\u00b7tisch", "und", "b\u00f6\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Sie hungern \u2013 und fr\u00e4ssen ihr eignes Gekr\u00f6se.", "tokens": ["Sie", "hun\u00b7gern", "\u2013", "und", "fr\u00e4s\u00b7sen", "ihr", "eig\u00b7nes", "Ge\u00b7kr\u00f6\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.9": {"text": "Zwei magre Nutten im Haustor frieren:", "tokens": ["Zwei", "mag\u00b7re", "Nut\u00b7ten", "im", "Haus\u00b7tor", "frie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Wir wolln uns mal wieder am\u00fcsieren.", "tokens": ["Wir", "wolln", "uns", "mal", "wie\u00b7der", "a\u00b7m\u00fc\u00b7sie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Es schneit, es st\u00fcrmt. Eine Stimme schreit: Halt ...", "tokens": ["Es", "schneit", ",", "es", "st\u00fcrmt", ".", "Ei\u00b7ne", "Stim\u00b7me", "schreit", ":", "Halt", "..."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "ART", "NN", "VVFIN", "$.", "NN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00dcber die D\u00e4cher t\u00fcrmt eine dunkle Gestalt ...", "tokens": ["\u00dc\u00b7ber", "die", "D\u00e4\u00b7cher", "t\u00fcrmt", "ei\u00b7ne", "dunk\u00b7le", "Ge\u00b7stalt", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Die Blicke brennen, mit letzter Kraft", "tokens": ["Die", "Bli\u00b7cke", "bren\u00b7nen", ",", "mit", "letz\u00b7ter", "Kraft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Umspannt die Hand einen Fahnenschaft.", "tokens": ["Um\u00b7spannt", "die", "Hand", "ei\u00b7nen", "Fah\u00b7nen\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die Fahne vom neunten November, bedreckt,", "tokens": ["Die", "Fah\u00b7ne", "vom", "neun\u00b7ten", "No\u00b7vem\u00b7ber", ",", "be\u00b7dreckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Er ist der letzte, der sie noch reckt ...", "tokens": ["Er", "ist", "der", "letz\u00b7te", ",", "der", "sie", "noch", "reckt", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "$,", "PRELS", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Zivilisten ... Soldaten ... tach tach tach ...", "tokens": ["Zi\u00b7vi\u00b7lis\u00b7ten", "...", "Sol\u00b7da\u00b7ten", "...", "tach", "tach", "tach", "..."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "FM.la", "FM.la", "FM.la", "$("], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Salvenfeuer ... ein Fall vom Dach ...", "tokens": ["Sal\u00b7ven\u00b7feu\u00b7er", "...", "ein", "Fall", "vom", "Dach", "..."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ART", "NN", "APPRART", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "Die deutsche Revolution ist tot ...", "tokens": ["Die", "deut\u00b7sche", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "ist", "tot", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Der weisse Schnee f\u00e4rbt sich blutrot ...", "tokens": ["Der", "weis\u00b7se", "Schnee", "f\u00e4rbt", "sich", "blut\u00b7rot", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die Gaslaternen flackern und stieren ...", "tokens": ["Die", "Gas\u00b7la\u00b7ter\u00b7nen", "fla\u00b7ckern", "und", "stie\u00b7ren", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "VVFIN", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Wir wolln uns mal wieder am\u00fcsieren ...", "tokens": ["Wir", "wolln", "uns", "mal", "wie\u00b7der", "a\u00b7m\u00fc\u00b7sie\u00b7ren", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}}}}