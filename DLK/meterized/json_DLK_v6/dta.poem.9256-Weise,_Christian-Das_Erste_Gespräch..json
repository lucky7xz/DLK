{"dta.poem.9256": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das Erste Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Allerliebstes Marili\u00dfgen", "tokens": ["Al\u00b7ler\u00b7liebs\u00b7tes", "Ma\u00b7ri\u00b7li\u00df\u00b7gen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gieb mir was ich w\u00fcnschen kan/", "tokens": ["Gieb", "mir", "was", "ich", "w\u00fcn\u00b7schen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PWS", "PPER", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nim ein gehorsam gr\u00fc\u00dfgen", "tokens": ["Und", "nim", "ein", "ge\u00b7hor\u00b7sam", "gr\u00fc\u00df\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "ART", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von demselben diener an/", "tokens": ["Von", "dem\u00b7sel\u00b7ben", "die\u00b7ner", "an", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welcher nichts auf dieser welt", "tokens": ["Wel\u00b7cher", "nichts", "auf", "die\u00b7ser", "welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAT", "PIS", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Uber deine freundschafft h\u00e4lt.", "tokens": ["U\u00b7ber", "dei\u00b7ne", "freund\u00b7schafft", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Zwar ich solte wohl bedencken", "tokens": ["Zwar", "ich", "sol\u00b7te", "wohl", "be\u00b7den\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VMFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer ich bin und wer du bist/", "tokens": ["Wer", "ich", "bin", "und", "wer", "du", "bist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "KON", "PWS", "PPER", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mein hertz nach einer lencken/", "tokens": ["Und", "mein", "hertz", "nach", "ei\u00b7ner", "len\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welche meines gleichen ist:", "tokens": ["Wel\u00b7che", "mei\u00b7nes", "glei\u00b7chen", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "ADJA", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch dein sch\u00f6ner tugend-schein", "tokens": ["Doch", "dein", "sch\u00f6\u00b7ner", "tu\u00b7gen\u00b7dschein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Heist mich ohne sorgen seyn.", "tokens": ["Heist", "mich", "oh\u00b7ne", "sor\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Denn wer sich verliebt will machen/", "tokens": ["Denn", "wer", "sich", "ver\u00b7liebt", "will", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "VVPP", "VMFIN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mu\u00df auf seines gleichen sehn;", "tokens": ["Mu\u00df", "auf", "sei\u00b7nes", "glei\u00b7chen", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch in blossen freundschaffts sachen", "tokens": ["Doch", "in", "blos\u00b7sen", "freund\u00b7schaffts", "sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kan es auch also geschehn/", "tokens": ["Kan", "es", "auch", "al\u00b7so", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ein schlecht und vornehm kind", "tokens": ["Da\u00df", "ein", "schlecht", "und", "vor\u00b7nehm", "kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "KON", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich zu gleicher gunst verbindt.", "tokens": ["Sich", "zu", "glei\u00b7cher", "gunst", "ver\u00b7bindt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Mach es wie die sonnenstrahlen/", "tokens": ["Mach", "es", "wie", "die", "son\u00b7nen\u00b7strah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn sie auf der blumen bahn", "tokens": ["Wenn", "sie", "auf", "der", "blu\u00b7men", "bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lilgen und narcissen mahlen/", "tokens": ["Lil\u00b7gen", "und", "nar\u00b7cis\u00b7sen", "mah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schaun sie auch ein kleeblat an:", "tokens": ["Schaun", "sie", "auch", "ein", "klee\u00b7blat", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Drum la\u00df mich/ mein sonnenschein/", "tokens": ["Drum", "la\u00df", "mich", "/", "mein", "son\u00b7nen\u00b7schein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$(", "PPOSAT", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Dein geringes kleeblat seyn.", "tokens": ["Dein", "ge\u00b7rin\u00b7ges", "klee\u00b7blat", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Wilstu mich also erfreuen/", "tokens": ["Wils\u00b7tu", "mich", "al\u00b7so", "er\u00b7freu\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "G\u00f6nstu mir die f\u00fcsse rast/", "tokens": ["G\u00f6ns\u00b7tu", "mir", "die", "f\u00fcs\u00b7se", "rast", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach so wird dichs nicht gereuen", "tokens": ["Ach", "so", "wird", "dichs", "nicht", "ge\u00b7reu\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "VAFIN", "PIS", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df du mich zum diener hast;", "tokens": ["Da\u00df", "du", "mich", "zum", "die\u00b7ner", "hast", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "PDS", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mir beliebt der tugend licht/", "tokens": ["Mir", "be\u00b7liebt", "der", "tu\u00b7gend", "licht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und die falschheit acht ich nicht.", "tokens": ["Und", "die", "falschheit", "acht", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "CARD", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "6. Nun wolan soll ich erkennen/", "tokens": ["Nun", "wo\u00b7lan", "soll", "ich", "er\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich mich ohn unterla\u00df", "tokens": ["Da\u00df", "ich", "mich", "ohn", "un\u00b7ter\u00b7la\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "D\u00fcrffte deinen diener nennen/", "tokens": ["D\u00fcrff\u00b7te", "dei\u00b7nen", "die\u00b7ner", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seelgen so befiehl mir was/", "tokens": ["Seel\u00b7gen", "so", "be\u00b7fiehl", "mir", "was", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "PPER", "PIS", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn ich schwere dir allein", "tokens": ["Denn", "ich", "schwe\u00b7re", "dir", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ich fromm und treu will seyn.", "tokens": ["Da\u00df", "ich", "fromm", "und", "treu", "will", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}