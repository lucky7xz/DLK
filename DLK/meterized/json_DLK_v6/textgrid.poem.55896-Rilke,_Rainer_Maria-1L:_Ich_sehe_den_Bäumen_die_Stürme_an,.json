{"textgrid.poem.55896": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich sehe den B\u00e4umen die St\u00fcrme an,", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich sehe den B\u00e4umen die St\u00fcrme an,", "tokens": ["Ich", "se\u00b7he", "den", "B\u00e4u\u00b7men", "die", "St\u00fcr\u00b7me", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "die aus laugewordenen Tagen", "tokens": ["die", "aus", "lau\u00b7ge\u00b7wor\u00b7de\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "an meine \u00e4ngstlichen Fenster schlagen,", "tokens": ["an", "mei\u00b7ne", "\u00e4ngst\u00b7li\u00b7chen", "Fens\u00b7ter", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und h\u00f6re die Fernen Dinge sagen,", "tokens": ["und", "h\u00f6\u00b7re", "die", "Fer\u00b7nen", "Din\u00b7ge", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "die ich nicht ohne Freund ertragen,", "tokens": ["die", "ich", "nicht", "oh\u00b7ne", "Freund", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "nicht ohne Schwester lieben kann.", "tokens": ["nicht", "oh\u00b7ne", "Schwes\u00b7ter", "lie\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da geht der Sturm, ein Umgestalter,", "tokens": ["Da", "geht", "der", "Sturm", ",", "ein", "Um\u00b7ge\u00b7stal\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "geht durch den Wald und durch die Zeit,", "tokens": ["geht", "durch", "den", "Wald", "und", "durch", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und alles ist wie ohne Alter:", "tokens": ["und", "al\u00b7les", "ist", "wie", "oh\u00b7ne", "Al\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die Landschaft, wie ein Vers im Psalter,", "tokens": ["die", "Land\u00b7schaft", ",", "wie", "ein", "Vers", "im", "Psal\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ist Ernst und Wucht und Ewigkeit.", "tokens": ["ist", "Ernst", "und", "Wucht", "und", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie ist das klein, womit wir ringen,", "tokens": ["Wie", "ist", "das", "klein", ",", "wo\u00b7mit", "wir", "rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "was mit uns ringt, wie ist das gro\u00df;", "tokens": ["was", "mit", "uns", "ringt", ",", "wie", "ist", "das", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVFIN", "$,", "PWAV", "VAFIN", "ART", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "lie\u00dfen wir, \u00e4hnlicher den Dingen,", "tokens": ["lie\u00b7\u00dfen", "wir", ",", "\u00e4hn\u00b7li\u00b7cher", "den", "Din\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADJA", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "uns ", "tokens": ["uns"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "wir w\u00fcrden weit und namenlos.", "tokens": ["wir", "w\u00fcr\u00b7den", "weit", "und", "na\u00b7men\u00b7los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was wir besiegen, ist das Kleine,", "tokens": ["Was", "wir", "be\u00b7sie\u00b7gen", ",", "ist", "das", "Klei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und der Erfolg selbst macht uns klein.", "tokens": ["und", "der", "Er\u00b7folg", "selbst", "macht", "uns", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Ewige und Ungemeine", "tokens": ["Das", "E\u00b7wi\u00b7ge", "und", "Un\u00b7ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist der Engel, der den Ringern", "tokens": ["Das", "ist", "der", "En\u00b7gel", ",", "der", "den", "Rin\u00b7gern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "des Alten Testaments erschien:", "tokens": ["des", "Al\u00b7ten", "Tes\u00b7ta\u00b7ments", "er\u00b7schien", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wenn seiner Widersacher Sehnen", "tokens": ["wenn", "sei\u00b7ner", "Wi\u00b7der\u00b7sa\u00b7cher", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "im Kampfe sich metallen dehnen,", "tokens": ["im", "Kamp\u00b7fe", "sich", "me\u00b7tal\u00b7len", "deh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "f\u00fchlt er sie unter seinen Fingern", "tokens": ["f\u00fchlt", "er", "sie", "un\u00b7ter", "sei\u00b7nen", "Fin\u00b7gern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "wie Saiten tiefer Melodien.", "tokens": ["wie", "Sai\u00b7ten", "tie\u00b7fer", "Me\u00b7lo\u00b7dien", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wen dieser Engel \u00fcberwand,", "tokens": ["Wen", "die\u00b7ser", "En\u00b7gel", "\u00fc\u00b7ber\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "welcher so oft auf Kampf verzichtet,", "tokens": ["wel\u00b7cher", "so", "oft", "auf", "Kampf", "ver\u00b7zich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "ADV", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "und gro\u00df aus jener harten Hand,", "tokens": ["und", "gro\u00df", "aus", "je\u00b7ner", "har\u00b7ten", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die sich, wie formend, an ihn schmiegte.", "tokens": ["die", "sich", ",", "wie", "for\u00b7mend", ",", "an", "ihn", "schmieg\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "$,", "PWAV", "VVPP", "$,", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Siege laden ihn nicht ein.", "tokens": ["Die", "Sie\u00b7ge", "la\u00b7den", "ihn", "nicht", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Wachstum ist: der Tiefbesiegte", "tokens": ["Sein", "Wachs\u00b7tum", "ist", ":", "der", "Tief\u00b7be\u00b7sieg\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "$.", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "von immer Gr\u00f6\u00dferem zu sein.", "tokens": ["von", "im\u00b7mer", "Gr\u00f6\u00b7\u00dfe\u00b7rem", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}