{"textgrid.poem.39553": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein \u00fcber alle Ma\u00dfen", "tokens": ["Ein", "\u00fc\u00b7ber", "al\u00b7le", "Ma\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Abscheuliches Pasquill", "tokens": ["Ab\u00b7scheu\u00b7li\u00b7ches", "Pas\u00b7quill"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "H\u00e4ngt hier in allen Stra\u00dfen,", "tokens": ["H\u00e4ngt", "hier", "in", "al\u00b7len", "Stra\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da liest es wer nur will.", "tokens": ["Da", "liest", "es", "wer", "nur", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PWS", "ADV", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Man liest es in den Stuben,", "tokens": ["Man", "liest", "es", "in", "den", "Stu\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "An der ", "tokens": ["An", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Zwar kommt es von einem Buben,", "tokens": ["Zwar", "kommt", "es", "von", "ei\u00b7nem", "Bu\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Doch s\u00e4h' ich geh\u00e4ngt ihn nicht gern.", "tokens": ["Doch", "s\u00e4h'", "ich", "ge\u00b7h\u00e4ngt", "ihn", "nicht", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Das Carnaval ward verboten;", "tokens": ["Das", "Car\u00b7na\u00b7val", "ward", "ver\u00b7bo\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ich selbst war dr\u00fcber best\u00fcrzt.", "tokens": ["Ich", "selbst", "war", "dr\u00fc\u00b7ber", "be\u00b7st\u00fcrzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich berichtete kein' Anekdoten,", "tokens": ["Ich", "be\u00b7rich\u00b7te\u00b7te", "kein'", "A\u00b7nek\u00b7do\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ich habe die Lust nicht verk\u00fcrzt.", "tokens": ["Ich", "ha\u00b7be", "die", "Lust", "nicht", "ver\u00b7k\u00fcrzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Ich bin von dem allerentferntesten", "tokens": ["Ich", "bin", "von", "dem", "al\u00b7le\u00b7rent\u00b7fern\u00b7tes\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Antheile daran weit entfernt.", "tokens": ["An\u00b7thei\u00b7le", "da\u00b7ran", "weit", "ent\u00b7fernt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Verl\u00e4umder, die ausgelerntesten,", "tokens": ["Die", "Ver\u00b7l\u00e4um\u00b7der", ",", "die", "aus\u00b7ge\u00b7lern\u00b7tes\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "--+--+-+--", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sie haben's vom Satan gelernt.", "tokens": ["Sie", "ha\u00b7ben's", "vom", "Sa\u00b7tan", "ge\u00b7lernt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}