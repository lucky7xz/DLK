{"textgrid.poem.62255": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "[menschenliebe, Zauberwort]", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Menschenliebe, Zauberwort,", "tokens": ["Men\u00b7schen\u00b7lie\u00b7be", ",", "Zau\u00b7ber\u00b7wort", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das die Welt vereinet,", "tokens": ["Das", "die", "Welt", "ver\u00b7ei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Menschenha\u00df ist Seelenmord,", "tokens": ["Men\u00b7schen\u00b7ha\u00df", "ist", "See\u00b7len\u00b7mord", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Guter Engel weinet \u2013", "tokens": ["Gu\u00b7ter", "En\u00b7gel", "wei\u00b7net", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Leidenschaften wilde Glut", "tokens": ["Lei\u00b7den\u00b7schaf\u00b7ten", "wil\u00b7de", "Glut"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unbewu\u00dft verheeret, \u2013", "tokens": ["Un\u00b7be\u00b7wu\u00dft", "ver\u00b7hee\u00b7ret", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Unbewu\u00dft sie B\u00f6ses tut,", "tokens": ["Un\u00b7be\u00b7wu\u00dft", "sie", "B\u00f6\u00b7ses", "tut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis sie sich zerst\u00f6ret.", "tokens": ["Bis", "sie", "sich", "zer\u00b7st\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Sie ist nicht von Gott gesandt,", "tokens": ["Sie", "ist", "nicht", "von", "Gott", "ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der die G\u00fcte einst erfand,", "tokens": ["Der", "die", "G\u00fc\u00b7te", "einst", "er\u00b7fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flammen in den Abgrund bannt.", "tokens": ["Flam\u00b7men", "in", "den", "Ab\u00b7grund", "bannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sein und gut ist, was da ist \u2013", "tokens": ["Sein", "und", "gut", "ist", ",", "was", "da", "ist", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "KON", "ADJD", "VAFIN", "$,", "PRELS", "ADV", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser ist nur eine Frist,", "tokens": ["Un\u00b7ser", "ist", "nur", "ei\u00b7ne", "Frist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob man gut, ob b\u00f6se ist. \u2013", "tokens": ["Ob", "man", "gut", ",", "ob", "b\u00f6\u00b7se", "ist", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "ADJD", "$,", "KOUS", "ADJD", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}