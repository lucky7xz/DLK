{"textgrid.poem.49119": {"metadata": {"author": {"name": "R\u00f6ling, Johann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wilstu, da\u00df dein Thun und Sinnen", "genre": "verse", "period": "N.A.", "pub_year": 1656, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wilstu, da\u00df dein Thun und Sinnen", "tokens": ["Wils\u00b7tu", ",", "da\u00df", "dein", "Thun", "und", "Sin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PPOSAT", "NN", "KON", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Soll erw\u00fcnschten Gang gewinnen,", "tokens": ["Soll", "er\u00b7w\u00fcnschten", "Gang", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Stell es erst mit Gott in Rath;", "tokens": ["Stell", "es", "erst", "mit", "Gott", "in", "Rath", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Heist es der, so wird es gehen,", "tokens": ["Heist", "es", "der", ",", "so", "wird", "es", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "$,", "ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Spricht er Nein, so mu\u00df es stehen,", "tokens": ["Spricht", "er", "Nein", ",", "so", "mu\u00df", "es", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKANT", "$,", "ADV", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sein ist Beydes, Will und That.", "tokens": ["Sein", "ist", "Bey\u00b7des", ",", "Will", "und", "That", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "PIS", "$,", "VMFIN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Was ein Vogel sonder Fl\u00fcgel,", "tokens": ["Was", "ein", "Vo\u00b7gel", "son\u00b7der", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NE", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sonder Licht und Glanz ein Spiegel,", "tokens": ["Son\u00b7der", "Licht", "und", "Glanz", "ein", "Spie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ein Schiff ohn Ruder ist,", "tokens": ["Was", "ein", "Schiff", "ohn", "Ru\u00b7der", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was der Tag ohn Sonnen-Strahlen", "tokens": ["Was", "der", "Tag", "ohn", "Son\u00b7nen\u00b7Strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und was sonder Kern die Schalen,", "tokens": ["Und", "was", "son\u00b7der", "Kern", "die", "Scha\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist ein Werk, das ihn vermist.", "tokens": ["Ist", "ein", "Werk", ",", "das", "ihn", "ver\u00b7mist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und was magstu dir vertrauen?", "tokens": ["Und", "was", "mags\u00b7tu", "dir", "ver\u00b7trau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kanstu, was dir dient, erschauen?", "tokens": ["Kans\u00b7tu", ",", "was", "dir", "dient", ",", "er\u00b7schau\u00b7en", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist nicht b\u00f6ser Will dein Rath?", "tokens": ["Ist", "nicht", "b\u00f6\u00b7ser", "Will", "dein", "Rath", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "VMFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist nicht Unverstand dein F\u00fchrer,", "tokens": ["Ist", "nicht", "Un\u00b7ver\u00b7stand", "dein", "F\u00fch\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Noth und Ohnmacht dein Regierer,", "tokens": ["Noth", "und", "Ohn\u00b7macht", "dein", "Re\u00b7gie\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "S\u00fcnd' und Eitelkeit die That?", "tokens": ["S\u00fcnd'", "und", "Ei\u00b7tel\u00b7keit", "die", "That", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bistu nicht ein Kind der Erden?", "tokens": ["Bis\u00b7tu", "nicht", "ein", "Kind", "der", "Er\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mustu das nicht wieder werden?", "tokens": ["Mus\u00b7tu", "das", "nicht", "wie\u00b7der", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "PTKNEG", "ADV", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bistu nicht des Gl\u00fcckes Ball,", "tokens": ["Bis\u00b7tu", "nicht", "des", "Gl\u00fc\u00b7ckes", "Ball", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Gehege vieler Sorgen?", "tokens": ["Ein", "Ge\u00b7he\u00b7ge", "vie\u00b7ler", "Sor\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lebest immerfort auch morgen", "tokens": ["Le\u00b7best", "im\u00b7mer\u00b7fort", "auch", "mor\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und vergehst letzt wie ein Schall.", "tokens": ["Und", "ver\u00b7gehst", "letzt", "wie", "ein", "Schall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Gott nur wei\u00df, was dir ertr\u00e4glich", "tokens": ["Gott", "nur", "wei\u00df", ",", "was", "dir", "er\u00b7tr\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "VVFIN", "$,", "PWS", "PPER", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und so n\u00fctzlich, als beh\u00e4glich,", "tokens": ["Und", "so", "n\u00fctz\u00b7lich", ",", "als", "be\u00b7h\u00e4g\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$,", "KOUS", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So erw\u00fcnscht, als selig f\u00e4llt;", "tokens": ["So", "er\u00b7w\u00fcnscht", ",", "als", "se\u00b7lig", "f\u00e4llt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er ist, der dich hat gemachet,", "tokens": ["Er", "ist", ",", "der", "dich", "hat", "ge\u00b7ma\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Der dich kleidet und bewachet,", "tokens": ["Der", "dich", "klei\u00b7det", "und", "be\u00b7wa\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich beschirmet und erh\u00e4lt.", "tokens": ["Dich", "be\u00b7schir\u00b7met", "und", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sonder seiner G\u00fct und Gnade", "tokens": ["Son\u00b7der", "sei\u00b7ner", "G\u00fct", "und", "Gna\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist all, was du thust, dein Schade", "tokens": ["Ist", "all", ",", "was", "du", "thust", ",", "dein", "Scha\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PIAT", "$,", "PWS", "PPER", "VVFIN", "$,", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und nichts, als nur Midas Gut:", "tokens": ["Und", "nichts", ",", "als", "nur", "Mi\u00b7das", "Gut", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "KOUS", "ADV", "NE", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Geld must du zum Hunger wehlen,", "tokens": ["Geld", "must", "du", "zum", "Hun\u00b7ger", "weh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ehre zum Beschwer der Seelen,", "tokens": ["Eh\u00b7re", "zum", "Be\u00b7schwer", "der", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Klugheit zum verkehrten Muth.", "tokens": ["Klug\u00b7heit", "zum", "ver\u00b7kehr\u00b7ten", "Muth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Baue Schl\u00f6sser, setze Schrifften,", "tokens": ["Bau\u00b7e", "Schl\u00f6s\u00b7ser", ",", "set\u00b7ze", "Schriff\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df dir grosse Denkmahl stifften,", "tokens": ["La\u00df", "dir", "gros\u00b7se", "Denk\u00b7mahl", "stiff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohn ihn geht es Alles ein;", "tokens": ["Ohn", "ihn", "geht", "es", "Al\u00b7les", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VVFIN", "PPER", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hie wird dich die Krafft der H\u00f6llen,", "tokens": ["Hie", "wird", "dich", "die", "Krafft", "der", "H\u00f6l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dort die Zeit- und Welt-Macht f\u00e4llen,", "tokens": ["Dort", "die", "Zeit", "und", "Welt\u00b7Macht", "f\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "TRUNC", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hie dein Fleisch dein Tod selbst sein.", "tokens": ["Hie", "dein", "Fleisch", "dein", "Tod", "selbst", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PPOSAT", "NN", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Herr, ich bin weit zu geringe,", "tokens": ["Herr", ",", "ich", "bin", "weit", "zu", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADJD", "PTKZU", "ADJA", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df ich dich nach W\u00fcrden singe,", "tokens": ["Da\u00df", "ich", "dich", "nach", "W\u00fcr\u00b7den", "sin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df es, Liebster, dennoch seyn.", "tokens": ["La\u00df", "es", ",", "Liebs\u00b7ter", ",", "den\u00b7noch", "seyn", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "NN", "$,", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gehstu vor, so wird es gehen,", "tokens": ["Gehs\u00b7tu", "vor", ",", "so", "wird", "es", "ge\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Stehstu ab, so soll es stehen,", "tokens": ["Steh\u00b7stu", "ab", ",", "so", "soll", "es", "ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "ADV", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "All dein Nein und Ja ist mein.", "tokens": ["All", "dein", "Nein", "und", "Ja", "ist", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "KON", "NN", "VAFIN", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}