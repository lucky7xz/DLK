{"textgrid.poem.24047": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Christoph, Rupprecht, Nikolaus", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich kenn drei gute, deutsche Geselln", "tokens": ["Ich", "kenn", "drei", "gu\u00b7te", ",", "deut\u00b7sche", "Ge\u00b7selln"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mit gro\u00dfen H\u00e4nden und Beinen schnelln;", "tokens": ["Mit", "gro\u00b7\u00dfen", "H\u00e4n\u00b7den", "und", "Bei\u00b7nen", "schnelln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit dicken S\u00e4cken auf breitem Buckel", "tokens": ["Mit", "di\u00b7cken", "S\u00e4\u00b7cken", "auf", "brei\u00b7tem", "Bu\u00b7ckel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Stampfen sie eilig durchs Land mit Gehuckel;", "tokens": ["Stamp\u00b7fen", "sie", "ei\u00b7lig", "durchs", "Land", "mit", "Ge\u00b7hu\u00b7ckel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPRART", "NN", "APPR", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Haben Eis im Bart", "tokens": ["Ha\u00b7ben", "Eis", "im", "Bart"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NN", "APPRART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Und grimmige Art,", "tokens": ["Und", "grim\u00b7mi\u00b7ge", "Art", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Aber Augen gar milde;", "tokens": ["A\u00b7ber", "Au\u00b7gen", "gar", "mil\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ADJD", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "F\u00fchrn Aepfel und N\u00fcsse und Kuchen im Schilde", "tokens": ["F\u00fchrn", "A\u00b7e\u00b7pfel", "und", "N\u00fcs\u00b7se", "und", "Ku\u00b7chen", "im", "Schil\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "KON", "NN", "KON", "NN", "APPRART", "NN"], "meter": "-----+--+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Und schleppen und schleppen im Huckepack", "tokens": ["Und", "schlep\u00b7pen", "und", "schlep\u00b7pen", "im", "Hu\u00b7cke\u00b7pack"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Himmeltausendsch\u00f6ne Sachen im Sack.", "tokens": ["Him\u00b7mel\u00b7tau\u00b7send\u00b7sch\u00f6\u00b7ne", "Sa\u00b7chen", "im", "Sack", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.2": {"line.1": {"text": "All drei sind fr\u00fcher Heiden gewesen.", "tokens": ["All", "drei", "sind", "fr\u00fc\u00b7her", "Hei\u00b7den", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "VAFIN", "ADJD", "NN", "VAPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der erst hei\u00dft Christoph: Auserlesen", "tokens": ["Der", "erst", "hei\u00dft", "Chris\u00b7toph", ":", "Au\u00b7ser\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADV", "VVFIN", "NE", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hat er in einer eisgrimmigen Nacht", "tokens": ["Hat", "er", "in", "ei\u00b7ner", "eis\u00b7grim\u00b7mi\u00b7gen", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Christkindel \u00fcbers Wildwasser gebracht.", "tokens": ["Das", "Christ\u00b7kin\u00b7del", "\u00fc\u00b7bers", "Wild\u00b7was\u00b7ser", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Rupprecht der zweite ist genannt:", "tokens": ["Rup\u00b7precht", "der", "zwei\u00b7te", "ist", "ge\u00b7nannt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der fuhr voreinsten \u00fcbers Land", "tokens": ["Der", "fuhr", "vor\u00b7e\u00b7ins\u00b7ten", "\u00fc\u00b7bers", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "VVFIN", "APPRART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Tief n\u00e4chten in Gespenstergraus", "tokens": ["Tief", "n\u00e4ch\u00b7ten", "in", "Ge\u00b7spens\u00b7ter\u00b7graus"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Als Heidengott. Den Nikolaus,", "tokens": ["Als", "Hei\u00b7den\u00b7gott", ".", "Den", "Ni\u00b7ko\u00b7laus", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als wie der dritte ist gehei\u00dfen,", "tokens": ["Als", "wie", "der", "drit\u00b7te", "ist", "ge\u00b7hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Th\u00e4t man als einen Bischof preisen.", "tokens": ["Th\u00e4t", "man", "als", "ei\u00b7nen", "Bi\u00b7schof", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Das ist nun all Legend und M\u00e4r.", "tokens": ["Das", "ist", "nun", "all", "Le\u00b7gend", "und", "M\u00e4r."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PDS", "VAFIN", "ADV", "PIAT", "NN", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ich \u00fcbernehme nicht Gw\u00e4hr,", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7neh\u00b7me", "nicht", "Gw\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da\u00df just genau es so gewesen.", "tokens": ["Da\u00df", "just", "ge\u00b7nau", "es", "so", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "PPER", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Habs nicht gesehn, habs nur gelesen.", "tokens": ["Habs", "nicht", "ge\u00b7sehn", ",", "habs", "nur", "ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "VVPP", "$,", "NE", "ADV", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Auf Schildereien jedermann", "tokens": ["Auf", "Schil\u00b7de\u00b7rei\u00b7en", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die dreie freilich sehen kann.", "tokens": ["Die", "drei\u00b7e", "frei\u00b7lich", "se\u00b7hen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da ist der Rupprecht dick beschneet", "tokens": ["Da", "ist", "der", "Rup\u00b7precht", "dick", "be\u00b7schneet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und derb gestiefelt f\u00fcrder geht.", "tokens": ["Und", "derb", "ge\u00b7stie\u00b7felt", "f\u00fcr\u00b7der", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Drei Aepfel tr\u00e4gt der Nikolaus,", "tokens": ["Drei", "A\u00b7e\u00b7pfel", "tr\u00e4gt", "der", "Ni\u00b7ko\u00b7laus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Sieht v\u00e4terlich und ernsthaft aus.", "tokens": ["Sieht", "v\u00e4\u00b7ter\u00b7lich", "und", "ernst\u00b7haft", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und Christophor im langen Bar", "tokens": ["Und", "Chris\u00b7to\u00b7phor", "im", "lan\u00b7gen", "Bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ist heidenm\u00e4\u00dfig dick behaart,", "tokens": ["Ist", "hei\u00b7den\u00b7m\u00e4\u00b7\u00dfig", "dick", "be\u00b7haart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Hat einen roten Mantel an", "tokens": ["Hat", "ei\u00b7nen", "ro\u00b7ten", "Man\u00b7tel", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und ist ansonst ein nackter Mann.", "tokens": ["Und", "ist", "an\u00b7sonst", "ein", "nack\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die dreie nun, da\u00df ihr es wi\u00dft,", "tokens": ["Die", "drei\u00b7e", "nun", ",", "da\u00df", "ihr", "es", "wi\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verehre ich als Mensch und Christ.", "tokens": ["Ver\u00b7eh\u00b7re", "ich", "als", "Mensch", "und", "Christ", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sind so lieb und ungeschlacht", "tokens": ["Sie", "sind", "so", "lieb", "und", "un\u00b7ge\u00b7schlacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ganz aus deutschem Mark gemacht.", "tokens": ["Und", "ganz", "aus", "deut\u00b7schem", "Mark", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mildherzig rauh, kratzhaarig lind,", "tokens": ["Mild\u00b7her\u00b7zig", "rauh", ",", "kratz\u00b7haa\u00b7rig", "lind", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des deutschen Gottes Ingesind.", "tokens": ["Des", "deut\u00b7schen", "Got\u00b7tes", "In\u00b7ge\u00b7sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die guten Knechte, reichen Herrn!", "tokens": ["Die", "gu\u00b7ten", "Knech\u00b7te", ",", "rei\u00b7chen", "Herrn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie dienen gern und schenken gern,", "tokens": ["Sie", "die\u00b7nen", "gern", "und", "schen\u00b7ken", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wolln keinen Dank, wolln keinen Lohn,", "tokens": ["Wolln", "kei\u00b7nen", "Dank", ",", "wolln", "kei\u00b7nen", "Lohn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "$,", "PWAV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind in sich selbst bedanklohnt schon.", "tokens": ["Sind", "in", "sich", "selbst", "be\u00b7dank\u00b7lohnt", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PRF", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Gr\u00fc\u00df Gott ihr dreie miteinand", "tokens": ["Gr\u00fc\u00df", "Gott", "ihr", "drei\u00b7e", "mi\u00b7tei\u00b7nand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "NN", "PPOSAT", "CARD", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Im lieben weiten deutschen Land!", "tokens": ["Im", "lie\u00b7ben", "wei\u00b7ten", "deut\u00b7schen", "Land", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Christoph, Rupprecht, Nikolaus!", "tokens": ["Chris\u00b7toph", ",", "Rup\u00b7precht", ",", "Ni\u00b7ko\u00b7laus", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sch\u00fcttet eure S\u00e4cke aus,", "tokens": ["Sch\u00fct\u00b7tet", "eu\u00b7re", "S\u00e4\u00b7cke", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sch\u00fcttet sie mit Lachen,", "tokens": ["Sch\u00fct\u00b7tet", "sie", "mit", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Blickt mit hellen Augen drein", "tokens": ["Blickt", "mit", "hel\u00b7len", "Au\u00b7gen", "drein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und la\u00dft wohl gesegnet sein", "tokens": ["Und", "la\u00dft", "wohl", "ge\u00b7seg\u00b7net", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "ADV", "VVPP", "VAINF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Eure Siebensachen.", "tokens": ["Eu\u00b7re", "Sie\u00b7ben\u00b7sa\u00b7chen", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}