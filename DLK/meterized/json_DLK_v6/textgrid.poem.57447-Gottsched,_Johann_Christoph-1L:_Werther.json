{"textgrid.poem.57447": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Werther ", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Werther ", "tokens": ["Wert\u00b7her"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Meister in der Kunst zu loben,", "tokens": ["Meis\u00b7ter", "in", "der", "Kunst", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie bereits aus hundert Proben,", "tokens": ["Wie", "be\u00b7reits", "aus", "hun\u00b7dert", "Pro\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die halb Deutschland liest, erscheint:", "tokens": ["Die", "halb", "Deutschland", "liest", ",", "er\u00b7scheint", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Lehre mich doch, wie man singet,", "tokens": ["Leh\u00b7re", "mich", "doch", ",", "wie", "man", "sin\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man Hertzen an sich zieht:", "tokens": ["Da\u00df", "man", "Hert\u00b7zen", "an", "sich", "zieht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Sprich, wie macht man solch ein Lied,", "tokens": ["Sprich", ",", "wie", "macht", "man", "solch", "ein", "Lied", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWAV", "VVFIN", "PIS", "PIAT", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Das gleich deinen Oden klinget!", "tokens": ["Das", "gleich", "dei\u00b7nen", "O\u00b7den", "klin\u00b7get", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Singe, sprichst du, k\u00fchn und neu,", "tokens": ["Sin\u00b7ge", ",", "sprichst", "du", ",", "k\u00fchn", "und", "neu", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Klebe nicht am tiefen Staube;", "tokens": ["Kle\u00b7be", "nicht", "am", "tie\u00b7fen", "Stau\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dichte frey, doch da\u00df mans glaube,", "tokens": ["Dich\u00b7te", "frey", ",", "doch", "da\u00df", "mans", "glau\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ADV", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Einfall gr\u00fcndlich sey;", "tokens": ["Und", "der", "Ein\u00b7fall", "gr\u00fcnd\u00b7lich", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeig ein m\u00e4nnlich-edles Wesen;", "tokens": ["Zeig", "ein", "m\u00e4nn\u00b7lich\u00b7ed\u00b7les", "We\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schreibe geistreich, kurtz und rein:", "tokens": ["Schrei\u00b7be", "geist\u00b7reich", ",", "kurtz", "und", "rein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn wirst du ein Dichter seyn,", "tokens": ["Denn", "wirst", "du", "ein", "Dich\u00b7ter", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "VAINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Den die Welt mit Lust wird lesen.", "tokens": ["Den", "die", "Welt", "mit", "Lust", "wird", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Hoer ich nicht Amphions Sohn", "tokens": ["Hoer", "ich", "nicht", "Am\u00b7phi\u00b7ons", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "PTKNEG", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seine Zauber-Kunst beschreiben?", "tokens": ["Sei\u00b7ne", "Zau\u00b7ber\u00b7Kunst", "be\u00b7schrei\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ists mein ", "tokens": ["Ists", "mein"], "token_info": ["word", "word"], "pos": ["NE", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Ja er ists. Man kennt den Thon.", "tokens": ["Ja", "er", "ists", ".", "Man", "kennt", "den", "Thon", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VAFIN", "$.", "PIS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Regen und entz\u00fccken mich;", "tokens": ["Re\u00b7gen", "und", "ent\u00b7z\u00fc\u00b7cken", "mich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Deutschlands Orpheus zeiget sich,", "tokens": ["Deutschlands", "Or\u00b7pheus", "zei\u00b7get", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PRF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und beweget Stein und B\u00e4ume.", "tokens": ["Und", "be\u00b7we\u00b7get", "Stein", "und", "B\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Freund, dein Rath ist wundersch\u00f6n:", "tokens": ["Freund", ",", "dein", "Rath", "ist", "wun\u00b7der\u00b7sch\u00f6n", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch was hilft dein Unterrichten?", "tokens": ["Doch", "was", "hilft", "dein", "Un\u00b7ter\u00b7rich\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gib mir auch die Krafft, im Dichten,", "tokens": ["Gib", "mir", "auch", "die", "Krafft", ",", "im", "Dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deinen Spuren nachzugehn.", "tokens": ["Dei\u00b7nen", "Spu\u00b7ren", "nach\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVIZU", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sprich, wie mach ichs, wenn ich singe,", "tokens": ["Sprich", ",", "wie", "mach", "ichs", ",", "wenn", "ich", "sin\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWAV", "VVFIN", "PIS", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df mein Lied zwar hoch und neu,", "tokens": ["Da\u00df", "mein", "Lied", "zwar", "hoch", "und", "neu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "M\u00e4nnlich, rein und edel sey;", "tokens": ["M\u00e4nn\u00b7lich", ",", "rein", "und", "e\u00b7del", "sey", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Doch nicht unnat\u00fcrlich klinge?", "tokens": ["Doch", "nicht", "un\u00b7na\u00b7t\u00fcr\u00b7lich", "klin\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Meine Geister sind zu schwach;", "tokens": ["Mei\u00b7ne", "Geis\u00b7ter", "sind", "zu", "schwach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Regt dort Pindar sein Gefieder,", "tokens": ["Regt", "dort", "Pin\u00b7dar", "sein", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Folgt Horatz durch k\u00fchne Lieder", "tokens": ["Folgt", "Ho\u00b7ratz", "durch", "k\u00fch\u00b7ne", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "ADJA", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "Diesem Adler gl\u00fccklich nach.", "tokens": ["Die\u00b7sem", "Ad\u00b7ler", "gl\u00fcck\u00b7lich", "nach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Seidel steigt mit eignen Fl\u00fcgeln,", "tokens": ["Sei\u00b7del", "steigt", "mit", "eig\u00b7nen", "Fl\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gottsched, der sie k\u00fcnsteln mu\u00df,", "tokens": ["Gott\u00b7sched", ",", "der", "sie", "k\u00fcns\u00b7teln", "mu\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Mag sich an des Icarus", "tokens": ["Mag", "sich", "an", "des", "I\u00b7ca\u00b7rus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "Weltbekanntem Falle spiegeln.", "tokens": ["Welt\u00b7be\u00b7kann\u00b7tem", "Fal\u00b7le", "spie\u00b7geln", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Waer Euterpe nur geneigt,", "tokens": ["Waer", "Eu\u00b7ter\u00b7pe", "nur", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Mir sowohl als dir zu dienen;", "tokens": ["Mir", "so\u00b7wohl", "als", "dir", "zu", "die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "KOUS", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie sie dir denn j\u00fcngst erschienen,", "tokens": ["Wie", "sie", "dir", "denn", "j\u00fcngst", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dir alle Gunst bezeugt:", "tokens": ["Und", "dir", "al\u00b7le", "Gunst", "be\u00b7zeugt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "O wie sollten Reim und Seyten,", "tokens": ["O", "wie", "soll\u00b7ten", "Reim", "und", "Sey\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch den allerz\u00e4rtsten Klang,", "tokens": ["Durch", "den", "al\u00b7ler\u00b7z\u00e4rts\u00b7ten", "Klang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Durch den sch\u00f6nsten Lobgesang,", "tokens": ["Durch", "den", "sch\u00f6ns\u00b7ten", "Lob\u00b7ge\u00b7sang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mit dir um die Lorbern streiten!", "tokens": ["Mit", "dir", "um", "die", "Lor\u00b7bern", "strei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch die Muse kennt mich nicht,", "tokens": ["Doch", "die", "Mu\u00b7se", "kennt", "mich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ph\u00f6bus g\u00f6nnt mir keine Triebe:", "tokens": ["Ph\u00f6\u00b7bus", "g\u00f6nnt", "mir", "kei\u00b7ne", "Trie\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6re denn, was Hertz und Liebe", "tokens": ["H\u00f6\u00b7re", "denn", ",", "was", "Hertz", "und", "Lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "PWS", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sonder Kunst und Farben spricht.", "tokens": ["Son\u00b7der", "Kunst", "und", "Far\u00b7ben", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil dein Kiel auch schlechte Dinge", "tokens": ["Weil", "dein", "Kiel", "auch", "schlech\u00b7te", "Din\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der Vergessenheit entzieht;", "tokens": ["Der", "Ver\u00b7ges\u00b7sen\u00b7heit", "ent\u00b7zieht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "So vergi\u00df nicht solch ein Lied,", "tokens": ["So", "ver\u00b7gi\u00df", "nicht", "solch", "ein", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PTKNEG", "PIAT", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Das von Deinem Freunde singe.", "tokens": ["Das", "von", "Dei\u00b7nem", "Freun\u00b7de", "sin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}