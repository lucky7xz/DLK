{"textgrid.poem.46109": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich empfind nun in meiner brust", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich empfind nun in meiner brust", "tokens": ["Ich", "emp\u00b7find", "nun", "in", "mei\u00b7ner", "brust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sich ein verlangen anzuz\u00fcnden,", "tokens": ["sich", "ein", "ver\u00b7lan\u00b7gen", "an\u00b7zu\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "ADJA", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "das treibet mich mit gro\u00dfem lust", "tokens": ["das", "trei\u00b7bet", "mich", "mit", "gro\u00b7\u00dfem", "lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein neues lobgesang zu finden.", "tokens": ["ein", "neu\u00b7es", "lob\u00b7ge\u00b7sang", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Neid, unerfahrenheit, misgunst", "tokens": ["Neid", ",", "un\u00b7er\u00b7fah\u00b7ren\u00b7heit", ",", "mis\u00b7gunst"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ADJD", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bem\u00fchen sich, nach ihrem willen,", "tokens": ["be\u00b7m\u00fc\u00b7hen", "sich", ",", "nach", "ih\u00b7rem", "wil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "doch finden, meine stim zu stillen,", "tokens": ["doch", "fin\u00b7den", ",", "mei\u00b7ne", "stim", "zu", "stil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "sie weder gnug gewalt noch kunst.", "tokens": ["sie", "we\u00b7der", "gnug", "ge\u00b7walt", "noch", "kunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ADV", "ADJD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und deren tugend gro\u00dfe ehr", "tokens": ["Und", "de\u00b7ren", "tu\u00b7gend", "gro\u00b7\u00dfe", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PRELAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von deren meine saiten klingen,", "tokens": ["von", "de\u00b7ren", "mei\u00b7ne", "sai\u00b7ten", "klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "erleuchtet mein gem\u00fct so sehr,", "tokens": ["er\u00b7leuch\u00b7tet", "mein", "ge\u00b7m\u00fct", "so", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "da\u00df ich kan mutiglich fortsingen.", "tokens": ["da\u00df", "ich", "kan", "mu\u00b7tig\u00b7lich", "fort\u00b7sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wann niemand schon so toll und grob,", "tokens": ["Wann", "nie\u00b7mand", "schon", "so", "toll", "und", "grob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der deinen namen nicht wolt preisen,", "tokens": ["der", "dei\u00b7nen", "na\u00b7men", "nicht", "wolt", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PTKNEG", "VMFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "kan niemand doch dein hohes lob,", "tokens": ["kan", "nie\u00b7mand", "doch", "dein", "ho\u00b7hes", "lob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "o Hohenloe, recht gnug ausweisen.", "tokens": ["o", "Ho\u00b7hen\u00b7loe", ",", "recht", "gnug", "aus\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM", "NE", "$,", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Darum ich, durch Apollons glanz", "tokens": ["Da\u00b7rum", "ich", ",", "durch", "A\u00b7pol\u00b7lons", "glanz"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "PPER", "$,", "APPR", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und durch der Musen gnad beleitet,", "tokens": ["und", "durch", "der", "Mu\u00b7sen", "gnad", "be\u00b7lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "f\u00fcr dich mit ihnen hab bereitet", "tokens": ["f\u00fcr", "dich", "mit", "ih\u00b7nen", "hab", "be\u00b7rei\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "APPR", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "den w\u00fcrdigst gr\u00fcnen lorberkranz,", "tokens": ["den", "w\u00fcr\u00b7digst", "gr\u00fc\u00b7nen", "lor\u00b7ber\u00b7kranz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der auch mit nicht geringerm schein", "tokens": ["Der", "auch", "mit", "nicht", "ge\u00b7rin\u00b7germ", "schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "wird unverwelklich dein haupt kr\u00f6nen,", "tokens": ["wird", "un\u00b7ver\u00b7wel\u00b7klich", "dein", "haupt", "kr\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "wie deine seel und leib allein", "tokens": ["wie", "dei\u00b7ne", "seel", "und", "leib", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "die lasterhafte welt besch\u00f6nen.", "tokens": ["die", "las\u00b7ter\u00b7haf\u00b7te", "welt", "be\u00b7sch\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wan deine thaten und weisheit", "tokens": ["Wan", "dei\u00b7ne", "tha\u00b7ten", "und", "weis\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "VVFIN", "KON", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "zu deinem ruhm nicht gnugsam w\u00e4ren,", "tokens": ["zu", "dei\u00b7nem", "ruhm", "nicht", "gnug\u00b7sam", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wolt ich auch deines bluts hochheit", "tokens": ["wolt", "ich", "auch", "dei\u00b7nes", "bluts", "hoch\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "vermehren, dein lob zu vermehren;", "tokens": ["ver\u00b7meh\u00b7ren", ",", "dein", "lob", "zu", "ver\u00b7meh\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVINF", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Jedoch gleichwie ein cirkul rund", "tokens": ["Je\u00b7doch", "gleich\u00b7wie", "ein", "cir\u00b7kul", "rund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ART", "NN", "ADJD"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "wird ganz vollkommen umgewendet", "tokens": ["wird", "ganz", "voll\u00b7kom\u00b7men", "um\u00b7ge\u00b7wen\u00b7det"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und endlos sich in sich selbs endet,", "tokens": ["und", "end\u00b7los", "sich", "in", "sich", "selbs", "en\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "APPR", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "also wird auch dein lob recht kund.", "tokens": ["al\u00b7so", "wird", "auch", "dein", "lob", "recht", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.9": {"text": "Dan warlich der vor\u00e4lter preis", "tokens": ["Dan", "war\u00b7lich", "der", "vor\u00b7\u00e4l\u00b7ter", "preis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "sehr wenig den nachk\u00f6mling zieret,", "tokens": ["sehr", "we\u00b7nig", "den", "nach\u00b7k\u00f6m\u00b7ling", "zie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "wa nicht die tugend gleicherweis", "tokens": ["wa", "nicht", "die", "tu\u00b7gend", "glei\u00b7cher\u00b7weis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["XY", "PTKNEG", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "sie in der elter tritten f\u00fchret.", "tokens": ["sie", "in", "der", "el\u00b7ter", "trit\u00b7ten", "f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Zwar es bedarf sich auch gar nicht", "tokens": ["Zwar", "es", "be\u00b7darf", "sich", "auch", "gar", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PRF", "ADV", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "deintwegen zu pindarisieren,", "tokens": ["de\u00b7int\u00b7we\u00b7gen", "zu", "pin\u00b7da\u00b7ri\u00b7sie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "PTKZU", "VVINF", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "aus einem alten lobgedicht", "tokens": ["aus", "ei\u00b7nem", "al\u00b7ten", "lob\u00b7ge\u00b7dicht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein neues lob zu destillieren,", "tokens": ["ein", "neu\u00b7es", "lob", "zu", "des\u00b7til\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dan dein verdienst selbs, der schon lang", "tokens": ["Dan", "dein", "ver\u00b7dienst", "selbs", ",", "der", "schon", "lang"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "VVFIN", "ADV", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die g\u00f6tter und die welt erquicket,", "tokens": ["die", "g\u00f6t\u00b7ter", "und", "die", "welt", "er\u00b7quic\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "hat die neun schwestern selbs begl\u00fccket", "tokens": ["hat", "die", "neun", "schwes\u00b7tern", "selbs", "be\u00b7gl\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "CARD", "VVFIN", "ADV", "VVFIN"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.8": {"text": "mit einem wahren lobgesang;", "tokens": ["mit", "ei\u00b7nem", "wah\u00b7ren", "lob\u00b7ge\u00b7sang", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wan deiner tugend klare macht", "tokens": ["Wan", "dei\u00b7ner", "tu\u00b7gend", "kla\u00b7re", "macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "ADJA", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "ganz lieblich ihr gesicht ergetzet,", "tokens": ["ganz", "lieb\u00b7lich", "ihr", "ge\u00b7sicht", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "recht wie das firmament zu nacht", "tokens": ["recht", "wie", "das", "fir\u00b7ma\u00b7ment", "zu", "nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "PDS", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "mit sternen leuchtet \u00fcbersetzet.", "tokens": ["mit", "ster\u00b7nen", "leuch\u00b7tet", "\u00fc\u00b7bers\u00b7et\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Achilles war hoch von statur,", "tokens": ["A\u00b7chil\u00b7les", "war", "hoch", "von", "sta\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "in aller kurzweil wol ge\u00fcbet,", "tokens": ["in", "al\u00b7ler", "kurz\u00b7weil", "wol", "ge\u00b7\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sch\u00f6n, lustig, freindlich von natur,", "tokens": ["sch\u00f6n", ",", "lus\u00b7tig", ",", "freind\u00b7lich", "von", "na\u00b7tur", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "von frauen billich auch geliebet;", "tokens": ["von", "frau\u00b7en", "bil\u00b7lich", "auch", "ge\u00b7lie\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein aber! w\u00fcrd man noch wol heut", "tokens": ["Mein", "a\u00b7ber", "!", "w\u00fcrd", "man", "noch", "wol", "heut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADV", "$.", "VAFIN", "PIS", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "von ihm so vil gedenkens tragen,", "tokens": ["von", "ihm", "so", "vil", "ge\u00b7den\u00b7kens", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "wan er nicht herzhaft sich zu wagen", "tokens": ["wan", "er", "nicht", "herz\u00b7haft", "sich", "zu", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "ADJD", "PRF", "PTKZU", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "stets selbs geworfen in den streit?", "tokens": ["stets", "selbs", "ge\u00b7wor\u00b7fen", "in", "den", "streit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Gar nicht! sein leib und lob zugleich", "tokens": ["Gar", "nicht", "!", "sein", "leib", "und", "lob", "zu\u00b7gleich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "$.", "PPOSAT", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "het m\u00fcssen durch den tod verbleichen,", "tokens": ["het", "m\u00fcs\u00b7sen", "durch", "den", "tod", "ver\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "het er sie nicht k\u00fchn und sigreich", "tokens": ["het", "er", "sie", "nicht", "k\u00fchn", "und", "sig\u00b7reich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "PTKNEG", "ADJD", "KON", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "gezeichnet selbs mit roten zeichen.", "tokens": ["ge\u00b7zeich\u00b7net", "selbs", "mit", "ro\u00b7ten", "zei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Mit solcher farb hat deine hand", "tokens": ["Mit", "sol\u00b7cher", "farb", "hat", "dei\u00b7ne", "hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "den allerstreitbarsten soldaten", "tokens": ["den", "al\u00b7ler\u00b7streit\u00b7bars\u00b7ten", "sol\u00b7da\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "in Ungern und in Niderland", "tokens": ["in", "Un\u00b7gern", "und", "in", "Ni\u00b7der\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sch\u00f6n f\u00fcrgemalet manche thaten.", "tokens": ["sch\u00f6n", "f\u00fcr\u00b7ge\u00b7ma\u00b7let", "man\u00b7che", "tha\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie oft hat deine dapferkeit", "tokens": ["Wie", "oft", "hat", "dei\u00b7ne", "dap\u00b7fer\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "werk \u00fcbermenschlich wol verrichtet", "tokens": ["werk", "\u00fc\u00b7ber\u00b7menschlich", "wol", "ver\u00b7rich\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ADV", "VVPP"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "und deines feinds hochmut vernichtet", "tokens": ["und", "dei\u00b7nes", "feinds", "hoch\u00b7mut", "ver\u00b7nich\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "VVPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "durch sein verdiente dienstbarkeit!", "tokens": ["durch", "sein", "ver\u00b7dien\u00b7te", "dienst\u00b7bar\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ja wie vil seelen hat dein wehr", "tokens": ["Ja", "wie", "vil", "see\u00b7len", "hat", "dein", "wehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "KOKOM", "ADV", "VVINF", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "den stolzen k\u00f6rpern ausgetrieben,", "tokens": ["den", "stol\u00b7zen", "k\u00f6r\u00b7pern", "aus\u00b7ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "da\u00df das feld von der feinde heer", "tokens": ["da\u00df", "das", "feld", "von", "der", "fein\u00b7de", "heer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.12": {"text": "gleich einer schedelstat geblieben!", "tokens": ["gleich", "ei\u00b7ner", "sche\u00b7dels\u00b7tat", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Seind nicht die Tonau und der Rhein", "tokens": ["Seind", "nicht", "die", "To\u00b7nau", "und", "der", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "KON", "ART", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "oft worden rot von deinen stichen?", "tokens": ["oft", "wor\u00b7den", "rot", "von", "dei\u00b7nen", "sti\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAPP", "ADJD", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "seind nicht ob deiner wafen schein", "tokens": ["seind", "nicht", "ob", "dei\u00b7ner", "wa\u00b7fen", "schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "KOUS", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die dapferste feind oft verblichen?", "tokens": ["die", "dap\u00b7fers\u00b7te", "feind", "oft", "ver\u00b7bli\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Zwar ist es jetz gar nicht mein will,", "tokens": ["Zwar", "ist", "es", "jetz", "gar", "nicht", "mein", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "PPOSAT", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wie es dan auch nicht mein verm\u00f6gen,", "tokens": ["wie", "es", "dan", "auch", "nicht", "mein", "ver\u00b7m\u00f6\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "PTKNEG", "PPOSAT", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "hie deine thaten auszulegen;", "tokens": ["hie", "dei\u00b7ne", "tha\u00b7ten", "aus\u00b7zu\u00b7le\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VVFIN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "darum nu halt ich jetzund still,", "tokens": ["da\u00b7rum", "nu", "halt", "ich", "je\u00b7tzund", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Weil andre tugenden noch mehr", "tokens": ["Weil", "and\u00b7re", "tu\u00b7gen\u00b7den", "noch", "mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "dich mit verstand und wolstand zieren,", "tokens": ["dich", "mit", "ver\u00b7stand", "und", "wol\u00b7stand", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "die billich auch mit h\u00f6chster ehr", "tokens": ["die", "bil\u00b7lich", "auch", "mit", "h\u00f6chs\u00b7ter", "ehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "auf meinen saiten zu ber\u00fchren.", "tokens": ["auf", "mei\u00b7nen", "sai\u00b7ten", "zu", "be\u00b7r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Du bist f\u00fcrsichtig, mild und weis", "tokens": ["Du", "bist", "f\u00fcr\u00b7sich\u00b7tig", ",", "mild", "und", "weis"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "ADJD", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kein mangel ist an dir zu merken;", "tokens": ["kein", "man\u00b7gel", "ist", "an", "dir", "zu", "mer\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "ja du bist unsers alters preis", "tokens": ["ja", "du", "bist", "un\u00b7sers", "al\u00b7ters", "preis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und taugenlich zu wort und werken:", "tokens": ["und", "tau\u00b7gen\u00b7lich", "zu", "wort", "und", "wer\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die tugent ist dein eigenschaft,", "tokens": ["Die", "tu\u00b7gent", "ist", "dein", "ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "umsunst bist du nicht Craft genennet;", "tokens": ["um\u00b7sunst", "bist", "du", "nicht", "Craft", "ge\u00b7nen\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "st\u00e4rk dich f\u00fcr ihre kraft erkennet,", "tokens": ["st\u00e4rk", "dich", "f\u00fcr", "ih\u00b7re", "kraft", "er\u00b7ken\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ohn dich ist dapferkeit ohn kraft.", "tokens": ["ohn", "dich", "ist", "dap\u00b7fer\u00b7keit", "ohn", "kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mars selbs bewohnet dein gem\u00fct,", "tokens": ["Mars", "selbs", "be\u00b7woh\u00b7net", "dein", "ge\u00b7m\u00fct", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von h\u00f6flichkeit hast du geberden,", "tokens": ["von", "h\u00f6f\u00b7lich\u00b7keit", "hast", "du", "ge\u00b7ber\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+----", "measure": "iambic.di.relaxed"}, "line.11": {"text": "Cupido f\u00fcllet dich mit g\u00fct,", "tokens": ["Cu\u00b7pi\u00b7do", "f\u00fcl\u00b7let", "dich", "mit", "g\u00fct", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "da\u00df alle menschen dir hold werden.", "tokens": ["da\u00df", "al\u00b7le", "men\u00b7schen", "dir", "hold", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+++-", "measure": "unknown.measure.penta"}}, "stanza.9": {"line.1": {"text": "Darum hat dich gots g\u00fctigkeit", "tokens": ["Da\u00b7rum", "hat", "dich", "gots", "g\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit einer f\u00fcrstin zart begabet,", "tokens": ["mit", "ei\u00b7ner", "f\u00fcrs\u00b7tin", "zart", "be\u00b7ga\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df du durch ihre s\u00fc\u00dfigkeit", "tokens": ["da\u00df", "du", "durch", "ih\u00b7re", "s\u00fc\u00b7\u00dfig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "den g\u00f6ttern werdest gleich erlabet;", "tokens": ["den", "g\u00f6t\u00b7tern", "wer\u00b7dest", "gleich", "er\u00b7la\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df du in steter lieb und ruh", "tokens": ["Da\u00df", "du", "in", "ste\u00b7ter", "lieb", "und", "ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "dein leben m\u00f6gest wol zubringen,", "tokens": ["dein", "le\u00b7ben", "m\u00f6\u00b7gest", "wol", "zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und da\u00df der welt aus euch entspringen", "tokens": ["und", "da\u00df", "der", "welt", "aus", "euch", "ent\u00b7sprin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "gleichlose helden, die wie du", "tokens": ["gleich\u00b7lo\u00b7se", "hel\u00b7den", ",", "die", "wie", "du"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "KOKOM", "PPER"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Durch die kraft ihrer k\u00f6pf und h\u00e4nd", "tokens": ["Durch", "die", "kraft", "ih\u00b7rer", "k\u00f6pf", "und", "h\u00e4nd"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "KON", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "die feind stets gl\u00fcckreich \u00fcberwinden,", "tokens": ["die", "feind", "stets", "gl\u00fcck\u00b7reich", "\u00fc\u00b7berw\u00b7in\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "da\u00df eures lobs und namens end", "tokens": ["da\u00df", "eu\u00b7res", "lobs", "und", "na\u00b7mens", "end"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "nicht vor der welt end zu erfinden.", "tokens": ["nicht", "vor", "der", "welt", "end", "zu", "er\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}