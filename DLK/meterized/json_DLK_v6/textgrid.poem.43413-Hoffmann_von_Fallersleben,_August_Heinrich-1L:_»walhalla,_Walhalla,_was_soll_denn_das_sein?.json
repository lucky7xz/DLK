{"textgrid.poem.43413": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbwalhalla, Walhalla, was soll denn das sein?", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbwalhalla, Walhalla, was soll denn das sein?", "tokens": ["\u00bb", "wal\u00b7hal\u00b7la", ",", "Wal\u00b7hal\u00b7la", ",", "was", "soll", "denn", "das", "sein", "?"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "$,", "NE", "$,", "PWS", "VMFIN", "ADV", "ART", "VAINF", "$."], "meter": "+--+---+--+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wird bairisches Bier da geschenkt oder Wein?\u00ab", "tokens": ["Wird", "bai\u00b7ri\u00b7sches", "Bier", "da", "ge\u00b7schenkt", "o\u00b7der", "Wein", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADV", "VVPP", "KON", "NN", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Da schenkt man nicht Bier und da schenkt man nicht Wein,", "tokens": ["Da", "schenkt", "man", "nicht", "Bier", "und", "da", "schenkt", "man", "nicht", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKNEG", "NN", "KON", "ADV", "VVFIN", "PIS", "PTKNEG", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Da stellt man verdienstvolle Deutsche hinein.", "tokens": ["Da", "stellt", "man", "ver\u00b7dienst\u00b7vol\u00b7le", "Deut\u00b7sche", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbverdienstvolle Deutsche, das klinget gar fein,", "tokens": ["\u00bb", "ver\u00b7dienst\u00b7vol\u00b7le", "Deut\u00b7sche", ",", "das", "klin\u00b7get", "gar", "fein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Darf drunter ein Ketzer und Jud' auch wol sein?\u00ab", "tokens": ["Darf", "drun\u00b7ter", "ein", "Ket\u00b7zer", "und", "Jud'", "auch", "wol", "sein", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PAV", "ART", "NN", "KON", "NN", "ADV", "ADV", "VAINF", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.4": {"line.1": {"text": "Katholisch gekoschert so kommt man allein", "tokens": ["Ka\u00b7tho\u00b7lisch", "ge\u00b7ko\u00b7schert", "so", "kommt", "man", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVPP", "ADV", "VVFIN", "PIS", "ADV"], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In unsere deutsche Walhalla hinein.", "tokens": ["In", "un\u00b7se\u00b7re", "deut\u00b7sche", "Wal\u00b7hal\u00b7la", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Denn Alles wol l\u00e4\u00dft sich auf Erden verzeih'n,", "tokens": ["Denn", "Al\u00b7les", "wol", "l\u00e4\u00dft", "sich", "auf", "Er\u00b7den", "ver\u00b7zeih'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "VVFIN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Doch nimmer und nimmer die Ketzerei'n.", "tokens": ["Doch", "nim\u00b7mer", "und", "nim\u00b7mer", "die", "Ket\u00b7ze\u00b7rei'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "ADV", "KON", "ADV", "ART", "NN", "NE"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Und wollte der Luther ein Heide nur sein,", "tokens": ["Und", "woll\u00b7te", "der", "Lu\u00b7ther", "ein", "Hei\u00b7de", "nur", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "NN", "ADV", "VAINF", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "So k\u00e4m' er am Ende wol auch noch hinein.", "tokens": ["So", "k\u00e4m'", "er", "am", "En\u00b7de", "wol", "auch", "noch", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbwas Luther, was Luther, der braucht nicht hinein!", "tokens": ["\u00bb", "was", "Lu\u00b7ther", ",", "was", "Lu\u00b7ther", ",", "der", "braucht", "nicht", "hin\u00b7ein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "NE", "$,", "PRELS", "NE", "$,", "PRELS", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der lebt in den Herzen, wozu noch in Stein?\u00ab", "tokens": ["Der", "lebt", "in", "den", "Her\u00b7zen", ",", "wo\u00b7zu", "noch", "in", "Stein", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$,", "PWAV", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbwenn keine Walhalla auf Erden wird sein,", "tokens": ["\u00bb", "wenn", "kei\u00b7ne", "Wal\u00b7hal\u00b7la", "auf", "Er\u00b7den", "wird", "sein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIAT", "NN", "APPR", "NN", "VAFIN", "VAINF", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "O Luther, so denket die Welt doch noch dein.\u00ab", "tokens": ["O", "Lu\u00b7ther", ",", "so", "den\u00b7ket", "die", "Welt", "doch", "noch", "dein", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "ADV", "VVFIN", "ART", "NN", "ADV", "ADV", "PPOSAT", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}}}}