{"textgrid.poem.53505": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Spanische Krankheit?", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was schleicht durch alle kriegf\u00fchrenden L\u00e4nder?", "tokens": ["Was", "schleicht", "durch", "al\u00b7le", "krieg\u00b7f\u00fch\u00b7ren\u00b7den", "L\u00e4n\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Welches Ding schleift die infizierten Gew\u00e4nder", "tokens": ["Wel\u00b7ches", "Ding", "schleift", "die", "in\u00b7fi\u00b7zier\u00b7ten", "Ge\u00b7w\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAT", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "vom Sch\u00fctzengraben zur Residenz?", "tokens": ["vom", "Sch\u00fct\u00b7zen\u00b7gra\u00b7ben", "zur", "Re\u00b7si\u00b7denz", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer hat es gesehn? Wer nennts? Wer erkennts?", "tokens": ["Wer", "hat", "es", "ge\u00b7sehn", "?", "Wer", "nennts", "?", "Wer", "er\u00b7kennts", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVPP", "$.", "PWS", "VVFIN", "$.", "PWS", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Schmerzen im Hals, Schmerzen im Ohr \u2013", "tokens": ["Schmer\u00b7zen", "im", "Hals", ",", "Schmer\u00b7zen", "im", "Ohr", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "NN", "APPRART", "NN", "$("], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "die Sache kommt mir spanisch vor.", "tokens": ["die", "Sa\u00b7che", "kommt", "mir", "spa\u00b7nisch", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Aber wenn ichs genau betrachte", "tokens": ["A\u00b7ber", "wenn", "ichs", "ge\u00b7nau", "be\u00b7trach\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "ADJD", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "und h\u00fcbsch auf alle Symptome achte,", "tokens": ["und", "h\u00fcbsch", "auf", "al\u00b7le", "Symp\u00b7to\u00b7me", "ach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PIAT", "NN", "ADJA", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "bemerke ich es mit einem Mal:", "tokens": ["be\u00b7mer\u00b7ke", "ich", "es", "mit", "ei\u00b7nem", "Mal", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "das ist nicht international.", "tokens": ["das", "ist", "nicht", "in\u00b7ter\u00b7na\u00b7ti\u00b7o\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Und seh ich das ganze Krankenkorps:", "tokens": ["Und", "seh", "ich", "das", "gan\u00b7ze", "Kran\u00b7ken\u00b7korps", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "kommts mir gar nicht mehr spanisch vor.", "tokens": ["kommts", "mir", "gar", "nicht", "mehr", "spa\u00b7nisch", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "Ein bi\u00dfchen Gefieber, ein bi\u00dfchen Beschwerden,", "tokens": ["Ein", "bi\u00df\u00b7chen", "Ge\u00b7fie\u00b7ber", ",", "ein", "bi\u00df\u00b7chen", "Be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Onkel Doktor sagt: \u00bbMorgen wirds besser werden!\u00ab", "tokens": ["On\u00b7kel", "Dok\u00b7tor", "sagt", ":", "\u00bb", "Mor\u00b7gen", "wirds", "bes\u00b7ser", "wer\u00b7den", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "VVFIN", "$.", "$(", "NN", "VAFIN", "ADJD", "VAINF", "$.", "$("], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Nachts im Dunkel Transpirieren,", "tokens": ["Nachts", "im", "Dun\u00b7kel", "Trans\u00b7pi\u00b7rie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Herzangst, Schwindel und Phantasieren,", "tokens": ["Herz\u00b7angst", ",", "Schwin\u00b7del", "und", "Phan\u00b7ta\u00b7sie\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "mittags Erhitzen, abends Erkalten,", "tokens": ["mit\u00b7tags", "Er\u00b7hit\u00b7zen", ",", "a\u00b7bends", "Er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "morgen ist alles wieder beim Alten \u2013", "tokens": ["mor\u00b7gen", "ist", "al\u00b7les", "wie\u00b7der", "beim", "Al\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "APPRART", "NN", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Das ist keine Grippe, kein Frost, keine Phtisis \u2013", "tokens": ["Das", "ist", "kei\u00b7ne", "Grip\u00b7pe", ",", "kein", "Frost", ",", "kei\u00b7ne", "Ph\u00b7ti\u00b7sis", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$("], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.8": {"text": "das ist eine deutsche politische Krisis.", "tokens": ["das", "ist", "ei\u00b7ne", "deut\u00b7sche", "po\u00b7li\u00b7ti\u00b7sche", "Kri\u00b7sis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}