{"textgrid.poem.26253": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Gestern und heute", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach, gestern schossen sie hier voll Wut.", "tokens": ["Ach", ",", "ge\u00b7stern", "schos\u00b7sen", "sie", "hier", "voll", "Wut", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Die B\u00e4ume stehen bespritzt mit Blut.", "tokens": ["Die", "B\u00e4u\u00b7me", "ste\u00b7hen", "be\u00b7spritzt", "mit", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Was tun sie heute? Was tun sie dort?", "tokens": ["Was", "tun", "sie", "heu\u00b7te", "?", "Was", "tun", "sie", "dort", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Sie gehen im Gras umher ohne Wort,", "tokens": ["Sie", "ge\u00b7hen", "im", "Gras", "um\u00b7her", "oh\u00b7ne", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "APPR", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den Helm im Nacken, sie stehen geb\u00fcckt,", "tokens": ["Den", "Helm", "im", "Na\u00b7cken", ",", "sie", "ste\u00b7hen", "ge\u00b7b\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "PPER", "VVFIN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Soldat bei Soldat heut Blumen pfl\u00fcckt.", "tokens": ["Sol\u00b7dat", "bei", "Sol\u00b7dat", "heut", "Blu\u00b7men", "pfl\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Heut grub man den tapferen Toten das Grab,", "tokens": ["Heut", "grub", "man", "den", "tap\u00b7fe\u00b7ren", "To\u00b7ten", "das", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Heut senkt man sie blumengeschm\u00fcckt hinab.", "tokens": ["Heut", "senkt", "man", "sie", "blu\u00b7men\u00b7ge\u00b7schm\u00fcckt", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Nicht eine Hand heut ans T\u00f6ten denkt.", "tokens": ["Nicht", "ei\u00b7ne", "Hand", "heut", "ans", "T\u00f6\u00b7ten", "denkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie sind ins Blumenpfl\u00fccken versenkt.", "tokens": ["Sie", "sind", "ins", "Blu\u00b7men\u00b7pfl\u00fc\u00b7cken", "ver\u00b7senkt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Der Flu\u00df geht vorsichtsvoll, nicht hart,", "tokens": ["Der", "Flu\u00df", "geht", "vor\u00b7sichts\u00b7voll", ",", "nicht", "hart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Wiesenhalme umwehen den Bart.", "tokens": ["Und", "Wie\u00b7sen\u00b7hal\u00b7me", "um\u00b7we\u00b7hen", "den", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie pfl\u00fccken alle. Sanft pfl\u00fcckt die Hand,", "tokens": ["Sie", "pfl\u00fc\u00b7cken", "al\u00b7le", ".", "Sanft", "pfl\u00fcckt", "die", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$.", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die gestern nur Zeit zum T\u00f6ten fand.", "tokens": ["Die", "ge\u00b7stern", "nur", "Zeit", "zum", "T\u00f6\u00b7ten", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Und bald vielleicht liegt still und starr", "tokens": ["Und", "bald", "viel\u00b7leicht", "liegt", "still", "und", "starr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PTKVZ", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dieselbe Hand in der Blumenschar.", "tokens": ["Die\u00b7sel\u00b7be", "Hand", "in", "der", "Blu\u00b7men\u00b7schar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}