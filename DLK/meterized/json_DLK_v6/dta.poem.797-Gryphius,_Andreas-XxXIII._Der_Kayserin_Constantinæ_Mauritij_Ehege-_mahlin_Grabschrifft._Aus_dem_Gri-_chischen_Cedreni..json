{"dta.poem.797": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XxXIII.  \n Der Kayserin  Constantin\u00e6 Mauritij  Ehege-  \n mahlin Grabschrifft. Aus dem Gri-  \n chischen  Cedreni.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Ich/ voll von tausend angst/ vnd voll von tausend pein/ ", "tokens": ["Ich", "/", "voll", "von", "tau\u00b7send", "angst", "/", "vnd", "voll", "von", "tau\u00b7send", "pein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "ADJD", "APPR", "CARD", "NN", "$(", "KON", "ADJD", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "De\u00df Kaysers Eh-gemahl/ von Keysern auch gebohren/", "tokens": ["De\u00df", "Kay\u00b7sers", "Eh\u00b7ge\u00b7mahl", "/", "von", "Key\u00b7sern", "auch", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "APPR", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Tiberius sein Kind/ das Mauritz jhm erkohren/", "tokens": ["Ti\u00b7be\u00b7ri\u00b7us", "sein", "Kind", "/", "das", "Mau\u00b7ritz", "jhm", "er\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$(", "ART", "NN", "PPER", "VVINF", "$("], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "De\u00df Kaysers werthe Fraw vud Mutter/ ging hier eyn!", "tokens": ["De\u00df", "Kay\u00b7sers", "wert\u00b7he", "Fraw", "vud", "Mut\u00b7ter", "/", "ging", "hier", "eyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN", "$(", "VVFIN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Jtzt lehr ich was es sey/ auff Thronen herrlich seyn.", "tokens": ["Jtzt", "lehr", "ich", "was", "es", "sey", "/", "auff", "Thro\u00b7nen", "herr\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PWS", "PPER", "VAFIN", "$(", "APPR", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich fiel durch grim de\u00df Volcks/ das sich auff mich verschwo-", "tokens": ["Ich", "fiel", "durch", "grim", "de\u00df", "Volcks", "/", "das", "sich", "auff", "mich", "ver\u00b7schwo"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "ART", "NN", "$(", "PRELS", "PRF", "APPR", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ren/", "tokens": ["ren", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "-", "measure": "single.down"}}, "stanza.3": {"line.1": {"text": "Durch der Soldaten list/ durch Meyneyd wurd verlohren", "tokens": ["Durch", "der", "Sol\u00b7da\u00b7ten", "list", "/", "durch", "Mey\u00b7neyd", "wurd", "ver\u00b7loh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$(", "APPR", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mann/ S\u00f6hn vnd T\u00f6chter die kaum deckt ein schlechter", "tokens": ["Mann", "/", "S\u00f6hn", "vnd", "T\u00f6ch\u00b7ter", "die", "kaum", "deckt", "ein", "schlech\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "KON", "NN", "ART", "ADV", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Stein.", "tokens": ["Stein", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Mu\u00df mir nicht ", "tokens": ["Mu\u00df", "mir", "nicht"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Ich bin der ", "tokens": ["Ich", "bin", "der"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Habt jhr zum Vater recht? Was hat sein Stamm verkerbt", "tokens": ["Habt", "jhr", "zum", "Va\u00b7ter", "recht", "?", "Was", "hat", "sein", "Stamm", "ver\u00b7kerbt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "ADJD", "$.", "PWS", "VAFIN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der noch kein falsch erkand? Er wird dich Rom nicht deckenl", "tokens": ["Der", "noch", "kein", "falsch", "er\u00b7kand", "?", "Er", "wird", "dich", "Rom", "nicht", "de\u00b7ckenl"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PIAT", "ADJD", "VVFIN", "$.", "PPER", "VAFIN", "PPER", "NE", "PTKNEG", "NE"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Dn wirst dich liebe Stadt nicht vmb die zweige strecken.", "tokens": ["Dn", "wirst", "dich", "lie\u00b7be", "Stadt", "nicht", "vmb", "die", "zwei\u00b7ge", "stre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "NN", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Nord\u2019 au\u00df ", "tokens": ["Der", "Nord'", "au\u00df"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "PTKVZ"], "meter": "-+-", "measure": "amphibrach.single"}}}}}