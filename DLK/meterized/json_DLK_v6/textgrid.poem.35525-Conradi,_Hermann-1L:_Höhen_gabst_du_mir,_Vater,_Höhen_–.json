{"textgrid.poem.35525": {"metadata": {"author": {"name": "Conradi, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "1L: H\u00f6hen gabst du mir, Vater, H\u00f6hen \u2013", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00f6hen gabst du mir, Vater, H\u00f6hen \u2013", "tokens": ["H\u00f6\u00b7hen", "gabst", "du", "mir", ",", "Va\u00b7ter", ",", "H\u00f6\u00b7hen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "$,", "NN", "$,", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Mittagsh\u00f6hen des Lebens!", "tokens": ["Mit\u00b7tags\u00b7h\u00f6\u00b7hen", "des", "Le\u00b7bens", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Da ich gr\u00f6\u00dfer war, denn du,", "tokens": ["Da", "ich", "gr\u00f6\u00b7\u00dfer", "war", ",", "denn", "du", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.2": {"line.1": {"text": "Denn ich begriff dich, Allesempfindender!", "tokens": ["Denn", "ich", "be\u00b7griff", "dich", ",", "Al\u00b7le\u00b7semp\u00b7fin\u00b7den\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Denn ich begriff dich", "tokens": ["Denn", "ich", "be\u00b7griff", "dich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Und deiner Gedanken", "tokens": ["Und", "dei\u00b7ner", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Weite Wunder!", "tokens": ["Wei\u00b7te", "Wun\u00b7der", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Ich str\u00f6mte in dir aus", "tokens": ["Ich", "str\u00f6m\u00b7te", "in", "dir", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Meiner Gef\u00fchle Katarakte!", "tokens": ["Mei\u00b7ner", "Ge\u00b7f\u00fch\u00b7le", "Ka\u00b7ta\u00b7rak\u00b7te", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "Vater! Da stand ich auf H\u00f6hen", "tokens": ["Va\u00b7ter", "!", "Da", "stand", "ich", "auf", "H\u00f6\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Des Geb\u00e4rers qualvolle Wollust", "tokens": ["Des", "Ge\u00b7b\u00e4\u00b7rers", "qual\u00b7vol\u00b7le", "Wol\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und deines Seelenbrunnens", "tokens": ["Und", "dei\u00b7nes", "See\u00b7len\u00b7brun\u00b7nens"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ewige Unergr\u00fcndlichkeit!", "tokens": ["E\u00b7wi\u00b7ge", "Un\u00b7er\u00b7gr\u00fcnd\u00b7lich\u00b7keit", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Stolze H\u00f6hen erklomm ich!", "tokens": ["Stol\u00b7ze", "H\u00f6\u00b7hen", "er\u00b7klomm", "ich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Uebermenschliche!", "tokens": ["Ue\u00b7ber\u00b7menschli\u00b7che", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Vater! Ich zittere nicht \u2013", "tokens": ["Va\u00b7ter", "!", "Ich", "zit\u00b7te\u00b7re", "nicht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PTKNEG", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Ich bange nicht,", "tokens": ["Ich", "ban\u00b7ge", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Denn ich ward wie du!", "tokens": ["Denn", "ich", "ward", "wie", "du", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "KOKOM", "PPER", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Vater! Gib mir ", "tokens": ["Va\u00b7ter", "!", "Gib", "mir"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$.", "VVIMP", "PPER"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Tiefen, Vater, Tiefen!", "tokens": ["Tie\u00b7fen", ",", "Va\u00b7ter", ",", "Tie\u00b7fen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "La\u00df mich des Staubes Eingeweide durchw\u00fchlen \u2013", "tokens": ["La\u00df", "mich", "des", "Stau\u00b7bes", "Ein\u00b7ge\u00b7wei\u00b7de", "durch\u00b7w\u00fch\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "NN", "VVINF", "$("], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Dr\u00fccke Mund und Stirne", "tokens": ["Dr\u00fc\u00b7cke", "Mund", "und", "Stir\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Tief ein in den d\u00fcrren, tauben Sand", "tokens": ["Tief", "ein", "in", "den", "d\u00fcr\u00b7ren", ",", "tau\u00b7ben", "Sand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "ART", "APPR", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Denn Vater, deine N\u00e4he \u2013", "tokens": ["Denn", "Va\u00b7ter", ",", "dei\u00b7ne", "N\u00e4\u00b7he", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Deine ", "tokens": ["Dei\u00b7ne"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Schm\u00f6lze die Seele mir in der Brust \u2013", "tokens": ["Schm\u00f6l\u00b7ze", "die", "See\u00b7le", "mir", "in", "der", "Brust", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Schm\u00f6lze sie \u2013", "tokens": ["Schm\u00f6l\u00b7ze", "sie", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Und ich zerfiele.", "tokens": ["Und", "ich", "zer\u00b7fie\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Nur der aus der Tiefe", "tokens": ["Nur", "der", "aus", "der", "Tie\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Zu dir emporklimmt,", "tokens": ["Zu", "dir", "em\u00b7por\u00b7klimmt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "M\u00e4chtig erbebend,", "tokens": ["M\u00e4ch\u00b7tig", "er\u00b7be\u00b7bend", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Wird wie du \u2013", "tokens": ["Wird", "wie", "du", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "PPER", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Wird du!", "tokens": ["Wird", "du", "!"], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "PPER", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.12": {"line.1": {"text": "Denn nur ein neues Hinab", "tokens": ["Denn", "nur", "ein", "neu\u00b7es", "Hin\u00b7ab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Gebiert ein neues Hinauf \u2013", "tokens": ["Ge\u00b7biert", "ein", "neu\u00b7es", "Hin\u00b7auf", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und nur im ", "tokens": ["Und", "nur", "im"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "APPRART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Vollendet sich die Erkenntnis!", "tokens": ["Voll\u00b7en\u00b7det", "sich", "die", "Er\u00b7kennt\u00b7nis", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Denn bin ich nicht du \u2013", "tokens": ["Denn", "bin", "ich", "nicht", "du", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PPER", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Und bist du nicht ich?", "tokens": ["Und", "bist", "du", "nicht", "ich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PPER", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Ruhlose Ruh", "tokens": ["Ruh\u00b7lo\u00b7se", "Ruh"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Bis zum letzten gro\u00dfen Gedankenstrich ...", "tokens": ["Bis", "zum", "letz\u00b7ten", "gro\u00b7\u00dfen", "Ge\u00b7dan\u00b7ken\u00b7strich", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "ADJA", "NN", "$("], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}