{"textgrid.poem.24924": {"metadata": {"author": {"name": "Schack, Adolf Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Walther von Immenstadt", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herr Walther war es von Immenstadt,", "tokens": ["Herr", "Walt\u00b7her", "war", "es", "von", "Im\u00b7men\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "PPER", "APPR", "NE", "$,"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Im Heere von allen der Beste,", "tokens": ["Im", "Hee\u00b7re", "von", "al\u00b7len", "der", "Bes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PIAT", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Der mit eisernem Arm, im Kampf nie matt,", "tokens": ["Der", "mit", "ei\u00b7ser\u00b7nem", "Arm", ",", "im", "Kampf", "nie", "matt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "$,", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Den Nacken der Heiden pre\u00dfte;", "tokens": ["Den", "Na\u00b7cken", "der", "Hei\u00b7den", "pre\u00df\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Kaum flammte sein Schwert vor Liddas Wall,", "tokens": ["Kaum", "flamm\u00b7te", "sein", "Schwert", "vor", "Lid\u00b7das", "Wall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So flohen die Sarazenen all,", "tokens": ["So", "flo\u00b7hen", "die", "Sa\u00b7ra\u00b7ze\u00b7nen", "all", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PIAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und es strahlte das Kreuz auf der Feste.", "tokens": ["Und", "es", "strahl\u00b7te", "das", "Kreuz", "auf", "der", "Fes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.2": {"line.1": {"text": "Mit dem wackern H\u00e4uflein zieht er durchs Thor;", "tokens": ["Mit", "dem", "wa\u00b7ckern", "H\u00e4uf\u00b7lein", "zieht", "er", "durchs", "Thor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "\u00bbnun geht, die Kerker zu sprengen!\u00ab", "tokens": ["\u00bb", "nun", "geht", ",", "die", "Ker\u00b7ker", "zu", "spren\u00b7gen", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Flugs thun sie sich auf; ihm schallt an das Ohr", "tokens": ["Flugs", "thun", "sie", "sich", "auf", ";", "ihm", "schallt", "an", "das", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Chor von Christenges\u00e4ngen;", "tokens": ["Ein", "Chor", "von", "Chris\u00b7ten\u00b7ge\u00b7s\u00e4n\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Er sieht die Befreiten, welk und bla\u00df,", "tokens": ["Er", "sieht", "die", "Be\u00b7frei\u00b7ten", ",", "welk", "und", "bla\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Die Hand ihm netzend mit Thr\u00e4nenna\u00df,", "tokens": ["Die", "Hand", "ihm", "net\u00b7zend", "mit", "Thr\u00e4\u00b7nen\u00b7na\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Um ihn, den Retter, sich dr\u00e4ngen.", "tokens": ["Um", "ihn", ",", "den", "Ret\u00b7ter", ",", "sich", "dr\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPER", "$,", "ART", "NN", "$,", "PRF", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Bald ist auf dem Markt ein purpurnes Zelt", "tokens": ["Bald", "ist", "auf", "dem", "Markt", "ein", "pur\u00b7pur\u00b7nes", "Zelt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von Damaskischer Seide zu schauen,", "tokens": ["Von", "Da\u00b7mas\u00b7ki\u00b7scher", "Sei\u00b7de", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und die Tafel reichlich mit allem bestellt,", "tokens": ["Und", "die", "Ta\u00b7fel", "reich\u00b7lich", "mit", "al\u00b7lem", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "APPR", "PIS", "VVPP", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was gedeiht auf Syriens Auen;", "tokens": ["Was", "ge\u00b7deiht", "auf", "Sy\u00b7ri\u00b7ens", "Au\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "NE", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Voll cyprischen Weines sch\u00e4umt der Pokal,", "tokens": ["Voll", "cy\u00b7pri\u00b7schen", "Wei\u00b7nes", "sch\u00e4umt", "der", "Po\u00b7kal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Und S\u00e4nger versch\u00f6nern mit Liedern das Mahl", "tokens": ["Und", "S\u00e4n\u00b7ger", "ver\u00b7sch\u00f6\u00b7nern", "mit", "Lie\u00b7dern", "das", "Mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "APPR", "NN", "ART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Und sarazenische Frauen.", "tokens": ["Und", "sa\u00b7ra\u00b7ze\u00b7ni\u00b7sche", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Da, musternd der gl\u00fccklichen G\u00e4ste Kreis.", "tokens": ["Da", ",", "mus\u00b7ternd", "der", "gl\u00fcck\u00b7li\u00b7chen", "G\u00e4s\u00b7te", "Kreis", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVPP", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Blickt pl\u00f6tzlich erstaunt Herr Walther.", "tokens": ["Blickt", "pl\u00f6tz\u00b7lich", "er\u00b7staunt", "Herr", "Walt\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVFIN", "NN", "NE", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbf\u00fcrwahr, dort dr\u00fcben erkenn' ich den Greis;", "tokens": ["\u00bb", "f\u00fcr\u00b7wahr", ",", "dort", "dr\u00fc\u00b7ben", "er\u00b7kenn'", "ich", "den", "Greis", ";"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "ADV", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer bist du? sage mir, Alter!\u00ab", "tokens": ["Wer", "bist", "du", "?", "sa\u00b7ge", "mir", ",", "Al\u00b7ter", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$.", "VVFIN", "PPER", "$,", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Der Greis erhebt sich: \u00bbHans Hildebrand,", "tokens": ["Der", "Greis", "er\u00b7hebt", "sich", ":", "\u00bb", "Hans", "Hil\u00b7de\u00b7brand", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$.", "$(", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Schulmeister aus Schwaben, k\u00fc\u00dft Euch die Hand,", "tokens": ["Schul\u00b7meis\u00b7ter", "aus", "Schwa\u00b7ben", ",", "k\u00fc\u00dft", "Euch", "die", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Mein Retter, mein Lebenserhalter!\u00ab", "tokens": ["Mein", "Ret\u00b7ter", ",", "mein", "Le\u00b7ben\u00b7ser\u00b7hal\u00b7ter", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbund bist du noch Walthers, des jungen, gedenk?\u00ab", "tokens": ["\u00bb", "und", "bist", "du", "noch", "Walt\u00b7hers", ",", "des", "jun\u00b7gen", ",", "ge\u00b7denk", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "ADV", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Fragt l\u00e4chelnd der Feldherr weiter.", "tokens": ["Fragt", "l\u00e4\u00b7chelnd", "der", "Feld\u00b7herr", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbei wohl!\u00ab \u2013 ruft jener, vom Rebengetr\u00e4nk", "tokens": ["\u00bb", "ei", "wohl", "!", "\u00ab", "\u2013", "ruft", "je\u00b7ner", ",", "vom", "Re\u00b7ben\u00b7ge\u00b7tr\u00e4nk"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ITJ", "ADV", "$.", "$(", "$(", "VVFIN", "PDS", "$,", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Schon halb umnebelt und heiter, \u2013", "tokens": ["Schon", "halb", "um\u00b7ne\u00b7belt", "und", "hei\u00b7ter", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVPP", "KON", "ADJD", "$,", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u00bbei wohl gedenk' ich des argen Wichts;", "tokens": ["\u00bb", "ei", "wohl", "ge\u00b7denk'", "ich", "des", "ar\u00b7gen", "Wichts", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "Ein Wildfang war er, ein Taugenichts,", "tokens": ["Ein", "Wild\u00b7fang", "war", "er", ",", "ein", "Tau\u00b7ge\u00b7nichts", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Wie in ganz Schwaben kein zweiter.", "tokens": ["Wie", "in", "ganz", "Schwa\u00b7ben", "kein", "zwei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADV", "NN", "PIAT", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Bei Aufruhr, Raufen und Schl\u00e4gerein", "tokens": ["Bei", "Auf\u00b7ruhr", ",", "Rau\u00b7fen", "und", "Schl\u00e4\u00b7ge\u00b7rein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kam keiner ihm gleich in der Schule;", "tokens": ["Kam", "kei\u00b7ner", "ihm", "gleich", "in", "der", "Schu\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Doch zum ABC und dem Einmalein", "tokens": ["Doch", "zum", "AbC", "und", "dem", "Ein\u00b7mal\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "KON", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Nie hatt' er Geduld auf dem Stuhle.", "tokens": ["Nie", "hatt'", "er", "Ge\u00b7duld", "auf", "dem", "Stuh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "War irgend geschehen ein b\u00f6ser Streich:", "tokens": ["War", "ir\u00b7gend", "ge\u00b7sche\u00b7hen", "ein", "b\u00f6\u00b7ser", "Streich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "\u203adas that der Walther\u2039, dacht' ich sogleich", "tokens": ["\u203a", "das", "that", "der", "Walt\u00b7her", "\u2039", ",", "dacht'", "ich", "sog\u00b7leich"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VVFIN", "ART", "NN", "$(", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und verw\u00fcnscht' ihn zum H\u00f6llenpfuhle.", "tokens": ["Und", "ver\u00b7w\u00fcnscht'", "ihn", "zum", "H\u00f6l\u00b7len\u00b7pfuh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.7": {"line.1": {"text": "H\u00e4tt' ich ihm mehr nur den R\u00fccken zerbl\u00e4ut,", "tokens": ["H\u00e4tt'", "ich", "ihm", "mehr", "nur", "den", "R\u00fc\u00b7cken", "zer\u00b7bl\u00e4ut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+---+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Das m\u00f6cht' ihn gebessert haben;", "tokens": ["Das", "m\u00f6cht'", "ihn", "ge\u00b7bes\u00b7sert", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch, wenn es so fortging, ist er heut", "tokens": ["Doch", ",", "wenn", "es", "so", "fort\u00b7ging", ",", "ist", "er", "heut"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "PPER", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "L\u00e4ngst unter dem Galgen begraben.\u00ab", "tokens": ["L\u00e4ngst", "un\u00b7ter", "dem", "Gal\u00b7gen", "be\u00b7gra\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Mehr will er erz\u00e4hlen, doch Walther lacht:", "tokens": ["Mehr", "will", "er", "er\u00b7z\u00e4h\u00b7len", ",", "doch", "Walt\u00b7her", "lacht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,", "ADV", "NE", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "\u00bbei! hat mich verwandelt die Kriegertracht?", "tokens": ["\u00bb", "ei", "!", "hat", "mich", "ver\u00b7wan\u00b7delt", "die", "Krie\u00b7ger\u00b7tracht", "?"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "VAFIN", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+---+--+-+", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Erkennst du in mir nicht den Knaben?\u00ab", "tokens": ["Er\u00b7kennst", "du", "in", "mir", "nicht", "den", "Kna\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKNEG", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der Greis sinkt bebend zu Boden hin", "tokens": ["Der", "Greis", "sinkt", "be\u00b7bend", "zu", "Bo\u00b7den", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "PTKVZ"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und fleht: \u00bbHerr! k\u00f6nnt Ihr vergeben?\u00ab", "tokens": ["Und", "fleht", ":", "\u00bb", "Herr", "!", "k\u00f6nnt", "Ihr", "ver\u00b7ge\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NN", "$.", "VVFIN", "PPER", "VVPP", "$.", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Doch Walther erhebt ihn und f\u00fcllt f\u00fcr ihn", "tokens": ["Doch", "Walt\u00b7her", "er\u00b7hebt", "ihn", "und", "f\u00fcllt", "f\u00fcr", "ihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "PPER", "KON", "VVFIN", "APPR", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Den Becher mit Na\u00df der Reben:", "tokens": ["Den", "Be\u00b7cher", "mit", "Na\u00df", "der", "Re\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u00bbauf! thu mir Bescheid in dem k\u00f6stlichen Saft!", "tokens": ["\u00bb", "auf", "!", "thu", "mir", "Be\u00b7scheid", "in", "dem", "k\u00f6st\u00b7li\u00b7chen", "Saft", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$.", "VVFIN", "PPER", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Das ABC und die Wissenschaft", "tokens": ["Das", "AbC", "und", "die", "Wis\u00b7sen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Und du, mein Lehrer, sollst leben!", "tokens": ["Und", "du", ",", "mein", "Leh\u00b7rer", ",", "sollst", "le\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPOSAT", "NN", "$,", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.9": {"line.1": {"text": "Doch da\u00df auch in Ehren das Kriegswerk sei", "tokens": ["Doch", "da\u00df", "auch", "in", "Eh\u00b7ren", "das", "Kriegs\u00b7werk", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "APPR", "NN", "ART", "NN", "VAFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und wer fr\u00fch sich \u00fcbt f\u00fcr die Schlachten!", "tokens": ["Und", "wer", "fr\u00fch", "sich", "\u00fcbt", "f\u00fcr", "die", "Schlach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJD", "PRF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Nicht hat er Behagen an Schulfuchserei;", "tokens": ["Nicht", "hat", "er", "Be\u00b7ha\u00b7gen", "an", "Schul\u00b7fuch\u00b7se\u00b7rei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VAFIN", "PPER", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Nach K\u00e4mpfen nur steht sein Trachten.", "tokens": ["Nach", "K\u00e4mp\u00b7fen", "nur", "steht", "sein", "Trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "W\u00e4r' ich, wie du wolltest, so zahm und bang", "tokens": ["W\u00e4r'", "ich", ",", "wie", "du", "woll\u00b7test", ",", "so", "zahm", "und", "bang"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "ADV", "ADJD", "KON", "ADJD"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Als Sch\u00fcler gewesen, du h\u00e4ttest noch lang,", "tokens": ["Als", "Sch\u00fc\u00b7ler", "ge\u00b7we\u00b7sen", ",", "du", "h\u00e4t\u00b7test", "noch", "lang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAPP", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Mein Guter, im Kerker zu schmachten.\u00ab", "tokens": ["Mein", "Gu\u00b7ter", ",", "im", "Ker\u00b7ker", "zu", "schmach\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPRART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}