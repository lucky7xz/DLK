{"textgrid.poem.55526": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Triumph der Tugend", "genre": "verse", "period": "N.A.", "pub_year": 1790, "urn": "N.A.", "language": ["de:0.85", "da:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Von stiller Wollust eingeladen,", "tokens": ["Von", "stil\u00b7ler", "Wol\u00b7lust", "ein\u00b7ge\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Drang in den Tempel der Dryaden", "tokens": ["Drang", "in", "den", "Tem\u00b7pel", "der", "Dry\u00b7a\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mit seinem M\u00e4dchen Daphnis ein,", "tokens": ["Mit", "sei\u00b7nem", "M\u00e4d\u00b7chen", "Daph\u00b7nis", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um z\u00e4rtlich ohnbemerkt zu sein.", "tokens": ["Um", "z\u00e4rt\u00b7lich", "ohn\u00b7be\u00b7merkt", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Des Taxus Nacht umgab den Fu\u00df der Eichen,", "tokens": ["Des", "Ta\u00b7xus", "Nacht", "um\u00b7gab", "den", "Fu\u00df", "der", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nur V\u00f6gel h\u00fcpften auf den Zweigen,", "tokens": ["Nur", "V\u00f6\u00b7gel", "h\u00fcpf\u00b7ten", "auf", "den", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Rings um sie her lag feierliches Schweigen,", "tokens": ["Rings", "um", "sie", "her", "lag", "fei\u00b7er\u00b7li\u00b7ches", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APZR", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als w\u00e4ren sie auf dieser Welt allein.", "tokens": ["Als", "w\u00e4\u00b7ren", "sie", "auf", "die\u00b7ser", "Welt", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "APPR", "PDAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sie sa\u00dfen t\u00e4ndelnd in dem K\u00fchlen.", "tokens": ["Sie", "sa\u00b7\u00dfen", "t\u00e4n\u00b7delnd", "in", "dem", "K\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Allein, dem Herzen nah, das uns so z\u00e4rtlich liebt \u2013", "tokens": ["Al\u00b7lein", ",", "dem", "Her\u00b7zen", "nah", ",", "das", "uns", "so", "z\u00e4rt\u00b7lich", "liebt", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "ADJD", "$,", "PRELS", "PPER", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wem Amor solch ein Gl\u00fccke gibt,", "tokens": ["Wem", "A\u00b7mor", "solch", "ein", "Gl\u00fc\u00b7cke", "gibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PIAT", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird der nicht mehr als sonsten f\u00fchlen?", "tokens": ["Wird", "der", "nicht", "mehr", "als", "sons\u00b7ten", "f\u00fch\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PTKNEG", "ADV", "KOKOM", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und unser Paar fing bald an, mehr zu f\u00fchlen.", "tokens": ["Und", "un\u00b7ser", "Paar", "fing", "bald", "an", ",", "mehr", "zu", "f\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "PTKVZ", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Des M\u00e4dchens z\u00e4rtlich Herz lag ganz in ihrem Blicke,", "tokens": ["Des", "M\u00e4d\u00b7chens", "z\u00e4rt\u00b7lich", "Herz", "lag", "ganz", "in", "ih\u00b7rem", "Bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Halb l\u00e4chelnd nennt sie ihn ihr bestes, gr\u00f6\u00dftes Gl\u00fccke.", "tokens": ["Halb", "l\u00e4\u00b7chelnd", "nennt", "sie", "ihn", "ihr", "bes\u00b7tes", ",", "gr\u00f6\u00df\u00b7tes", "Gl\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVFIN", "PPER", "PPER", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sein Herz, von hei\u00dfem Blut erf\u00fcllt,", "tokens": ["Sein", "Herz", ",", "von", "hei\u00b7\u00dfem", "Blut", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dr\u00fcckt sich an ihrs, l\u00e4\u00dft nach, dr\u00fcckt wieder;", "tokens": ["Dr\u00fcckt", "sich", "an", "ihrs", ",", "l\u00e4\u00dft", "nach", ",", "dr\u00fcckt", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "$,", "VVFIN", "PTKVZ", "$,", "VVFIN", "ADV", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Und wenn das Blut einmal von Liebe schwillt,", "tokens": ["Und", "wenn", "das", "Blut", "ein\u00b7mal", "von", "Lie\u00b7be", "schwillt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Rei\u00dft es gar leicht der Ehrfurcht Grenzen nieder.", "tokens": ["Rei\u00dft", "es", "gar", "leicht", "der", "Ehr\u00b7furcht", "Gren\u00b7zen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.4": {"line.1": {"text": "Konnt Daphnis wohl dem Reiz des Busens widerstehn?", "tokens": ["Konnt", "Daph\u00b7nis", "wohl", "dem", "Reiz", "des", "Bu\u00b7sens", "wi\u00b7der\u00b7stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bei jedem Ku\u00df durchgl\u00fcht' ihn neues Feuer,", "tokens": ["Bei", "je\u00b7dem", "Ku\u00df", "durch\u00b7gl\u00fcht'", "ihn", "neu\u00b7es", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bei jedem Kusse ward er freier,", "tokens": ["Bei", "je\u00b7dem", "Kus\u00b7se", "ward", "er", "frei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sie \u2013 und sie \u2013 lie\u00df es geschehn.", "tokens": ["Und", "sie", "\u2013", "und", "sie", "\u2013", "lie\u00df", "es", "ge\u00b7schehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "KON", "PPER", "$(", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "Der Sch\u00e4fer f\u00fchlt ein taumelndes Entz\u00fccken,", "tokens": ["Der", "Sch\u00e4\u00b7fer", "f\u00fchlt", "ein", "tau\u00b7meln\u00b7des", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und da sie schweigt, da jetzt in ihren Blicken", "tokens": ["Und", "da", "sie", "schweigt", ",", "da", "jetzt", "in", "ih\u00b7ren", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Anstatt der Munterkeit ein sanfter Kummer liegt,", "tokens": ["An\u00b7statt", "der", "Mun\u00b7ter\u00b7keit", "ein", "sanf\u00b7ter", "Kum\u00b7mer", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Glaubt er sie auf dem Grad von feurigen Entz\u00fccken,", "tokens": ["Glaubt", "er", "sie", "auf", "dem", "Grad", "von", "feu\u00b7ri\u00b7gen", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo man die M\u00e4dchen leicht besiegt.", "tokens": ["Wo", "man", "die", "M\u00e4d\u00b7chen", "leicht", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sie war an seine Brust gesunken,", "tokens": ["Sie", "war", "an", "sei\u00b7ne", "Brust", "ge\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und er zuletzt, von Wollust trunken,", "tokens": ["Und", "er", "zu\u00b7letzt", ",", "von", "Wol\u00b7lust", "trun\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erbat sich, Amor, Sieg von dir.", "tokens": ["Er\u00b7bat", "sich", ",", "A\u00b7mor", ",", "Sieg", "von", "dir", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "NE", "$,", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch schnell entri\u00df sie sich den Armen,", "tokens": ["Doch", "schnell", "ent\u00b7ri\u00df", "sie", "sich", "den", "Ar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die sie umfa\u00dften: \u00bbAus Erbarmen\u00ab,", "tokens": ["Die", "sie", "um\u00b7fa\u00df\u00b7ten", ":", "\u00bb", "Aus", "Er\u00b7bar\u00b7men", "\u00ab", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "VVFIN", "$.", "$(", "APPR", "NN", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Rief sie, \u00bbkomm, eile weg von hier.\u00ab", "tokens": ["Rief", "sie", ",", "\u00bb", "komm", ",", "ei\u00b7le", "weg", "von", "hier", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "VVFIN", "$,", "VVFIN", "ADV", "APPR", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Best\u00fcrzt und zitternd folgt er ihr.", "tokens": ["Be\u00b7st\u00fcrzt", "und", "zit\u00b7ternd", "folgt", "er", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Da sprach sie z\u00e4rtlich: \u00bbLa\u00df nicht mehr", "tokens": ["Da", "sprach", "sie", "z\u00e4rt\u00b7lich", ":", "\u00bb", "La\u00df", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "$(", "VVIMP", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich die Gelegenheit verf\u00fchren;", "tokens": ["Dich", "die", "Ge\u00b7le\u00b7gen\u00b7heit", "ver\u00b7f\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "O Freund, ich liebe dich zu sehr,", "tokens": ["O", "Freund", ",", "ich", "lie\u00b7be", "dich", "zu", "sehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um dich unw\u00fcrdig zu verlieren.\u00ab", "tokens": ["Um", "dich", "un\u00b7w\u00fcr\u00b7dig", "zu", "ver\u00b7lie\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PRF", "ADJD", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}