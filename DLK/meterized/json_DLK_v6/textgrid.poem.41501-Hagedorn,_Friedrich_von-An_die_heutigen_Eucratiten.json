{"textgrid.poem.41501": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "An die heutigen Eucratiten", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was edle Seelen Wollust nennen,", "tokens": ["Was", "ed\u00b7le", "See\u00b7len", "Wol\u00b7lust", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vermischt mit schn\u00f6den L\u00fcsten nicht!", "tokens": ["Ver\u00b7mischt", "mit", "schn\u00f6\u00b7den", "L\u00fcs\u00b7ten", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der \u00e4chten Freude Werth zu kennen", "tokens": ["Der", "\u00e4ch\u00b7ten", "Freu\u00b7de", "Werth", "zu", "ken\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist gleichfalls unsers Daseins Pflicht.", "tokens": ["Ist", "gleich\u00b7falls", "un\u00b7sers", "Da\u00b7seins", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr fallt oft tiefer, klimmt oft h\u00f6her,", "tokens": ["Ihr", "fallt", "oft", "tie\u00b7fer", ",", "klimmt", "oft", "h\u00f6\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als die begl\u00fcckende Natur:", "tokens": ["Als", "die", "be\u00b7gl\u00fc\u00b7cken\u00b7de", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr kennt vielleicht Epicur\u00e4er;", "tokens": ["Ihr", "kennt", "viel\u00b7leicht", "E\u00b7pi\u00b7cu\u00b7r\u00e4\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Doch kennt ihr auch den Epicur?", "tokens": ["Doch", "kennt", "ihr", "auch", "den", "E\u00b7pi\u00b7cur", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sind nicht der wahren Freude Grenzen", "tokens": ["Sind", "nicht", "der", "wah\u00b7ren", "Freu\u00b7de", "Gren\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geschmack und Wahl und Artigkeit?", "tokens": ["Ge\u00b7schmack", "und", "Wahl", "und", "Ar\u00b7tig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entehrte Scipio mit T\u00e4nzen", "tokens": ["Ent\u00b7ehr\u00b7te", "Sci\u00b7pio", "mit", "T\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Den Heldenruhm und seine Zeit?", "tokens": ["Den", "Hel\u00b7den\u00b7ruhm", "und", "sei\u00b7ne", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Liebe, die auch Weise loben,", "tokens": ["Die", "Lie\u00b7be", ",", "die", "auch", "Wei\u00b7se", "lo\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Macht ihre Liebe nicht zu frei:", "tokens": ["Macht", "ih\u00b7re", "Lie\u00b7be", "nicht", "zu", "frei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Der Wein, den Plato selbst erhoben,", "tokens": ["Der", "Wein", ",", "den", "Pla\u00b7to", "selbst", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Verf\u00fchrt ihn nicht zur V\u00f6llerei.", "tokens": ["Ver\u00b7f\u00fchrt", "ihn", "nicht", "zur", "V\u00f6l\u00b7le\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Zu altdeutsch trinken, taumelnd k\u00fcssen", "tokens": ["Zu", "alt\u00b7deutsch", "trin\u00b7ken", ",", "tau\u00b7melnd", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PTKA", "ADJD", "VVINF", "$,", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist h\u00f6chstens nur der Wenden Lust:", "tokens": ["Ist", "h\u00f6chs\u00b7tens", "nur", "der", "Wen\u00b7den", "Lust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Kluge zu genie\u00dfen wissen,", "tokens": ["Wie", "Klu\u00b7ge", "zu", "ge\u00b7nie\u00b7\u00dfen", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verbleibt dem P\u00f6bel unbewu\u00dft,", "tokens": ["Ver\u00b7bleibt", "dem", "P\u00f6\u00b7bel", "un\u00b7be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem P\u00f6bel, der in Gift verkehret,", "tokens": ["Dem", "P\u00f6\u00b7bel", ",", "der", "in", "Gift", "ver\u00b7keh\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was unserm Leben St\u00e4rkung bringt,", "tokens": ["Was", "un\u00b7serm", "Le\u00b7ben", "St\u00e4r\u00b7kung", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und der die Becher wirklich leeret,", "tokens": ["Und", "der", "die", "Be\u00b7cher", "wirk\u00b7lich", "lee\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wovon der Dichter doch nur singt.", "tokens": ["Wo\u00b7von", "der", "Dich\u00b7ter", "doch", "nur", "singt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Von welchen V\u00e4tern, welchen M\u00fcttern", "tokens": ["Von", "wel\u00b7chen", "V\u00e4\u00b7tern", ",", "wel\u00b7chen", "M\u00fct\u00b7tern"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PWAT", "NN", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erbt ihr die Einsicht gro\u00dfer Welt?", "tokens": ["Erbt", "ihr", "die", "Ein\u00b7sicht", "gro\u00b7\u00dfer", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Liebe kennt ihr aus den Rittern,", "tokens": ["Die", "Lie\u00b7be", "kennt", "ihr", "aus", "den", "Rit\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die uns Cervantes dargestellt;", "tokens": ["Die", "uns", "Cer\u00b7van\u00b7tes", "dar\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Euch hei\u00dft der Wein der Unart Zunder,", "tokens": ["Euch", "hei\u00dft", "der", "Wein", "der", "Un\u00b7art", "Zun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und fremder V\u00f6lker Trinklied Tand:", "tokens": ["Und", "frem\u00b7der", "V\u00f6l\u00b7ker", "Trin\u00b7klied", "Tand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O daf\u00fcr bleib' euch der Burgunder,", "tokens": ["O", "da\u00b7f\u00fcr", "bleib'", "euch", "der", "Bur\u00b7gun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Lainez und Babet unbekannt!", "tokens": ["Lai\u00b7nez", "und", "Ba\u00b7bet", "un\u00b7be\u00b7kannt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Unterschied in Witz und Tugend", "tokens": ["Der", "Un\u00b7ter\u00b7schied", "in", "Witz", "und", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist gr\u00f6\u00dfer, als man denken kann.", "tokens": ["Ist", "gr\u00f6\u00b7\u00dfer", ",", "als", "man", "den\u00b7ken", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es zeigt die Sprache muntrer Jugend", "tokens": ["Es", "zeigt", "die", "Spra\u00b7che", "mun\u00b7trer", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht stets der Jugend Fehler an.", "tokens": ["Nicht", "stets", "der", "Ju\u00b7gend", "Feh\u00b7ler", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Petrarchen, der in Versen herzet,", "tokens": ["Pe\u00b7trar\u00b7chen", ",", "der", "in", "Ver\u00b7sen", "her\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "War Laura keine Lesbia;", "tokens": ["War", "Lau\u00b7ra", "kei\u00b7ne", "Les\u00b7bia", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PIAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Voiture, der so feurig scherzet,", "tokens": ["Voi\u00b7tu\u00b7re", ",", "der", "so", "feu\u00b7rig", "scher\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Trank Wasser, wie ein Seneca.", "tokens": ["Trank", "Was\u00b7ser", ",", "wie", "ein", "Se\u00b7ne\u00b7ca", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PWAV", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nie ist der Einfalt Urtheil schw\u00e4cher,", "tokens": ["Nie", "ist", "der", "Ein\u00b7falt", "Ur\u00b7theil", "schw\u00e4\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als wann's auf Schriftverfasser geht.", "tokens": ["Als", "wann's", "auf", "Schrift\u00b7ver\u00b7fas\u00b7ser", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da hei\u00dft Sallust kein Ehebrecher:", "tokens": ["Da", "hei\u00dft", "Sal\u00b7lust", "kein", "E\u00b7heb\u00b7re\u00b7cher", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "PIAT", "NN", "$."], "meter": "--+-+-+--", "measure": "anapaest.init"}, "line.4": {"text": "Er lehrt ja streng, als Epictet;", "tokens": ["Er", "lehrt", "ja", "streng", ",", "als", "E\u00b7pic\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVFIN", "$,", "KOUS", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Doch Plinius ist zu verdammen:", "tokens": ["Doch", "Pli\u00b7nius", "ist", "zu", "ver\u00b7dam\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Der hatte Welt und Laster lieb.", "tokens": ["Der", "hat\u00b7te", "Welt", "und", "Las\u00b7ter", "lieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie sehr verdient er Straf' und Flammen,", "tokens": ["Wie", "sehr", "ver\u00b7dient", "er", "Straf'", "und", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil er ein freies Liedchen schrieb!", "tokens": ["Weil", "er", "ein", "frei\u00b7es", "Lied\u00b7chen", "schrieb", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So liebreich und so gr\u00fcndlich denken", "tokens": ["So", "lieb\u00b7reich", "und", "so", "gr\u00fcnd\u00b7lich", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Tadler spielender Vernunft,", "tokens": ["Die", "Tad\u00b7ler", "spie\u00b7len\u00b7der", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fcnschen, um sie einzuschr\u00e4nken,", "tokens": ["Und", "w\u00fcn\u00b7schen", ",", "um", "sie", "ein\u00b7zu\u00b7schr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUI", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der ernsten Zeiten Wiederkunft;", "tokens": ["Der", "erns\u00b7ten", "Zei\u00b7ten", "Wie\u00b7der\u00b7kunft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Jahre, da des Gastmahls L\u00e4nge", "tokens": ["Der", "Jah\u00b7re", ",", "da", "des", "Gast\u00b7mahls", "L\u00e4n\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den steifen Sitzern Lust gebar,", "tokens": ["Den", "stei\u00b7fen", "Sit\u00b7zern", "Lust", "ge\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wiederholtes Wortgepr\u00e4nge,", "tokens": ["Und", "wie\u00b7der\u00b7hol\u00b7tes", "Wort\u00b7ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was jetzt ein Lied von Carpsern, war.", "tokens": ["Was", "jetzt", "ein", "Lied", "von", "Carp\u00b7sern", ",", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "APPR", "NN", "$,", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}