{"dta.poem.8535": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Freundlich .", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1860", "urn": "urn:nbn:de:kobv:b4-200905191007", "language": ["de:0.85", "sv:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Und als ich nun gen Balsora kam,", "tokens": ["Und", "als", "ich", "nun", "gen", "Bal\u00b7so\u00b7ra", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da rief die Stimme vom Gitter:", "tokens": ["Da", "rief", "die", "Stim\u00b7me", "vom", "Git\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201ebist du es, Hassan, geliebter Freund,", "tokens": ["\u201e", "bist", "du", "es", ",", "Has\u00b7san", ",", "ge\u00b7lieb\u00b7ter", "Freund", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPER", "$,", "NE", "$,", "ADJA", "NN", "$,"], "meter": "+--++-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Komm herein, da\u00df ich dich umfange,", "tokens": ["Komm", "her\u00b7ein", ",", "da\u00df", "ich", "dich", "um\u00b7fan\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ich die F\u00fc\u00dfe dir waschen mag,", "tokens": ["Da\u00df", "ich", "die", "F\u00fc\u00b7\u00dfe", "dir", "wa\u00b7schen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und mag die Stirne dir salben.\u201c", "tokens": ["Und", "mag", "die", "Stir\u00b7ne", "dir", "sal\u00b7ben", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Und als ich nach Mekka, der heiligen, kam,", "tokens": ["Und", "als", "ich", "nach", "Mek\u00b7ka", ",", "der", "hei\u00b7li\u00b7gen", ",", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NE", "$,", "ART", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "Da gr\u00fc\u00dften mich viele Stimmen;", "tokens": ["Da", "gr\u00fc\u00df\u00b7ten", "mich", "vie\u00b7le", "Stim\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "\u201enicht bin ich Hassan, und Jener nicht,", "tokens": ["\u201e", "nicht", "bin", "ich", "Has\u00b7san", ",", "und", "Je\u00b7ner", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "VAFIN", "PPER", "NE", "$,", "KON", "NE", "PTKNEG", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Doch halt\u2019 ich Allah\u2019s Gebote;", "tokens": ["Doch", "halt'", "ich", "Al\u00b7lah's", "Ge\u00b7bo\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Drum hat er gesegnet das Antlitz mir,", "tokens": ["Drum", "hat", "er", "ge\u00b7seg\u00b7net", "das", "Ant\u00b7litz", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVFIN", "ART", "NN", "PPER", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Da\u00df ich Jegliches Freund ihm erscheine.\u201c", "tokens": ["Da\u00df", "ich", "Jeg\u00b7li\u00b7ches", "Freund", "ihm", "er\u00b7schei\u00b7ne", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}}}}