{"textgrid.poem.25754": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Constantia! du tief verstecktes Thal,", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Constantia! du tief verstecktes Thal,", "tokens": ["Con\u00b7stan\u00b7tia", "!", "du", "tief", "ver\u00b7steck\u00b7tes", "Thal", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Das dunkle B\u00fcsche rund umkr\u00e4nzen,", "tokens": ["Das", "dunk\u00b7le", "B\u00fc\u00b7sche", "rund", "um\u00b7kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erhelle dich, und la\u00df im Mondenstrahl'", "tokens": ["Er\u00b7hel\u00b7le", "dich", ",", "und", "la\u00df", "im", "Mon\u00b7den\u00b7strahl'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVIMP", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die wei\u00dfen Felsenw\u00e4nde gl\u00e4nzen,", "tokens": ["Die", "wei\u00b7\u00dfen", "Fel\u00b7sen\u00b7w\u00e4n\u00b7de", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Denn sieh! dein alter Freund ist da,", "tokens": ["Denn", "sieh", "!", "dein", "al\u00b7ter", "Freund", "ist", "da", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$.", "PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Constantia!", "tokens": ["Con\u00b7stan\u00b7tia", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Die halbe Welt durchstrich ", "tokens": ["Die", "hal\u00b7be", "Welt", "durch\u00b7strich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Die Werke der Natur zu schauen;", "tokens": ["Die", "Wer\u00b7ke", "der", "Na\u00b7tur", "zu", "schau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Den Preis behielt zuletzt der Genfer See.", "tokens": ["Den", "Preis", "be\u00b7hielt", "zu\u00b7letzt", "der", "Gen\u00b7fer", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Auch ich sah ihn; doch ", "tokens": ["Auch", "ich", "sah", "ihn", ";", "doch"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "$.", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "Zog ich dich vor, als ich dich sah,", "tokens": ["Zog", "ich", "dich", "vor", ",", "als", "ich", "dich", "sah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKVZ", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Constantia!", "tokens": ["Con\u00b7stan\u00b7tia", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "O wie viel lieber h\u00f6rt' ich deinen Bach", "tokens": ["O", "wie", "viel", "lie\u00b7ber", "h\u00f6rt'", "ich", "dei\u00b7nen", "Bach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ADV", "ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Sanft rieseln, als den Rheinfall toben!", "tokens": ["Sanft", "rie\u00b7seln", ",", "als", "den", "Rhein\u00b7fall", "to\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und schlugen deine Nachtigallen: ach!", "tokens": ["Und", "schlu\u00b7gen", "dei\u00b7ne", "Nach\u00b7ti\u00b7gal\u00b7len", ":", "ach", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "XY", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Weit \u00fcber Welt und Gl\u00fcck erhoben", "tokens": ["Weit", "\u00fc\u00b7ber", "Welt", "und", "Gl\u00fcck", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "D\u00fcnkt' ich Ungl\u00fccklicher mich da,", "tokens": ["D\u00fcnkt'", "ich", "Un\u00b7gl\u00fcck\u00b7li\u00b7cher", "mich", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PPER", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Constantia!", "tokens": ["Con\u00b7stan\u00b7tia", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.19": {"text": "Mag er ber\u00fchmt und noch so theuer seyn", "tokens": ["Mag", "er", "be\u00b7r\u00fchmt", "und", "noch", "so", "theu\u00b7er", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADJD", "KON", "ADV", "ADV", "ADJD", "VAINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Der Berg, der deinen Namen f\u00fchret", "tokens": ["Der", "Berg", ",", "der", "dei\u00b7nen", "Na\u00b7men", "f\u00fch\u00b7ret"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Und gibt er gleich den F\u00fcrsten s\u00fc\u00dfern Wein,", "tokens": ["Und", "gibt", "er", "gleich", "den", "F\u00fcrs\u00b7ten", "s\u00fc\u00b7\u00dfern", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Als ganz Germanien gebieret:", "tokens": ["Als", "ganz", "Ger\u00b7ma\u00b7ni\u00b7en", "ge\u00b7bie\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Ich n\u00e4hme, l\u00e4g't zur Wahl ihr da,", "tokens": ["Ich", "n\u00e4h\u00b7me", ",", "l\u00e4g't", "zur", "Wahl", "ihr", "da", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "APPRART", "NN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Constantia!", "tokens": ["Con\u00b7stan\u00b7tia", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.25": {"text": "Durch deine B\u00fcsche wird zum letztenmal", "tokens": ["Durch", "dei\u00b7ne", "B\u00fc\u00b7sche", "wird", "zum", "letz\u00b7ten\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "APPRART", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Heut Zephyr meine Seufzer wehen.", "tokens": ["Heut", "Ze\u00b7phyr", "mei\u00b7ne", "Seuf\u00b7zer", "we\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Und k\u00fcnftig wirst du, mein geliebtes Thal,", "tokens": ["Und", "k\u00fcnf\u00b7tig", "wirst", "du", ",", "mein", "ge\u00b7lieb\u00b7tes", "Thal", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Von mir verlassen, einsam stehen;", "tokens": ["Von", "mir", "ver\u00b7las\u00b7sen", ",", "ein\u00b7sam", "ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Werd' ich dich wieder schauen? \u2013 Ja!", "tokens": ["Werd'", "ich", "dich", "wie\u00b7der", "schau\u00b7en", "?", "\u2013", "Ja", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "VVINF", "$.", "$(", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Constantia!", "tokens": ["Con\u00b7stan\u00b7tia", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}