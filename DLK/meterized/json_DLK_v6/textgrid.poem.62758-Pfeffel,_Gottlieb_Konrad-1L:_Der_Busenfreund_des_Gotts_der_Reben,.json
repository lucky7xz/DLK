{"textgrid.poem.62758": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Busenfreund des Gotts der Reben,", "genre": "verse", "period": "N.A.", "pub_year": 1754, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Busenfreund des Gotts der Reben,", "tokens": ["Der", "Bu\u00b7sen\u00b7freund", "des", "Gotts", "der", "Re\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Thrax hat das Zechen aufgegeben.", "tokens": ["Thrax", "hat", "das", "Ze\u00b7chen", "auf\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "O ja! denn in dem Augenblicke", "tokens": ["O", "ja", "!", "denn", "in", "dem", "Au\u00b7gen\u00b7bli\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "ITJ", "$.", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "K\u00f6mmt man von seinem Grab zur\u00fccke.", "tokens": ["K\u00f6mmt", "man", "von", "sei\u00b7nem", "Grab", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Dulcindor hat sich hoch vermessen,", "tokens": ["Dul\u00b7cin\u00b7dor", "hat", "sich", "hoch", "ver\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Alisen ewig zu vergessen.", "tokens": ["A\u00b7li\u00b7sen", "e\u00b7wig", "zu", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Der k\u00fchne Geck ward von Alisen", "tokens": ["Der", "k\u00fch\u00b7ne", "Geck", "ward", "von", "A\u00b7li\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "NE"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Mit Schimpf und Schande fortgewiesen.", "tokens": ["Mit", "Schimpf", "und", "Schan\u00b7de", "fort\u00b7ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Griselde will in ihrem Leben", "tokens": ["Gri\u00b7sel\u00b7de", "will", "in", "ih\u00b7rem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Spiegel keinen Blick mehr geben.", "tokens": ["Dem", "Spie\u00b7gel", "kei\u00b7nen", "Blick", "mehr", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sie glaubet beym Vor\u00fcbergehen", "tokens": ["Sie", "glau\u00b7bet", "beym", "Vor\u00b7\u00fc\u00b7ber\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Stets ein Gespenst darinn zu sehen.", "tokens": ["Stets", "ein", "Ge\u00b7spenst", "da\u00b7rinn", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Dem gl\u00fccklichen Strophil verfliessen", "tokens": ["Dem", "gl\u00fcck\u00b7li\u00b7chen", "Stro\u00b7phil", "ver\u00b7flies\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die Stunden unter Wein und K\u00fcssen.", "tokens": ["Die", "Stun\u00b7den", "un\u00b7ter", "Wein", "und", "K\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Er selbst sagt es auf zwanzig Bogen", "tokens": ["Er", "selbst", "sagt", "es", "auf", "zwan\u00b7zig", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "APPR", "CARD", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Von Oden, Liedern und Eklogen.", "tokens": ["Von", "O\u00b7den", ",", "Lie\u00b7dern", "und", "Ek\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Der stolze Ritter Curt vom Lande", "tokens": ["Der", "stol\u00b7ze", "Rit\u00b7ter", "Curt", "vom", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NE", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Freyt Lieschen aus dem B\u00fcrgerstande:", "tokens": ["Freyt", "Lie\u00b7schen", "aus", "dem", "B\u00fcr\u00b7ger\u00b7stan\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Die Braut hat sechzigtausend Gulden;", "tokens": ["Die", "Braut", "hat", "sech\u00b7zig\u00b7tau\u00b7send", "Gul\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Damit bezahlt er seine Schulden.", "tokens": ["Da\u00b7mit", "be\u00b7zahlt", "er", "sei\u00b7ne", "Schul\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Ismenens Mann starb wohl betaget.", "tokens": ["Is\u00b7me\u00b7nens", "Mann", "starb", "wohl", "be\u00b7ta\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADV", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Das junge Weibchen weint und klaget.", "tokens": ["Das", "jun\u00b7ge", "Weib\u00b7chen", "weint", "und", "kla\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Das Wittwenjahr! das ist der Knoten,", "tokens": ["Das", "Witt\u00b7wen\u00b7jahr", "!", "das", "ist", "der", "Kno\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nur das beweint sie, nicht den Todten.", "tokens": ["Nur", "das", "be\u00b7weint", "sie", ",", "nicht", "den", "Tod\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "$,", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Chrysant, der nur auf Wucher denket,", "tokens": ["Chry\u00b7sant", ",", "der", "nur", "auf", "Wu\u00b7cher", "den\u00b7ket", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat heut ein armes Weib beschenket.", "tokens": ["Hat", "heut", "ein", "ar\u00b7mes", "Weib", "be\u00b7schen\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Er thats, damit sie beten solle,", "tokens": ["Er", "thats", ",", "da\u00b7mit", "sie", "be\u00b7ten", "sol\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Gott sein Geld vermehren wolle.", "tokens": ["Da\u00df", "Gott", "sein", "Geld", "ver\u00b7meh\u00b7ren", "wol\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Pachom spei\u00dft \u00f6fters bey Philisten;", "tokens": ["Pa\u00b7chom", "spei\u00dft", "\u00f6f\u00b7ters", "bey", "Phi\u00b7lis\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Ketzerfeind beym Calvinisten.", "tokens": ["Der", "Ket\u00b7zer\u00b7feind", "beym", "Cal\u00b7vi\u00b7nis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Der Ketzer, unter uns gesprochen,", "tokens": ["Der", "Ket\u00b7zer", ",", "un\u00b7ter", "uns", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "L\u00e4\u00dft desto orthodoxer kochen.", "tokens": ["L\u00e4\u00dft", "des\u00b7to", "or\u00b7tho\u00b7do\u00b7xer", "ko\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Balbs Meisterwerk von dreyzehn B\u00e4nden", "tokens": ["Balbs", "Meis\u00b7ter\u00b7werk", "von", "drey\u00b7zehn", "B\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist nun in aller Menschen H\u00e4nden.", "tokens": ["Ist", "nun", "in", "al\u00b7ler", "Men\u00b7schen", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Man kriegt es von den Tr\u00f6deljuden", "tokens": ["Man", "kriegt", "es", "von", "den", "Tr\u00f6\u00b7del\u00b7ju\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und in den K\u00e4s- und H\u00e4ringsbuden,", "tokens": ["Und", "in", "den", "K\u00e4s", "und", "H\u00e4\u00b7rings\u00b7bu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Laidion will sich bequemen", "tokens": ["Lai\u00b7di\u00b7on", "will", "sich", "be\u00b7que\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PRF", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Den h\u00e4\u00dflichen Marull zu nehmen.", "tokens": ["Den", "h\u00e4\u00df\u00b7li\u00b7chen", "Ma\u00b7rull", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das kann nicht seyn!", "tokens": ["Das", "kann", "nicht", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Mich reizt, so sprach die kluge Dirne,", "tokens": ["Mich", "reizt", ",", "so", "sprach", "die", "klu\u00b7ge", "Dir\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "An ihm die sch\u00f6ne breite Stirne.", "tokens": ["An", "ihm", "die", "sch\u00f6\u00b7ne", "brei\u00b7te", "Stir\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So r\u00e4um ichs ein.", "tokens": ["So", "r\u00e4um", "ichs", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}