{"dta.poem.20596": {"metadata": {"author": {"name": "Hebel, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Der Storch .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1803", "urn": "urn:nbn:de:kobv:b4-200905192133", "language": ["de:0.99"], "booktitle": "[Hebel, Johann Peter]: Allemannische Gedichte. Karlsruhe, 1803."}, "poem": {"stanza.1": {"line.1": {"text": "Willkumm Her Storch! bisch au scho do,               ", "tokens": ["Will\u00b7kumm", "Her", "Storch", "!", "bisch", "au", "scho", "do", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$.", "APPR", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und schmecksch im Weiher d\u2019 Fr\u00f6sche scho?", "tokens": ["und", "schmeck\u00b7sch", "im", "Wei\u00b7her", "d'", "Fr\u00f6\u00b7sche", "scho", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "NE", "NE", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und meinsch der Winter heig si Sach,", "tokens": ["Und", "meinsch", "der", "Win\u00b7ter", "heig", "si", "Sach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und \u2019s besser Wetter ch\u00f6mm alsgmach?", "tokens": ["und", "'s", "bes\u00b7ser", "Wet\u00b7ter", "ch\u00f6mm", "alsg\u00b7mach", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJA", "NN", "NE", "NE", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "He io, der Schnee gieng \u00fcberal;", "tokens": ["He", "i\u00b7o", ",", "der", "Schnee", "gieng", "\u00fc\u00b7be\u00b7ral", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "me meint, es werd scho gr\u00fcn im Thal.", "tokens": ["me", "meint", ",", "es", "werd", "scho", "gr\u00fcn", "im", "Thal", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "$,", "PPER", "VAFIN", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Himmel isch so rein und blau,", "tokens": ["Der", "Him\u00b7mel", "isch", "so", "rein", "und", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und \u2019s weiht ein a so mild und lau. \u2014", "tokens": ["und", "'s", "weiht", "ein", "a", "so", "mild", "und", "lau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NE", "ADV", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Nei loset, wiener welsche cha!", "tokens": ["Nei", "lo\u00b7set", ",", "wie\u00b7ner", "wel\u00b7sche", "cha", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verstoht men au ne W\u00f6rtli dra?", "tokens": ["Ver\u00b7stoht", "men", "au", "ne", "W\u00f6rt\u00b7li", "dra", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NE", "NE", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Drum chunnt er \u00fcber Strom und Meer", "tokens": ["Drum", "chunnt", "er", "\u00fc\u00b7ber", "Strom", "und", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "us wite fremde L\u00e4ndere her.", "tokens": ["us", "wi\u00b7te", "frem\u00b7de", "L\u00e4n\u00b7de\u00b7re", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was bringsch denn Neu\u2019s us Afrika?", "tokens": ["Was", "bringsch", "denn", "Neu's", "us", "Af\u00b7ri\u00b7ka", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "NE", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hen gwis au so Umst\u00e4nd gha,", "tokens": ["Sie", "hen", "gwis", "au", "so", "Um\u00b7st\u00e4nd", "gha", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "ADV", "NN", "NE", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.3": {"text": "und d\u2019 B\u00fcchse gspannt, und d\u2019 S\u00e4bel g\u2019wezt,", "tokens": ["und", "d'", "B\u00fcch\u00b7se", "gs\u00b7pannt", ",", "und", "d'", "S\u00e4\u00b7bel", "g'\u00b7wezt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VVFIN", "$,", "KON", "NE", "NN", "VVPP", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "und Freiheits-B\u00e4um vor d\u2019 Chilche gsezt?", "tokens": ["und", "Frei\u00b7heits\u00b7B\u00e4\u00b7um", "vor", "d'", "Chil\u00b7che", "gsezt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "De hesch so rothi Str\u00fcmpfli a.", "tokens": ["De", "hesch", "so", "ro\u00b7thi", "Str\u00fcm\u00b7pf\u00b7li", "a."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Isch \u00f6bbe Blut vom Schlachtfeld dra?", "tokens": ["Isch", "\u00f6b\u00b7be", "Blut", "vom", "Schlacht\u00b7feld", "dra", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo hesch die schwarze Fegge gno?", "tokens": ["Wo", "hesch", "die", "schwar\u00b7ze", "Feg\u00b7ge", "gno", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bisch \u00f6bbe z\u2019nooch an d\u2019 Flamme cho?", "tokens": ["Bisch", "\u00f6b\u00b7be", "z'\u00b7nooch", "an", "d'", "Flam\u00b7me", "cho", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "APPR", "NE", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Um das h\u00e4ttsch \u00fcber Land und Meer", "tokens": ["Um", "das", "h\u00e4ttsch", "\u00fc\u00b7ber", "Land", "und", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "ADJD", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "nit reise d\u00f6rfe hi und her", "tokens": ["nit", "rei\u00b7se", "d\u00f6r\u00b7fe", "hi", "und", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "FM", "FM", "FM", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "vom Rhi\u2019-Strom bis in Afrika;", "tokens": ["vom", "Rhi'\u00b7Strom", "bis", "in", "Af\u00b7ri\u00b7ka", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPR", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "de h\u00e4ttschs io in der N\u00f6\u00f6chi g\u2019ha.", "tokens": ["de", "h\u00e4ttschs", "i\u00b7o", "in", "der", "N\u00f6\u00f6\u00b7chi", "g'\u00b7ha", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Mer w\u00fcsse leider au dervo,", "tokens": ["Mer", "w\u00fcs\u00b7se", "lei\u00b7der", "au", "der\u00b7vo", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und mengi Wunde blutet no,", "tokens": ["und", "men\u00b7gi", "Wun\u00b7de", "blu\u00b7tet", "no", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "VVFIN", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "und \u2019s drukt no menge Chummer schwer,", "tokens": ["und", "'s", "drukt", "no", "men\u00b7ge", "Chum\u00b7mer", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NE", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und menge sch\u00f6ne Trog isch leer.", "tokens": ["und", "men\u00b7ge", "sch\u00f6\u00b7ne", "Trog", "isch", "leer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "ADJD", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Und witer an den Alpe hi", "tokens": ["Und", "wi\u00b7ter", "an", "den", "Al\u00b7pe", "hi"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ischs, Gott erbarms, no \u00e4rger gsi,", "tokens": ["ischs", ",", "Gott", "er\u00b7barms", ",", "no", "\u00e4r\u00b7ger", "gsi", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "NN", "NE", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und Weh und Ach het usem Wald", "tokens": ["und", "Weh", "und", "Ach", "het", "u\u00b7sem", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und us de Berge widerhallt.", "tokens": ["und", "us", "de", "Ber\u00b7ge", "wi\u00b7der\u00b7hallt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ans Wilhelm Telle Freiheits-Hut", "tokens": ["Ans", "Wil\u00b7helm", "Tel\u00b7le", "Frei\u00b7heits\u00b7Hut"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hangt menge Tropfe Schwitzerblut.", "tokens": ["hangt", "men\u00b7ge", "Trop\u00b7fe", "Schwit\u00b7zer\u00b7blut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Wie hets nit ummen blizt und g\u2019chracht,", "tokens": ["Wie", "hets", "nit", "um\u00b7men", "blizt", "und", "g'\u00b7chracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PTKNEG", "VVINF", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und dunderet in der Wetter-Nacht!", "tokens": ["und", "dun\u00b7de\u00b7ret", "in", "der", "Wet\u00b7ter\u00b7Nacht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Doch \u00f6bben in der Wetter-Nacht", "tokens": ["Doch", "\u00f6b\u00b7ben", "in", "der", "Wet\u00b7ter\u00b7Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "het Gottis Engel au no gwacht \u2014", "tokens": ["het", "Got\u00b7tis", "En\u00b7gel", "au", "no", "gwacht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "NE", "NE", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was peppersch? Mer verst\u00f6hn di nit!", "tokens": ["Was", "pep\u00b7per\u00b7sch", "?", "Mer", "ver\u00b7st\u00f6hn", "di", "nit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "$.", "NN", "VVFIN", "NE", "PTKNEG", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Schwetz d\u00fctli, wenn de rede witt!", "tokens": ["Schwetz", "d\u00fct\u00b7li", ",", "wenn", "de", "re\u00b7de", "witt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "KOUS", "NE", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Gang, hol ein \u2019s Becke Chasperli!", "tokens": ["Gang", ",", "hol", "ein", "'s", "Be\u00b7cke", "Chas\u00b7per\u00b7li", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "PPER", "NE", "NE", "$."], "meter": "+--++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Er isch e Rung im Welschland gsi;", "tokens": ["Er", "isch", "e", "Rung", "im", "Wel\u00b7schland", "gsi", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJA", "NN", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er het emol go Vivis gschmekt,", "tokens": ["er", "het", "e\u00b7mol", "go", "Vi\u00b7vis", "gschmekt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "FM", "FM", "FM", "FM", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "und wie der Storch si Schnabel g\u2019strekt.", "tokens": ["und", "wie", "der", "Storch", "si", "Schna\u00b7bel", "g'\u00b7strekt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "CARD", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.12": {"line.1": {"text": "Und welsche chaner, \u2019s isch e Gruus;", "tokens": ["Und", "wel\u00b7sche", "cha\u00b7ner", ",", "'s", "isch", "e", "Gru\u00b7us", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "ADJA", "$,", "PPER", "ADJD", "NE", "NE", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "es blibt ke Wentelen im Hus,", "tokens": ["es", "blibt", "ke", "Wen\u00b7te\u00b7len", "im", "Hus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und \u2019s Glas stoht an de Fenstern ab;", "tokens": ["und", "'s", "Glas", "stoht", "an", "de", "Fens\u00b7tern", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVFIN", "APPR", "NE", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "wer wei\u00df, verstoht er ", "tokens": ["wer", "wei\u00df", ",", "ver\u00b7stoht", "er"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "PPER"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.13": {"line.1": {"text": "Zwor w\u00fcrd\u2019 er anderi Gsch\u00e4fte ha;", "tokens": ["Zwor", "w\u00fcrd'", "er", "an\u00b7de\u00b7ri", "Gsch\u00e4f\u00b7te", "ha", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADJA", "NN", "NE", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "er martschet n\u00e4ume, wenn er cha", "tokens": ["er", "mart\u00b7schet", "n\u00e4u\u00b7me", ",", "wenn", "er", "cha"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVFIN", "$,", "KOUS", "PPER", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ejez ", "tokens": ["\u201e", "jez"], "token_info": ["punct", "word"], "pos": ["$(", "NE"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "\u201ene Mos verspielt! Potz Mundie!\u201c \u2014", "tokens": ["\u201e", "ne", "Mos", "ver\u00b7spielt", "!", "Potz", "Mun\u00b7die", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "VVPP", "$.", "NN", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u2019s isch gnug, Her Storch! Mer w\u00fcsse\u2019s scho,", "tokens": ["'s", "isch", "gnug", ",", "Her", "Storch", "!", "Mer", "w\u00fcs\u00b7se's", "scho", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "$,", "NN", "NN", "$.", "NE", "NE", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und was de seisch, mer glaube\u2019s io!", "tokens": ["und", "was", "de", "seisch", ",", "mer", "glau\u00b7be's", "i\u00b7o", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NE", "ADJD", "$,", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es freut di au, a\u00df \u2019s Dorf no stoht,", "tokens": ["Es", "freut", "di", "au", ",", "a\u00df", "'s", "Dorf", "no", "stoht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "$,", "VVFIN", "PPER", "NN", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und alles gsund isch \u2014 dank der Gott!", "tokens": ["und", "al\u00b7les", "gsund", "isch", "dank", "der", "Gott", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "ADJD", "$(", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "\u2019s isch au nit alles grad und recht,", "tokens": ["'s", "isch", "au", "nit", "al\u00b7les", "grad", "und", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NE", "PTKNEG", "PIS", "ADV", "KON", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "und \u2019s Nochbers Chind isch s\u00f6lli schlecht;", "tokens": ["und", "'s", "Noch\u00b7bers", "Chind", "isch", "s\u00f6l\u00b7li", "schlecht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "FM", "FM", "FM", "FM", "ADJD", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "mi Gschwey het hinecht bynem gwacht,", "tokens": ["mi", "Gschwey", "het", "hi\u00b7necht", "by\u00b7nem", "gwacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u2019s het Gichter gha die ganzi Nacht.", "tokens": ["'s", "het", "Gich\u00b7ter", "gha", "die", "gan\u00b7zi", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Sust m\u00f6chts, Gottlob, so ziemli go,", "tokens": ["Sust", "m\u00f6chts", ",", "Gott\u00b7lob", ",", "so", "ziem\u00b7li", "go", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "NN", "$,", "ADV", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und \u2019s Feld-Picket isch n\u00fcmme do;", "tokens": ["und", "'s", "Feld\u00b7Pi\u00b7cket", "isch", "n\u00fcm\u00b7me", "do", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "ADJD", "VVFIN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "wo Lager gsi sin Zelt an Zelt,", "tokens": ["wo", "La\u00b7ger", "gsi", "sin", "Zelt", "an", "Zelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NE", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "goht iez der Pflug im Ackerfeld.", "tokens": ["goht", "iez", "der", "Pflug", "im", "A\u00b7cker\u00b7feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Und der, wo d\u2019 Storche hei\u00dfet cho,", "tokens": ["Und", "der", ",", "wo", "d'", "Stor\u00b7che", "hei\u00b7\u00dfet", "cho", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PWAV", "NE", "NN", "VVFIN", "NE", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "und d\u2019 Rabe n\u00e4hrt, isch au no do;", "tokens": ["und", "d'", "Ra\u00b7be", "n\u00e4hrt", ",", "isch", "au", "no", "do", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "VVFIN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "er schafft den Arme Brod ins Hus,", "tokens": ["er", "schafft", "den", "Ar\u00b7me", "Brod", "ins", "Hus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und heilt die alte Presten us.", "tokens": ["und", "heilt", "die", "al\u00b7te", "Pres\u00b7ten", "us", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Und wo me luegt, und luege cha,", "tokens": ["Und", "wo", "me", "luegt", ",", "und", "lu\u00b7e\u00b7ge", "cha", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "VVFIN", "$,", "KON", "VVFIN", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "se l\u00e4chlet ein der Frieden a,", "tokens": ["se", "l\u00e4ch\u00b7let", "ein", "der", "Frie\u00b7den", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie Morgeliecht, wenn d\u2019 Nacht vergoht,", "tokens": ["wie", "Mor\u00b7ge\u00b7liecht", ",", "wenn", "d'", "Nacht", "ver\u00b7goht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "KOUS", "NE", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und d\u2019 Sunne hinter de Tanne stoht.", "tokens": ["und", "d'", "Sun\u00b7ne", "hin\u00b7ter", "de", "Tan\u00b7ne", "stoht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-++-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "Gang lueg e wenig d\u2019 Gegnig a!", "tokens": ["Gang", "lu\u00b7eg", "e", "we\u00b7nig", "d'", "Geg\u00b7nig", "a", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "ADV", "NE", "NN", "NE", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "J glaub, de wirsch e Gfalle ha.", "tokens": ["J", "glaub", ",", "de", "wirsch", "e", "Gfal\u00b7le", "ha", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mi Matten isch der wol bikannt,", "tokens": ["Mi", "Mat\u00b7ten", "isch", "der", "wol", "bi\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "ART", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "am Brunnen abe linker Hand.", "tokens": ["am", "Brun\u00b7nen", "a\u00b7be", "lin\u00b7ker", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Und trifsch am Bach e Fr\u00f6schli a,", "tokens": ["Und", "trifsch", "am", "Bach", "e", "Fr\u00f6schli", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "sen ischs der gunnt. Verstick nit dra!", "tokens": ["sen", "ischs", "der", "gunnt", ".", "Ver\u00b7stick", "nit", "dra", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ART", "ADJD", "$.", "NN", "PTKNEG", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und, was i bitt, lo\u00df d\u2019Imme goh!", "tokens": ["Und", ",", "was", "i", "bitt", ",", "lo\u00df", "d'\u00b7Im\u00b7me", "goh", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "NE", "VVFIN", "$,", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Mi Gro\u00dfe seit, sie fliege scho.", "tokens": ["Mi", "Gro\u00b7\u00dfe", "seit", ",", "sie", "flie\u00b7ge", "scho", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}