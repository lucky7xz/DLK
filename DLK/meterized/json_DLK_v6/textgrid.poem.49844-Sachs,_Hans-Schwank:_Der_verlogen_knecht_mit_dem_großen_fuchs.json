{"textgrid.poem.49844": {"metadata": {"author": {"name": "Sachs, Hans", "birth": "N.A.", "death": "N.A."}, "title": "Schwank: Der verlogen knecht mit dem gro\u00dfen fuchs", "genre": "verse", "period": "N.A.", "pub_year": 1563, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein edelman in Schwabenlant,", "tokens": ["Ein", "e\u00b7del\u00b7man", "in", "Schwa\u00b7ben\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "des gschlecht und nam hie ungenant,", "tokens": ["des", "gschlecht", "und", "nam", "hie", "un\u00b7ge\u00b7nant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein frommer man, weis und gerecht,", "tokens": ["ein", "from\u00b7mer", "man", ",", "weis", "und", "ge\u00b7recht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIS", "$,", "PTKVZ", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "der het ein verlognen reitknecht,", "tokens": ["der", "het", "ein", "ver\u00b7log\u00b7nen", "reit\u00b7knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "ART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "rumredig mit gschw\u00fclstigen worten,", "tokens": ["rum\u00b7re\u00b7dig", "mit", "gschw\u00fcls\u00b7ti\u00b7gen", "wor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.6": {"text": "die lant durchloffen an vil orten,", "tokens": ["die", "lant", "durch\u00b7lof\u00b7fen", "an", "vil", "or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "het auch, wie ein alt sprichwort sagt,", "tokens": ["het", "auch", ",", "wie", "ein", "alt", "sprich\u00b7wort", "sagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWAV", "ART", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ein hunt durch das Welschlant gejagt;", "tokens": ["ein", "hunt", "durch", "das", "Wel\u00b7schlant", "ge\u00b7jagt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "darvon tet er gro\u00df wunder jehen,", "tokens": ["dar\u00b7von", "tet", "er", "gro\u00df", "wun\u00b7der", "je\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "wie er het di\u00df und jens gesehen,", "tokens": ["wie", "er", "het", "di\u00df", "und", "jens", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "PDS", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "darvon gro\u00df brocken er narriert,", "tokens": ["dar\u00b7von", "gro\u00df", "bro\u00b7cken", "er", "nar\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "und log, sam wer ims maul geschmiert.", "tokens": ["und", "log", ",", "sam", "wer", "ims", "maul", "ge\u00b7schmiert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADJD", "PWS", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "sein junkher war ein weltweis man,", "tokens": ["sein", "junk\u00b7her", "war", "ein", "welt\u00b7weis", "man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VAFIN", "ART", "PRELS", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "tet sein rumredig l\u00fcg verstan,", "tokens": ["tet", "sein", "rum\u00b7re\u00b7dig", "l\u00fcg", "ver\u00b7stan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJD", "VVFIN", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.15": {"text": "sagt oft spotweis: wie mag das sein?", "tokens": ["sagt", "oft", "spot\u00b7weis", ":", "wie", "mag", "das", "sein", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$.", "PWAV", "VMFIN", "PDS", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "so schwur der knecht denn stein und bein,", "tokens": ["so", "schwur", "der", "knecht", "denn", "stein", "und", "bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "solichs und solches wer geschehen,", "tokens": ["so\u00b7lichs", "und", "sol\u00b7ches", "wer", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KON", "PIAT", "PWS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "er hets mit sein augen gesehen;", "tokens": ["er", "hets", "mit", "sein", "au\u00b7gen", "ge\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.19": {"text": "doch wurt er oft mit worten gfangen,", "tokens": ["doch", "wurt", "er", "oft", "mit", "wor\u00b7ten", "gfan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "das er blib in der lug behangen.", "tokens": ["das", "er", "blib", "in", "der", "lug", "be\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "VVFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.21": {"text": "darnach der knecht nichts fragen tet,", "tokens": ["dar\u00b7nach", "der", "knecht", "nichts", "fra\u00b7gen", "tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.22": {"text": "weil er der lug gewonet het,", "tokens": ["weil", "er", "der", "lug", "ge\u00b7wo\u00b7net", "het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.23": {"text": "doch war er sonst diensthaft durchaus.", "tokens": ["doch", "war", "er", "sonst", "dienst\u00b7haft", "durc\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.24": {"text": "eins tages fr\u00fc ritten sie aus,", "tokens": ["eins", "ta\u00b7ges", "fr\u00fc", "rit\u00b7ten", "sie", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.25": {"text": "da sach der junkher in dem walt", "tokens": ["da", "sach", "der", "junk\u00b7her", "in", "dem", "walt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "dort laufen einen fuchsen alt", "tokens": ["dort", "lau\u00b7fen", "ei\u00b7nen", "fuch\u00b7sen", "alt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "und sprach: schau, schau, ein gro\u00dfer fuchs!", "tokens": ["und", "sprach", ":", "schau", ",", "schau", ",", "ein", "gro\u00b7\u00dfer", "fuchs", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PTKVZ", "$,", "PTKVZ", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "der knecht sach den und antwort flugs:", "tokens": ["der", "knecht", "sach", "den", "und", "ant\u00b7wort", "flugs", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "KON", "NN", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.29": {"text": "junkher, habt ir ob dem fuchs wunder?", "tokens": ["junk\u00b7her", ",", "habt", "ir", "ob", "dem", "fuchs", "wun\u00b7der", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VAFIN", "PPER", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "ich bin gwest in eim lant besunder,", "tokens": ["ich", "bin", "gwest", "in", "eim", "lant", "be\u00b7sun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "ART", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "darinnen die f\u00fcchs so gro\u00df sint", "tokens": ["da\u00b7rin\u00b7nen", "die", "f\u00fcchs", "so", "gro\u00df", "sint"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "ADV", "ADJD", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.32": {"text": "als in unserm lant ochsn und rint.", "tokens": ["als", "in", "un\u00b7serm", "lant", "ochsn", "und", "rint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJD", "VVINF", "KON", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.33": {"text": "der junkher sprach: da sint auf glauben", "tokens": ["der", "junk\u00b7her", "sprach", ":", "da", "sint", "auf", "glau\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "$.", "ADV", "VVFIN", "APPR", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "gut futtern die r\u00f6ck und die schauben,", "tokens": ["gut", "fut\u00b7tern", "die", "r\u00f6ck", "und", "die", "schau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "KON", "ART", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.35": {"text": "wenn man im lant ein k\u00fcrsner f\u00fcnt,", "tokens": ["wenn", "man", "im", "lant", "ein", "k\u00fcrs\u00b7ner", "f\u00fcnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "der die belg wol bereiten k\u00fcnt.", "tokens": ["der", "die", "belg", "wol", "be\u00b7rei\u00b7ten", "k\u00fcnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVINF", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.37": {"text": "da nun der red geschwigen wart,", "tokens": ["da", "nun", "der", "red", "ge\u00b7schwi\u00b7gen", "wart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "VVFIN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "der edelman erseufzet hart", "tokens": ["der", "e\u00b7del\u00b7man", "er\u00b7seuf\u00b7zet", "hart"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "und sprach: herr got, ste uns heut bei", "tokens": ["und", "sprach", ":", "herr", "got", ",", "ste", "uns", "heut", "bei"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "NN", "NE", "$,", "VVFIN", "PPER", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "auf diser stra\u00df, darmit wir frei", "tokens": ["auf", "di\u00b7ser", "stra\u00df", ",", "dar\u00b7mit", "wir", "frei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PDS", "VVFIN", "$,", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "beleiben vor allerlei l\u00fcgen,", "tokens": ["be\u00b7lei\u00b7ben", "vor", "al\u00b7ler\u00b7lei", "l\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "ADJA", "$,"], "meter": "-+--+-++-", "measure": "iambic.tetra.relaxed"}, "line.42": {"text": "auf das wir sicher kommen m\u00fcgen", "tokens": ["auf", "das", "wir", "si\u00b7cher", "kom\u00b7men", "m\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVINF", "VMFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.43": {"text": "durch das wa\u00dfer mit unserm leben,", "tokens": ["durch", "das", "wa\u00b7\u00dfer", "mit", "un\u00b7serm", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPOSAT", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.44": {"text": "und tu uns heut gut herberg geben.", "tokens": ["und", "tu", "uns", "heut", "gut", "her\u00b7berg", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "der knecht sprach: junkher, saget frei,", "tokens": ["der", "knecht", "sprach", ":", "junk\u00b7her", ",", "sa\u00b7get", "frei", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ADJA", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "wo das gro\u00df ungst\u00fcm wa\u00dfer sei,", "tokens": ["wo", "das", "gro\u00df", "ungs\u00b7t\u00fcm", "wa\u00b7\u00dfer", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJD", "ADJD", "ADJD", "VAFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.47": {"text": "vor dem ir euch gesegnet schlecht?", "tokens": ["vor", "dem", "ir", "euch", "ge\u00b7seg\u00b7net", "schlecht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPER", "VVPP", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.48": {"text": "der junkher sprach: h\u00f6r, lieber knecht,", "tokens": ["der", "junk\u00b7her", "sprach", ":", "h\u00f6r", ",", "lie\u00b7ber", "knecht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$.", "VVFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "ein gro\u00df wa\u00dfer fleu\u00dft dort von weiten,", "tokens": ["ein", "gro\u00df", "wa\u00b7\u00dfer", "fleu\u00dft", "dort", "von", "wei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ADV", "APPR", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.50": {"text": "dardurch so m\u00fc\u00dfen wir heut reiten,", "tokens": ["dar\u00b7durch", "so", "m\u00fc\u00b7\u00dfen", "wir", "heut", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "das hat die kraft, welicher man", "tokens": ["das", "hat", "die", "kraft", ",", "we\u00b7li\u00b7cher", "man"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PIS"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.52": {"text": "denselben tag ein lug hat tan,", "tokens": ["den\u00b7sel\u00b7ben", "tag", "ein", "lug", "hat", "tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ART", "NN", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.53": {"text": "der mu\u00df in dem wa\u00dfer ertrinken,", "tokens": ["der", "mu\u00df", "in", "dem", "wa\u00b7\u00dfer", "er\u00b7trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "ART", "ADJA", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.54": {"text": "verderben und zu boden sinken.", "tokens": ["ver\u00b7der\u00b7ben", "und", "zu", "bo\u00b7den", "sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.55": {"text": "der knecht erschrak ob disen worten,", "tokens": ["der", "knecht", "er\u00b7schrak", "ob", "di\u00b7sen", "wor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOUS", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "und als sie ritten an den orten,", "tokens": ["und", "als", "sie", "rit\u00b7ten", "an", "den", "or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "kamen sie an ein gro\u00dfen bach.", "tokens": ["ka\u00b7men", "sie", "an", "ein", "gro\u00b7\u00dfen", "bach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.58": {"text": "der knecht zu dem junkheren sprach:", "tokens": ["der", "knecht", "zu", "dem", "junk\u00b7he\u00b7ren", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-----+", "measure": "dactylic.init"}, "line.59": {"text": "o junkher, sagt, ist das der flu\u00df,", "tokens": ["o", "junk\u00b7her", ",", "sagt", ",", "ist", "das", "der", "flu\u00df", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "ADJA", "$,", "VVFIN", "$,", "VAFIN", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "drin ein l\u00fcgner ertrinken mu\u00df?", "tokens": ["drin", "ein", "l\u00fcg\u00b7ner", "er\u00b7trin\u00b7ken", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.61": {"text": "da sagt durch list der edelmon:", "tokens": ["da", "sagt", "durch", "list", "der", "e\u00b7del\u00b7mon", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "nein, wir sint noch gar ferr darvon.", "tokens": ["nein", ",", "wir", "sint", "noch", "gar", "ferr", "dar\u00b7von", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ADV", "ADV", "ADJD", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "der knecht sprach: herr, darumb ich frag,", "tokens": ["der", "knecht", "sprach", ":", "herr", ",", "da\u00b7rumb", "ich", "frag", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PTKVZ", "$,", "PAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "auf das ich euch die warheit sag,", "tokens": ["auf", "das", "ich", "euch", "die", "war\u00b7heit", "sag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "ich het mich heut weit \u00fcberdacht", "tokens": ["ich", "het", "mich", "heut", "weit", "\u00fc\u00b7berd\u00b7acht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.66": {"text": "und meinen fuchs zu gro\u00df gemacht,", "tokens": ["und", "mei\u00b7nen", "fuchs", "zu", "gro\u00df", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "er war nur so gro\u00df seiner h\u00f6ch", "tokens": ["er", "war", "nur", "so", "gro\u00df", "sei\u00b7ner", "h\u00f6ch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "PPOSAT", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.68": {"text": "als von einem hirschen das rech.", "tokens": ["als", "von", "ei\u00b7nem", "hir\u00b7schen", "das", "rech", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "ART", "ADJD", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.69": {"text": "der junkher sprach: ich bin sorglos,", "tokens": ["der", "junk\u00b7her", "sprach", ":", "ich", "bin", "sorg\u00b7los", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$.", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "der fuchs sei gwest klein oder gro\u00df;", "tokens": ["der", "fuchs", "sei", "gwest", "klein", "o\u00b7der", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.71": {"text": "merkt wol des knechts heimlich grisgramen.", "tokens": ["merkt", "wol", "des", "knechts", "heim\u00b7lich", "gris\u00b7gra\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.72": {"text": "nach dem sie an ein wa\u00dfer kamen,", "tokens": ["nach", "dem", "sie", "an", "ein", "wa\u00b7\u00dfer", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "da sprach der knecht: junkher, ists das", "tokens": ["da", "sprach", "der", "knecht", ":", "junk\u00b7her", ",", "ists", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ADJA", "$,", "VAFIN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "wa\u00dfer, so tregt dem l\u00fcgner ha\u00df?", "tokens": ["wa\u00b7\u00dfer", ",", "so", "tregt", "dem", "l\u00fcg\u00b7ner", "ha\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.75": {"text": "der herr sprach: nein, das ists auch nicht.", "tokens": ["der", "herr", "sprach", ":", "nein", ",", "das", "ists", "auch", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PTKANT", "$,", "PDS", "VAFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.76": {"text": "darauf der knecht sprach: nemt bericht", "tokens": ["da\u00b7rauf", "der", "knecht", "sprach", ":", "nemt", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "des fuchsen heut noch meinenthalb,", "tokens": ["des", "fuch\u00b7sen", "heut", "noch", "mei\u00b7nen\u00b7thalb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "der war nit gr\u00f6\u00dfer den ein kalb,", "tokens": ["der", "war", "nit", "gr\u00f6\u00b7\u00dfer", "den", "ein", "kalb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PTKNEG", "ADJD", "ART", "ART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.79": {"text": "auf das im wa\u00dfer ich beste.", "tokens": ["auf", "das", "im", "wa\u00b7\u00dfer", "ich", "bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.80": {"text": "der junkher sprach: ich frag nit me", "tokens": ["der", "junk\u00b7her", "sprach", ":", "ich", "frag", "nit", "me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "NE"], "meter": "---++-+-", "measure": "unknown.measure.tri"}, "line.81": {"text": "nach deim fuchs, sei gro\u00df oder klein.", "tokens": ["nach", "deim", "fuchs", ",", "sei", "gro\u00df", "o\u00b7der", "klein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "nach dem kamens sie beid gemein", "tokens": ["nach", "dem", "ka\u00b7mens", "sie", "beid", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.83": {"text": "an ein wa\u00dfer, da der knecht fragt:", "tokens": ["an", "ein", "wa\u00b7\u00dfer", ",", "da", "der", "knecht", "fragt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.84": {"text": "ist di\u00df das wa\u00dfr, darvon ir sagt", "tokens": ["ist", "di\u00df", "das", "wa\u00dfr", ",", "dar\u00b7von", "ir", "sagt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PAV", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.85": {"text": "heut fr\u00fc, drin die l\u00fcgner ertrenken?", "tokens": ["heut", "fr\u00fc", ",", "drin", "die", "l\u00fcg\u00b7ner", "er\u00b7tren\u00b7ken", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ART", "ADJA", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.86": {"text": "so ich des fuchs tu recht bedenken,", "tokens": ["so", "ich", "des", "fuchs", "tu", "recht", "be\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "NE", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.87": {"text": "ist er nicht gr\u00f6\u00dfer gwesen sider,", "tokens": ["ist", "er", "nicht", "gr\u00f6\u00b7\u00dfer", "gwe\u00b7sen", "si\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.88": {"text": "den bei uns hie ist ein schafwider.", "tokens": ["den", "bei", "uns", "hie", "ist", "ein", "scha\u00b7fwi\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "ADV", "VAFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.89": {"text": "der junkher sprach: das wa\u00dfr ists nicht.", "tokens": ["der", "junk\u00b7her", "sprach", ":", "das", "wa\u00dfr", "ists", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$.", "ART", "NN", "VAFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "nach dem zu vesperzeit gericht", "tokens": ["nach", "dem", "zu", "ves\u00b7per\u00b7zeit", "ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.91": {"text": "kamen sie an ein wa\u00dfer, flo\u00df", "tokens": ["ka\u00b7men", "sie", "an", "ein", "wa\u00b7\u00dfer", ",", "flo\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "$,", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.92": {"text": "gar schnell mit wellen breit und gro\u00df.", "tokens": ["gar", "schnell", "mit", "wel\u00b7len", "breit", "und", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PWAT", "NN", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "der knecht fragt, obs das wa\u00dfer wer,", "tokens": ["der", "knecht", "fragt", ",", "obs", "das", "wa\u00b7\u00dfer", "wer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "ART", "ADJA", "PWS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "darvon fr\u00fc het gesaget er.", "tokens": ["dar\u00b7von", "fr\u00fc", "het", "ge\u00b7sa\u00b7get", "er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VAFIN", "VVPP", "PPER", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.95": {"text": "der junkher sprach: das ist das recht.", "tokens": ["der", "junk\u00b7her", "sprach", ":", "das", "ist", "das", "recht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$.", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.96": {"text": "ob dem wa\u00dfer erschrak der knecht,", "tokens": ["ob", "dem", "wa\u00b7\u00dfer", "er\u00b7schrak", "der", "knecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.97": {"text": "weil er sach weder bruck noch schif;", "tokens": ["weil", "er", "sach", "we\u00b7der", "bruck", "noch", "schif", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.98": {"text": "der angstschwei\u00df \u00fcbr sein angsicht lif,", "tokens": ["der", "angstsc\u00b7hwei\u00df", "\u00fcbr", "sein", "ang\u00b7sicht", "lif", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.99": {"text": "zittert beide an f\u00fc\u00df und henden.", "tokens": ["zit\u00b7tert", "bei\u00b7de", "an", "f\u00fc\u00df", "und", "hen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NE", "KON", "NN", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.100": {"text": "als sie zum wa\u00dfer teten lenden,", "tokens": ["als", "sie", "zum", "wa\u00b7\u00dfer", "te\u00b7ten", "len\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.101": {"text": "da saget der verlogen knecht:", "tokens": ["da", "sa\u00b7get", "der", "ver\u00b7lo\u00b7gen", "knecht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "mein lug mu\u00df ich bekennen schlecht,", "tokens": ["mein", "lug", "mu\u00df", "ich", "be\u00b7ken\u00b7nen", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.103": {"text": "der fuchs, den ich so gro\u00df bescheit,", "tokens": ["der", "fuchs", ",", "den", "ich", "so", "gro\u00df", "be\u00b7scheit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "der war nicht gr\u00f6\u00dfer auf mein eit", "tokens": ["der", "war", "nicht", "gr\u00f6\u00b7\u00dfer", "auf", "mein", "eit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "VAFIN", "PTKNEG", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.105": {"text": "dan der heutige fuchse alt,", "tokens": ["dan", "der", "heu\u00b7ti\u00b7ge", "fuch\u00b7se", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.106": {"text": "den wir fr\u00fc sahen in dem walt.", "tokens": ["den", "wir", "fr\u00fc", "sa\u00b7hen", "in", "dem", "walt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.107": {"text": "des schwanks lachet der junkher ser", "tokens": ["des", "schwanks", "la\u00b7chet", "der", "junk\u00b7her", "ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.108": {"text": "und sprach zu seinem knecht: so schwer", "tokens": ["und", "sprach", "zu", "sei\u00b7nem", "knecht", ":", "so", "schwer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.109": {"text": "ich dir, das dises wa\u00dfer pur", "tokens": ["ich", "dir", ",", "das", "di\u00b7ses", "wa\u00b7\u00dfer", "pur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PPER", "$,", "PRELS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "hat kein ander kraft und natur", "tokens": ["hat", "kein", "an\u00b7der", "kraft", "und", "na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "ADJD", "ADJD", "KON", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.111": {"text": "als andre wa\u00dfer in der nehen,", "tokens": ["als", "and\u00b7re", "wa\u00b7\u00dfer", "in", "der", "ne\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.112": {"text": "die wir vor haben heut gesehen.", "tokens": ["die", "wir", "vor", "ha\u00b7ben", "heut", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.113": {"text": "darmit nam ir gesprech ein ent,", "tokens": ["dar\u00b7mit", "nam", "ir", "ge\u00b7sprech", "ein", "ent", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "ART", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.114": {"text": "schwemmten \u00fcbers wa\u00dfer behent.", "tokens": ["schwemm\u00b7ten", "\u00fc\u00b7bers", "wa\u00b7\u00dfer", "be\u00b7hent", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}}}}