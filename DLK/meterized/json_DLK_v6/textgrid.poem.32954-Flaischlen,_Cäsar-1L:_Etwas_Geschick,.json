{"textgrid.poem.32954": {"metadata": {"author": {"name": "Flaischlen, C\u00e4sar", "birth": "N.A.", "death": "N.A."}, "title": "1L: Etwas Geschick,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Etwas Geschick,", "tokens": ["Et\u00b7was", "Ge\u00b7schick", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "ein wenig Gl\u00fcck,", "tokens": ["ein", "we\u00b7nig", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "ein bi\u00dfchen T\u00fcck,", "tokens": ["ein", "bi\u00df\u00b7chen", "T\u00fcck", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "gibt allezeit", "tokens": ["gibt", "al\u00b7le\u00b7zeit"], "token_info": ["word", "word"], "pos": ["VVFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "ein Meisterst\u00fcck.", "tokens": ["ein", "Meis\u00b7ter\u00b7st\u00fcck", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Wer Gl\u00fcck hat, den kriegt", "tokens": ["Wer", "Gl\u00fcck", "hat", ",", "den", "kriegt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "NN", "VAFIN", "$,", "ART", "VVFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "selbst mit dem Hut auf dem Kopf,", "tokens": ["selbst", "mit", "dem", "Hut", "auf", "dem", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "sein Gl\u00fcck, wenn es will,", "tokens": ["sein", "Gl\u00fcck", ",", "wenn", "es", "will", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "auch durch den Hut noch beim Schopf.", "tokens": ["auch", "durch", "den", "Hut", "noch", "beim", "Schopf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Aufs B\u00fccherschreiben sich zu legen,", "tokens": ["Aufs", "B\u00fc\u00b7cher\u00b7schrei\u00b7ben", "sich", "zu", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ein danklos Ding, voll Ungemach!", "tokens": ["ein", "dank\u00b7los", "Ding", ",", "voll", "Un\u00b7ge\u00b7mach", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "man glaubt, den Erdball zu bewegen", "tokens": ["man", "glaubt", ",", "den", "Erd\u00b7ball", "zu", "be\u00b7we\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und ach, es kr\u00e4ht kein Hahn danach!", "tokens": ["und", "ach", ",", "es", "kr\u00e4ht", "kein", "Hahn", "da\u00b7nach", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "PPER", "VVFIN", "PIAT", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Erst verspottet und verlacht,", "tokens": ["Erst", "ver\u00b7spot\u00b7tet", "und", "ver\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "dann im stillen nachgemacht,", "tokens": ["dann", "im", "stil\u00b7len", "nach\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und zuletzt als neu erdacht", "tokens": ["und", "zu\u00b7letzt", "als", "neu", "er\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KOUS", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "mit viel L\u00e4rm zu Markt gebracht.", "tokens": ["mit", "viel", "L\u00e4rm", "zu", "Markt", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Lieber Wortklauber,", "tokens": ["Lie\u00b7ber", "Wort\u00b7klau\u00b7ber", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "als Wortglauber.", "tokens": ["als", "Wort\u00b7glau\u00b7ber", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Bedenkt auch, wenn ihr etwas kritisiert,", "tokens": ["Be\u00b7denkt", "auch", ",", "wenn", "ihr", "et\u00b7was", "kri\u00b7ti\u00b7siert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und dies und das dran auszusetzen wi\u00dft,", "tokens": ["und", "dies", "und", "das", "dran", "aus\u00b7zu\u00b7set\u00b7zen", "wi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "KON", "ART", "PAV", "VVIZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "bedenkt, da\u00df ein Urteil immer zugleich", "tokens": ["be\u00b7denkt", ",", "da\u00df", "ein", "Ur\u00b7teil", "im\u00b7mer", "zu\u00b7gleich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "ADV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "ein Urteil auch \u00fcber den Urteiler ist.", "tokens": ["ein", "Ur\u00b7teil", "auch", "\u00fc\u00b7ber", "den", "Ur\u00b7tei\u00b7ler", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Was frommt Talent,", "tokens": ["Was", "frommt", "Ta\u00b7lent", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "was frommt Genie,", "tokens": ["was", "frommt", "Ge\u00b7nie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "bleibt es latent", "tokens": ["bleibt", "es", "la\u00b7tent"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "VVFIN"], "meter": "+---", "measure": "dactylic.init"}, "line.4": {"text": "und kl\u00e4rt sich's nie?!", "tokens": ["und", "kl\u00e4rt", "sich's", "nie", "?!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Nicht Einem wohl gen\u00fcgt so ganz,", "tokens": ["Nicht", "Ei\u00b7nem", "wohl", "ge\u00b7n\u00fcgt", "so", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "ADV", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "was ihm Geschick und Ungeschick brachte,", "tokens": ["was", "ihm", "Ge\u00b7schick", "und", "Un\u00b7ge\u00b7schick", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+--+-+-++-", "measure": "iambic.penta.invert"}, "line.3": {"text": "da\u00df er, noch einmal auf der Welt,", "tokens": ["da\u00df", "er", ",", "noch", "ein\u00b7mal", "auf", "der", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "es nicht von Grund aus anders machte.", "tokens": ["es", "nicht", "von", "Grund", "aus", "an\u00b7ders", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ein bi\u00dfchen \u00c4rger und Verdru\u00df", "tokens": ["Ein", "bi\u00df\u00b7chen", "\u00c4r\u00b7ger", "und", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "geh\u00f6rt zum Leben ...", "tokens": ["ge\u00b7h\u00f6rt", "zum", "Le\u00b7ben", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "nur Zucker und Zibeben", "tokens": ["nur", "Zu\u00b7cker", "und", "Zi\u00b7be\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.4": {"text": "w\u00e4r auf die Dauer kein Genu\u00df!", "tokens": ["w\u00e4r", "auf", "die", "Dau\u00b7er", "kein", "Ge\u00b7nu\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Was hilft alles Wollen, was alles Versprechen,", "tokens": ["Was", "hilft", "al\u00b7les", "Wol\u00b7len", ",", "was", "al\u00b7les", "Ver\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIAT", "NN", "$,", "PRELS", "PIAT", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "und wenn es das Herrlichste verhei\u00dft,", "tokens": ["und", "wenn", "es", "das", "Herr\u00b7lichs\u00b7te", "ver\u00b7hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--++--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "im K\u00f6nnen liegt der Wert des Menschen,", "tokens": ["im", "K\u00f6n\u00b7nen", "liegt", "der", "Wert", "des", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die Tat allein ist's, die beweist.", "tokens": ["die", "Tat", "al\u00b7lein", "ist's", ",", "die", "be\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "$,", "PRELS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Nicht: wer nur redet", "tokens": ["Nicht", ":", "wer", "nur", "re\u00b7det"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "$.", "PWS", "ADV", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "oder drum betet,", "tokens": ["o\u00b7der", "drum", "be\u00b7tet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "wer es macht,", "tokens": ["wer", "es", "macht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "hat die Macht.", "tokens": ["hat", "die", "Macht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "Das Beste doch von allem Guten", "tokens": ["Das", "Bes\u00b7te", "doch", "von", "al\u00b7lem", "Gu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ist dann und wann, fein still und brav,", "tokens": ["ist", "dann", "und", "wann", ",", "fein", "still", "und", "brav", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KON", "PWAV", "$,", "ADJD", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und notabene ohne Tr\u00e4ume:", "tokens": ["und", "no\u00b7ta\u00b7be\u00b7ne", "oh\u00b7ne", "Tr\u00e4u\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "in gutem Bett ein guter Schlaf.", "tokens": ["in", "gu\u00b7tem", "Bett", "ein", "gu\u00b7ter", "Schlaf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}