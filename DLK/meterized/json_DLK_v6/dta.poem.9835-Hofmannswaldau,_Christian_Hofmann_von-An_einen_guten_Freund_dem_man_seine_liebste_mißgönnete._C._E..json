{"dta.poem.9835": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "An einen guten Freund/ dem man seine  \n liebste mi\u00dfg\u00f6nnete.  \n C. E.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.85", "nl:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mjrtillo/ leidstu noch von deiner tugend wegen/", "tokens": ["Mjr\u00b7til\u00b7lo", "/", "leids\u00b7tu", "noch", "von", "dei\u00b7ner", "tu\u00b7gend", "we\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Geht h\u00f6ll\u2019 und teuffel wider dich/", "tokens": ["Geht", "h\u00f6ll'", "und", "teuf\u00b7fel", "wi\u00b7der", "dich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und will das ungewitter sich", "tokens": ["Und", "will", "das", "un\u00b7ge\u00b7wit\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "ADJA", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht einst zur stillen ruhe legen?", "tokens": ["Nicht", "einst", "zur", "stil\u00b7len", "ru\u00b7he", "le\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Speyt die verfluchte neider-schaar", "tokens": ["Speyt", "die", "ver\u00b7fluch\u00b7te", "nei\u00b7der\u00b7schaar"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Auff dich noch ihre l\u00e4ster-flammen/", "tokens": ["Auff", "dich", "noch", "ih\u00b7re", "l\u00e4s\u00b7ter\u00b7flam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wirstu t\u00e4glich nur gewahr/", "tokens": ["Und", "wirs\u00b7tu", "t\u00e4g\u00b7lich", "nur", "ge\u00b7wahr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wie sie dein freyes thun vergifften und verdammen?", "tokens": ["Wie", "sie", "dein", "frey\u00b7es", "thun", "ver\u00b7giff\u00b7ten", "und", "ver\u00b7dam\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "VVINF", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es ist des neides art: er nagt an hohen fachen/", "tokens": ["Es", "ist", "des", "nei\u00b7des", "art", ":", "er", "nagt", "an", "ho\u00b7hen", "fa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er ha\u00dft/ was er nicht haben kan/", "tokens": ["Er", "ha\u00dft", "/", "was", "er", "nicht", "ha\u00b7ben", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWS", "PPER", "PTKNEG", "VAINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sieht mit scheelen augen an/", "tokens": ["Und", "sieht", "mit", "schee\u00b7len", "au\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was ihm entweicht aus seinem rachen.", "tokens": ["Was", "ihm", "ent\u00b7weicht", "aus", "sei\u00b7nem", "ra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00df aber ihn nur immer gehn/", "tokens": ["La\u00df", "a\u00b7ber", "ihn", "nur", "im\u00b7mer", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "La\u00df ihn noch eins so hefftig blasen/", "tokens": ["La\u00df", "ihn", "noch", "eins", "so", "heff\u00b7tig", "bla\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIS", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du bleibst wie feste cedern stehn/", "tokens": ["Du", "bleibst", "wie", "fes\u00b7te", "ce\u00b7dern", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ob sturm und nordwind gleich umb deine gipffel rasen.", "tokens": ["Ob", "sturm", "und", "nord\u00b7wind", "gleich", "umb", "dei\u00b7ne", "gipf\u00b7fel", "ra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "KON", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Kein blitz noch donner kan dein felsen-hertze schw\u00e4chen/", "tokens": ["Kein", "blitz", "noch", "don\u00b7ner", "kan", "dein", "fel\u00b7sen\u00b7hert\u00b7ze", "schw\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das nichts aus seinem stande r\u00fcckt.", "tokens": ["Das", "nichts", "aus", "sei\u00b7nem", "stan\u00b7de", "r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die last/ die einen strauch zerdr\u00fcckt/", "tokens": ["Die", "last", "/", "die", "ei\u00b7nen", "strauch", "zer\u00b7dr\u00fcckt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "ART", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan steiffe palmen nicht zerbrechen;", "tokens": ["Kan", "steif\u00b7fe", "pal\u00b7men", "nicht", "zer\u00b7bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du hebst nur h\u00f6her dich empor/", "tokens": ["Du", "hebst", "nur", "h\u00f6\u00b7her", "dich", "em\u00b7por", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df ha\u00df und neid auch drob erschrecken/", "tokens": ["Da\u00df", "ha\u00df", "und", "neid", "auch", "drob", "er\u00b7schre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVIMP", "KON", "VVFIN", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und brichst mit hellerm glantz hervor/", "tokens": ["Und", "brichst", "mit", "hel\u00b7lerm", "glantz", "her\u00b7vor", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Je mehr dich finsterni\u00df und schwartze wolcken decken.", "tokens": ["Je", "mehr", "dich", "fins\u00b7ter\u00b7ni\u00df", "und", "schwart\u00b7ze", "wol\u00b7cken", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Bellt dann/ so gut ihr k\u00f6nnt/ ihr hei\u00dfer z\u00fcrnten hunde/", "tokens": ["Bellt", "dann", "/", "so", "gut", "ihr", "k\u00f6nnt", "/", "ihr", "hei\u00b7\u00dfer", "z\u00fcrn\u00b7ten", "hun\u00b7de", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "ADV", "ADJD", "PPER", "VVFIN", "$(", "PPOSAT", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jhr hemmet nicht des monden lauff/", "tokens": ["Ihr", "hem\u00b7met", "nicht", "des", "mon\u00b7den", "lauff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er geht mit sch\u00f6nren strahlen auff/", "tokens": ["Er", "geht", "mit", "sch\u00f6n\u00b7ren", "strah\u00b7len", "auff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und spottet eurem l\u00e4ster-munde.", "tokens": ["Und", "spot\u00b7tet", "eu\u00b7rem", "l\u00e4s\u00b7ter\u00b7mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mirtillo h\u00e4lt die tugend-bahn/", "tokens": ["Mir\u00b7til\u00b7lo", "h\u00e4lt", "die", "tu\u00b7gen\u00b7dbahn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ist bereits dahin gestiegen/", "tokens": ["Und", "ist", "be\u00b7reits", "da\u00b7hin", "ge\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da er die sonne sehen kan/", "tokens": ["Da", "er", "die", "son\u00b7ne", "se\u00b7hen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und keine fledermau\u00df ihm iemahls nach wird fliegen.", "tokens": ["Und", "kei\u00b7ne", "fle\u00b7der\u00b7mau\u00df", "ihm", "ie\u00b7mahls", "nach", "wird", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "ADV", "APPR", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ja wol/ du tr\u00e4gst den schatz/ Mirtillo/ in den h\u00e4nden/", "tokens": ["Ja", "wol", "/", "du", "tr\u00e4gst", "den", "schatz", "/", "Mir\u00b7til\u00b7lo", "/", "in", "den", "h\u00e4n\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$(", "PPER", "VVFIN", "ART", "NN", "$(", "NE", "$(", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den dir kein Pluto rauben kan;", "tokens": ["Den", "dir", "kein", "Plu\u00b7to", "rau\u00b7ben", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch um ein kleines ists gethan/", "tokens": ["Noch", "um", "ein", "klei\u00b7nes", "ists", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So siehstu sich das wetter wenden.", "tokens": ["So", "sieh\u00b7stu", "sich", "das", "wet\u00b7ter", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach! glaub\u2019 es kan nicht anders gehn;", "tokens": ["Ach", "!", "glaub'", "es", "kan", "nicht", "an\u00b7ders", "gehn", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "VMFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer sich im paradie\u00df will laben", "tokens": ["Wer", "sich", "im", "pa\u00b7ra\u00b7die\u00df", "will", "la\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPRART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und neben einem engel stehn/", "tokens": ["Und", "ne\u00b7ben", "ei\u00b7nem", "en\u00b7gel", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mu\u00df h\u00f6ll und fegefeur erst wohl versuchet haben.", "tokens": ["Mu\u00df", "h\u00f6ll", "und", "fe\u00b7ge\u00b7feur", "erst", "wohl", "ver\u00b7su\u00b7chet", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "KON", "ADJD", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}