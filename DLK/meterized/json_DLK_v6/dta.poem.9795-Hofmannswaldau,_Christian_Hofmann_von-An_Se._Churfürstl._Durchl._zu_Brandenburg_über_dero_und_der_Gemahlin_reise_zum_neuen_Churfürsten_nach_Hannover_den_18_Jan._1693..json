{"dta.poem.9795": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "An Se. Churf\u00fcrstl. Durchl. zu Brandenburg/  \n \u00fcber dero und der Gemahlin reise/ zum neuen  \n Churf\u00fcrsten nach Hannover/  \n den 18 Jan. 1693.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Zeuch Friedrich mit Charlotten bin", "tokens": ["Zeuch", "Fried\u00b7rich", "mit", "Char\u00b7lot\u00b7ten", "bin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hannovers Chur-hut zu begr\u00fcssen/", "tokens": ["Han\u00b7no\u00b7vers", "Chur\u00b7hut", "zu", "be\u00b7gr\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKZU", "VVINF", "$("], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und mit der neuen Churf\u00fcrstinn/", "tokens": ["Und", "mit", "der", "neu\u00b7en", "Chur\u00b7f\u00fcrs\u00b7tinn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.4": {"text": "Des landes freude zu geniessen.", "tokens": ["Des", "lan\u00b7des", "freu\u00b7de", "zu", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du siehst/ wie dieses hohe hau\u00df", "tokens": ["Du", "siehst", "/", "wie", "die\u00b7ses", "ho\u00b7he", "hau\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOKOM", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An glantz f\u00fcr dich auch zugenommen;", "tokens": ["An", "glantz", "f\u00fcr", "dich", "auch", "zu\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nachdem du dein gemahl daraus/", "tokens": ["Nach\u00b7dem", "du", "dein", "ge\u00b7mahl", "da\u00b7raus", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und mit ihr solches recht bekommen.", "tokens": ["Und", "mit", "ihr", "sol\u00b7ches", "recht", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Di\u00df hau\u00df steigt wieder in den stand/", "tokens": ["Di\u00df", "hau\u00df", "steigt", "wie\u00b7der", "in", "den", "stand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ADV", "APPR", "ART", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den es vor langer zeit besessen;", "tokens": ["Den", "es", "vor", "lan\u00b7ger", "zeit", "be\u00b7ses\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch hat es weniger das land/", "tokens": ["Doch", "hat", "es", "we\u00b7ni\u00b7ger", "das", "land", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als dessen f\u00fcrst sich beyzumessen.", "tokens": ["Als", "des\u00b7sen", "f\u00fcrst", "sich", "bey\u00b7zu\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "VVFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das reich/ und selbst des K\u00e4ysers thron/", "tokens": ["Das", "reich", "/", "und", "selbst", "des", "K\u00e4y\u00b7sers", "thron", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "$(", "KON", "ADV", "ART", "NN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sind seiner tugend so verbunden/", "tokens": ["Sind", "sei\u00b7ner", "tu\u00b7gend", "so", "ver\u00b7bun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df sie sonst keinen andern lohn", "tokens": ["Da\u00df", "sie", "sonst", "kei\u00b7nen", "an\u00b7dern", "lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "F\u00fcr seine tapferkeit gefunden.", "tokens": ["F\u00fcr", "sei\u00b7ne", "tap\u00b7fer\u00b7keit", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was iedem vorfahr noch zu schwer/", "tokens": ["Was", "ie\u00b7dem", "vor\u00b7fahr", "noch", "zu", "schwer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df endlich Ernst August vollf\u00fchren.", "tokens": ["Mu\u00df", "end\u00b7lich", "Ernst", "Au\u00b7gust", "voll\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und war nicht solches l\u00e4ngst vorher", "tokens": ["Und", "war", "nicht", "sol\u00b7ches", "l\u00e4ngst", "vor\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PTKNEG", "PIS", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An seiner hohen eh zu sp\u00fcren?", "tokens": ["An", "sei\u00b7ner", "ho\u00b7hen", "eh", "zu", "sp\u00fc\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es war der kluge F\u00fcrst bedacht/", "tokens": ["Es", "war", "der", "klu\u00b7ge", "F\u00fcrst", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich k\u00f6niglich erst zu verm\u00e4hlen.", "tokens": ["Sich", "k\u00f6\u00b7nig\u00b7lich", "erst", "zu", "ver\u00b7m\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Denn was die K\u00f6nigs-w\u00fcrde macht/", "tokens": ["Denn", "was", "die", "K\u00f6\u00b7nigs\u00b7w\u00fcr\u00b7de", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kont\u2019 ihm durch eine Chur nicht fehlen.", "tokens": ["Kont'", "ihm", "durch", "ei\u00b7ne", "Chur", "nicht", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nun was sein muth beschlossen hat/", "tokens": ["Nun", "was", "sein", "muth", "be\u00b7schlos\u00b7sen", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPOSAT", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist seinen thaten schon gelungen;", "tokens": ["Ist", "sei\u00b7nen", "tha\u00b7ten", "schon", "ge\u00b7lun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gl\u00fcckseelig/ Friedrich/ wo dein rath", "tokens": ["Gl\u00fcck\u00b7see\u00b7lig", "/", "Fried\u00b7rich", "/", "wo", "dein", "rath"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "$(", "NE", "$(", "PWAV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jhm hierin h\u00fclfreich beygesprungen!", "tokens": ["Jhm", "hie\u00b7rin", "h\u00fclf\u00b7reich", "bey\u00b7ge\u00b7sprun\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer eltern ehrt/ ehrt die natur/", "tokens": ["Wer", "el\u00b7tern", "ehrt", "/", "ehrt", "die", "na\u00b7tur", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$(", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie aber kan man sie mehr ehren?", "tokens": ["Wie", "a\u00b7ber", "kan", "man", "sie", "mehr", "eh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PIS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als da\u00df ein Sohn/ mit einer Chur/", "tokens": ["Als", "da\u00df", "ein", "Sohn", "/", "mit", "ei\u00b7ner", "Chur", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "$(", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Des Vaters Hoheit hilfft vermehren.", "tokens": ["Des", "Va\u00b7ters", "Ho\u00b7heit", "hilfft", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}