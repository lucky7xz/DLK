{"textgrid.poem.53474": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der Lenz ist da!", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Lenzsymptom zeigt sich zuerst beim Hunde,", "tokens": ["Das", "Lenz\u00b7symp\u00b7tom", "zeigt", "sich", "zu\u00b7erst", "beim", "Hun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "dann im Kalender und dann in der Luft,", "tokens": ["dann", "im", "Ka\u00b7len\u00b7der", "und", "dann", "in", "der", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "und endlich h\u00fcllt auch Fr\u00e4ulein Adelgunde", "tokens": ["und", "end\u00b7lich", "h\u00fcllt", "auch", "Fr\u00e4u\u00b7lein", "A\u00b7del\u00b7gun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "NN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sich in die frischgewaschene Fr\u00fchlingskluft.", "tokens": ["sich", "in", "die", "frischge\u00b7wa\u00b7sche\u00b7ne", "Fr\u00fch\u00b7lings\u00b7kluft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ach ja, der Mensch! Was will er nur vom Lenze?", "tokens": ["Ach", "ja", ",", "der", "Mensch", "!", "Was", "will", "er", "nur", "vom", "Len\u00b7ze", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$,", "ART", "NN", "$.", "PWS", "VMFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist er denn nicht das ganze Jahr in Brunst?", "tokens": ["Ist", "er", "denn", "nicht", "das", "gan\u00b7ze", "Jahr", "in", "Brunst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch seine Triebe kennen keine Grenze \u2013", "tokens": ["Doch", "sei\u00b7ne", "Trie\u00b7be", "ken\u00b7nen", "kei\u00b7ne", "Gren\u00b7ze", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dies Uhrwerk hat der liebe Gott verhunzt.", "tokens": ["dies", "Uhr\u00b7werk", "hat", "der", "lie\u00b7be", "Gott", "ver\u00b7hunzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Der Vorgang ist in jedem Jahr derselbe:", "tokens": ["Der", "Vor\u00b7gang", "ist", "in", "je\u00b7dem", "Jahr", "der\u00b7sel\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PIAT", "NN", "PDAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "man schwelgt, wo man nur z\u00fcchtig beten sollt,", "tokens": ["man", "schwelgt", ",", "wo", "man", "nur", "z\u00fcch\u00b7tig", "be\u00b7ten", "sollt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PWAV", "PIS", "ADV", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und man zerdr\u00fcckt dem Heiligtum das gelbe", "tokens": ["und", "man", "zer\u00b7dr\u00fcckt", "dem", "Hei\u00b7lig\u00b7tum", "das", "gel\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "gebl\u00fcmte Kleid \u2013 ja, hat das Gott gewollt?", "tokens": ["ge\u00b7bl\u00fcm\u00b7te", "Kleid", "\u2013", "ja", ",", "hat", "das", "Gott", "ge\u00b7wollt", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PTKANT", "$,", "VAFIN", "ART", "NN", "VMPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Die ganze Fauna treibt es immer wieder:", "tokens": ["Die", "gan\u00b7ze", "Fau\u00b7na", "treibt", "es", "im\u00b7mer", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da ist ein Spitz und eine Pudelmaid \u2013", "tokens": ["Da", "ist", "ein", "Spitz", "und", "ei\u00b7ne", "Pu\u00b7del\u00b7maid", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "die feine Dame senkt die Augenlider,", "tokens": ["die", "fei\u00b7ne", "Da\u00b7me", "senkt", "die", "Au\u00b7gen\u00b7li\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der Arbeitsmann hingegen scheint voll Neid.", "tokens": ["der", "Ar\u00b7beits\u00b7mann", "hin\u00b7ge\u00b7gen", "scheint", "voll", "Neid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "ADJD", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Durch rauh Gebr\u00fcll l\u00e4\u00dft sich das Paar nicht st\u00f6ren,", "tokens": ["Durch", "rauh", "Ge\u00b7br\u00fcll", "l\u00e4\u00dft", "sich", "das", "Paar", "nicht", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "NN", "VVFIN", "PRF", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ein Fu\u00dftritt trifft den armen Romeo \u2013", "tokens": ["ein", "Fu\u00df\u00b7tritt", "trifft", "den", "ar\u00b7men", "Ro\u00b7meo", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "mich deucht, hier sollten zwei sich nicht geh\u00f6ren . . .", "tokens": ["mich", "deucht", ",", "hier", "soll\u00b7ten", "zwei", "sich", "nicht", "ge\u00b7h\u00f6\u00b7ren", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "VMFIN", "CARD", "PRF", "PTKNEG", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und das geht alle, alle Jahre so.", "tokens": ["Und", "das", "geht", "al\u00b7le", ",", "al\u00b7le", "Jah\u00b7re", "so", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PIS", "$,", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Komm, Mutter, reich mir meine Mandoline,", "tokens": ["Komm", ",", "Mut\u00b7ter", ",", "reich", "mir", "mei\u00b7ne", "Man\u00b7do\u00b7li\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "ADJD", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "stell mir den Kaffee auf den K\u00fcchentritt. \u2013", "tokens": ["stell", "mir", "den", "Kaf\u00b7fee", "auf", "den", "K\u00fc\u00b7chen\u00b7tritt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PPER", "ART", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Schon dr\u00f6hnt mein Ba\u00df: Sabine, bine, bine . . .", "tokens": ["Schon", "dr\u00f6hnt", "mein", "Ba\u00df", ":", "Sa\u00b7bi\u00b7ne", ",", "bi\u00b7ne", ",", "bi\u00b7ne", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "NE", "$,", "VVFIN", "$,", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was will man tun? Man macht es schlie\u00dflich mit.", "tokens": ["Was", "will", "man", "tun", "?", "Man", "macht", "es", "schlie\u00df\u00b7lich", "mit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "VVINF", "$.", "PIS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}