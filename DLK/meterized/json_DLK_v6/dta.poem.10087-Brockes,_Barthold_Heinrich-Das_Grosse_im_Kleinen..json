{"dta.poem.10087": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Das Grosse im Kleinen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wir haben zu des Sch\u00f6pfers Ruhme, wol eh' uns in\ndie H\u00f6h' geschwungen,", "tokens": ["Wir", "ha\u00b7ben", "zu", "des", "Sch\u00f6p\u00b7fers", "Ruh\u00b7me", ",", "wol", "eh'", "uns", "in", "die", "H\u00f6h'", "ge\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "NN", "$,", "ADV", "KOUS", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Und, zu des Allerh\u00f6chsten Ehren, wol eh\u2019 vom Grossen was", "tokens": ["Und", ",", "zu", "des", "Al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "Eh\u00b7ren", ",", "wol", "eh'", "vom", "Gros\u00b7sen", "was"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN", "$,", "ADV", "KOUS", "APPRART", "NN", "PWS"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Wir haben ebenfalls den Geist auch in die Enge wol", "tokens": ["Wir", "ha\u00b7ben", "e\u00b7ben\u00b7falls", "den", "Geist", "auch", "in", "die", "En\u00b7ge", "wol"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADV", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Und das, was klein in der Natur, mit Andacht, gleicher", "tokens": ["Und", "das", ",", "was", "klein", "in", "der", "Na\u00b7tur", ",", "mit", "An\u00b7dacht", ",", "glei\u00b7cher"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "PDS", "$,", "PRELS", "ADJD", "APPR", "ART", "NN", "$,", "APPR", "NN", "$,", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Auf! lasset uns denn ietzt mit Lust, und Ernst, und An-", "tokens": ["Auf", "!", "las\u00b7set", "uns", "denn", "ietzt", "mit", "Lust", ",", "und", "Ernst", ",", "und", "An"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "$.", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$,", "KON", "NE", "$,", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf einen grossen Satz, der gleichfalls so wahr als die, recht", "tokens": ["Auf", "ei\u00b7nen", "gros\u00b7sen", "Satz", ",", "der", "gleich\u00b7falls", "so", "wahr", "als", "die", ",", "recht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "ADJD", "KOKOM", "ART", "$,", "ADJD"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ist \u00fcberall unendlich gro\u00df, und folglich gro\u00df auch in\ndem Kleinen.", "tokens": ["Ist", "\u00fc\u00b7be\u00b7rall", "un\u00b7end\u00b7lich", "gro\u00df", ",", "und", "folg\u00b7lich", "gro\u00df", "auch", "in", "dem", "Klei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADJD", "$,", "KON", "ADV", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.3": {"line.1": {"text": "Wenn die Materie den Geist verm\u00f6gend w\u00e4re auszu-", "tokens": ["Wenn", "die", "Ma\u00b7te\u00b7rie", "den", "Geist", "ver\u00b7m\u00f6\u00b7gend", "w\u00e4\u00b7re", "aus\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVPP", "VAFIN", "TRUNC"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "So w\u00fcrde, wenn man dieses glaubte, unstreitig daraus", "tokens": ["So", "w\u00fcr\u00b7de", ",", "wenn", "man", "die\u00b7ses", "glaub\u00b7te", ",", "un\u00b7strei\u00b7tig", "da\u00b7raus"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "PIS", "PDS", "VVFIN", "$,", "ADJD", "PAV"], "meter": "-+-+-+-+-+--++", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Da\u00df selbst die Gottheit Grentzen h\u00e4tte; da\u00df Sie, bis zur", "tokens": ["Da\u00df", "selbst", "die", "Got\u00b7theit", "Grent\u00b7zen", "h\u00e4t\u00b7te", ";", "da\u00df", "Sie", ",", "bis", "zur"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "VAFIN", "$.", "KOUS", "PPER", "$,", "KOUS", "APPRART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur blo\u00df, und dann nicht weiter geh.", "tokens": ["Nur", "blo\u00df", ",", "und", "dann", "nicht", "wei\u00b7ter", "geh."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "ADV", "$,", "KON", "ADV", "PTKNEG", "ADV", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie l\u00e4ch-und l\u00e4sterlich nun die\u00df, wird ja ein ieder leicht", "tokens": ["Wie", "l\u00e4ch\u00b7\u00b7und", "l\u00e4s\u00b7ter\u00b7lich", "nun", "die\u00df", ",", "wird", "ja", "ein", "ie\u00b7der", "leicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ADJD", "ADV", "PDS", "$,", "VAFIN", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "Dem GOTT nur den geringsten Theil von einer Seele", "tokens": ["Dem", "GoTT", "nur", "den", "ge\u00b7rings\u00b7ten", "Theil", "von", "ei\u00b7ner", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durchdringt hingegen eine GOTTHEJT (so wie sie ja", "tokens": ["Durch\u00b7dringt", "hin\u00b7ge\u00b7gen", "ei\u00b7ne", "GoTTHEJT", "(", "so", "wie", "sie", "ja"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "$(", "ADV", "KOKOM", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da Sie allgegenw\u00e4rtig ist) an allen Orten alle Dinge;", "tokens": ["Da", "Sie", "all\u00b7ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "ist", ")", "an", "al\u00b7len", "Or\u00b7ten", "al\u00b7le", "Din\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$(", "APPR", "PIAT", "NN", "PIAT", "NN", "$."], "meter": "-+---+-+-+-+-+-+-", "measure": "dactylic.init"}, "line.9": {"text": "So ist kein C\u00f6rperchen so klein, und kein Gesch\u00f6pfe so ge-", "tokens": ["So", "ist", "kein", "C\u00f6r\u00b7per\u00b7chen", "so", "klein", ",", "und", "kein", "Ge\u00b7sch\u00f6p\u00b7fe", "so", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,", "KON", "PIAT", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.10": {"text": "Das Sie nicht durch und durch erf\u00fcllt; in welchem Sie", "tokens": ["Das", "Sie", "nicht", "durch", "und", "durch", "er\u00b7f\u00fcllt", ";", "in", "wel\u00b7chem", "Sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "PPER", "PTKNEG", "APPR", "KON", "APPR", "VVPP", "$.", "APPR", "PRELS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Erkenne denn, geliebter Leser, wie nahe GOTT dir sey", "tokens": ["Er\u00b7ken\u00b7ne", "denn", ",", "ge\u00b7lieb\u00b7ter", "Le\u00b7ser", ",", "wie", "na\u00b7he", "GoTT", "dir", "sey"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "ADJA", "NN", "$,", "PWAV", "ADJD", "NN", "PPER", "VAFIN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Erkenne, da\u00df allgegenw\u00e4rtig Er in der kleinsten Creatur,", "tokens": ["Er\u00b7ken\u00b7ne", ",", "da\u00df", "all\u00b7ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "Er", "in", "der", "kleins\u00b7ten", "Crea\u00b7tur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADJD", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+--+--+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ohn allen Wiederspruch, vorhanden. Da\u00df folglich unser", "tokens": ["Ohn", "al\u00b7len", "Wie\u00b7der\u00b7spruch", ",", "vor\u00b7han\u00b7den", ".", "Da\u00df", "folg\u00b7lich", "un\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "ADJD", "$.", "KOUS", "ADV", "PPOSAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Was wir auf dieser Welt bemercken, Betrachtungs- und", "tokens": ["Was", "wir", "auf", "die\u00b7ser", "Welt", "be\u00b7mer\u00b7cken", ",", "Be\u00b7trach\u00b7tungs", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "APPR", "PDAT", "NN", "VVINF", "$,", "TRUNC", "KON"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ja einzig anzubeten sey. Da denn Vernunft und Glaube", "tokens": ["Ja", "ein\u00b7zig", "an\u00b7zu\u00b7be\u00b7ten", "sey", ".", "Da", "denn", "Ver\u00b7nunft", "und", "Glau\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADJD", "VVIZU", "VAFIN", "$.", "ADV", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Es werd\u2019 ein solcher GOTTES-Dienst verhoffentlich", "tokens": ["Es", "werd'", "ein", "sol\u00b7cher", "GoT\u00b7TES\u00b7Dienst", "ver\u00b7hof\u00b7fent\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}