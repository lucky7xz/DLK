{"dta.poem.21780": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "V.  \n  Hoffart kommt zu Falle.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Die Dellmane krigt einen Sto\u00df/", "tokens": ["Die", "Dell\u00b7ma\u00b7ne", "krigt", "ei\u00b7nen", "Sto\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "die Dellmane/ die sich in Seiden", "tokens": ["die", "Dell\u00b7ma\u00b7ne", "/", "die", "sich", "in", "Sei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "PRF", "APPR", "NE"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "in Gold und Perlen liesse kleiden/", "tokens": ["in", "Gold", "und", "Per\u00b7len", "lies\u00b7se", "klei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "geht iezt entehret/ nakt und blo\u00df.", "tokens": ["geht", "iezt", "en\u00b7teh\u00b7ret", "/", "nakt", "und", "blo\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "$(", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nn kan ich meinen Schimpff verschmer-", "tokens": ["Nn", "kan", "ich", "mei\u00b7nen", "Schimpff", "ver\u00b7schmer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "es trifft dich mein gew\u00fcnschter Fluch/", "tokens": ["es", "trifft", "dich", "mein", "ge\u00b7w\u00fcnschter", "Fluch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "iezt nagestu am Hunger-tuch\u2019", "tokens": ["iezt", "na\u00b7ge\u00b7stu", "am", "Hun\u00b7ger\u00b7tuch'"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ich g\u00f6nn\u2019 es deinem stolzen Herzen.", "tokens": ["ich", "g\u00f6nn'", "es", "dei\u00b7nem", "stol\u00b7zen", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie offt hab\u2019 ich dich tieff gegr\u00fcsset/", "tokens": ["Wie", "offt", "hab'", "ich", "dich", "tieff", "ge\u00b7gr\u00fcs\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PRF", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wie offt mich gegen dir geneiget/", "tokens": ["wie", "offt", "mich", "ge\u00b7gen", "dir", "ge\u00b7nei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und solche Demuht dir erzeiget/", "tokens": ["und", "sol\u00b7che", "De\u00b7muht", "dir", "er\u00b7zei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der du nicht wehrt gewesen bist.", "tokens": ["der", "du", "nicht", "wehrt", "ge\u00b7we\u00b7sen", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVFIN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du hast mich schielend angesehen/", "tokens": ["Du", "hast", "mich", "schie\u00b7lend", "an\u00b7ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "mich armen Buhler ganz veracht", "tokens": ["mich", "ar\u00b7men", "Buh\u00b7ler", "ganz", "ver\u00b7acht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "nu wirstu wiederum verlacht", "tokens": ["nu", "wirs\u00b7tu", "wie\u00b7de\u00b7rum", "ver\u00b7lacht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und mnst in Spott und Schanden stehen.", "tokens": ["und", "mnst", "in", "Spott", "und", "Schan\u00b7den", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich war nicht hoch genug/ nicht reich/", "tokens": ["Ich", "war", "nicht", "hoch", "ge\u00b7nug", "/", "nicht", "reich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "ADV", "$(", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "nicht h\u00f6fflich satt dich zubedienen", "tokens": ["nicht", "h\u00f6ff\u00b7lich", "satt", "dich", "zu\u00b7be\u00b7die\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "du aber d\u00fcrffest dich erk\u00fchnen", "tokens": ["du", "a\u00b7ber", "d\u00fcrf\u00b7fest", "dich", "er\u00b7k\u00fch\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zu sch\u00e4zzen einer F\u00fcrstinn gleich.", "tokens": ["zu", "sch\u00e4z\u00b7zen", "ei\u00b7ner", "F\u00fcrs\u00b7tinn", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nu wird dein Hochmuht recht belohnet.", "tokens": ["Nu", "wird", "dein", "Hoch\u00b7muht", "recht", "be\u00b7loh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Donner l\u00e4st die H\u00fctten stehn/", "tokens": ["Der", "Don\u00b7ner", "l\u00e4st", "die", "H\u00fct\u00b7ten", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Pall\u00e4ste m\u00fcssen untergehn.", "tokens": ["Pal\u00b7l\u00e4s\u00b7te", "m\u00fcs\u00b7sen", "un\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl dehm/ der wie ich tieffer wohnet.", "tokens": ["Wohl", "dehm", "/", "der", "wie", "ich", "tief\u00b7fer", "woh\u00b7net", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ART", "PWAV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich werde doch wol Brod und Hau\u00df/", "tokens": ["Ich", "wer\u00b7de", "doch", "wol", "Brod", "und", "Hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und einsten gute Nahrung finden/", "tokens": ["und", "eins\u00b7ten", "gu\u00b7te", "Nah\u00b7rung", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da/ Dellmane/ du bleibst dahinden/", "tokens": ["da", "/", "Dell\u00b7ma\u00b7ne", "/", "du", "bleibst", "da\u00b7hin\u00b7den", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "NE", "$(", "PPER", "VVFIN", "PAV", "$("], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "und fegst die \u00f6den Winkel au\u00df.", "tokens": ["und", "fegst", "die", "\u00f6\u00b7den", "Win\u00b7kel", "au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Geh und bestell dir einen Besen/", "tokens": ["Geh", "und", "be\u00b7stell", "dir", "ei\u00b7nen", "Be\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "der Anfang ist bereit gemacht/", "tokens": ["der", "An\u00b7fang", "ist", "be\u00b7reit", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "worauff du iederman veracht", "tokens": ["wo\u00b7rauff", "du", "ie\u00b7der\u00b7man", "ver\u00b7acht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wirstu auff-au\u00df der Asche-lesen.", "tokens": ["wirs\u00b7tu", "auf\u00b7fau\u00df", "der", "A\u00b7sche\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}