{"textgrid.poem.31265": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: Arsinoe/ du sch\u00f6ne Dokk", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.85", "no:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Arsinoe/ du sch\u00f6ne Dokk", "tokens": ["Ar\u00b7si\u00b7noe", "/", "du", "sch\u00f6\u00b7ne", "Dokk"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$(", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "im gelb und Himmel-blauen Rokk/", "tokens": ["im", "gelb", "und", "Him\u00b7mel\u00b7blau\u00b7en", "Rokk", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJD", "KON", "NN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "gl\u00e4ubstu/ da\u00df macht mich nach dir kranck/", "tokens": ["gl\u00e4ubs\u00b7tu", "/", "da\u00df", "macht", "mich", "nach", "dir", "kranck", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOUS", "VVFIN", "PRF", "APPR", "PPER", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bloh\u00df weil dein Leib so Dannen-schlanck?", "tokens": ["bloh\u00df", "weil", "dein", "Leib", "so", "Dan\u00b7nen\u00b7schlanck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du durchau\u00df unverschehmbtes Thier/", "tokens": ["Du", "durch\u00b7au\u00df", "un\u00b7ver\u00b7schehmb\u00b7tes", "Thier", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wer fragt nach dir?", "tokens": ["wer", "fragt", "nach", "dir", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "For dihsen Krantz hihr \u00fcmb mein Haupt", "tokens": ["For", "dih\u00b7sen", "Krantz", "hihr", "\u00fcmb", "mein", "Haupt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "steht ", "tokens": ["steht"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "auff meine Lider lauscht entbrannt", "tokens": ["auff", "mei\u00b7ne", "Li\u00b7der", "lauscht", "ent\u00b7brannt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "gantz Lieff-Teutsch-Holl- und Enge-Land.", "tokens": ["gantz", "Lief\u00b7fTeut\u00b7schHoll", "und", "En\u00b7ge\u00b7Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kein ", "tokens": ["Kein"], "token_info": ["word"], "pos": ["PIAT"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "sein S\u00e4yten-Spihl!", "tokens": ["sein", "S\u00e4y\u00b7ten\u00b7Spihl", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Schon mehr al\u00df Eine dhat wie du/", "tokens": ["Schon", "mehr", "al\u00df", "Ei\u00b7ne", "dhat", "wie", "du", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "ART", "NN", "KOKOM", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zum Schlu\u00df lieff sie mir br\u00fcnstig zu;", "tokens": ["zum", "Schlu\u00df", "lieff", "sie", "mir", "br\u00fcns\u00b7tig", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein Leichtrichin und dreyn ein Licht/", "tokens": ["ein", "Leicht\u00b7ri\u00b7chin", "und", "dreyn", "ein", "Licht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "CARD", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "for nasse Seufftzer b\u00fcn ich nicht.", "tokens": ["for", "nas\u00b7se", "Seufft\u00b7zer", "b\u00fcn", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wei\u00df es dr\u00fcmb und wei\u00df es doch/", "tokens": ["Ich", "wei\u00df", "es", "dr\u00fcmb", "und", "wei\u00df", "es", "doch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "KON", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "du kombst mir noch!", "tokens": ["du", "kombst", "mir", "noch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Zerbleicht auch gleichsahm deinen Glantz", "tokens": ["Zer\u00b7bleicht", "auch", "gleich\u00b7sahm", "dei\u00b7nen", "Glantz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kein bundt-beaugter Pfauen-Schwantz/", "tokens": ["kein", "bundt\u00b7be\u00b7aug\u00b7ter", "Pfau\u00b7en\u00b7Schwantz", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "noch steinerner al\u00df bloh\u00df au\u00df Stein/", "tokens": ["noch", "stei\u00b7ner\u00b7ner", "al\u00df", "bloh\u00df", "au\u00df", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADV", "APPR", "NN", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "wie adamanten werd ich seyn.", "tokens": ["wie", "a\u00b7da\u00b7man\u00b7ten", "werd", "ich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "VAFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr meine Kniee/ sonder Sinn/", "tokens": ["F\u00fcr", "mei\u00b7ne", "Kni\u00b7ee", "/", "son\u00b7der", "Sinn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "brichstu dan hin!", "tokens": ["brichs\u00b7tu", "dan", "hin", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$."], "meter": "+---", "measure": "dactylic.init"}}, "stanza.5": {"line.1": {"text": "Mord-schwere Noht! Bozz Blizz und Bein!", "tokens": ["Mord\u00b7schwe\u00b7re", "Noht", "!", "Bozz", "Blizz", "und", "Bein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "B\u00fcn ich dein H\u00fcndgen Liberlein?", "tokens": ["B\u00fcn", "ich", "dein", "H\u00fcnd\u00b7gen", "Li\u00b7berl\u00b7ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich spei dir mitten ins Gesicht:", "tokens": ["Ich", "spei", "dir", "mit\u00b7ten", "ins", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Steh auff/ dreh \u00fcmb/ ich br\u00e4uch dich nicht!", "tokens": ["Steh", "auff", "/", "dreh", "\u00fcmb", "/", "ich", "br\u00e4uch", "dich", "nicht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "$(", "XY", "XY", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "An jedem Finger baumeln mir", "tokens": ["An", "je\u00b7dem", "Fin\u00b7ger", "bau\u00b7meln", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zum mindsten zwihr!", "tokens": ["zum", "minds\u00b7ten", "zwihr", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Itzt fast noch bla\u00df/ itzt wihder roht/", "tokens": ["Itzt", "fast", "noch", "bla\u00df", "/", "itzt", "wih\u00b7der", "roht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "$(", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "lebendig bistu dan schon dodt", "tokens": ["le\u00b7ben\u00b7dig", "bis\u00b7tu", "dan", "schon", "dodt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und traumst in jeder schwartzen Nacht/", "tokens": ["und", "traumst", "in", "je\u00b7der", "schwart\u00b7zen", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wa\u00df ", "tokens": ["wa\u00df"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "inde\u00df an deiner Kammer-Dh\u00fcr", "tokens": ["in\u00b7de\u00df", "an", "dei\u00b7ner", "Kam\u00b7mer\u00b7\u00b7D\u00b7h\u00fcr"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.6": {"text": "kein Riegel f\u00fcr!", "tokens": ["kein", "Rie\u00b7gel", "f\u00fcr", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Stihlt dan mein L\u00fcmmel ", "tokens": ["Stihlt", "dan", "mein", "L\u00fcm\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "sich schlau bi\u00df f\u00fcr dein Rohsen-Dhor/", "tokens": ["sich", "schlau", "bi\u00df", "f\u00fcr", "dein", "Roh\u00b7sen\u00b7\u00b7D\u00b7hor", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "dan kanstu/ matt f\u00fcr s\u00fcsser Pein/", "tokens": ["dan", "kans\u00b7tu", "/", "matt", "f\u00fcr", "s\u00fcs\u00b7ser", "Pein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "$(", "ADJD", "APPR", "ADJA", "NN", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "nicht mehr von ihm entsondert seyn", "tokens": ["nicht", "mehr", "von", "ihm", "ent\u00b7son\u00b7dert", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "PPER", "VVPP", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und lenckst ihn ins gelohbte Land/", "tokens": ["und", "lenckst", "ihn", "ins", "ge\u00b7lohb\u00b7te", "Land", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit eigner Hand!", "tokens": ["mit", "eig\u00b7ner", "Hand", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}