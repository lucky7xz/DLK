{"textgrid.poem.53238": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: F\u00fcrsten von gerechtem Muth", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "F\u00fcrsten von gerechtem Muth", "tokens": ["F\u00fcrs\u00b7ten", "von", "ge\u00b7rech\u00b7tem", "Muth"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind ein allgemeines Gut.", "tokens": ["Sind", "ein", "all\u00b7ge\u00b7mei\u00b7nes", "Gut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was von ihnen sey zu halten,", "tokens": ["Was", "von", "ih\u00b7nen", "sey", "zu", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird am meisten dar erkant,", "tokens": ["Wird", "am", "meis\u00b7ten", "dar", "er\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "PIS", "PTKVZ", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo man \u00fcber Leut und Land", "tokens": ["Wo", "man", "\u00fc\u00b7ber", "Leut", "und", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen W\u00fcttrich siehet walten,", "tokens": ["Ei\u00b7nen", "W\u00fctt\u00b7rich", "sie\u00b7het", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Dem die Herrschafft nur behagt,", "tokens": ["Dem", "die", "Herr\u00b7schafft", "nur", "be\u00b7hagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der nach keiner Satzung fragt,", "tokens": ["Der", "nach", "kei\u00b7ner", "Sat\u00b7zung", "fragt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der nur wil gef\u00fcrchtet werden,", "tokens": ["Der", "nur", "wil", "ge\u00b7f\u00fcrch\u00b7tet", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und auff seinen Nutz nur schawt,", "tokens": ["Und", "auff", "sei\u00b7nen", "Nutz", "nur", "schawt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja, der beydes Woll' und Haut", "tokens": ["Ja", ",", "der", "bey\u00b7des", "Woll'", "und", "Haut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Abzeucht seiner matten Herden.", "tokens": ["Ab\u00b7zeucht", "sei\u00b7ner", "mat\u00b7ten", "Her\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wer h\u00e4lt seine Freyheit wehrt?", "tokens": ["Wer", "h\u00e4lt", "sei\u00b7ne", "Frey\u00b7heit", "wehrt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wer sein Leben? und begehrt", "tokens": ["Wer", "sein", "Le\u00b7ben", "?", "und", "be\u00b7gehrt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "$.", "KON", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Phalaris zum Herren?", "tokens": ["Ei\u00b7nen", "Pha\u00b7la\u00b7ris", "zum", "Her\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "O, was Elend mu\u00df es seyn,", "tokens": ["O", ",", "was", "E\u00b7lend", "mu\u00df", "es", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "NN", "VMFIN", "PPER", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn man wegen Furcht und Pein", "tokens": ["Wenn", "man", "we\u00b7gen", "Furcht", "und", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich f\u00fcr sich mu\u00df selbst versperren!", "tokens": ["Sich", "f\u00fcr", "sich", "mu\u00df", "selbst", "ver\u00b7sper\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PRF", "VMFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "W\u00fcst' ich unter dir, Tiber,", "tokens": ["W\u00fcst'", "ich", "un\u00b7ter", "dir", ",", "Ti\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$,", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Auch Seianen Gl\u00fcck und Ehr", "tokens": ["Auch", "Sei\u00b7a\u00b7nen", "Gl\u00fcck", "und", "Ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein K\u00f6nigreich zu haben", "tokens": ["Und", "ein", "K\u00f6\u00b7nig\u00b7reich", "zu", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PTKZU", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und daneben die Gefahr,", "tokens": ["Und", "da\u00b7ne\u00b7ben", "die", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "So zu deinen Zeiten war,", "tokens": ["So", "zu", "dei\u00b7nen", "Zei\u00b7ten", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wozu solten mir die Gaben?", "tokens": ["Wo\u00b7zu", "sol\u00b7ten", "mir", "die", "Ga\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Kan auch jener fr\u00f6lich seyn", "tokens": ["Kan", "auch", "je\u00b7ner", "fr\u00f6\u00b7lich", "seyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PDAT", "ADJD", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bey den Seiten, bey dem Wein,", "tokens": ["Bey", "den", "Sei\u00b7ten", ",", "bey", "dem", "Wein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bey den K\u00f6niglichen Speisen,", "tokens": ["Bey", "den", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "Spei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn er fort und fort gedenckt,", "tokens": ["Wenn", "er", "fort", "und", "fort", "ge\u00b7denckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKVZ", "KON", "PTKVZ", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df man \u00fcber ihn gehenckt", "tokens": ["Da\u00df", "man", "\u00fc\u00b7ber", "ihn", "ge\u00b7henckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "PPER", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "An ein Har ein blanckes Eisen?", "tokens": ["An", "ein", "Har", "ein", "blan\u00b7ckes", "Ei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Nein, mir gn\u00fcget Saltz und Brod,", "tokens": ["Nein", ",", "mir", "gn\u00fc\u00b7get", "Saltz", "und", "Brod", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hie wo ich der gleichen Noht", "tokens": ["Hie", "wo", "ich", "der", "glei\u00b7chen", "Noht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mehr als wol kan m\u00fc\u00dfig gehen,", "tokens": ["Mehr", "als", "wol", "kan", "m\u00fc\u00b7\u00dfig", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ADV", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Grosser ChurF\u00fcrst, unter dir,", "tokens": ["Gros\u00b7ser", "Chur", "F\u00fcrst", ",", "un\u00b7ter", "dir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welcher gern in Bl\u00fct und Zier", "tokens": ["Wel\u00b7cher", "gern", "in", "Bl\u00fct", "und", "Zier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAT", "ADV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Siehet seine V\u00f6lcker stehen.", "tokens": ["Sie\u00b7het", "sei\u00b7ne", "V\u00f6l\u00b7cker", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Darumb ist es wunder, Held,", "tokens": ["Da\u00b7rumb", "ist", "es", "wun\u00b7der", ",", "Held", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "NN", "$,", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df man nicht au\u00df aller Welt", "tokens": ["Da\u00df", "man", "nicht", "au\u00df", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PTKNEG", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vom verborgnen Nilus-Strande,", "tokens": ["Vom", "ver\u00b7borg\u00b7nen", "Ni\u00b7lus\u00b7Stran\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der die sieben Au\u00dff\u00e4ll' hat,", "tokens": ["Der", "die", "sie\u00b7ben", "Au\u00df\u00b7f\u00e4ll'", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "CARD", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Von dem Ganges und Euphrat", "tokens": ["Von", "dem", "Gan\u00b7ges", "und", "Eu\u00b7ph\u00b7rat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Sich begiebt in deine Lande.", "tokens": ["Sich", "be\u00b7giebt", "in", "dei\u00b7ne", "Lan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und des sch\u00f6nen Tages Pracht,", "tokens": ["Und", "des", "sch\u00f6\u00b7nen", "Ta\u00b7ges", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Welcher dich zur Welt gebracht,", "tokens": ["Wel\u00b7cher", "dich", "zur", "Welt", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sollt' uns unbegangen bleiben?", "tokens": ["Sollt'", "uns", "un\u00b7be\u00b7gan\u00b7gen", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nein, der Himmel feyret ihn,", "tokens": ["Nein", ",", "der", "Him\u00b7mel", "fey\u00b7ret", "ihn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der mit Frost sich wil beziehn", "tokens": ["Der", "mit", "Frost", "sich", "wil", "be\u00b7ziehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "PRF", "VMFIN", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und des Nebels Gifft vertreiben.", "tokens": ["Und", "des", "Ne\u00b7bels", "Gifft", "ver\u00b7trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sey gegr\u00fcsst, O Tagelicht,", "tokens": ["Sey", "ge\u00b7gr\u00fcs\u00b7st", ",", "O", "Ta\u00b7ge\u00b7licht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "NE", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Das uns newe Gunst verspricht.", "tokens": ["Das", "uns", "ne\u00b7we", "Gunst", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Des Gew\u00f6lckes Wust geht \u00fcber.", "tokens": ["Des", "Ge\u00b7w\u00f6l\u00b7ckes", "Wust", "geht", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Brachte der Tag Gn\u00fcg und Lust,", "tokens": ["Brach\u00b7te", "der", "Tag", "Gn\u00fcg", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NE", "KON", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Welcher Rom gebahr August,", "tokens": ["Wel\u00b7cher", "Rom", "ge\u00b7bahr", "Au\u00b7gust", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NE", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du bist uns in Warheit lieber.", "tokens": ["Du", "bist", "uns", "in", "War\u00b7heit", "lie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Wein und Seiten-Spiel heran!", "tokens": ["Wein", "und", "Sei\u00b7ten\u00b7Spiel", "he\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sorg' und was betr\u00fcben kan,", "tokens": ["Sor\u00b7g'", "und", "was", "be\u00b7tr\u00fc\u00b7ben", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PWS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Trollt euch auff die w\u00fcste Wellen!", "tokens": ["Trollt", "euch", "auff", "die", "w\u00fcs\u00b7te", "Wel\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Redner und Poeten auff,", "tokens": ["Red\u00b7ner", "und", "Po\u00b7et\u00b7en", "auff", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lasst der Musen Schar zu hauff", "tokens": ["Lasst", "der", "Mu\u00b7sen", "Schar", "zu", "hauff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich anjetzt zu euch gesellen!", "tokens": ["Sich", "an\u00b7jetzt", "zu", "euch", "ge\u00b7sel\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Was? Gebeht und Seufftzer her!", "tokens": ["Was", "?", "Ge\u00b7beht", "und", "Seufft\u00b7zer", "her", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Frewden-Thr\u00e4nen, macht ein Meer,", "tokens": ["Fre\u00b7wden\u00b7Thr\u00e4\u00b7nen", ",", "macht", "ein", "Meer", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gott den H\u00f6chsten zu gewinnen,", "tokens": ["Gott", "den", "H\u00f6chs\u00b7ten", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Kirchen dancken Ihm", "tokens": ["Al\u00b7le", "Kir\u00b7chen", "dan\u00b7cken", "Ihm"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch der Andacht Ungest\u00fcm", "tokens": ["Durch", "der", "An\u00b7dacht", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und in Lieb' erhitzte Sinnen.", "tokens": ["Und", "in", "Lieb'", "er\u00b7hitz\u00b7te", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Der wird Ihn, sein wehrtes Theil,", "tokens": ["Der", "wird", "Ihn", ",", "sein", "wehr\u00b7tes", "Theil", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Unsrer aller Trost und Heil,", "tokens": ["Uns\u00b7rer", "al\u00b7ler", "Trost", "und", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns noch lange Zeit erhalten,", "tokens": ["Uns", "noch", "lan\u00b7ge", "Zeit", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und in seiner Neffen Schaar", "tokens": ["Und", "in", "sei\u00b7ner", "Nef\u00b7fen", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "(gott mach diese Weissag war!)", "tokens": ["(", "gott", "mach", "die\u00b7se", "Weis\u00b7sag", "war", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PDAT", "NN", "VAFIN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gleich dem Nestor lassen alten.", "tokens": ["Gleich", "dem", "Nes\u00b7tor", "las\u00b7sen", "al\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Dieser so gew\u00fcnschte Tag,", "tokens": ["Die\u00b7ser", "so", "ge\u00b7w\u00fcnschte", "Tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Als die Sonn' ihn tragen mag,", "tokens": ["Als", "die", "Sonn'", "ihn", "tra\u00b7gen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird uns manche Frewde geben.", "tokens": ["Wird", "uns", "man\u00b7che", "Frew\u00b7de", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo wir ihn nicht weiter sehn,", "tokens": ["Wo", "wir", "ihn", "nicht", "wei\u00b7ter", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "(gott la\u00df dieses nicht geschehn!)", "tokens": ["(", "gott", "la\u00df", "die\u00b7ses", "nicht", "ge\u00b7schehn", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PDS", "PTKNEG", "VVINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wer wollt' einen Tag mehr leben!", "tokens": ["Wer", "wollt'", "ei\u00b7nen", "Tag", "mehr", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}