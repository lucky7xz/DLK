{"textgrid.poem.48762": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "49. Nachdem das Holsteinische Schiff von der gef\u00e4rlichen Truckne im Munde der Wolgen durch g\u00f6tlichen Segen erhoben ward", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wirf nun den Wehmut weg, du edler Haufe du,", "tokens": ["Wirf", "nun", "den", "Weh\u00b7mut", "weg", ",", "du", "ed\u00b7ler", "Hau\u00b7fe", "du", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "PTKVZ", "$,", "PPER", "ADJA", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "schau, was der Himmel tut f\u00fcr dich und f\u00fcr dein Gl\u00fccke.", "tokens": ["schau", ",", "was", "der", "Him\u00b7mel", "tut", "f\u00fcr", "dich", "und", "f\u00fcr", "dein", "Gl\u00fc\u00b7cke", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "PRELS", "ART", "NN", "VVFIN", "APPR", "PPER", "KON", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Er schl\u00e4gt die falsche Flut mit strenger Macht zur\u00fccke,", "tokens": ["Er", "schl\u00e4gt", "die", "fal\u00b7sche", "Flut", "mit", "stren\u00b7ger", "Macht", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "die dein Verr\u00e4ter war. So sprich dich denn zur Ruh.", "tokens": ["die", "dein", "Ver\u00b7r\u00e4\u00b7ter", "war", ".", "So", "sprich", "dich", "denn", "zur", "Ruh", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der g\u00fcnstige S\u00fcdost, der weht dir Freundschaft zu,", "tokens": ["Der", "g\u00fcns\u00b7ti\u00b7ge", "S\u00fcd\u00b7ost", ",", "der", "weht", "dir", "Freund\u00b7schaft", "zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "hebt dein gestrand'tes Schiff in einem Augenblicke,", "tokens": ["hebt", "dein", "ge\u00b7stran\u00b7d'\u00b7tes", "Schiff", "in", "ei\u00b7nem", "Au\u00b7gen\u00b7bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "+---+-+-+-+-+-", "measure": "dactylic.init"}, "line.3": {"text": "das nun fast ratlos fiel in seines Todes Stricke,", "tokens": ["das", "nun", "fast", "rat\u00b7los", "fiel", "in", "sei\u00b7nes", "To\u00b7des", "Stri\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und bl\u00e4st sein Segelwerk gleich \u00fcber auf ", "tokens": ["und", "bl\u00e4st", "sein", "Se\u00b7gel\u00b7werk", "gleich", "\u00fc\u00b7ber", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "So traurig du warst vor, so froh sei nun itzunder", "tokens": ["So", "trau\u00b7rig", "du", "warst", "vor", ",", "so", "froh", "sei", "nun", "it\u00b7zun\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "PTKVZ", "$,", "ADV", "ADJD", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und achte dieses Werk vor nicht ein schlechtes Wunder,", "tokens": ["und", "ach\u00b7te", "die\u00b7ses", "Werk", "vor", "nicht", "ein", "schlech\u00b7tes", "Wun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "PDAT", "NN", "APPR", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "in dem dir Gott ist gut. Bring' erstlich deinen Dank!", "tokens": ["in", "dem", "dir", "Gott", "ist", "gut", ".", "Bring'", "erst\u00b7lich", "dei\u00b7nen", "Dank", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "NN", "VAFIN", "ADJD", "$.", "NE", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Nach diesem fleh' ihn an um unsers ", "tokens": ["Nach", "die\u00b7sem", "fleh'", "ihn", "an", "um", "un\u00b7sers"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "APPR", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "bei dem auch unser Tod sein Leben auf wil geben.", "tokens": ["bei", "dem", "auch", "un\u00b7ser", "Tod", "sein", "Le\u00b7ben", "auf", "wil", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "APPR", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist dieser nicht gesund, so sind wir alle krank.", "tokens": ["Ist", "die\u00b7ser", "nicht", "ge\u00b7sund", ",", "so", "sind", "wir", "al\u00b7le", "krank", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PTKNEG", "ADJD", "$,", "ADV", "VAFIN", "PPER", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}