{"textgrid.poem.62387": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "Als er in Frankenberg bei Aachen wohnte", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich zieh' in euch, ihr Mauern,", "tokens": ["Ich", "zieh'", "in", "euch", ",", "ihr", "Mau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit Wehmuth und mit Lust,", "tokens": ["Mit", "Weh\u00b7muth", "und", "mit", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O Vorzeit reich an Schauern,", "tokens": ["O", "Vor\u00b7zeit", "reich", "an", "Schau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du ziehst in meine Brust.", "tokens": ["Du", "ziehst", "in", "mei\u00b7ne", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ihr W\u00e4nde habt belauschet", "tokens": ["Ihr", "W\u00e4n\u00b7de", "habt", "be\u00b7lau\u00b7schet"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Des alten Kaisers Gl\u00fcck,", "tokens": ["Des", "al\u00b7ten", "Kai\u00b7sers", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von Saitenklang durchrauschet,", "tokens": ["Von", "Sai\u00b7ten\u00b7klang", "durc\u00b7hrau\u00b7schet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erhellt vom Sonnenblick.", "tokens": ["Er\u00b7hellt", "vom", "Son\u00b7nen\u00b7blick", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Hier hat der Held gesessen,", "tokens": ["Hier", "hat", "der", "Held", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als ihm sein Lieb entschlief:", "tokens": ["Als", "ihm", "sein", "Lieb", "ent\u00b7schlief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Lust war unermessen,", "tokens": ["Die", "Lust", "war", "un\u00b7er\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Leid war gar zu tief.", "tokens": ["Das", "Leid", "war", "gar", "zu", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und was ihn so gekr\u00e4nket,", "tokens": ["Und", "was", "ihn", "so", "ge\u00b7kr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was ihm sein Herz bezwang,", "tokens": ["Was", "ihm", "sein", "Herz", "be\u00b7zwang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Liegt hier im See versenket", "tokens": ["Liegt", "hier", "im", "See", "ver\u00b7sen\u00b7ket"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schon tausend Jahre lang.", "tokens": ["Schon", "tau\u00b7send", "Jah\u00b7re", "lang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der Ring von seiner Lieben,", "tokens": ["Der", "Ring", "von", "sei\u00b7ner", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den trug sie an der Hand,", "tokens": ["Den", "trug", "sie", "an", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In dem ein Wort geschrieben", "tokens": ["In", "dem", "ein", "Wort", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von ew'gem Liebespfand;", "tokens": ["Von", "ew'\u00b7gem", "Lie\u00b7be\u00b7spfand", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Den hat der See verschlungen:", "tokens": ["Den", "hat", "der", "See", "ver\u00b7schlun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da war der Karl geheilt. \u2013", "tokens": ["Da", "war", "der", "Karl", "ge\u00b7heilt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NE", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Pilger blickt gezwungen", "tokens": ["Der", "Pil\u00b7ger", "blickt", "ge\u00b7zwun\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zur Tiefe nun und weilt.", "tokens": ["Zur", "Tie\u00b7fe", "nun", "und", "weilt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wol Jeder hat getrunken", "tokens": ["Wol", "Je\u00b7der", "hat", "ge\u00b7trun\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIS", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vom Becher voll und s\u00fc\u00df,", "tokens": ["Vom", "Be\u00b7cher", "voll", "und", "s\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wol Jedem liegt versunken", "tokens": ["Wol", "Je\u00b7dem", "liegt", "ver\u00b7sun\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "VVFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein fr\u00fches Paradies.", "tokens": ["Ein", "fr\u00fc\u00b7hes", "Pa\u00b7ra\u00b7dies", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Drum ist der See so tr\u00fcbe,", "tokens": ["Drum", "ist", "der", "See", "so", "tr\u00fc\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit Laub und Schilf bedeckt,", "tokens": ["Mit", "Laub", "und", "Schilf", "be\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil ihren Gram die Liebe", "tokens": ["Weil", "ih\u00b7ren", "Gram", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gern aller Welt versteckt.", "tokens": ["Gern", "al\u00b7ler", "Welt", "ver\u00b7steckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ihr Gl\u00fcck l\u00e4\u00dft Liebe scheinen", "tokens": ["Ihr", "Gl\u00fcck", "l\u00e4\u00dft", "Lie\u00b7be", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und zeigt es unverstellt;", "tokens": ["Und", "zeigt", "es", "un\u00b7ver\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch mu\u00df die Liebe weinen,", "tokens": ["Doch", "mu\u00df", "die", "Lie\u00b7be", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So flieht sie vor der Welt.", "tokens": ["So", "flieht", "sie", "vor", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "O Sehnsucht allgewaltig,", "tokens": ["O", "Sehn\u00b7sucht", "all\u00b7ge\u00b7wal\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Halb dunkel, halb bewu\u00dft,", "tokens": ["Halb", "dun\u00b7kel", ",", "halb", "be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O Sehnsucht, vielgestaltig", "tokens": ["O", "Sehn\u00b7sucht", ",", "viel\u00b7ge\u00b7stal\u00b7tig"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "NN", "$,", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Beschleichst du meine Brust.", "tokens": ["Be\u00b7schleichst", "du", "mei\u00b7ne", "Brust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Ich will nun in die Felder", "tokens": ["Ich", "will", "nun", "in", "die", "Fel\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und an die klaren See'n,", "tokens": ["Und", "an", "die", "kla\u00b7ren", "See'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Durchschweifen gr\u00fcne W\u00e4lder", "tokens": ["Durch\u00b7schwei\u00b7fen", "gr\u00fc\u00b7ne", "W\u00e4l\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und alte Felsenh\u00f6h'n.", "tokens": ["Und", "al\u00b7te", "Fel\u00b7sen\u00b7h\u00f6h'", "n."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["KON", "ADJA", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}