{"dta.poem.9169": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n Als er von der reise wieder kam und sein voriges m\u00e4dgen  \n nicht mehr lieben konte.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.85", "sv:0.14"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ich h\u00e4tt es nicht vermeint/ da\u00df bey den junggeselle\u0303/", "tokens": ["Ich", "h\u00e4tt", "es", "nicht", "ver\u00b7meint", "/", "da\u00df", "bey", "den", "jung\u00b7ge\u00b7sell\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$(", "KOUS", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wann sie sich freundlich stellen/", "tokens": ["Wann", "sie", "sich", "freund\u00b7lich", "stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die angemaste treu", "tokens": ["Die", "an\u00b7ge\u00b7mas\u00b7te", "treu"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "So wanckelm\u00fcthig sey:", "tokens": ["So", "wan\u00b7ckel\u00b7m\u00fct\u00b7hig", "sey", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Weil aber mein gewissen", "tokens": ["Weil", "a\u00b7ber", "mein", "ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Mir selbst entgegen scheint/", "tokens": ["Mir", "selbst", "ent\u00b7ge\u00b7gen", "scheint", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKVZ", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Hab ich offt sagen m\u00fcssen:", "tokens": ["Hab", "ich", "offt", "sa\u00b7gen", "m\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ich h\u00e4tt es nicht vermeynt.", "tokens": ["Ich", "h\u00e4tt", "es", "nicht", "ver\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Ich h\u00e4tt es nicht vermeynt. Es sind gar wenig", "tokens": ["Ich", "h\u00e4tt", "es", "nicht", "ver\u00b7meynt", ".", "Es", "sind", "gar", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$.", "PPER", "VAFIN", "ADV", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Indessen angebrochen/ ", "tokens": ["In\u00b7des\u00b7sen", "an\u00b7ge\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Al\u00df ich ein sch\u00f6nes bild", "tokens": ["Al\u00df", "ich", "ein", "sch\u00f6\u00b7nes", "bild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Noch vor mein labsal hielt;", "tokens": ["Noch", "vor", "mein", "lab\u00b7sal", "hielt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nun seh ich/ da\u00df mein hertze", "tokens": ["Nun", "seh", "ich", "/", "da\u00df", "mein", "hert\u00b7ze"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Den handel gantz verneint/", "tokens": ["Den", "han\u00b7del", "gantz", "ver\u00b7neint", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und spricht noch wohl im schertze:", "tokens": ["Und", "spricht", "noch", "wohl", "im", "schert\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "APPRART", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Das h\u00e4tt ich nicht vermeynt.", "tokens": ["Das", "h\u00e4tt", "ich", "nicht", "ver\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. Doch h\u00e4tt ichs nicht vermeynt: Denn meine see-", "tokens": ["Doch", "h\u00e4tt", "ichs", "nicht", "ver\u00b7meynt", ":", "Denn", "mei\u00b7ne", "see"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PIS", "PTKNEG", "VVPP", "$.", "KON", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich mich selbst nicht kannte/ ", "tokens": ["Da\u00df", "ich", "mich", "selbst", "nicht", "kann\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich redt/ ich sang von ihr/", "tokens": ["Ich", "redt", "/", "ich", "sang", "von", "ihr", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "APPR", "PPOSAT", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Stets war ich ausser mir:", "tokens": ["Stets", "war", "ich", "aus\u00b7ser", "mir", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nun bin ich zwar geblieben", "tokens": ["Nun", "bin", "ich", "zwar", "ge\u00b7blie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ein blosser guter freund/", "tokens": ["Ein", "blos\u00b7ser", "gu\u00b7ter", "freund", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Doch kan ich sie nicht lieben:", "tokens": ["Doch", "kan", "ich", "sie", "nicht", "lie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Das h\u00e4tt ich nicht vermeynt.", "tokens": ["Das", "h\u00e4tt", "ich", "nicht", "ver\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "4. Ich h\u00e4tt es nicht vermeynt: als wir zusammen", "tokens": ["Ich", "h\u00e4tt", "es", "nicht", "ver\u00b7meynt", ":", "als", "wir", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$.", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und endlich abschied nahmen/ ", "tokens": ["Und", "end\u00b7lich", "ab\u00b7schied", "nah\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da bildt ich mir wohl ein", "tokens": ["Da", "bildt", "ich", "mir", "wohl", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich m\u00fcste traurig seyn.", "tokens": ["Ich", "m\u00fcs\u00b7te", "trau\u00b7rig", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch weil mir nun bey andern", "tokens": ["Doch", "weil", "mir", "nun", "bey", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das gl\u00fccke g\u00fcnstig scheint/", "tokens": ["Das", "gl\u00fc\u00b7cke", "g\u00fcns\u00b7tig", "scheint", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "So bin ich auch von Flandern.", "tokens": ["So", "bin", "ich", "auch", "von", "Flan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Das h\u00e4tt ich nicht vermeynt.", "tokens": ["Das", "h\u00e4tt", "ich", "nicht", "ver\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "5. Das h\u00e4tt ich nicht vermeynt/ als ich die bangig-", "tokens": ["Das", "h\u00e4tt", "ich", "nicht", "ver\u00b7meynt", "/", "als", "ich", "die", "ban\u00b7gig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$(", "KOUS", "PPER", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In meiner seele streiten ", "tokens": ["In", "mei\u00b7ner", "see\u00b7le", "strei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und schmertzen und verdrie\u00df", "tokens": ["Und", "schmert\u00b7zen", "und", "ver\u00b7drie\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVINF", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mich stets best\u00fcrmen lie\u00df.", "tokens": ["Mich", "stets", "be\u00b7st\u00fcr\u00b7men", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nun leg ich alles nieder/", "tokens": ["Nun", "leg", "ich", "al\u00b7les", "nie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PPER", "PIS", "PTKVZ", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und bin ihr zwar nicht feind/", "tokens": ["Und", "bin", "ihr", "zwar", "nicht", "feind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PTKNEG", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Doch komm ich ihr nicht wieder/", "tokens": ["Doch", "komm", "ich", "ihr", "nicht", "wie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und h\u00e4tt ichs nie vermeynt.", "tokens": ["Und", "h\u00e4tt", "ichs", "nie", "ver\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}