{"dta.poem.18998": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Ode.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Ojhr krumme/ schlimme sehlen/", "tokens": ["Ojhr", "krum\u00b7me", "/", "schlim\u00b7me", "seh\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$(", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wolt jhr euch", "tokens": ["Wolt", "jhr", "euch"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER"], "meter": "+--", "measure": "dactylic.init"}, "line.3": {"text": "Laster-reich", "tokens": ["Las\u00b7ter\u00b7reich"], "token_info": ["word"], "pos": ["NE"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Nu mit dieser welt verm\u00e4hlen?", "tokens": ["Nu", "mit", "die\u00b7ser", "welt", "ver\u00b7m\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bochet nicht auff ewre st\u00f6ll/", "tokens": ["Bo\u00b7chet", "nicht", "auff", "ew\u00b7re", "st\u00b7\u00f6ll", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Dan die welt nur eine H\u00f6ll/", "tokens": ["Dan", "die", "welt", "nur", "ei\u00b7ne", "H\u00f6ll", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Euch zu martern vnd zu qu\u00e4len.", "tokens": ["Euch", "zu", "mar\u00b7tern", "vnd", "zu", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wollet jhr ein weil nu leben", "tokens": ["Wol\u00b7let", "jhr", "ein", "weil", "nu", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "KOUS", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach geb\u00fchr/", "tokens": ["Nach", "ge\u00b7b\u00fchr", "/"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "So solt jhr", "tokens": ["So", "solt", "jhr"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Al\u00df bald nach dem himmel streben:", "tokens": ["Al\u00df", "bald", "nach", "dem", "him\u00b7mel", "stre\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist der himmel euch nicht lieb/", "tokens": ["Ist", "der", "him\u00b7mel", "euch", "nicht", "lieb", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "PTKNEG", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "So seit jhr nicht wehrt/ jhr dieb/", "tokens": ["So", "seit", "jhr", "nicht", "wehrt", "/", "jhr", "dieb", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PTKNEG", "VVFIN", "$(", "PPOSAT", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Da\u00df er euch sein liecht gegeben.", "tokens": ["Da\u00df", "er", "euch", "sein", "liecht", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Lasset euch zu hertzen gehen", "tokens": ["Las\u00b7set", "euch", "zu", "hert\u00b7zen", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was f\u00fcr frayd/", "tokens": ["Was", "f\u00fcr", "frayd", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Was f\u00fcr layd", "tokens": ["Was", "f\u00fcr", "layd"], "token_info": ["word", "word", "word"], "pos": ["PWS", "APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Jmmer in der welt zusehen:", "tokens": ["Jm\u00b7mer", "in", "der", "welt", "zu\u00b7se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kan ein mensch auff disem Meer", "tokens": ["Kan", "ein", "mensch", "auff", "di\u00b7sem", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "In so vieler vbeln heer", "tokens": ["In", "so", "vie\u00b7ler", "vbeln", "heer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIAT", "NN", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Sicher vnd forchtlo\u00df bestehen!", "tokens": ["Si\u00b7cher", "vnd", "forcht\u00b7lo\u00df", "be\u00b7ste\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bi\u00df in das grab von der wiegen", "tokens": ["Bi\u00df", "in", "das", "grab", "von", "der", "wie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mu\u00df alhie", "tokens": ["Mu\u00df", "al\u00b7hie"], "token_info": ["word", "word"], "pos": ["VMFIN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Vnder m\u00fch", "tokens": ["Vn\u00b7der", "m\u00fch"], "token_info": ["word", "word"], "pos": ["KON", "ADJD"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Vnd ellend der mensch sich biegen:", "tokens": ["Vnd", "el\u00b7lend", "der", "mensch", "sich", "bie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dan anfechtung/ Creutz vnd noht", "tokens": ["Dan", "an\u00b7fech\u00b7tung", "/", "Creutz", "vnd", "noht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Jhn bi\u00df in den bittern tod", "tokens": ["Jhn", "bi\u00df", "in", "den", "bit\u00b7tern", "tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.7": {"text": "Stehts verfolgen vnd bekriegen.", "tokens": ["Stehts", "ver\u00b7fol\u00b7gen", "vnd", "be\u00b7krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Auch ist sein geburth so kl\u00e4glich", "tokens": ["Auch", "ist", "sein", "ge\u00b7burth", "so", "kl\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df die plag/", "tokens": ["Da\u00df", "die", "plag", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Mit dem tag", "tokens": ["Mit", "dem", "tag"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Gleich anfangend/ kaum ertr\u00e4glich:", "tokens": ["Gleich", "an\u00b7fan\u00b7gend", "/", "kaum", "er\u00b7tr\u00e4g\u00b7lich", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$(", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine schwachheit vnd der schmertz/", "tokens": ["Sei\u00b7ne", "schwach\u00b7heit", "vnd", "der", "schmertz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "T\u00f6dtend seiner Mutter hertz/", "tokens": ["T\u00f6d\u00b7tend", "sei\u00b7ner", "Mut\u00b7ter", "hertz", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Seind empfindlich vnd vns\u00e4glich.", "tokens": ["Seind", "emp\u00b7find\u00b7lich", "vnd", "vn\u00b7s\u00e4g\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+++-", "measure": "unknown.measure.penta"}}, "stanza.6": {"line.1": {"text": "Wan durch schmertzen tieff empfunden", "tokens": ["Wan", "durch", "schmert\u00b7zen", "tieff", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er voll pein", "tokens": ["Er", "voll", "pein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "ADJD", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Schwach vnd klein", "tokens": ["Schwach", "vnd", "klein"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "ADJD"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Die geburth nu vberwunden:", "tokens": ["Die", "ge\u00b7burth", "nu", "vber\u00b7wun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wirt Er seinem stand gem\u00e4\u00df/", "tokens": ["Wirt", "Er", "sei\u00b7nem", "stand", "ge\u00b7m\u00e4\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "VVFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als ein vbelth\u00e4ter b\u00f6\u00df", "tokens": ["Als", "ein", "vbelt\u00b7h\u00e4\u00b7ter", "b\u00f6\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Eingewicklet vnd gebunden.", "tokens": ["Ein\u00b7ge\u00b7wick\u00b7let", "vnd", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie offt mu\u00df/ jhn zugeschwaigen/", "tokens": ["Wie", "offt", "mu\u00df", "/", "jhn", "zu\u00b7ge\u00b7schwai\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "$(", "PPER", "VVPP", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Jhm mit fug", "tokens": ["Jhm", "mit", "fug"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Ohn verzug", "tokens": ["Ohn", "ver\u00b7zug"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Seine S\u00e4ugam hilff erzaigen;", "tokens": ["Sei\u00b7ne", "S\u00e4u\u00b7gam", "hilff", "er\u00b7zai\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd den s\u00e4ugling von dem wust", "tokens": ["Vnd", "den", "s\u00e4ug\u00b7ling", "von", "dem", "wust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Reinigend/ mit bloser brust", "tokens": ["Rei\u00b7ni\u00b7gend", "/", "mit", "blo\u00b7ser", "brust"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$(", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "In der gr\u00f6sten k\u00e4ltin s\u00e4ugen.", "tokens": ["In", "der", "gr\u00f6s\u00b7ten", "k\u00e4l\u00b7tin", "s\u00e4u\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nemend jhn bald auff bald nider/", "tokens": ["Ne\u00b7mend", "jhn", "bald", "auff", "bald", "ni\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADV", "PTKVZ", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sunst hilfflo\u00df/", "tokens": ["Sunst", "hilf\u00b7flo\u00df", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Auff der scho\u00df", "tokens": ["Auff", "der", "scho\u00df"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wieget sie jhn hin vnd wider:", "tokens": ["Wie\u00b7get", "sie", "jhn", "hin", "vnd", "wi\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.5": {"text": "Bi\u00df Er/ weil jhr sorg vnd m\u00fch", "tokens": ["Bi\u00df", "Er", "/", "weil", "jhr", "sorg", "vnd", "m\u00fch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$(", "KOUS", "PPER", "VVFIN", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Reibet seine bein vnd kn\u00fce/", "tokens": ["Rei\u00b7bet", "sei\u00b7ne", "bein", "vnd", "kn\u00fce", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "St\u00f6rcket seine schwache glider.", "tokens": ["St\u00f6r\u00b7cket", "sei\u00b7ne", "schwa\u00b7che", "gli\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Fanget Er dan an zugehen/", "tokens": ["Fan\u00b7get", "Er", "dan", "an", "zu\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch die sprach", "tokens": ["Auch", "die", "sprach"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Nach vnd nach", "tokens": ["Nach", "vnd", "nach"], "token_info": ["word", "word", "word"], "pos": ["APPR", "KON", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "(bl\u00f6d vnd lisplend) zuverstehen:", "tokens": ["(", "bl\u00f6d", "vnd", "lis\u00b7plend", ")", "zu\u00b7ver\u00b7ste\u00b7hen", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJD", "KON", "ADJD", "$(", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist sein gang vnd seine bitt", "tokens": ["Ist", "sein", "gang", "vnd", "sei\u00b7ne", "bitt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Halbe wort vnd halbe tritt/", "tokens": ["Hal\u00b7be", "wort", "vnd", "hal\u00b7be", "tritt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Schwach zu reden/ schwach zu stehen.", "tokens": ["Schwach", "zu", "re\u00b7den", "/", "schwach", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$(", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Seine kr\u00e4fften mit den jahren/", "tokens": ["Sei\u00b7ne", "kr\u00e4ff\u00b7ten", "mit", "den", "jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seine witz/", "tokens": ["Sei\u00b7ne", "witz", "/"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Seine hitz/", "tokens": ["Sei\u00b7ne", "hitz", "/"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Seine arbeit/ m\u00fch/ gefahren/", "tokens": ["Sei\u00b7ne", "ar\u00b7beit", "/", "m\u00fch", "/", "ge\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ADJD", "$(", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nemen mit einander zu/", "tokens": ["Ne\u00b7men", "mit", "ein\u00b7an\u00b7der", "zu", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PRF", "PTKZU", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Allein nimmet ab die ruh/", "tokens": ["Al\u00b7lein", "nim\u00b7met", "ab", "die", "ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Nichts kan jhn f\u00fcr layd bewahren.", "tokens": ["Nichts", "kan", "jhn", "f\u00fcr", "layd", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Al\u00dfbald seine tag nu bl\u00fchen", "tokens": ["Al\u00df\u00b7bald", "sei\u00b7ne", "tag", "nu", "bl\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan sein muht", "tokens": ["Kan", "sein", "muht"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "VAINF", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Sich der wuht", "tokens": ["Sich", "der", "wuht"], "token_info": ["word", "word", "word"], "pos": ["PRF", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Seiner jugent nicht entziehen;", "tokens": ["Sei\u00b7ner", "ju\u00b7gent", "nicht", "ent\u00b7zie\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gro\u00df ist dan sein vnbestand/", "tokens": ["Gro\u00df", "ist", "dan", "sein", "vn\u00b7be\u00b7stand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd er felt in dise schand", "tokens": ["Vnd", "er", "felt", "in", "di\u00b7se", "schand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wan er will von jener fliehen.", "tokens": ["Wan", "er", "will", "von", "je\u00b7ner", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "APPR", "PDAT", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Spihlend mag Er sich wol vben", "tokens": ["Spih\u00b7lend", "mag", "Er", "sich", "wol", "vben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "PRF", "ADV", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil Er noch", "tokens": ["Weil", "Er", "noch"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Ohn ein joch;", "tokens": ["Ohn", "ein", "joch", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Aber jhn mehr zu betrieben", "tokens": ["A\u00b7ber", "jhn", "mehr", "zu", "be\u00b7trie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Reuttet jhm auff einmahl auff", "tokens": ["Reut\u00b7tet", "jhm", "auff", "ein\u00b7mahl", "auff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller lastern grosser hauff", "tokens": ["Al\u00b7ler", "las\u00b7tern", "gros\u00b7ser", "hauff"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Bi\u00df da\u00df er sich mu\u00df verlieben.", "tokens": ["Bi\u00df", "da\u00df", "er", "sich", "mu\u00df", "ver\u00b7lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PRF", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Al\u00dfdan vnder Amors wafen", "tokens": ["Al\u00df\u00b7dan", "vn\u00b7der", "A\u00b7mors", "wa\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "NE", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Taub vnd blind", "tokens": ["Taub", "vnd", "blind"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "ADJD"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wie ein kind", "tokens": ["Wie", "ein", "kind"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "K\u00f6nden jhn zway augen strafen:", "tokens": ["K\u00f6n\u00b7den", "jhn", "zway", "au\u00b7gen", "stra\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "CARD", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hofnung/ trost/ wollust/ genu\u00df/", "tokens": ["Hof\u00b7nung", "/", "trost", "/", "wol\u00b7lust", "/", "ge\u00b7nu\u00df", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "$(", "VMFIN", "$(", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Forcht/ verzweyflung/ zorn/ verdru\u00df/", "tokens": ["Forcht", "/", "ver\u00b7zwey\u00b7flung", "/", "zorn", "/", "ver\u00b7dru\u00df", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$(", "NN", "$(", "NN", "$(", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wollen jhn nicht lassen schlafen.", "tokens": ["Wol\u00b7len", "jhn", "nicht", "las\u00b7sen", "schla\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Kan er dises vberwinden/", "tokens": ["Kan", "er", "di\u00b7ses", "vber\u00b7win\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDS", "VVINF", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Findet Er", "tokens": ["Fin\u00b7det", "Er"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Noch vil mehr", "tokens": ["Noch", "vil", "mehr"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Tr\u00fcbsal vnd vnglick dahinden:", "tokens": ["Tr\u00fcb\u00b7sal", "vnd", "vnglick", "da\u00b7hin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ehrgeitz/ geltgeitz/ vbermuht/", "tokens": ["Ehr\u00b7geitz", "/", "gelt\u00b7geitz", "/", "vber\u00b7muht", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NE", "$(", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Hader/ h\u00e4ndel/ zanck vnd wuht", "tokens": ["Ha\u00b7der", "/", "h\u00e4n\u00b7del", "/", "zanck", "vnd", "wuht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$(", "NE", "$(", "VVIMP", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wollen jhn zu schinden binden.", "tokens": ["Wol\u00b7len", "jhn", "zu", "schin\u00b7den", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Kommet Er dan fortgegangen", "tokens": ["Kom\u00b7met", "Er", "dan", "fort\u00b7ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "VVPP"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df das glick", "tokens": ["Da\u00df", "das", "glick"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Vnd die strick", "tokens": ["Vnd", "die", "strick"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Aller laster jhn nicht fangen:", "tokens": ["Al\u00b7ler", "las\u00b7ter", "jhn", "nicht", "fan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wirt Er au\u00df der jugent saal", "tokens": ["Wirt", "Er", "au\u00df", "der", "ju\u00b7gent", "saal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "In der alten leut spital", "tokens": ["In", "der", "al\u00b7ten", "leut", "spi\u00b7tal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Schlim vnd liederlich empfangen.", "tokens": ["Schlim", "vnd", "lie\u00b7der\u00b7lich", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Dan da kommen auffgezogen", "tokens": ["Dan", "da", "kom\u00b7men", "auff\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kalte Fl\u00fcssz", "tokens": ["Kal\u00b7te", "Fl\u00fcssz"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "F\u00fcr die k\u00fcssz", "tokens": ["F\u00fcr", "die", "k\u00fcssz"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Die jhn vnlangst jung betrogen:", "tokens": ["Die", "jhn", "vn\u00b7langst", "jung", "be\u00b7tro\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zittrend werden h\u00e4nd vnd f\u00fc\u00df/", "tokens": ["Zitt\u00b7rend", "wer\u00b7den", "h\u00e4nd", "vnd", "f\u00fc\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "VAFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Das gicht/ zipperlin vnd gr\u00fc\u00df", "tokens": ["Das", "gicht", "/", "zip\u00b7per\u00b7lin", "vnd", "gr\u00fc\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$(", "NE", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Machen jhn krumb vnd gebogen.", "tokens": ["Ma\u00b7chen", "jhn", "krumb", "vnd", "ge\u00b7bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "KON", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Vnd wan schon das Alter ehrlich/", "tokens": ["Vnd", "wan", "schon", "das", "Al\u00b7ter", "ehr\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "ART", "NN", "ADJD", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ist die ehr", "tokens": ["Ist", "die", "ehr"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Jhm doch schwer/", "tokens": ["Jhm", "doch", "schwer", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Weil jhm alles gantz beschwerlich:", "tokens": ["Weil", "jhm", "al\u00b7les", "gantz", "be\u00b7schwer\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine z\u00e4hn nu fallen au\u00df/", "tokens": ["Sei\u00b7ne", "z\u00e4hn", "nu", "fal\u00b7len", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "ADV", "VVFIN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Haupt vnd hertz voll schnee vnd grau\u00df", "tokens": ["Haupt", "vnd", "hertz", "voll", "schnee", "vnd", "grau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ADJD", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Mahlen alle ding gef\u00f6hrlich.", "tokens": ["Mah\u00b7len", "al\u00b7le", "ding", "ge\u00b7f\u00f6hr\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Ach wie langsam Er nu schreittet/", "tokens": ["Ach", "wie", "lang\u00b7sam", "Er", "nu", "schreit\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADJD", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil die bu\u00df", "tokens": ["Weil", "die", "bu\u00df"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Auff dem fu\u00df", "tokens": ["Auff", "dem", "fu\u00df"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Folgend allzeit jhn bestreittet:", "tokens": ["Fol\u00b7gend", "all\u00b7zeit", "jhn", "be\u00b7streit\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle hofnung ist dahin/", "tokens": ["Al\u00b7le", "hof\u00b7nung", "ist", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PAV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ach vnd weh ist sein gewihn/", "tokens": ["Ach", "vnd", "weh", "ist", "sein", "ge\u00b7wihn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KON", "ADJD", "VAFIN", "PPOSAT", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Bi\u00df da\u00df jhn der Tod erbeuttet.", "tokens": ["Bi\u00df", "da\u00df", "jhn", "der", "Tod", "er\u00b7beut\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wa/ wie/ wan er auch mag leben", "tokens": ["Wa", "/", "wie", "/", "wan", "er", "auch", "mag", "le\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "PWAV", "$(", "PWAV", "PPER", "ADV", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jung vnd alt/", "tokens": ["Jung", "vnd", "alt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Warm vnd kalt/", "tokens": ["Warm", "vnd", "kalt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Jhn die kranckheiten vmbgeben:", "tokens": ["Jhn", "die", "kran\u00b7ck\u00b7hei\u00b7ten", "vmb\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Schwachheit/ sorgen/ falsche freind/", "tokens": ["Schwach\u00b7heit", "/", "sor\u00b7gen", "/", "fal\u00b7sche", "freind", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "L\u00fcgen/ neyd/ verleumbdung/ feind/", "tokens": ["L\u00fc\u00b7gen", "/", "neyd", "/", "ver\u00b7leumb\u00b7dung", "/", "feind", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Jhm verdr\u00fc\u00dflich wider-streben.", "tokens": ["Jhm", "ver\u00b7dr\u00fc\u00df\u00b7lich", "wi\u00b7der\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Wie ein vogel durch sein fliegen", "tokens": ["Wie", "ein", "vo\u00b7gel", "durch", "sein", "flie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "PPOSAT", "VVINF"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Wie ein pfeyl", "tokens": ["Wie", "ein", "pfeyl"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "In der eyl", "tokens": ["In", "der", "eyl"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Leichtlich kan das aug betr\u00fcegen:", "tokens": ["Leicht\u00b7lich", "kan", "das", "aug", "be\u00b7tr\u00fce\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So schnell ist des menschen haab/", "tokens": ["So", "schnell", "ist", "des", "men\u00b7schen", "ha\u00b7ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd sein schrit zu seinem graab", "tokens": ["Vnd", "sein", "schrit", "zu", "sei\u00b7nem", "graab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist nicht weit von seiner wiegen.", "tokens": ["Ist", "nicht", "weit", "von", "sei\u00b7ner", "wie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "APPR", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Endlich mu\u00df er sein verm\u00f6gen", "tokens": ["End\u00b7lich", "mu\u00df", "er", "sein", "ver\u00b7m\u00f6\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VAINF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als den raub", "tokens": ["Als", "den", "raub"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "In den staub", "tokens": ["In", "den", "staub"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Mit dem c\u00f6rper niderl\u00f6gen:", "tokens": ["Mit", "dem", "c\u00f6r\u00b7per", "ni\u00b7der\u00b7l\u00f6\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also endet nu das spihl/", "tokens": ["Al\u00b7so", "en\u00b7det", "nu", "das", "spihl", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df weder l\u00fctzel noch vihl", "tokens": ["Da\u00df", "we\u00b7der", "l\u00fct\u00b7zel", "noch", "vihl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KON", "NE", "ADV", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Kan jhn/ kan er nu bew\u00f6gen.", "tokens": ["Kan", "jhn", "/", "kan", "er", "nu", "be\u00b7w\u00f6\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Wan man dan nicht kan verneinen", "tokens": ["Wan", "man", "dan", "nicht", "kan", "ver\u00b7nei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "PTKNEG", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df allhie", "tokens": ["Da\u00df", "all\u00b7hie"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Taussent m\u00fch", "tokens": ["Taus\u00b7sent", "m\u00fch"], "token_info": ["word", "word"], "pos": ["NN", "ADJD"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wider vns sich stehts aufleynen:", "tokens": ["Wi\u00b7der", "vns", "sich", "stehts", "auf\u00b7ley\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Solten wir von hertzen grund", "tokens": ["Sol\u00b7ten", "wir", "von", "hert\u00b7zen", "grund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnser ellend alle stund", "tokens": ["Vn\u00b7ser", "el\u00b7lend", "al\u00b7le", "stund"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Nicht beklagen/ vnd beweinen?", "tokens": ["Nicht", "be\u00b7kla\u00b7gen", "/", "vnd", "be\u00b7wei\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$(", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Kan vns aber nichts klug machen/", "tokens": ["Kan", "vns", "a\u00b7ber", "nichts", "klug", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "ADJD", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sondern wir", "tokens": ["Son\u00b7dern", "wir"], "token_info": ["word", "word"], "pos": ["KON", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Ohn gebihr", "tokens": ["Ohn", "ge\u00b7bihr"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wollen lachen diser sachen:", "tokens": ["Wol\u00b7len", "la\u00b7chen", "di\u00b7ser", "sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach! so lachet reich vnd arm/", "tokens": ["Ach", "!", "so", "la\u00b7chet", "reich", "vnd", "arm", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Lachet/ da\u00df es Got erbarm/", "tokens": ["La\u00b7chet", "/", "da\u00df", "es", "Got", "er\u00b7barm", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOUS", "PPER", "NN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ewers ellends selbs zu lachen!", "tokens": ["E\u00b7wers", "el\u00b7lends", "selbs", "zu", "la\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}