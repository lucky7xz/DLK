{"textgrid.poem.46106": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Johan-Friderich zu Wirtemberg", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sih ich nicht einen got daher kommen,", "tokens": ["Sih", "ich", "nicht", "ei\u00b7nen", "got", "da\u00b7her", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "ART", "NN", "PAV", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "dessen hand", "tokens": ["des\u00b7sen", "hand"], "token_info": ["word", "word"], "pos": ["PRELAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "m\u00e4chtig in ihren schutz hat genommen", "tokens": ["m\u00e4ch\u00b7tig", "in", "ih\u00b7ren", "schutz", "hat", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "dieses land?", "tokens": ["die\u00b7ses", "land", "?"], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ja, es ist der wafen starker got,", "tokens": ["Ja", ",", "es", "ist", "der", "wa\u00b7fen", "star\u00b7ker", "got", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "der machet unsern feind zu spot.", "tokens": ["der", "ma\u00b7chet", "un\u00b7sern", "feind", "zu", "spot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPOSAT", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Aber Mars kan so freindlich nicht sehen;", "tokens": ["A\u00b7ber", "Mars", "kan", "so", "freind\u00b7lich", "nicht", "se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ADV", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "sein geh\u00f6r", "tokens": ["sein", "ge\u00b7h\u00f6r"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "achtet auch nicht der elenden flehen,", "tokens": ["ach\u00b7tet", "auch", "nicht", "der", "e\u00b7len\u00b7den", "fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "ART", "ADJA", "VVINF", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "noch begehr,", "tokens": ["noch", "be\u00b7gehr", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "und sein haupt fasset nicht so vil kunst,", "tokens": ["und", "sein", "haupt", "fas\u00b7set", "nicht", "so", "vil", "kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKNEG", "ADV", "ADV", "PTKVZ", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "noch sein herz so vil gnad und gunst.", "tokens": ["noch", "sein", "herz", "so", "vil", "gnad", "und", "gunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "PIAT", "NN", "KON", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "So kan er wol Hermes genant werden:", "tokens": ["So", "kan", "er", "wol", "Her\u00b7mes", "ge\u00b7nant", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "NE", "VVPP", "VAINF", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "dan es kund,", "tokens": ["dan", "es", "kund", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKVZ", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "da\u00df die zier seiner s\u00fc\u00dfen geberden", "tokens": ["da\u00df", "die", "zier", "sei\u00b7ner", "s\u00fc\u00b7\u00dfen", "ge\u00b7ber\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "--+--+-+--", "measure": "anapaest.di.plus"}, "line.4": {"text": "und sein mund", "tokens": ["und", "sein", "mund"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "reich an gnad, reich an wolredenheit", "tokens": ["reich", "an", "gnad", ",", "reich", "an", "wol\u00b7re\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "APPR", "NN", "$,", "ADJD", "APPR", "NN"], "meter": "--+--+-++", "measure": "anapaest.di.plus"}, "line.6": {"text": "seind voll l\u00f6blicher lieblichkeit.", "tokens": ["seind", "voll", "l\u00f6b\u00b7li\u00b7cher", "lieb\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Aber wie kan Mercurius haben", "tokens": ["A\u00b7ber", "wie", "kan", "Mer\u00b7cu\u00b7rius", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "VMFIN", "NE", "VAFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "so vil macht,", "tokens": ["so", "vil", "macht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "mayestet, herrlichkeit, reiche gaben", "tokens": ["ma\u00b7ye\u00b7stet", ",", "herr\u00b7lich\u00b7keit", ",", "rei\u00b7che", "ga\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "ADJA", "VVFIN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "kraft und pracht?", "tokens": ["kraft", "und", "pracht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "freilich nein, Hermes ist nicht so klar", "tokens": ["frei\u00b7lich", "nein", ",", "Her\u00b7mes", "ist", "nicht", "so", "klar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKANT", "$,", "NE", "VAFIN", "PTKNEG", "ADV", "ADJD"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "und hat auch nicht so sch\u00f6ne haar.", "tokens": ["und", "hat", "auch", "nicht", "so", "sch\u00f6\u00b7ne", "haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "So mu\u00df man ihm des gots namen geben,", "tokens": ["So", "mu\u00df", "man", "ihm", "des", "gots", "na\u00b7men", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "der allein", "tokens": ["der", "al\u00b7lein"], "token_info": ["word", "word"], "pos": ["ART", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "kan fruchtreich alle gesch\u00f6pf beleben", "tokens": ["kan", "fruch\u00b7treich", "al\u00b7le", "ge\u00b7sch\u00f6pf", "be\u00b7le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "PIAT", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "mit dem schein;", "tokens": ["mit", "dem", "schein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "doch ist auch zu manlich sein gesicht,", "tokens": ["doch", "ist", "auch", "zu", "man\u00b7lich", "sein", "ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PTKA", "ADJD", "VAINF", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "darum ist er Apollo nicht.", "tokens": ["da\u00b7rum", "ist", "er", "A\u00b7pol\u00b7lo", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "NE", "PTKNEG", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Nun sih ich, da\u00df sein glanz mich verf\u00fchret,", "tokens": ["Nun", "sih", "ich", ",", "da\u00df", "sein", "glanz", "mich", "ver\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "dan ich merk,", "tokens": ["dan", "ich", "merk", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "da\u00df es mein gro\u00dfer prinz, der regieret", "tokens": ["da\u00df", "es", "mein", "gro\u00b7\u00dfer", "prinz", ",", "der", "re\u00b7gie\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "VVFIN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wirtemberg;", "tokens": ["Wir\u00b7tem\u00b7berg", ";"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.5": {"text": "dessen faust, mund, stirn zeiget uns an,", "tokens": ["des\u00b7sen", "faust", ",", "mund", ",", "stirn", "zei\u00b7get", "uns", "an", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-++--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "was Mars, Hermes und Ph\u00f6bus kan.", "tokens": ["was", "Mars", ",", "Her\u00b7mes", "und", "Ph\u00f6\u00b7bus", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "NE", "KON", "NE", "VMFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}