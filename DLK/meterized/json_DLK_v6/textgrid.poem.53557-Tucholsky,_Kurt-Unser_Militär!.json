{"textgrid.poem.53557": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Unser Milit\u00e4r!", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einstmals, als ich ein kleiner Junge", "tokens": ["Einst\u00b7mals", ",", "als", "ich", "ein", "klei\u00b7ner", "Jun\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und mit dem Ranzen zur Schule ging,", "tokens": ["und", "mit", "dem", "Ran\u00b7zen", "zur", "Schu\u00b7le", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "schrie ich m\u00e4chtig, aus voller Lunge,", "tokens": ["schrie", "ich", "m\u00e4ch\u00b7tig", ",", "aus", "vol\u00b7ler", "Lun\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "h\u00f6rt ich von fern das Tschingderingdsching.", "tokens": ["h\u00f6rt", "ich", "von", "fern", "das", "Tsching\u00b7de\u00b7ringd\u00b7sching", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJD", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Lief wohl mitten \u00fcber den Damm,", "tokens": ["Lief", "wohl", "mit\u00b7ten", "\u00fc\u00b7ber", "den", "Damm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "stand vor dem Herrn Hauptmann stramm,", "tokens": ["stand", "vor", "dem", "Herrn", "Haupt\u00b7mann", "stramm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.7": {"text": "vor den Leutnants, den schlanken und steifen . . .", "tokens": ["vor", "den", "Leut\u00b7nants", ",", "den", "schlan\u00b7ken", "und", "stei\u00b7fen", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "ADJA", "KON", "VVINF", "$.", "$.", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Und wenn dann die Trommeln und die Pfeifen", "tokens": ["Und", "wenn", "dann", "die", "Trom\u00b7meln", "und", "die", "Pfei\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "\u00fcbergingen zum Preu\u00dfenmarsch,", "tokens": ["\u00fc\u00b7ber\u00b7gin\u00b7gen", "zum", "Preu\u00b7\u00dfen\u00b7marsch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "fiel ich vor Freude fast auf den Boden \u2013", "tokens": ["fiel", "ich", "vor", "Freu\u00b7de", "fast", "auf", "den", "Bo\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "ADV", "APPR", "ART", "NN", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "die Augen gl\u00e4nzten \u2013 zum Himmel stieg", "tokens": ["die", "Au\u00b7gen", "gl\u00e4nz\u00b7ten", "\u2013", "zum", "Him\u00b7mel", "stieg"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$(", "APPRART", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Milit\u00e4rmusik! Milit\u00e4rmusik!", "tokens": ["Mi\u00b7li\u00b7t\u00e4r\u00b7mu\u00b7sik", "!", "Mi\u00b7li\u00b7t\u00e4r\u00b7mu\u00b7sik", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Die Jahre gingen. Was damals ein Kind", "tokens": ["Die", "Jah\u00b7re", "gin\u00b7gen", ".", "Was", "da\u00b7mals", "ein", "Kind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PWS", "ADV", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "bejubelt aus kindlichem Herzen,", "tokens": ["be\u00b7ju\u00b7belt", "aus", "kind\u00b7li\u00b7chem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "sah nun ein J\u00fcngling im russischen Wind", "tokens": ["sah", "nun", "ein", "J\u00fcng\u00b7ling", "im", "rus\u00b7si\u00b7schen", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "+--+--++-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "von nahe und unter Schmerzen.", "tokens": ["von", "na\u00b7he", "und", "un\u00b7ter", "Schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Er sah die Roheit und sah den Betrug.", "tokens": ["Er", "sah", "die", "Ro\u00b7heit", "und", "sah", "den", "Be\u00b7trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ducken! ducken! noch nicht genug!", "tokens": ["Du\u00b7cken", "!", "du\u00b7cken", "!", "noch", "nicht", "ge\u00b7nug", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVINF", "$.", "ADV", "PTKNEG", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Tiefer ducken! tiefer b\u00fccken!", "tokens": ["Tie\u00b7fer", "du\u00b7cken", "!", "tie\u00b7fer", "b\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$.", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Treten und sto\u00dfen auf krumme R\u00fccken!", "tokens": ["Tre\u00b7ten", "und", "sto\u00b7\u00dfen", "auf", "krum\u00b7me", "R\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "Die Leutnants fressen und saufen und huren,", "tokens": ["Die", "Leut\u00b7nants", "fres\u00b7sen", "und", "sau\u00b7fen", "und", "hu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "wenn sie nicht grade auf Urlaub fuhren.", "tokens": ["wenn", "sie", "nicht", "gra\u00b7de", "auf", "Ur\u00b7laub", "fuh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "---+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Die Leutnants saufen und huren und fressen", "tokens": ["Die", "Leut\u00b7nants", "sau\u00b7fen", "und", "hu\u00b7ren", "und", "fres\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "KON", "VVINF", "KON", "VVINF"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "das Fleisch und das Weizenbrot wessen? wessen?", "tokens": ["das", "Fleisch", "und", "das", "Wei\u00b7zen\u00b7brot", "wes\u00b7sen", "?", "wes\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVINF", "$.", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Die Leutnants fressen und huren und saufen . . .", "tokens": ["Die", "Leut\u00b7nants", "fres\u00b7sen", "und", "hu\u00b7ren", "und", "sau\u00b7fen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "VVINF", "KON", "VVFIN", "$.", "$.", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Der Mann kann sich kaum das N\u00f6tigste kaufen.", "tokens": ["Der", "Mann", "kann", "sich", "kaum", "das", "N\u00f6\u00b7tigs\u00b7te", "kau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Und hungert. Und st\u00fcrmt. Und schwitzt. Und marschiert.", "tokens": ["Und", "hun\u00b7gert", ".", "Und", "st\u00fcrmt", ".", "Und", "schwitzt", ".", "Und", "mar\u00b7schiert", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "KON", "VVFIN", "$.", "KON", "VVFIN", "$.", "KON", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Bis er krepiert.", "tokens": ["Bis", "er", "kre\u00b7piert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.17": {"text": "Und das sah einer mit brennenden Augen", "tokens": ["Und", "das", "sah", "ei\u00b7ner", "mit", "bren\u00b7nen\u00b7den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "ART", "APPR", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "und glaubte, der Krempel k\u00f6nne nichts taugen.", "tokens": ["und", "glaub\u00b7te", ",", "der", "Krem\u00b7pel", "k\u00f6n\u00b7ne", "nichts", "tau\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "NN", "VMFIN", "PIS", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Und glaubte, das m\u00fcsse zusammenfallen", "tokens": ["Und", "glaub\u00b7te", ",", "das", "m\u00fcs\u00b7se", "zu\u00b7sam\u00b7men\u00b7fal\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PDS", "VMFIN", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "zum Heile von Deutschland, zum Heil von uns allen . . .", "tokens": ["zum", "Hei\u00b7le", "von", "Deutschland", ",", "zum", "Heil", "von", "uns", "al\u00b7len", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "$,", "APPRART", "NN", "APPR", "PPER", "PIAT", "$.", "$.", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Aber noch \u00fcbert\u00f6nte den Jammer im Krieg", "tokens": ["A\u00b7ber", "noch", "\u00fc\u00b7ber\u00b7t\u00f6n\u00b7te", "den", "Jam\u00b7mer", "im", "Krieg"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.22": {"text": "Milit\u00e4rmusik! Milit\u00e4rmusik!", "tokens": ["Mi\u00b7li\u00b7t\u00e4r\u00b7mu\u00b7sik", "!", "Mi\u00b7li\u00b7t\u00e4r\u00b7mu\u00b7sik", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Und heute?", "tokens": ["Und", "heu\u00b7te", "?"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ach heute! Die Herren oben", "tokens": ["Ach", "heu\u00b7te", "!", "Die", "Her\u00b7ren", "o\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "ADV", "$.", "ART", "NN", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "tun ihren Pater Noske loben", "tokens": ["tun", "ih\u00b7ren", "Pa\u00b7ter", "Nos\u00b7ke", "lo\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NE", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und brauchen als St\u00fctze f\u00fcr ihr Prinzip", "tokens": ["und", "brau\u00b7chen", "als", "St\u00fct\u00b7ze", "f\u00fcr", "ihr", "Prin\u00b7zip"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOUS", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "den alten, trostlosen Leutnantstyp.", "tokens": ["den", "al\u00b7ten", ",", "trost\u00b7lo\u00b7sen", "Leut\u00b7nant\u00b7styp", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das verhaftet, regiert und vertobakt Leute,", "tokens": ["Das", "ver\u00b7haf\u00b7tet", ",", "re\u00b7giert", "und", "ver\u00b7to\u00b7bakt", "Leu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "NN", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.7": {"text": "damals wie heute, damals wie heute \u2013", "tokens": ["da\u00b7mals", "wie", "heu\u00b7te", ",", "da\u00b7mals", "wie", "heu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "$,", "ADV", "KOKOM", "ADV", "$("], "meter": "+--+-+-++-", "measure": "iambic.penta.invert"}, "line.8": {"text": "und f\u00e4llt einer wirklich mal herein,", "tokens": ["und", "f\u00e4llt", "ei\u00b7ner", "wirk\u00b7lich", "mal", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJD", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "setzt sich ein andrer f\u00fcr ihn ein.", "tokens": ["setzt", "sich", "ein", "an\u00b7drer", "f\u00fcr", "ihn", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Liebknecht ist tot. Vogel heidi.", "tokens": ["Lieb\u00b7knecht", "ist", "tot", ".", "Vo\u00b7gel", "hei\u00b7di", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$.", "NE", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Solche M\u00f6rder straft Deutschland nie.", "tokens": ["Sol\u00b7che", "M\u00f6r\u00b7der", "straft", "Deutschland", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NE", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Na und \u2013?", "tokens": ["Na", "und", "\u2013", "?"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NE", "KON", "$(", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.13": {"text": "Der Ha\u00df, der da unten sich sammelt,", "tokens": ["Der", "Ha\u00df", ",", "der", "da", "un\u00b7ten", "sich", "sam\u00b7melt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "hat euch den Weg noch nicht verrammelt.", "tokens": ["hat", "euch", "den", "Weg", "noch", "nicht", "ver\u00b7ram\u00b7melt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.15": {"text": "Aber das kann noch einmal kommen . . . !", "tokens": ["A\u00b7ber", "das", "kann", "noch", "ein\u00b7mal", "kom\u00b7men", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["KON", "PDS", "VMFIN", "ADV", "ADV", "VVINF", "$.", "$.", "$.", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Nicht alle Feuer, die tiefrot glommen", "tokens": ["Nicht", "al\u00b7le", "Feu\u00b7er", ",", "die", "tief\u00b7rot", "glom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "PIAT", "NN", "$,", "PRELS", "ADJD", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "unter der Asche, gehen aus.", "tokens": ["un\u00b7ter", "der", "A\u00b7sche", ",", "ge\u00b7hen", "aus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Achtung! Es ist Z\u00fcndstoff im Haus!", "tokens": ["Ach\u00b7tung", "!", "Es", "ist", "Z\u00fcnd\u00b7stoff", "im", "Haus", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Wir wollen nicht diese Nationalisten,", "tokens": ["Wir", "wol\u00b7len", "nicht", "die\u00b7se", "Na\u00b7ti\u00b7o\u00b7na\u00b7lis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PDAT", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "diese Ordnungsbolschewisten,", "tokens": ["die\u00b7se", "Ord\u00b7nungs\u00b7bol\u00b7sche\u00b7wis\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "all das Gesindel, das uns geknutet,", "tokens": ["all", "das", "Ge\u00b7sin\u00b7del", ",", "das", "uns", "ge\u00b7knu\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.22": {"text": "unter dem Rosa Luxemburg verblutet.", "tokens": ["un\u00b7ter", "dem", "Ro\u00b7sa", "Lu\u00b7xem\u00b7burg", "ver\u00b7blu\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.23": {"text": "Nennt ihr es auch Freiwilligenverb\u00e4nde:", "tokens": ["Nennt", "ihr", "es", "auch", "Frei\u00b7wil\u00b7li\u00b7gen\u00b7ver\u00b7b\u00e4n\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "NN", "$."], "meter": "-+-+++-+-+-", "measure": "unknown.measure.hexa"}, "line.24": {"text": "es sind die alten, schmutzigen H\u00e4nde.", "tokens": ["es", "sind", "die", "al\u00b7ten", ",", "schmut\u00b7zi\u00b7gen", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Wir kennen die Firma, wir kennen den Geist,", "tokens": ["Wir", "ken\u00b7nen", "die", "Fir\u00b7ma", ",", "wir", "ken\u00b7nen", "den", "Geist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.26": {"text": "wir wissen, was ein Korpsbefehl hei\u00dft . . .", "tokens": ["wir", "wis\u00b7sen", ",", "was", "ein", "Korps\u00b7be\u00b7fehl", "hei\u00dft", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVINF", "$,", "PRELS", "ART", "NN", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.27": {"text": "Fort damit \u2013!", "tokens": ["Fort", "da\u00b7mit", "\u2013", "!"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NN", "PAV", "$(", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.28": {"text": "Rei\u00dft ihre Achselst\u00fccke", "tokens": ["Rei\u00dft", "ih\u00b7re", "Ach\u00b7sel\u00b7st\u00fc\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.29": {"text": "in Fetzen \u2013 die Kultur kriegt keine L\u00fccke,", "tokens": ["in", "Fet\u00b7zen", "\u2013", "die", "Kul\u00b7tur", "kriegt", "kei\u00b7ne", "L\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "ART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "wenn einmal im Lande der verschwindet,", "tokens": ["wenn", "ein\u00b7mal", "im", "Lan\u00b7de", "der", "ver\u00b7schwin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPRART", "NN", "ART", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "dessen Druck kein Freier verwindet.", "tokens": ["des\u00b7sen", "Druck", "kein", "Frei\u00b7er", "ver\u00b7win\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELAT", "NN", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.32": {"text": "Es gibt zwei Deutschland \u2013: eins ist frei,", "tokens": ["Es", "gibt", "zwei", "Deutschland", "\u2013", ":", "eins", "ist", "frei", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "$(", "$.", "PIS", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.33": {"text": "das andre knechtisch, wer es auch sei.", "tokens": ["das", "and\u00b7re", "knech\u00b7tisch", ",", "wer", "es", "auch", "sei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWS", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.34": {"text": "La\u00df endlich schweigen, o Republik,", "tokens": ["La\u00df", "end\u00b7lich", "schwei\u00b7gen", ",", "o", "Re\u00b7pub\u00b7lik", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "VVINF", "$,", "FM", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "Milit\u00e4rmusik! Milit\u00e4rmusik\u2013!", "tokens": ["Mi\u00b7li\u00b7t\u00e4r\u00b7mu\u00b7sik", "!", "Mi\u00b7li\u00b7t\u00e4r\u00b7mu\u00b7sik", "\u2013", "!"], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["NN", "$.", "NN", "$(", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}