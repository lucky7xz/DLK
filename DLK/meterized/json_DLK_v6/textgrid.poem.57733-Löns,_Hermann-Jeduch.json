{"textgrid.poem.57733": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Jeduch", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich stehe hier am Jammerstein", "tokens": ["Ich", "ste\u00b7he", "hier", "am", "Jam\u00b7mer\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schreie meinen Fluch;", "tokens": ["Und", "schrei\u00b7e", "mei\u00b7nen", "Fluch", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr M\u00e4nner von Meckeloh, h\u00f6rt mein Schrein,", "tokens": ["Ihr", "M\u00e4n\u00b7ner", "von", "Me\u00b7cke\u00b7loh", ",", "h\u00f6rt", "mein", "Schrein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Jeduch, jeduch, jeduch!", "tokens": ["Je\u00b7duch", ",", "je\u00b7duch", ",", "je\u00b7duch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "H\u00f6rt mein Schrein und h\u00f6rt meine Not,", "tokens": ["H\u00f6rt", "mein", "Schrein", "und", "h\u00f6rt", "mei\u00b7ne", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ich stehe am Jammerstein;", "tokens": ["Ich", "ste\u00b7he", "am", "Jam\u00b7mer\u00b7stein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mein Hennecke, euer Haupt ist tot,", "tokens": ["Mein", "Hen\u00b7ne\u00b7cke", ",", "eu\u00b7er", "Haupt", "ist", "tot", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und Jeduch mu\u00df ich ihm schrein.", "tokens": ["Und", "Je\u00b7duch", "mu\u00df", "ich", "ihm", "schrein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Jeduch auf die Leute aus L\u00fcttgeloh,", "tokens": ["Je\u00b7duch", "auf", "die", "Leu\u00b7te", "aus", "L\u00fctt\u00b7ge\u00b7loh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die ihn schlugen mit heimlicher Hand;", "tokens": ["Die", "ihn", "schlu\u00b7gen", "mit", "heim\u00b7li\u00b7cher", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ich rufe Jeduch durch den ganzen Go,", "tokens": ["Ich", "ru\u00b7fe", "Je\u00b7duch", "durch", "den", "gan\u00b7zen", "Go", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u00dcber Feld, \u00fcber Moor, \u00fcber Sand.", "tokens": ["\u00dc\u00b7ber", "Feld", ",", "\u00fc\u00b7ber", "Moor", ",", "\u00fc\u00b7ber", "Sand", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.4": {"line.1": {"text": "Wo die Beeke kommt aus dem gro\u00dfen Moor,", "tokens": ["Wo", "die", "Bee\u00b7ke", "kommt", "aus", "dem", "gro\u00b7\u00dfen", "Moor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da fand ich ihn liegen im Sand;", "tokens": ["Da", "fand", "ich", "ihn", "lie\u00b7gen", "im", "Sand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Aus seinem Haar krochen Maden hervor,", "tokens": ["Aus", "sei\u00b7nem", "Haar", "kro\u00b7chen", "Ma\u00b7den", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In den Augen das Blut ihm stand.", "tokens": ["In", "den", "Au\u00b7gen", "das", "Blut", "ihm", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Seinen Br\u00e4gen hatte der Fuchs verbracht,", "tokens": ["Sei\u00b7nen", "Br\u00e4\u00b7gen", "hat\u00b7te", "der", "Fuchs", "ver\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NE", "VVPP", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Seinen Nacken der Wolf zernagt;", "tokens": ["Sei\u00b7nen", "Na\u00b7cken", "der", "Wolf", "zer\u00b7nagt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NE", "VVPP", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Mit dem Haar hab' ich ihm sein Gesicht rein gemacht,", "tokens": ["Mit", "dem", "Haar", "hab'", "ich", "ihm", "sein", "Ge\u00b7sicht", "rein", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PPER", "PPOSAT", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.4": {"text": "Mit der Hand ihm die Fliegen verjagt.", "tokens": ["Mit", "der", "Hand", "ihm", "die", "Flie\u00b7gen", "ver\u00b7jagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.6": {"line.1": {"text": "Sein Arm war hart, seine Hand war rauh,", "tokens": ["Sein", "Arm", "war", "hart", ",", "sei\u00b7ne", "Hand", "war", "rauh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sein Herz und sein Mund waren weich;", "tokens": ["Sein", "Herz", "und", "sein", "Mund", "wa\u00b7ren", "weich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Seine Augen, die waren wie Bachblumen blau,", "tokens": ["Sei\u00b7ne", "Au\u00b7gen", ",", "die", "wa\u00b7ren", "wie", "Bach\u00b7blu\u00b7men", "blau", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VAFIN", "KOKOM", "NN", "ADJD", "$,"], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Keiner von euch ist ihm gleich.", "tokens": ["Kei\u00b7ner", "von", "euch", "ist", "ihm", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PPER", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wo er hinschlug, kam das Gras nicht zur\u00fcck,", "tokens": ["Wo", "er", "hin\u00b7schlug", ",", "kam", "das", "Gras", "nicht", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Wo er k\u00fc\u00dfte, k\u00fc\u00dfte er Glut;", "tokens": ["Wo", "er", "k\u00fc\u00df\u00b7te", ",", "k\u00fc\u00df\u00b7te", "er", "Glut", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Des Dorfes Stolz, meiner Augen Gl\u00fcck,", "tokens": ["Des", "Dor\u00b7fes", "Stolz", ",", "mei\u00b7ner", "Au\u00b7gen", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da liegt er in seinem Blut!", "tokens": ["Da", "liegt", "er", "in", "sei\u00b7nem", "Blut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Bei Nacht und Nebel, vor Tau und Tag", "tokens": ["Bei", "Nacht", "und", "Ne\u00b7bel", ",", "vor", "Tau", "und", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Erschlug ihn das Hundegez\u00fccht;", "tokens": ["Er\u00b7schlug", "ihn", "das", "Hun\u00b7de\u00b7ge\u00b7z\u00fccht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Von hinten traf ihn des M\u00f6rders Schlag,", "tokens": ["Von", "hin\u00b7ten", "traf", "ihn", "des", "M\u00f6r\u00b7ders", "Schlag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er lag auf seinem Gesicht.", "tokens": ["Er", "lag", "auf", "sei\u00b7nem", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Keine Nacht noch war er in Wonnen bei mir,", "tokens": ["Kei\u00b7ne", "Nacht", "noch", "war", "er", "in", "Won\u00b7nen", "bei", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VAFIN", "PPER", "APPR", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Kein Kind von ihm tr\u00e4gt mein Leib;", "tokens": ["Kein", "Kind", "von", "ihm", "tr\u00e4gt", "mein", "Leib", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eine Jungfernwitwe, so stehe ich hier,", "tokens": ["Ei\u00b7ne", "Jung\u00b7fern\u00b7wit\u00b7we", ",", "so", "ste\u00b7he", "ich", "hier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ein ungl\u00fcckseliges Weib.", "tokens": ["Ein", "un\u00b7gl\u00fcck\u00b7se\u00b7li\u00b7ges", "Weib", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Wenn der Kuckucksruf aus dem Maibaum schallt,", "tokens": ["Wenn", "der", "Ku\u00b7ckucks\u00b7ruf", "aus", "dem", "Mai\u00b7baum", "schallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dann sollte sein Weib ich sein;", "tokens": ["Dann", "soll\u00b7te", "sein", "Weib", "ich", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "PPER", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Jetzt liegt auf der Deele er steif und kalt,", "tokens": ["Jetzt", "liegt", "auf", "der", "Dee\u00b7le", "er", "steif", "und", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und ich bin gelt und allein.", "tokens": ["Und", "ich", "bin", "gelt", "und", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "KON", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich schnitt mir vom Kopfe mein sch\u00f6nes Haar,", "tokens": ["Ich", "schnitt", "mir", "vom", "Kop\u00b7fe", "mein", "sch\u00f6\u00b7nes", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Zerkratzte mir Brust und Gesicht;", "tokens": ["Zer\u00b7kratz\u00b7te", "mir", "Brust", "und", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Aller Zier und Pracht will ich werden bar,", "tokens": ["Al\u00b7ler", "Zier", "und", "Pracht", "will", "ich", "wer\u00b7den", "bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "VMFIN", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Einem andern g\u00f6nn' ich das nicht.", "tokens": ["Ei\u00b7nem", "an\u00b7dern", "g\u00f6nn'", "ich", "das", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PDS", "PTKNEG", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.12": {"line.1": {"text": "Will in Lumpen gehn, will in Lappen sein,", "tokens": ["Will", "in", "Lum\u00b7pen", "gehn", ",", "will", "in", "Lap\u00b7pen", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$,", "VMFIN", "APPR", "NN", "VAINF", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Um den Kopf das Witwentuch;", "tokens": ["Um", "den", "Kopf", "das", "Wit\u00b7wen\u00b7tuch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und immer blo\u00df schrein und schrein und schrein:", "tokens": ["Und", "im\u00b7mer", "blo\u00df", "schrein", "und", "schrein", "und", "schrein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Jeduch, jeduch, jeduch!", "tokens": ["Je\u00b7duch", ",", "je\u00b7duch", ",", "je\u00b7duch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Bis L\u00fcttgeloh brennt, bis L\u00fcttgeloh qualmt,", "tokens": ["Bis", "L\u00fctt\u00b7ge\u00b7loh", "brennt", ",", "bis", "L\u00fctt\u00b7ge\u00b7loh", "qualmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+--+---", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bis zum Himmel soll blaken die Glut;", "tokens": ["Bis", "zum", "Him\u00b7mel", "soll", "bla\u00b7ken", "die", "Glut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "VMFIN", "VVINF", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Bis der Hammer der M\u00f6rder Knochen zermalmt,", "tokens": ["Bis", "der", "Ham\u00b7mer", "der", "M\u00f6r\u00b7der", "Kno\u00b7chen", "zer\u00b7malmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "In den Mist soll flie\u00dfen ihr Blut.", "tokens": ["In", "den", "Mist", "soll", "flie\u00b7\u00dfen", "ihr", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "VVINF", "PPOSAT", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.14": {"line.1": {"text": "Aus L\u00fcttgelohs Balken baut mir dann", "tokens": ["Aus", "L\u00fctt\u00b7ge\u00b7lohs", "Bal\u00b7ken", "baut", "mir", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die letzte Lagerstatt;", "tokens": ["Die", "letz\u00b7te", "La\u00b7ger\u00b7statt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und der M\u00f6rder Blut soll kleben daran,", "tokens": ["Und", "der", "M\u00f6r\u00b7der", "Blut", "soll", "kle\u00b7ben", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VMFIN", "VVINF", "PAV", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das macht meine Augen satt.", "tokens": ["Das", "macht", "mei\u00b7ne", "Au\u00b7gen", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Dann will ich legen mein Bestkleid an,", "tokens": ["Dann", "will", "ich", "le\u00b7gen", "mein", "Be\u00b7stkleid", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Will tragen das gro\u00dfe Geschmeid;", "tokens": ["Will", "tra\u00b7gen", "das", "gro\u00b7\u00dfe", "Ge\u00b7schmeid", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Zu Hennecke geh' ich, zu meinem Mann,", "tokens": ["Zu", "Hen\u00b7ne\u00b7cke", "geh'", "ich", ",", "zu", "mei\u00b7nem", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Unser Bett, das ist bereit.", "tokens": ["Un\u00b7ser", "Bett", ",", "das", "ist", "be\u00b7reit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PDS", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Wenn in L\u00fcttgeloh die Kinder schrein,", "tokens": ["Wenn", "in", "L\u00fctt\u00b7ge\u00b7loh", "die", "Kin\u00b7der", "schrein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wenn das Vieh verkohlt im Stall,", "tokens": ["Wenn", "das", "Vieh", "ver\u00b7kohlt", "im", "Stall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann will meines Hennecke Weib ich sein,", "tokens": ["Dann", "will", "mei\u00b7nes", "Hen\u00b7ne\u00b7cke", "Weib", "ich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "NN", "PPER", "VAINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Will fahren mit ihm zu Walhall.", "tokens": ["Will", "fah\u00b7ren", "mit", "ihm", "zu", "Wal\u00b7hall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Ich stehe hier am Jammerstein", "tokens": ["Ich", "ste\u00b7he", "hier", "am", "Jam\u00b7mer\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schreie meinen Fluch;", "tokens": ["Und", "schrei\u00b7e", "mei\u00b7nen", "Fluch", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr M\u00e4nner von Meckeloh, h\u00f6rt mein Schrein,", "tokens": ["Ihr", "M\u00e4n\u00b7ner", "von", "Me\u00b7cke\u00b7loh", ",", "h\u00f6rt", "mein", "Schrein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Jeduch, jeduch, jeduch!", "tokens": ["Je\u00b7duch", ",", "je\u00b7duch", ",", "je\u00b7duch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}