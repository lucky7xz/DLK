{"textgrid.poem.66077": {"metadata": {"author": {"name": "Falke, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "Konsequenz", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In meinem G\u00e4rtchen, zwei Fu\u00df vom Weg,", "tokens": ["In", "mei\u00b7nem", "G\u00e4rt\u00b7chen", ",", "zwei", "Fu\u00df", "vom", "Weg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "CARD", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hinter dem niedern Gittergeheg,", "tokens": ["Hin\u00b7ter", "dem", "nie\u00b7dern", "Git\u00b7ter\u00b7ge\u00b7heg", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Bl\u00fcht mir ein blauer Syringenstrauch,", "tokens": ["Bl\u00fcht", "mir", "ein", "blau\u00b7er", "Sy\u00b7rin\u00b7gen\u00b7strauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Meine Freude, und meiner Kinder auch.", "tokens": ["Mei\u00b7ne", "Freu\u00b7de", ",", "und", "mei\u00b7ner", "Kin\u00b7der", "auch", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Aber die Buben von den Gassen,", "tokens": ["A\u00b7ber", "die", "Bu\u00b7ben", "von", "den", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Die Racker, k\u00f6nnen das R\u00e4ubern nicht lassen.", "tokens": ["Die", "Ra\u00b7cker", ",", "k\u00f6n\u00b7nen", "das", "R\u00e4u\u00b7bern", "nicht", "las\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Wenn sie fr\u00fch in die Schule gehn,", "tokens": ["Wenn", "sie", "fr\u00fch", "in", "die", "Schu\u00b7le", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ein Kleinster bleibt begehrlich stehn,", "tokens": ["Ein", "Kleins\u00b7ter", "bleibt", "be\u00b7gehr\u00b7lich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein zweiter stellt sich daneben auf", "tokens": ["Ein", "zwei\u00b7ter", "stellt", "sich", "da\u00b7ne\u00b7ben", "auf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "PAV", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und schielt mit ihm zum B\u00e4umchen hinauf,", "tokens": ["Und", "schielt", "mit", "ihm", "zum", "B\u00e4um\u00b7chen", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "M\u00f6chten gerne von den Syringen", "tokens": ["M\u00f6ch\u00b7ten", "ger\u00b7ne", "von", "den", "Sy\u00b7rin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Ein Zweiglein mit in die Klasse bringen.", "tokens": ["Ein", "Zwei\u00b7glein", "mit", "in", "die", "Klas\u00b7se", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Kommt ein dritter, hops, wie er hupft,", "tokens": ["Kommt", "ein", "drit\u00b7ter", ",", "hops", ",", "wie", "er", "hupft", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "$,", "NE", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Hat sich ein paar Bl\u00e4tter gerupft,", "tokens": ["Hat", "sich", "ein", "paar", "Bl\u00e4t\u00b7ter", "ge\u00b7rupft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Aber der Gr\u00fcnkram gen\u00fcgt ihm nicht,", "tokens": ["A\u00b7ber", "der", "Gr\u00fcn\u00b7kram", "ge\u00b7n\u00fcgt", "ihm", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Er ist mal auf Syringen erpicht.", "tokens": ["Er", "ist", "mal", "auf", "Sy\u00b7rin\u00b7gen", "er\u00b7picht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Noch einmal, hops! \u2013 Euch will ich kriegen.", "tokens": ["Noch", "ein\u00b7mal", ",", "hops", "!", "\u2013", "Euch", "will", "ich", "krie\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ITJ", "$.", "$(", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich klopf ans Fenster. Hei, wie sie fliegen.", "tokens": ["Ich", "klopf", "ans", "Fens\u00b7ter", ".", "Hei", ",", "wie", "sie", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$.", "NN", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "So ein Bubenvolk ist schlimm,", "tokens": ["So", "ein", "Bu\u00b7ben\u00b7volk", "ist", "schlimm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Gef\u00e4llt ihm was, gleich denkt es: nimm!", "tokens": ["Ge\u00b7f\u00e4llt", "ihm", "was", ",", "gleich", "denkt", "es", ":", "nimm", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "$,", "ADV", "VVFIN", "PPER", "$.", "VVIMP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aber da\u00df auch die M\u00e4del \u2013 ich bitt,", "tokens": ["A\u00b7ber", "da\u00df", "auch", "die", "M\u00e4\u00b7del", "\u2013", "ich", "bitt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "NN", "$(", "PPER", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Kommen da welche gleich zu dritt,", "tokens": ["Kom\u00b7men", "da", "wel\u00b7che", "gleich", "zu", "dritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PRELS", "ADV", "PTKA", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Recken die H\u00e4lschen, drehen die K\u00f6pfchen", "tokens": ["Re\u00b7cken", "die", "H\u00e4l\u00b7schen", ",", "dre\u00b7hen", "die", "K\u00f6pf\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "\u00c4ngstlich und schlenkern mit den Z\u00f6pfchen.", "tokens": ["\u00c4ngst\u00b7lich", "und", "schlen\u00b7kern", "mit", "den", "Z\u00f6pf\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "Hebt sich die l\u00e4ngste auf den Zehn,", "tokens": ["Hebt", "sich", "die", "l\u00e4ngs\u00b7te", "auf", "den", "Zehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "APPR", "ART", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Einmal, zweimal, es will nicht gehn.", "tokens": ["Ein\u00b7mal", ",", "zwei\u00b7mal", ",", "es", "will", "nicht", "gehn", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Gehuschel, Getuschel. M\u00e4del sind klug;", "tokens": ["Ge\u00b7hu\u00b7schel", ",", "Ge\u00b7tu\u00b7schel", ".", "M\u00e4\u00b7del", "sind", "klug", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$.", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hat sie, bevor ich ans Fenster schlug,", "tokens": ["Hat", "sie", ",", "be\u00b7vor", "ich", "ans", "Fens\u00b7ter", "schlug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Das kleinste schnell auf den Arm genommen", "tokens": ["Das", "kleins\u00b7te", "schnell", "auf", "den", "Arm", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJD", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und die allersch\u00f6nsten Syringen bekommen.", "tokens": ["Und", "die", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "Sy\u00b7rin\u00b7gen", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Ich drohe ihr, sie lacht mich an,", "tokens": ["Ich", "dro\u00b7he", "ihr", ",", "sie", "lacht", "mich", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie nur ein M\u00e4del lachen kann,", "tokens": ["Wie", "nur", "ein", "M\u00e4\u00b7del", "la\u00b7chen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Spitzb\u00fcbisch, schelmisch und doch ganz lieb.", "tokens": ["Spitz\u00b7b\u00fc\u00b7bisch", ",", "schel\u00b7misch", "und", "doch", "ganz", "lieb", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es ist ein allerliebster Dieb,", "tokens": ["Es", "ist", "ein", "al\u00b7ler\u00b7liebs\u00b7ter", "Dieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da \u2013 ich will recht finster blicken", "tokens": ["Und", "da", "\u2013", "ich", "will", "recht", "fins\u00b7ter", "bli\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "$(", "PPER", "VMFIN", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und kann nur lachen und freundlich nicken.", "tokens": ["Und", "kann", "nur", "la\u00b7chen", "und", "freund\u00b7lich", "ni\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVINF", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "In Zukunft sind die Syringen frei,", "tokens": ["In", "Zu\u00b7kunft", "sind", "die", "Sy\u00b7rin\u00b7gen", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ob M\u00e4del, ob Buben, ist einerlei.", "tokens": ["Ob", "M\u00e4\u00b7del", ",", "ob", "Bu\u00b7ben", ",", "ist", "ei\u00b7ner\u00b7lei", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN", "$,", "VAFIN", "ADV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Was ihr im Sprung erhaschen k\u00f6nnt,", "tokens": ["Was", "ihr", "im", "Sprung", "er\u00b7ha\u00b7schen", "k\u00f6nnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Diebsgelichter, sei euch geg\u00f6nnt.", "tokens": ["Ihr", "Diebs\u00b7ge\u00b7lich\u00b7ter", ",", "sei", "euch", "ge\u00b7g\u00f6nnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Nur braucht ihr das selber nicht grade zu wissen,", "tokens": ["Nur", "braucht", "ihr", "das", "sel\u00b7ber", "nicht", "gra\u00b7de", "zu", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.6": {"text": "Mein B\u00e4umchen w\u00fcrde mir arg zerrissen.", "tokens": ["Mein", "B\u00e4um\u00b7chen", "w\u00fcr\u00b7de", "mir", "arg", "zer\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}