{"textgrid.poem.42814": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ob ich Biblio- was bin?", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ob ich Biblio- was bin?", "tokens": ["Ob", "ich", "Bi\u00b7blio", "was", "bin", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "TRUNC", "PWS", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Phile? \u00bbFreund von B\u00fcchern\u00ab meinen Sie?", "tokens": ["Phi\u00b7le", "?", "\u00bb", "Freund", "von", "B\u00fc\u00b7chern", "\u00ab", "mei\u00b7nen", "Sie", "?"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "APPR", "NN", "$(", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Na, und ob ich das bin!", "tokens": ["Na", ",", "und", "ob", "ich", "das", "bin", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KON", "KOUS", "PPER", "PDS", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ha! und wie!", "tokens": ["Ha", "!", "und", "wie", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$.", "KON", "PWAV", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Mir sind B\u00fccher, was den andern Leuten", "tokens": ["Mir", "sind", "B\u00fc\u00b7cher", ",", "was", "den", "an\u00b7dern", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Weiber, Tanz, Gesellschaft, Kartenspiel,", "tokens": ["Wei\u00b7ber", ",", "Tanz", ",", "Ge\u00b7sell\u00b7schaft", ",", "Kar\u00b7ten\u00b7spiel", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Turnsport, Wein, und wei\u00df ich was, bedeuten.", "tokens": ["Turns\u00b7port", ",", "Wein", ",", "und", "wei\u00df", "ich", "was", ",", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KON", "VVFIN", "PPER", "PIS", "$,", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Meine B\u00fccher \u2013 \u2013 \u2013 wie beliebt? Wieviel?", "tokens": ["Mei\u00b7ne", "B\u00fc\u00b7cher", "\u2013", "\u2013", "\u2013", "wie", "be\u00b7liebt", "?", "Wie\u00b7viel", "?"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "$(", "$(", "PWAV", "ADJD", "$.", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Was, zum Henker, k\u00fcmmert mich die Zahl.", "tokens": ["Was", ",", "zum", "Hen\u00b7ker", ",", "k\u00fcm\u00b7mert", "mich", "die", "Zahl", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "APPRART", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Bitte, doch mich auszureden lassen.", "tokens": ["Bit\u00b7te", ",", "doch", "mich", "aus\u00b7zu\u00b7re\u00b7den", "las\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "PPER", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Jedenfalls: viel mehr, als mein Regal", "tokens": ["Je\u00b7den\u00b7falls", ":", "viel", "mehr", ",", "als", "mein", "Re\u00b7gal"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Halb imstande ist zu fassen.", "tokens": ["Halb", "ims\u00b7tan\u00b7de", "ist", "zu", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Unterhaltung? Ja, bei Gott, das geben", "tokens": ["Un\u00b7ter\u00b7hal\u00b7tung", "?", "Ja", ",", "bei", "Gott", ",", "das", "ge\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$.", "PTKANT", "$,", "APPR", "NN", "$,", "PDS", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Sie mir reichlich. Morgens zw\u00f6lfmal nur", "tokens": ["Sie", "mir", "reich\u00b7lich", ".", "Mor\u00b7gens", "zw\u00f6lf\u00b7mal", "nur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "PPER", "ADJD", "$.", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "N\u00fcchtern zwanzig Brockhausb\u00e4nde heben \u2013 \u2013 \u2013", "tokens": ["N\u00fcch\u00b7tern", "zwan\u00b7zig", "Brock\u00b7haus\u00b7b\u00e4n\u00b7de", "he\u00b7ben", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "CARD", "NN", "VVINF", "$(", "$(", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Hei! das gibt den Muskeln die Latur.", "tokens": ["Hei", "!", "das", "gibt", "den", "Mus\u00b7keln", "die", "La\u00b7tur", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PDS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Oh, ich mu\u00dfte meine B\u00fccherei,", "tokens": ["Oh", ",", "ich", "mu\u00df\u00b7te", "mei\u00b7ne", "B\u00fc\u00b7che\u00b7rei", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wenn ich je verreiste, stets vermissen.", "tokens": ["Wenn", "ich", "je", "ver\u00b7reis\u00b7te", ",", "stets", "ver\u00b7mis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ob ein Stuhl zu hoch, zu niedrig sei,", "tokens": ["Ob", "ein", "Stuhl", "zu", "hoch", ",", "zu", "nied\u00b7rig", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sechzig B\u00fccher sind wie sechzig Kissen.", "tokens": ["Sech\u00b7zig", "B\u00fc\u00b7cher", "sind", "wie", "sech\u00b7zig", "Kis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "KOKOM", "CARD", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Ja nat\u00fcrlich auch vom k\u00fcnstlerischen", "tokens": ["Ja", "na\u00b7t\u00fcr\u00b7lich", "auch", "vom", "k\u00fcnst\u00b7le\u00b7ri\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ADV", "APPRART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Standpunkt. Denn ich wei\u00df die R\u00fccken", "tokens": ["Stand\u00b7punkt", ".", "Denn", "ich", "wei\u00df", "die", "R\u00fc\u00b7cken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "KON", "PPER", "VVFIN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So nach Gold und Lederton zu mischen,", "tokens": ["So", "nach", "Gold", "und", "Le\u00b7der\u00b7ton", "zu", "mi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Da\u00df sie wie ein Bild die Stube schm\u00fccken.", "tokens": ["Da\u00df", "sie", "wie", "ein", "Bild", "die", "Stu\u00b7be", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "\u00c4u\u00dferlich? Mein Bester, Sie vergessen", "tokens": ["\u00c4u\u00b7\u00dfer\u00b7lich", "?", "Mein", "Bes\u00b7ter", ",", "Sie", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "$.", "PPOSAT", "NN", "$,", "PPER", "VVPP"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Meine ungeheure Leidenschaft,", "tokens": ["Mei\u00b7ne", "un\u00b7ge\u00b7heu\u00b7re", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Pflanzen f\u00fcrs Herbarium zu pressen.", "tokens": ["Pflan\u00b7zen", "f\u00fcrs", "Her\u00b7ba\u00b7ri\u00b7um", "zu", "pres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "B\u00fccher lasten, B\u00fccher haben Kraft.", "tokens": ["B\u00fc\u00b7cher", "las\u00b7ten", ",", "B\u00fc\u00b7cher", "ha\u00b7ben", "Kraft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Junger Freund, Sie sind recht unerfahren,", "tokens": ["Jun\u00b7ger", "Freund", ",", "Sie", "sind", "recht", "un\u00b7er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und Sie fragen etwas reichlich frei.", "tokens": ["Und", "Sie", "fra\u00b7gen", "et\u00b7was", "reich\u00b7lich", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Auch bei andern Menschen als Barbaren", "tokens": ["Auch", "bei", "an\u00b7dern", "Men\u00b7schen", "als", "Bar\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "KOUS", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Gehen schlie\u00dflich B\u00fccher mal entzwei.", "tokens": ["Ge\u00b7hen", "schlie\u00df\u00b7lich", "B\u00fc\u00b7cher", "mal", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Wie? \u2013 ich jemals auch in B\u00fcchern lese??", "tokens": ["Wie", "?", "\u2013", "ich", "je\u00b7mals", "auch", "in", "B\u00fc\u00b7chern", "le\u00b7se", "??"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "$(", "PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Oh, Sie unerh\u00f6rter Ese \u2013 \u2013 \u2013", "tokens": ["Oh", ",", "Sie", "un\u00b7er\u00b7h\u00f6r\u00b7ter", "E\u00b7se", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ITJ", "$,", "PPER", "ADJA", "NN", "$(", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein, pardon! \u2013 Doch positus, ich s\u00e4\u00dfe", "tokens": ["Nein", ",", "par\u00b7don", "!", "\u2013", "Doch", "po\u00b7si\u00b7tus", ",", "ich", "s\u00e4\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "NN", "$.", "$(", "KON", "NE", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Auf dem Lokus, und Sie harrten", "tokens": ["Auf", "dem", "Lo\u00b7kus", ",", "und", "Sie", "harr\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Drau\u00dfen meiner R\u00fcckkehr, ach dann nur", "tokens": ["Drau\u00b7\u00dfen", "mei\u00b7ner", "R\u00fcck\u00b7kehr", ",", "ach", "dann", "nur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "$,", "ITJ", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Ja nicht l\u00e4nger auf mich warten.", "tokens": ["Ja", "nicht", "l\u00e4n\u00b7ger", "auf", "mich", "war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PTKNEG", "ADJD", "APPR", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn der Lokus ist bei mir ein Garten,", "tokens": ["Denn", "der", "Lo\u00b7kus", "ist", "bei", "mir", "ein", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "--+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Den man abseits ohne Zeit und Uhr", "tokens": ["Den", "man", "ab\u00b7seits", "oh\u00b7ne", "Zeit", "und", "Uhr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "D\u00fcngt und erntet dann Literatur.", "tokens": ["D\u00fcngt", "und", "ern\u00b7tet", "dann", "Li\u00b7te\u00b7ra\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "ADV", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "B\u00fccher \u2013 Nein, ich bitte Sie inst\u00e4ndig:", "tokens": ["B\u00fc\u00b7cher", "\u2013", "Nein", ",", "ich", "bit\u00b7te", "Sie", "in\u00b7st\u00e4n\u00b7dig", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Nicht mehr fragen! La\u00df dich doch belehren!", "tokens": ["Nicht", "mehr", "fra\u00b7gen", "!", "La\u00df", "dich", "doch", "be\u00b7leh\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "$.", "VVIMP", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "B\u00fccher, auch wenn sie nicht eigenh\u00e4ndig", "tokens": ["B\u00fc\u00b7cher", ",", "auch", "wenn", "sie", "nicht", "ei\u00b7gen\u00b7h\u00e4n\u00b7dig"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "KOUS", "PPER", "PTKNEG", "ADJD"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Handsigniert sind, soll man hoch verehren.", "tokens": ["Hand\u00b7sig\u00b7niert", "sind", ",", "soll", "man", "hoch", "ver\u00b7eh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "VMFIN", "PIS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "B\u00fccher werden, wenn man will, lebendig.", "tokens": ["B\u00fc\u00b7cher", "wer\u00b7den", ",", "wenn", "man", "will", ",", "le\u00b7ben\u00b7dig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VAINF", "$,", "KOUS", "PIS", "VMFIN", "$,", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "\u00dcber B\u00fccher kann man ganz befehlen.", "tokens": ["\u00dc\u00b7ber", "B\u00fc\u00b7cher", "kann", "man", "ganz", "be\u00b7feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Und wer B\u00fccher kauft, der kauft sich Seelen,", "tokens": ["Und", "wer", "B\u00fc\u00b7cher", "kauft", ",", "der", "kauft", "sich", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "PRF", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Und die Seelen k\u00f6nnen sich nicht wehren.", "tokens": ["Und", "die", "See\u00b7len", "k\u00f6n\u00b7nen", "sich", "nicht", "weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}