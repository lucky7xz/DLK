{"textgrid.poem.52392": {"metadata": {"author": {"name": "Reuter, Fritz", "birth": "N.A.", "death": "N.A."}, "title": "42. En Proze\u00df will hei nich hewwen", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tau Rostock bi Sleuders vertellten sick", "tokens": ["Tau", "Ros\u00b7tock", "bi", "Sleu\u00b7ders", "ver\u00b7tell\u00b7ten", "sick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "NE", "NE", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Weck G\u00e4st mal R\u00e4ubergeschichten", "tokens": ["Weck", "G\u00e4st", "mal", "R\u00e4u\u00b7ber\u00b7ge\u00b7schich\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "ADV", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Un sch\u00fcll'n dorbi ganz f\u00fcrchterlich", "tokens": ["Un", "sch\u00fcll'n", "dor\u00b7bi", "ganz", "f\u00fcrch\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Up hisige Landesgerichten.", "tokens": ["Up", "hi\u00b7si\u00b7ge", "Lan\u00b7des\u00b7ge\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "De ein vertellt en langen Stral", "tokens": ["De", "ein", "ver\u00b7tellt", "en", "lan\u00b7gen", "Stral"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "VVFIN", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von't Amtsgericht tau Wohren,", "tokens": ["Von't", "Amts\u00b7ge\u00b7richt", "tau", "Woh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "De anner von't Patrimonjal \u2013,", "tokens": ["De", "an\u00b7ner", "von't", "Pat\u00b7ri\u00b7mon\u00b7jal", "\u2013", ","], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von't Ridderschafts-Verfohren.", "tokens": ["Von't", "Rid\u00b7der\u00b7schafts\u00b7Ver\u00b7foh\u00b7ren", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sin Stadtgericht, s\u00e4d Nummer drei,", "tokens": ["Sin", "Stadt\u00b7ge\u00b7richt", ",", "s\u00e4d", "Num\u00b7mer", "drei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "ADV", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dat k\u00fcnn de D\u00fcwel halen;", "tokens": ["Dat", "k\u00fcnn", "de", "D\u00fc\u00b7wel", "ha\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "De virt, dat de Justiz-Kanzlei", "tokens": ["De", "virt", ",", "dat", "de", "Jus\u00b7ti\u00b7zKanz\u00b7lei"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PRELS", "NE", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Sick hellsehen let betahlen.", "tokens": ["Sick", "hell\u00b7se\u00b7hen", "let", "be\u00b7tah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Un alltausamen stimmen s' in:", "tokens": ["Un", "all\u00b7tau\u00b7sa\u00b7men", "stim\u00b7men", "s'", "in", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Dat d\u00fcllst s\u00fclln de Avkaten sin.", "tokens": ["Dat", "d\u00fcllst", "s\u00fclln", "de", "Av\u00b7ka\u00b7ten", "sin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Un schrigen all in einen Aten:", "tokens": ["Un", "schri\u00b7gen", "all", "in", "ei\u00b7nen", "A\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbwenn einen so recht de Avkaten faten,", "tokens": ["\u00bb", "wenn", "ei\u00b7nen", "so", "recht", "de", "Av\u00b7ka\u00b7ten", "fa\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "ADV", "ADJD", "NE", "NE", "VVFIN", "$,"], "meter": "-+--+----+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Denn m\u00f6t hei den letzten Dukaten laten!\u00ab", "tokens": ["Denn", "m\u00f6t", "hei", "den", "letz\u00b7ten", "Du\u00b7ka\u00b7ten", "la\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "NE", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "De armen mecklenb\u00f6rg'schen Herrn Avkaten!", "tokens": ["De", "ar\u00b7men", "meck\u00b7len\u00b7b\u00f6r\u00b7g'\u00b7schen", "Herrn", "Av\u00b7ka\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Dunn dr\u00e4ngt en ollen Milit\u00f6r", "tokens": ["Dunn", "dr\u00e4ngt", "en", "ol\u00b7len", "Mi\u00b7li\u00b7t\u00f6r"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sick d\u00f6rch den H\u00fcmpel bet nah v\u00f6r.", "tokens": ["Sick", "d\u00f6rch", "den", "H\u00fcm\u00b7pel", "bet", "nah", "v\u00f6r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwas Sie da sagen, meine Herrn,", "tokens": ["\u00bb", "was", "Sie", "da", "sa\u00b7gen", ",", "mei\u00b7ne", "Herrn", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "PPER", "ADV", "VVINF", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das glaub ich gern,", "tokens": ["Das", "glaub", "ich", "gern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Denn ich hab ganz was anders noch erfohren \u2013", "tokens": ["Denn", "ich", "hab", "ganz", "was", "an\u00b7ders", "noch", "er\u00b7foh\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PWS", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das war vor zirka sieben Johren,", "tokens": ["Das", "war", "vor", "zir\u00b7ka", "sie\u00b7ben", "Joh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NE", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "War dazumalen nach Major,", "tokens": ["War", "da\u00b7zu\u00b7ma\u00b7len", "nach", "Ma\u00b7jor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da nahm ich mich denn ernstlich vor,", "tokens": ["Da", "nahm", "ich", "mich", "denn", "ernst\u00b7lich", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df meine Kinder auch was lernen m\u00fcssen \u2013", "tokens": ["Da\u00df", "mei\u00b7ne", "Kin\u00b7der", "auch", "was", "ler\u00b7nen", "m\u00fcs\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Avangzemang is nich mehr wie vor dissen,", "tokens": ["A\u00b7vang\u00b7ze\u00b7mang", "is", "nich", "mehr", "wie", "vor", "dis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "PTKNEG", "ADV", "KOKOM", "APPR", "PDS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Beruht nich mehr auf Heldentaten.", "tokens": ["Be\u00b7ruht", "nich", "mehr", "auf", "Hel\u00b7den\u00b7ta\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ich miet mich also einen Kannidaten,", "tokens": ["Ich", "miet", "mich", "al\u00b7so", "ei\u00b7nen", "Kan\u00b7ni\u00b7da\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Acht Tage lang auch sehr zufrieden.", "tokens": ["Acht", "Ta\u00b7ge", "lang", "auch", "sehr", "zu\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Den Sonntag drauf ein kleines Desch\u00f6neh,", "tokens": ["Den", "Sonn\u00b7tag", "drauf", "ein", "klei\u00b7nes", "De\u00b7sch\u00f6\u00b7neh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Wo, wie gew\u00f6hnlich, meine Freunde seh.", "tokens": ["Wo", ",", "wie", "ge\u00b7w\u00f6hn\u00b7lich", ",", "mei\u00b7ne", "Freun\u00b7de", "seh", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "ADJD", "$,", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Der Kannidat auch hin beschieden,", "tokens": ["Der", "Kan\u00b7ni\u00b7dat", "auch", "hin", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Ganz nett, ganz sauber, ganz \u00e0 la Bonn\u00f6hr:", "tokens": ["Ganz", "nett", ",", "ganz", "sau\u00b7ber", ",", "ganz", "\u00e0", "la", "Bon\u00b7n\u00f6hr", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "FM", "FM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "En schwarzen Frak, 'ne wei\u00dfe Weste.", "tokens": ["En", "schwar\u00b7zen", "Frak", ",", "'ne", "wei\u00b7\u00dfe", "Wes\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Kurzum gesagt! Ich freut mir sehr.", "tokens": ["Kur\u00b7zum", "ge\u00b7sagt", "!", "Ich", "freut", "mir", "sehr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$.", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Man spricht nu manches hin un her,", "tokens": ["Man", "spricht", "nu", "man\u00b7ches", "hin", "un", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PIS", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "Da mischt der Mensch sich mang die G\u00e4ste", "tokens": ["Da", "mischt", "der", "Mensch", "sich", "mang", "die", "G\u00e4s\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Un redt da mit", "tokens": ["Un", "redt", "da", "mit"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.23": {"text": "Von dat un dit,", "tokens": ["Von", "dat", "un", "dit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "FM", "FM", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.24": {"text": "Als w\u00e4r er ganz uns ebenb\u00fcrtig.", "tokens": ["Als", "w\u00e4r", "er", "ganz", "uns", "e\u00b7ben\u00b7b\u00fcr\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Na, das war mich denn sehr merkw\u00fcrdig", "tokens": ["Na", ",", "das", "war", "mich", "denn", "sehr", "merk\u00b7w\u00fcr\u00b7dig"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PDS", "VAFIN", "PPER", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Un pa\u00dfte mir denn nu nat\u00fcrlich nicht;", "tokens": ["Un", "pa\u00df\u00b7te", "mir", "denn", "nu", "na\u00b7t\u00fcr\u00b7lich", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Ich seh ihn also grad in dem Gesicht;", "tokens": ["Ich", "seh", "ihn", "al\u00b7so", "grad", "in", "dem", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Doch er bleibt ruhig an das Wort.", "tokens": ["Doch", "er", "bleibt", "ru\u00b7hig", "an", "das", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.29": {"text": "Ich leg das Messer und die Gabel fort", "tokens": ["Ich", "leg", "das", "Mes\u00b7ser", "und", "die", "Ga\u00b7bel", "fort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NE", "ART", "NN", "KON", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Un richt mich etwas in der H\u00f6h", "tokens": ["Un", "richt", "mich", "et\u00b7was", "in", "der", "H\u00f6h"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Und seh ihn sehr bedeutend an \u2013", "tokens": ["Und", "seh", "ihn", "sehr", "be\u00b7deu\u00b7tend", "an", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Und, meine Herrn, wenn ich so seh,", "tokens": ["Und", ",", "mei\u00b7ne", "Herrn", ",", "wenn", "ich", "so", "seh", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Wie ich zuweilen sehen kann,", "tokens": ["Wie", "ich", "zu\u00b7wei\u00b7len", "se\u00b7hen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Dann \u2013 \u00e4h \u2013 \u00e4h \u2013 \u00e4h \u2013 dann \u00e4h \u2013 \u00e4h,", "tokens": ["Dann", "\u2013", "\u00e4h", "\u2013", "\u00e4h", "\u2013", "\u00e4h", "\u2013", "dann", "\u00e4h", "\u2013", "\u00e4h", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$(", "ADJD", "$(", "ADJD", "$(", "ADJD", "$(", "ADV", "ADJD", "$(", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.35": {"text": "Dann bleib mir jeder aus der N\u00e4h!", "tokens": ["Dann", "bleib", "mir", "je\u00b7der", "aus", "der", "N\u00e4h", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Doch er, er kehrt sich gar nich dran,", "tokens": ["Doch", "er", ",", "er", "kehrt", "sich", "gar", "nich", "dran", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VVFIN", "PRF", "ADV", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "F\u00e4hrt ruhig im Erz\u00e4hlen fort.", "tokens": ["F\u00e4hrt", "ru\u00b7hig", "im", "Er\u00b7z\u00e4h\u00b7len", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Na, hier war nun denn nicht der Ort,", "tokens": ["Na", ",", "hier", "war", "nun", "denn", "nicht", "der", "Ort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "ADV", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Geh\u00f6rig Bildung ihm zu lernen,", "tokens": ["Ge\u00b7h\u00f6\u00b7rig", "Bil\u00b7dung", "ihm", "zu", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Ich werd ihn noch mal scharf ansehn", "tokens": ["Ich", "werd", "ihn", "noch", "mal", "scharf", "an\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Und fang dann an herauszugehn", "tokens": ["Und", "fang", "dann", "an", "her\u00b7aus\u00b7zu\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Und werde mich sogleich entfernen,", "tokens": ["Und", "wer\u00b7de", "mich", "sog\u00b7leich", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Und, denken Sie, er bleibt ganz froh und heiter,", "tokens": ["Und", ",", "den\u00b7ken", "Sie", ",", "er", "bleibt", "ganz", "froh", "und", "hei\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "\u00bbje, Herr von L\u00fcttmann\u00ab, seggt de ein,", "tokens": ["\u00bb", "je", ",", "Herr", "von", "L\u00fctt\u00b7mann", "\u00ab", ",", "seggt", "de", "ein", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "NN", "APPR", "NE", "$(", "$,", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "\u00bbdenn heww'n S' em woll nich naug anseihn.\u00ab", "tokens": ["\u00bb", "denn", "hew\u00b7w'n", "S'", "em", "woll", "nich", "naug", "an\u00b7seihn", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "\u00bbne\u00ab, seggt de anner, \u00bbHerr von L\u00fcttmann,", "tokens": ["\u00bb", "ne", "\u00ab", ",", "seggt", "de", "an\u00b7ner", ",", "\u00bb", "Herr", "von", "L\u00fctt\u00b7mann", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$(", "$,", "FM.fr", "FM.fr", "FM.fr", "$,", "$(", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Denn seg'n S' em doch nich scharp naug an.\u00ab", "tokens": ["Denn", "seg'n", "S'", "em", "doch", "nich", "scharp", "naug", "an", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.48": {"text": "\u00bbna, meine Herrn, ich sag Sie ja,", "tokens": ["\u00bb", "na", ",", "mei\u00b7ne", "Herrn", ",", "ich", "sag", "Sie", "ja", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Da\u00df ich nach ihm ganz eklig sah.", "tokens": ["Da\u00df", "ich", "nach", "ihm", "ganz", "ek\u00b7lig", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "So sah ich auf den Menschen nieder!\u00ab", "tokens": ["So", "sah", "ich", "auf", "den", "Men\u00b7schen", "nie\u00b7der", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "\u00bbwo's't m\u00e4glich!\u00ab seggt denn nu de dr\u00fcdd,", "tokens": ["\u00bb", "wo'\u00b7s't", "m\u00e4g\u00b7lich", "!", "\u00ab", "seggt", "denn", "nu", "de", "dr\u00fcdd", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "$.", "$(", "VVFIN", "ADV", "ADV", "NE", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.52": {"text": "\u00bbdat em dorbi nich grugen w\u00fcrd.", "tokens": ["\u00bb", "dat", "em", "dor\u00b7bi", "nich", "gru\u00b7gen", "w\u00fcrd", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.la", "FM.la", "FM.la", "PTKNEG", "VVINF", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.53": {"text": "Un de verdammte Kirl et wider!\u00ab", "tokens": ["Un", "de", "ver\u00b7damm\u00b7te", "Kirl", "et", "wi\u00b7der", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "NE", "PTKVZ", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.54": {"text": "\u00bbna, nu, nat\u00fcrlich setz ich mir denn hin", "tokens": ["\u00bb", "na", ",", "nu", ",", "na\u00b7t\u00fcr\u00b7lich", "setz", "ich", "mir", "denn", "hin"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ITJ", "$,", "ADV", "$,", "ADV", "VVFIN", "PPER", "PPER", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.55": {"text": "Und werde einen Brief ihm schreiben,", "tokens": ["Und", "wer\u00b7de", "ei\u00b7nen", "Brief", "ihm", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Das k\u00f6nnt nat\u00fcrlich nich mehr sin,", "tokens": ["Das", "k\u00f6nnt", "na\u00b7t\u00fcr\u00b7lich", "nich", "mehr", "sin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKNEG", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.57": {"text": "Mein Kannidat k\u00f6nnt er nich l\u00e4nger bleiben,", "tokens": ["Mein", "Kan\u00b7ni\u00b7dat", "k\u00f6nnt", "er", "nich", "l\u00e4n\u00b7ger", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.58": {"text": "Wir t\u00e4ten doch wohl nich zusammen passen,", "tokens": ["Wir", "t\u00e4\u00b7ten", "doch", "wohl", "nich", "zu\u00b7sam\u00b7men", "pas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.59": {"text": "Er m\u00f6cht sogleich mein Haus verlassen.", "tokens": ["Er", "m\u00f6cht", "sog\u00b7leich", "mein", "Haus", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.60": {"text": "Das tut er auch, verl\u00e4\u00dft mein Haus.", "tokens": ["Das", "tut", "er", "auch", ",", "ver\u00b7l\u00e4\u00dft", "mein", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Und ich denk denn, die Sach ist lange aus,", "tokens": ["Und", "ich", "denk", "denn", ",", "die", "Sach", "ist", "lan\u00b7ge", "aus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$,"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.62": {"text": "Da kommt en Brief denn mit der Post", "tokens": ["Da", "kommt", "en", "Brief", "denn", "mit", "der", "Post"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "Von einem Kerl von Advokaten,", "tokens": ["Von", "ei\u00b7nem", "Kerl", "von", "Ad\u00b7vo\u00b7ka\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "Worin er f\u00fcr den Kannidaten", "tokens": ["Wo\u00b7rin", "er", "f\u00fcr", "den", "Kan\u00b7ni\u00b7da\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "Verlangt an Lohn, an Wohnung und an Kost", "tokens": ["Ver\u00b7langt", "an", "Lohn", ",", "an", "Woh\u00b7nung", "und", "an", "Kost"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "$,", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.66": {"text": "Und sonst'gen Alimentationen \u2013", "tokens": ["Und", "sonst'\u00b7gen", "A\u00b7li\u00b7men\u00b7ta\u00b7ti\u00b7o\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.67": {"text": "Wo viel? Nu raten Sie! \u2013 Vierhundert!", "tokens": ["Wo", "viel", "?", "Nu", "ra\u00b7ten", "Sie", "!", "\u2013", "Vier\u00b7hun\u00b7dert", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "$.", "ADV", "VVFIN", "PPER", "$.", "$(", "CARD", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.68": {"text": "Ich denn nat\u00fcrlich sehr verwundert,", "tokens": ["Ich", "denn", "na\u00b7t\u00fcr\u00b7lich", "sehr", "ver\u00b7wun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "Ich schreib an ihm, er m\u00f6chte mir verschonen,", "tokens": ["Ich", "schreib", "an", "ihm", ",", "er", "m\u00f6ch\u00b7te", "mir", "ver\u00b7scho\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.70": {"text": "Die Sache w\u00e4re l\u00e4ngst vorbei,", "tokens": ["Die", "Sa\u00b7che", "w\u00e4\u00b7re", "l\u00e4ngst", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Un ich w\u00e4r gar nicht vor Prozessen.", "tokens": ["Un", "ich", "w\u00e4r", "gar", "nicht", "vor", "Pro\u00b7zes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VAFIN", "ADV", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+----", "measure": "unknown.measure.tri"}, "line.72": {"text": "Ich denk denn nu, 's ist allens in der Reih,", "tokens": ["Ich", "denk", "denn", "nu", ",", "'s", "ist", "al\u00b7lens", "in", "der", "Reih", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.73": {"text": "Die Sach ist aus der Welt, da kriege ich indessen", "tokens": ["Die", "Sach", "ist", "aus", "der", "Welt", ",", "da", "krie\u00b7ge", "ich", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Ein Schreiben der Justizkanzlei,", "tokens": ["Ein", "Schrei\u00b7ben", "der", "Jus\u00b7tiz\u00b7kanz\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "En gro\u00dfen Brief. \u2013 Das kommt mir schnurrig f\u00fcr,", "tokens": ["En", "gro\u00b7\u00dfen", "Brief", ".", "\u2013", "Das", "kommt", "mir", "schnur\u00b7rig", "f\u00fcr", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "$(", "PDS", "VVFIN", "PPER", "ADJD", "APPR", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.76": {"text": "Ich brech ihn auf, ich les', ich wunder mir,", "tokens": ["Ich", "brech", "ihn", "auf", ",", "ich", "les'", ",", "ich", "wun\u00b7der", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "$,", "PPER", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.77": {"text": "Denn, denken Sie!, man wird mich drin zitieren,", "tokens": ["Denn", ",", "den\u00b7ken", "Sie", "!", ",", "man", "wird", "mich", "drin", "zi\u00b7tie\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$.", "$,", "PIS", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.78": {"text": "Mich in der Kannidaten-Angelegenheit", "tokens": ["Mich", "in", "der", "Kan\u00b7ni\u00b7da\u00b7ten\u00b7An\u00b7ge\u00b7le\u00b7gen\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Vor der Kanzlei zu deffendieren!\u00ab", "tokens": ["Vor", "der", "Kanz\u00b7lei", "zu", "def\u00b7fen\u00b7die\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.80": {"text": "\u00bbas wenn Sei\u00ab, seggt de irst, \u00bbso'n Schauster wiren?\u00ab", "tokens": ["\u00bb", "as", "wenn", "Sei", "\u00ab", ",", "seggt", "de", "irst", ",", "\u00bb", "so'n", "Schaus\u00b7ter", "wi\u00b7ren", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "KOUS", "NN", "$(", "$,", "FM.fr", "FM.fr", "FM.fr", "$,", "$(", "KON", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.81": {"text": "\u00bbna, dit ward \u00fcmmer netter\u00ab, seggt de tweit.", "tokens": ["\u00bb", "na", ",", "dit", "ward", "\u00fcm\u00b7mer", "net\u00b7ter", "\u00ab", ",", "seggt", "de", "tweit", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NE", "VAFIN", "ADV", "ADJA", "$(", "$,", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.82": {"text": "\u00bbja, so'n Geschichten\u00ab, seggt de dr\u00fcdd,", "tokens": ["\u00bb", "ja", ",", "so'n", "Ge\u00b7schich\u00b7ten", "\u00ab", ",", "seggt", "de", "dr\u00fcdd", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "KON", "NN", "$(", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.83": {"text": "\u00bbde k\u00fcnn de Kanzelei ok laten.", "tokens": ["\u00bb", "de", "k\u00fcnn", "de", "Kan\u00b7ze\u00b7lei", "ok", "la\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.da", "FM.da", "FM.da", "FM.da", "FM.da", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.84": {"text": "\u00dcm so'n Kirl von Kannidaten!", "tokens": ["\u00dcm", "so'n", "Kirl", "von", "Kan\u00b7ni\u00b7da\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.85": {"text": "Wenn ick mal Kanzelei-Direkter w\u00fcrd ...\u00ab", "tokens": ["Wenn", "ick", "mal", "Kan\u00b7ze\u00b7lei\u00b7Di\u00b7rek\u00b7ter", "w\u00fcrd", "...", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VAFIN", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.86": {"text": "\u00bbna, ich\u00ab, seggt Herr von L\u00fcttmann, \u00bbsetz mich dal,", "tokens": ["\u00bb", "na", ",", "ich", "\u00ab", ",", "seggt", "Herr", "von", "L\u00fctt\u00b7mann", ",", "\u00bb", "setz", "mich", "dal", ","], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PPER", "$(", "$,", "VVFIN", "NN", "APPR", "NE", "$,", "$(", "VVIMP", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Der Kanzelei-Direktor ist mein alter Freund,", "tokens": ["Der", "Kan\u00b7ze\u00b7lei\u00b7Di\u00b7rek\u00b7tor", "ist", "mein", "al\u00b7ter", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und schreibe denn an ihm: so w\u00e4r es nich gemeint.", "tokens": ["Und", "schrei\u00b7be", "denn", "an", "ihm", ":", "so", "w\u00e4r", "es", "nich", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPER", "$.", "ADV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Erz\u00e4hl ihm die Geschicht noch mal,", "tokens": ["Er\u00b7z\u00e4hl", "ihm", "die", "Ge\u00b7schicht", "noch", "mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "Wo ich den Menschen dreimal angekuckt,", "tokens": ["Wo", "ich", "den", "Men\u00b7schen", "drei\u00b7mal", "an\u00b7ge\u00b7kuckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.91": {"text": "Wie er dabei sich nicht gemuckt", "tokens": ["Wie", "er", "da\u00b7bei", "sich", "nicht", "ge\u00b7muckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PAV", "PRF", "PTKNEG", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "Und wie die Sache l\u00e4ngst begraben,", "tokens": ["Und", "wie", "die", "Sa\u00b7che", "l\u00e4ngst", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.93": {"text": "Und en Proze\u00df wollt ich durchaus nicht haben!", "tokens": ["Und", "en", "Pro\u00b7ze\u00df", "wollt", "ich", "durc\u00b7haus", "nicht", "ha\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VMFIN", "PPER", "ADV", "PTKNEG", "VAINF", "$."], "meter": "-+-+--++-+-", "measure": "iambic.penta.relaxed"}, "line.94": {"text": "Na, nu nat\u00fcrlich, denk ich, ist's vorbei;", "tokens": ["Na", ",", "nu", "na\u00b7t\u00fcr\u00b7lich", ",", "denk", "ich", ",", "ist's", "vor\u00b7bei", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "ADV", "$,", "VVFIN", "PPER", "$,", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.95": {"text": "Ich hatt mich deutlich ausgesprochen,", "tokens": ["Ich", "hatt", "mich", "deut\u00b7lich", "aus\u00b7ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.96": {"text": "Da, denken Sie, erhalt ich nach vier Wochen", "tokens": ["Da", ",", "den\u00b7ken", "Sie", ",", "er\u00b7halt", "ich", "nach", "vier", "Wo\u00b7chen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.97": {"text": "Ein zweites Schreiben von der Kanzelei:", "tokens": ["Ein", "zwei\u00b7tes", "Schrei\u00b7ben", "von", "der", "Kan\u00b7ze\u00b7lei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.98": {"text": "Ich h\u00e4tt schon eine Frist versessen,", "tokens": ["Ich", "h\u00e4tt", "schon", "ei\u00b7ne", "Frist", "ver\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.99": {"text": "Bei Androhung von weiterm Schaden", "tokens": ["Bei", "A\u00b7ndro\u00b7hung", "von", "wei\u00b7term", "Scha\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.100": {"text": "Ward ich darin zum zweitenmal geladen.", "tokens": ["Ward", "ich", "da\u00b7rin", "zum", "zwei\u00b7ten\u00b7mal", "ge\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.101": {"text": "Und ich \u2013 ich wollt ja nicht prozessen!\u00ab", "tokens": ["Und", "ich", "\u2013", "ich", "wollt", "ja", "nicht", "pro\u00b7zes\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "$(", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.102": {"text": "\u00bbwenn einer\u00ab, seggt de irst, \u00bbnu doch nich will!\u00ab", "tokens": ["\u00bb", "wenn", "ei\u00b7ner", "\u00ab", ",", "seggt", "de", "irst", ",", "\u00bb", "nu", "doch", "nich", "will", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "ART", "$(", "$,", "FM.fr", "FM.fr", "FM.fr", "$,", "$(", "ADV", "ADV", "PTKNEG", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.103": {"text": "\u00bbde Kanzelei sich sch\u00e4men s\u00fcll\u00ab,", "tokens": ["\u00bb", "de", "Kan\u00b7ze\u00b7lei", "sich", "sch\u00e4\u00b7men", "s\u00fcll", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "FM", "PRF", "VVFIN", "ADJD", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "Seggt nu de tweit, \u00bbdat is gemein!\u00ab", "tokens": ["Seggt", "nu", "de", "tweit", ",", "\u00bb", "dat", "is", "ge\u00b7mein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "$(", "ART", "FM", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.105": {"text": "\u00bbna, Herr von L\u00fcttmann\u00ab, seggt de dr\u00fcdd,", "tokens": ["\u00bb", "na", ",", "Herr", "von", "L\u00fctt\u00b7mann", "\u00ab", ",", "seggt", "de", "dr\u00fcdd", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NN", "APPR", "NE", "$(", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.106": {"text": "\u00bbwenn ", "tokens": ["\u00bb", "wenn"], "token_info": ["punct", "word"], "pos": ["$(", "KOUS"], "meter": "+", "measure": "single.up"}, "line.107": {"text": "Denn, Herr von L\u00fcttmann, s\u00fcll'n Sei seihn ...\u00ab", "tokens": ["Denn", ",", "Herr", "von", "L\u00fctt\u00b7mann", ",", "s\u00fcll'n", "Sei", "seihn", "...", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$,", "NN", "APPR", "NE", "$,", "FM.fr", "FM.fr", "FM.fr", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.108": {"text": "\u00bbna\u00ab, seggt nu ", "tokens": ["\u00bb", "na", "\u00ab", ",", "seggt", "nu"], "token_info": ["punct", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ITJ", "$(", "$,", "VVFIN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.109": {"text": "Und schreib an den Direktor noch einmal:", "tokens": ["Und", "schreib", "an", "den", "Di\u00b7rek\u00b7tor", "noch", "ein\u00b7mal", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.110": {"text": "Mein erster Brief w\u00e4r wohl verloren,", "tokens": ["Mein", "ers\u00b7ter", "Brief", "w\u00e4r", "wohl", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.111": {"text": "Man sollt mich lassen ungeschoren,", "tokens": ["Man", "sollt", "mich", "las\u00b7sen", "un\u00b7ge\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.112": {"text": "Ich h\u00e4tte nichts nich mit dem Kannidaten,", "tokens": ["Ich", "h\u00e4t\u00b7te", "nichts", "nich", "mit", "dem", "Kan\u00b7ni\u00b7da\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.113": {"text": "Auch nichts nich mit die Advokaten,", "tokens": ["Auch", "nichts", "nich", "mit", "die", "Ad\u00b7vo\u00b7ka\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.114": {"text": "Die Advokaten w\u00e4ren Raben,", "tokens": ["Die", "Ad\u00b7vo\u00b7ka\u00b7ten", "w\u00e4\u00b7ren", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.115": {"text": "Und en Proze\u00df wollt ich durchaus nicht haben.\u00ab", "tokens": ["Und", "en", "Pro\u00b7ze\u00df", "wollt", "ich", "durc\u00b7haus", "nicht", "ha\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "VMFIN", "PPER", "ADV", "PTKNEG", "VAINF", "$.", "$("], "meter": "-+-+--++-+-", "measure": "iambic.penta.relaxed"}, "line.116": {"text": "\u00bbrecht!\u00ab seggt de irst, \u00bbden s\u00e4d'n Sei gaud Bescheid!\u00ab", "tokens": ["\u00bb", "recht", "!", "\u00ab", "seggt", "de", "irst", ",", "\u00bb", "den", "s\u00e4d'n", "Sei", "gaud", "Be\u00b7scheid", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "$(", "FM.la", "FM.la", "FM.la", "$,", "$(", "ART", "FM", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.117": {"text": "\u00bbde kreg sin'n richt'gen Tappen\u00ab, seggt de tweit.", "tokens": ["\u00bb", "de", "kreg", "sin'n", "richt'\u00b7gen", "Tap\u00b7pen", "\u00ab", ",", "seggt", "de", "tweit", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM.da", "FM.da", "FM.da", "ADJA", "NN", "$(", "$,", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.118": {"text": "\u00bbja, Herr von L\u00fcttmann\u00ab, seggt de dr\u00fcdd,", "tokens": ["\u00bb", "ja", ",", "Herr", "von", "L\u00fctt\u00b7mann", "\u00ab", ",", "seggt", "de", "dr\u00fcdd", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "NN", "APPR", "NE", "$(", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.119": {"text": "\u00bbwenn ", "tokens": ["\u00bb", "wenn"], "token_info": ["punct", "word"], "pos": ["$(", "KOUS"], "meter": "+", "measure": "single.up"}, "line.120": {"text": "\u00bbnu, denk ich, ist es abgemacht\u00ab,", "tokens": ["\u00bb", "nu", ",", "denk", "ich", ",", "ist", "es", "ab\u00b7ge\u00b7macht", "\u00ab", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "VVPP", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.121": {"text": "Seggt Herr von L\u00fcttmann, \u00bbdoch nach acht Wochen,", "tokens": ["Seggt", "Herr", "von", "L\u00fctt\u00b7mann", ",", "\u00bb", "doch", "nach", "acht", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "NE", "$,", "$(", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.122": {"text": "Als ich schon lang an nichts gedacht,", "tokens": ["Als", "ich", "schon", "lang", "an", "nichts", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.123": {"text": "Da kommt ein dicker Brief an mir,", "tokens": ["Da", "kommt", "ein", "di\u00b7cker", "Brief", "an", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.124": {"text": "Das kommt mir sonderbaren f\u00fcr.", "tokens": ["Das", "kommt", "mir", "son\u00b7der\u00b7ba\u00b7ren", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVFIN", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.125": {"text": "Und als das Siegel ich erbrochen,", "tokens": ["Und", "als", "das", "Sie\u00b7gel", "ich", "er\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.126": {"text": "Da les ich denn, ich bin verurteilt:", "tokens": ["Da", "les", "ich", "denn", ",", "ich", "bin", "ver\u00b7ur\u00b7teilt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.127": {"text": "Die ganze Summe und die Kosten,", "tokens": ["Die", "gan\u00b7ze", "Sum\u00b7me", "und", "die", "Kos\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.128": {"text": "Zusammen ein recht netter Posten,", "tokens": ["Zu\u00b7sam\u00b7men", "ein", "recht", "net\u00b7ter", "Pos\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.129": {"text": "Den ich sogleich bezahlen sollte! \u2013", "tokens": ["Den", "ich", "sog\u00b7leich", "be\u00b7zah\u00b7len", "soll\u00b7te", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "ADV", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.130": {"text": "Proze\u00df verloren, den ich gar nicht wollte!", "tokens": ["Pro\u00b7ze\u00df", "ver\u00b7lo\u00b7ren", ",", "den", "ich", "gar", "nicht", "woll\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "PPER", "ADV", "PTKNEG", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.131": {"text": "Ich kuck den Brief woll dreimal an,", "tokens": ["Ich", "kuck", "den", "Brief", "woll", "drei\u00b7mal", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.132": {"text": "Sie wissen, wo ick kucken kann.", "tokens": ["Sie", "wis\u00b7sen", ",", "wo", "ick", "ku\u00b7cken", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.133": {"text": "Die Sache war ja l\u00e4ngst begraben,", "tokens": ["Die", "Sa\u00b7che", "war", "ja", "l\u00e4ngst", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.134": {"text": "Un en Proze\u00df wollt ich ja gar nicht haben.", "tokens": ["Un", "en", "Pro\u00b7ze\u00df", "wollt", "ich", "ja", "gar", "nicht", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "VAINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.135": {"text": "Und nun, trotzdem, ihn doch verloren! \u2013", "tokens": ["Und", "nun", ",", "trotz\u00b7dem", ",", "ihn", "doch", "ver\u00b7lo\u00b7ren", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "$,", "PAV", "$,", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.136": {"text": "Das nennt man ein Gerichtsverfohren!\u00ab", "tokens": ["Das", "nennt", "man", "ein", "Ge\u00b7richts\u00b7ver\u00b7foh\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}