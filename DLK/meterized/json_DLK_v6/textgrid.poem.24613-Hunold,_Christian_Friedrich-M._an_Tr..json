{"textgrid.poem.24613": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "M. an Tr.", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Beliebter Hertzens-Freund/ wenn auf der wilden Fluht", "tokens": ["Be\u00b7lieb\u00b7ter", "Hert\u00b7zens\u00b7Freund", "/", "wenn", "auf", "der", "wil\u00b7den", "Fluht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$(", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Schiff zu tr\u00fcmmern geht/ und denn das beste Gut", "tokens": ["Ein", "Schiff", "zu", "tr\u00fcm\u00b7mern", "geht", "/", "und", "denn", "das", "bes\u00b7te", "Gut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$(", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die tiefe See verschlingt/ auch ihren weiten Rachen", "tokens": ["Die", "tie\u00b7fe", "See", "ver\u00b7schlingt", "/", "auch", "ih\u00b7ren", "wei\u00b7ten", "Ra\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu aller Menschen-Todt beginnet auf zu machen;", "tokens": ["Zu", "al\u00b7ler", "Men\u00b7schen\u00b7Todt", "be\u00b7gin\u00b7net", "auf", "zu", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und man in Aengsten schwebt/ des Freundes untergehn/", "tokens": ["Und", "man", "in", "A\u00b7engs\u00b7ten", "schwebt", "/", "des", "Freun\u00b7des", "un\u00b7ter\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NE", "VVFIN", "$(", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.6": {"text": "Der auf den Wellen schwimmt/ erbarmlich anzusehn;", "tokens": ["Der", "auf", "den", "Wel\u00b7len", "schwimmt", "/", "er\u00b7barm\u00b7lich", "an\u00b7zu\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$(", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er aber noch ein Bret durch Gottes-Huld ergreiffet/", "tokens": ["Er", "a\u00b7ber", "noch", "ein", "Bret", "durch", "Got\u00b7tes\u00b7Huld", "er\u00b7greif\u00b7fet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und an das Ufer komt/ wenn sein Gef\u00e4rth ers\u00e4uffet:", "tokens": ["Und", "an", "das", "U\u00b7fer", "komt", "/", "wenn", "sein", "Ge\u00b7f\u00e4rth", "er\u00b7s\u00e4uf\u00b7fet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$(", "KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So strecket man den Arm mit vielen Freuden aus/", "tokens": ["So", "stre\u00b7cket", "man", "den", "Arm", "mit", "vie\u00b7len", "Freu\u00b7den", "aus", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Umfa\u00dft den Wehrten Freund/ f\u00fchrt ihn ins nechste Hau\u00df/", "tokens": ["Um\u00b7fa\u00dft", "den", "Wehr\u00b7ten", "Freund", "/", "f\u00fchrt", "ihn", "ins", "nechs\u00b7te", "Hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$(", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Erqvickt den matten Geist/ erw\u00e4rmet seine Glieder/", "tokens": ["E\u00b7rqvickt", "den", "mat\u00b7ten", "Geist", "/", "er\u00b7w\u00e4r\u00b7met", "sei\u00b7ne", "Glie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und st\u00e4rcket nach der Noht so Lieb als Seele wieder.", "tokens": ["Und", "st\u00e4r\u00b7cket", "nach", "der", "Noht", "so", "Lieb", "als", "See\u00b7le", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV", "NN", "KOUS", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "So viel Gefahr hat nicht die Offenbahre See/", "tokens": ["So", "viel", "Ge\u00b7fahr", "hat", "nicht", "die", "Of\u00b7fen\u00b7bah\u00b7re", "See", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "PTKNEG", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als wie der Wollust Meer: da in den Hafen laufen/", "tokens": ["Als", "wie", "der", "Wol\u00b7lust", "Meer", ":", "da", "in", "den", "Ha\u00b7fen", "lau\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "NN", "$.", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erlangen was man w\u00fcnscht/ hei\u00dft zum zuk\u00fcnftgen Weh", "tokens": ["Er\u00b7lan\u00b7gen", "was", "man", "w\u00fcnscht", "/", "hei\u00dft", "zum", "zu\u00b7k\u00fcnft\u00b7gen", "Weh"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PWS", "PIS", "VVFIN", "$(", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit gro\u00dfen Durst den Tod der Seelen in sich saufen.", "tokens": ["Mit", "gro\u00b7\u00dfen", "Durst", "den", "Tod", "der", "See\u00b7len", "in", "sich", "sau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "ART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man rei\u00dft uns aus der See/ aus Lieben nicht so leicht.", "tokens": ["Man", "rei\u00dft", "uns", "aus", "der", "See", "/", "aus", "Lie\u00b7ben", "nicht", "so", "leicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "APPR", "ADJA", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dort st\u00fcrtzet man uns um/ das Wa\u00dfer ab zu treiben;", "tokens": ["Dort", "st\u00fcrt\u00b7zet", "man", "uns", "um", "/", "das", "Wa\u00b7\u00dfer", "ab", "zu", "trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "APPR", "$(", "ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch wenn sich ", "tokens": ["Doch", "wenn", "sich"], "token_info": ["word", "word", "word"], "pos": ["KON", "KOUS", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Wird von der W\u00fcrckung meist etwas zur\u00fccke bleiben.", "tokens": ["Wird", "von", "der", "W\u00fcr\u00b7ckung", "meist", "et\u00b7was", "zu\u00b7r\u00fc\u00b7cke", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "PIS", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So Leib als Seele mu\u00df hier umgekehret seyn.", "tokens": ["So", "Leib", "als", "See\u00b7le", "mu\u00df", "hier", "um\u00b7ge\u00b7keh\u00b7ret", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ach! dieses kostet viel; das sind die Helden-Proben/", "tokens": ["Ach", "!", "die\u00b7ses", "kos\u00b7tet", "viel", ";", "das", "sind", "die", "Hel\u00b7den\u00b7Pro\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PDS", "VVFIN", "ADV", "$.", "PDS", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wer sein Gem\u00fcth umst\u00fcrtzt/ und bildet sich nicht ein/", "tokens": ["Wer", "sein", "Ge\u00b7m\u00fcth", "um\u00b7st\u00fcrtzt", "/", "und", "bil\u00b7det", "sich", "nicht", "ein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$(", "KON", "VVFIN", "PRF", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn er nur Athem sch\u00f6pft/ das Ubel sey gehoben.", "tokens": ["Wenn", "er", "nur", "A\u00b7them", "sch\u00f6pft", "/", "das", "U\u00b7bel", "sey", "ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VVFIN", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Zumahl/ weil deine Brust noch viele Schmertzen hegt/", "tokens": ["Zu\u00b7mahl", "/", "weil", "dei\u00b7ne", "Brust", "noch", "vie\u00b7le", "Schmert\u00b7zen", "hegt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "KOUS", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df in ", "tokens": ["Da\u00df", "in"], "token_info": ["word", "word"], "pos": ["KOUS", "APPR"], "meter": "++", "measure": "spondeus"}, "line.15": {"text": "Denn wenn sie der Verdru\u00df aus deinen Sinnen schl\u00e4gt/", "tokens": ["Denn", "wenn", "sie", "der", "Ver\u00b7dru\u00df", "aus", "dei\u00b7nen", "Sin\u00b7nen", "schl\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So thuts die Tugend nicht/ und ist zum Schein ersonnen.", "tokens": ["So", "thuts", "die", "Tu\u00b7gend", "nicht", "/", "und", "ist", "zum", "Schein", "er\u00b7son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKNEG", "$(", "KON", "VAFIN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was triumphirst du nun? Du bist noch nicht aus Land.", "tokens": ["Was", "tri\u00b7um\u00b7phirst", "du", "nun", "?", "Du", "bist", "noch", "nicht", "aus", "Land", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "ADV", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Aus Unlust wilst du hin; weil dirs nicht wohl gegangen.", "tokens": ["Aus", "Un\u00b7lust", "wilst", "du", "hin", ";", "weil", "dirs", "nicht", "wohl", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PTKVZ", "$.", "KOUS", "PIS", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Neicht dir ", "tokens": ["Neicht", "dir"], "token_info": ["word", "word"], "pos": ["NN", "PPER"], "meter": "-+", "measure": "iambic.single"}, "line.20": {"text": "Weil du noch auf dem Meer/ so bist du schon gefangen.", "tokens": ["Weil", "du", "noch", "auf", "dem", "Meer", "/", "so", "bist", "du", "schon", "ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "$(", "ADV", "VAFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Als denn so seuffzet man/ wenn man die Unruh sp\u00fcrt/", "tokens": ["Als", "denn", "so", "seuff\u00b7zet", "man", "/", "wenn", "man", "die", "Un\u00b7ruh", "sp\u00fcrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "VVFIN", "PIS", "$(", "KOUS", "PIS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die die Vollkommenheit der L\u00fcste bey sich f\u00fchrt/", "tokens": ["Die", "die", "Voll\u00b7kom\u00b7men\u00b7heit", "der", "L\u00fcs\u00b7te", "bey", "sich", "f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nach einem edlern Gut/ und wolte gern erwehlen/", "tokens": ["Nach", "ei\u00b7nem", "ed\u00b7lern", "Gut", "/", "und", "wol\u00b7te", "gern", "er\u00b7weh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "KON", "VMFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vor ein unruhig Hertz/ die Ruhe seiner Seelen.", "tokens": ["Vor", "ein", "un\u00b7ru\u00b7hig", "Hertz", "/", "die", "Ru\u00b7he", "sei\u00b7ner", "See\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "NN", "$(", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Die Wei\u00dfheit thut gemach der Augen Fell hinweg/", "tokens": ["Die", "Wei\u00df\u00b7heit", "thut", "ge\u00b7mach", "der", "Au\u00b7gen", "Fell", "hin\u00b7weg", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "APZR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das uns mit blindheit schlug/ und weiset uns den Steg/", "tokens": ["Das", "uns", "mit", "blind\u00b7heit", "schlug", "/", "und", "wei\u00b7set", "uns", "den", "Steg", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "VVFIN", "$(", "KON", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Worauf die Tugend laufft/ das wahre Gl\u00fcck zu fangen/", "tokens": ["Wo\u00b7rauf", "die", "Tu\u00b7gend", "laufft", "/", "das", "wah\u00b7re", "Gl\u00fcck", "zu", "fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVFIN", "$(", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Das leicht zu nennen ist/ doch schwerlich zu erlangen.", "tokens": ["Das", "leicht", "zu", "nen\u00b7nen", "ist", "/", "doch", "schwer\u00b7lich", "zu", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "PTKZU", "VVINF", "VAFIN", "$(", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer aus der Finsterni\u00df/ aus einer duncklen Gruben/", "tokens": ["Wer", "aus", "der", "Fins\u00b7ter\u00b7ni\u00df", "/", "aus", "ei\u00b7ner", "dunck\u00b7len", "Gru\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In der er lange Zeit/ gleich einem b\u00f6sen Buben/", "tokens": ["In", "der", "er", "lan\u00b7ge", "Zeit", "/", "gleich", "ei\u00b7nem", "b\u00f6\u00b7sen", "Bu\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "NN", "$(", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aus Ubelthat gesteckt/ wird an das Licht gebracht/", "tokens": ["Aus", "U\u00b7belt\u00b7hat", "ge\u00b7steckt", "/", "wird", "an", "das", "Licht", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$(", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der r\u00fchmet de\u00dfen Glantz/ verflucht die b\u00f6se Nacht/", "tokens": ["Der", "r\u00fch\u00b7met", "de\u00b7\u00dfen", "Glantz", "/", "ver\u00b7flucht", "die", "b\u00f6\u00b7se", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Verwundert sich/ wie er so lange sich betrogen/", "tokens": ["Ver\u00b7wun\u00b7dert", "sich", "/", "wie", "er", "so", "lan\u00b7ge", "sich", "be\u00b7tro\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$(", "PWAV", "PPER", "ADV", "ADV", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und statt der Sonnen sey dem dunckeln nach gezogen;", "tokens": ["Und", "statt", "der", "Son\u00b7nen", "sey", "dem", "dun\u00b7ckeln", "nach", "ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Legt alle Thorheit ab/ verdammt des Hertzens-Wahn/", "tokens": ["Legt", "al\u00b7le", "Thor\u00b7heit", "ab", "/", "ver\u00b7dammt", "des", "Hert\u00b7zens\u00b7Wahn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$(", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und z\u00fcndet seinem Geist ein G\u00f6ttlichs Feuer an.", "tokens": ["Und", "z\u00fcn\u00b7det", "sei\u00b7nem", "Geist", "ein", "G\u00f6tt\u00b7lichs", "Feu\u00b7er", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Den Weg zum Himmel sehn als denn die Adlers Augen.", "tokens": ["Den", "Weg", "zum", "Him\u00b7mel", "sehn", "als", "denn", "die", "Ad\u00b7lers", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "KOKOM", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Jedoch zu unserm Gl\u00fcck kan blo\u00dfes sehn nicht taugen:", "tokens": ["Je\u00b7doch", "zu", "un\u00b7serm", "Gl\u00fcck", "kan", "blo\u00b7\u00dfes", "sehn", "nicht", "tau\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VMFIN", "ADJA", "VVFIN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Fl\u00fcgel schwingen wir/ bi\u00df da\u00df man Kr\u00e4ffte kriegt/", "tokens": ["Die", "Fl\u00fc\u00b7gel", "schwin\u00b7gen", "wir", "/", "bi\u00df", "da\u00df", "man", "Kr\u00e4ff\u00b7te", "kriegt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$(", "APPR", "KOUS", "PIS", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sich von der Erden hebt/ und denn zum Himmel fliegt.", "tokens": ["Sich", "von", "der", "Er\u00b7den", "hebt", "/", "und", "denn", "zum", "Him\u00b7mel", "fliegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVFIN", "$(", "KON", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ein Wa\u00dfer stincket bald/ das nicht die Fluht erregt.", "tokens": ["Ein", "Wa\u00b7\u00dfer", "stin\u00b7cket", "bald", "/", "das", "nicht", "die", "Fluht", "er\u00b7regt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "PDS", "PTKNEG", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie ein Gem\u00fcht/ das sich in guten nicht bewegt.", "tokens": ["Wie", "ein", "Ge\u00b7m\u00fcht", "/", "das", "sich", "in", "gu\u00b7ten", "nicht", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$(", "PRELS", "PRF", "APPR", "ADJA", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Tugend/ wenn sie reist/ wird nicht im Gasthof bleiben/", "tokens": ["Die", "Tu\u00b7gend", "/", "wenn", "sie", "reist", "/", "wird", "nicht", "im", "Gast\u00b7hof", "blei\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOUS", "PPER", "VVFIN", "$(", "VAFIN", "PTKNEG", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo man nicht immer scheurt; sie liebt die Reinlichkeit.", "tokens": ["Wo", "man", "nicht", "im\u00b7mer", "scheurt", ";", "sie", "liebt", "die", "Rein\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PTKNEG", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein garstig Zimmer wird den reinen Geist vertreiben/", "tokens": ["Ein", "gars\u00b7tig", "Zim\u00b7mer", "wird", "den", "rei\u00b7nen", "Geist", "ver\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Jedoch ein sch\u00f6nes Hau\u00df wehlt sie auf Lebens Zeit.", "tokens": ["Je\u00b7doch", "ein", "sch\u00f6\u00b7nes", "Hau\u00df", "wehlt", "sie", "auf", "Le\u00b7bens", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Drum ist kein Lieben gut/ das nicht vern\u00fcnftig ist.", "tokens": ["Drum", "ist", "kein", "Lie\u00b7ben", "gut", "/", "das", "nicht", "ver\u00b7n\u00fcnf\u00b7tig", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PIAT", "ADJA", "ADJD", "$(", "PDS", "PTKNEG", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn selbst der Ehestand von Himmel eingesetzet/", "tokens": ["Denn", "selbst", "der", "E\u00b7hes\u00b7tand", "von", "Him\u00b7mel", "ein\u00b7ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird offtermahls befleckt/ da\u00df der auch s\u00fcndlich k\u00fc\u00dft/", "tokens": ["Wird", "off\u00b7ter\u00b7mahls", "be\u00b7fleckt", "/", "da\u00df", "der", "auch", "s\u00fcnd\u00b7lich", "k\u00fc\u00dft", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$(", "KOUS", "ART", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der in verg\u00f6nnter Lust unm\u00e4\u00dfig sich ergetzet.", "tokens": ["Der", "in", "ver\u00b7g\u00f6nn\u00b7ter", "Lust", "un\u00b7m\u00e4\u00b7\u00dfig", "sich", "er\u00b7get\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Freundschafft bleibet sch\u00f6n/ allwo ein sch\u00f6n Gem\u00fcht", "tokens": ["Die", "Freund\u00b7schafft", "blei\u00b7bet", "sch\u00f6n", "/", "all\u00b7wo", "ein", "sch\u00f6n", "Ge\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$(", "PWAV", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Beym Frauen Zimmer so/ als wie bey unsrer Jugend/", "tokens": ["Beym", "Frau\u00b7en", "Zim\u00b7mer", "so", "/", "als", "wie", "bey", "uns\u00b7rer", "Ju\u00b7gend", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "ADV", "$(", "KOUS", "KOKOM", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Uns zwar mit Anmuht spei\u00dft/ doch m\u00e4\u00dfig an sich zieht:", "tokens": ["Uns", "zwar", "mit", "An\u00b7muht", "spei\u00dft", "/", "doch", "m\u00e4\u00b7\u00dfig", "an", "sich", "zieht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVFIN", "$(", "ADV", "ADJD", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn wer unruhig liebt/ liebt niemahls nach der Tugend.", "tokens": ["Denn", "wer", "un\u00b7ru\u00b7hig", "liebt", "/", "liebt", "nie\u00b7mahls", "nach", "der", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJD", "VVFIN", "$(", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der Liebe dienstbar seyn/ hei\u00dft einen Herrn besitzen/", "tokens": ["Der", "Lie\u00b7be", "dienst\u00b7bar", "seyn", "/", "hei\u00dft", "ei\u00b7nen", "Herrn", "be\u00b7sit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAINF", "$(", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der mehr Gewalt an uns/ als ein Tyrann ver\u00fcbt.", "tokens": ["Der", "mehr", "Ge\u00b7walt", "an", "uns", "/", "als", "ein", "Ty\u00b7rann", "ver\u00b7\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "PPER", "$(", "KOUS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bey Feuer wird man kalt/ in K\u00e4lte mu\u00df man schwitzen/", "tokens": ["Bey", "Feu\u00b7er", "wird", "man", "kalt", "/", "in", "K\u00e4l\u00b7te", "mu\u00df", "man", "schwit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PIS", "ADJD", "$(", "APPR", "NN", "VMFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ungl\u00fccklich macht ihr Gl\u00fcck/ ihr freudig seyn betr\u00fcbt.", "tokens": ["Un\u00b7gl\u00fcck\u00b7lich", "macht", "ihr", "Gl\u00fcck", "/", "ihr", "freu\u00b7dig", "seyn", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN", "$(", "PPER", "ADJD", "VAINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie jagt uns durch das Meer/ l\u00e4\u00dft uns auf Felsen klettern/", "tokens": ["Sie", "jagt", "uns", "durch", "das", "Meer", "/", "l\u00e4\u00dft", "uns", "auf", "Fel\u00b7sen", "klet\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein Feuer scheuet sie/ verlacht die gr\u00f6ste Noht.", "tokens": ["Kein", "Feu\u00b7er", "scheu\u00b7et", "sie", "/", "ver\u00b7lacht", "die", "gr\u00f6s\u00b7te", "Noht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$(", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir reisen/ wenn es blitzt und tausend Keile schmettern/", "tokens": ["Wir", "rei\u00b7sen", "/", "wenn", "es", "blitzt", "und", "tau\u00b7send", "Kei\u00b7le", "schmet\u00b7tern", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "VVFIN", "KON", "CARD", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und unsre Wohlfahrt rennt offt sporren streichs in Todt.", "tokens": ["Und", "uns\u00b7re", "Wohl\u00b7fahrt", "rennt", "offt", "spor\u00b7ren", "streichs", "in", "Todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "VVINF", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wohl dem/ der nicht ihr Knecht; und sich der Tugend Wesen/", "tokens": ["Wohl", "dem", "/", "der", "nicht", "ihr", "Knecht", ";", "und", "sich", "der", "Tu\u00b7gend", "We\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "ART", "PTKNEG", "PPOSAT", "NN", "$.", "KON", "PRF", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Gem\u00fchts-Best\u00e4ndigkeit zu seinem Gl\u00fcck erkie\u00dft:", "tokens": ["Ge\u00b7m\u00fchts\u00b7Be\u00b7st\u00e4n\u00b7dig\u00b7keit", "zu", "sei\u00b7nem", "Gl\u00fcck", "er\u00b7kie\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da ist die Freude rein/ das Wohlseyn auserlesen/", "tokens": ["Da", "ist", "die", "Freu\u00b7de", "rein", "/", "das", "Wohl\u00b7seyn", "au\u00b7ser\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$(", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Qvelle/ die mit Lust bi\u00df an das Ende flie\u00dft.", "tokens": ["Die", "Qvel\u00b7le", "/", "die", "mit", "Lust", "bi\u00df", "an", "das", "En\u00b7de", "flie\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "APPR", "NN", "APPR", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So hat die Sch\u00f6nheit sie gleichfalls bezaubert?", "tokens": ["So", "hat", "die", "Sch\u00f6n\u00b7heit", "sie", "gleich\u00b7falls", "be\u00b7zau\u00b7bert", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Die Sch\u00f6nheit/ die das Aug' ergetzet/", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "/", "die", "das", "Aug'", "er\u00b7get\u00b7zet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Hertz entflammst und verletzet/", "tokens": ["Das", "Hertz", "ent\u00b7flammst", "und", "ver\u00b7let\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und den Verstand in Blindheit setzet?", "tokens": ["Und", "den", "Ver\u00b7stand", "in", "Blind\u00b7heit", "set\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Poch auf dein keusches Hertz nicht allzu lange Zeit:", "tokens": ["Poch", "auf", "dein", "keu\u00b7sches", "Hertz", "nicht", "all\u00b7zu", "lan\u00b7ge", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "PTKNEG", "PTKA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein sch\u00f6nes Auge strafft sonst die Verwegenheit.", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Au\u00b7ge", "strafft", "sonst", "die", "Ver\u00b7we\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Liebe findet leicht durch Fleisch und Blut die Spur:", "tokens": ["Die", "Lie\u00b7be", "fin\u00b7det", "leicht", "durch", "Fleisch", "und", "Blut", "die", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Schlo\u00df/ wo Tugend wohnt/ hei\u00dft menschliche Natur.", "tokens": ["Das", "Schlo\u00df", "/", "wo", "Tu\u00b7gend", "wohnt", "/", "hei\u00dft", "menschli\u00b7che", "Na\u00b7tur", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWAV", "NN", "VVFIN", "$(", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.11": {"line.1": {"text": "Wo einen sch\u00f6nen Leib die Tugenden durchflie\u00dfen/", "tokens": ["Wo", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Leib", "die", "Tu\u00b7gen\u00b7den", "durch\u00b7flie\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da ist ein sch\u00f6ner Bach in einer gr\u00fcnen Wiesen.", "tokens": ["Da", "ist", "ein", "sch\u00f6\u00b7ner", "Bach", "in", "ei\u00b7ner", "gr\u00fc\u00b7nen", "Wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Nach den k\u00fc\u00dfen/", "tokens": ["Nach", "den", "k\u00fc\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Will man gerne weiter wi\u00dfen ", "tokens": ["Will", "man", "ger\u00b7ne", "wei\u00b7ter", "wi\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Wer meint/ er wolle sich mit wenigem Vergn\u00fcgen/", "tokens": ["Wer", "meint", "/", "er", "wol\u00b7le", "sich", "mit", "we\u00b7ni\u00b7gem", "Ver\u00b7gn\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "PPER", "VMFIN", "PRF", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um kleine Freyheit fleht/ das K\u00fc\u00dfen edel hei\u00dft/", "tokens": ["Um", "klei\u00b7ne", "Frey\u00b7heit", "fleht", "/", "das", "K\u00fc\u00b7\u00dfen", "e\u00b7del", "hei\u00dft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJA", "NN", "VVFIN", "$(", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der ist in einen Flu\u00df/ der seichte scheint/ gestiegen/", "tokens": ["Der", "ist", "in", "ei\u00b7nen", "Flu\u00df", "/", "der", "seich\u00b7te", "scheint", "/", "ge\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ART", "NN", "$(", "ART", "NN", "VVFIN", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der unversehens w\u00e4chst/ und alles mit sich rei\u00dft.", "tokens": ["Der", "un\u00b7ver\u00b7se\u00b7hens", "w\u00e4chst", "/", "und", "al\u00b7les", "mit", "sich", "rei\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "$(", "KON", "PIS", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Doch da ein anderer bey jener Sch\u00f6nen stehet:", "tokens": ["Doch", "da", "ein", "an\u00b7de\u00b7rer", "bey", "je\u00b7ner", "Sch\u00f6\u00b7nen", "ste\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So schlag' ich mir mit Recht ", "tokens": ["So", "schlag'", "ich", "mir", "mit", "Recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da ich nicht gantz allein in ihrem Hertzen bin.", "tokens": ["Da", "ich", "nicht", "gantz", "al\u00b7lein", "in", "ih\u00b7rem", "Hert\u00b7zen", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Bi\u00df sie mit dir zugleich wird wahre Tugend lieben.", "tokens": ["Bi\u00df", "sie", "mit", "dir", "zu\u00b7gleich", "wird", "wah\u00b7re", "Tu\u00b7gend", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "VAFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nimm dich alsdenn in acht/ wenn dein Gem\u00fcthe steht:", "tokens": ["Nimm", "dich", "als\u00b7denn", "in", "acht", "/", "wenn", "dein", "Ge\u00b7m\u00fc\u00b7the", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "CARD", "$(", "KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil unsre Tugend hier auf glattem Eise geht.", "tokens": ["Weil", "uns\u00b7re", "Tu\u00b7gend", "hier", "auf", "glat\u00b7tem", "Ei\u00b7se", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gar viele pr\u00fcfen nicht den tiefen Grund der Hertzen.", "tokens": ["Gar", "vie\u00b7le", "pr\u00fc\u00b7fen", "nicht", "den", "tie\u00b7fen", "Grund", "der", "Hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PTKNEG", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du aber wirst dein Gl\u00fcck unwissend nicht verschertzen.", "tokens": ["Du", "a\u00b7ber", "wirst", "dein", "Gl\u00fcck", "un\u00b7wis\u00b7send", "nicht", "ver\u00b7schert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PPOSAT", "NN", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Offt f\u00e4lt die Bahn zu schwer/ die uns die Wei\u00dfheit zeigt.", "tokens": ["Offt", "f\u00e4lt", "die", "Bahn", "zu", "schwer", "/", "die", "uns", "die", "Wei\u00df\u00b7heit", "zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKA", "ADJD", "$(", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein Hertz wird muthig seyn/ wenn es auf solche steigt.", "tokens": ["Dein", "Hertz", "wird", "mut\u00b7hig", "seyn", "/", "wenn", "es", "auf", "sol\u00b7che", "steigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VAINF", "$(", "KOUS", "PPER", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf diesem Meer der Welt l\u00e4\u00dft man den Arm oft sincken.", "tokens": ["Auf", "die\u00b7sem", "Meer", "der", "Welt", "l\u00e4\u00dft", "man", "den", "Arm", "oft", "sin\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "VVFIN", "PIS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gewi\u00df du schwimmest fort/ nicht deinen Tod zu trincken.", "tokens": ["Ge\u00b7wi\u00df", "du", "schwim\u00b7mest", "fort", "/", "nicht", "dei\u00b7nen", "Tod", "zu", "trin\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "PTKVZ", "$(", "PTKNEG", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ich selber bin noch schwach/ drum gib mir keinen Ruhm.", "tokens": ["Ich", "sel\u00b7ber", "bin", "noch", "schwach", "/", "drum", "gib", "mir", "kei\u00b7nen", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ADJD", "$(", "PAV", "VVIMP", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dein starcker F\u00fchrer sey das Helden-Christenthum.", "tokens": ["Dein", "star\u00b7cker", "F\u00fch\u00b7rer", "sey", "das", "Hel\u00b7den\u00b7Chris\u00b7ten\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Sitten-Lehre Glantz ist sch\u00f6n/ doch wie ein Schatten/", "tokens": ["Der", "Sit\u00b7ten\u00b7Leh\u00b7re", "Glantz", "ist", "sch\u00f6n", "/", "doch", "wie", "ein", "Schat\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "$(", "ADV", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wer mit dem Himmels-Strahl sein Hertz nicht denckt zu gatten.", "tokens": ["Wer", "mit", "dem", "Him\u00b7mels\u00b7Strahl", "sein", "Hertz", "nicht", "denckt", "zu", "gat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PPOSAT", "NN", "PTKNEG", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Lehre der Vernunfft zeigt nur das Elend an.", "tokens": ["Die", "Leh\u00b7re", "der", "Ver\u00b7nunfft", "zeigt", "nur", "das", "E\u00b7lend", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und die Gl\u00fcckseeligkeit w\u00e4chst auf der Christen Bahn.", "tokens": ["Und", "die", "Gl\u00fcck\u00b7see\u00b7lig\u00b7keit", "w\u00e4chst", "auf", "der", "Chris\u00b7ten", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Drum brauche jenes Licht/ dich von Natur zu kennen/", "tokens": ["Drum", "brau\u00b7che", "je\u00b7nes", "Licht", "/", "dich", "von", "Na\u00b7tur", "zu", "ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PDAT", "NN", "$(", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Da\u00df Gottes Sonne m\u00f6g' in dir viel heller brennen.", "tokens": ["Da\u00df", "Got\u00b7tes", "Son\u00b7ne", "m\u00f6g'", "in", "dir", "viel", "hel\u00b7ler", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "VMFIN", "APPR", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wo diese Seligkeit nun dein Gem\u00fcth antrifft/", "tokens": ["Wo", "die\u00b7se", "Se\u00b7lig\u00b7keit", "nun", "dein", "Ge\u00b7m\u00fcth", "an\u00b7trifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Das zeigt der Wei\u00dfheit Schatz/ das zeigt die heilge Schrifft.", "tokens": ["Das", "zeigt", "der", "Wei\u00df\u00b7heit", "Schatz", "/", "das", "zeigt", "die", "heil\u00b7ge", "Schrifft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "$(", "PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "In dieser forsche stets/ denn die erkl\u00e4rt die Augen/", "tokens": ["In", "die\u00b7ser", "for\u00b7sche", "stets", "/", "denn", "die", "er\u00b7kl\u00e4rt", "die", "Au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "ADV", "$(", "KON", "ART", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und l\u00e4\u00dft die rechte Krafft zur Tugend in sich saugen.", "tokens": ["Und", "l\u00e4\u00dft", "die", "rech\u00b7te", "Krafft", "zur", "Tu\u00b7gend", "in", "sich", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Kan endlich deine Brust nicht ohne Liebe seyn:", "tokens": ["Kan", "end\u00b7lich", "dei\u00b7ne", "Brust", "nicht", "oh\u00b7ne", "Lie\u00b7be", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So weist das Bibel-Buch dir eine/ welche rein/", "tokens": ["So", "weist", "das", "Bi\u00b7bel\u00b7Buch", "dir", "ei\u00b7ne", "/", "wel\u00b7che", "rein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ART", "$(", "PRELS", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die freundlich/ h\u00fclfreich/ fromm/ dem\u00fcthig und gelinde;", "tokens": ["Die", "freund\u00b7lich", "/", "h\u00fclf\u00b7reich", "/", "fromm", "/", "de\u00b7m\u00fct\u00b7hig", "und", "ge\u00b7lin\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$(", "ADJD", "$(", "ADJD", "$(", "ADJD", "KON", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wo ich/ wenn sie mich k\u00fc\u00dft/ viel S\u00fc\u00dfigkeit empfinde.", "tokens": ["Wo", "ich", "/", "wenn", "sie", "mich", "k\u00fc\u00dft", "/", "viel", "S\u00fc\u00b7\u00dfig\u00b7keit", "emp\u00b7fin\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$(", "KOUS", "PPER", "PPER", "VVFIN", "$(", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die nie unruhig macht/ die selbst der Himmel liebt/", "tokens": ["Die", "nie", "un\u00b7ru\u00b7hig", "macht", "/", "die", "selbst", "der", "Him\u00b7mel", "liebt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "$(", "ART", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.27": {"text": "Die Gott und Menschen sich allzeit zu eigen giebt/", "tokens": ["Die", "Gott", "und", "Men\u00b7schen", "sich", "all\u00b7zeit", "zu", "ei\u00b7gen", "giebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PRF", "ADV", "PTKA", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Die mehr als Hoffnung gilt/ und auch dem Helden-Glauben/", "tokens": ["Die", "mehr", "als", "Hoff\u00b7nung", "gilt", "/", "und", "auch", "dem", "Hel\u00b7den\u00b7Glau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "KOKOM", "NN", "VVFIN", "$(", "KON", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wie selbst die Wei\u00dfheit sagt/ den Vorzug wei\u00df zu rauben/", "tokens": ["Wie", "selbst", "die", "Wei\u00df\u00b7heit", "sagt", "/", "den", "Vor\u00b7zug", "wei\u00df", "zu", "rau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVFIN", "$(", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die Liebe/ die zuletzt die Liebe nicht verdammt/", "tokens": ["Die", "Lie\u00b7be", "/", "die", "zu\u00b7letzt", "die", "Lie\u00b7be", "nicht", "ver\u00b7dammt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Damit du gegen mich/ und gegen dich entflammt.", "tokens": ["Da\u00b7mit", "du", "ge\u00b7gen", "mich", "/", "und", "ge\u00b7gen", "dich", "ent\u00b7flammt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "$(", "KON", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}