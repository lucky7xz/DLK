{"dta.poem.18133": {"metadata": {"author": {"name": "Bodmer, Johann Jacob", "birth": "N.A.", "death": "N.A."}, "title": "Pr\u00fcffung  der  Uebers etzung  \n von Horazens Dichtkunst.", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-200905198432", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "F\u00fcrwahr ein artig Bild!V. 1. F\u00fcrwahr ein artig Bild)\nLa\u00df mir das eine treffliche Uebersetzung seyn, wenn die\nerste Zeile schon einer Entschuldigung bedarff! Hr. Gott-\nsched hat selbst vor n\u00f6thig erachtet, diesen Zusatz von sei-\nner Erfindung in folgender Anmerckung zu entschuldigen:\n\u201dDiese Worte hat der Grundtext nicht. Horaz f\u00e4ngt\n\u201dgleich an, sein Gleichni\u00df von einem seltsamen Gem\u00e4hl-\n\u201dde vorzutragen. Allein da sichs im Deutschen nicht in\n\u201deinen eintzigen Satz bringen lie\u00df, und also zertrennet\n\u201dwerden mu\u00dfte; so macht dieser Anfang den Leser auf-\n\u201dmercksam, und sagt ihm kurtz, was er zu gewarten habe.\u201d\nEr h\u00e4lt dieses eingeflickte Hemistichium um so viel unstr\u00e4fli-\ncher, weil sich das Horazische Gem\u00e4hlde doch in der Ue-\nbersetzung nicht wohl in einen eintzigen Satz h\u00e4tte zwin-\ngen lassen, und also zertrennt werden m\u00fcssen. Das ist,\ner m\u00f6chte gerne die Freyheit seiner Ausschweiffungen mit\ndem ungezwungenen Wesen der deutschen Sprache bem\u00e4n-\nteln. Gesetzt aber, es w\u00e4re mehr der Natur der deutschen\nSprache, als dem Unverm\u00f6gen des Uebersetzers zuzu-\nschreiben, da\u00df das Horatzianische Gleichni\u00df-Bild in dem\nVerfolge in verschiedene Abs\u00e4tze zertrennt worden; was\ngiebt ihm dieses f\u00fcr Freyheit ohne Noth noch weiter aus-\nzuschweifen, und dem Gem\u00e4hlde neue Lappen anzuflicken?\nH\u00e4tte ihn diese nothwendige Abweichung von der Grund-\nschrift, die in der verschiedenen Art beyder Sprachen ge-\ngr\u00fcndet war, nicht desto behutsamer machen sollen? Al-\nlein Hr. Gottsched begn\u00fcget sich mit dieser kahlen Ent-\nschuldigung nicht, sondern behauptet, da\u00df dieser Zusatz,\nden er der Horatzischen Vorstellung geliehen, die verbor-\ngene Kraft habe, die Leser recht aufmercksam zu machen, Es steht ein Menschenkopf ", "tokens": ["F\u00fcr\u00b7wahr", "ein", "ar\u00b7tig", "Bild", "!", "V.", "1.", "F\u00fcr\u00b7wahr", "ein", "ar\u00b7tig", "Bild", ")", "La\u00df", "mir", "das", "ei\u00b7ne", "treff\u00b7li\u00b7che", "Ue\u00b7ber\u00b7set\u00b7zung", "seyn", ",", "wenn", "die", "ers\u00b7te", "Zei\u00b7le", "schon", "ei\u00b7ner", "Ent\u00b7schul\u00b7di\u00b7gung", "be\u00b7darff", "!", "Hr.", "Got\u00b7t", "sched", "hat", "selbst", "vor", "n\u00f6\u00b7thig", "e\u00b7rach\u00b7tet", ",", "die\u00b7sen", "Zu\u00b7satz", "von", "sei", "ner", "Er\u00b7fin\u00b7dung", "in", "fol\u00b7gen\u00b7der", "An\u00b7mer\u00b7ckung", "zu", "ent\u00b7schul\u00b7di\u00b7gen", ":", "\"", "Die\u00b7se", "Wor\u00b7te", "hat", "der", "Grund\u00b7text", "nicht", ".", "Ho\u00b7raz", "f\u00e4ngt", "\"", "gleich", "an", ",", "sein", "Gleich\u00b7ni\u00df", "von", "ei\u00b7nem", "selt\u00b7sa\u00b7men", "Ge\u00b7m\u00e4hl", "\"", "de", "vor\u00b7zu\u00b7tra\u00b7gen", ".", "Al\u00b7lein", "da", "sichs", "im", "Deut\u00b7schen", "nicht", "in", "\"", "ei\u00b7nen", "eint\u00b7zi\u00b7gen", "Satz", "brin\u00b7gen", "lie\u00df", ",", "und", "al\u00b7so", "zer\u00b7tren\u00b7net", "\"", "wer\u00b7den", "mu\u00df\u00b7te", ";", "so", "macht", "die\u00b7ser", "An\u00b7fang", "den", "Le\u00b7ser", "auf", "\"", "merck\u00b7sam", ",", "und", "sagt", "ihm", "kurtz", ",", "was", "er", "zu", "ge\u00b7war\u00b7ten", "ha\u00b7be", ".", "\"", "Er", "h\u00e4lt", "die\u00b7ses", "ein\u00b7ge\u00b7flick\u00b7te", "He\u00b7mis\u00b7ti\u00b7chi\u00b7um", "um", "so", "viel", "un\u00b7str\u00e4f\u00b7li", "cher", ",", "weil", "sich", "das", "Ho\u00b7ra\u00b7zi\u00b7sche", "Ge\u00b7m\u00e4hl\u00b7de", "doch", "in", "der", "Ue", "ber\u00b7set\u00b7zung", "nicht", "wohl", "in", "ei\u00b7nen", "eint\u00b7zi\u00b7gen", "Satz", "h\u00e4t\u00b7te", "zwin", "gen", "las\u00b7sen", ",", "und", "al\u00b7so", "zer\u00b7trennt", "wer\u00b7den", "m\u00fcs\u00b7sen", ".", "Das", "ist", ",", "er", "m\u00f6ch\u00b7te", "ger\u00b7ne", "die", "Frey\u00b7heit", "sei\u00b7ner", "Aus\u00b7schwei\u00b7ffun\u00b7gen", "mit", "dem", "un\u00b7ge\u00b7zwun\u00b7ge\u00b7nen", "We\u00b7sen", "der", "deut\u00b7schen", "Spra\u00b7che", "be\u00b7m\u00e4n", "teln", ".", "Ge\u00b7setzt", "a\u00b7ber", ",", "es", "w\u00e4\u00b7re", "mehr", "der", "Na\u00b7tur", "der", "deut\u00b7schen", "Spra\u00b7che", ",", "als", "dem", "Un\u00b7ver\u00b7m\u00f6\u00b7gen", "des", "Ue\u00b7ber\u00b7set\u00b7zers", "zu\u00b7zu", "schrei\u00b7ben", ",", "da\u00df", "das", "Ho\u00b7rat\u00b7zi\u00b7a\u00b7ni\u00b7sche", "Gleich\u00b7ni\u00df\u00b7Bild", "in", "dem", "Ver\u00b7fol\u00b7ge", "in", "ver\u00b7schie\u00b7de\u00b7ne", "Ab\u00b7s\u00e4t\u00b7ze", "zer\u00b7trennt", "wor\u00b7den", ";", "was", "giebt", "ihm", "die\u00b7ses", "f\u00fcr", "Frey\u00b7heit", "oh\u00b7ne", "Noth", "noch", "wei\u00b7ter", "aus", "zu\u00b7schwei\u00b7fen", ",", "und", "dem", "Ge\u00b7m\u00e4hl\u00b7de", "neu\u00b7e", "Lap\u00b7pen", "an\u00b7zu\u00b7fli\u00b7cken", "?", "H\u00e4t\u00b7te", "ihn", "die\u00b7se", "noth\u00b7wen\u00b7di\u00b7ge", "Ab\u00b7wei\u00b7chung", "von", "der", "Grun\u00b7d", "schrift", ",", "die", "in", "der", "ver\u00b7schie\u00b7de\u00b7nen", "Art", "bey\u00b7der", "Spra\u00b7chen", "ge", "gr\u00fcn\u00b7det", "war", ",", "nicht", "des\u00b7to", "be\u00b7hut\u00b7sa\u00b7mer", "ma\u00b7chen", "sol\u00b7len", "?", "Al", "lein", "Hr.", "Gott\u00b7sched", "be\u00b7gn\u00fc\u00b7get", "sich", "mit", "die\u00b7ser", "kah\u00b7len", "Ent", "schul\u00b7di\u00b7gung", "nicht", ",", "son\u00b7dern", "be\u00b7haup\u00b7tet", ",", "da\u00df", "die\u00b7ser", "Zu\u00b7satz", ",", "den", "er", "der", "Ho\u00b7rat\u00b7zi\u00b7schen", "Vor\u00b7stel\u00b7lung", "ge\u00b7lie\u00b7hen", ",", "die", "ver\u00b7bor", "ge\u00b7ne", "Kraft", "ha\u00b7be", ",", "die", "Le\u00b7ser", "recht", "auf\u00b7merck\u00b7sam", "zu", "ma\u00b7chen", ",", "Es", "steht", "ein", "Men\u00b7schen\u00b7kopf"], "token_info": ["word", "word", "word", "word", "punct", "abbreviation", "ordinal", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "abbreviation", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "abbreviation", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJD", "NN", "$.", "NE", "ADJA", "NN", "ART", "ADJD", "NN", "$(", "VVIMP", "PPER", "PDS", "ART", "ADJA", "NN", "VAINF", "$,", "KOUS", "ART", "ADJA", "NN", "ADV", "ART", "NN", "VVFIN", "$.", "NE", "TRUNC", "ADJD", "VAFIN", "ADV", "APPR", "ADJD", "VVPP", "$,", "PDAT", "NN", "APPR", "TRUNC", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$.", "$(", "PDAT", "NN", "VAFIN", "ART", "NN", "PTKNEG", "$.", "NE", "VVFIN", "$(", "ADV", "PTKVZ", "$,", "PPOSAT", "NN", "APPR", "ART", "ADJA", "TRUNC", "$(", "NE", "VVIZU", "$.", "ADV", "KOUS", "PIS", "APPRART", "NN", "PTKNEG", "APPR", "$(", "ART", "ADJA", "NN", "VVINF", "VVFIN", "$,", "KON", "ADV", "VVFIN", "$(", "VAINF", "VMFIN", "$.", "ADV", "VVFIN", "PDAT", "NN", "ART", "NN", "TRUNC", "$(", "ADJD", "$,", "KON", "VVFIN", "PPER", "ADJD", "$,", "PWS", "PPER", "PTKZU", "VVINF", "VAFIN", "$.", "$(", "PPER", "VVFIN", "PDAT", "ADJA", "NN", "APPR", "ADV", "ADV", "TRUNC", "NE", "$,", "KOUS", "PRF", "ART", "ADJA", "NN", "ADV", "APPR", "ART", "TRUNC", "NN", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN", "VAFIN", "TRUNC", "VVINF", "VVINF", "$,", "KON", "ADV", "VVPP", "VAINF", "VMFIN", "$.", "PDS", "VAFIN", "$,", "PPER", "VMFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "TRUNC", "VVINF", "$.", "VVPP", "ADV", "$,", "PPER", "VAFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,", "KOUS", "ART", "NN", "ART", "NN", "TRUNC", "VVINF", "$,", "KOUS", "ART", "ADJA", "NN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVPP", "VAPP", "$.", "PWS", "VVFIN", "PPER", "PDAT", "APPR", "NN", "APPR", "NN", "ADV", "ADV", "TRUNC", "VVINF", "$,", "KON", "ART", "NN", "ADJA", "NN", "VVIZU", "$.", "VVFIN", "PPER", "PDAT", "ADJA", "NN", "APPR", "ART", "TRUNC", "VVFIN", "$,", "PRELS", "APPR", "ART", "ADJA", "NN", "PIAT", "NN", "TRUNC", "VVPP", "VAFIN", "$,", "PTKNEG", "ADV", "ADJD", "VVINF", "VMFIN", "$.", "TRUNC", "NN", "NE", "NE", "VVFIN", "PRF", "APPR", "PDAT", "ADJA", "TRUNC", "NN", "PTKNEG", "$,", "KON", "VVFIN", "$,", "KOUS", "PDAT", "NN", "$,", "PRELS", "PPER", "ART", "ADJA", "NN", "VVPP", "$,", "ART", "TRUNC", "ADJA", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+---+-+--+-+-+--+-+--+--+-+-+-+-+-+-+-+-+-+--+--+--+--+--+-+--+-+-+-+--+-+-+-+--+--+--+-+-+--+-+-+-+-+-+--+--+-+--+-+-+--+--+--+-+---+-+--+-+-+--+--+-+--+---+-+-+---+-+-+--+-+--+-+--+-+-+--+--+-+--+--+--+--+-+-+--+-+-+-+-+-+-+--+--+-+--+--+---+-+--+-+-+-+-+-+--+-+-+-+-+-+-+-+-+-+-+-+-+-+--++--+-+-+-+--+-+-+-+-+-+-+--+-+-+-+-+-+--+--+--+-+--+-+-+--+--+--+--+-+-+--+--+-+--+-+-+---+-+-+-+--+--+--+--+-+-+-+-+---+-+-+--+---+--++--+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Auf eines Pferdes Hals. Den dicken Vogelkropf ", "tokens": ["Auf", "ei\u00b7nes", "Pfer\u00b7des", "Hals", ".", "Den", "di\u00b7cken", "Vo\u00b7gel\u00b7kropf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bedeckt ein bunter Schmuck von farbigtem Gefieder:", "tokens": ["Be\u00b7deckt", "ein", "bun\u00b7ter", "Schmuck", "von", "far\u00b7big\u00b7tem", "Ge\u00b7fie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hernach erblicket man verschiedner Thiere Glieder.", "tokens": ["Her\u00b7nach", "er\u00b7bli\u00b7cket", "man", "ver\u00b7schied\u00b7ner", "Thie\u00b7re", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von oben zeigt ein Weib ihr sch\u00f6nes Angesicht. ", "tokens": ["Von", "o\u00b7ben", "zeigt", "ein", "Weib", "ihr", "sch\u00f6\u00b7nes", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von unten wirds ein Fisch. ", "tokens": ["Von", "un\u00b7ten", "wirds", "ein", "Fisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wir wollen mit Geduld des Malers Thorheit schonen. ", "tokens": ["Wir", "wol\u00b7len", "mit", "Ge\u00b7duld", "des", "Ma\u00b7lers", "Thor\u00b7heit", "scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Indessen glaubet mir,", "tokens": ["In\u00b7des\u00b7sen", "glau\u00b7bet", "mir", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Dafern mein Wort was gilt, da\u00df eine tolle Schrift,", "tokens": ["Da\u00b7fern", "mein", "Wort", "was", "gilt", ",", "da\u00df", "ei\u00b7ne", "tol\u00b7le", "Schrift", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PWS", "VVFIN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wo weder Haupt noch Schwanz geschickt zusam\u0303en trifft, ", "tokens": ["Wo", "we\u00b7der", "Haupt", "noch", "Schwanz", "ge\u00b7schickt", "zu\u00b7sam\u0303en", "trifft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "NN", "ADV", "NN", "VVPP", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und nicht mehr Ordnung herrscht", "tokens": ["Und", "nicht", "mehr", "Ord\u00b7nung", "herrscht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ADV", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "(met,", "tokens": ["(", "met", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.13": {"text": "Sich unvergleichlich wohl zu solchem Bilde reimet.", "tokens": ["Sich", "un\u00b7ver\u00b7gleich\u00b7lich", "wohl", "zu", "sol\u00b7chem", "Bil\u00b7de", "rei\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ich wei\u00df wol was man glaubt. Man spricht und bleibt dabey:", "tokens": ["Ich", "wei\u00df", "wol", "was", "man", "glaubt", ".", "Man", "spricht", "und", "bleibt", "da\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PWS", "PIS", "VVFIN", "$.", "PIS", "VVFIN", "KON", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ein Maler und Poet folgt seiner Phantasey:", "tokens": ["Ein", "Ma\u00b7ler", "und", "Po\u00b7et", "folgt", "sei\u00b7ner", "Phan\u00b7ta\u00b7sey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Er kan sich seiner Kunst nach eigner Lust bedienen, ", "tokens": ["Er", "kan", "sich", "sei\u00b7ner", "Kunst", "nach", "eig\u00b7ner", "Lust", "be\u00b7die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und sich durch Geist und Witz, was ihm beliebt, erk\u00fchnen.", "tokens": ["Und", "sich", "durch", "Geist", "und", "Witz", ",", "was", "ihm", "be\u00b7liebt", ",", "er\u00b7k\u00fch\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "KON", "NN", "$,", "PWS", "PPER", "ADJD", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ganz recht, ich geb es zu, und mach es selber so.", "tokens": ["Ganz", "recht", ",", "ich", "geb", "es", "zu", ",", "und", "mach", "es", "sel\u00b7ber", "so", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Allein man mische nie das Feuer in das Stroh.", "tokens": ["Al\u00b7lein", "man", "mi\u00b7sche", "nie", "das", "Feu\u00b7er", "in", "das", "Stroh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Kein Tiger zeug ein Lamm, kein Adler hecke Schlangen.", "tokens": ["Kein", "Ti\u00b7ger", "zeug", "ein", "Lamm", ",", "kein", "Ad\u00b7ler", "he\u00b7cke", "Schlan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$,", "PIAT", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Doch m", "tokens": ["Doch", "m"], "token_info": ["word", "word"], "pos": ["KON", "NE"], "meter": "+-", "measure": "trochaic.single"}, "line.22": {"text": "Man schm\u00fcckt sie hin und her mit Edelsteinen aus,", "tokens": ["Man", "schm\u00fcckt", "sie", "hin", "und", "her", "mit", "E\u00b7del\u00b7stei\u00b7nen", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "KON", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Beschreibt Dianens H\u00e4yn, Altar und G\u00f6tterhaus,", "tokens": ["Be\u00b7schreibt", "Di\u00b7a\u00b7nens", "H\u00e4yn", ",", "Al\u00b7tar", "und", "G\u00f6t\u00b7ter\u00b7haus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Entwirft mit grosser Kunst des Rheinstroms Wasserwogen,", "tokens": ["Ent\u00b7wirft", "mit", "gros\u00b7ser", "Kunst", "des", "Rhein\u00b7stroms", "Was\u00b7ser\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "ART", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und malt der Farben Glanz im bunten Regenbogen.", "tokens": ["Und", "malt", "der", "Far\u00b7ben", "Glanz", "im", "bun\u00b7ten", "Re\u00b7gen\u00b7bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das alles ist schon gut; nur hier geh\u00f6rts nicht her. ", "tokens": ["Das", "al\u00b7les", "ist", "schon", "gut", ";", "nur", "hier", "ge\u00b7h\u00f6rts", "nicht", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "ADV", "ADJD", "$.", "ADV", "ADV", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Dort st\u00fcrzt ein wilder Sturm den Schiffer in das Meer:", "tokens": ["Dort", "st\u00fcrzt", "ein", "wil\u00b7der", "Sturm", "den", "Schif\u00b7fer", "in", "das", "Meer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Gesetzt, du k\u00f6nntest nun Cypressenw\u00e4lder schildern,", "tokens": ["Ge\u00b7setzt", ",", "du", "k\u00f6nn\u00b7test", "nun", "Cyp\u00b7res\u00b7sen\u00b7w\u00e4l\u00b7der", "schil\u00b7dern", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Was hilft dir diese Kunst? da sich in deinen Bildern", "tokens": ["Was", "hilft", "dir", "die\u00b7se", "Kunst", "?", "da", "sich", "in", "dei\u00b7nen", "Bil\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PDAT", "NN", "$.", "KOUS", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Der Schiffbruch zeigen soll", "tokens": ["Der", "Schiff\u00b7bruch", "zei\u00b7gen", "soll"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.31": {"text": "Nach \u00fcberstandner Noth, mit Flei\u00df bey dir bestellt. ", "tokens": ["Nach", "\u00fc\u00b7bers\u00b7tand\u00b7ner", "Noth", ",", "mit", "Flei\u00df", "bey", "dir", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Dein stolzer Anfang pralt von seltnen Wundersachen,", "tokens": ["Dein", "stol\u00b7zer", "An\u00b7fang", "pralt", "von", "selt\u00b7nen", "Wun\u00b7der\u00b7sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wie reizt uns denn hernach der magre Schlu\u00df zum Lachen?", "tokens": ["Wie", "reizt", "uns", "denn", "her\u00b7nach", "der", "mag\u00b7re", "Schlu\u00df", "zum", "La\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Kurz, alles was du schreibst mu\u00df schlecht und einsach seyn.", "tokens": ["Kurz", ",", "al\u00b7les", "was", "du", "schreibst", "mu\u00df", "schlecht", "und", "ein\u00b7sach", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIS", "PWS", "PPER", "VVFIN", "VMFIN", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Doch, Piso, tr\u00fcgt uns oft des Guten falscher Schein.", "tokens": ["Doch", ",", "Pi\u00b7so", ",", "tr\u00fcgt", "uns", "oft", "des", "Gu\u00b7ten", "fal\u00b7scher", "Schein", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NE", "$,", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Die K\u00fcrze macht mich schwer", "tokens": ["Die", "K\u00fcr\u00b7ze", "macht", "mich", "schwer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.37": {"text": "Und leyret lahm und matt. Der strebt nach grossen Dingen,", "tokens": ["Und", "ley\u00b7ret", "lahm", "und", "matt", ".", "Der", "strebt", "nach", "gros\u00b7sen", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "ADJD", "$.", "ART", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Und bl\u00e4ht sich schw\u00fclstig auf. Wenn jener furchtsam schreibt", "tokens": ["Und", "bl\u00e4ht", "sich", "schw\u00fcls\u00b7tig", "auf", ".", "Wenn", "je\u00b7ner", "furcht\u00b7sam", "schreibt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "PTKVZ", "$.", "KOUS", "PDS", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Geschieht es, da\u00df er gar am Staube kleben bleibt.", "tokens": ["Ge\u00b7schieht", "es", ",", "da\u00df", "er", "gar", "am", "Stau\u00b7be", "kle\u00b7ben", "bleibt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "APPRART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Wer sich bem\u00fcht, ein Ding sehr vielfach ", "tokens": ["Wer", "sich", "be\u00b7m\u00fcht", ",", "ein", "Ding", "sehr", "viel\u00b7fach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "VVPP", "$,", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.41": {"text": "Malt leicht den St\u00f6hr ins Holz, den Eber in die Wellen. ", "tokens": ["Malt", "leicht", "den", "St\u00f6hr", "ins", "Holz", ",", "den", "E\u00b7ber", "in", "die", "Wel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So leicht ist es geschehn, auch wenn man sich bem\u00fcht", "tokens": ["So", "leicht", "ist", "es", "ge\u00b7schehn", ",", "auch", "wenn", "man", "sich", "be\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "VVPP", "$,", "ADV", "KOUS", "PIS", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Von Fehlern frey zu seyn, da\u00df sich der Kiel versieht.", "tokens": ["Von", "Feh\u00b7lern", "frey", "zu", "seyn", ",", "da\u00df", "sich", "der", "Kiel", "ver\u00b7sieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "PTKZU", "VAINF", "$,", "KOUS", "PRF", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Man l\u00e4\u00dft ein Fechterspiel aus dichtem Erzte giessen;", "tokens": ["Man", "l\u00e4\u00dft", "ein", "Fech\u00b7ter\u00b7spiel", "aus", "dich\u00b7tem", "Erz\u00b7te", "gies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Da hat der St\u00fcmper nun die N\u00e4gel an den F\u00fcssen", "tokens": ["Da", "hat", "der", "St\u00fcm\u00b7per", "nun", "die", "N\u00e4\u00b7gel", "an", "den", "F\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Und jedes Haar des Haupts sehr k\u00fcnstlich ausgedr\u00fcckt; ", "tokens": ["Und", "je\u00b7des", "Haar", "des", "Haupts", "sehr", "k\u00fcnst\u00b7lich", "aus\u00b7ge\u00b7dr\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Die Bildung \u00fcberhaupt ist plump und ungeschickt,", "tokens": ["Die", "Bil\u00b7dung", "\u00fc\u00b7ber\u00b7haupt", "ist", "plump", "und", "un\u00b7ge\u00b7schickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Weil Ordnung und Gestalt und Stellung gar nichts taugen.", "tokens": ["Weil", "Ord\u00b7nung", "und", "Ge\u00b7stalt", "und", "Stel\u00b7lung", "gar", "nichts", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "KON", "NN", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Viel lieber w\u00fcnsch ich mir, bey schwarzem Haar und Augen,", "tokens": ["Viel", "lie\u00b7ber", "w\u00fcnsch", "ich", "mir", ",", "bey", "schwar\u00b7zem", "Haar", "und", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "$,", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Ein scheu\u00dflich Angesicht und krummes Nasenbein,", "tokens": ["Ein", "scheu\u00df\u00b7lich", "An\u00b7ge\u00b7sicht", "und", "krum\u00b7mes", "Na\u00b7sen\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Als da\u00df ein Vers von mir, wie dieses Bild soll seyn. ", "tokens": ["Als", "da\u00df", "ein", "Vers", "von", "mir", ",", "wie", "die\u00b7ses", "Bild", "soll", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "APPR", "PPER", "$,", "PWAV", "PDAT", "NN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Jhr Dichter, wagt doch nichts, als was ihr wohl versteht,", "tokens": ["Ihr", "Dich\u00b7ter", ",", "wagt", "doch", "nichts", ",", "als", "was", "ihr", "wohl", "ver\u00b7steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ADV", "PIS", "$,", "KOUS", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Versuchts, wie weit die Kraft von euren Schultern geht,", "tokens": ["Ver\u00b7suchts", ",", "wie", "weit", "die", "Kraft", "von", "eu\u00b7ren", "Schul\u00b7tern", "geht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADJD", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und \u00fcberlegt es wohl: So wird nach klugem W\u00e4hlen,", "tokens": ["Und", "\u00fc\u00b7ber\u00b7legt", "es", "wohl", ":", "So", "wird", "nach", "klu\u00b7gem", "W\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$.", "ADV", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Den Schriften weder Kunst, noch Licht, noch Ordnung fehlen.", "tokens": ["Den", "Schrif\u00b7ten", "we\u00b7der", "Kunst", ",", "noch", "Licht", ",", "noch", "Ord\u00b7nung", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "ADV", "NN", "$,", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Mich d\u00fcnkt, da\u00df sich allda der Ordnung Sch\u00f6nheit zeigt, ", "tokens": ["Mich", "d\u00fcnkt", ",", "da\u00df", "sich", "all\u00b7da", "der", "Ord\u00b7nung", "Sch\u00f6n\u00b7heit", "zeigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PRF", "PAV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Wenn man das Wichtigste von vorne zwar verschweigt,", "tokens": ["Wenn", "man", "das", "Wich\u00b7tigs\u00b7te", "von", "vor\u00b7ne", "zwar", "ver\u00b7schweigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "APPR", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Doch r\u00e4thselhaft entdeckt", "tokens": ["Doch", "r\u00e4th\u00b7sel\u00b7haft", "ent\u00b7deckt"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJD", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.59": {"text": "Die sch\u00f6nsten Sachen wehlt, die schlechten weis zu meiden.", "tokens": ["Die", "sch\u00f6ns\u00b7ten", "Sa\u00b7chen", "wehlt", ",", "die", "schlech\u00b7ten", "weis", "zu", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "In neuer W\u00f6rter Bau", "tokens": ["In", "neu\u00b7er", "W\u00f6r\u00b7ter", "Bau"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.61": {"text": "Das \u00e4ltste l\u00e4\u00dft sich oft auf neue Sachen ziehn, ", "tokens": ["Das", "\u00e4lts\u00b7te", "l\u00e4\u00dft", "sich", "oft", "auf", "neu\u00b7e", "Sa\u00b7chen", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Nur mu\u00df die Redensart des Schreibers Sinn erkl\u00e4ren.", "tokens": ["Nur", "mu\u00df", "die", "Re\u00b7den\u00b7sart", "des", "Schrei\u00b7bers", "Sinn", "er\u00b7kl\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Doch sollten Kunst und Flei\u00df ein neues Ding gew\u00e4hren,", "tokens": ["Doch", "soll\u00b7ten", "Kunst", "und", "Flei\u00df", "ein", "neu\u00b7es", "Ding", "ge\u00b7w\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "So stellt mans ungescheut durch einen Ausdruck dar,", "tokens": ["So", "stellt", "mans", "un\u00b7ge\u00b7scheut", "durch", "ei\u00b7nen", "Aus\u00b7druck", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Der unsern V\u00e4tern noch was unerh\u00f6rtes war.", "tokens": ["Der", "un\u00b7sern", "V\u00e4\u00b7tern", "noch", "was", "un\u00b7er\u00b7h\u00f6r\u00b7tes", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "PWS", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wer die\u00df bescheiden thut, dem kan mans nicht verwehren. ", "tokens": ["Wer", "die\u00df", "be\u00b7schei\u00b7den", "thut", ",", "dem", "kan", "mans", "nicht", "ver\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVINF", "VVFIN", "$,", "PDS", "VMFIN", "PIS", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Zuweilen kan man auch der W\u00f6rter nicht entbehren,", "tokens": ["Zu\u00b7wei\u00b7len", "kan", "man", "auch", "der", "W\u00f6r\u00b7ter", "nicht", "ent\u00b7beh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die Griechenland uns leiht.", "tokens": ["Die", "Grie\u00b7chen\u00b7land", "uns", "leiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.69": {"text": "Vorzeiten Macht gehabt, das kan ja auch Virgil.", "tokens": ["Vor\u00b7zei\u00b7ten", "Macht", "ge\u00b7habt", ",", "das", "kan", "ja", "auch", "Vir\u00b7gil", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAPP", "$,", "PDS", "VMFIN", "ADV", "ADV", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Hat Ennius uns nicht manch neues Wort gelehret?", "tokens": ["Hat", "En\u00b7ni\u00b7us", "uns", "nicht", "manch", "neu\u00b7es", "Wort", "ge\u00b7leh\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PPER", "PTKNEG", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Hat Cato das Latein nicht ebenfalls vermehret, ", "tokens": ["Hat", "Ca\u00b7to", "das", "La\u00b7tein", "nicht", "e\u00b7ben\u00b7falls", "ver\u00b7meh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ART", "NN", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.72": {"text": "Und manche Redensart zu Rom in Schwang gebracht?", "tokens": ["Und", "man\u00b7che", "Re\u00b7den\u00b7sart", "zu", "Rom", "in", "Schwang", "ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NE", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Wie k\u00f6mmts denn, da\u00df man itzt ein solches Wesen macht,", "tokens": ["Wie", "k\u00f6mmts", "denn", ",", "da\u00df", "man", "itzt", "ein", "sol\u00b7ches", "We\u00b7sen", "macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "$,", "KOUS", "PIS", "ADV", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Wenn ichs zuweilen thu? Wer hat mich hier zu schelten?", "tokens": ["Wenn", "ichs", "zu\u00b7wei\u00b7len", "thu", "?", "Wer", "hat", "mich", "hier", "zu", "schel\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVFIN", "$.", "PWS", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Ein neuer Ausdruck mu\u00df gleich neuen Thalern gelten.", "tokens": ["Ein", "neu\u00b7er", "Aus\u00b7druck", "mu\u00df", "gleich", "neu\u00b7en", "Tha\u00b7lern", "gel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "So wie es alle Jahr belaubten W\u00e4ldern geht; ", "tokens": ["So", "wie", "es", "al\u00b7le", "Jahr", "be\u00b7laub\u00b7ten", "W\u00e4l\u00b7dern", "geht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "PIAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Das welcke Laub f\u00e4llt ab, das neue Blatt entsteht:", "tokens": ["Das", "wel\u00b7cke", "Laub", "f\u00e4llt", "ab", ",", "das", "neu\u00b7e", "Blatt", "ent\u00b7steht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "So gehts den Sprachen auch. Ein altes Wort verschwindet,", "tokens": ["So", "gehts", "den", "Spra\u00b7chen", "auch", ".", "Ein", "al\u00b7tes", "Wort", "ver\u00b7schwin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$.", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Indem sich unvermerckt ein neuer Ausdruck findet.", "tokens": ["In\u00b7dem", "sich", "un\u00b7ver\u00b7merckt", "ein", "neu\u00b7er", "Aus\u00b7druck", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADJD", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Dem Tode sind nicht nur wir Menschen unterthan,", "tokens": ["Dem", "To\u00b7de", "sind", "nicht", "nur", "wir", "Men\u00b7schen", "un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Sein Arm greift alles das, was menschlich heisset, an. ", "tokens": ["Sein", "Arm", "greift", "al\u00b7les", "das", ",", "was", "menschlich", "heis\u00b7set", ",", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIS", "PDS", "$,", "PRELS", "ADJD", "VVFIN", "$,", "PTKVZ", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.82": {"text": "Hier l\u00e4\u00dft ein Julius den neuen Hafen bauen,", "tokens": ["Hier", "l\u00e4\u00dft", "ein", "Ju\u00b7lius", "den", "neu\u00b7en", "Ha\u00b7fen", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.83": {"text": "Dem sich bey Sturm und Fluth die Flotten anvertrauen,", "tokens": ["Dem", "sich", "bey", "Sturm", "und", "Fluth", "die", "Flot\u00b7ten", "an\u00b7ver\u00b7trau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Ein k\u00f6nigliches Werck! Was kan Augustus thun?", "tokens": ["Ein", "k\u00f6\u00b7nig\u00b7li\u00b7ches", "Werck", "!", "Was", "kan", "Au\u00b7gus\u00b7tus", "thun", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PWS", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Er trocknet Seen aus, und kann nicht eher ruhn,", "tokens": ["Er", "trock\u00b7net", "Seen", "aus", ",", "und", "kann", "nicht", "e\u00b7her", "ruhn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "$,", "KON", "VMFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.86": {"text": "Als bis wir, wo der Wind die Flaggen pflegt zu wehen, ", "tokens": ["Als", "bis", "wir", ",", "wo", "der", "Wind", "die", "Flag\u00b7gen", "pflegt", "zu", "we\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "$,", "PWAV", "ART", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Ein fruchtbar Ackerland und fette Wiesen sehen.", "tokens": ["Ein", "frucht\u00b7bar", "A\u00b7cker\u00b7land", "und", "fet\u00b7te", "Wie\u00b7sen", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Noch mehr, er \u00e4ndert gar der Tyber alten Lauf,", "tokens": ["Noch", "mehr", ",", "er", "\u00e4n\u00b7dert", "gar", "der", "Ty\u00b7ber", "al\u00b7ten", "Lauf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PPER", "VVFIN", "ADV", "ART", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Und schr\u00e4nckt die Fluthen ein.", "tokens": ["Und", "schr\u00e4nckt", "die", "Flut\u00b7hen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.90": {"text": "Der gr\u00f6\u00dften Wercke Pracht mu\u00df endlich untergehen:", "tokens": ["Der", "gr\u00f6\u00df\u00b7ten", "Wer\u00b7cke", "Pracht", "mu\u00df", "end\u00b7lich", "un\u00b7ter\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wie k\u00f6nnten denn der Zeit die Sprachen widerstehen? ", "tokens": ["Wie", "k\u00f6nn\u00b7ten", "denn", "der", "Zeit", "die", "Spra\u00b7chen", "wi\u00b7der\u00b7ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "So manch verlegnes Wort, das l\u00e4ngst vergessen war,", "tokens": ["So", "manch", "ver\u00b7leg\u00b7nes", "Wort", ",", "das", "l\u00e4ngst", "ver\u00b7ges\u00b7sen", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "K\u00f6mmt wieder an das Licht, und stellt sich sch\u00f6ner dar,", "tokens": ["K\u00f6mmt", "wie\u00b7der", "an", "das", "Licht", ",", "und", "stellt", "sich", "sch\u00f6\u00b7ner", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "PRF", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Und was man itzo braucht, das wird man einst vergessen;", "tokens": ["Und", "was", "man", "it\u00b7zo", "braucht", ",", "das", "wird", "man", "einst", "ver\u00b7ges\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "VVFIN", "$,", "PDS", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Kurz, Sprachen m\u00fcssen sich nach der Gewohnheit messen.", "tokens": ["Kurz", ",", "Spra\u00b7chen", "m\u00fcs\u00b7sen", "sich", "nach", "der", "Ge\u00b7wohn\u00b7heit", "mes\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "VMFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}}}}