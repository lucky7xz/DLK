{"textgrid.poem.48568": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "17. Auf Herrn Martin M\u00fcnsterbergers seines geliebten S\u00f6hnleins sein Absterben, von Astrachan nach Moskow gesandt", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Teurer Freund der ersten Zeit,", "tokens": ["Teu\u00b7rer", "Freund", "der", "ers\u00b7ten", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die mich Ru\u00dfland hie\u00df durchziehen", "tokens": ["die", "mich", "Ru\u00df\u00b7land", "hie\u00df", "durch\u00b7zie\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRELS", "PRF", "NE", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und auf Weiters was bem\u00fchen,", "tokens": ["und", "auf", "Wei\u00b7ters", "was", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das mich mehr als sehr nun reut,", "tokens": ["das", "mich", "mehr", "als", "sehr", "nun", "reut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "KOKOM", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ist's so, wie mir k\u00f6mmt zu Ohren,", "tokens": ["ist's", "so", ",", "wie", "mir", "k\u00f6mmt", "zu", "Oh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWAV", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df dein S\u00f6hnlein ist verloren?", "tokens": ["da\u00df", "dein", "S\u00f6hn\u00b7lein", "ist", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Allzuwahr! Erbarm es Gott!", "tokens": ["All\u00b7zu\u00b7wahr", "!", "Er\u00b7barm", "es", "Gott", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er, des Vatern anders Herze", "tokens": ["Er", ",", "des", "Va\u00b7tern", "an\u00b7ders", "Her\u00b7ze"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "ART", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und der Matter s\u00fc\u00dfer Schmerze,", "tokens": ["und", "der", "Mat\u00b7ter", "s\u00fc\u00b7\u00dfer", "Schmer\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "er, der traute Sohn, ist tot.", "tokens": ["er", ",", "der", "trau\u00b7te", "Sohn", ",", "ist", "tot", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "NN", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihres Wundsches ganzes Hoffen", "tokens": ["Ih\u00b7res", "Wund\u00b7sches", "gan\u00b7zes", "Hof\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "hat des W\u00fcrgers Pfeil getroffen.", "tokens": ["hat", "des", "W\u00fcr\u00b7gers", "Pfeil", "ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Billich tust du, da\u00df du zagst,", "tokens": ["Bil\u00b7lich", "tust", "du", ",", "da\u00df", "du", "zagst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "doch so tust du auch hingegen", "tokens": ["doch", "so", "tust", "du", "auch", "hin\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wie die frommen Priester pflegen,", "tokens": ["wie", "die", "from\u00b7men", "Pries\u00b7ter", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df du auch von Troste sagst,", "tokens": ["da\u00df", "du", "auch", "von", "Tros\u00b7te", "sagst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "den dir Gottes Buch verehret", "tokens": ["den", "dir", "Got\u00b7tes", "Buch", "ver\u00b7eh\u00b7ret"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und nun seinen Lehrer lehret.", "tokens": ["und", "nun", "sei\u00b7nen", "Leh\u00b7rer", "leh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Alles ist mehr nichts als nichts,", "tokens": ["Al\u00b7les", "ist", "mehr", "nichts", "als", "nichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "PIS", "KOKOM", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leben, Ehre, Kunst, Verm\u00fcgen;", "tokens": ["Le\u00b7ben", ",", "Eh\u00b7re", ",", "Kunst", ",", "Ver\u00b7m\u00fc\u00b7gen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "es entgeht uns, eh' wirs kriegen;", "tokens": ["es", "ent\u00b7geht", "uns", ",", "eh'", "wirs", "krie\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "eh' wirs fassen, so zerbrichts;", "tokens": ["eh'", "wirs", "fas\u00b7sen", ",", "so", "zer\u00b7brichts", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "$,", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "es verschwindet, eh' wirs n\u00fctzen,", "tokens": ["es", "ver\u00b7schwin\u00b7det", ",", "eh'", "wirs", "n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Winden gleich und schnellen Blitzen.", "tokens": ["Win\u00b7den", "gleich", "und", "schnel\u00b7len", "Blit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Mu\u00df es denn gestorben sein,", "tokens": ["Mu\u00df", "es", "denn", "ge\u00b7stor\u00b7ben", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ei, so ist es balde besser.", "tokens": ["ei", ",", "so", "ist", "es", "bal\u00b7de", "bes\u00b7ser", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Verzug macht Strafe gr\u00f6\u00dfer,", "tokens": ["Der", "Ver\u00b7zug", "macht", "Stra\u00b7fe", "gr\u00f6\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "vom Verschube w\u00e4chst die Pein.", "tokens": ["vom", "Ver\u00b7schu\u00b7be", "w\u00e4chst", "die", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der ist klug, der allen F\u00e4llen", "tokens": ["Der", "ist", "klug", ",", "der", "al\u00b7len", "F\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADJD", "$,", "PRELS", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "allzeit sich gefa\u00dft kan stellen.", "tokens": ["all\u00b7zeit", "sich", "ge\u00b7fa\u00dft", "kan", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVPP", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Tr\u00f6ste dich und deinen Trost,", "tokens": ["Tr\u00f6s\u00b7te", "dich", "und", "dei\u00b7nen", "Trost", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "der dir in den Armen weinet!", "tokens": ["der", "dir", "in", "den", "Ar\u00b7men", "wei\u00b7net", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sprich: Der B\u00f6ses gut doch meinet,", "tokens": ["Sprich", ":", "Der", "B\u00f6\u00b7ses", "gut", "doch", "mei\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "ART", "NN", "ADJD", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der hat \u00fcber uns gelost.", "tokens": ["der", "hat", "\u00fc\u00b7ber", "uns", "ge\u00b7lost", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Unser Leben frei zu b\u00fcrgen,", "tokens": ["Un\u00b7ser", "Le\u00b7ben", "frei", "zu", "b\u00fcr\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "l\u00e4\u00dft sich unser Liebstes w\u00fcrgen.", "tokens": ["l\u00e4\u00dft", "sich", "un\u00b7ser", "Liebs\u00b7tes", "w\u00fcr\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Iederman, der wirds gestehn:", "tokens": ["Ie\u00b7der\u00b7man", ",", "der", "wirds", "ge\u00b7stehn", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jahre h\u00e4ufen Schuld und S\u00fcnde.", "tokens": ["Jah\u00b7re", "h\u00e4u\u00b7fen", "Schuld", "und", "S\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wol geschiehet einem Kinde,", "tokens": ["Wol", "ge\u00b7schie\u00b7het", "ei\u00b7nem", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das mit Mute hin kan gehn", "tokens": ["das", "mit", "Mu\u00b7te", "hin", "kan", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "NN", "ADV", "VMFIN", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und den Richter fein darf fragen:", "tokens": ["und", "den", "Rich\u00b7ter", "fein", "darf", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hast du was auf mich zu sagen?", "tokens": ["Hast", "du", "was", "auf", "mich", "zu", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRELS", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.8": {"line.1": {"text": "Und woher entsteht der Graus?", "tokens": ["Und", "wo\u00b7her", "ent\u00b7steht", "der", "Graus", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "ART", "NN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Alten ist das Sterben bitter.", "tokens": ["Al\u00b7ten", "ist", "das", "Ster\u00b7ben", "bit\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kinder fallen wie die Ritter,", "tokens": ["Kin\u00b7der", "fal\u00b7len", "wie", "die", "Rit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die den Tod nur spotten aus.", "tokens": ["die", "den", "Tod", "nur", "spot\u00b7ten", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wert ists, da\u00df man das verlachet,", "tokens": ["Wert", "ists", ",", "da\u00df", "man", "das", "ver\u00b7la\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "KOUS", "PIS", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das nichts f\u00fchlt und f\u00fchlen machet.", "tokens": ["das", "nichts", "f\u00fchlt", "und", "f\u00fch\u00b7len", "ma\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "KON", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wen der H\u00f6chste herzlich meint,", "tokens": ["Wen", "der", "H\u00f6chs\u00b7te", "herz\u00b7lich", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "den versetzt er jung von Jahren", "tokens": ["den", "ver\u00b7setzt", "er", "jung", "von", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "PPER", "ADJD", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "in der Engel reine Scharen.", "tokens": ["in", "der", "En\u00b7gel", "rei\u00b7ne", "Scha\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lachen ist es, das ihr weint,", "tokens": ["La\u00b7chen", "ist", "es", ",", "das", "ihr", "weint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "denn auch ihr begehrt zu kommen,", "tokens": ["denn", "auch", "ihr", "be\u00b7gehrt", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo er hin ist aufgenommen.", "tokens": ["wo", "er", "hin", "ist", "auf\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Wei\u00df er schon nichts von der Welt", "tokens": ["Wei\u00df", "er", "schon", "nichts", "von", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "APPR", "ART", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "und von Gottes Wundern drinnen,", "tokens": ["und", "von", "Got\u00b7tes", "Wun\u00b7dern", "drin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "er hat itzt den Himmel innen,", "tokens": ["er", "hat", "itzt", "den", "Him\u00b7mel", "in\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "welcher Alles in sich h\u00e4lt,", "tokens": ["wel\u00b7cher", "Al\u00b7les", "in", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "gegen den das Tun der Erden", "tokens": ["ge\u00b7gen", "den", "das", "Tun", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ganz f\u00fcr nichts gesch\u00e4tzt mag werden.", "tokens": ["ganz", "f\u00fcr", "nichts", "ge\u00b7sch\u00e4tzt", "mag", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIS", "VVPP", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Gleichwol habt ihr ihn gehabt,", "tokens": ["Gleich\u00b7wol", "habt", "ihr", "ihn", "ge\u00b7habt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VAPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ist er schon hinweg getragen.", "tokens": ["ist", "er", "schon", "hin\u00b7weg", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APZR", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Saget, was ihr habt zu sagen,", "tokens": ["Sa\u00b7get", ",", "was", "ihr", "habt", "zu", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "euer bleibts, was ihr vergrabt.", "tokens": ["eu\u00b7er", "bleibts", ",", "was", "ihr", "ver\u00b7grabt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und was hei\u00dfen doch wir Toren,", "tokens": ["Und", "was", "hei\u00b7\u00dfen", "doch", "wir", "To\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVINF", "KON", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "was uns selbsten sucht, verloren?", "tokens": ["was", "uns", "selbs\u00b7ten", "sucht", ",", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Euer Sohn, der gieng voran,", "tokens": ["Eu\u00b7er", "Sohn", ",", "der", "gieng", "vo\u00b7ran", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "euch die Bahne nur zu brechen", "tokens": ["euch", "die", "Bah\u00b7ne", "nur", "zu", "bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und die Stelle zu besprechen,", "tokens": ["und", "die", "Stel\u00b7le", "zu", "be\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da er stets bei euch sein kan.", "tokens": ["da", "er", "stets", "bei", "euch", "sein", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "In des Himmels hohen Thronen", "tokens": ["In", "des", "Him\u00b7mels", "ho\u00b7hen", "Thro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "solt ihr ewig bei ihm wohnen.", "tokens": ["solt", "ihr", "e\u00b7wig", "bei", "ihm", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Gott, der wei\u00df, wenn, wo und wie", "tokens": ["Gott", ",", "der", "wei\u00df", ",", "wenn", ",", "wo", "und", "wie"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVFIN", "$,", "KOUS", "$,", "PWAV", "KON", "PWAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wir dem Knaben folgen sollen", "tokens": ["wir", "dem", "Kna\u00b7ben", "fol\u00b7gen", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "VVINF", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und f\u00fcr unsren Wucher zollen.", "tokens": ["und", "f\u00fcr", "un\u00b7sren", "Wu\u00b7cher", "zol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die geliebte Seele, die", "tokens": ["Die", "ge\u00b7lieb\u00b7te", "See\u00b7le", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "hat in einem Augenblicke", "tokens": ["hat", "in", "ei\u00b7nem", "Au\u00b7gen\u00b7bli\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Welt und Not und Tod zur\u00fccke.", "tokens": ["Welt", "und", "Not", "und", "Tod", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Wol dir, kleiner Freund, f\u00fcr dich!", "tokens": ["Wol", "dir", ",", "klei\u00b7ner", "Freund", ",", "f\u00fcr", "dich", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ADJA", "NN", "$,", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich bin fertig dir zu folgen,", "tokens": ["Ich", "bin", "fer\u00b7tig", "dir", "zu", "fol\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "will es Gott, noch von der ", "tokens": ["will", "es", "Gott", ",", "noch", "von", "der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "NN", "$,", "ADV", "APPR", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "die mich lange st\u00f6\u00dft von sich,", "tokens": ["die", "mich", "lan\u00b7ge", "st\u00f6\u00dft", "von", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "APPR", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df die Meinen mich empfangen,", "tokens": ["da\u00df", "die", "Mei\u00b7nen", "mich", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo sie vor mir hin sind gangen.", "tokens": ["wo", "sie", "vor", "mir", "hin", "sind", "gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}