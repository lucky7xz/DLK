{"textgrid.poem.53409": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "[sind wir denn noch nicht gnug]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sind wir denn noch nicht gnug", "tokens": ["Sind", "wir", "denn", "noch", "nicht", "gnug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die Zeit her mit genommen?", "tokens": ["Die", "Zeit", "her", "mit", "ge\u00b7nom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APZR", "APPR", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn werden wir doch klug", "tokens": ["Wenn", "wer\u00b7den", "wir", "doch", "klug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Den Straffen zu entkommen?", "tokens": ["Den", "Straf\u00b7fen", "zu", "ent\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es sind drey volle Jahr", "tokens": ["Es", "sind", "drey", "vol\u00b7le", "Jahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "CARD", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Seit uns der Krieg zerrissen,", "tokens": ["Seit", "uns", "der", "Krieg", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da Drangsal und Gefahr", "tokens": ["Da", "Dran\u00b7gsal", "und", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Vns grawsam hart geschmissen.", "tokens": ["Vns", "graw\u00b7sam", "hart", "ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Pest hat uns verheert,", "tokens": ["Die", "Pest", "hat", "uns", "ver\u00b7heert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das Vieh ist uns gestorben,", "tokens": ["Das", "Vieh", "ist", "uns", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mars hat das auffgezehrt", "tokens": ["Mars", "hat", "das", "auff\u00b7ge\u00b7zehrt"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PDS", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Was wir durch M\u00fch erworben,", "tokens": ["Was", "wir", "durch", "M\u00fch", "er\u00b7wor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Himmel ist uns feind,", "tokens": ["Der", "Him\u00b7mel", "ist", "uns", "feind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Daher das Liecht der Sonnen,", "tokens": ["Da\u00b7her", "das", "Liecht", "der", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das uns so selten scheint,", "tokens": ["Das", "uns", "so", "sel\u00b7ten", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Nur Thr\u00e4nen hat gewonnen:", "tokens": ["Nur", "Thr\u00e4\u00b7nen", "hat", "ge\u00b7won\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die Gerste reiffet nicht,", "tokens": ["Die", "Gers\u00b7te", "reif\u00b7fet", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Kein Sommer ist gewesen,", "tokens": ["Kein", "Som\u00b7mer", "ist", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VAPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ist, nun der Herbst anbricht,", "tokens": ["Ist", ",", "nun", "der", "Herbst", "an\u00b7bricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Noch erstlich ein zu lesen,", "tokens": ["Noch", "erst\u00b7lich", "ein", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Selbst die Natur wird la\u00df", "tokens": ["Selbst", "die", "Na\u00b7tur", "wird", "la\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VAFIN", "XY"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Vnd misset Hertz und H\u00e4nde,", "tokens": ["Vnd", "mis\u00b7set", "Hertz", "und", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Jetzt ist es all zu na\u00df,", "tokens": ["Jetzt", "ist", "es", "all", "zu", "na\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "PTKA", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Itzt st\u00fcrmet es ohn ende.", "tokens": ["Itzt", "st\u00fcr\u00b7met", "es", "ohn", "en\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Vnd k\u00f6mpt der Segen ein,", "tokens": ["Vnd", "k\u00f6mpt", "der", "Se\u00b7gen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Wer weis wer ihn verzeeret,", "tokens": ["Wer", "weis", "wer", "ihn", "ver\u00b7zee\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Wild' ist noch nicht rein,", "tokens": ["Die", "Wild'", "ist", "noch", "nicht", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Keydan itzt auch verheeret,", "tokens": ["Key\u00b7dan", "itzt", "auch", "ver\u00b7hee\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das arme LandVolck fleucht", "tokens": ["Das", "ar\u00b7me", "Land", "Volck", "fleucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Zu Vns mit Furcht und Schrecken,", "tokens": ["Zu", "Vns", "mit", "Furcht", "und", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wie, wann der Habicht zeucht,", "tokens": ["Wie", ",", "wann", "der", "Ha\u00b7bicht", "zeucht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Die Tauben sich verstecken.", "tokens": ["Die", "Tau\u00b7ben", "sich", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "F\u00fcr dieser Nachbarschafft", "tokens": ["F\u00fcr", "die\u00b7ser", "Nach\u00b7bar\u00b7schafft"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Hat mir allzeit gegrawet,", "tokens": ["Hat", "mir", "all\u00b7zeit", "ge\u00b7gra\u00b7wet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Kein Leben keine Krafft", "tokens": ["Kein", "Le\u00b7ben", "kei\u00b7ne", "Krafft"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wird schier in mir gechawet,", "tokens": ["Wird", "schier", "in", "mir", "ge\u00b7cha\u00b7wet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Gedenck ich nur daran.", "tokens": ["Ge\u00b7denck", "ich", "nur", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Lasst keinen Fried euch tr\u00e4wmen,", "tokens": ["Lasst", "kei\u00b7nen", "Fried", "euch", "tr\u00e4w\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Kein guttes, eh und wan", "tokens": ["Kein", "gut\u00b7tes", ",", "eh", "und", "wan"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ADJA", "$,", "KOUS", "KON", "PWAV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Sie nicht die Grentzen r\u00e4umen.", "tokens": ["Sie", "nicht", "die", "Grent\u00b7zen", "r\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Von jenem andern Heer", "tokens": ["Von", "je\u00b7nem", "an\u00b7dern", "Heer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Wil ich nicht einmal sagen", "tokens": ["Wil", "ich", "nicht", "ein\u00b7mal", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "VVINF"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Das ietzt zu Land und Meer", "tokens": ["Das", "ietzt", "zu", "Land", "und", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Bekrieget Coppenhagen:", "tokens": ["Be\u00b7krie\u00b7get", "Cop\u00b7pen\u00b7ha\u00b7gen", ":"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "O eine grosse Noht,", "tokens": ["O", "ei\u00b7ne", "gros\u00b7se", "Noht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Darinn wir alle schweben,", "tokens": ["Da\u00b7rinn", "wir", "al\u00b7le", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Gef\u00e4ngnis Tr\u00fcbsal Tod", "tokens": ["Ge\u00b7f\u00e4ng\u00b7nis", "Tr\u00fcb\u00b7sal", "Tod"], "token_info": ["word", "word", "word"], "pos": ["NN", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Die stehn nach unserm Leben.", "tokens": ["Die", "stehn", "nach", "un\u00b7serm", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Vnd wir in dieser Stad", "tokens": ["Vnd", "wir", "in", "die\u00b7ser", "Stad"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Wir k\u00f6nnen uns noch br\u00fcsten,", "tokens": ["Wir", "k\u00f6n\u00b7nen", "uns", "noch", "br\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sind \u00fcbrig fett und satt", "tokens": ["Sind", "\u00fcb\u00b7rig", "fett", "und", "satt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "ADJD", "KON", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Von Hoffart und von L\u00fcsten.", "tokens": ["Von", "Hof\u00b7fart", "und", "von", "L\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Wir schlummern, druckt das Joch", "tokens": ["Wir", "schlum\u00b7mern", ",", "druckt", "das", "Joch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Vns gleich von allen seiten,", "tokens": ["Vns", "gleich", "von", "al\u00b7len", "sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Als w\u00e4ren bey uns noch", "tokens": ["Als", "w\u00e4\u00b7ren", "bey", "uns", "noch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "APPR", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Es lauter g\u00fcldne Zeiten.", "tokens": ["Es", "lau\u00b7ter", "g\u00fcld\u00b7ne", "Zei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "O flieht' mit aller Macht", "tokens": ["O", "flieht'", "mit", "al\u00b7ler", "Macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das Gold und das Geschmeide", "tokens": ["Das", "Gold", "und", "das", "Ge\u00b7schmei\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Leinen-Flieger Tracht,", "tokens": ["Die", "Lei\u00b7nen\u00b7F\u00b7lie\u00b7ger", "Tracht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Vnd geht im Bettel-Kleide,", "tokens": ["Vnd", "geht", "im", "Bet\u00b7tel\u00b7Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr allen wenn ihr nun", "tokens": ["F\u00fcr", "al\u00b7len", "wenn", "ihr", "nun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "KOUS", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Vor ewren Gott wollt tretten,", "tokens": ["Vor", "ew\u00b7ren", "Gott", "wollt", "tret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ihm einen Fu\u00dffall thun", "tokens": ["Ihm", "ei\u00b7nen", "Fu\u00df\u00b7fall", "thun"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Mit Thr\u00e4nen und Gebehten.", "tokens": ["Mit", "Thr\u00e4\u00b7nen", "und", "Ge\u00b7beh\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Vieleicht wird er bewegt", "tokens": ["Vie\u00b7leicht", "wird", "er", "be\u00b7wegt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Vns Gnade zu gewehren,", "tokens": ["Vns", "Gna\u00b7de", "zu", "ge\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als der erbarmen tr\u00e4gt", "tokens": ["Als", "der", "er\u00b7bar\u00b7men", "tr\u00e4gt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "So bald wir uns bekehren:", "tokens": ["So", "bald", "wir", "uns", "be\u00b7keh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wer aber dieses thut", "tokens": ["Wer", "a\u00b7ber", "die\u00b7ses", "thut"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "PDS", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Der hat sich nicht zu kr\u00e4ncken", "tokens": ["Der", "hat", "sich", "nicht", "zu", "kr\u00e4n\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PRF", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wenn auch der Hellen Glut", "tokens": ["Wenn", "auch", "der", "Hel\u00b7len", "Glut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Ihn woltte gar ertr\u00e4ncken.", "tokens": ["Ihn", "wolt\u00b7te", "gar", "er\u00b7tr\u00e4n\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Denn seine Zuversicht", "tokens": ["Denn", "sei\u00b7ne", "Zu\u00b7ver\u00b7sicht"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ist Gott in allen N\u00f6hten,", "tokens": ["Ist", "Gott", "in", "al\u00b7len", "N\u00f6h\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der l\u00e4sst die Seinen nicht", "tokens": ["Der", "l\u00e4sst", "die", "Sei\u00b7nen", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "PPOSS", "PTKNEG"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Auch scheint er sie zu t\u00f6dten,", "tokens": ["Auch", "scheint", "er", "sie", "zu", "t\u00f6d\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ja er nimmt ihrer war", "tokens": ["Ja", "er", "nimmt", "ih\u00b7rer", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "VVFIN", "PPER", "VAFIN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Wie Daniels Gesellen,", "tokens": ["Wie", "Da\u00b7ni\u00b7els", "Ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der keinem nicht ein Har", "tokens": ["Der", "kei\u00b7nem", "nicht", "ein", "Har"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "PTKNEG", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Versengt ward in der Hellen.", "tokens": ["Ver\u00b7sengt", "ward", "in", "der", "Hel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Der weis sich ewer auch,", "tokens": ["Der", "weis", "sich", "e\u00b7wer", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKVZ", "PRF", "ADJD", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Fraw, trewlich anzumassen", "tokens": ["Fraw", ",", "trew\u00b7lich", "an\u00b7zu\u00b7mas\u00b7sen"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "ADJD", "VVIZU"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Seyd ihr nach Glaubens brauch", "tokens": ["Seyd", "ihr", "nach", "Glau\u00b7bens", "brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAIMP", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ihm gantz und gar gelassen:", "tokens": ["Ihm", "gantz", "und", "gar", "ge\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "War ist es, dieser Zeit", "tokens": ["War", "ist", "es", ",", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VAFIN", "PPER", "$,", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ach! umb den Hau\u00dfwirth kommen", "tokens": ["Ach", "!", "umb", "den", "Hau\u00df\u00b7wirth", "kom\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ist nicht geringes Leid,", "tokens": ["Ist", "nicht", "ge\u00b7rin\u00b7ges", "Leid", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Ihr Schutz wird ihr genommen.", "tokens": ["Ihr", "Schutz", "wird", "ihr", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Allein ist Gott nicht mehr?", "tokens": ["Al\u00b7lein", "ist", "Gott", "nicht", "mehr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ihr habt euch vor zu schawen", "tokens": ["Ihr", "habt", "euch", "vor", "zu", "scha\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Damit ihr nicht zu sehr", "tokens": ["Da\u00b7mit", "ihr", "nicht", "zu", "sehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "PTKA", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Auff Fleisch setzt das Vertrawen.", "tokens": ["Auff", "Fleisch", "setzt", "das", "Ver\u00b7tra\u00b7wen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.5": {"text": "Den Meinen sag ich offt", "tokens": ["Den", "Mei\u00b7nen", "sag", "ich", "offt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wenn Kranckheit mich befallen:", "tokens": ["Wenn", "Kran\u00b7ck\u00b7heit", "mich", "be\u00b7fal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Gott sey, auff den ihr hofft,", "tokens": ["Gott", "sey", ",", "auff", "den", "ihr", "hofft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "APPR", "ART", "PPER", "VVFIN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Ergebt euch dem f\u00fcr allen.", "tokens": ["Er\u00b7gebt", "euch", "dem", "f\u00fcr", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "APPR", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Nicht f\u00fchret umb mich Pein", "tokens": ["Nicht", "f\u00fch\u00b7ret", "umb", "mich", "Pein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "APPR", "PPER", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sterb' ich heut oder morgen,", "tokens": ["Sterb'", "ich", "heut", "o\u00b7der", "mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihm bleibt die Ehr' allein", "tokens": ["Ihm", "bleibt", "die", "Ehr'", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Euch besser zu versorgen,", "tokens": ["Euch", "bes\u00b7ser", "zu", "ver\u00b7sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Auff mich nur sehen, heisst", "tokens": ["Auff", "mich", "nur", "se\u00b7hen", ",", "heisst"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPER", "ADV", "VVINF", "$,", "VVFIN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Auff Menschen sich verlassen,", "tokens": ["Auff", "Men\u00b7schen", "sich", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das uns des Herren Geist", "tokens": ["Das", "uns", "des", "Her\u00b7ren", "Geist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Verbohten aller massen.", "tokens": ["Ver\u00b7boh\u00b7ten", "al\u00b7ler", "mas\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}