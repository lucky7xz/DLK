{"textgrid.poem.43637": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Bescheidenheit siegt", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Lerche singt, der Kuckuck schreit,", "tokens": ["Die", "Ler\u00b7che", "singt", ",", "der", "Ku\u00b7ckuck", "schreit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Krieg f\u00fchrt die ganze Welt.", "tokens": ["Krieg", "f\u00fchrt", "die", "gan\u00b7ze", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es f\u00e4ngt nun an ein gro\u00dfer Streit", "tokens": ["Es", "f\u00e4ngt", "nun", "an", "ein", "gro\u00b7\u00dfer", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Wald und Wies' und Feld.", "tokens": ["In", "Wald", "und", "Wies'", "und", "Feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Blumen streiten heftiglich,", "tokens": ["Die", "Blu\u00b7men", "strei\u00b7ten", "hef\u00b7tig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer wohl die Sch\u00f6nste sei;", "tokens": ["Wer", "wohl", "die", "Sch\u00f6ns\u00b7te", "sei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und nur die Rose denkt f\u00fcr sich:", "tokens": ["Und", "nur", "die", "Ro\u00b7se", "denkt", "f\u00fcr", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPR", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist mir einerlei.", "tokens": ["Das", "ist", "mir", "ei\u00b7ner\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und auch die V\u00f6gel streiten sich", "tokens": ["Und", "auch", "die", "V\u00f6\u00b7gel", "strei\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um ihren Sang und Schall.", "tokens": ["Um", "ih\u00b7ren", "Sang", "und", "Schall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was aber soll das k\u00fcmmern mich?", "tokens": ["Was", "a\u00b7ber", "soll", "das", "k\u00fcm\u00b7mern", "mich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "PDS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So sagt die Nachtigall.", "tokens": ["So", "sagt", "die", "Nach\u00b7ti\u00b7gall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da mischet sich der Fr\u00fchling drein:", "tokens": ["Da", "mi\u00b7schet", "sich", "der", "Fr\u00fch\u00b7ling", "drein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was, spricht er, soll der Krieg?", "tokens": ["Was", ",", "spricht", "er", ",", "soll", "der", "Krieg", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "VVFIN", "PPER", "$,", "VMFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Nachtigall und Ros' allein", "tokens": ["Der", "Nach\u00b7ti\u00b7gall", "und", "Ros'", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geb\u00fchrt der Preis und Sieg.", "tokens": ["Ge\u00b7b\u00fchrt", "der", "Preis", "und", "Sieg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "So la\u00dft uns wie die Rose sein", "tokens": ["So", "la\u00dft", "uns", "wie", "die", "Ro\u00b7se", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "KOKOM", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wie die Nachtigall:", "tokens": ["Und", "wie", "die", "Nach\u00b7ti\u00b7gall", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bescheidne Herzen sch\u00f6n und rein,", "tokens": ["Be\u00b7scheid\u00b7ne", "Her\u00b7zen", "sch\u00f6n", "und", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die siegen \u00fcberall.", "tokens": ["Die", "sie\u00b7gen", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}