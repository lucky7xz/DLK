{"dta.poem.12415": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Von Hofleuten .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich sprech, wenn ich nicht l\u00fcge,               ", "tokens": ["Ich", "sprech", ",", "wenn", "ich", "nicht", "l\u00fc\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So sollt ihr glauben mir,", "tokens": ["So", "sollt", "ihr", "glau\u00b7ben", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr habt oft sehen Fliegen,", "tokens": ["Ihr", "habt", "oft", "se\u00b7hen", "Flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das ist ein solches Thier.", "tokens": ["Das", "ist", "ein", "sol\u00b7ches", "Thier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wenn man ein Kost richt anne,", "tokens": ["Wenn", "man", "ein", "Kost", "richt", "an\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie sey saur oder s\u00fc\u00df,", "tokens": ["Sie", "sey", "saur", "o\u00b7der", "s\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sind sie die ersten dranne,", "tokens": ["Sind", "sie", "die", "ers\u00b7ten", "dran\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit H\u00e4nden und mit F\u00fc\u00df.", "tokens": ["Mit", "H\u00e4n\u00b7den", "und", "mit", "F\u00fc\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Kommt dann ein Kr\u00e4mer here", "tokens": ["Kommt", "dann", "ein", "Kr\u00e4\u00b7mer", "he\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit guter Specerey,", "tokens": ["Mit", "gu\u00b7ter", "Spe\u00b7ce\u00b7rey", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Zucker und Latwere,", "tokens": ["Mit", "Zu\u00b7cker", "und", "Lat\u00b7we\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sind sie die ersten frey.", "tokens": ["Sind", "sie", "die", "ers\u00b7ten", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und die das Maul drin schlagen,", "tokens": ["Und", "die", "das", "Maul", "drin", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Versuchens um und um,", "tokens": ["Ver\u00b7su\u00b7chens", "um", "und", "um", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wenn mans dann thut jagen,", "tokens": ["Und", "wenn", "mans", "dann", "thut", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So gebns kein Heller drum.", "tokens": ["So", "gebns", "kein", "Hel\u00b7ler", "drum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wo man hat Bier und Mete,", "tokens": ["Wo", "man", "hat", "Bier", "und", "Me\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da ist den Fliegen wohl,", "tokens": ["Da", "ist", "den", "Flie\u00b7gen", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie kommen ungebeten,", "tokens": ["Sie", "kom\u00b7men", "un\u00b7ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und saufen sich auch voll.", "tokens": ["Und", "sau\u00b7fen", "sich", "auch", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Da\u00df manche thut ertrinken,", "tokens": ["Da\u00df", "man\u00b7che", "thut", "er\u00b7trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Becher und im Glas,", "tokens": ["Im", "Be\u00b7cher", "und", "im", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kommt raus, so thut sie hinken,", "tokens": ["Kommt", "raus", ",", "so", "thut", "sie", "hin\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Kleider sind ihr na\u00df.", "tokens": ["Die", "Klei\u00b7der", "sind", "ihr", "na\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ist einer dann beschoren,", "tokens": ["Ist", "ei\u00b7ner", "dann", "be\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und hat ein kurzes Haar,", "tokens": ["Und", "hat", "ein", "kur\u00b7zes", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Fliegen um ihn bohren,", "tokens": ["Die", "Flie\u00b7gen", "um", "ihn", "boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sieht man im Sommer zwar.", "tokens": ["Sieht", "man", "im", "Som\u00b7mer", "zwar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Es mu\u00df sich einer oft wehren,", "tokens": ["Es", "mu\u00df", "sich", "ei\u00b7ner", "oft", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ART", "ADV", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Will er Fried vor ihn han,", "tokens": ["Will", "er", "Fried", "vor", "ihn", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "APPR", "PPER", "VAFIN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sie thuns F\u00fcrsten und Herren,", "tokens": ["Sie", "thuns", "F\u00fcrs\u00b7ten", "und", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Es hilft daf\u00fcr kein Zaun.", "tokens": ["Es", "hilft", "da\u00b7f\u00fcr", "kein", "Zaun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Auch ich umfliege eine,", "tokens": ["Auch", "ich", "um\u00b7flie\u00b7ge", "ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und sie erwehrt sich mein,", "tokens": ["Und", "sie", "er\u00b7wehrt", "sich", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "PPOSAT", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch find ich sie alleine,", "tokens": ["Doch", "find", "ich", "sie", "al\u00b7lei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So ist sie dennoch mein.", "tokens": ["So", "ist", "sie", "den\u00b7noch", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}