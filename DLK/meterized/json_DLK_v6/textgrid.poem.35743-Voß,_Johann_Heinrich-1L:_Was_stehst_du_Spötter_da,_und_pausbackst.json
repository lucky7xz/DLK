{"textgrid.poem.35743": {"metadata": {"author": {"name": "Vo\u00df, Johann Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was stehst du Sp\u00f6tter da, und pausbackst", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was stehst du Sp\u00f6tter da, und pausbackst", "tokens": ["Was", "stehst", "du", "Sp\u00f6t\u00b7ter", "da", ",", "und", "paus\u00b7backst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schwerreimende Lehroden her?", "tokens": ["Schwer\u00b7rei\u00b7men\u00b7de", "Leh\u00b7ro\u00b7den", "her", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Gieb acht, da\u00df man dich nicht hinausbaxt,", "tokens": ["Gieb", "acht", ",", "da\u00df", "man", "dich", "nicht", "hin\u00b7aus\u00b7baxt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$,", "KOUS", "PIS", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "F\u00fcr dein satyrisches Gepl\u00e4rr.", "tokens": ["F\u00fcr", "dein", "sa\u00b7ty\u00b7ri\u00b7sches", "Ge\u00b7pl\u00e4rr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nur selten liebt den losen Jokus", "tokens": ["Nur", "sel\u00b7ten", "liebt", "den", "lo\u00b7sen", "Jo\u00b7kus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Apolls erhabner Tubaist;", "tokens": ["A\u00b7polls", "er\u00b7hab\u00b7ner", "Tu\u00b7baist", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+---", "measure": "unknown.measure.di"}, "line.3": {"text": "Noch minder h\u00e4lt von Hokuspokus", "tokens": ["Noch", "min\u00b7der", "h\u00e4lt", "von", "Ho\u00b7kus\u00b7po\u00b7kus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "APPR", "NE"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Des ernsten Wodans Urhornist.", "tokens": ["Des", "erns\u00b7ten", "Wo\u00b7dans", "Ur\u00b7hor\u00b7nist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Verla\u00df den stachelvollen Jambos,", "tokens": ["Ver\u00b7la\u00df", "den", "sta\u00b7chel\u00b7vol\u00b7len", "Jam\u00b7bos", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Womit du's Dichterchor bestreitst,", "tokens": ["Wo\u00b7mit", "du's", "Dich\u00b7ter\u00b7chor", "be\u00b7streitst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und leg was bessers auf den Ambos,", "tokens": ["Und", "leg", "was", "bes\u00b7sers", "auf", "den", "Am\u00b7bos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PWS", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das keines Barden Galle reizt!", "tokens": ["Das", "kei\u00b7nes", "Bar\u00b7den", "Gal\u00b7le", "reizt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn mehr als je herrscht jetzt das Faustrecht,", "tokens": ["Denn", "mehr", "als", "je", "herrscht", "jetzt", "das", "Faus\u00b7trecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Sense, Mistfork, Axt und Spie\u00df", "tokens": ["Mit", "Sen\u00b7se", ",", "Mist\u00b7fork", ",", "Axt", "und", "Spie\u00df"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NE", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf dem Parna\u00df; besonders braust recht", "tokens": ["Auf", "dem", "Par\u00b7na\u00df", ";", "be\u00b7son\u00b7ders", "braust", "recht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "ADV", "VVFIN", "ADJD"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Die Knotenkeule der Genies.", "tokens": ["Die", "Kno\u00b7ten\u00b7keu\u00b7le", "der", "Ge\u00b7nies", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Auf! weihe dich dem Dienst der Eypris,", "tokens": ["Auf", "!", "wei\u00b7he", "dich", "dem", "Dienst", "der", "Ey\u00b7pris", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PRF", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und preise mit galantem Ton,", "tokens": ["Und", "prei\u00b7se", "mit", "ga\u00b7lan\u00b7tem", "Ton", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was seit der Sch\u00f6pfung ", "tokens": ["Was", "seit", "der", "Sch\u00f6p\u00b7fung"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Das T\u00e4ndelspiel mit ihrem Sohn.", "tokens": ["Das", "T\u00e4n\u00b7del\u00b7spiel", "mit", "ih\u00b7rem", "Sohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und male deines Liedes Hirtin", "tokens": ["Und", "ma\u00b7le", "dei\u00b7nes", "Lie\u00b7des", "Hir\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit blo\u00dfer Brust und hochgesch\u00fcrzt,", "tokens": ["Mit", "blo\u00b7\u00dfer", "Brust", "und", "hoch\u00b7ge\u00b7sch\u00fcrzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und fein von Welt, wodurch Frau Wirtin", "tokens": ["Und", "fein", "von", "Welt", ",", "wo\u00b7durch", "Frau", "Wir\u00b7tin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "NN", "$,", "PWAV", "NN", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Oft ungew\u00fcrzte Suppen w\u00fcrzt;", "tokens": ["Oft", "un\u00b7ge\u00b7w\u00fcrz\u00b7te", "Sup\u00b7pen", "w\u00fcrzt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sch\u00f6n, wie die Leserin von Tischbein:", "tokens": ["Sch\u00f6n", ",", "wie", "die", "Le\u00b7se\u00b7rin", "von", "Tischbein", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Doch merk! ein M\u00f6pschen statt des Buchs!", "tokens": ["Doch", "merk", "!", "ein", "M\u00f6p\u00b7schen", "statt", "des", "Buchs", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Haar ein Mehltalgturm! mit Fischbein", "tokens": ["Ihr", "Haar", "ein", "Mehl\u00b7talg\u00b7turm", "!", "mit", "Fischbein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "NN", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Umpanzert ihr Insektentwuchs!", "tokens": ["Um\u00b7pan\u00b7zert", "ihr", "In\u00b7sek\u00b7tent\u00b7wuchs", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Sing, wie ihr Hirn von Punsch und Witz dampft,", "tokens": ["Sing", ",", "wie", "ihr", "Hirn", "von", "Pun\u00b7sch", "und", "Witz", "dampft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wie sie im Rausch des Hornget\u00f6ns", "tokens": ["Wie", "sie", "im", "Rausch", "des", "Horn\u00b7ge\u00b7t\u00f6ns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Taumeltanz bacchantisch mit stampft,", "tokens": ["Den", "Tau\u00b7mel\u00b7tanz", "bac\u00b7chan\u00b7tisch", "mit", "stampft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und dann noch endlich dies und jens.", "tokens": ["Und", "dann", "noch", "end\u00b7lich", "dies", "und", "jens", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "PDS", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Von solchem Singsang, fein und sinnreich,", "tokens": ["Von", "sol\u00b7chem", "Sings\u00b7ang", ",", "fein", "und", "sinn\u00b7reich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Druck' in den Almanach was rechts!", "tokens": ["Druck'", "in", "den", "Al\u00b7ma\u00b7nach", "was", "rechts", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PWS", "ADV", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er macht ihn zehnmal mehr gewinnreich,", "tokens": ["Er", "macht", "ihn", "zehn\u00b7mal", "mehr", "ge\u00b7winn\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als all dein \u00c4chzen und Gekr\u00e4chz.", "tokens": ["Als", "all", "dein", "\u00c4ch\u00b7zen", "und", "Ge\u00b7kr\u00e4chz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Von Nova Zembla bis Gibraltar,", "tokens": ["Von", "No\u00b7va", "Zem\u00b7bla", "bis", "Gib\u00b7ral\u00b7tar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "APPR", "NN", "$,"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Von Jura bis nach Astrakan,", "tokens": ["Von", "Ju\u00b7ra", "bis", "nach", "As\u00b7tra\u00b7kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Singt man daraus an Venus' Altar,", "tokens": ["Singt", "man", "da\u00b7raus", "an", "Ve\u00b7nus'", "Al\u00b7tar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PAV", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und subskribiert nach Klopstocks Plan.", "tokens": ["Und", "sub\u00b7skri\u00b7biert", "nach", "Klops\u00b7tocks", "Plan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ihn kauft Murx, Hasenfu\u00df und Gr\u00fctzkopf,", "tokens": ["Ihn", "kauft", "Mu\u00b7rx", ",", "Ha\u00b7sen\u00b7fu\u00df", "und", "Gr\u00fctz\u00b7kopf", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Strohjunker, Schranz' und B\u00fcrgerochs,", "tokens": ["Stroh\u00b7jun\u00b7ker", ",", "Schranz'", "und", "B\u00fcr\u00b7ge\u00b7rochs", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sogar der Seelenk\u00e4ufer Spitzkopf;", "tokens": ["So\u00b7gar", "der", "See\u00b7len\u00b7k\u00e4u\u00b7fer", "Spitz\u00b7kopf", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kurz, Ketzer, Jud' und Orthodox.", "tokens": ["Kurz", ",", "Ket\u00b7zer", ",", "Jud'", "und", "Or\u00b7tho\u00b7dox", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ihn kleidet der verlaffte F\u00e4hndrich", "tokens": ["Ihn", "klei\u00b7det", "der", "ver\u00b7laff\u00b7te", "F\u00e4hn\u00b7drich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr seine Dam' in Gold und Mohr,", "tokens": ["F\u00fcr", "sei\u00b7ne", "Dam'", "in", "Gold", "und", "Mohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und packert, wie ein geiler Entrich", "tokens": ["Und", "pa\u00b7ckert", ",", "wie", "ein", "gei\u00b7ler", "Ent\u00b7rich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr deine s\u00fc\u00dfen Zoten vor.", "tokens": ["Ihr", "dei\u00b7ne", "s\u00fc\u00b7\u00dfen", "Zo\u00b7ten", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sanft hinterm F\u00e4cher grinzt das Fr\u00e4ulein,", "tokens": ["Sanft", "hin\u00b7term", "F\u00e4\u00b7cher", "grinzt", "das", "Fr\u00e4u\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Err\u00f6tet \u2013 nicht, und schn\u00fcffelt schnipp'sch:", "tokens": ["Er\u00b7r\u00f6\u00b7tet", "\u2013", "nicht", ",", "und", "schn\u00fcf\u00b7felt", "schnipp'sch", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "PTKNEG", "$,", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbherr Vo\u00df traktiert uns zwar wie S\u00e4ulein,", "tokens": ["\u00bb", "herr", "Vo\u00df", "trak\u00b7tiert", "uns", "zwar", "wie", "S\u00e4u\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "VVFIN", "PPER", "ADV", "KOKOM", "NN", "$,"], "meter": "+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Doch wie er's thut, die Art ist h\u00fcbsch.\u00ab", "tokens": ["Doch", "wie", "er's", "thut", ",", "die", "Art", "ist", "h\u00fcbsch", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "PIS", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Der Herold der Journalenfama", "tokens": ["Der", "He\u00b7rold", "der", "Jour\u00b7na\u00b7len\u00b7fa\u00b7ma"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Posaunt das Werklein deines Geists;", "tokens": ["Po\u00b7saunt", "das", "Wer\u00b7klein", "dei\u00b7nes", "Geists", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Selbst des Katheders Dalailama,", "tokens": ["Selbst", "des", "Ka\u00b7the\u00b7ders", "Da\u00b7lai\u00b7la\u00b7ma", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Des Kot die Purschen fressen, preist's.", "tokens": ["Des", "Kot", "die", "Pur\u00b7schen", "fres\u00b7sen", ",", "preist'", "s."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "abbreviation"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$,", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Hast du von diesen Leuten Kundschaft?", "tokens": ["Hast", "du", "von", "die\u00b7sen", "Leu\u00b7ten", "Kund\u00b7schaft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Am Pindus stand, lorbeerumgr\u00fcnt,", "tokens": ["Am", "Pin\u00b7dus", "stand", ",", "lor\u00b7bee\u00b7rum\u00b7gr\u00fcnt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vordem ein Stall f\u00fcr Ph\u00f6bus' Hundschaft,", "tokens": ["Vor\u00b7dem", "ein", "Stall", "f\u00fcr", "Ph\u00f6\u00b7bus'", "Hund\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die ihm als Hirten einst gedient.", "tokens": ["Die", "ihm", "als", "Hir\u00b7ten", "einst", "ge\u00b7dient", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOUS", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Klang vom Gebirg der Musen Paian,", "tokens": ["Klang", "vom", "Ge\u00b7birg", "der", "Mu\u00b7sen", "Pai\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "NE", "$,"], "meter": "+--+-+---", "measure": "iambic.tri.invert"}, "line.2": {"text": "Gleich H\u00e4ndels oder Bachs Musik;", "tokens": ["Gleich", "H\u00e4n\u00b7dels", "o\u00b7der", "Bachs", "Mu\u00b7sik", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So ging im Stall ein Zeterschrei an", "tokens": ["So", "ging", "im", "Stall", "ein", "Ze\u00b7ter\u00b7schrei", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "ART", "NN", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von grimmigbellender Kritik.", "tokens": ["Von", "grim\u00b7mig\u00b7bel\u00b7len\u00b7der", "Kri\u00b7tik", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wenn unter Marsyas' Anf\u00fchrung", "tokens": ["Wenn", "un\u00b7ter", "Mar\u00b7syas'", "An\u00b7f\u00fch\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NE", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Ein Faunenchor dann aufpfiff; hu!", "tokens": ["Ein", "Fau\u00b7nen\u00b7chor", "dann", "auf\u00b7pfiff", ";", "hu", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$.", "XY", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie laut heult' ihm, voll tiefer R\u00fchrung,", "tokens": ["Wie", "laut", "heult'", "ihm", ",", "voll", "tie\u00b7fer", "R\u00fch\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Kuppel ihren Beifall zu!", "tokens": ["Die", "Kup\u00b7pel", "ih\u00b7ren", "Bei\u00b7fall", "zu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Oft brannte schon der Zorn Apollos;", "tokens": ["Oft", "brann\u00b7te", "schon", "der", "Zorn", "A\u00b7pol\u00b7los", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Er nahm die bleigef\u00fcllte Knut',", "tokens": ["Er", "nahm", "die", "blei\u00b7ge\u00b7f\u00fcll\u00b7te", "Knut'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schlug aufs Rabenaas f\u00fcr toll los;", "tokens": ["Und", "schlug", "aufs", "Ra\u00b7be\u00b7naas", "f\u00fcr", "toll", "los", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "APPR", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der ganze Hundsstall schwamm in Blut.", "tokens": ["Der", "gan\u00b7ze", "Hunds\u00b7stall", "schwamm", "in", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Doch alles schien ihm zu gelind', und", "tokens": ["Doch", "al\u00b7les", "schien", "ihm", "zu", "ge\u00b7lind'", ",", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "VVFIN", "PPER", "PTKA", "ADJD", "$,", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verwandelt ward das Rabenaas.", "tokens": ["Ver\u00b7wan\u00b7delt", "ward", "das", "Ra\u00b7be\u00b7naas", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Professorm\u00e4\u00dfig stellt' ein Windhund", "tokens": ["Pro\u00b7fes\u00b7sor\u00b7m\u00e4\u00b7\u00dfig", "stellt'", "ein", "Wind\u00b7hund"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich auf die Hinterbein', und las:", "tokens": ["Sich", "auf", "die", "Hin\u00b7ter\u00b7bein'", ",", "und", "las", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "\u00bbsehr wertgesch\u00e4tzte Herrn! Das wichtigst'", "tokens": ["\u00bb", "sehr", "wert\u00b7ge\u00b7sch\u00e4tz\u00b7te", "Herrn", "!", "Das", "wich\u00b7tigst'"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "ADV", "ADJA", "NN", "$.", "PDS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und erste Prolegomenon", "tokens": ["Und", "ers\u00b7te", "Pro\u00b7le\u00b7go\u00b7me\u00b7non"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist nun wohl die baldm\u00f6glichstrichtigst-", "tokens": ["Ist", "nun", "wohl", "die", "bald\u00b7m\u00f6g\u00b7lich\u00b7strich\u00b7tigst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "e ... hauf! ... ", "tokens": ["e", "...", "hauf", "!", "..."], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["NE", "$(", "PTKVZ", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.21": {"line.1": {"text": "Dann thut er wie Apolls Prophet dick,", "tokens": ["Dann", "thut", "er", "wie", "A\u00b7polls", "Pro\u00b7phet", "dick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "NE", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Paukt auf sein Pult, und zeiget, bauz!", "tokens": ["Paukt", "auf", "sein", "Pult", ",", "und", "zei\u00b7get", ",", "bauz", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdes Dichters Leitstern sei \u00c4sthetik!\u00ab", "tokens": ["\u00bb", "des", "Dich\u00b7ters", "Leits\u00b7tern", "sei", "\u00c4s\u00b7the\u00b7tik", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "NN", "VAFIN", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und bespa\u00dfvogelts und besauts.", "tokens": ["Und", "be\u00b7spa\u00df\u00b7vo\u00b7gelts", "und", "be\u00b7sauts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.22": {"line.1": {"text": "Ein alter hagrer Mops voll Griesgram", "tokens": ["Ein", "al\u00b7ter", "hag\u00b7rer", "Mops", "voll", "Gries\u00b7gram"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bleibt noch von Kopf und Pfot' ein Mops,", "tokens": ["Bleibt", "noch", "von", "Kopf", "und", "Pfot'", "ein", "Mops", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bleibt noch den Werken des Genies gram;", "tokens": ["Bleibt", "noch", "den", "Wer\u00b7ken", "des", "Ge\u00b7nies", "gram", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wird Ausrufer Schimpfs und Lobs.", "tokens": ["Und", "wird", "Aus\u00b7ru\u00b7fer", "Schimpfs", "und", "Lobs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Schimpf bellt er beim Gesang des Orpheus;", "tokens": ["Schimpf", "bellt", "er", "beim", "Ge\u00b7sang", "des", "Or\u00b7pheus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPRART", "NN", "ART", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer sein bierschenkenhaft Gelei'r,", "tokens": ["Wer", "sein", "bier\u00b7schen\u00b7ken\u00b7haft", "Ge\u00b7lei'r", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Fix, wie der Musikant im Dorf, wei\u00df,", "tokens": ["Fix", ",", "wie", "der", "Mu\u00b7si\u00b7kant", "im", "Dorf", ",", "wei\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem lobheult Mops wie all der Gei'r!", "tokens": ["Dem", "lob\u00b7heult", "Mops", "wie", "all", "der", "Gei'r", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "KOKOM", "PIAT", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Die G\u00e4nsespul' in rascher Hundspfot',", "tokens": ["Die", "G\u00e4n\u00b7se\u00b7spul'", "in", "ra\u00b7scher", "Hunds\u00b7pfot'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Krizkrazt im Hui er sein Journal.", "tokens": ["Kriz\u00b7krazt", "im", "Hui", "er", "sein", "Jour\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "FM", "PPER", "PPOSAT", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Daher kriegt' er den Namen Hundsfott;", "tokens": ["Da\u00b7her", "kriegt'", "er", "den", "Na\u00b7men", "Hunds\u00b7fott", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Jetzt braucht man noch das Beiwort, kahl.", "tokens": ["Jetzt", "braucht", "man", "noch", "das", "Bei\u00b7wort", ",", "kahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}