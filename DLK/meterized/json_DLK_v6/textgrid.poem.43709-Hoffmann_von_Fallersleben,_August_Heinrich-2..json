{"textgrid.poem.43709": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir hatten schon lange d'rauf geharrt,", "tokens": ["Wir", "hat\u00b7ten", "schon", "lan\u00b7ge", "d'\u00b7rauf", "ge\u00b7harrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PAV", "VVPP", "$,"], "meter": "-+--+----+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df der Teich mal abgelassen ward.", "tokens": ["Da\u00df", "der", "Teich", "mal", "ab\u00b7ge\u00b7las\u00b7sen", "ward", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Das ist nun endlich gestern gescheh'n", "tokens": ["Das", "ist", "nun", "end\u00b7lich", "ge\u00b7stern", "ge\u00b7scheh'n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "ADV", "VVPP"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und wir k\u00f6nnen heute zum Fischen geh'n.", "tokens": ["Und", "wir", "k\u00f6n\u00b7nen", "heu\u00b7te", "zum", "Fi\u00b7schen", "geh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "PPER", "VMFIN", "ADV", "APPRART", "NN", "VVFIN", "NE"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Sobald man gesenkt das Netz in den Teich,", "tokens": ["So\u00b7bald", "man", "ge\u00b7senkt", "das", "Netz", "in", "den", "Teich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVPP", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Beginnt auch das Fischen alsogleich.", "tokens": ["Be\u00b7ginnt", "auch", "das", "Fi\u00b7schen", "al\u00b7so\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir Kinder d\u00fcrfen auch nehmen Theil,", "tokens": ["Wir", "Kin\u00b7der", "d\u00fcr\u00b7fen", "auch", "neh\u00b7men", "Theil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VMFIN", "ADV", "VVINF", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wir ziehen mit an dem gro\u00dfen Seil,", "tokens": ["Wir", "zie\u00b7hen", "mit", "an", "dem", "gro\u00b7\u00dfen", "Seil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und werfen Stein' ins Wasser und schlagen", "tokens": ["Und", "wer\u00b7fen", "Stein'", "ins", "Was\u00b7ser", "und", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NE", "APPRART", "NN", "KON", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Mit Gerten hinein, die Fische zu jagen,", "tokens": ["Mit", "Ger\u00b7ten", "hin\u00b7ein", ",", "die", "Fi\u00b7sche", "zu", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Da\u00df keiner entschl\u00fcpft und Gro\u00df und Klein", "tokens": ["Da\u00df", "kei\u00b7ner", "ent\u00b7schl\u00fcpft", "und", "Gro\u00df", "und", "Klein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVPP", "KON", "NE", "KON", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Spazieren all' in das Netz hinein.", "tokens": ["Spa\u00b7zie\u00b7ren", "all'", "in", "das", "Netz", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}}}}