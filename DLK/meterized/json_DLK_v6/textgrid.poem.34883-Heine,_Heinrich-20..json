{"textgrid.poem.34883": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "20.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir schlafen ganz, wie Brutus schlief \u2013", "tokens": ["Wir", "schla\u00b7fen", "ganz", ",", "wie", "Bru\u00b7tus", "schlief", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "NE", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch jener erwachte und bohrte tief", "tokens": ["Doch", "je\u00b7ner", "er\u00b7wach\u00b7te", "und", "bohr\u00b7te", "tief"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "KON", "VVFIN", "ADJD"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "In C\u00e4sars Brust das kalte Messer!", "tokens": ["In", "C\u00e4\u00b7sars", "Brust", "das", "kal\u00b7te", "Mes\u00b7ser", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die R\u00f6mer waren Tyrannenfresser.", "tokens": ["Die", "R\u00f6\u00b7mer", "wa\u00b7ren", "Ty\u00b7ran\u00b7nen\u00b7fres\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Wir sind keine R\u00f6mer, wir rauchen Tabak.", "tokens": ["Wir", "sind", "kei\u00b7ne", "R\u00f6\u00b7mer", ",", "wir", "rau\u00b7chen", "Ta\u00b7bak", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VVFIN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ein jedes Volk hat seinen Geschmack,", "tokens": ["Ein", "je\u00b7des", "Volk", "hat", "sei\u00b7nen", "Ge\u00b7schmack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ein jedes Volk hat seine Gr\u00f6\u00dfe;", "tokens": ["Ein", "je\u00b7des", "Volk", "hat", "sei\u00b7ne", "Gr\u00f6\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In Schwaben kocht man die besten Kl\u00f6\u00dfe.", "tokens": ["In", "Schwa\u00b7ben", "kocht", "man", "die", "bes\u00b7ten", "Kl\u00f6\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Wir sind Germanen, gem\u00fctlich und brav,", "tokens": ["Wir", "sind", "Ger\u00b7ma\u00b7nen", ",", "ge\u00b7m\u00fct\u00b7lich", "und", "brav", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir schlafen gesunden Pflanzenschlaf,", "tokens": ["Wir", "schla\u00b7fen", "ge\u00b7sun\u00b7den", "Pflan\u00b7zen\u00b7schlaf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wenn wir erwachen, pflegt uns zu d\u00fcrsten,", "tokens": ["Und", "wenn", "wir", "er\u00b7wa\u00b7chen", ",", "pflegt", "uns", "zu", "d\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVINF", "$,", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch nicht nach dem Blute unserer F\u00fcrsten.", "tokens": ["Doch", "nicht", "nach", "dem", "Blu\u00b7te", "un\u00b7se\u00b7rer", "F\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Wir sind so treu wie Eichenholz,", "tokens": ["Wir", "sind", "so", "treu", "wie", "Ei\u00b7chen\u00b7holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch Lindenholz, drauf sind wir stolz;", "tokens": ["Auch", "Lin\u00b7den\u00b7holz", ",", "drauf", "sind", "wir", "stolz", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "PAV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Land der Eichen und der Linden", "tokens": ["Im", "Land", "der", "Ei\u00b7chen", "und", "der", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "KON", "ART", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wird niemals sich ein Brutus finden.", "tokens": ["Wird", "nie\u00b7mals", "sich", "ein", "Bru\u00b7tus", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PRF", "ART", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und wenn auch ein Brutus unter uns w\u00e4r,", "tokens": ["Und", "wenn", "auch", "ein", "Bru\u00b7tus", "un\u00b7ter", "uns", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "NE", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den C\u00e4sar f\u00e4nd er nimmermehr,", "tokens": ["Den", "C\u00e4\u00b7sar", "f\u00e4nd", "er", "nim\u00b7mer\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vergeblich w\u00fcrd er den C\u00e4sar suchen;", "tokens": ["Ver\u00b7geb\u00b7lich", "w\u00fcrd", "er", "den", "C\u00e4\u00b7sar", "su\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ART", "NE", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wir haben gute Pfefferkuchen.", "tokens": ["Wir", "ha\u00b7ben", "gu\u00b7te", "Pfef\u00b7fer\u00b7ku\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wir haben sechsunddrei\u00dfig Herrn", "tokens": ["Wir", "ha\u00b7ben", "sech\u00b7sund\u00b7drei\u00b7\u00dfig", "Herrn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(ist nicht zuviel!), und einen Stern", "tokens": ["(", "ist", "nicht", "zu\u00b7viel", "!", ")", ",", "und", "ei\u00b7nen", "Stern"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word"], "pos": ["$(", "VAFIN", "PTKNEG", "ADV", "$.", "$(", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Tr\u00e4gt jeder sch\u00fctzend auf seinem Herzen,", "tokens": ["Tr\u00e4gt", "je\u00b7der", "sch\u00fct\u00b7zend", "auf", "sei\u00b7nem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und er braucht nicht zu f\u00fcrchten die Iden des M\u00e4rzen.", "tokens": ["Und", "er", "braucht", "nicht", "zu", "f\u00fcrch\u00b7ten", "die", "I\u00b7den", "des", "M\u00e4r\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "PTKZU", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}}, "stanza.7": {"line.1": {"text": "Wir nennen sie V\u00e4ter, und Vaterland", "tokens": ["Wir", "nen\u00b7nen", "sie", "V\u00e4\u00b7ter", ",", "und", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "KON", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Benennen wir dasjenige Land,", "tokens": ["Be\u00b7nen\u00b7nen", "wir", "das\u00b7je\u00b7ni\u00b7ge", "Land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PDAT", "NN", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Das erbeigent\u00fcmlich geh\u00f6rt den F\u00fcrsten;", "tokens": ["Das", "er\u00b7bei\u00b7gen\u00b7t\u00fcm\u00b7lich", "ge\u00b7h\u00f6rt", "den", "F\u00fcrs\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wir lieben auch Sauerkraut mit W\u00fcrsten.", "tokens": ["Wir", "lie\u00b7ben", "auch", "Sau\u00b7er\u00b7kraut", "mit", "W\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Wenn unser Vater spazierengeht,", "tokens": ["Wenn", "un\u00b7ser", "Va\u00b7ter", "spa\u00b7zie\u00b7ren\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ziehn wir den Hut mit Piet\u00e4t;", "tokens": ["Ziehn", "wir", "den", "Hut", "mit", "Pi\u00b7e\u00b7t\u00e4t", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Deutschland, die fromme Kinderstube,", "tokens": ["Deutschland", ",", "die", "from\u00b7me", "Kin\u00b7der\u00b7stu\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist keine r\u00f6mische M\u00f6rdergrube.", "tokens": ["Ist", "kei\u00b7ne", "r\u00f6\u00b7mi\u00b7sche", "M\u00f6r\u00b7der\u00b7gru\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}