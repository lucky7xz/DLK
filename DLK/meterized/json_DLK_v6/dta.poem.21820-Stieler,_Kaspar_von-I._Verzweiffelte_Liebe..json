{"dta.poem.21820": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "I.  \n  Verzweiffelte Liebe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Hjer ist das Herz/ sto\u00df/ Morta/ nach der Linken!", "tokens": ["Hjer", "ist", "das", "Herz", "/", "sto\u00df", "/", "Mor\u00b7ta", "/", "nach", "der", "Lin\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$(", "VVFIN", "$(", "NE", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Parzen-Heer/", "tokens": ["Pa\u00b7rzen\u00b7Heer", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "indehm die m\u00fcden Augen sinken:", "tokens": ["in\u00b7dehm", "die", "m\u00fc\u00b7den", "Au\u00b7gen", "sin\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ist doch schon mein Geist", "tokens": ["ist", "doch", "schon", "mein", "Geist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "au\u00df d", "tokens": ["au\u00df", "d"], "token_info": ["word", "word"], "pos": ["APPR", "XY"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Du s\u00fcsses Sterben/", "tokens": ["Du", "s\u00fcs\u00b7ses", "Ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "was wirstu mir vor Ruh erwerben!", "tokens": ["was", "wirs\u00b7tu", "mir", "vor", "Ruh", "er\u00b7wer\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Acheron!", "tokens": ["A\u00b7che\u00b7ron", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "ich wil auff dir darvon:", "tokens": ["ich", "wil", "auff", "dir", "dar\u00b7von", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Was hab\u2019 ich arme", "tokens": ["Was", "hab'", "ich", "ar\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "zu hoffen sonst/ als tausend Todes-M\u00fch.", "tokens": ["zu", "hof\u00b7fen", "sonst", "/", "als", "tau\u00b7send", "To\u00b7des\u00b7M\u00fch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVFIN", "ADV", "$(", "KOKOM", "CARD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Denn hat sie sich/ die Wilde/ satt gerochen/", "tokens": ["Denn", "hat", "sie", "sich", "/", "die", "Wil\u00b7de", "/", "satt", "ge\u00b7ro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PRF", "$(", "ART", "NN", "$(", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wenn der Todt", "tokens": ["wenn", "der", "Todt"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "mein all u", "tokens": ["mein", "all", "u"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "PIAT", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Stellt das K", "tokens": ["Stellt", "das", "K"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "la\u00dft betr\u00fcbtes Weinen sein!", "tokens": ["la\u00dft", "be\u00b7tr\u00fcb\u00b7tes", "Wei\u00b7nen", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wer Lieben kennet", "tokens": ["Wer", "Lie\u00b7ben", "ken\u00b7net"], "token_info": ["word", "word", "word"], "pos": ["PWS", "ADJA", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "wie sie das arme Leben brennet", "tokens": ["wie", "sie", "das", "ar\u00b7me", "Le\u00b7ben", "bren\u00b7net"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "wird mit Lust", "tokens": ["wird", "mit", "Lust"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "das Blut au\u00df warmer Brust", "tokens": ["das", "Blut", "au\u00df", "war\u00b7mer", "Brust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "zusamt dem rohtem Herzen sehn", "tokens": ["zu\u00b7samt", "dem", "roh\u00b7tem", "Her\u00b7zen", "sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "au\u00df de\u00df verliebten Bruders K\u00f6rper gehn.", "tokens": ["au\u00df", "de\u00df", "ver\u00b7lieb\u00b7ten", "Bru\u00b7ders", "K\u00f6r\u00b7per", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ach! h\u00e4tte mich der Lebens-Schwestern eine", "tokens": ["Ach", "!", "h\u00e4t\u00b7te", "mich", "der", "Le\u00b7bens\u00b7Schwes\u00b7tern", "ei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "ART", "NN", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "umgebracht", "tokens": ["um\u00b7ge\u00b7bracht"], "token_info": ["word"], "pos": ["VVPP"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "die erste Nacht", "tokens": ["die", "ers\u00b7te", "Nacht"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "als ich noch ohn Vernunfft und kleine", "tokens": ["als", "ich", "noch", "ohn", "Ver\u00b7nunfft", "und", "klei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "an der Mutter sog", "tokens": ["an", "der", "Mut\u00b7ter", "sog"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "und mein Elend nicht erwog.", "tokens": ["und", "mein", "E\u00b7lend", "nicht", "er\u00b7wog", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist di\u00df der Frommen", "tokens": ["Ist", "di\u00df", "der", "From\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "da\u00df ich zu Jahren bin gekommen/", "tokens": ["da\u00df", "ich", "zu", "Jah\u00b7ren", "bin", "ge\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "und unvergn\u00fcgt zu sein?", "tokens": ["und", "un\u00b7ver\u00b7gn\u00fcgt", "zu", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Ach Liebe! herber Nater-stich?", "tokens": ["Ach", "Lie\u00b7be", "!", "her\u00b7ber", "Na\u00b7ter\u00b7stich", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "ADV", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ach b\u00f6se Liebe/ wor zu bringstu mich?", "tokens": ["Ach", "b\u00f6\u00b7se", "Lie\u00b7be", "/", "wor", "zu", "brings\u00b7tu", "mich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$(", "NE", "PTKZU", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Doch wird es ihr noch einst vergolten werden:", "tokens": ["Doch", "wird", "es", "ihr", "noch", "einst", "ver\u00b7gol\u00b7ten", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ist gewi\u00df", "tokens": ["ist", "ge\u00b7wi\u00df"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "nur Nemesis", "tokens": ["nur", "Ne\u00b7me\u00b7sis"], "token_info": ["word", "word"], "pos": ["ADV", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "alhier/ und schaut das Tuhn der Erden:", "tokens": ["al\u00b7hier", "/", "und", "schaut", "das", "Tuhn", "der", "Er\u00b7den", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ist nur Venus nicht", "tokens": ["ist", "nur", "Ve\u00b7nus", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "PTKNEG"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "und ihr Amor ein Gedicht.", "tokens": ["und", "ihr", "A\u00b7mor", "ein", "Ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Gedenke/ Sch\u00f6ne", "tokens": ["Ge\u00b7den\u00b7ke", "/", "Sch\u00f6\u00b7ne"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$(", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "was ich iezt sterbend dir erwehne", "tokens": ["was", "ich", "iezt", "ster\u00b7bend", "dir", "er\u00b7weh\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Reu und Schmerz", "tokens": ["Reu", "und", "Schmerz"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "wird einst dein eisern Herz", "tokens": ["wird", "einst", "dein", "ei\u00b7sern", "Herz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "ganz unbarmherzig greiffen an.", "tokens": ["ganz", "un\u00b7barm\u00b7her\u00b7zig", "greif\u00b7fen", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Denn/ denke/ da\u00df du mir es auch getahn.", "tokens": ["Denn", "/", "den\u00b7ke", "/", "da\u00df", "du", "mir", "es", "auch", "ge\u00b7tahn", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "$(", "KOUS", "PPER", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}