{"textgrid.poem.60702": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nichts wiegt wie ein Geheimnis schwer,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nichts wiegt wie ein Geheimnis schwer,", "tokens": ["Nichts", "wiegt", "wie", "ein", "Ge\u00b7heim\u00b7nis", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOKOM", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Drum k\u00f6nnen's Frauen nicht weit tragen.", "tokens": ["Drum", "k\u00f6n\u00b7nen's", "Frau\u00b7en", "nicht", "weit", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch wei\u00df ich auch von manchem Mann zu sagen:", "tokens": ["Doch", "wei\u00df", "ich", "auch", "von", "man\u00b7chem", "Mann", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Er gleicht darin den Frauen sehr.", "tokens": ["Er", "gleicht", "da\u00b7rin", "den", "Frau\u00b7en", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Um seine zu erproben, rief ein Mann", "tokens": ["Um", "sei\u00b7ne", "zu", "er\u00b7pro\u00b7ben", ",", "rief", "ein", "Mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "PTKZU", "VVINF", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Des Nachts an ihrer Seite: \u00bbGott! Was fang ich an?", "tokens": ["Des", "Nachts", "an", "ih\u00b7rer", "Sei\u00b7te", ":", "\u00bb", "Gott", "!", "Was", "fang", "ich", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "$.", "$(", "NN", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich kann nicht mehr \u2013 oh, es zerrei\u00dft mich fast!\u00ab", "tokens": ["Ich", "kann", "nicht", "mehr", "\u2013", "oh", ",", "es", "zer\u00b7rei\u00dft", "mich", "fast", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "$(", "FM", "$,", "PPER", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u00bbwas denn?\u00ab \u00bbIch mu\u00df ein Ei geb\u00e4ren!\u00ab \u00bbWie, ein Ei?\u00ab", "tokens": ["\u00bb", "was", "denn", "?", "\u00ab", "\u00bb", "Ich", "mu\u00df", "ein", "Ei", "ge\u00b7b\u00e4\u00b7ren", "!", "\u00ab", "\u00bb", "Wie", ",", "ein", "Ei", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "ADV", "$.", "$(", "$(", "PPER", "VMFIN", "ART", "NN", "VVPP", "$.", "$(", "$(", "PWAV", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbja, welche Last!", "tokens": ["\u00bb", "ja", ",", "wel\u00b7che", "Last", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "PWAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Sieh her, wie frisch und neu!", "tokens": ["Sieh", "her", ",", "wie", "frisch", "und", "neu", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "PWAV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nur bitt ich dich, erz\u00e4hl es nicht herum,", "tokens": ["Nur", "bitt", "ich", "dich", ",", "er\u00b7z\u00e4hl", "es", "nicht", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denn da\u00df man sagt, ich sei ein Huhn, ist mir zu dumm.\u00ab", "tokens": ["Denn", "da\u00df", "man", "sagt", ",", "ich", "sei", "ein", "Huhn", ",", "ist", "mir", "zu", "dumm", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "$,", "VAFIN", "PPER", "PTKA", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die junge Frau, der dieser Fall so neu", "tokens": ["Die", "jun\u00b7ge", "Frau", ",", "der", "die\u00b7ser", "Fall", "so", "neu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PDAT", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wie manches andre von den Ehedingen,", "tokens": ["Wie", "man\u00b7ches", "and\u00b7re", "von", "den", "E\u00b7he\u00b7din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Glaubt auch an diesen und verspricht zu schweigen.", "tokens": ["Glaubt", "auch", "an", "die\u00b7sen", "und", "ver\u00b7spricht", "zu", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PDAT", "KON", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Kaum aber kam der Tag herbei,", "tokens": ["Kaum", "a\u00b7ber", "kam", "der", "Tag", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Da kann sie nicht mehr sich bezwingen,", "tokens": ["Da", "kann", "sie", "nicht", "mehr", "sich", "be\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "ADV", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Es brennt sie, aus dem Bett zu steigen", "tokens": ["Es", "brennt", "sie", ",", "aus", "dem", "Bett", "zu", "stei\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und hinzugehn zur Nachbarin.", "tokens": ["Und", "hin\u00b7zu\u00b7gehn", "zur", "Nach\u00b7ba\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Sie sagt ihr: \u00bbAch, Gevatterin,", "tokens": ["Sie", "sagt", "ihr", ":", "\u00bb", "Ach", ",", "Ge\u00b7vat\u00b7te\u00b7rin", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "$(", "ITJ", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Ach denkt nur, was geschehen!", "tokens": ["Ach", "denkt", "nur", ",", "was", "ge\u00b7sche\u00b7hen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "$,", "PWS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Doch redet's nicht herum, sonst t\u00e4t's mir schlecht ergehen.", "tokens": ["Doch", "re\u00b7det's", "nicht", "he\u00b7rum", ",", "sonst", "t\u00e4t's", "mir", "schlecht", "er\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Mein Mann hat heute Nacht", "tokens": ["Mein", "Mann", "hat", "heu\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Ein Ei zur Welt gebracht,", "tokens": ["Ein", "Ei", "zur", "Welt", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Das ist so gro\u00df wie vier.", "tokens": ["Das", "ist", "so", "gro\u00df", "wie", "vier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "KOKOM", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.22": {"text": "Nur bitt ich Euch, versprechet mir,", "tokens": ["Nur", "bitt", "ich", "Euch", ",", "ver\u00b7spre\u00b7chet", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Da\u00df Ihr dar\u00fcber schweigt.\u00ab", "tokens": ["Da\u00df", "Ihr", "da\u00b7r\u00fc\u00b7ber", "schweigt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PAV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Zu gro\u00dfe Angst. Nat\u00fcrlich bin ich stumm.\u00ab", "tokens": ["Zu", "gro\u00b7\u00dfe", "Angst", ".", "Na\u00b7t\u00fcr\u00b7lich", "bin", "ich", "stumm", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Die Frau des Eierlegers geht nach Haus.", "tokens": ["Die", "Frau", "des", "Ei\u00b7er\u00b7le\u00b7gers", "geht", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Die andre klatscht nat\u00fcrlich gleich herum", "tokens": ["Die", "and\u00b7re", "klatscht", "na\u00b7t\u00fcr\u00b7lich", "gleich", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ADV", "ADV", "APZR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Und tr\u00e4gt's nach zehn verschiednen Seiten aus.", "tokens": ["Und", "tr\u00e4gt's", "nach", "zehn", "ver\u00b7schied\u00b7nen", "Sei\u00b7ten", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "CARD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Anstatt von ", "tokens": ["An\u00b7statt", "von"], "token_info": ["word", "word"], "pos": ["NN", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.29": {"text": "Doch das schien nicht genug, denn schon die n\u00e4chste Frau", "tokens": ["Doch", "das", "schien", "nicht", "ge\u00b7nug", ",", "denn", "schon", "die", "n\u00e4chs\u00b7te", "Frau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "PTKNEG", "ADV", "$,", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.30": {"text": "Erz\u00e4hlt von ", "tokens": ["Er\u00b7z\u00e4hlt", "von"], "token_info": ["word", "word"], "pos": ["VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.31": {"text": "So nimmt es keine sehr genau.", "tokens": ["So", "nimmt", "es", "kei\u00b7ne", "sehr", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Die Zahl der Eier steigt und steigt,", "tokens": ["Die", "Zahl", "der", "Ei\u00b7er", "steigt", "und", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Von Mund zu Munde w\u00e4chst sie an \u2013", "tokens": ["Von", "Mund", "zu", "Mun\u00b7de", "w\u00e4chst", "sie", "an", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Was Wunder dann,", "tokens": ["Was", "Wun\u00b7der", "dann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.35": {"text": "Da\u00df sie, als sich die Abendsonne neigt,", "tokens": ["Da\u00df", "sie", ",", "als", "sich", "die", "A\u00b7bend\u00b7son\u00b7ne", "neigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Bereits an hundert zeigt.", "tokens": ["Be\u00b7reits", "an", "hun\u00b7dert", "zeigt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}