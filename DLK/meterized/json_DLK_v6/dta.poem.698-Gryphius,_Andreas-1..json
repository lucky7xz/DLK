{"dta.poem.698": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Es ist vergebens Laelia da\u00df man acht ", "tokens": ["Es", "ist", "ver\u00b7ge\u00b7bens", "Lae\u00b7lia", "da\u00df", "man", "acht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "NE", "KOUS", "PIS", "CARD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Augen glantz der trefflichen ", "tokens": ["Der", "Au\u00b7gen", "glantz", "der", "treff\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ART", "ADJA"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.2": {"line.1": {"text": "Der Purpur ", "tokens": ["Der", "Pur\u00b7pur"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Sey m\u00e4chtig dieses Hertz zufangen!", "tokens": ["Sey", "m\u00e4ch\u00b7tig", "die\u00b7ses", "Hertz", "zu\u00b7fan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nein! ewre Lippen sind nur umbsonst bem\u00fcht!", "tokens": ["Nein", "!", "ew\u00b7re", "Lip\u00b7pen", "sind", "nur", "um\u00b7bsonst", "be\u00b7m\u00fcht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPOSAT", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ob gleich di\u00df Antlitz gleich einer Rose bl\u00fcht:", "tokens": ["Ob", "gleich", "di\u00df", "Ant\u00b7litz", "gleich", "ei\u00b7ner", "Ro\u00b7se", "bl\u00fcht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDS", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ob gleich das \u00fcbers\u00fcsse singen", "tokens": ["Ob", "gleich", "das", "\u00fc\u00b7ber\u00b7s\u00fcs\u00b7se", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch m\u00e4chtig L\u00f6wen zu bezwingen!", "tokens": ["Auch", "m\u00e4ch\u00b7tig", "L\u00f6\u00b7wen", "zu", "be\u00b7zwin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sch\u00f6nste Syren/ Der lieblichen Seiten klang/", "tokens": ["Sch\u00f6ns\u00b7te", "Sy\u00b7ren", "/", "Der", "lieb\u00b7li\u00b7chen", "Sei\u00b7ten", "klang", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die marmor Brust/ der lustigen ", "tokens": ["Die", "mar\u00b7mor", "Brust", "/", "der", "lus\u00b7ti\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Di\u00df ", "tokens": ["Di\u00df"], "token_info": ["word"], "pos": ["PDS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Der Leib dem kein gesch\u00f6pff zu gleichen; ", "tokens": ["Der", "Leib", "dem", "kein", "ge\u00b7sch\u00f6pff", "zu", "glei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der H\u00e4nde Schnee/ der m\u00e4chtigen Arme bandt", "tokens": ["Der", "H\u00e4n\u00b7de", "Schnee", "/", "der", "m\u00e4ch\u00b7ti\u00b7gen", "Ar\u00b7me", "bandt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$(", "ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sind viel zu nichtig/ wenn nicht das werthe Pfandt/", "tokens": ["Sind", "viel", "zu", "nich\u00b7tig", "/", "wenn", "nicht", "das", "wert\u00b7he", "Pfandt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKA", "ADJD", "$(", "KOUS", "PTKNEG", "PDS", "VVFIN", "NN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das nur de\u00df Himmels gunst au\u00dftheilet/", "tokens": ["Das", "nur", "de\u00df", "Him\u00b7mels", "gunst", "au\u00df\u00b7thei\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Tugend ew\u2019re schwachheit heilet.", "tokens": ["Die", "Tu\u00b7gend", "ew'\u00b7re", "schwach\u00b7heit", "hei\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die werthe Tugend Laelia bleibt vnd steht! ", "tokens": ["Die", "wert\u00b7he", "Tu\u00b7gend", "Lae\u00b7lia", "bleibt", "vnd", "steht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "NE", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn nun die sch\u00f6nheit al\u00df lichter blitz vergeht", "tokens": ["Wenn", "nun", "die", "sch\u00f6n\u00b7heit", "al\u00df", "lich\u00b7ter", "blitz", "ver\u00b7geht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ADJD", "ADJD", "VVFIN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Vnd wenn die beyden ", "tokens": ["Vnd", "wenn", "die", "bey\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "PIAT"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Vnd wenn der C\u00f6rper wird zur Leichen.", "tokens": ["Vnd", "wenn", "der", "C\u00f6r\u00b7per", "wird", "zur", "Lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VAFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die steckt mich jetzt mit sch\u00fctternden flam&#769;en an! ", "tokens": ["Die", "steckt", "mich", "jetzt", "mit", "sch\u00fct\u00b7tern\u00b7den", "flam", "&#769;", "en", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "FM", "FM", "FM", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die macht da\u00df ich mich selbst nicht regiren kan", "tokens": ["Die", "macht", "da\u00df", "ich", "mich", "selbst", "nicht", "re\u00b7gi\u00b7ren", "kan"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "VMFIN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die zwingt mich au\u00df mir selbst zu reissen/ ", "tokens": ["Die", "zwingt", "mich", "au\u00df", "mir", "selbst", "zu", "reis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd was nicht ewig/ hin zuschmeissen.", "tokens": ["Vnd", "was", "nicht", "e\u00b7wig", "/", "hin", "zu\u00b7schmeis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "ADJD", "$(", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Weg welt! weg Erden! nichtige Phantasie!", "tokens": ["Weg", "welt", "!", "weg", "Er\u00b7den", "!", "nich\u00b7ti\u00b7ge", "Phan\u00b7ta\u00b7sie", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "ADV", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Weg ", "tokens": ["Weg"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Weg was mein Geist zuvor geliebet!", "tokens": ["Weg", "was", "mein", "Geist", "zu\u00b7vor", "ge\u00b7lie\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRELS", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weg was mein schlechtes Hertz betr\u00fcbet.", "tokens": ["Weg", "was", "mein", "schlech\u00b7tes", "Hertz", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRELS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.9": {"line.1": {"text": "Gelehrte Thorheit! k\u00f6stlicher vnverstandt!", "tokens": ["Ge\u00b7lehr\u00b7te", "Thor\u00b7heit", "!", "k\u00f6st\u00b7li\u00b7cher", "vn\u00b7ver\u00b7standt", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ADJD", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vor mein begehren! jtzt nun du nur bekandt", "tokens": ["Vor", "mein", "be\u00b7geh\u00b7ren", "!", "jtzt", "nun", "du", "nur", "be\u00b7kandt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "VVINF", "$.", "ADV", "ADV", "PPER", "ADV", "ADJD"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mein Schmertz vnd Jrren/ geh' bey seitte: ", "tokens": ["Mein", "Schmertz", "vnd", "Jr\u00b7ren", "/", "geh'", "bey", "seit\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$(", "VVFIN", "APPR", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Eh\u2019 ich mich ferner mehr verleitte.", "tokens": ["Eh'", "ich", "mich", "fer\u00b7ner", "mehr", "ver\u00b7leit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Weg meine Lauten! was wird das singen seyn/ ", "tokens": ["Weg", "mei\u00b7ne", "Lau\u00b7ten", "!", "was", "wird", "das", "sin\u00b7gen", "seyn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$.", "PWS", "VAFIN", "ART", "ADJA", "VAINF", "$("], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wenn man die Glieder setzt in die gruben eyn?", "tokens": ["Wenn", "man", "die", "Glie\u00b7der", "setzt", "in", "die", "gru\u00b7ben", "eyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wird jemand was ich schreibe lesen;", "tokens": ["Wird", "je\u00b7mand", "was", "ich", "schrei\u00b7be", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PWS", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wann ich werd\u2019 in der grufft verwesen?", "tokens": ["Wann", "ich", "werd'", "in", "der", "grufft", "ver\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Blo\u00df vnd alleine nach dem ", "tokens": ["Blo\u00df", "vnd", "al\u00b7lei\u00b7ne", "nach", "dem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ADV", "APPR", "ART"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Da\u00df mich ein sterblich Mensch geehret: ", "tokens": ["Da\u00df", "mich", "ein", "sterb\u00b7lich", "Mensch", "ge\u00b7eh\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd mir mit anmuth zu geh\u00f6ret?", "tokens": ["Vnd", "mir", "mit", "an\u00b7muth", "zu", "ge\u00b7h\u00f6\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Die Tugend bricht das schreckliche Netz entzwey: ", "tokens": ["Die", "Tu\u00b7gend", "bricht", "das", "schreck\u00b7li\u00b7che", "Netz", "ent\u00b7zwey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Trotzt Tod vnd ", "tokens": ["Trotzt", "Tod", "vnd"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "NN", "KON"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Sie lehrt was jrrdisch ist verlachen.", "tokens": ["Sie", "lehrt", "was", "jrr\u00b7disch", "ist", "ver\u00b7la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd kan vn\u00df gleich den G\u00f6ttern machen. ", "tokens": ["Vnd", "kan", "vn\u00df", "gleich", "den", "G\u00f6t\u00b7tern", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}