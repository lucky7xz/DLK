{"textgrid.poem.34996": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1649\u20131793\u2013????", "genre": "verse", "period": "N.A.", "pub_year": 1852, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Briten zeigten sich sehr r\u00fcde", "tokens": ["Die", "Bri\u00b7ten", "zeig\u00b7ten", "sich", "sehr", "r\u00fc\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ungeschliffen als Regizide.", "tokens": ["Und", "un\u00b7ge\u00b7schlif\u00b7fen", "als", "Re\u00b7gi\u00b7zi\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Schlaflos hat K\u00f6nig Karl verbracht", "tokens": ["Schlaf\u00b7los", "hat", "K\u00f6\u00b7nig", "Karl", "ver\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "NN", "NE", "VVPP"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Whitehall seine letzte Nacht.", "tokens": ["In", "Whi\u00b7te\u00b7hall", "sei\u00b7ne", "letz\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Vor seinem Fenster sang der Spott", "tokens": ["Vor", "sei\u00b7nem", "Fens\u00b7ter", "sang", "der", "Spott"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ward geh\u00e4mmert an seinem Schafott.", "tokens": ["Und", "ward", "ge\u00b7h\u00e4m\u00b7mert", "an", "sei\u00b7nem", "Scha\u00b7fott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Viel h\u00f6flicher nicht die Franzosen waren.", "tokens": ["Viel", "h\u00f6f\u00b7li\u00b7cher", "nicht", "die", "Fran\u00b7zo\u00b7sen", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKNEG", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In einem Fiaker haben diese", "tokens": ["In", "ei\u00b7nem", "Fi\u00b7a\u00b7ker", "ha\u00b7ben", "die\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "PDS"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den Ludwig Capet zum Richtplatz gefahren;", "tokens": ["Den", "Lud\u00b7wig", "Ca\u00b7pet", "zum", "Richt\u00b7platz", "ge\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie gaben ihm keine Cal\u00e8che de Remise,", "tokens": ["Sie", "ga\u00b7ben", "ihm", "kei\u00b7ne", "Ca\u00b7l\u00e8che", "de", "Re\u00b7mi\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "NE", "NE", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wie nach der alten Etikette", "tokens": ["Wie", "nach", "der", "al\u00b7ten", "E\u00b7ti\u00b7ket\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Majest\u00e4t geb\u00fchret h\u00e4tte.", "tokens": ["Der", "Ma\u00b7jes\u00b7t\u00e4t", "ge\u00b7b\u00fch\u00b7ret", "h\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Noch schlimmer erging's der Marie Antoinette,", "tokens": ["Noch", "schlim\u00b7mer", "er\u00b7ging's", "der", "Ma\u00b7rie", "An\u00b7to\u00b7i\u00b7net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NE", "NE", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Denn sie bekam nur eine Charrette;", "tokens": ["Denn", "sie", "be\u00b7kam", "nur", "ei\u00b7ne", "Char\u00b7ret\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Statt Chambellan und Dame d'Atour", "tokens": ["Statt", "Cham\u00b7bel\u00b7lan", "und", "Da\u00b7me", "d'\u00b7A\u00b7tour"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NE", "KON", "NN", "NE"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "Ein Sansculotte mit ihr fuhr.", "tokens": ["Ein", "San\u00b7scu\u00b7lot\u00b7te", "mit", "ihr", "fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Witwe Capet hob h\u00f6hnisch und schnippe", "tokens": ["Die", "Wit\u00b7we", "Ca\u00b7pet", "hob", "h\u00f6h\u00b7nisch", "und", "schnip\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VVFIN", "ADJD", "KON", "VVFIN"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Die dicke habsburgische Unterlippe.", "tokens": ["Die", "di\u00b7cke", "habs\u00b7bur\u00b7gi\u00b7sche", "Un\u00b7ter\u00b7lip\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Franzosen und Briten sind von Natur", "tokens": ["Fran\u00b7zo\u00b7sen", "und", "Bri\u00b7ten", "sind", "von", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VAFIN", "APPR", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ganz ohne Gem\u00fct; Gem\u00fct hat nur", "tokens": ["Ganz", "oh\u00b7ne", "Ge\u00b7m\u00fct", ";", "Ge\u00b7m\u00fct", "hat", "nur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "$.", "VVPP", "VAFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Deutsche, er wird gem\u00fctlich bleiben", "tokens": ["Der", "Deut\u00b7sche", ",", "er", "wird", "ge\u00b7m\u00fct\u00b7lich", "blei\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PPER", "VAFIN", "ADJD", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sogar im terroristischen Treiben.", "tokens": ["So\u00b7gar", "im", "ter\u00b7ro\u00b7ris\u00b7ti\u00b7schen", "Trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Der Deutsche wird die Majest\u00e4t", "tokens": ["Der", "Deut\u00b7sche", "wird", "die", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Behandeln stets mit Piet\u00e4t.", "tokens": ["Be\u00b7han\u00b7deln", "stets", "mit", "Pi\u00b7e\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In einer sechssp\u00e4nnigen Hofkarosse,", "tokens": ["In", "ei\u00b7ner", "sechs\u00b7sp\u00e4n\u00b7ni\u00b7gen", "Hof\u00b7ka\u00b7ros\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Schwarz panaschiert und beflort die Rosse,", "tokens": ["Schwarz", "pa\u00b7na\u00b7schiert", "und", "be\u00b7flort", "die", "Ros\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Hoch auf dem Bock mit der Trauerpeitsche", "tokens": ["Hoch", "auf", "dem", "Bock", "mit", "der", "Trau\u00b7er\u00b7peit\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NE", "APPR", "ART", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Der weinende Kutscher \u2013 so wird der deutsche", "tokens": ["Der", "wei\u00b7nen\u00b7de", "Kut\u00b7scher", "\u2013", "so", "wird", "der", "deut\u00b7sche"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "VAFIN", "ART", "ADJA"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Monarch einst nach dem Richtplatz kutschiert", "tokens": ["Mon\u00b7arch", "einst", "nach", "dem", "Richt\u00b7platz", "kut\u00b7schiert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "Und untert\u00e4nigst guillotiniert.", "tokens": ["Und", "un\u00b7ter\u00b7t\u00e4\u00b7nigst", "guil\u00b7lo\u00b7ti\u00b7niert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}