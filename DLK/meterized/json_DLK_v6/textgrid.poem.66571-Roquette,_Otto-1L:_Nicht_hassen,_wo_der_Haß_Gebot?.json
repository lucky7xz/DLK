{"textgrid.poem.66571": {"metadata": {"author": {"name": "Roquette, Otto", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nicht hassen, wo der Ha\u00df Gebot?", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nicht hassen, wo der Ha\u00df Gebot?", "tokens": ["Nicht", "has\u00b7sen", ",", "wo", "der", "Ha\u00df", "Ge\u00b7bot", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,", "PWAV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Angst sich bergen vor kindischer Schuld?", "tokens": ["In", "Angst", "sich", "ber\u00b7gen", "vor", "kin\u00b7di\u00b7scher", "Schuld", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das Leben verk\u00fcmmern Loth f\u00fcr Loth \u2013", "tokens": ["Das", "Le\u00b7ben", "ver\u00b7k\u00fcm\u00b7mern", "Loth", "f\u00fcr", "Loth", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "O wundersame Eselsgeduld!", "tokens": ["O", "wun\u00b7der\u00b7sa\u00b7me", "E\u00b7sels\u00b7ge\u00b7duld", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Kommt mir nur nicht mit Sittlichkeit her,", "tokens": ["Kommt", "mir", "nur", "nicht", "mit", "Sitt\u00b7lich\u00b7keit", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und heuchlerischem Moralgeschw\u00e4nz!", "tokens": ["Und", "heuch\u00b7le\u00b7ri\u00b7schem", "Mo\u00b7ral\u00b7ge\u00b7schw\u00e4nz", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist doch eure ganze Sittlichkeitslehr'", "tokens": ["Ist", "doch", "eu\u00b7re", "gan\u00b7ze", "Sitt\u00b7lich\u00b7keits\u00b7lehr'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Nur eitle Bl\u00e4hung der Impotenz!", "tokens": ["Nur", "eit\u00b7le", "Bl\u00e4\u00b7hung", "der", "Im\u00b7po\u00b7tenz", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Der Katechismus eurer Moral", "tokens": ["Der", "Ka\u00b7te\u00b7chis\u00b7mus", "eu\u00b7rer", "Mo\u00b7ral"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Am Schn\u00fcrchen schnurrt er von Pflicht zu Pflicht,", "tokens": ["Am", "Schn\u00fcr\u00b7chen", "schnurrt", "er", "von", "Pflicht", "zu", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das Leben fordert viel hundertmal", "tokens": ["Das", "Le\u00b7ben", "for\u00b7dert", "viel", "hun\u00b7dert\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sich zu w\u00e4rmen, zu leuchten mit eignem Licht.", "tokens": ["Sich", "zu", "w\u00e4r\u00b7men", ",", "zu", "leuch\u00b7ten", "mit", "eig\u00b7nem", "Licht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "$,", "PTKZU", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}}}}}