{"textgrid.poem.53385": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Fahr fort, O K\u00fcnstler, als du thust,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fahr fort, O K\u00fcnstler, als du thust,", "tokens": ["Fahr", "fort", ",", "O", "K\u00fcnst\u00b7ler", ",", "als", "du", "thust", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "NE", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und streich die Geige deine Lust,", "tokens": ["Und", "streich", "die", "Gei\u00b7ge", "dei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df h\u00f6ren alle Liebligkeiten,", "tokens": ["La\u00df", "h\u00f6\u00b7ren", "al\u00b7le", "Lieb\u00b7lig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Hertz im Leibe h\u00fcpfft und singt", "tokens": ["Mein", "Hertz", "im", "Lei\u00b7be", "h\u00fcpfft", "und", "singt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wie dein schneller Bogen springt", "tokens": ["So", "wie", "dein", "schnel\u00b7ler", "Bo\u00b7gen", "springt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In dem er blitzet auff den Seiten.", "tokens": ["In", "dem", "er", "blit\u00b7zet", "auff", "den", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Jetzt f\u00e4hrst du l\u00e4ngsam vnd gelind", "tokens": ["Jetzt", "f\u00e4hrst", "du", "l\u00e4ng\u00b7sam", "vnd", "ge\u00b7lind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gleich wie ein Schiff mit sanfftem Wind", "tokens": ["Gleich", "wie", "ein", "Schiff", "mit", "sanff\u00b7tem", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Herauff k\u00f6mpt in dem stillen Pregel,", "tokens": ["Her\u00b7auff", "k\u00f6mpt", "in", "dem", "stil\u00b7len", "Pre\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jetzt f\u00fchrest du geschwindern Zug,", "tokens": ["Jetzt", "f\u00fch\u00b7rest", "du", "ge\u00b7schwin\u00b7dern", "Zug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Jetzt einen Adler-schnellen Flug", "tokens": ["Jetzt", "ei\u00b7nen", "Ad\u00b7ler\u00b7schnel\u00b7len", "Flug"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gleich wie ein Ostwind-volles Segel.", "tokens": ["Gleich", "wie", "ein", "Ost\u00b7win\u00b7dvol\u00b7les", "Se\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du hast mein Hertz in deiner Macht,", "tokens": ["Du", "hast", "mein", "Hertz", "in", "dei\u00b7ner", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich lache wird von dir gelacht,", "tokens": ["Ich", "la\u00b7che", "wird", "von", "dir", "ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd klage hebst du an zu klagen,", "tokens": ["Vnd", "kla\u00b7ge", "hebst", "du", "an", "zu", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du brauchst zu wunderliche Zier,", "tokens": ["Du", "brauchst", "zu", "wun\u00b7der\u00b7li\u00b7che", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich warlich weis nicht was ich schier", "tokens": ["Ich", "war\u00b7lich", "weis", "nicht", "was", "ich", "schier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "PTKVZ", "PTKNEG", "PWS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sol von den s\u00fcssen Strichen sagen.", "tokens": ["Sol", "von", "den", "s\u00fcs\u00b7sen", "Stri\u00b7chen", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Das Holtz, das Schaf-ged\u00e4rm, das Har", "tokens": ["Das", "Holtz", ",", "das", "Schaf\u00b7ge\u00b7d\u00e4rm", ",", "das", "Har"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So vor der k\u00fchnen Rosse war", "tokens": ["So", "vor", "der", "k\u00fch\u00b7nen", "Ros\u00b7se", "war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kan das die Anmuht von sich geben?", "tokens": ["Kan", "das", "die", "An\u00b7muht", "von", "sich", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sag ist er menschlich dein Gesang,", "tokens": ["Sag", "ist", "er", "menschlich", "dein", "Ge\u00b7sang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und r\u00fchrt der angenehme Klang", "tokens": ["Und", "r\u00fchrt", "der", "an\u00b7ge\u00b7neh\u00b7me", "Klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu uns herab aus jenem Leben?", "tokens": ["Zu", "uns", "her\u00b7ab", "aus", "je\u00b7nem", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nun la\u00df erschallen Berg und Thal", "tokens": ["Nun", "la\u00df", "er\u00b7schal\u00b7len", "Berg", "und", "Thal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch das Geschrey der Nachtigall,", "tokens": ["Durch", "das", "Ge\u00b7schrey", "der", "Nach\u00b7ti\u00b7gall", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie wird sich, h\u00f6rt sie dich, verkriechen,", "tokens": ["Sie", "wird", "sich", ",", "h\u00f6rt", "sie", "dich", ",", "ver\u00b7krie\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "$,", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich la\u00df' Amphions K\u00fcnste seyn,", "tokens": ["Ich", "la\u00df'", "Am\u00b7phi\u00b7ons", "K\u00fcns\u00b7te", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du h\u00e4ttest besser Holtz und Stein", "tokens": ["Du", "h\u00e4t\u00b7test", "bes\u00b7ser", "Holtz", "und", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Beseelt, wenn du nur angestrichen.", "tokens": ["Be\u00b7seelt", ",", "wenn", "du", "nur", "an\u00b7ge\u00b7stri\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nicht Orpheus, du du h\u00e4ttest vor", "tokens": ["Nicht", "Or\u00b7pheus", ",", "du", "du", "h\u00e4t\u00b7test", "vor"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "NE", "$,", "PPER", "PPER", "VAFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ertheilt den Felsen Sinn und Ohr", "tokens": ["Er\u00b7theilt", "den", "Fel\u00b7sen", "Sinn", "und", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd dir zu folgen sie bewogen,", "tokens": ["Vnd", "dir", "zu", "fol\u00b7gen", "sie", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du h\u00e4ttest Brunnen, Wild und Wald", "tokens": ["Du", "h\u00e4t\u00b7test", "Brun\u00b7nen", ",", "Wild", "und", "Wald"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd Str\u00f6me durch geschwinden halt", "tokens": ["Vnd", "Str\u00f6\u00b7me", "durch", "ge\u00b7schwin\u00b7den", "halt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und unges\u00e4umt dir nachgezogen.", "tokens": ["Und", "un\u00b7ge\u00b7s\u00e4umt", "dir", "nach\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sonst prangt mit Noah Engelland,", "tokens": ["Sonst", "prangt", "mit", "Noah", "En\u00b7gel\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "NE", "$,"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Mit Constantin der Seynen Rand,", "tokens": ["Mit", "Con\u00b7stan\u00b7tin", "der", "Sey\u00b7nen", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Von Schopen hab' ich viel vernommen,", "tokens": ["Von", "Scho\u00b7pen", "hab'", "ich", "viel", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind Bonamente Bertaly", "tokens": ["Sind", "Bo\u00b7na\u00b7men\u00b7te", "Ber\u00b7ta\u00b7ly"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "NN", "NE"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.5": {"text": "Mehr Fockart, Allegrand allhie", "tokens": ["Mehr", "Foc\u00b7kart", ",", "Al\u00b7le\u00b7grand", "all\u00b7hie"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIS", "KOKOM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mir jemals zu Gesichte kommen?", "tokens": ["Mir", "je\u00b7mals", "zu", "Ge\u00b7sich\u00b7te", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dr\u00fcmb stell' ich auch mein Vrtheil ein.", "tokens": ["Dr\u00fcmb", "stell'", "ich", "auch", "mein", "Vrtheil", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo aber sie noch besser seyn,", "tokens": ["Wo", "a\u00b7ber", "sie", "noch", "bes\u00b7ser", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hoch doch wird die Kunst dann steigen?", "tokens": ["Wie", "hoch", "doch", "wird", "die", "Kunst", "dann", "stei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "VAFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vor diesem trieb ich auch die\u00df Spil,", "tokens": ["Vor", "die\u00b7sem", "trieb", "ich", "auch", "die\u00df", "Spil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ADV", "PDS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun h\u00f6r' ich dich und schweige still,", "tokens": ["Nun", "h\u00f6r'", "ich", "dich", "und", "schwei\u00b7ge", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd werde nie f\u00fcr dir mehr geigen.", "tokens": ["Vnd", "wer\u00b7de", "nie", "f\u00fcr", "dir", "mehr", "gei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch spieltest du auch noch so sch\u00f6n", "tokens": ["Doch", "spiel\u00b7test", "du", "auch", "noch", "so", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wirst du durch dein Leid-Geth\u00f6n", "tokens": ["So", "wirst", "du", "durch", "dein", "Lei\u00b7dGet\u00b7h\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Menschen Noht nicht gnug beweinen,", "tokens": ["Der", "Men\u00b7schen", "Noht", "nicht", "gnug", "be\u00b7wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bedenck ich sie, wird Spiel und Schertz", "tokens": ["Be\u00b7denck", "ich", "sie", ",", "wird", "Spiel", "und", "Schertz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPER", "$,", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mir stracks ein Eckel, und mein Hertz", "tokens": ["Mir", "stracks", "ein", "E\u00b7ckel", ",", "und", "mein", "Hertz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "NN", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist bey den Seiten wie aus Steinen.", "tokens": ["Ist", "bey", "den", "Sei\u00b7ten", "wie", "aus", "Stei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die schn\u00f6de Lust der Welt ist Dunst,", "tokens": ["Die", "schn\u00f6\u00b7de", "Lust", "der", "Welt", "ist", "Dunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd schwinget so wie deine Kunst", "tokens": ["Vnd", "schwin\u00b7get", "so", "wie", "dei\u00b7ne", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "KOKOM", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nimmst du die Hand nur von der Seiten,", "tokens": ["Nimmst", "du", "die", "Hand", "nur", "von", "der", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Ding kan in die L\u00e4nge stehn,", "tokens": ["Kein", "Ding", "kan", "in", "die", "L\u00e4n\u00b7ge", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gewalt und Herligheit vergehn", "tokens": ["Ge\u00b7walt", "und", "Her\u00b7lig\u00b7heit", "ver\u00b7gehn"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch den geschwinden Lauff der Zeiten.", "tokens": ["Durch", "den", "ge\u00b7schwin\u00b7den", "Lauff", "der", "Zei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wie offt ich dieses auch beklagt,", "tokens": ["Wie", "offt", "ich", "die\u00b7ses", "auch", "be\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PDS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch dennoch, alsobald es tagt,", "tokens": ["Noch", "den\u00b7noch", ",", "al\u00b7so\u00b7bald", "es", "tagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So steigt mir newe Noht zu Ohren:", "tokens": ["So", "steigt", "mir", "ne\u00b7we", "Noht", "zu", "Oh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ich h\u00f6r' es offt mit Thr\u00e4nen an,", "tokens": ["Ich", "h\u00f6r'", "es", "offt", "mit", "Thr\u00e4\u00b7nen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die hat jhr Kind, die jhren Mann", "tokens": ["Die", "hat", "jhr", "Kind", ",", "die", "jhren", "Mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Vnd der sein liebstes Hertz verlohren.", "tokens": ["Vnd", "der", "sein", "liebs\u00b7tes", "Hertz", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ich schreibe von des Todes Macht", "tokens": ["Ich", "schrei\u00b7be", "von", "des", "To\u00b7des", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schier alle Stunde Tag und Nacht,", "tokens": ["Schier", "al\u00b7le", "Stun\u00b7de", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Reim-Brunn wil mir nicht mehr taugen,", "tokens": ["Mein", "Reim\u00b7Brunn", "wil", "mir", "nicht", "mehr", "tau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Adern sind fast alle leer,", "tokens": ["Die", "A\u00b7dern", "sind", "fast", "al\u00b7le", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die H\u00e4nde werden mir zu schwer,", "tokens": ["Die", "H\u00e4n\u00b7de", "wer\u00b7den", "mir", "zu", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Thr\u00e4n ist mehr in meinen Augen.", "tokens": ["Kein", "Thr\u00e4n", "ist", "mehr", "in", "mei\u00b7nen", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Da Noht und Tod doch nie gebricht,", "tokens": ["Da", "Noht", "und", "Tod", "doch", "nie", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ach da\u00df, Herr Schlieben, mein Geticht", "tokens": ["Ach", "da\u00df", ",", "Herr", "Schlie\u00b7ben", ",", "mein", "Ge\u00b7ticht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "KOUS", "$,", "NN", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch ewer Hau\u00df jetzt mu\u00df ber\u00fchren.", "tokens": ["Auch", "e\u00b7wer", "Hau\u00df", "jetzt", "mu\u00df", "be\u00b7r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da alles sich verh\u00fcllt in Pein,", "tokens": ["Da", "al\u00b7les", "sich", "ver\u00b7h\u00fcllt", "in", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gerdawen geht betr\u00fcbt herein,", "tokens": ["Ger\u00b7da\u00b7wen", "geht", "be\u00b7tr\u00fcbt", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd Wandlack mu\u00df nur Klage f\u00fchren.", "tokens": ["Vnd", "Wand\u00b7lack", "mu\u00df", "nur", "Kla\u00b7ge", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Sie ewres Hertzens Liecht vnd Krohn'", "tokens": ["Sie", "ew\u00b7res", "Hert\u00b7zens", "Liecht", "vnd", "Krohn'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd ewrer strengen Tugend Lohn", "tokens": ["Vnd", "ew\u00b7rer", "stren\u00b7gen", "Tu\u00b7gend", "Lohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird jetzt, o Jammer! hin getragen,", "tokens": ["Wird", "jetzt", ",", "o", "Jam\u00b7mer", "!", "hin", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "FM", "NN", "$.", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht durch ein hohes Alter mat,", "tokens": ["Nicht", "durch", "ein", "ho\u00b7hes", "Al\u00b7ter", "mat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd dieses eiteln Lebens sat,", "tokens": ["Vnd", "die\u00b7ses", "ei\u00b7teln", "Le\u00b7bens", "sat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach nein in ihren besten Tagen.", "tokens": ["Ach", "nein", "in", "ih\u00b7ren", "bes\u00b7ten", "Ta\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Was hat der Edlen doch gefehlt?", "tokens": ["Was", "hat", "der", "Ed\u00b7len", "doch", "ge\u00b7fehlt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was war vmb sie nicht ausserwehlt?", "tokens": ["Was", "war", "vmb", "sie", "nicht", "aus\u00b7ser\u00b7wehlt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gebrach es jhr an thewren Ahnen,", "tokens": ["Ge\u00b7brach", "es", "jhr", "an", "thew\u00b7ren", "Ah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War jhres edlen Stammes Pracht", "tokens": ["War", "jhres", "ed\u00b7len", "Stam\u00b7mes", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht was der Mond' vmb helle Nacht?", "tokens": ["Nicht", "was", "der", "Mond'", "vmb", "hel\u00b7le", "Nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PWS", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd zeigt jhr Hau\u00df nicht Schild noch Fahnen?", "tokens": ["Vnd", "zeigt", "jhr", "Hau\u00df", "nicht", "Schild", "noch", "Fah\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKNEG", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Fehlt' jhr ein Tugendhaffter Muht,", "tokens": ["Fehlt'", "jhr", "ein", "Tu\u00b7gend\u00b7haff\u00b7ter", "Muht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gl\u00fcck, Ehre, Lust, Gestalt vnd Gut", "tokens": ["Gl\u00fcck", ",", "Eh\u00b7re", ",", "Lust", ",", "Ge\u00b7stalt", "vnd", "Gut"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Daher sie h\u00e4tt' jhr Hertz gefressen?", "tokens": ["Da\u00b7her", "sie", "h\u00e4tt'", "jhr", "Hertz", "ge\u00b7fres\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nein, Gut, Geburt, Verstand vnd Stand", "tokens": ["Nein", ",", "Gut", ",", "Ge\u00b7burt", ",", "Ver\u00b7stand", "vnd", "Stand"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADJD", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd alles war mit reicher Hand", "tokens": ["Vnd", "al\u00b7les", "war", "mit", "rei\u00b7cher", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr von dem Himmel zugemessen.", "tokens": ["Ihr", "von", "dem", "Him\u00b7mel", "zu\u00b7ge\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Vnd, Herr, insonderheit wart ihr", "tokens": ["Vnd", ",", "Herr", ",", "in\u00b7son\u00b7der\u00b7heit", "wart", "ihr"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "ADV", "VVFIN", "PPER"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ihr Hertz und aller Gn\u00fcge Zier,", "tokens": ["Ihr", "Hertz", "und", "al\u00b7ler", "Gn\u00fc\u00b7ge", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gleich wie ihr Sie geliebt habt wieder,", "tokens": ["Gleich", "wie", "ihr", "Sie", "ge\u00b7liebt", "habt", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "PPER", "VVPP", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wohnt' irgends Gl\u00fcck so wohnt es hie,", "tokens": ["Wohnt'", "ir\u00b7gends", "Gl\u00fcck", "so", "wohnt", "es", "hie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie liebet' euch, ihr liebtet sie,", "tokens": ["Sie", "lie\u00b7bet'", "euch", ",", "ihr", "lieb\u00b7tet", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd dennoch fiel sie euch danieder.", "tokens": ["Vnd", "den\u00b7noch", "fiel", "sie", "euch", "da\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Das macht der Dinge Flucht und Fall", "tokens": ["Das", "macht", "der", "Din\u00b7ge", "Flucht", "und", "Fall"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der bey den Menschen \u00fcberall", "tokens": ["Der", "bey", "den", "Men\u00b7schen", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Am allermeisten Platz gewonnen.", "tokens": ["Am", "al\u00b7ler\u00b7meis\u00b7ten", "Platz", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Seit da\u00df sich Adam abgewand,", "tokens": ["Seit", "da\u00df", "sich", "A\u00b7dam", "ab\u00b7ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PRF", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Herrscht Ungl\u00fcck, Tod und Vnbestand", "tokens": ["Herrscht", "Un\u00b7gl\u00fcck", ",", "Tod", "und", "Vn\u00b7be\u00b7stand"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo man erkennt das Liecht der Sonnen.", "tokens": ["Wo", "man", "er\u00b7kennt", "das", "Liecht", "der", "Son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Dr\u00fcmb thut mit klagen, Herr, gemach", "tokens": ["Dr\u00fcmb", "thut", "mit", "kla\u00b7gen", ",", "Herr", ",", "ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PAV", "VVFIN", "APPR", "VVINF", "$,", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd denckt dem Wort des Herren nach,", "tokens": ["Vnd", "denckt", "dem", "Wort", "des", "Her\u00b7ren", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Daraus ihr den Bericht k\u00f6nnt werben,", "tokens": ["Da\u00b7raus", "ihr", "den", "Be\u00b7richt", "k\u00f6nnt", "wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da\u00df nur der Leib sich Grabwerts kehrt,", "tokens": ["Da\u00df", "nur", "der", "Leib", "sich", "Grab\u00b7werts", "kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und derer Geist gen Himmel f\u00e4hrt", "tokens": ["Und", "de\u00b7rer", "Geist", "gen", "Him\u00b7mel", "f\u00e4hrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die selig und im Herren sterben.", "tokens": ["Die", "se\u00b7lig", "und", "im", "Her\u00b7ren", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Von ewrer Kreitzinn senckt ihr ein", "tokens": ["Von", "ew\u00b7rer", "Kreit\u00b7zinn", "senckt", "ihr", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur ihren Leib und ihr Gebein,", "tokens": ["Nur", "ih\u00b7ren", "Leib", "und", "ihr", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr bestes fleucht die Grabes-H\u00f6le", "tokens": ["Ihr", "bes\u00b7tes", "fleucht", "die", "Gra\u00b7bes\u00b7H\u00f6le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd schwebet bey der Frommen Schaar,", "tokens": ["Vnd", "schwe\u00b7bet", "bey", "der", "From\u00b7men", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie ist ohn Schmertzen immerdar", "tokens": ["Sie", "ist", "ohn", "Schmert\u00b7zen", "im\u00b7mer\u00b7dar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was anlangt ihre liebe Seele.", "tokens": ["Was", "an\u00b7langt", "ih\u00b7re", "lie\u00b7be", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Sol dieser Geist der Tugend Sal,", "tokens": ["Sol", "die\u00b7ser", "Geist", "der", "Tu\u00b7gend", "Sal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDAT", "NN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der sich so embsig Gott befahl", "tokens": ["Der", "sich", "so", "emb\u00b7sig", "Gott", "be\u00b7fahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "ADV", "ADJD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der keinem Leibe sich ergeben,", "tokens": ["Der", "kei\u00b7nem", "Lei\u00b7be", "sich", "er\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der auff der krancken Lagerstat", "tokens": ["Der", "auff", "der", "kran\u00b7cken", "La\u00b7ger\u00b7stat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gott trewlich au\u00dfgehalten hat,", "tokens": ["Gott", "trew\u00b7lich", "au\u00df\u00b7ge\u00b7hal\u00b7ten", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht \u00fcbrig seyn nach diesem Leben?", "tokens": ["Nicht", "\u00fcb\u00b7rig", "seyn", "nach", "die\u00b7sem", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAINF", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Der Aertzte Flei\u00df und Raht war aus,", "tokens": ["Der", "A\u00b7ertz\u00b7te", "Flei\u00df", "und", "Raht", "war", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VAFIN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es hie\u00df mit ihr: Beschick dein Hau\u00df,", "tokens": ["Es", "hie\u00df", "mit", "ihr", ":", "Be\u00b7schick", "dein", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "$(", "VVIMP", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Tod rafft jetz und dich von hinnen,", "tokens": ["Der", "Tod", "rafft", "jetz", "und", "dich", "von", "hin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "PRF", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erbebte sie aus Kleinmuht? nein,", "tokens": ["Er\u00b7beb\u00b7te", "sie", "aus", "Klein\u00b7muht", "?", "nein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$.", "PTKANT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie gab gedultig sich darein", "tokens": ["Sie", "gab", "ge\u00b7dul\u00b7tig", "sich", "da\u00b7rein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PRF", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Starck an des wahren Glaubens Sinnen.", "tokens": ["Starck", "an", "des", "wah\u00b7ren", "Glau\u00b7bens", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Des Herren Leib und theures Blut", "tokens": ["Des", "Her\u00b7ren", "Leib", "und", "theu\u00b7res", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward ihrer Heimfahrt edles Gut,", "tokens": ["Ward", "ih\u00b7rer", "Heim\u00b7fahrt", "ed\u00b7les", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie hat des h\u00f6chsten Hut befohlen", "tokens": ["Sie", "hat", "des", "h\u00f6chs\u00b7ten", "Hut", "be\u00b7foh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Euch und die edlen Kinder auch,", "tokens": ["Euch", "und", "die", "ed\u00b7len", "Kin\u00b7der", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd fuhr dahin nach Schlaffes brauch", "tokens": ["Vnd", "fuhr", "da\u00b7hin", "nach", "Schlaf\u00b7fes", "brauch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PAV", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd lies sich in den Himmel holen.", "tokens": ["Vnd", "lies", "sich", "in", "den", "Him\u00b7mel", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Da wohnt sie ihrem Hause bey", "tokens": ["Da", "wohnt", "sie", "ih\u00b7rem", "Hau\u00b7se", "bey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd h\u00f6rt der Engel Melodey,", "tokens": ["Vnd", "h\u00f6rt", "der", "En\u00b7gel", "Me\u00b7lo\u00b7dey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Herren ewig nicht verschweigen,", "tokens": ["Den", "Her\u00b7ren", "e\u00b7wig", "nicht", "ver\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Daf\u00fcr die Lieder Schatten sind", "tokens": ["Da\u00b7f\u00fcr", "die", "Lie\u00b7der", "Schat\u00b7ten", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die vnser h\u00f6chster Flei\u00df beginnt", "tokens": ["Die", "vn\u00b7ser", "h\u00f6chs\u00b7ter", "Flei\u00df", "be\u00b7ginnt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie sch\u00f6n wir singen oder geigen.", "tokens": ["Wie", "sch\u00f6n", "wir", "sin\u00b7gen", "o\u00b7der", "gei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Hie ist das Reich der Eitelkeit,", "tokens": ["Hie", "ist", "das", "Reich", "der", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hie herschen Unfall, Gl\u00fcck und Zeit,", "tokens": ["Hie", "her\u00b7schen", "Un\u00b7fall", ",", "Gl\u00fcck", "und", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort ist Bestand und Rhu zu finden:", "tokens": ["Dort", "ist", "Be\u00b7stand", "und", "Rhu", "zu", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "KON", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die sol nach diesem kurtzen Lauff,", "tokens": ["Die", "sol", "nach", "die\u00b7sem", "kurt\u00b7zen", "Lauff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gott nehm' uns nur in Frieden auff,", "tokens": ["Gott", "nehm'", "uns", "nur", "in", "Frie\u00b7den", "auff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vns Ihr in Ewigkeit verbinden.", "tokens": ["Vns", "Ihr", "in", "E\u00b7wig\u00b7keit", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}