{"textgrid.poem.54467": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "[widmung]", "genre": "verse", "period": "N.A.", "pub_year": 1640, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herr Popschitz/ den mein Hertz' von jugend auff gelibt/", "tokens": ["Herr", "Pop\u00b7schitz", "/", "den", "mein", "Hertz'", "von", "ju\u00b7gend", "auff", "ge\u00b7libt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$(", "ART", "PPOSAT", "NN", "APPR", "NN", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Niederland mich fest; vnd Franckreich mehr verbunden.", "tokens": ["Dem", "Nie\u00b7der\u00b7land", "mich", "fest", ";", "vnd", "Fran\u00b7ck\u00b7reich", "mehr", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "$.", "KON", "NE", "ADV", "VVPP", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Vnd jhr/ den Leid\u1ebd gab v\u00f1 Stra\u00dfburg wieder gibt/", "tokens": ["Vnd", "jhr", "/", "den", "Lei\u00b7d\u1ebd", "gab", "v\u00f1", "Stra\u00df\u00b7burg", "wie\u00b7der", "gibt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "$(", "ART", "NN", "VVFIN", "NE", "NE", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In welchem ich aufs new/ die alte gunst gefunden:", "tokens": ["In", "wel\u00b7chem", "ich", "aufs", "new", "/", "die", "al\u00b7te", "gunst", "ge\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPRART", "ADJD", "$(", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nemb't di\u00df geringe Pfand/ der vnverf\u00e4lscht\u1ebd trew:", "tokens": ["Nem\u00b7b't", "di\u00df", "ge\u00b7rin\u00b7ge", "Pfand", "/", "der", "vn\u00b7ver\u00b7f\u00e4lscht\u1ebd", "trew", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADJA", "NN", "$(", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Da\u00df ich/ (ach fern' v\u00f5 euch!) mein Popschitz vbergebe.", "tokens": ["Da\u00df", "ich", "/", "(", "ach", "fern'", "v\u00f5", "euch", "!", ")", "mein", "Pop\u00b7schitz", "vber\u00b7ge\u00b7be", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "$(", "XY", "XY", "XY", "PPER", "$.", "$(", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.7": {"text": "Di\u00df pfand Herr Haffdersle/ soll zeug\u1ebd sonder schew", "tokens": ["Di\u00df", "pfand", "Herr", "Haff\u00b7ders\u00b7le", "/", "soll", "zeug\u1ebd", "son\u00b7der", "schew"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NN", "NE", "$(", "VMFIN", "VVFIN", "ADV", "ADJD"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Das mein Geist n\u00e4her Euch/ als wol/ mein C\u00f6rper lebe.", "tokens": ["Das", "mein", "Geist", "n\u00e4\u00b7her", "Euch", "/", "als", "wol", "/", "mein", "C\u00f6r\u00b7per", "le\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADJD", "PPER", "$(", "KOKOM", "ADV", "$(", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+++-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.9": {"text": "Von Einem scheiden mich Berg/ L\u00e4nder/ Feld vnd See:", "tokens": ["Von", "Ei\u00b7nem", "schei\u00b7den", "mich", "Berg", "/", "L\u00e4n\u00b7der", "/", "Feld", "vnd", "See", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PPER", "NN", "$(", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den andern sucht von mir ein falscher Mund zu tre\u00f1en;", "tokens": ["Den", "an\u00b7dern", "sucht", "von", "mir", "ein", "fal\u00b7scher", "Mund", "zu", "tre\u00f1en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Vmbsonst/ weil freundschaft gleich/ fern nah' in tieff' vnd h\u00f6h'", "tokens": ["Vmbsonst", "/", "weil", "freund\u00b7schaft", "gleich", "/", "fern", "nah'", "in", "tief\u00b7f'", "vnd", "h\u00f6h'"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "KOUS", "ADJD", "ADV", "$(", "ADJD", "VVFIN", "APPR", "NE", "KON", "XY"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.12": {"text": "Vnd wir einander nicht nur von gesicht erkennen:", "tokens": ["Vnd", "wir", "ein\u00b7an\u00b7der", "nicht", "nur", "von", "ge\u00b7sicht", "er\u00b7ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "PTKNEG", "ADV", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Jedoch! weil zeit vnd Neydt/ so mit vns vmb will gehn/", "tokens": ["Je\u00b7doch", "!", "weil", "zeit", "vnd", "Neydt", "/", "so", "mit", "vns", "vmb", "will", "gehn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KOUS", "NN", "KON", "NE", "$(", "ADV", "APPR", "PPER", "APPR", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Mu\u00df wider zeit vnd Neydt die feder mittel finden;", "tokens": ["Mu\u00df", "wi\u00b7der", "zeit", "vnd", "Neydt", "die", "fe\u00b7der", "mit\u00b7tel", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da\u00df wir/ trotz zeit v\u00f1 neydt/ doch vnzertre\u00f1et stehn:", "tokens": ["Da\u00df", "wir", "/", "trotz", "zeit", "v\u00f1", "neydt", "/", "doch", "vn\u00b7zer\u00b7tre\u00f1et", "stehn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "APPR", "NN", "NE", "NE", "$(", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Wenn nun der bleiche Neydt mu\u00df mit der zeit verschwinden.", "tokens": ["Wenn", "nun", "der", "blei\u00b7che", "Neydt", "mu\u00df", "mit", "der", "zeit", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Stra\u00dfburg/ auff des H. Andre\u00e6", "tokens": ["Stra\u00df\u00b7burg", "/", "auff", "des", "H.", "An\u00b7dre\u00e6"], "token_info": ["word", "punct", "word", "word", "abbreviation", "word"], "pos": ["NE", "$(", "APPR", "ART", "NE", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Abendt, ", "tokens": ["A\u00b7bendt", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}}}}}