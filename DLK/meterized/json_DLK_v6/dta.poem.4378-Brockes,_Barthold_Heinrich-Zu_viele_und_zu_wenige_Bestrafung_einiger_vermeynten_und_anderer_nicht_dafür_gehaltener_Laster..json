{"dta.poem.4378": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Zu viele und zu wenige  \n Bestrafung  \n einiger vermeynten und anderer nicht  \n daf\u00fcr gehaltener Laster.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wie ich schon oftermahls erwogen,", "tokens": ["Wie", "ich", "schon", "of\u00b7ter\u00b7mahls", "er\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df auch von ganz gleichg\u00fclt\u2019gen Sachen", "tokens": ["Da\u00df", "auch", "von", "ganz", "gleich\u00b7g\u00fclt'\u00b7gen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir, leider! \u00f6fters Laster machen,", "tokens": ["Wir", ",", "lei\u00b7der", "!", "\u00f6f\u00b7ters", "Las\u00b7ter", "ma\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "$.", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und da\u00df oft gar zur S\u00fcnde wird gezogen,", "tokens": ["Und", "da\u00df", "oft", "gar", "zur", "S\u00fcn\u00b7de", "wird", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ADV", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Was niemahls S\u00fcnde war;", "tokens": ["Was", "nie\u00b7mahls", "S\u00fcn\u00b7de", "war", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "So find ich die\u00df hingegen,", "tokens": ["So", "find", "ich", "die\u00df", "hin\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df wir das, welches offenbar", "tokens": ["Da\u00df", "wir", "das", ",", "wel\u00b7ches", "of\u00b7fen\u00b7bar"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zur S\u00fcnden-Liste hinzurechnen, meist ganz zu \u00fcbergehen", "tokens": ["Zur", "S\u00fcn\u00b7den\u00b7Lis\u00b7te", "hin\u00b7zu\u00b7rech\u00b7nen", ",", "meist", "ganz", "zu", "\u00fc\u00b7ber\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVINF", "$,", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "pflegen.", "tokens": ["pfle\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Zum Beyspiel: wenn man Thiere qu\u00e4let,", "tokens": ["Zum", "Bey\u00b7spiel", ":", "wenn", "man", "Thie\u00b7re", "qu\u00e4\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "KOUS", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Mit vielen Martern sie entseelet,", "tokens": ["Mit", "vie\u00b7len", "Mar\u00b7tern", "sie", "ent\u00b7see\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Sie, ohne Nutz, zum Zeit-Vertreibe plagt,", "tokens": ["Sie", ",", "oh\u00b7ne", "Nutz", ",", "zum", "Zeit\u00b7Ver\u00b7trei\u00b7be", "plagt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUI", "NN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und sie beschwehrt mit Schmerz und Pein,", "tokens": ["Und", "sie", "be\u00b7schwehrt", "mit", "Schmerz", "und", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Da doch die Schrift uns nicht nur deutlich sagt", "tokens": ["Da", "doch", "die", "Schrift", "uns", "nicht", "nur", "deut\u00b7lich", "sagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "PPER", "PTKNEG", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Vom Seufzen der Gesch\u00f6pf, da die Vernunft so gar", "tokens": ["Vom", "Seuf\u00b7zen", "der", "Ge\u00b7sch\u00f6pf", ",", "da", "die", "Ver\u00b7nunft", "so", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "KOUS", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Uns \u00fcberzeuglich lehrt, und zeigt uns Sonnen-klar,", "tokens": ["Uns", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "lehrt", ",", "und", "zeigt", "uns", "Son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$,", "KON", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Da\u00df sie sowohl, als wir, Gesch\u00f6pfe GOttes seyn,", "tokens": ["Da\u00df", "sie", "so\u00b7wohl", ",", "als", "wir", ",", "Ge\u00b7sch\u00f6p\u00b7fe", "Got\u00b7tes", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "KOUS", "PPER", "$,", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df man in ihnen auch den Sch\u00f6pfer ehrt,", "tokens": ["Da\u00df", "man", "in", "ih\u00b7nen", "auch", "den", "Sch\u00f6p\u00b7fer", "ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Da\u00df sie, Betrachtungs-wehrte Gaben,", "tokens": ["Da\u00df", "sie", ",", "Be\u00b7trach\u00b7tungs\u00b7wehr\u00b7te", "Ga\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die unserer Bewundrung wehrt,", "tokens": ["Die", "un\u00b7se\u00b7rer", "Be\u00b7wund\u00b7rung", "wehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Von GOtt, in reicher Maa\u00df, empfangen haben,", "tokens": ["Von", "Gott", ",", "in", "rei\u00b7cher", "Maa\u00df", ",", "emp\u00b7fan\u00b7gen", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Da\u00df, ob sie uns gleich unterworfen worden", "tokens": ["Da\u00df", ",", "ob", "sie", "uns", "gleich", "un\u00b7ter\u00b7wor\u00b7fen", "wor\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "PPER", "ADV", "VVPP", "VAPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "zum Nutzen, zur Bequemlichkeit,", "tokens": ["zum", "Nut\u00b7zen", ",", "zur", "Be\u00b7quem\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wir dennoch nicht befugt, ohn\u2019 Unterscheid,", "tokens": ["Wir", "den\u00b7noch", "nicht", "be\u00b7fugt", ",", "ohn'", "Un\u00b7ter\u00b7scheid", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "VVPP", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Aufs grausamste sie zu ermorden.", "tokens": ["Aufs", "grau\u00b7sams\u00b7te", "sie", "zu", "er\u00b7mor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kein W\u00fcrmchen ist so klein, dem wir das Leben,", "tokens": ["Kein", "W\u00fcrm\u00b7chen", "ist", "so", "klein", ",", "dem", "wir", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "PRELS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit aller unsrer Macht, zu geben", "tokens": ["Mit", "al\u00b7ler", "uns\u00b7rer", "Macht", ",", "zu", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verm\u00f6gend seyn.", "tokens": ["Ver\u00b7m\u00f6\u00b7gend", "seyn", "."], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Wenn die\u00df nun, f\u00fcr den Wurm, ein unsch\u00e4tzbares Gut;", "tokens": ["Wenn", "die\u00df", "nun", ",", "f\u00fcr", "den", "Wurm", ",", "ein", "un\u00b7sch\u00e4tz\u00b7ba\u00b7res", "Gut", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "$,", "APPR", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie kann man glauben,", "tokens": ["Wie", "kann", "man", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Da\u00df man daran nicht Unrecht thut,", "tokens": ["Da\u00df", "man", "da\u00b7ran", "nicht", "Un\u00b7recht", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wenn wir es ihm aus Frevel rauben,", "tokens": ["Wenn", "wir", "es", "ihm", "aus", "Fre\u00b7vel", "rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ja noch dazu mit Pein und Qu\u00e4len", "tokens": ["Ja", "noch", "da\u00b7zu", "mit", "Pein", "und", "Qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "PAV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Jhn oft zerfleischen und entseelen.", "tokens": ["Jhn", "oft", "zer\u00b7flei\u00b7schen", "und", "ent\u00b7see\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wie letzters nun zumahl den gr\u00f6bsten Unverstand,", "tokens": ["Wie", "letz\u00b7ters", "nun", "zu\u00b7mahl", "den", "gr\u00f6bs\u00b7ten", "Un\u00b7ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da ihnen ihre Schuld und Bosheit unbekannt,", "tokens": ["Da", "ih\u00b7nen", "ih\u00b7re", "Schuld", "und", "Bos\u00b7heit", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Aus Mangel der Belehrung, zeiget;", "tokens": ["Aus", "Man\u00b7gel", "der", "Be\u00b7leh\u00b7rung", ",", "zei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "So ist es wahrlich zu beklagen,", "tokens": ["So", "ist", "es", "wahr\u00b7lich", "zu", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Da\u00df man von diesem Unrecht schweiget,", "tokens": ["Da\u00df", "man", "von", "die\u00b7sem", "Un\u00b7recht", "schwei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und da\u00df wir nichts hievon, zu ihrer Lehre, sagen.", "tokens": ["Und", "da\u00df", "wir", "nichts", "hie\u00b7von", ",", "zu", "ih\u00b7rer", "Leh\u00b7re", ",", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "PAV", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Noch mehr. In GOttes Wunder-Werken", "tokens": ["Noch", "mehr", ".", "In", "Got\u00b7tes", "Wun\u00b7der\u00b7Wer\u00b7ken"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Sch\u00f6pfers Weisheit, Liebe, Macht,", "tokens": ["Des", "Sch\u00f6p\u00b7fers", "Weis\u00b7heit", ",", "Lie\u00b7be", ",", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So ungl\u00fcckselig nicht bemerken,", "tokens": ["So", "un\u00b7gl\u00fcck\u00b7se\u00b7lig", "nicht", "be\u00b7mer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wird ebenfalls f\u00fcr S\u00fcnde nicht geacht,", "tokens": ["Wird", "e\u00b7ben\u00b7falls", "f\u00fcr", "S\u00fcn\u00b7de", "nicht", "ge\u00b7acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da es doch kl\u00e4rlich darzuthun,", "tokens": ["Da", "es", "doch", "kl\u00e4r\u00b7lich", "dar\u00b7zu\u00b7thun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df vieler S\u00fcnden Str\u00f6hm\u2019 in dieser S\u00fcnde ruhn.", "tokens": ["Da\u00df", "vie\u00b7ler", "S\u00fcn\u00b7den", "Str\u00f6hm'", "in", "die\u00b7ser", "S\u00fcn\u00b7de", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NE", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ich habe wohl zuweilen nachgefraget:", "tokens": ["Ich", "ha\u00b7be", "wohl", "zu\u00b7wei\u00b7len", "nach\u00b7ge\u00b7fra\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Woher es k\u00e4me, da\u00df man, GOtt zum Abbruch gleichsam", "tokens": ["Wo\u00b7her", "es", "k\u00e4\u00b7me", ",", "da\u00df", "man", ",", "Gott", "zum", "Ab\u00b7bruch", "gleich\u00b7sam"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "KOUS", "PIS", "$,", "NN", "APPRART", "NN", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Seiner Ehre,", "tokens": ["Sei\u00b7ner", "Eh\u00b7re", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "In diesem Punct so blind und unempfindlich w\u00e4re?", "tokens": ["In", "die\u00b7sem", "Punct", "so", "blind", "und", "un\u00b7emp\u00b7find\u00b7lich", "w\u00e4\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "ADJD", "KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So hie\u00df es mehrentheils: Hievon hat uns der Priester", "tokens": ["So", "hie\u00df", "es", "meh\u00b7ren\u00b7theils", ":", "Hie\u00b7von", "hat", "uns", "der", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PAV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "nichts gesaget.", "tokens": ["nichts", "ge\u00b7sa\u00b7get", "."], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Wie es nun recht und gut, mit v\u00f6lligem Vertrauen", "tokens": ["Wie", "es", "nun", "recht", "und", "gut", ",", "mit", "v\u00f6l\u00b7li\u00b7gem", "Ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "KON", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auf unsrer Lehrer Lehren bauen;", "tokens": ["Auf", "uns\u00b7rer", "Leh\u00b7rer", "Leh\u00b7ren", "bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "So folgt zugleich unwiedersprechlich die\u00df,", "tokens": ["So", "folgt", "zu\u00b7gleich", "un\u00b7wie\u00b7der\u00b7sprech\u00b7lich", "die\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADJD", "PDS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Da\u00df, da wir glauben, was sie sagen,", "tokens": ["Da\u00df", ",", "da", "wir", "glau\u00b7ben", ",", "was", "sie", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "VVFIN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie auch verbunden sind also sich zu betragen,", "tokens": ["Sie", "auch", "ver\u00b7bun\u00b7den", "sind", "al\u00b7so", "sich", "zu", "be\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAFIN", "ADV", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Da\u00df etwas n\u00f6htiges, zum Ruhm des Sch\u00f6pfers Himmels", "tokens": ["Da\u00df", "et\u00b7was", "n\u00f6h\u00b7ti\u00b7ges", ",", "zum", "Ruhm", "des", "Sch\u00f6p\u00b7fers", "Him\u00b7mels"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "ADJA", "$,", "APPRART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und der Erden,", "tokens": ["und", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Nicht mu\u00df verschwiegen seyn, nicht unterlassen werden.", "tokens": ["Nicht", "mu\u00df", "ver\u00b7schwie\u00b7gen", "seyn", ",", "nicht", "un\u00b7ter\u00b7las\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VMFIN", "VVPP", "VAINF", "$,", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und fragt sich, wenns geschicht, ob sie nicht fast allein", "tokens": ["Und", "fragt", "sich", ",", "wenns", "ge\u00b7schicht", ",", "ob", "sie", "nicht", "fast", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "$,", "KOUS", "VVPP", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Am allerstr\u00e4flichsten, der Folge halber, seyn?", "tokens": ["Am", "al\u00b7ler\u00b7str\u00e4f\u00b7lichs\u00b7ten", ",", "der", "Fol\u00b7ge", "hal\u00b7ber", ",", "seyn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "ART", "NN", "APPO", "$,", "VAINF", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Ob ich nun gleich die\u00df unsern Lehrern nicht gerne hier zu", "tokens": ["Ob", "ich", "nun", "gleich", "die\u00df", "un\u00b7sern", "Leh\u00b7rern", "nicht", "ger\u00b7ne", "hier", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PDS", "PPOSAT", "NN", "PTKNEG", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Laste lege,", "tokens": ["Las\u00b7te", "le\u00b7ge", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Da ich f\u00fcr ihr so heilig Amt und sie, viel\u2019 Ehrerbietung", "tokens": ["Da", "ich", "f\u00fcr", "ihr", "so", "hei\u00b7lig", "Amt", "und", "sie", ",", "viel'", "Ehr\u00b7er\u00b7bie\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "ADJD", "NN", "KON", "PPER", "$,", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.11": {"text": "hege;", "tokens": ["he\u00b7ge", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.12": {"text": "So deucht mich doch, wenn ich die Umst\u00e4nd\u2019 und der Ge-", "tokens": ["So", "deucht", "mich", "doch", ",", "wenn", "ich", "die", "Um\u00b7st\u00e4nd'", "und", "der", "Ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "KON", "ART", "TRUNC"], "meter": "-+-+-+-++-+-", "measure": "unknown.measure.hexa"}, "line.13": {"text": "wohnheit Macht erwege,", "tokens": ["wohn\u00b7heit", "Macht", "er\u00b7we\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.14": {"text": "Da\u00df ich von ihnen einige doch zu ersuchen schuldig bin,", "tokens": ["Da\u00df", "ich", "von", "ih\u00b7nen", "ei\u00b7ni\u00b7ge", "doch", "zu", "er\u00b7su\u00b7chen", "schul\u00b7dig", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PIS", "ADV", "PTKZU", "VVINF", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.15": {"text": "Damit dieselben k\u00fcnftighin", "tokens": ["Da\u00b7mit", "die\u00b7sel\u00b7ben", "k\u00fcnf\u00b7tig\u00b7hin"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit mehrerm Ernst die S\u00fcnde strafen.", "tokens": ["Mit", "meh\u00b7rerm", "Ernst", "die", "S\u00fcn\u00b7de", "stra\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Wodurch wir, wenn wir GOtt nicht sp\u00fchren", "tokens": ["Wo\u00b7durch", "wir", ",", "wenn", "wir", "Gott", "nicht", "sp\u00fch\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "$,", "KOUS", "PPER", "NN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "In Seinem Werk, das Er jedoch f\u00fcr uns, zu Seiner", "tokens": ["In", "Sei\u00b7nem", "Werk", ",", "das", "Er", "je\u00b7doch", "f\u00fcr", "uns", ",", "zu", "Sei\u00b7ner"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV", "APPR", "PPER", "$,", "APPR", "PPOSAT"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.19": {"text": "Ehr', erschaffen,", "tokens": ["Ehr'", ",", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.20": {"text": "Und woraus Er allein erkenntlich, wir leicht den Sch\u00f6pfer", "tokens": ["Und", "wo\u00b7raus", "Er", "al\u00b7lein", "er\u00b7kennt\u00b7lich", ",", "wir", "leicht", "den", "Sch\u00f6p\u00b7fer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADJD", "$,", "PPER", "ADJD", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "selbst verlieren,", "tokens": ["selbst", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.22": {"text": "Zumahl die H\u00f6rer, wenn sie GOtt nicht recht als ihren", "tokens": ["Zu\u00b7mahl", "die", "H\u00f6\u00b7rer", ",", "wenn", "sie", "Gott", "nicht", "recht", "als", "ih\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "PPER", "NN", "PTKNEG", "ADJD", "KOKOM", "PPOSAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sch\u00f6pfer lieben,", "tokens": ["Sch\u00f6p\u00b7fer", "lie\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.24": {"text": "Sie die\u00df Vergehen mehrentheils auf ihrer Lehrer Schwei-", "tokens": ["Sie", "die\u00df", "Ver\u00b7ge\u00b7hen", "meh\u00b7ren\u00b7theils", "auf", "ih\u00b7rer", "Leh\u00b7rer", "Schwei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PDS", "NN", "ADV", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.25": {"text": "gen schieben.", "tokens": ["gen", "schie\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}