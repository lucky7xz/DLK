{"textgrid.poem.55208": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Sendschreiben", "genre": "verse", "period": "N.A.", "pub_year": 1774, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein altes Evangelium", "tokens": ["Mein", "al\u00b7tes", "E\u00b7van\u00b7ge\u00b7li\u00b7um"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bring ich dir hier schon wieder;", "tokens": ["Bring", "ich", "dir", "hier", "schon", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch ist mir's wohl um mich herum,", "tokens": ["Doch", "ist", "mir's", "wohl", "um", "mich", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NE", "ADV", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darum schreib ich dir's nieder.", "tokens": ["Da\u00b7rum", "schreib", "ich", "dir's", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich holte Gold, ich holte Wein,", "tokens": ["Ich", "hol\u00b7te", "Gold", ",", "ich", "hol\u00b7te", "Wein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stellt alles da zusammen.", "tokens": ["Stellt", "al\u00b7les", "da", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da, dacht ich, da wird W\u00e4rme sein,", "tokens": ["Da", ",", "dacht", "ich", ",", "da", "wird", "W\u00e4r\u00b7me", "sein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "ADV", "VAFIN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geht mein Gem\u00e4ld in Flammen!", "tokens": ["Geht", "mein", "Ge\u00b7m\u00e4ld", "in", "Flam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Auch t\u00e4t ich bei der Sch\u00e4tze Flor", "tokens": ["Auch", "t\u00e4t", "ich", "bei", "der", "Sch\u00e4t\u00b7ze", "Flor"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Glut und Reichtum schw\u00e4rmen;", "tokens": ["Viel", "Glut", "und", "Reich\u00b7tum", "schw\u00e4r\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch Menschenfleisch geht allem vor,", "tokens": ["Doch", "Men\u00b7schen\u00b7fleisch", "geht", "al\u00b7lem", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um sich daran zu w\u00e4rmen.", "tokens": ["Um", "sich", "da\u00b7ran", "zu", "w\u00e4r\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und wer nicht richtet, sondern flei\u00dfig ist,", "tokens": ["Und", "wer", "nicht", "rich\u00b7tet", ",", "son\u00b7dern", "flei\u00b7\u00dfig", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "VVFIN", "$,", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie ich bin und wie du bist,", "tokens": ["Wie", "ich", "bin", "und", "wie", "du", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "KON", "PWAV", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den belohnt auch die Arbeit mit Genu\u00df;", "tokens": ["Den", "be\u00b7lohnt", "auch", "die", "Ar\u00b7beit", "mit", "Ge\u00b7nu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Nichts wird auf der Welt ihm \u00dcberdru\u00df.", "tokens": ["Nichts", "wird", "auf", "der", "Welt", "ihm", "\u00dc\u00b7berd\u00b7ru\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "ART", "NN", "PPER", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Denn er blecket nicht mit stumpfem Zahn", "tokens": ["Denn", "er", "blec\u00b7ket", "nicht", "mit", "stump\u00b7fem", "Zahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Lang Gesottnes und Gebratnes an,", "tokens": ["Lang", "Ge\u00b7sott\u00b7nes", "und", "Ge\u00b7brat\u00b7nes", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Das er, wenn er noch so sittlich kaut,", "tokens": ["Das", "er", ",", "wenn", "er", "noch", "so", "sitt\u00b7lich", "kaut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Endlich doch nicht sonderlich verdaut;", "tokens": ["End\u00b7lich", "doch", "nicht", "son\u00b7der\u00b7lich", "ver\u00b7daut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Sondern fa\u00dft ein t\u00fcchtig Schinkenbein,", "tokens": ["Son\u00b7dern", "fa\u00dft", "ein", "t\u00fcch\u00b7tig", "Schin\u00b7ken\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Haut da gut tagl\u00f6hnerm\u00e4\u00dfig drein,", "tokens": ["Haut", "da", "gut", "tag\u00b7l\u00f6h\u00b7ner\u00b7m\u00e4\u00b7\u00dfig", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.11": {"text": "F\u00fcllt bis oben gierig den Pokal,", "tokens": ["F\u00fcllt", "bis", "o\u00b7ben", "gie\u00b7rig", "den", "Po\u00b7kal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Trinkt, und wischt das Maul wohl nicht einmal.", "tokens": ["Trinkt", ",", "und", "wischt", "das", "Maul", "wohl", "nicht", "ein\u00b7mal", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Sieh, so ist Natur ein Buch lebendig,", "tokens": ["Sieh", ",", "so", "ist", "Na\u00b7tur", "ein", "Buch", "le\u00b7ben\u00b7dig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VAFIN", "NN", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Unverstanden, doch nicht unverst\u00e4ndlich:", "tokens": ["Un\u00b7ver\u00b7stan\u00b7den", ",", "doch", "nicht", "un\u00b7ver\u00b7st\u00e4nd\u00b7lich", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Denn dein Herz hat viel und gro\u00df Begehr,", "tokens": ["Denn", "dein", "Herz", "hat", "viel", "und", "gro\u00df", "Be\u00b7gehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "KON", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Was wohl in der Welt f\u00fcr Freude w\u00e4r,", "tokens": ["Was", "wohl", "in", "der", "Welt", "f\u00fcr", "Freu\u00b7de", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Allen Sonnenschein und alle B\u00e4ume,", "tokens": ["Al\u00b7len", "Son\u00b7nen\u00b7schein", "und", "al\u00b7le", "B\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Alles Meergestad und alle Tr\u00e4ume", "tokens": ["Al\u00b7les", "Meer\u00b7ge\u00b7stad", "und", "al\u00b7le", "Tr\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "In dein Herz zu sammeln miteinander,", "tokens": ["In", "dein", "Herz", "zu", "sam\u00b7meln", "mi\u00b7tein\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "ADV", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Wie die Welt durchw\u00fchlend Banks, Solander.", "tokens": ["Wie", "die", "Welt", "durch\u00b7w\u00fch\u00b7lend", "Banks", ",", "So\u00b7lan\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Und wie mu\u00df dir's werden, wenn du f\u00fchlest,", "tokens": ["Und", "wie", "mu\u00df", "dir's", "wer\u00b7den", ",", "wenn", "du", "f\u00fch\u00b7lest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PIS", "VAINF", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df du alles in dir selbst erzielest,", "tokens": ["Da\u00df", "du", "al\u00b7les", "in", "dir", "selbst", "er\u00b7zie\u00b7lest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Freude hast an deiner Frau und Hunden,", "tokens": ["Freu\u00b7de", "hast", "an", "dei\u00b7ner", "Frau", "und", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Als noch keiner in Elysium gefunden,", "tokens": ["Als", "noch", "kei\u00b7ner", "in", "E\u00b7ly\u00b7si\u00b7um", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "APPR", "NE", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Als er da mit Schatten lieblich schweifte", "tokens": ["Als", "er", "da", "mit", "Schat\u00b7ten", "lieb\u00b7lich", "schweif\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "ADJD", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Und an goldne Gottgestalten streifte.", "tokens": ["Und", "an", "gold\u00b7ne", "Gott\u00b7ge\u00b7stal\u00b7ten", "streif\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Nicht in Rom, in Magna Graecia,", "tokens": ["Nicht", "in", "Rom", ",", "in", "Mag\u00b7na", "Grae\u00b7cia", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NE", "$,", "APPR", "NE", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Dir im Herzen ist die Wonne da!", "tokens": ["Dir", "im", "Her\u00b7zen", "ist", "die", "Won\u00b7ne", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Wer mit seiner Mutter, der Natur, sich h\u00e4lt,", "tokens": ["Wer", "mit", "sei\u00b7ner", "Mut\u00b7ter", ",", "der", "Na\u00b7tur", ",", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.10": {"text": "Findt im Stengelglas wohl eine Welt.", "tokens": ["Findt", "im", "Sten\u00b7gel\u00b7glas", "wohl", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}