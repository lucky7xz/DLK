{"dta.poem.23435": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die deutsche Presse  \n  unter des durchlauchtigsten deutschen Bundes  \n sch\u00fctzenden Privilegien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1841", "urn": "urn:nbn:de:kobv:b4-200905192634", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "B\u00fc\u00dfen mu\u00dft du, deutsche Presse,", "tokens": ["B\u00fc\u00b7\u00dfen", "mu\u00dft", "du", ",", "deut\u00b7sche", "Pres\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit Gef\u00e4ngni\u00df und mit Geld,", "tokens": ["Mit", "Ge\u00b7f\u00e4ng\u00b7ni\u00df", "und", "mit", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bringst du etwas von Interesse", "tokens": ["Bringst", "du", "et\u00b7was", "von", "In\u00b7ter\u00b7es\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Was den Fremden nicht gef\u00e4llt.", "tokens": ["Was", "den", "Frem\u00b7den", "nicht", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Frankreich pfuscht in deine Sachen,", "tokens": ["Fran\u00b7kreich", "pfuscht", "in", "dei\u00b7ne", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frankreich h\u00e4lt bei uns Gericht,", "tokens": ["Fran\u00b7kreich", "h\u00e4lt", "bei", "uns", "Ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Frankreich kann es heute machen,", "tokens": ["Fran\u00b7kreich", "kann", "es", "heu\u00b7te", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df kein Deutscher deutsch mehr spricht.", "tokens": ["Da\u00df", "kein", "Deut\u00b7scher", "deutsch", "mehr", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJD", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ru\u00dfland, dieser Geisterzwinger,", "tokens": ["Ru\u00df\u00b7land", ",", "die\u00b7ser", "Geis\u00b7ter\u00b7zwin\u00b7ger", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ru\u00dfland steht von fern und droht,", "tokens": ["Ru\u00df\u00b7land", "steht", "von", "fern", "und", "droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ru\u00dfland hebt den kleinen Finger:", "tokens": ["Ru\u00df\u00b7land", "hebt", "den", "klei\u00b7nen", "Fin\u00b7ger", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deutsche Press', es ist dein Tod.", "tokens": ["Deut\u00b7sche", "Press'", ",", "es", "ist", "dein", "Tod", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "China wird nun auch erwachen,", "tokens": ["Chi\u00b7na", "wird", "nun", "auch", "er\u00b7wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehn was man in Deutschland schreibt,", "tokens": ["Sehn", "was", "man", "in", "Deutschland", "schreibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "PIS", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und bei Allem Einspruch machen", "tokens": ["Und", "bei", "Al\u00b7lem", "Ein\u00b7spruch", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was dir jetzt noch \u00fcbrig bleibt.", "tokens": ["Was", "dir", "jetzt", "noch", "\u00fcb\u00b7rig", "bleibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Deutsche Presse, arme Presse,", "tokens": ["Deut\u00b7sche", "Pres\u00b7se", ",", "ar\u00b7me", "Pres\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kauf dich bald in Gotha ein,", "tokens": ["Kauf", "dich", "bald", "in", "Go\u00b7tha", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "NE", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df zu deiner Todtenmesse", "tokens": ["Da\u00df", "zu", "dei\u00b7ner", "Tod\u00b7ten\u00b7mes\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns noch wird ein Pr\u00e4mienschein!", "tokens": ["Uns", "noch", "wird", "ein", "Pr\u00e4\u00b7mien\u00b7schein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}