{"textgrid.poem.34336": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Welt war immer gern betrogen,", "genre": "verse", "period": "N.A.", "pub_year": 1775, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Welt war immer gern betrogen,", "tokens": ["Die", "Welt", "war", "im\u00b7mer", "gern", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und niemand hat so sch\u00f6n gelogen", "tokens": ["Und", "nie\u00b7mand", "hat", "so", "sch\u00f6n", "ge\u00b7lo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als wer den Bart in Munde nahm,", "tokens": ["Als", "wer", "den", "Bart", "in", "Mun\u00b7de", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in der Wahrheit Mantel kam.", "tokens": ["Und", "in", "der", "Wahr\u00b7heit", "Man\u00b7tel", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur bitt ich, halte man Poeten", "tokens": ["Nur", "bitt", "ich", ",", "hal\u00b7te", "man", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "PIS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht f\u00fcr Apostel und Propheten,", "tokens": ["Nicht", "f\u00fcr", "A\u00b7pos\u00b7tel", "und", "Pro\u00b7phe\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und sagen sie, sie w\u00e4ren es,", "tokens": ["Und", "sa\u00b7gen", "sie", ",", "sie", "w\u00e4\u00b7ren", "es", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So peitscht den falschen Sokrates.", "tokens": ["So", "peitscht", "den", "fal\u00b7schen", "Sok\u00b7ra\u00b7tes", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sie wollen reitzen und gefallen,", "tokens": ["Sie", "wol\u00b7len", "reit\u00b7zen", "und", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie suchen euer Herz vor allen;", "tokens": ["Sie", "su\u00b7chen", "eu\u00b7er", "Herz", "vor", "al\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sagen was ihr gerne habt.", "tokens": ["Sie", "sa\u00b7gen", "was", "ihr", "ger\u00b7ne", "habt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr k\u00f6nnt es pr\u00fcfen, tadeln, h\u00f6hnen;", "tokens": ["Ihr", "k\u00f6nnt", "es", "pr\u00fc\u00b7fen", ",", "ta\u00b7deln", ",", "h\u00f6h\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nur, wollt ihr sie mit Dornen kr\u00f6nen,", "tokens": ["Nur", ",", "wollt", "ihr", "sie", "mit", "Dor\u00b7nen", "kr\u00f6\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VMFIN", "PPER", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bedenkt, da\u00df ihr den Zunder gabt.", "tokens": ["Be\u00b7denkt", ",", "da\u00df", "ihr", "den", "Zun\u00b7der", "gabt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Als euch, der Lust geheim zu dienen,", "tokens": ["Als", "euch", ",", "der", "Lust", "ge\u00b7heim", "zu", "die\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verbotne Freuden s\u00fcsser schienen,", "tokens": ["Ver\u00b7bot\u00b7ne", "Freu\u00b7den", "s\u00fcs\u00b7ser", "schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da machte noch ein Meisterst\u00fcck", "tokens": ["Da", "mach\u00b7te", "noch", "ein", "Meis\u00b7ter\u00b7st\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Schl\u00fcpfrigkeit bey euch sein Gl\u00fcck.", "tokens": ["Der", "Schl\u00fcpf\u00b7rig\u00b7keit", "bey", "euch", "sein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Jezt, da man andre Wollust kennet,", "tokens": ["Jezt", ",", "da", "man", "and\u00b7re", "Wol\u00b7lust", "ken\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sich ", "tokens": ["Sich"], "token_info": ["word"], "pos": ["PRF"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Ist f\u00fcr ein h\u00f6her brausend Blut", "tokens": ["Ist", "f\u00fcr", "ein", "h\u00f6\u00b7her", "brau\u00b7send", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "ADJD", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur der Entz\u00fcckung Taumel gut.", "tokens": ["Nur", "der", "Ent\u00b7z\u00fc\u00b7ckung", "Tau\u00b7mel", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Und ist die Schw\u00e4rmerey zu tadeln?", "tokens": ["Und", "ist", "die", "Schw\u00e4r\u00b7me\u00b7rey", "zu", "ta\u00b7deln", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist sie's nicht, die die Seele adeln", "tokens": ["Ist", "sie's", "nicht", ",", "die", "die", "See\u00b7le", "a\u00b7deln"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "$,", "PRELS", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und zu der G\u00f6tter Nektarku\u00df", "tokens": ["Und", "zu", "der", "G\u00f6t\u00b7ter", "Nek\u00b7tar\u00b7ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Orpheus T\u00f6nen weyhen mu\u00df,", "tokens": ["Mit", "Or\u00b7pheus", "T\u00f6\u00b7nen", "wey\u00b7hen", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem kalte Felsen selbst sich l\u00fcpften,", "tokens": ["Dem", "kal\u00b7te", "Fel\u00b7sen", "selbst", "sich", "l\u00fcpf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Str\u00f6me horchten, W\u00e4lder h\u00fcpften,", "tokens": ["Dem", "Str\u00f6\u00b7me", "horch\u00b7ten", ",", "W\u00e4l\u00b7der", "h\u00fcpf\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Zu dessen F\u00fcssen kriechend zahm", "tokens": ["Zu", "des\u00b7sen", "F\u00fcs\u00b7sen", "krie\u00b7chend", "zahm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "VVPP", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der blut'ge Tyger lekend kam?", "tokens": ["Der", "blut'\u00b7ge", "Ty\u00b7ger", "le\u00b7kend", "kam", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Liebe Traum, der Ehre Schattenbilder,", "tokens": ["Der", "Lie\u00b7be", "Traum", ",", "der", "Eh\u00b7re", "Schat\u00b7ten\u00b7bil\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sagt, machen sie die Seele wilder", "tokens": ["Sagt", ",", "ma\u00b7chen", "sie", "die", "See\u00b7le", "wil\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als thierischer Genu\u00df? und d\u00fcrfen Phantasey'n", "tokens": ["Als", "thie\u00b7ri\u00b7scher", "Ge\u00b7nu\u00df", "?", "und", "d\u00fcr\u00b7fen", "Phan\u00b7ta\u00b7sey'n"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "$.", "KON", "VMFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht ihnen auch Gew\u00e4nder leyh'n?", "tokens": ["Nicht", "ih\u00b7nen", "auch", "Ge\u00b7w\u00e4n\u00b7der", "ley\u00b7h'n", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Sagt, sind sie nichts? sind sie gef\u00e4hrlich?", "tokens": ["Sagt", ",", "sind", "sie", "nichts", "?", "sind", "sie", "ge\u00b7f\u00e4hr\u00b7lich", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VAFIN", "PPER", "PIS", "$.", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ach, oder sind sie nur beschwerlich?", "tokens": ["Ach", ",", "o\u00b7der", "sind", "sie", "nur", "be\u00b7schwer\u00b7lich", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KON", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und ruft nicht die Natur euch immer heimlich zu:", "tokens": ["Und", "ruft", "nicht", "die", "Na\u00b7tur", "euch", "im\u00b7mer", "heim\u00b7lich", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mensch, Mensch, du bist nicht f\u00fcr die Ruh!", "tokens": ["Mensch", ",", "Mensch", ",", "du", "bist", "nicht", "f\u00fcr", "die", "Ruh", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "VAFIN", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "St\u00fcrzt ein Betrogner von den H\u00f6hen,", "tokens": ["St\u00fcrzt", "ein", "Be\u00b7trog\u00b7ner", "von", "den", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die er sich aufgeth\u00fcrmt, la\u00dft uns ihn fallen sehen,", "tokens": ["Die", "er", "sich", "auf\u00b7ge\u00b7th\u00fcrmt", ",", "la\u00dft", "uns", "ihn", "fal\u00b7len", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "VVPP", "$,", "VVIMP", "PPER", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und forschen nach, warum hart unter seinem Ziel", "tokens": ["Und", "for\u00b7schen", "nach", ",", "wa\u00b7rum", "hart", "un\u00b7ter", "sei\u00b7nem", "Ziel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "PWAV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der M\u00e4rtyrer, vielleicht uns zum Exempel, fiel,", "tokens": ["Der", "M\u00e4r\u00b7ty\u00b7rer", ",", "viel\u00b7leicht", "uns", "zum", "Ex\u00b7em\u00b7pel", ",", "fiel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "APPRART", "NN", "$,", "VVFIN", "$,"], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Den Busen voll von seinen Leiden.", "tokens": ["Den", "Bu\u00b7sen", "voll", "von", "sei\u00b7nen", "Lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "La\u00dft uns den Trauerpfad vermeiden,", "tokens": ["La\u00dft", "uns", "den", "Trau\u00b7er\u00b7pfad", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auf den er sich verstieg, und suchen nebenan", "tokens": ["Auf", "den", "er", "sich", "ver\u00b7stieg", ",", "und", "su\u00b7chen", "ne\u00b7be\u00b7nan"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "PPER", "PRF", "VVFIN", "$,", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ob nicht ein be\u00dfrer uns zum Ziele f\u00fchren kann!", "tokens": ["Ob", "nicht", "ein", "be\u00df\u00b7rer", "uns", "zum", "Zie\u00b7le", "f\u00fch\u00b7ren", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Was sind wir denn, wenn zwischen Tod und Leben", "tokens": ["Was", "sind", "wir", "denn", ",", "wenn", "zwi\u00b7schen", "Tod", "und", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$,", "KOUS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir ohne Muth und Kraft gekr\u00fcmmt am Boden kleben,", "tokens": ["Wir", "oh\u00b7ne", "Muth", "und", "Kraft", "ge\u00b7kr\u00fcmmt", "am", "Bo\u00b7den", "kle\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVPP", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was sind wir denn, wir G\u00f6tter, wir,", "tokens": ["Was", "sind", "wir", "denn", ",", "wir", "G\u00f6t\u00b7ter", ",", "wir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$,", "PPER", "NN", "$,", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf diesem W\u00fcrmerneste hier?", "tokens": ["Auf", "die\u00b7sem", "W\u00fcr\u00b7mer\u00b7nes\u00b7te", "hier", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die sich durch Muskelnwitz, ha oft mit Mi\u00dfvergn\u00fcgen,", "tokens": ["Die", "sich", "durch", "Mus\u00b7keln\u00b7witz", ",", "ha", "oft", "mit", "Mi\u00df\u00b7ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "$,", "ITJ", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Um ihre Existenz betr\u00fcgen,", "tokens": ["Um", "ih\u00b7re", "E\u00b7xis\u00b7tenz", "be\u00b7tr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sich ein- und ausziehn, wie ein Wurm,", "tokens": ["Sich", "ein", "und", "aus\u00b7ziehn", ",", "wie", "ein", "Wurm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "TRUNC", "KON", "VVINF", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und sterben dann beym ersten Sturm.", "tokens": ["Und", "ster\u00b7ben", "dann", "beym", "ers\u00b7ten", "Sturm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wir sterben \u2013 pocht mit euren F\u00e4usten,", "tokens": ["Wir", "ster\u00b7ben", "\u2013", "pocht", "mit", "eu\u00b7ren", "F\u00e4us\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Freunde! auf die Brust, und schreyt: Wir sterben? Nie!", "tokens": ["Ihr", "Freun\u00b7de", "!", "auf", "die", "Brust", ",", "und", "schreyt", ":", "Wir", "ster\u00b7ben", "?", "Nie", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "$.", "PPER", "VVFIN", "$.", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit dieser Flamm' im Herzen, dieser Harmonie,", "tokens": ["Mit", "die\u00b7ser", "Flamm'", "im", "Her\u00b7zen", ",", "die\u00b7ser", "Har\u00b7mo\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPRART", "NN", "$,", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Darf sich der Tod uns je zu nah'n erdreisten?", "tokens": ["Darf", "sich", "der", "Tod", "uns", "je", "zu", "nah'n", "er\u00b7dreis\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "PPER", "ADV", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Geh'n wir ihm nicht entgegen? Flieht er nicht,", "tokens": ["Geh'n", "wir", "ihm", "nicht", "ent\u00b7ge\u00b7gen", "?", "Flieht", "er", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "PTKNEG", "PTKVZ", "$.", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Seh'n wir ihm nur getrost ins Fratzenangesicht?", "tokens": ["Seh'n", "wir", "ihm", "nur", "ge\u00b7trost", "ins", "Frat\u00b7zen\u00b7an\u00b7ge\u00b7sicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verachtet ihn, und wie vor'm Alexander", "tokens": ["Ver\u00b7ach\u00b7tet", "ihn", ",", "und", "wie", "vor'm", "A\u00b7lex\u00b7an\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KON", "PWAV", "APPRART", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "F\u00e4llt seine Plunderr\u00fcstung auseinander.", "tokens": ["F\u00e4llt", "sei\u00b7ne", "Plun\u00b7der\u00b7r\u00fcs\u00b7tung", "aus\u00b7ein\u00b7an\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die Sense m\u00e4ht den Feigen nur,", "tokens": ["Die", "Sen\u00b7se", "m\u00e4ht", "den", "Fei\u00b7gen", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und seiner Dratpupphand entreissen wir die Uhr.", "tokens": ["Und", "sei\u00b7ner", "Drat\u00b7pupp\u00b7hand", "en\u00b7treis\u00b7sen", "wir", "die", "Uhr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Wir sterben? G\u00f6tter sterben? \u2013 Nimmer \u2013", "tokens": ["Wir", "ster\u00b7ben", "?", "G\u00f6t\u00b7ter", "ster\u00b7ben", "?", "\u2013", "Nim\u00b7mer", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NN", "VVINF", "$.", "$(", "NE", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Sch\u00f6pfung Meisterst\u00fcck und Ziel?", "tokens": ["Der", "Sch\u00f6p\u00b7fung", "Meis\u00b7ter\u00b7st\u00fcck", "und", "Ziel", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer will uns t\u00f6den, zwingen? Tr\u00fcmmer", "tokens": ["Wer", "will", "uns", "t\u00f6\u00b7den", ",", "zwin\u00b7gen", "?", "Tr\u00fcm\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$,", "VVINF", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind nur f\u00fcr Menschenarbeit, nimmer", "tokens": ["Sind", "nur", "f\u00fcr", "Men\u00b7schen\u00b7ar\u00b7beit", ",", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADV", "APPR", "NN", "$,", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr einer Gottheit hohes Spiel.", "tokens": ["F\u00fcr", "ei\u00b7ner", "Got\u00b7theit", "ho\u00b7hes", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es kann ein Obeliskus st\u00fcrzen,", "tokens": ["Es", "kann", "ein", "O\u00b7be\u00b7lis\u00b7kus", "st\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Um einem h\u00f6hern Geist die Zeit zu k\u00fcrzen;", "tokens": ["Um", "ei\u00b7nem", "h\u00f6\u00b7hern", "Geist", "die", "Zeit", "zu", "k\u00fcr\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch eh mag ein System von Sonnen stille stehn", "tokens": ["Doch", "eh", "mag", "ein", "Sys\u00b7tem", "von", "Son\u00b7nen", "stil\u00b7le", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "VMFIN", "ART", "NN", "APPR", "NN", "VVFIN", "VVINF"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Als dieser G\u00f6tterhauch in unsrer Brust vergehn.", "tokens": ["Als", "die\u00b7ser", "G\u00f6t\u00b7ter\u00b7hauch", "in", "uns\u00b7rer", "Brust", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wir, Weltbeherrscher, wir, die Erben", "tokens": ["Wir", ",", "Welt\u00b7be\u00b7herr\u00b7scher", ",", "wir", ",", "die", "Er\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "PWAT", "$,", "PPER", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Von dem was da ist, sterben, sterben?", "tokens": ["Von", "dem", "was", "da", "ist", ",", "ster\u00b7ben", ",", "ster\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "PWS", "ADV", "VAFIN", "$,", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und schmeichelte und lachte dann", "tokens": ["Und", "schmei\u00b7chel\u00b7te", "und", "lach\u00b7te", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Sonne uns vergeblich an,", "tokens": ["Die", "Son\u00b7ne", "uns", "ver\u00b7geb\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die das Gef\u00fchl von W\u00e4rm' und Leben,", "tokens": ["Die", "das", "Ge\u00b7f\u00fchl", "von", "W\u00e4rm'", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Das unser Herz ihr schlagen macht,", "tokens": ["Das", "un\u00b7ser", "Herz", "ihr", "schla\u00b7gen", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wahrhaftig nicht hineingebracht,", "tokens": ["Wahr\u00b7haf\u00b7tig", "nicht", "hin\u00b7ein\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Der wir, was sie uns gab, gevierfacht wiedergeben.", "tokens": ["Der", "wir", ",", "was", "sie", "uns", "gab", ",", "ge\u00b7vier\u00b7facht", "wie\u00b7der\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "PRELS", "PPER", "PPER", "VVFIN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und traurte nicht ver\u00f6det die Natur,", "tokens": ["Und", "traur\u00b7te", "nicht", "ver\u00b7\u00f6\u00b7det", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Wenn wir, um die sie buhlt, wenn wir sie nicht gen\u00f6ssen?", "tokens": ["Wenn", "wir", ",", "um", "die", "sie", "buhlt", ",", "wenn", "wir", "sie", "nicht", "ge\u00b7n\u00f6s\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wenn wir sie nicht verg\u00f6tterten? Vergessen,", "tokens": ["Wenn", "wir", "sie", "nicht", "ver\u00b7g\u00f6t\u00b7ter\u00b7ten", "?", "Ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVINF", "$.", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Ach nicht gepriesen, nicht geliebt, gefressen", "tokens": ["Ach", "nicht", "ge\u00b7prie\u00b7sen", ",", "nicht", "ge\u00b7liebt", ",", "ge\u00b7fres\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ITJ", "PTKNEG", "VVPP", "$,", "PTKNEG", "VVPP", "$,", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Von ihren eignen Kindern, wie Saturn,", "tokens": ["Von", "ih\u00b7ren", "eig\u00b7nen", "Kin\u00b7dern", ",", "wie", "Sa\u00b7turn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PWAV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "So l\u00e4ge sie abscheulich, Babels Thurn,", "tokens": ["So", "l\u00e4\u00b7ge", "sie", "ab\u00b7scheu\u00b7lich", ",", "Ba\u00b7bels", "Thurn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "NE", "NE", "$,"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Der in die Wolken reicht, dicht unterm Ziel verfehlet,", "tokens": ["Der", "in", "die", "Wol\u00b7ken", "reicht", ",", "dicht", "un\u00b7term", "Ziel", "ver\u00b7feh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und seines Meisters Schmach entheelet.", "tokens": ["Und", "sei\u00b7nes", "Meis\u00b7ters", "Schmach", "en\u00b7thee\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Nein, leben, ewig leben wollen wir", "tokens": ["Nein", ",", "le\u00b7ben", ",", "e\u00b7wig", "le\u00b7ben", "wol\u00b7len", "wir"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "$,", "ADJD", "VVINF", "VMFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und m\u00fcssen wir, der Welt zur Ehre,", "tokens": ["Und", "m\u00fcs\u00b7sen", "wir", ",", "der", "Welt", "zur", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bis Welt und Zeit und Atmosph\u00e4re", "tokens": ["Bis", "Welt", "und", "Zeit", "und", "At\u00b7mo\u00b7sph\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An unsern Sohlen h\u00e4ngt, und gl\u00fchende Begier", "tokens": ["An", "un\u00b7sern", "Soh\u00b7len", "h\u00e4ngt", ",", "und", "gl\u00fc\u00b7hen\u00b7de", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den ungeb\u00e4ndigt stolzen Geist", "tokens": ["Den", "un\u00b7ge\u00b7b\u00e4n\u00b7digt", "stol\u00b7zen", "Geist"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von Welt zu Welt, von Sph\u00e4r zu Sph\u00e4re rei\u00dft.", "tokens": ["Von", "Welt", "zu", "Welt", ",", "von", "Sph\u00e4r", "zu", "Sph\u00e4\u00b7re", "rei\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$,", "APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ha immer uners\u00e4ttlich \u2013 leben,", "tokens": ["Ha", "im\u00b7mer", "un\u00b7er\u00b7s\u00e4tt\u00b7lich", "\u2013", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "ADV", "ADJD", "$(", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ja leben wollen wir, und beben", "tokens": ["Ja", "le\u00b7ben", "wol\u00b7len", "wir", ",", "und", "be\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "VVINF", "VMFIN", "PPER", "$,", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Soll unter unserm Tritt der Boden der uns scheut,", "tokens": ["Soll", "un\u00b7ter", "un\u00b7serm", "Tritt", "der", "Bo\u00b7den", "der", "uns", "scheut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Luft sich auseinander pressen, Streit", "tokens": ["Die", "Luft", "sich", "aus\u00b7ein\u00b7an\u00b7der", "pres\u00b7sen", ",", "Streit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "PRF", "ADV", "VVFIN", "$,", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Die Elemente f\u00fchren, die uns d\u00e4mpfen", "tokens": ["Die", "E\u00b7le\u00b7men\u00b7te", "f\u00fch\u00b7ren", ",", "die", "uns", "d\u00e4mp\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "$,", "PRELS", "PPER", "VVINF"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "Uns G\u00f6tter d\u00e4mpfen wollen, und wie M\u00e4use k\u00e4mpfen", "tokens": ["Uns", "G\u00f6t\u00b7ter", "d\u00e4mp\u00b7fen", "wol\u00b7len", ",", "und", "wie", "M\u00e4u\u00b7se", "k\u00e4mp\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VVINF", "VMFIN", "$,", "KON", "PWAV", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wir lachen ihrer todten Macht,", "tokens": ["Wir", "la\u00b7chen", "ih\u00b7rer", "tod\u00b7ten", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wie einer Maus der L\u00f6we lacht,", "tokens": ["Wie", "ei\u00b7ner", "Maus", "der", "L\u00f6\u00b7we", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und dringen br\u00fcllend fort zur Unausf\u00fcllbarkeit", "tokens": ["Und", "drin\u00b7gen", "br\u00fcl\u00b7lend", "fort", "zur", "Un\u00b7aus\u00b7f\u00fcll\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Gr\u00e4nzenlosen Ewigkeit.", "tokens": ["Der", "Gr\u00e4n\u00b7zen\u00b7lo\u00b7sen", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Das war ein Neujahrswunsch zu Pferde,", "tokens": ["Das", "war", "ein", "Neu\u00b7jahrs\u00b7wunsch", "zu", "Pfer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u1f31\u03c0\u03c0\u1f79\u03c1\u03c9\u03bc\u03bf\u03bd wie es der Grieche nennt.", "tokens": ["\u1f31\u03c0\u03c0\u03cc\u03c1\u03c9\u03bc\u03bf\u03bd", "wie", "es", "der", "Grie\u00b7che", "nennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch wem mein Fl\u00fcgelro\u00df zu hastig rennt,", "tokens": ["Doch", "wem", "mein", "Fl\u00fc\u00b7gel\u00b7ro\u00df", "zu", "has\u00b7tig", "rennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der steige mit mir auf die Erde.", "tokens": ["Der", "stei\u00b7ge", "mit", "mir", "auf", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da w\u00fcnsch ich ihm, frey von Gefahr,", "tokens": ["Da", "w\u00fcnsch", "ich", "ihm", ",", "frey", "von", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}}}}}