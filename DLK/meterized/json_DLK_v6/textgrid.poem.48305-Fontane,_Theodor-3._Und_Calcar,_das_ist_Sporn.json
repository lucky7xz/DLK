{"textgrid.poem.48305": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "3. Und Calcar, das ist Sporn", "genre": "verse", "period": "N.A.", "pub_year": 1877, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In B\u00fcchern und auf B\u00e4nken,", "tokens": ["In", "B\u00fc\u00b7chern", "und", "auf", "B\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da war er nicht zu Haus,", "tokens": ["Da", "war", "er", "nicht", "zu", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Pferd im Stall zu tr\u00e4nken,", "tokens": ["Ein", "Pferd", "im", "Stall", "zu", "tr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das sah schon besser aus;", "tokens": ["Das", "sah", "schon", "bes\u00b7ser", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "An schnallt er die silbernen Sporen,", "tokens": ["An", "schnallt", "er", "die", "sil\u00b7ber\u00b7nen", "Spo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Blaust\u00e4hlern war der Dorn \u2013", "tokens": ["Blau\u00b7st\u00e4h\u00b7lern", "war", "der", "Dorn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$("], "meter": "++-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Zu ", "tokens": ["Zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Und Calcar, das ist Sporn.", "tokens": ["Und", "Cal\u00b7car", ",", "das", "ist", "Sporn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "PDS", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Es sausen die Windm\u00fchlfl\u00fcgel,", "tokens": ["Es", "sau\u00b7sen", "die", "Wind\u00b7m\u00fchl\u00b7fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Es klappern Leiter und Steg,", "tokens": ["Es", "klap\u00b7pern", "Lei\u00b7ter", "und", "Steg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da, mit verh\u00e4ngtem Z\u00fcgel,", "tokens": ["Da", ",", "mit", "ver\u00b7h\u00e4ng\u00b7tem", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geht's unter dem Fl\u00fcgel weg,", "tokens": ["Geht's", "un\u00b7ter", "dem", "Fl\u00fc\u00b7gel", "weg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und b\u00fcckend sich vom Pferde,", "tokens": ["Und", "b\u00fc\u00b7ckend", "sich", "vom", "Pfer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "'nen vollen B\u00fcschel Korn", "tokens": ["'nen", "vol\u00b7len", "B\u00fc\u00b7schel", "Korn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Aus rei\u00dft er aus der Erde \u2013", "tokens": ["Aus", "rei\u00dft", "er", "aus", "der", "Er\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Hei, Calcar, das ist Sporn.", "tokens": ["Hei", ",", "Cal\u00b7car", ",", "das", "ist", "Sporn", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "PDS", "VAFIN", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Sie reiten \u00fcber die Br\u00fccken,", "tokens": ["Sie", "rei\u00b7ten", "\u00fc\u00b7ber", "die", "Br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und Friedrich scherzt: \u00bbJe, nun,", "tokens": ["Und", "Fried\u00b7rich", "scherzt", ":", "\u00bb", "Je", ",", "nun", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$.", "$(", "ADV", "$,", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hie Feind in Front und R\u00fccken,", "tokens": ["Hie", "Feind", "in", "Front", "und", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Seydlitz, was w\u00fcrd' Er tun?\u00ab", "tokens": ["Seyd\u00b7litz", ",", "was", "w\u00fcrd'", "Er", "tun", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "PWS", "VAFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der, \u00fcber die Br\u00fcckenwandung", "tokens": ["Der", ",", "\u00fc\u00b7ber", "die", "Br\u00fc\u00b7cken\u00b7wan\u00b7dung"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ART", "$,", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Spornt er halblinks nach vorn,", "tokens": ["Spornt", "er", "hal\u00b7blinks", "nach", "vorn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADV", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Der Strom sch\u00e4umt auf wie Brandung \u2013", "tokens": ["Der", "Strom", "sch\u00e4umt", "auf", "wie", "Bran\u00b7dung", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KOKOM", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ja, Calcar, das ist Sporn.", "tokens": ["Ja", ",", "Cal\u00b7car", ",", "das", "ist", "Sporn", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "$,", "PDS", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und andre Zeiten wieder;", "tokens": ["Und", "and\u00b7re", "Zei\u00b7ten", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "O kurzes Heldentum,", "tokens": ["O", "kur\u00b7zes", "Hel\u00b7den\u00b7tum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu Tode liegt er danieder", "tokens": ["Zu", "To\u00b7de", "liegt", "er", "da\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PAV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und l\u00e4chelt: \u00bbWas ist Ruhm?", "tokens": ["Und", "l\u00e4\u00b7chelt", ":", "\u00bb", "Was", "ist", "Ruhm", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PWS", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich h\u00f6re nun allerwegen", "tokens": ["Ich", "h\u00f6\u00b7re", "nun", "al\u00b7ler\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Eines st\u00e4rkeren Reiters Horn,", "tokens": ["Ei\u00b7nes", "st\u00e4r\u00b7ke\u00b7ren", "Rei\u00b7ters", "Horn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Aber auch ", "tokens": ["A\u00b7ber", "auch"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Denn Calcar, das ist Sporn.\u00ab", "tokens": ["Denn", "Cal\u00b7car", ",", "das", "ist", "Sporn", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "$,", "PDS", "VAFIN", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}