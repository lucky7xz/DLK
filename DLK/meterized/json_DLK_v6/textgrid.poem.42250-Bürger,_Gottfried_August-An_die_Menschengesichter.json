{"textgrid.poem.42250": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "An die Menschengesichter", "genre": "verse", "period": "N.A.", "pub_year": 1778, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe was Liebes, das hab' ich zu lieb;", "tokens": ["Ich", "ha\u00b7be", "was", "Lie\u00b7bes", ",", "das", "hab'", "ich", "zu", "lieb", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "NN", "$,", "PDS", "VAFIN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Was kann ich, was kann ich daf\u00fcr?", "tokens": ["Was", "kann", "ich", ",", "was", "kann", "ich", "da\u00b7f\u00fcr", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "$,", "PWS", "VMFIN", "PPER", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "D'rum sind mir die Menschengesichter nicht hold:", "tokens": ["D'\u00b7rum", "sind", "mir", "die", "Men\u00b7schen\u00b7ge\u00b7sich\u00b7ter", "nicht", "hold", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Doch spinn' ich ja leider nicht Seide, noch Gold,", "tokens": ["Doch", "spinn'", "ich", "ja", "lei\u00b7der", "nicht", "Sei\u00b7de", ",", "noch", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "NE", "$,", "ADV", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Ich spinne nur Herzeleid mir.", "tokens": ["Ich", "spin\u00b7ne", "nur", "Her\u00b7ze\u00b7leid", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "PPER", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Auch mich hat was Liebes im Herzen zu lieb;", "tokens": ["Auch", "mich", "hat", "was", "Lie\u00b7bes", "im", "Her\u00b7zen", "zu", "lieb", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PIS", "NN", "APPRART", "NN", "PTKA", "ADJD", "$."], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Was kann es, was kann es f\u00fcr's Herz?", "tokens": ["Was", "kann", "es", ",", "was", "kann", "es", "f\u00fcr's", "Herz", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "$,", "PWS", "VMFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Auch ihm sind die Menschengesichter nicht hold:", "tokens": ["Auch", "ihm", "sind", "die", "Men\u00b7schen\u00b7ge\u00b7sich\u00b7ter", "nicht", "hold", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Doch spinnt es ja leider nicht Seide noch Gold,", "tokens": ["Doch", "spinnt", "es", "ja", "lei\u00b7der", "nicht", "Sei\u00b7de", "noch", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "NE", "ADV", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Es spinnt sich nur Elend und Schmerz.", "tokens": ["Es", "spinnt", "sich", "nur", "E\u00b7lend", "und", "Schmerz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Wir seufzen und sehnen, wir schmachten uns nach,", "tokens": ["Wir", "seuf\u00b7zen", "und", "seh\u00b7nen", ",", "wir", "schmach\u00b7ten", "uns", "nach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVINF", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wir sehnen und seufzen uns krank.", "tokens": ["Wir", "seh\u00b7nen", "und", "seuf\u00b7zen", "uns", "krank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Die Menschengesichter verargen uns das;", "tokens": ["Die", "Men\u00b7schen\u00b7ge\u00b7sich\u00b7ter", "ver\u00b7ar\u00b7gen", "uns", "das", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PDS", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Sie reden, sie thun uns bald dies und bald das,", "tokens": ["Sie", "re\u00b7den", ",", "sie", "thun", "uns", "bald", "dies", "und", "bald", "das", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "PPER", "VVFIN", "PPER", "ADV", "PDS", "KON", "ADV", "PDS", "$,"], "meter": "-+-+++-+-+-", "measure": "unknown.measure.hexa"}, "line.5": {"text": "Und schmieden uns Fessel und Zwang.", "tokens": ["Und", "schmie\u00b7den", "uns", "Fes\u00b7sel", "und", "Zwang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Wenn ihr f\u00fcr die Leiden der Liebe was k\u00f6nnt,", "tokens": ["Wenn", "ihr", "f\u00fcr", "die", "Lei\u00b7den", "der", "Lie\u00b7be", "was", "k\u00f6nnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN", "PWS", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Gesichter, so g\u00f6nnen wir's euch.", "tokens": ["Ge\u00b7sich\u00b7ter", ",", "so", "g\u00f6n\u00b7nen", "wir's", "euch", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVINF", "VAFIN", "PPER", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Wenn wir es nicht k\u00f6nnen, so irr' es euch nicht!", "tokens": ["Wenn", "wir", "es", "nicht", "k\u00f6n\u00b7nen", ",", "so", "irr'", "es", "euch", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VMFIN", "$,", "ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Wir k\u00f6nnen, ach leider! wir k\u00f6nnen es nicht,", "tokens": ["Wir", "k\u00f6n\u00b7nen", ",", "ach", "lei\u00b7der", "!", "wir", "k\u00f6n\u00b7nen", "es", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "ITJ", "ADV", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Nicht f\u00fcr das mogolische Reich!", "tokens": ["Nicht", "f\u00fcr", "das", "mo\u00b7go\u00b7li\u00b7sche", "Reich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "Wir irren und qu\u00e4len euch Andre ja nicht;", "tokens": ["Wir", "ir\u00b7ren", "und", "qu\u00e4\u00b7len", "euch", "And\u00b7re", "ja", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "PIS", "ADV", "PTKNEG", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wir qu\u00e4len ja uns nur allein.", "tokens": ["Wir", "qu\u00e4\u00b7len", "ja", "uns", "nur", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "D'rum, Menschengesichter, wir bitten euch sehr,", "tokens": ["D'\u00b7rum", ",", "Men\u00b7schen\u00b7ge\u00b7sich\u00b7ter", ",", "wir", "bit\u00b7ten", "euch", "sehr", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "D'rum la\u00dft uns gew\u00e4hren, und qu\u00e4lt uns nicht mehr,", "tokens": ["D'\u00b7rum", "la\u00dft", "uns", "ge\u00b7w\u00e4h\u00b7ren", ",", "und", "qu\u00e4lt", "uns", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "VVINF", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.5": {"text": "O la\u00dft uns gew\u00e4hren allein!", "tokens": ["O", "la\u00dft", "uns", "ge\u00b7w\u00e4h\u00b7ren", "al\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "++--+--+", "measure": "prosodiakos"}}, "stanza.6": {"line.1": {"text": "Das dr\u00e4nget ihr euch um die Kranken herum,", "tokens": ["Das", "dr\u00e4n\u00b7get", "ihr", "euch", "um", "die", "Kran\u00b7ken", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und scheltet und schnarchet sie an?", "tokens": ["Und", "schel\u00b7tet", "und", "schnar\u00b7chet", "sie", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Von Schelten und Schnarchen genesen sie nicht.", "tokens": ["Von", "Schel\u00b7ten", "und", "Schnar\u00b7chen", "ge\u00b7ne\u00b7sen", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "PPER", "PTKNEG", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Man liebet ja Tugend, man \u00fcbet ja Pflicht;", "tokens": ["Man", "lie\u00b7bet", "ja", "Tu\u00b7gend", ",", "man", "\u00fc\u00b7bet", "ja", "Pflicht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "NN", "$,", "PIS", "VVFIN", "ADV", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Doch Keiner thut mehr, als er kann.", "tokens": ["Doch", "Kei\u00b7ner", "thut", "mehr", ",", "als", "er", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die Sonne, sie leuchtet; sie schattet, die Nacht;", "tokens": ["Die", "Son\u00b7ne", ",", "sie", "leuch\u00b7tet", ";", "sie", "schat\u00b7tet", ",", "die", "Nacht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "$,", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Hinab will der Bach, nicht hinan;", "tokens": ["Hin\u00b7ab", "will", "der", "Bach", ",", "nicht", "hi\u00b7nan", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$,", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Der Sommerwind trocknet; der Regen macht na\u00df;", "tokens": ["Der", "Som\u00b7mer\u00b7wind", "trock\u00b7net", ";", "der", "Re\u00b7gen", "macht", "na\u00df", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das Feuer verbrennet. \u2013 Wie hindert ihr das? \u2013", "tokens": ["Das", "Feu\u00b7er", "ver\u00b7bren\u00b7net", ".", "\u2013", "Wie", "hin\u00b7dert", "ihr", "das", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PWAV", "VVFIN", "PPER", "PDS", "$.", "$("], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "O la\u00dft es gew\u00e4hren, wie's kann!", "tokens": ["O", "la\u00dft", "es", "ge\u00b7w\u00e4h\u00b7ren", ",", "wie's", "kann", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "VVINF", "$,", "PWAV", "VMFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.8": {"line.1": {"text": "Es hungert den Hunger, es d\u00fcrstet den Durst;", "tokens": ["Es", "hun\u00b7gert", "den", "Hun\u00b7ger", ",", "es", "d\u00fcrs\u00b7tet", "den", "Durst", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VMFIN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sie sterben von Nahrung entfernt.", "tokens": ["Sie", "ster\u00b7ben", "von", "Nah\u00b7rung", "ent\u00b7fernt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Naturgang wendet kein Aber und Wenn. \u2013", "tokens": ["Na\u00b7tur\u00b7gang", "wen\u00b7det", "kein", "A\u00b7ber", "und", "Wenn", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "KON", "KOUS", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "O Menschengesichter, wie zwinget ihr's denn,", "tokens": ["O", "Men\u00b7schen\u00b7ge\u00b7sich\u00b7ter", ",", "wie", "zwin\u00b7get", "ih\u00b7r's", "denn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Da\u00df Liebe zu lieben verlernt?", "tokens": ["Da\u00df", "Lie\u00b7be", "zu", "lie\u00b7ben", "ver\u00b7lernt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}}}}