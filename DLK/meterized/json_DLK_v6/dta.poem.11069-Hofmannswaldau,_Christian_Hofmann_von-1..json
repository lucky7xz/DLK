{"dta.poem.11069": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein fr\u00fchling ist verschwunden,", "tokens": ["Mein", "fr\u00fch\u00b7ling", "ist", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich sp\u00fchre nichts, als rauhe winters-zeit;", "tokens": ["Ich", "sp\u00fch\u00b7re", "nichts", ",", "als", "rau\u00b7he", "win\u00b7ter\u00b7szeit", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "KOUS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das haupt h\u00e4lt flor umwunden,", "tokens": ["Das", "haupt", "h\u00e4lt", "flor", "um\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mein hertze steht in schwartzen boy gekleidt;", "tokens": ["Mein", "hert\u00b7ze", "steht", "in", "schwart\u00b7zen", "boy", "ge\u00b7kleidt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was ist die gr\u00f6sse meiner missethat,", "tokens": ["Was", "ist", "die", "gr\u00f6s\u00b7se", "mei\u00b7ner", "mis\u00b7se\u00b7that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df ich mich soll im leben selbst begraben?", "tokens": ["Da\u00df", "ich", "mich", "soll", "im", "le\u00b7ben", "selbst", "be\u00b7gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VMFIN", "APPRART", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Mein kind! der himmel lobt nicht diesen rath,", "tokens": ["Mein", "kind", "!", "der", "him\u00b7mel", "lobt", "nicht", "die\u00b7sen", "rath", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "ART", "NN", "VVFIN", "PTKNEG", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Du wilst zu schwere bu\u00df\u2019 auf kleine fehler haben.", "tokens": ["Du", "wilst", "zu", "schwe\u00b7re", "bu\u00df'", "auf", "klei\u00b7ne", "feh\u00b7ler", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich habe nichts verbrochen,", "tokens": ["Ich", "ha\u00b7be", "nichts", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mein mund hat deinen purpur nur ber\u00fchrt;", "tokens": ["Mein", "mund", "hat", "dei\u00b7nen", "pur\u00b7pur", "nur", "be\u00b7r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mu\u00df dieser seyn gerochen", "tokens": ["Mu\u00df", "die\u00b7ser", "seyn", "ge\u00b7ro\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PDAT", "PPOSAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit blitz und feur, das dein gesichte f\u00fchrt?", "tokens": ["Mit", "blitz", "und", "feur", ",", "das", "dein", "ge\u00b7sich\u00b7te", "f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dein glantz wird ja durch keinen ku\u00df versehrt:", "tokens": ["Dein", "glantz", "wird", "ja", "durch", "kei\u00b7nen", "ku\u00df", "ver\u00b7sehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was himmlisch ist, wird nie von irrdischen beflecket.", "tokens": ["Was", "himm\u00b7lisch", "ist", ",", "wird", "nie", "von", "irr\u00b7di\u00b7schen", "be\u00b7fle\u00b7cket", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VAFIN", "ADV", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was hat die sonn an ihrem schein gest\u00f6hrt,", "tokens": ["Was", "hat", "die", "sonn", "an", "ih\u00b7rem", "schein", "ge\u00b7st\u00f6hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Obgleich ihr helles licht auch schwartze erde decket.", "tokens": ["Ob\u00b7gleich", "ihr", "hel\u00b7les", "licht", "auch", "schwart\u00b7ze", "er\u00b7de", "de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dein himmel ist umzogen,", "tokens": ["Dein", "him\u00b7mel", "ist", "um\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jtzt seh ich nichts als nur cometen stehn;", "tokens": ["Jtzt", "seh", "ich", "nichts", "als", "nur", "co\u00b7me\u00b7ten", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "KOKOM", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was hat dich nun bewogen,", "tokens": ["Was", "hat", "dich", "nun", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Melinde! da\u00df dein knecht soll untergehn?", "tokens": ["Me\u00b7lin\u00b7de", "!", "da\u00df", "dein", "knecht", "soll", "un\u00b7ter\u00b7gehn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KOUS", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich bin kein holtz, auch nicht ein harter stein,", "tokens": ["Ich", "bin", "kein", "holtz", ",", "auch", "nicht", "ein", "har\u00b7ter", "stein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mein hertze mu\u00df in blut und regung wallen.", "tokens": ["Mein", "hert\u00b7ze", "mu\u00df", "in", "blut", "und", "re\u00b7gung", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Selbst engel k\u00f6nnen nicht ohn fehler seyn,", "tokens": ["Selbst", "en\u00b7gel", "k\u00f6n\u00b7nen", "nicht", "ohn", "feh\u00b7ler", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "PTKNEG", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Du weist, wie sie vor dem auch eben sind gefallen.", "tokens": ["Du", "weist", ",", "wie", "sie", "vor", "dem", "auch", "e\u00b7ben", "sind", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "APPR", "PRELS", "ADV", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch sinck ich dir zu f\u00fcssen,", "tokens": ["Doch", "sinck", "ich", "dir", "zu", "f\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Melind\u2019! allhier liegt dein entseelter knecht;", "tokens": ["Me\u00b7lind'", "!", "all\u00b7hier", "liegt", "dein", "ent\u00b7seel\u00b7ter", "knecht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er will die fehler b\u00fcssen,", "tokens": ["Er", "will", "die", "feh\u00b7ler", "b\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ach! la\u00df erbarmung gehn vor strenges recht,", "tokens": ["Ach", "!", "la\u00df", "er\u00b7bar\u00b7mung", "gehn", "vor", "stren\u00b7ges", "recht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVIMP", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nicht schaue mich mit harten blicken an!", "tokens": ["Nicht", "schau\u00b7e", "mich", "mit", "har\u00b7ten", "bli\u00b7cken", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PRF", "APPR", "ADJA", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Kein schwaches auge kan den hellen blitz ertragen,", "tokens": ["Kein", "schwa\u00b7ches", "au\u00b7ge", "kan", "den", "hel\u00b7len", "blitz", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du weist, wie leicht es um uns ist gethan,", "tokens": ["Du", "weist", ",", "wie", "leicht", "es", "um", "uns", "ist", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPER", "APPR", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wenn uns der donner will mit scharffen keilen schlagen.", "tokens": ["Wenn", "uns", "der", "don\u00b7ner", "will", "mit", "scharf\u00b7fen", "kei\u00b7len", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VMFIN", "APPR", "VVFIN", "PIAT", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "La\u00df deine sonn aufgehen,", "tokens": ["La\u00df", "dei\u00b7ne", "sonn", "auf\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So zeigt mein himmel auch sein freuden-licht.", "tokens": ["So", "zeigt", "mein", "him\u00b7mel", "auch", "sein", "freu\u00b7den\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wer kan vor dir bestehen,", "tokens": ["Wer", "kan", "vor", "dir", "be\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn rach und zorn aus deinen augen bricht?", "tokens": ["Wenn", "rach", "und", "zorn", "aus", "dei\u00b7nen", "au\u00b7gen", "bricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dr\u00fcm falle nicht der strengen meynung bey:", "tokens": ["Dr\u00fcm", "fal\u00b7le", "nicht", "der", "stren\u00b7gen", "mey\u00b7nung", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df liebes-s\u00fcnden nur sind durch den tod gehoben.", "tokens": ["Da\u00df", "lie\u00b7bes\u00b7s\u00fcn\u00b7den", "nur", "sind", "durch", "den", "tod", "ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADV", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die h\u00f6lle lehret uns, was grausam sey,", "tokens": ["Die", "h\u00f6l\u00b7le", "leh\u00b7ret", "uns", ",", "was", "grau\u00b7sam", "sey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "$,", "PRELS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Den himmel h\u00f6rt man stets von gnad und g\u00fcte loben.", "tokens": ["Den", "him\u00b7mel", "h\u00f6rt", "man", "stets", "von", "gnad", "und", "g\u00fc\u00b7te", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}