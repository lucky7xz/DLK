{"dta.poem.10888": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Herbst-Bl\u00e4tter.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1740", "urn": "urn:nbn:de:kobv:b4-200905198572", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Man sieht mit Lust, im frohen Lenzen,", "tokens": ["Man", "sieht", "mit", "Lust", ",", "im", "fro\u00b7hen", "Len\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die jungen Bl\u00e4tter lieblich gl\u00e4nzen.", "tokens": ["Die", "jun\u00b7gen", "Bl\u00e4t\u00b7ter", "lieb\u00b7lich", "gl\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie scheinen selbst vergn\u00fcgt, von lauer Luft gestreichelt,", "tokens": ["Sie", "schei\u00b7nen", "selbst", "ver\u00b7gn\u00fcgt", ",", "von", "lau\u00b7er", "Luft", "ge\u00b7strei\u00b7chelt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVPP", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Getr\u00e4nkt, erfrischet, und geschmeichelt.", "tokens": ["Ge\u00b7tr\u00e4nkt", ",", "er\u00b7fri\u00b7schet", ",", "und", "ge\u00b7schmei\u00b7chelt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "$,", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch wenn die Luft nachher sie widriger begegnet,", "tokens": ["Doch", "wenn", "die", "Luft", "nach\u00b7her", "sie", "wid\u00b7ri\u00b7ger", "be\u00b7geg\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie, bald durch D\u00fcrre schw\u00e4cht, bald sie zu stark beregnet,", "tokens": ["Sie", ",", "bald", "durch", "D\u00fcr\u00b7re", "schw\u00e4cht", ",", "bald", "sie", "zu", "stark", "be\u00b7reg\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "APPR", "NE", "VVFIN", "$,", "ADV", "PPER", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bald durch die St\u00fcrme neckt, bald durch die K\u00e4lte qu\u00e4lt,", "tokens": ["Bald", "durch", "die", "St\u00fcr\u00b7me", "neckt", ",", "bald", "durch", "die", "K\u00e4l\u00b7te", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und nimmer ruhen l\u00e4\u00dft: Scheint jedes, halb entseelt,", "tokens": ["Und", "nim\u00b7mer", "ru\u00b7hen", "l\u00e4\u00dft", ":", "Scheint", "je\u00b7des", ",", "halb", "ent\u00b7seelt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "VVFIN", "$.", "VVFIN", "PIAT", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Als ob sichs, l\u00e4nger so zu leben, abgew\u00f6hnte,", "tokens": ["Als", "ob", "sichs", ",", "l\u00e4n\u00b7ger", "so", "zu", "le\u00b7ben", ",", "ab\u00b7ge\u00b7w\u00f6hn\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "$,", "ADJD", "ADV", "PTKZU", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als wenn sichs wiederum nach seinem Ursprung sehnte,", "tokens": ["Als", "wenn", "sichs", "wie\u00b7de\u00b7rum", "nach", "sei\u00b7nem", "Ur\u00b7sprung", "sehn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und, nach der Mutter Schoo\u00df.", "tokens": ["Und", ",", "nach", "der", "Mut\u00b7ter", "Schoo\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Dahero wurden nun die Zweige pl\u00f6tzlich blo\u00df,", "tokens": ["Da\u00b7he\u00b7ro", "wur\u00b7den", "nun", "die", "Zwei\u00b7ge", "pl\u00f6tz\u00b7lich", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "ART", "NN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Indem ein jegliches, von seinem Sitz herab,", "tokens": ["In\u00b7dem", "ein", "jeg\u00b7li\u00b7ches", ",", "von", "sei\u00b7nem", "Sitz", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "$,", "APPR", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Sich nach der Mutter Schoo\u00df in aller Eil begab,", "tokens": ["Sich", "nach", "der", "Mut\u00b7ter", "Schoo\u00df", "in", "al\u00b7ler", "Eil", "be\u00b7gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und sich mit ihr vereint.", "tokens": ["Und", "sich", "mit", "ihr", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Der Bl\u00e4tterchen Betragen stellte mir,", "tokens": ["Der", "Bl\u00e4t\u00b7ter\u00b7chen", "Be\u00b7tra\u00b7gen", "stell\u00b7te", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Wie ich es \u00fcberlegt, ein n\u00fctzlichs Beyspiel f\u00fcr,", "tokens": ["Wie", "ich", "es", "\u00fc\u00b7ber\u00b7legt", ",", "ein", "n\u00fctz\u00b7lichs", "Bey\u00b7spiel", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVPP", "$,", "ART", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wenn wir in unsrer Lebenszeit,", "tokens": ["Wenn", "wir", "in", "uns\u00b7rer", "Le\u00b7bens\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Von Alter, Krankheit, Gram und Widerw\u00e4rtigkeit,", "tokens": ["Von", "Al\u00b7ter", ",", "Krank\u00b7heit", ",", "Gram", "und", "Wi\u00b7der\u00b7w\u00e4r\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Recht m\u00fcrb und matt gemacht: Wie, da\u00df wir auch, wie sie", "tokens": ["Recht", "m\u00fcrb", "und", "matt", "ge\u00b7macht", ":", "Wie", ",", "da\u00df", "wir", "auch", ",", "wie", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJD", "KON", "ADJD", "VVPP", "$.", "PWAV", "$,", "KOUS", "PPER", "ADV", "$,", "PWAV", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ohn allerley Bek\u00fcmmerni\u00df und M\u00fch,", "tokens": ["Ohn", "al\u00b7ler\u00b7ley", "Be\u00b7k\u00fcm\u00b7mer\u00b7ni\u00df", "und", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Den irdschen Theil nicht gern zu seinem Ursprung senken,", "tokens": ["Den", "ird\u00b7schen", "Theil", "nicht", "gern", "zu", "sei\u00b7nem", "Ur\u00b7sprung", "sen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Damit der andere, von allem Kummer frey,", "tokens": ["Da\u00b7mit", "der", "an\u00b7de\u00b7re", ",", "von", "al\u00b7lem", "Kum\u00b7mer", "frey", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "$,", "APPR", "PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Entfernt von Noth, Gefahr und Kr\u00e4nken,", "tokens": ["Ent\u00b7fernt", "von", "Noth", ",", "Ge\u00b7fahr", "und", "Kr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "In einer ewgen Ruhe sey!", "tokens": ["In", "ei\u00b7ner", "ew\u00b7gen", "Ru\u00b7he", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}