{"dta.poem.21765": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Wer will/ kan ein gekr\u00f6ntes Buch", "tokens": ["Wer", "will", "/", "kan", "ein", "ge\u00b7kr\u00f6n\u00b7tes", "Buch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "$(", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von schwarzen Krieges-zeilen schrei-", "tokens": ["von", "schwar\u00b7zen", "Krie\u00b7ge\u00b7szei\u00b7len", "schrei"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will auff Venus Angesuch", "tokens": ["Ich", "will", "auff", "Ve\u00b7nus", "An\u00b7ge\u00b7such"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ihr s\u00fcsses Liebes-handwerk treiben:", "tokens": ["ihr", "s\u00fcs\u00b7ses", "Lie\u00b7bes\u00b7hand\u00b7werk", "trei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich brenne. Wer nicht brennen kan/", "tokens": ["Ich", "bren\u00b7ne", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich sehe vor mir Blut und Staub/", "tokens": ["Ich", "se\u00b7he", "vor", "mir", "Blut", "und", "Staub", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und tausent Mann gewaffnet liegen/", "tokens": ["und", "tau\u00b7sent", "Mann", "ge\u00b7waff\u00b7net", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ich sehe/ wie auff Sieg und Raub", "tokens": ["ich", "se\u00b7he", "/", "wie", "auff", "Sieg", "und", "Raub"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOKOM", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "doch brenn\u2019 ich. Wer nicht brennen kan/", "tokens": ["doch", "brenn'", "ich", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich h\u00f6re der Trom\u0303peten Schall/", "tokens": ["Ich", "h\u00f6\u00b7re", "der", "Trom\u0303\u00b7pe\u00b7ten", "Schall", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "der Paukken Lerm/ den klang der Waffen/", "tokens": ["der", "Pauk\u00b7ken", "Lerm", "/", "den", "klang", "der", "Waf\u00b7fen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ART", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der schrekkenden Kartaunen knall/", "tokens": ["der", "schrek\u00b7ken\u00b7den", "Kar\u00b7tau\u00b7nen", "knall", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der B\u00fcchsen und Musketen paffen", "tokens": ["der", "B\u00fcch\u00b7sen", "und", "Mus\u00b7ke\u00b7ten", "paf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "und brenne. Wer nicht brennen kan/", "tokens": ["und", "bren\u00b7ne", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich h\u00e4tte die Gelegenheit", "tokens": ["Ich", "h\u00e4t\u00b7te", "die", "Ge\u00b7le\u00b7gen\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ein neues Jlium zumelden:", "tokens": ["ein", "neu\u00b7es", "Jlium", "zu\u00b7mel\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es gibt mir Anla\u00df mancher Streit", "tokens": ["Es", "gibt", "mir", "An\u00b7la\u00df", "man\u00b7cher", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch brenn\u2019 ich. Wer nicht brennen kan/", "tokens": ["Doch", "brenn'", "ich", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich sp\u00fcr\u2019 auch hier Ulyssens Wizz/", "tokens": ["Ich", "sp\u00fcr'", "auch", "hier", "U\u00b7lys\u00b7sens", "Wizz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NE", "NE", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "mich reizen Hektors tapfre Tahten:", "tokens": ["mich", "rei\u00b7zen", "Hek\u00b7tors", "tapf\u00b7re", "Tah\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was hilffts? mich l\u00e4st die Liebes-hizz\u2019", "tokens": ["Was", "hilffts", "?", "mich", "l\u00e4st", "die", "Lie\u00b7bes\u00b7hiz\u00b7z'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "anff andre K\u00fcnste nicht gerahten.", "tokens": ["anff", "and\u00b7re", "K\u00fcns\u00b7te", "nicht", "ge\u00b7rah\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich brenne. Wer nicht brennen kan/", "tokens": ["Ich", "bren\u00b7ne", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Was mein beflammtes Herze hegt/", "tokens": ["Was", "mein", "be\u00b7flamm\u00b7tes", "Her\u00b7ze", "hegt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zieht meinen Geist von seiner Erden:", "tokens": ["zieht", "mei\u00b7nen", "Geist", "von", "sei\u00b7ner", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "h\u00e4tt\u2019 Amors Gluht mich nicht geregt/", "tokens": ["h\u00e4tt'", "A\u00b7mors", "Gluht", "mich", "nicht", "ge\u00b7regt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "PPER", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wie w\u00fcrd\u2019 ich je beschrieen werden?", "tokens": ["wie", "w\u00fcrd'", "ich", "je", "be\u00b7schri\u00b7een", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nun brenn\u2019 ich. Wer nicht brennen kan/", "tokens": ["Nun", "brenn'", "ich", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was mir die Venus predigt ein", "tokens": ["Was", "mir", "die", "Ve\u00b7nus", "pre\u00b7digt", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ART", "NN", "VVFIN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mag meines Nahmens Lorber sein", "tokens": ["mag", "mei\u00b7nes", "Nah\u00b7mens", "Lor\u00b7ber", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst brauch\u2019 ich keiner andern Musen.", "tokens": ["Sonst", "brauch'", "ich", "kei\u00b7ner", "an\u00b7dern", "Mu\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich brenne. Wer nicht brennen kan/", "tokens": ["Ich", "bren\u00b7ne", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was frag\u2019 ich nach der Alten Neid/", "tokens": ["Was", "frag'", "ich", "nach", "der", "Al\u00b7ten", "Neid", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "was nach dem stumpfen Tadler-besen!", "tokens": ["was", "nach", "dem", "stump\u00b7fen", "Tad\u00b7ler\u00b7be\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist genug/ wenn nach der Zeit", "tokens": ["Es", "ist", "ge\u00b7nug", "/", "wenn", "nach", "der", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "$(", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mich liebe Jungfern werden lesen.", "tokens": ["mich", "lie\u00b7be", "Jung\u00b7fern", "wer\u00b7den", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich brenne. Wer nicht brennen kan/", "tokens": ["Ich", "bren\u00b7ne", ".", "Wer", "nicht", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "fang\u2019 ein ber\u00fchmter Wesen an.", "tokens": ["fang'", "ein", "be\u00b7r\u00fchm\u00b7ter", "We\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich wei\u00df/ wenn ich verweset bin/", "tokens": ["Ich", "wei\u00df", "/", "wenn", "ich", "ver\u00b7we\u00b7set", "bin", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wird mich das junge Volk betrauren/", "tokens": ["wird", "mich", "das", "jun\u00b7ge", "Volk", "be\u00b7trau\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und sagen: Ach/ da\u00df der ist hin", "tokens": ["und", "sa\u00b7gen", ":", "Ach", "/", "da\u00df", "der", "ist", "hin"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "$.", "ITJ", "$(", "KOUS", "ART", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "den Venus ewig hiesse dauren!", "tokens": ["den", "Ve\u00b7nus", "e\u00b7wig", "hies\u00b7se", "dau\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer aber nimmer brennen kan/", "tokens": ["Wer", "a\u00b7ber", "nim\u00b7mer", "bren\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wird keine Venus fangen an.", "tokens": ["wird", "kei\u00b7ne", "Ve\u00b7nus", "fan\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}