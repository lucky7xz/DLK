{"textgrid.poem.53196": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: K\u00f6nnen also schlechte Tr\u00e4wme", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "K\u00f6nnen also schlechte Tr\u00e4wme", "tokens": ["K\u00f6n\u00b7nen", "al\u00b7so", "schlech\u00b7te", "Tr\u00e4w\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jetzund Gold vnd Silber seyn?", "tokens": ["Je\u00b7tzund", "Gold", "vnd", "Sil\u00b7ber", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schickt ihr mir auff wenig Reime", "tokens": ["Schickt", "ihr", "mir", "auff", "we\u00b7nig", "Rei\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Solche sch\u00f6ne Gaben ein,", "tokens": ["Sol\u00b7che", "sch\u00f6\u00b7ne", "Ga\u00b7ben", "ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind die Zeiten mir nicht hold,", "tokens": ["Sind", "die", "Zei\u00b7ten", "mir", "nicht", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nichts, das machen sie mir Gold.", "tokens": ["Nichts", ",", "das", "ma\u00b7chen", "sie", "mir", "Gold", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PDS", "VVFIN", "PPER", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Welchen solte nicht gewinnen", "tokens": ["Wel\u00b7chen", "sol\u00b7te", "nicht", "ge\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "VMFIN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So ein sch\u00f6nes Liebe Pfand?", "tokens": ["So", "ein", "sch\u00f6\u00b7nes", "Lie\u00b7be", "Pfand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bestarb in meinen Sinnen,", "tokens": ["Ich", "be\u00b7starb", "in", "mei\u00b7nen", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Al\u00df ich seinen Glantz erkant.", "tokens": ["Al\u00df", "ich", "sei\u00b7nen", "Glantz", "er\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mein Polinchen ward wie Blut", "tokens": ["Mein", "Po\u00b7lin\u00b7chen", "ward", "wie", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fcr der Keuschen R\u00f6hte Glut.", "tokens": ["F\u00fcr", "der", "Keu\u00b7schen", "R\u00f6h\u00b7te", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Venus m\u00f6chte sich nicht sch\u00e4men", "tokens": ["Ve\u00b7nus", "m\u00f6ch\u00b7te", "sich", "nicht", "sch\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PRF", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihren s\u00fcssen Himmelswein", "tokens": ["Ih\u00b7ren", "s\u00fcs\u00b7sen", "Him\u00b7mels\u00b7wein"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Au\u00df dem K\u00e4nnchen einzunehmen,", "tokens": ["Au\u00df", "dem", "K\u00e4nn\u00b7chen", "ein\u00b7zu\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn die G\u00f6tter lustig seyn,", "tokens": ["Wenn", "die", "G\u00f6t\u00b7ter", "lus\u00b7tig", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kommen bessre Kannen nicht,", "tokens": ["Kom\u00b7men", "bess\u00b7re", "Kan\u00b7nen", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Jupiter, dir zu Gesicht.", "tokens": ["Ju\u00b7pi\u00b7ter", ",", "dir", "zu", "Ge\u00b7sicht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "APPR", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Hab ich gleich f\u00fcnff Kinder springen,", "tokens": ["Hab", "ich", "gleich", "f\u00fcnff", "Kin\u00b7der", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "CARD", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dennoch soll es Lust vnd Muht", "tokens": ["Den\u00b7noch", "soll", "es", "Lust", "vnd", "Muht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meinem Liebsten Hertzen bringen,", "tokens": ["Mei\u00b7nem", "Liebs\u00b7ten", "Hert\u00b7zen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Diesem K\u00e4nnchen nur zu gut,", "tokens": ["Die\u00b7sem", "K\u00e4nn\u00b7chen", "nur", "zu", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Solte sie seyn wie vorhin", "tokens": ["Sol\u00b7te", "sie", "seyn", "wie", "vor\u00b7hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VAINF", "KOKOM", "ADV"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "Noch einmahl Sechsw\u00f6cherin.", "tokens": ["Noch", "ein\u00b7mahl", "Sechs\u00b7w\u00f6\u00b7che\u00b7rin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Dieses kr\u00e4ncket mich f\u00fcr allen,", "tokens": ["Die\u00b7ses", "kr\u00e4n\u00b7cket", "mich", "f\u00fcr", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich also mehr vnd mehr", "tokens": ["Da\u00df", "ich", "al\u00b7so", "mehr", "vnd", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fort in ewre Schuld mu\u00df fallen,", "tokens": ["Fort", "in", "ew\u00b7re", "Schuld", "mu\u00df", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Newlich strebt ich einig sehr,", "tokens": ["New\u00b7lich", "strebt", "ich", "ei\u00b7nig", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Etwas lo\u00df von ihr zu seyn,", "tokens": ["Et\u00b7was", "lo\u00df", "von", "ihr", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd komm tieffer ietzt hinein.", "tokens": ["Vnd", "komm", "tief\u00b7fer", "ietzt", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}