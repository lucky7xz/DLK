{"textgrid.poem.49122": {"metadata": {"author": {"name": "R\u00f6ling, Johann", "birth": "N.A.", "death": "N.A."}, "title": "Von der Sch\u00f6pffung", "genre": "verse", "period": "N.A.", "pub_year": 1656, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gott, du warest f\u00fcr und f\u00fcr", "tokens": ["Gott", ",", "du", "wa\u00b7rest", "f\u00fcr", "und", "f\u00fcr"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "VAFIN", "APPR", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und von Ewigkeit in dir,", "tokens": ["Und", "von", "E\u00b7wig\u00b7keit", "in", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles selbst dir und dein eigen.", "tokens": ["Al\u00b7les", "selbst", "dir", "und", "dein", "ei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PPER", "KON", "PPOSAT", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nie ohn Werk, nie m\u00fc\u00dfig nicht,", "tokens": ["Nie", "ohn", "Werk", ",", "nie", "m\u00fc\u00b7\u00dfig", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "ADV", "ADJD", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch allein in deinem Licht,", "tokens": ["Doch", "al\u00b7lein", "in", "dei\u00b7nem", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Niemand d\u00f6rfft dir Ehr' erzeigen,", "tokens": ["Nie\u00b7mand", "d\u00f6rfft", "dir", "Ehr'", "er\u00b7zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und doch warest du erh\u00f6ht", "tokens": ["Und", "doch", "wa\u00b7rest", "du", "er\u00b7h\u00f6ht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "In der h\u00f6chsten Majest\u00e4t.", "tokens": ["In", "der", "h\u00f6chs\u00b7ten", "Ma\u00b7jes\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Herr warst du, und Herr allein,", "tokens": ["Herr", "warst", "du", ",", "und", "Herr", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "KON", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und kontst dies ohn Knechte seyn;", "tokens": ["Und", "kontst", "dies", "ohn", "Knech\u00b7te", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PDS", "APPR", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Herrlich war es, wo du wohntest,", "tokens": ["Herr\u00b7lich", "war", "es", ",", "wo", "du", "wohn\u00b7test", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es war sonst nichts, als du,", "tokens": ["Und", "es", "war", "sonst", "nichts", ",", "als", "du", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PIS", "$,", "KOUS", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aller Reichthum stand dir zu", "tokens": ["Al\u00b7ler", "Reicht\u00b7hum", "stand", "dir", "zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und doch war nicht, dem du lohntest,", "tokens": ["Und", "doch", "war", "nicht", ",", "dem", "du", "lohn\u00b7test", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PTKNEG", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Liebster Gott, ein Stand und Sitz,", "tokens": ["Liebs\u00b7ter", "Gott", ",", "ein", "Stand", "und", "Sitz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Der zu hoch f\u00fcr unsern Witz.", "tokens": ["Der", "zu", "hoch", "f\u00fcr", "un\u00b7sern", "Witz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKA", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Bi\u00df es endlich dir gefiel,", "tokens": ["Bi\u00df", "es", "end\u00b7lich", "dir", "ge\u00b7fiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df, Herr, deiner H\u00e4nde Spiel", "tokens": ["Da\u00df", ",", "Herr", ",", "dei\u00b7ner", "H\u00e4n\u00b7de", "Spiel"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "$,", "NN", "$,", "PPOSAT", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Diese Welt zuwege brachte.", "tokens": ["Die\u00b7se", "Welt", "zu\u00b7we\u00b7ge", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht bed\u00f6rfftstu dazu M\u00fch,", "tokens": ["Nicht", "be\u00b7d\u00f6rffts\u00b7tu", "da\u00b7zu", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PAV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nur ein einigs Wort war hie,", "tokens": ["Nur", "ein", "ei\u00b7nigs", "Wort", "war", "hie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Das gab an, das baut' und machte.", "tokens": ["Das", "gab", "an", ",", "das", "baut'", "und", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "$,", "PDS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Es gescheh! sprachst du allein,", "tokens": ["Es", "ge\u00b7scheh", "!", "sprachst", "du", "al\u00b7lein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Die\u00df hie\u00df Nichtes Alles seyn.", "tokens": ["Die\u00df", "hie\u00df", "Nich\u00b7tes", "Al\u00b7les", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "PIS", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "H\u00f6chster Sch\u00f6pffer, was f\u00fcr Zier,", "tokens": ["H\u00f6chs\u00b7ter", "Sch\u00f6pf\u00b7fer", ",", "was", "f\u00fcr", "Zier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was f\u00fcr Krafft mu\u00df seyn in dir,", "tokens": ["Was", "f\u00fcr", "Krafft", "mu\u00df", "seyn", "in", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VMFIN", "PPOSAT", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der ein solches Pracht-Geb\u00e4ude", "tokens": ["Der", "ein", "sol\u00b7ches", "Pracht\u00b7Ge\u00b7b\u00e4u\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So befestigt, gro\u00df und sch\u00f6n,", "tokens": ["So", "be\u00b7fes\u00b7tigt", ",", "gro\u00df", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Also leichtlich heist entstehn;", "tokens": ["Al\u00b7so", "leicht\u00b7lich", "heist", "ent\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht das Werk solch Augenweide,", "tokens": ["Macht", "das", "Werk", "solch", "Au\u00b7gen\u00b7wei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Von wie au\u00dferwehltem Schein", "tokens": ["Von", "wie", "au\u00b7\u00dfer\u00b7wehl\u00b7tem", "Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mu\u00df doch dessen Meister seyn.", "tokens": ["Mu\u00df", "doch", "des\u00b7sen", "Meis\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach, wie weis' in solcher Eyl", "tokens": ["Ach", ",", "wie", "weis'", "in", "sol\u00b7cher", "Eyl"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWAV", "VVFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat ein Jeder doch sein Theil,", "tokens": ["Hat", "ein", "Je\u00b7der", "doch", "sein", "Theil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PIS", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie schickt eines sich zum andern,", "tokens": ["Wie", "schickt", "ei\u00b7nes", "sich", "zum", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "PRF", "APPRART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was f\u00fcr Kreyse gro\u00df und klein", "tokens": ["Was", "f\u00fcr", "Krey\u00b7se", "gro\u00df", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schliessen ein den andern ein,", "tokens": ["Schlies\u00b7sen", "ein", "den", "an\u00b7dern", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ART", "ADJA", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Um das Punkt gesamt zu wandern,", "tokens": ["Um", "das", "Punkt", "ge\u00b7samt", "zu", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVPP", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das Punkt, das sich doch so weit", "tokens": ["Das", "Punkt", ",", "das", "sich", "doch", "so", "weit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "ADV", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und in so viel Reich' au\u00dfbreit.", "tokens": ["Und", "in", "so", "viel", "Reich'", "au\u00df\u00b7breit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "PIAT", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Oben spantest du dein Hau\u00df", "tokens": ["O\u00b7ben", "span\u00b7test", "du", "dein", "Hau\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie den hellsten Leinwand au\u00df,", "tokens": ["Wie", "den", "hells\u00b7ten", "Lein\u00b7wand", "au\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der, bedruckt mit g\u00fcldnen Sternen,", "tokens": ["Der", ",", "be\u00b7druckt", "mit", "g\u00fcld\u00b7nen", "Ster\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleich dem sch\u00f6nsten Stickwerk gl\u00e4nzt", "tokens": ["Gleich", "dem", "sch\u00f6ns\u00b7ten", "Stick\u00b7werk", "gl\u00e4nzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und den Herren-Stuhl umgrentzt,", "tokens": ["Und", "den", "Her\u00b7ren\u00b7Stuhl", "um\u00b7grentzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wof\u00fcr Alle dienen lernen,", "tokens": ["Wo\u00b7f\u00fcr", "Al\u00b7le", "die\u00b7nen", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und der reinen Engel Stat", "tokens": ["Und", "der", "rei\u00b7nen", "En\u00b7gel", "Stat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Ihren Stab und Sitzthum hat.", "tokens": ["Ih\u00b7ren", "Stab", "und", "Sitz\u00b7thum", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Mitten hat die Lufft den Platz,", "tokens": ["Mit\u00b7ten", "hat", "die", "Lufft", "den", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Drinn der Thau- und Regen-Schatz,", "tokens": ["Drinn", "der", "Thau", "und", "Re\u00b7gen\u00b7Schatz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hagel, Reiff und Schnee verborgen", "tokens": ["Ha\u00b7gel", ",", "Reiff", "und", "Schnee", "ver\u00b7bor\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "KON", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dein Donner sich anstimmt,", "tokens": ["Und", "dein", "Don\u00b7ner", "sich", "an\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn du \u00fcber uns ergrimmt;", "tokens": ["Wenn", "du", "\u00fc\u00b7ber", "uns", "er\u00b7grimmt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hie entfreyt sich seiner Sorgen", "tokens": ["Hie", "ent\u00b7freyt", "sich", "sei\u00b7ner", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Der erfreuten V\u00f6gel Chor", "tokens": ["Der", "er\u00b7freu\u00b7ten", "V\u00f6\u00b7gel", "Chor"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und bringt dir sein Lob-Lied vor.", "tokens": ["Und", "bringt", "dir", "sein", "Lob\u00b7Lied", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Unten blieben Erd' und Flut,", "tokens": ["Un\u00b7ten", "blie\u00b7ben", "Erd'", "und", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Stand und Ritter-Gut,", "tokens": ["Un\u00b7ser", "Stand", "und", "Rit\u00b7ter\u00b7Gut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unten an sind wir gesetzet;", "tokens": ["Un\u00b7ten", "an", "sind", "wir", "ge\u00b7set\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber welch ein mildes Feld,", "tokens": ["A\u00b7ber", "welch", "ein", "mil\u00b7des", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welch ein' hulde Garten-Welt", "tokens": ["Welch", "ein'", "hul\u00b7de", "Gar\u00b7ten\u00b7Welt"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat uns um und um ergetzet!", "tokens": ["Hat", "uns", "um", "und", "um", "er\u00b7get\u00b7zet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKVZ", "KON", "APPR", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Kr\u00e4uter, Fr\u00fcchte, Vieh und Fisch", "tokens": ["Kr\u00e4u\u00b7ter", ",", "Fr\u00fcch\u00b7te", ",", "Vieh", "und", "Fisch"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Waren All vor unsern Tisch.", "tokens": ["Wa\u00b7ren", "All", "vor", "un\u00b7sern", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "O niemals verdiente Gnad,", "tokens": ["O", "nie\u00b7mals", "ver\u00b7dien\u00b7te", "Gnad", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die uns so beg\u00fctert hat,", "tokens": ["Die", "uns", "so", "be\u00b7g\u00fc\u00b7tert", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch die der nicht zu vergleichen,", "tokens": ["Doch", "die", "der", "nicht", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welch' an uns selbst deine Hand", "tokens": ["Welch'", "an", "uns", "selbst", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "APPR", "PPER", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Als ihr Meister-St\u00fcck gewandt,", "tokens": ["Als", "ihr", "Meis\u00b7ter\u00b7St\u00fcck", "ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die, Herr, deiner Gottheit Zeichen,", "tokens": ["Die", ",", "Herr", ",", "dei\u00b7ner", "Got\u00b7theit", "Zei\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "NN", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Deine Wei\u00dfheit, deine Zier", "tokens": ["Dei\u00b7ne", "Wei\u00df\u00b7heit", ",", "dei\u00b7ne", "Zier"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Hat in uns gebildet f\u00fcr.", "tokens": ["Hat", "in", "uns", "ge\u00b7bil\u00b7det", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Aber ach, wie dankten wir", "tokens": ["A\u00b7ber", "ach", ",", "wie", "dank\u00b7ten", "wir"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PWAV", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dir doch, treuer Gott, daf\u00fcr?", "tokens": ["Dir", "doch", ",", "treu\u00b7er", "Gott", ",", "da\u00b7f\u00fcr", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJA", "NN", "$,", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles gabst du uns ohn Massen", "tokens": ["Al\u00b7les", "gabst", "du", "uns", "ohn", "Mas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur ein einger Baum allein", "tokens": ["Nur", "ein", "ein\u00b7ger", "Baum", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "Solte dir behalten seyn.", "tokens": ["Sol\u00b7te", "dir", "be\u00b7hal\u00b7ten", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sieh, den konten wir nicht lassen,", "tokens": ["Sieh", ",", "den", "kon\u00b7ten", "wir", "nicht", "las\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Nichts von Unserm stand uns an,", "tokens": ["Nichts", "von", "Un\u00b7serm", "stand", "uns", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nur was dein war muste dran.", "tokens": ["Nur", "was", "dein", "war", "mus\u00b7te", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPOSAT", "VAFIN", "ADJA", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "O ein theurer Apffel, Gott!", "tokens": ["O", "ein", "theu\u00b7rer", "Apf\u00b7fel", ",", "Gott", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "O ein eiferigs Gebott,", "tokens": ["O", "ein", "ei\u00b7fe\u00b7rigs", "Ge\u00b7bott", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das daf\u00fcr den gantzen Garten", "tokens": ["Das", "da\u00b7f\u00fcr", "den", "gant\u00b7zen", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PAV", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Uns durch strengen Spruch entzog,", "tokens": ["Uns", "durch", "stren\u00b7gen", "Spruch", "ent\u00b7zog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja, schon den zum Tode bog,", "tokens": ["Ja", ",", "schon", "den", "zum", "To\u00b7de", "bog", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ART", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Der noch erst war zu gewarten.", "tokens": ["Der", "noch", "erst", "war", "zu", "ge\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Wie k\u00f6mmt eines Menschen S\u00fcnd'", "tokens": ["Wie", "k\u00f6mmt", "ei\u00b7nes", "Men\u00b7schen", "S\u00fcnd'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Auff sein Kind und Kindes-Kind?", "tokens": ["Auff", "sein", "Kind", "und", "Kin\u00b7des\u00b7Kind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Aber, Herr, du bist gerecht,", "tokens": ["A\u00b7ber", ",", "Herr", ",", "du", "bist", "ge\u00b7recht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir sind Knecht' und b\u00f6se Knecht',", "tokens": ["Wir", "sind", "Knecht'", "und", "b\u00f6\u00b7se", "Knecht'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wir der Thon, du bist der T\u00f6pffer,", "tokens": ["Wir", "der", "Thon", ",", "du", "bist", "der", "T\u00f6pf\u00b7fer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was will jener wider den?", "tokens": ["Was", "will", "je\u00b7ner", "wi\u00b7der", "den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PDS", "APPR", "ART", "$."], "meter": "+-+----", "measure": "unknown.measure.di"}, "line.5": {"text": "So auch w\u00fcrd' es uns anstehn,", "tokens": ["So", "auch", "w\u00fcrd'", "es", "uns", "an\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Strafften wir dich, unsern Sch\u00f6pffer;", "tokens": ["Straff\u00b7ten", "wir", "dich", ",", "un\u00b7sern", "Sch\u00f6pf\u00b7fer", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Du hast dennoch deine Hand", "tokens": ["Du", "hast", "den\u00b7noch", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Nicht gantz von uns abgewandt.", "tokens": ["Nicht", "gantz", "von", "uns", "ab\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Wie uns sonst nichts helffen k\u00f6nnt,", "tokens": ["Wie", "uns", "sonst", "nichts", "helf\u00b7fen", "k\u00f6nnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIS", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hastu selbst dein Kind ernennt,", "tokens": ["Has\u00b7tu", "selbst", "dein", "Kind", "er\u00b7nennt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das f\u00fcr uns sich t\u00f6dten lassen", "tokens": ["Das", "f\u00fcr", "uns", "sich", "t\u00f6d\u00b7ten", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "PPER", "PRF", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und hiedurch uns neu erzeugt.", "tokens": ["Und", "hie\u00b7durch", "uns", "neu", "er\u00b7zeugt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "PPER", "ADJD", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Warstu vor uns so geneigt,", "tokens": ["Wars\u00b7tu", "vor", "uns", "so", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da an uns nichts, als zu hassen,", "tokens": ["Da", "an", "uns", "nichts", ",", "als", "zu", "has\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PIS", "$,", "KOUS", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Wie kanst du uns abhold seyn,", "tokens": ["Wie", "kanst", "du", "uns", "ab\u00b7hold", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "ADJD", "VAINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Da dir unser Blut gemein?", "tokens": ["Da", "dir", "un\u00b7ser", "Blut", "ge\u00b7mein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Sch\u00f6n war Alles vor gemacht,", "tokens": ["Sch\u00f6n", "war", "Al\u00b7les", "vor", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIS", "APPR", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Drum die S\u00fcnd' uns hat gebracht,", "tokens": ["Drum", "die", "S\u00fcnd'", "uns", "hat", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00f6ner aber sind wir worden,", "tokens": ["Sch\u00f6\u00b7ner", "a\u00b7ber", "sind", "wir", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PPER", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da dein auserkohrner Sohn", "tokens": ["Da", "dein", "au\u00b7ser\u00b7kohr\u00b7ner", "Sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Unser Fleisch auf seinen Thron", "tokens": ["Un\u00b7ser", "Fleisch", "auf", "sei\u00b7nen", "Thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und uns in den Himmels-Orden", "tokens": ["Und", "uns", "in", "den", "Him\u00b7mels\u00b7Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zu der h\u00f6chsten Majest\u00e4t", "tokens": ["Zu", "der", "h\u00f6chs\u00b7ten", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Aus dem Staube hat erh\u00f6ht.", "tokens": ["Aus", "dem", "Stau\u00b7be", "hat", "er\u00b7h\u00f6ht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Herr, wie gro\u00df ist deine G\u00fct!", "tokens": ["Herr", ",", "wie", "gro\u00df", "ist", "dei\u00b7ne", "G\u00fct", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Stell mir dieses zu Gem\u00fcth,", "tokens": ["Stell", "mir", "die\u00b7ses", "zu", "Ge\u00b7m\u00fcth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PDAT", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich nicht undankbar werde;", "tokens": ["Da\u00df", "ich", "nicht", "un\u00b7dank\u00b7bar", "wer\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Trag' ich denn itzt wenig ein,", "tokens": ["Trag'", "ich", "denn", "itzt", "we\u00b7nig", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wird es k\u00fcnfftig besser seyn.", "tokens": ["Wird", "es", "k\u00fcnff\u00b7tig", "bes\u00b7ser", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil ich hie bin, geb' ich Erde,", "tokens": ["Weil", "ich", "hie", "bin", ",", "geb'", "ich", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "$,", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Machest du mich himmlisch dort,", "tokens": ["Ma\u00b7chest", "du", "mich", "himm\u00b7lisch", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Soll auch himmlisch sein mein Wort.", "tokens": ["Soll", "auch", "himm\u00b7lisch", "sein", "mein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Zweymal hastu mich bereit,", "tokens": ["Zwey\u00b7mal", "has\u00b7tu", "mich", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Erst erschaffen, nach erneut;", "tokens": ["Erst", "er\u00b7schaf\u00b7fen", ",", "nach", "er\u00b7neut", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "APPR", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Noch das drittemal ist \u00fcber,", "tokens": ["Noch", "das", "drit\u00b7te\u00b7mal", "ist", "\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADV", "VAFIN", "APPR", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn du meinen Todt belebst", "tokens": ["Wenn", "du", "mei\u00b7nen", "Todt", "be\u00b7lebst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und mich au\u00df dem Grabe hebst.", "tokens": ["Und", "mich", "au\u00df", "dem", "Gra\u00b7be", "hebst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ach, je \u00f6ffter, Herr, je lieber!", "tokens": ["Ach", ",", "je", "\u00f6ff\u00b7ter", ",", "Herr", ",", "je", "lie\u00b7ber", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "ADJD", "$,", "NN", "$,", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Drey ist vollkommn insgemein,", "tokens": ["Drey", "ist", "voll\u00b7kommn", "ins\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "VAFIN", "ADJD", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "La\u00df auch so mein drittes seyn.", "tokens": ["La\u00df", "auch", "so", "mein", "drit\u00b7tes", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "PPOSAT", "ADJA", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}