{"textgrid.poem.56165": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "24.", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O diese Lust, immer neu, aus gelockertem Lehm!", "tokens": ["O", "die\u00b7se", "Lust", ",", "im\u00b7mer", "neu", ",", "aus", "ge\u00b7lo\u00b7cker\u00b7tem", "Lehm", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "$,", "ADV", "ADJD", "$,", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.2": {"text": "Niemand beinah hat den fr\u00fchesten Wagern geholfen.", "tokens": ["Nie\u00b7mand", "bei\u00b7nah", "hat", "den", "fr\u00fc\u00b7hes\u00b7ten", "Wa\u00b7gern", "ge\u00b7hol\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "St\u00e4dte entstanden trotzdem an beseligten Golfen,", "tokens": ["St\u00e4d\u00b7te", "ent\u00b7stan\u00b7den", "trotz\u00b7dem", "an", "be\u00b7se\u00b7lig\u00b7ten", "Gol\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Wasser und \u00d6l f\u00fcllten die Kr\u00fcge trotzdem.", "tokens": ["Was\u00b7ser", "und", "\u00d6l", "f\u00fcll\u00b7ten", "die", "Kr\u00fc\u00b7ge", "trotz\u00b7dem", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "ART", "NN", "PAV", "$."], "meter": "+--++--+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "G\u00f6tter, wir planen sie erst in erk\u00fchnten Entw\u00fcrfen,", "tokens": ["G\u00f6t\u00b7ter", ",", "wir", "pla\u00b7nen", "sie", "erst", "in", "er\u00b7k\u00fchn\u00b7ten", "Ent\u00b7w\u00fcr\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "die uns das m\u00fcrrische Schicksal wieder zerst\u00f6rt.", "tokens": ["die", "uns", "das", "m\u00fcr\u00b7ri\u00b7sche", "Schick\u00b7sal", "wie\u00b7der", "zer\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Aber sie sind die Unsterblichen. Sehet, wir d\u00fcrfen", "tokens": ["A\u00b7ber", "sie", "sind", "die", "U\u00b7nsterb\u00b7li\u00b7chen", ".", "Se\u00b7het", ",", "wir", "d\u00fcr\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "$.", "VVFIN", "$,", "PPER", "VMFIN"], "meter": "+--+-+---+--+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "jenen erhorchen, der uns am Ende erh\u00f6rt.", "tokens": ["je\u00b7nen", "er\u00b7hor\u00b7chen", ",", "der", "uns", "am", "En\u00b7de", "er\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "$,", "PRELS", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Wir, ein Geschlecht durch Jahrtausende: M\u00fctter und V\u00e4ter,", "tokens": ["Wir", ",", "ein", "Ge\u00b7schlecht", "durch", "Jahr\u00b7tau\u00b7sen\u00b7de", ":", "M\u00fct\u00b7ter", "und", "V\u00e4\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "APPR", "NN", "$.", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "immer erf\u00fcllter von dem k\u00fcnftigen Kind,", "tokens": ["im\u00b7mer", "er\u00b7f\u00fcll\u00b7ter", "von", "dem", "k\u00fcnf\u00b7ti\u00b7gen", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.3": {"text": "da\u00df es uns einst, \u00fcbersteigend, ersch\u00fcttere, sp\u00e4ter.", "tokens": ["da\u00df", "es", "uns", "einst", ",", "\u00fc\u00b7bers\u00b7tei\u00b7gend", ",", "er\u00b7sch\u00fct\u00b7te\u00b7re", ",", "sp\u00e4\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "$,", "VVPP", "$,", "ADJA", "$,", "ADJD", "$."], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}}, "stanza.4": {"line.1": {"text": "Wir, wir unendlich Gewagten, was haben wir Zeit!", "tokens": ["Wir", ",", "wir", "un\u00b7end\u00b7lich", "Ge\u00b7wag\u00b7ten", ",", "was", "ha\u00b7ben", "wir", "Zeit", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "ADJD", "NN", "$,", "PWS", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und nur der schweigsame Tod, der wei\u00df, was wir sind", "tokens": ["Und", "nur", "der", "schweig\u00b7sa\u00b7me", "Tod", ",", "der", "wei\u00df", ",", "was", "wir", "sind"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "$,", "PRELS", "PPER", "VAFIN"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "und was er immer gewinnt, wenn er uns leiht.", "tokens": ["und", "was", "er", "im\u00b7mer", "ge\u00b7winnt", ",", "wenn", "er", "uns", "leiht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}}}}