{"textgrid.poem.44556": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "[seht an uns hier in kriegrischer Tracht]", "genre": "verse", "period": "N.A.", "pub_year": 1848, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Seht an uns hier in kriegrischer Tracht,", "tokens": ["Seht", "an", "uns", "hier", "in", "krie\u00b7gri\u00b7scher", "Tracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wir sind die Wiener Studenten,", "tokens": ["Wir", "sind", "die", "Wie\u00b7ner", "Stu\u00b7den\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Wir haben studiert bei Tag und Nacht", "tokens": ["Wir", "ha\u00b7ben", "stu\u00b7diert", "bei", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "NN", "KON", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und haben endlich auf eins gebracht,", "tokens": ["Und", "ha\u00b7ben", "end\u00b7lich", "auf", "eins", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Was Furcht und Gewohnheit trennten.", "tokens": ["Was", "Furcht", "und", "Ge\u00b7wohn\u00b7heit", "trenn\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Die ewige Herrschaft des ewigen Rechts,", "tokens": ["Die", "e\u00b7wi\u00b7ge", "Herr\u00b7schaft", "des", "e\u00b7wi\u00b7gen", "Rechts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Arzenei f\u00fcr die Seelen,", "tokens": ["Die", "Ar\u00b7ze\u00b7nei", "f\u00fcr", "die", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Polytechnik des Menschengeschlechts,", "tokens": ["Die", "Po\u00b7ly\u00b7tech\u00b7nik", "des", "Men\u00b7schen\u00b7ge\u00b7schlechts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Philosophie, wo statt Wortgefechts", "tokens": ["Die", "Phi\u00b7lo\u00b7so\u00b7phie", ",", "wo", "statt", "Wort\u00b7ge\u00b7fechts"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "APPR", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Die Geister zu Taten sich st\u00e4hlen.", "tokens": ["Die", "Geis\u00b7ter", "zu", "Ta\u00b7ten", "sich", "st\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PRF", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Die Pr\u00fcfung aber war scharf und schnell,", "tokens": ["Die", "Pr\u00fc\u00b7fung", "a\u00b7ber", "war", "scharf", "und", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es gab ein schweres Examen,", "tokens": ["Es", "gab", "ein", "schwe\u00b7res", "E\u00b7xa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Kugeln pfiffen die Fragen hell,", "tokens": ["Die", "Ku\u00b7geln", "pfif\u00b7fen", "die", "Fra\u00b7gen", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Tod stand nah als grimmer Pedell,", "tokens": ["Der", "Tod", "stand", "nah", "als", "grim\u00b7mer", "Pe\u00b7dell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Der Karzer war nicht blo\u00df ein Namen.", "tokens": ["Der", "Kar\u00b7zer", "war", "nicht", "blo\u00df", "ein", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wir aber bestanden und sind graduiert,", "tokens": ["Wir", "a\u00b7ber", "be\u00b7stan\u00b7den", "und", "sind", "gra\u00b7du\u00b7iert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "KON", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wer k\u00f6nnte, was wir nicht k\u00f6nnten!", "tokens": ["Wer", "k\u00f6nn\u00b7te", ",", "was", "wir", "nicht", "k\u00f6nn\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,", "PRELS", "PPER", "PTKNEG", "VMFIN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Die Hefte, wobei wir die Feder gef\u00fchrt,", "tokens": ["Die", "Hef\u00b7te", ",", "wo\u00b7bei", "wir", "die", "Fe\u00b7der", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Sie werden wohl noch von der Nachwelt studiert:", "tokens": ["Sie", "wer\u00b7den", "wohl", "noch", "von", "der", "Nach\u00b7welt", "stu\u00b7diert", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Halloh, die Wiener Studenten.", "tokens": ["Hal\u00b7loh", ",", "die", "Wie\u00b7ner", "Stu\u00b7den\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+--+-+--", "measure": "iambic.tri.invert"}}}}}