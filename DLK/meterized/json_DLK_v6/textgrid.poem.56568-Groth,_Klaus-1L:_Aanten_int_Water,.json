{"textgrid.poem.56568": {"metadata": {"author": {"name": "Groth, Klaus", "birth": "N.A.", "death": "N.A."}, "title": "1L: Aanten int Water,", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Aanten int Water,", "tokens": ["Aan\u00b7ten", "int", "Wa\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wat v\u0153rn Gesnater!", "tokens": ["Wat", "v\u0153rn", "Ges\u00b7na\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Aanten in Dik,", "tokens": ["Aan\u00b7ten", "in", "Dik", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wat v\u0153rn Musik!", "tokens": ["Wat", "v\u0153rn", "Mu\u00b7sik", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "De Wart is wat heesch: Wat wat wat sch\u00fcll wi \u0119ten?", "tokens": ["De", "Wart", "is", "wat", "heesch", ":", "Wat", "wat", "wat", "sch\u00fcll", "wi", "\u0119ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "ADJD", "$.", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Murt, inne Murt, inne Grund is dat fett!", "tokens": ["Murt", ",", "in\u00b7ne", "Murt", ",", "in\u00b7ne", "Grund", "is", "dat", "fett", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "H\u00f6ja! de graue fangt lud an to r\u0119den:", "tokens": ["H\u00f6\u00b7ja", "!", "de", "grau\u00b7e", "fangt", "lud", "an", "to", "r\u0119\u00b7den", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Quark un warm Water! un alle ropt mit.", "tokens": ["Quark", "un", "warm", "Wa\u00b7ter", "!", "un", "al\u00b7le", "ropt", "mit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "FM", "ADJD", "NN", "$.", "FM", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Aanten int Water,", "tokens": ["Aan\u00b7ten", "int", "Wa\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wat v\u0153rn Gesnater!", "tokens": ["Wat", "v\u0153rn", "Ges\u00b7na\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Aanten in Dik,", "tokens": ["Aan\u00b7ten", "in", "Dik", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wat v\u0153rn Musik!", "tokens": ["Wat", "v\u0153rn", "Mu\u00b7sik", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "De R\u00fcnnsteen hentlank all int Tr\u00fcnneln un Snappeln!", "tokens": ["De", "R\u00fcnn\u00b7steen", "hent\u00b7lank", "all", "int", "Tr\u00fcn\u00b7neln", "un", "Snap\u00b7peln", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PIAT", "FM", "FM", "FM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Barbeent un plattf\u00f6t, un j\u00fcmmer vergn\u00f6gt!", "tokens": ["Barb\u00b7eent", "un", "platt\u00b7f\u00f6t", ",", "un", "j\u00fcm\u00b7mer", "ver\u00b7gn\u00f6gt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "$,", "FM", "ADV", "VVPP", "$."], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Hier is de K\u0153kengu\u00df! Beersupp mit Appeln!", "tokens": ["Hier", "is", "de", "K\u0153ken\u00b7gu\u00df", "!", "Beer\u00b7supp", "mit", "Ap\u00b7peln", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "NN", "$.", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wackeli, gackeli \u2013 s\u00fch, wa se s\u00f6kt!", "tokens": ["Wa\u00b7cke\u00b7li", ",", "ga\u00b7cke\u00b7li", "\u2013", "s\u00fch", ",", "wa", "se", "s\u00f6kt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$(", "ADJD", "$,", "FM", "FM", "FM", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.5": {"line.1": {"text": "Aanten int Water,", "tokens": ["Aan\u00b7ten", "int", "Wa\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wat v\u0153rn Gesnater!", "tokens": ["Wat", "v\u0153rn", "Ges\u00b7na\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Aanten in Dik,", "tokens": ["Aan\u00b7ten", "in", "Dik", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wat v\u0153rn Musik!", "tokens": ["Wat", "v\u0153rn", "Mu\u00b7sik", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Nu oppen Wall! un nu ropt wi de G\u00fcnner!", "tokens": ["Nu", "op\u00b7pen", "Wall", "!", "un", "nu", "ropt", "wi", "de", "G\u00fcn\u00b7ner", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$.", "FM", "ADV", "ADJD", "KOKOM", "NE", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nu kamt se an, un nu gift dat en Snack.", "tokens": ["Nu", "kamt", "se", "an", ",", "un", "nu", "gift", "dat", "en", "Snack", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$,", "FM", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Nu fleegt wi dal un nu dukt wi uns \u00fcnner!", "tokens": ["Nu", "fleegt", "wi", "dal", "un", "nu", "dukt", "wi", "uns", "\u00fcn\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "FM", "FM", "FM", "ADV", "ADJD", "KOKOM", "PPER", "ADJD", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "All dat warm Water l\u00f6ppt blank vunne Nack!", "tokens": ["All", "dat", "warm", "Wa\u00b7ter", "l\u00f6ppt", "blank", "vun\u00b7ne", "Nack", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "NN", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Aanten int Water,", "tokens": ["Aan\u00b7ten", "int", "Wa\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wat v\u0153rn Gesnater!", "tokens": ["Wat", "v\u0153rn", "Ges\u00b7na\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Aanten in Dik,", "tokens": ["Aan\u00b7ten", "in", "Dik", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wat v\u0153rn Musik!", "tokens": ["Wat", "v\u0153rn", "Mu\u00b7sik", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Wat wat wat w\u00fcllt wi? nu w\u00fcllt wi na'n Misten.", "tokens": ["Wat", "wat", "wat", "w\u00fcllt", "wi", "?", "nu", "w\u00fcllt", "wi", "na'n", "Mis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "ADV", "VVFIN", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "H\u00f6r! se d\u00f6scht Weten! wi krupt d\u0153r de Rill!", "tokens": ["H\u00f6r", "!", "se", "d\u00f6scht", "We\u00b7ten", "!", "wi", "krupt", "d\u0153r", "de", "Rill", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "FM", "FM", "NN", "$.", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Kamt man! man sachden! op T\u00f6ntjen! mit Listen!", "tokens": ["Kamt", "man", "!", "man", "sach\u00b7den", "!", "op", "T\u00f6nt\u00b7jen", "!", "mit", "Lis\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$.", "PIS", "VVINF", "$.", "NE", "NE", "$.", "APPR", "NN", "$."], "meter": "+--+--++-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "N\u00fcckt mit den Kopp, un \u0119t gau, un swigt still!", "tokens": ["N\u00fcckt", "mit", "den", "Kopp", ",", "un", "\u0119t", "gau", ",", "un", "swigt", "still", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "FM.fr", "FM.fr", "FM.fr", "$,", "FM", "VVFIN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.9": {"line.1": {"text": "Aanten int Water,", "tokens": ["Aan\u00b7ten", "int", "Wa\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wat v\u0153rn Gesnater!", "tokens": ["Wat", "v\u0153rn", "Ges\u00b7na\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Aanten int Stroh \u2013", "tokens": ["Aan\u00b7ten", "int", "Stroh", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wat v\u0153rn Halloh!", "tokens": ["Wat", "v\u0153rn", "Hal\u00b7loh", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Dar kumt de K\u0153ksch! neiht man ut, brukt de Fl\u00fcnken!", "tokens": ["Dar", "kumt", "de", "K\u0153ksch", "!", "neiht", "man", "ut", ",", "brukt", "de", "Fl\u00fcn\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "NE", "$.", "VVFIN", "PIS", "ADJD", "$,", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hoch \u0153wern Tun, un koppheister na'n Dik!", "tokens": ["Hoch", "\u0153wern", "Tun", ",", "un", "kop\u00b7pheis\u00b7ter", "na'n", "Dik", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "FM", "ADJA", "ADJA", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Swimm' as de Pocken, un flegen as L\u00fcnken,", "tokens": ["Swimm'", "as", "de", "Po\u00b7cken", ",", "un", "fle\u00b7gen", "as", "L\u00fcn\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NN", "$,", "FM", "FM", "FM", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Klok as en Minsch \u2013 un so dick! un so dick!", "tokens": ["Klok", "as", "en", "Minsch", "\u2013", "un", "so", "dick", "!", "un", "so", "dick", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$(", "FM", "ADV", "ADJD", "$.", "FM", "ADV", "ADJD", "$."], "meter": "-+-++-+--+", "measure": "iambic.penta.chol"}}, "stanza.11": {"line.1": {"text": "Aanten int Water,", "tokens": ["Aan\u00b7ten", "int", "Wa\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wat v\u0153rn Gesnater!", "tokens": ["Wat", "v\u0153rn", "Ges\u00b7na\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Aanten in Dik,", "tokens": ["Aan\u00b7ten", "in", "Dik", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wat v\u0153rn Musik!", "tokens": ["Wat", "v\u0153rn", "Mu\u00b7sik", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}