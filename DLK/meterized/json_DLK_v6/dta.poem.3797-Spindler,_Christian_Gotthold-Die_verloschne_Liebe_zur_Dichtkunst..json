{"dta.poem.3797": {"metadata": {"author": {"name": "Spindler, Christian Gotthold", "birth": "N.A.", "death": "N.A."}, "title": "Die verloschne Liebe zur Dichtkunst.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1745", "urn": "urn:nbn:de:kobv:b4-20581-9", "language": ["de:0.99"], "booktitle": "Spindler, Christian Gotthold: Unschuldige Jugend-Fr\u00fcchte. Leipzig, 1745."}, "poem": {"stanza.1": {"line.1": {"text": "Herr Bruder! wilt du etwa wissen,", "tokens": ["Herr", "Bru\u00b7der", "!", "wilt", "du", "et\u00b7wa", "wis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum ich gar so traurig bin?", "tokens": ["Wa\u00b7rum", "ich", "gar", "so", "trau\u00b7rig", "bin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du kanst es aus den Zeilen schliessen,", "tokens": ["Du", "kanst", "es", "aus", "den", "Zei\u00b7len", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Er hincket schon auf allen vieren,", "tokens": ["Er", "hin\u00b7cket", "schon", "auf", "al\u00b7len", "vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich werd ihn balde gar verliehren,", "tokens": ["Ich", "werd", "ihn", "bal\u00b7de", "gar", "ver\u00b7lieh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nun liegt der gantze Dichter-Kram,", "tokens": ["Nun", "liegt", "der", "gant\u00b7ze", "Dich\u00b7ter\u00b7Kram", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}}, "stanza.2": {"line.1": {"text": "Herr Bruder! das heist recht geschoren!", "tokens": ["Herr", "Bru\u00b7der", "!", "das", "heist", "recht", "ge\u00b7scho\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "PDS", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Sieh nur, was hab ich denn davon?", "tokens": ["Sieh", "nur", ",", "was", "hab", "ich", "denn", "da\u00b7von", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PWS", "VAFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Drey Eisen sind bereits verlohren,", "tokens": ["Drey", "Ei\u00b7sen", "sind", "be\u00b7reits", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und auch das vierte wackelt schon.", "tokens": ["Und", "auch", "das", "vier\u00b7te", "wa\u00b7ckelt", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun ruffet jener Splitter-Richter:", "tokens": ["Nun", "ruf\u00b7fet", "je\u00b7ner", "Split\u00b7ter\u00b7Rich\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da lieget nun der arme Dichter,", "tokens": ["Da", "lie\u00b7get", "nun", "der", "ar\u00b7me", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da liegt er nun mit sammt dem Gaul;", "tokens": ["Da", "liegt", "er", "nun", "mit", "sammt", "dem", "Gaul", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So zieht ", "tokens": ["So", "zieht"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.3": {"line.1": {"text": "Er suchet mich recht abzukappen,", "tokens": ["Er", "su\u00b7chet", "mich", "recht", "ab\u00b7zu\u00b7kap\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jtzt lachet der Verwegne frey,", "tokens": ["Jtzt", "la\u00b7chet", "der", "Ver\u00b7weg\u00b7ne", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er spricht: da liegt des Dichters Rappen", "tokens": ["Er", "spricht", ":", "da", "liegt", "des", "Dich\u00b7ters", "Rap\u00b7pen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit seiner gantzen Reuterey,", "tokens": ["Mit", "sei\u00b7ner", "gant\u00b7zen", "Reu\u00b7te\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun hat er Sattel, Zeug und Spohren,", "tokens": ["Nun", "hat", "er", "Sat\u00b7tel", ",", "Zeug", "und", "Spoh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ja auch den K\u00fctzel selbst verlohren.", "tokens": ["Ja", "auch", "den", "K\u00fct\u00b7zel", "selbst", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da liegt das arme matte Pferd,", "tokens": ["Da", "liegt", "das", "ar\u00b7me", "mat\u00b7te", "Pferd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und ist nicht einen Batzen wehrt.", "tokens": ["Und", "ist", "nicht", "ei\u00b7nen", "Bat\u00b7zen", "wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sieh nur, auf solche falsche Weise,", "tokens": ["Sieh", "nur", ",", "auf", "sol\u00b7che", "fal\u00b7sche", "Wei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da nun mein lieber Rappen hin,", "tokens": ["Da", "nun", "mein", "lie\u00b7ber", "Rap\u00b7pen", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Macht mir verzweiffelt b\u00f6se M\u00e4use,", "tokens": ["Macht", "mir", "ver\u00b7zweif\u00b7felt", "b\u00f6\u00b7se", "M\u00e4u\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Der weggeworffne Mann, ", "tokens": ["Der", "weg\u00b7ge\u00b7worff\u00b7ne", "Mann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und balde wird ers gar noch wagen,", "tokens": ["Und", "bal\u00b7de", "wird", "ers", "gar", "noch", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIS", "ADV", "ADV", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Das Creutz ihm vollends einzuschlagen,", "tokens": ["Das", "Creutz", "ihm", "vol\u00b7lends", "ein\u00b7zu\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Er hat bereits den Schlu\u00df gefast,", "tokens": ["Er", "hat", "be\u00b7reits", "den", "Schlu\u00df", "ge\u00b7fast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das arme Thier ist ihm verhast.", "tokens": ["Das", "ar\u00b7me", "Thier", "ist", "ihm", "ver\u00b7hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Um nun das liebe Pferd zu heilen,", "tokens": ["Um", "nun", "das", "lie\u00b7be", "Pferd", "zu", "hei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind schon zwey frische Boten fort.", "tokens": ["Sind", "schon", "zwey", "fri\u00b7sche", "Bo\u00b7ten", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "CARD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich schickte sie mit vollen Eilen,", "tokens": ["Ich", "schick\u00b7te", "sie", "mit", "vol\u00b7len", "Ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An jenes angenehme Ort,", "tokens": ["An", "je\u00b7nes", "an\u00b7ge\u00b7neh\u00b7me", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Und wo der Dichtkunst Schutzgeist thronet;", "tokens": ["Und", "wo", "der", "Dicht\u00b7kunst", "Schutz\u00b7geist", "thro\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Denn dieser frommen Schwestern Zahl", "tokens": ["Denn", "die\u00b7ser", "from\u00b7men", "Schwes\u00b7tern", "Zahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wei\u00df Mittel vor dergleichen Quaal.", "tokens": ["Wei\u00df", "Mit\u00b7tel", "vor", "derg\u00b7lei\u00b7chen", "Qua\u00b7al", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "PIS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich habe dir ein grosses Schreiben", "tokens": ["Ich", "ha\u00b7be", "dir", "ein", "gros\u00b7ses", "Schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit viel Crimassen ausgespickt,", "tokens": ["Mit", "viel", "Cri\u00b7mas\u00b7sen", "aus\u00b7ge\u00b7spickt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie solten diese Noth vertreiben,", "tokens": ["Sie", "sol\u00b7ten", "die\u00b7se", "Noth", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu ihren Bergen abgeschickt.", "tokens": ["Zu", "ih\u00b7ren", "Ber\u00b7gen", "ab\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Herr Bruder! ach schon ehegestern", "tokens": ["Herr", "Bru\u00b7der", "!", "ach", "schon", "e\u00b7he\u00b7ge\u00b7stern"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$.", "ADV", "ADV", "VVINF"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Schickt ich zu diesen lieben Schwestern.", "tokens": ["Schickt", "ich", "zu", "die\u00b7sen", "lie\u00b7ben", "Schwes\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vieleicht thut der ", "tokens": ["Vie\u00b7leicht", "thut", "der"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Mein Ungl\u00fccks-Fall in etwas weh.", "tokens": ["Mein", "Un\u00b7gl\u00fccks\u00b7Fall", "in", "et\u00b7was", "weh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Denn meinem Gaule hilfft kein Schmieren,", "tokens": ["Denn", "mei\u00b7nem", "Gau\u00b7le", "hilfft", "kein", "Schmie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Pflaster, ", "tokens": ["Kein", "Pflas\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Mit Pillen kan ich nicht curiren,", "tokens": ["Mit", "Pil\u00b7len", "kan", "ich", "nicht", "cu\u00b7ri\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das n\u00e4hm ihm vollends alle Krafft;", "tokens": ["Das", "n\u00e4hm", "ihm", "vol\u00b7lends", "al\u00b7le", "Krafft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und braucht ich gleich Barbier und Bader,", "tokens": ["Und", "braucht", "ich", "gleich", "Bar\u00b7bier", "und", "Ba\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Lie\u00df ich ihm hundertmahl zur Ader,", "tokens": ["Lie\u00df", "ich", "ihm", "hun\u00b7dert\u00b7mahl", "zur", "A\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Braucht ich ", "tokens": ["Braucht", "ich"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Das hilfft dir alles nicht daf\u00fcr.", "tokens": ["Das", "hilfft", "dir", "al\u00b7les", "nicht", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIS", "PTKNEG", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Das letzte Mittel will ich wagen,", "tokens": ["Das", "letz\u00b7te", "Mit\u00b7tel", "will", "ich", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Damit es nur nicht gar vergeht,", "tokens": ["Da\u00b7mit", "es", "nur", "nicht", "gar", "ver\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Bote wird schon Antwort sagen,", "tokens": ["Der", "Bo\u00b7te", "wird", "schon", "Ant\u00b7wort", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ob ihm auch noch zu helffen steht.", "tokens": ["Ob", "ihm", "auch", "noch", "zu", "helf\u00b7fen", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vieleicht schickt eine solche Sch\u00f6ne", "tokens": ["Vie\u00b7leicht", "schickt", "ei\u00b7ne", "sol\u00b7che", "Sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Fl\u00e4schgen von der ", "tokens": ["Ein", "Fl\u00e4schgen", "von", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART"], "meter": "-+--", "measure": "dactylic.init"}, "line.7": {"text": "Doch Bruder! komme bald zu mir,", "tokens": ["Doch", "Bru\u00b7der", "!", "kom\u00b7me", "bald", "zu", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "VVFIN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich habe etwas anders f\u00fcr.", "tokens": ["Ich", "ha\u00b7be", "et\u00b7was", "an\u00b7ders", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der edle ", "tokens": ["Der", "ed\u00b7le"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Sey unser Labsal in der Noth.", "tokens": ["Sey", "un\u00b7ser", "Lab\u00b7sal", "in", "der", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Ist gleich mein ", "tokens": ["Ist", "gleich", "mein"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Dein Schertz und angenehmes Lachen", "tokens": ["Dein", "Schertz", "und", "an\u00b7ge\u00b7neh\u00b7mes", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird ihn in etwas munter machen;", "tokens": ["Wird", "ihn", "in", "et\u00b7was", "mun\u00b7ter", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So st\u00e4rcket uns bey diesem Spa\u00df", "tokens": ["So", "st\u00e4r\u00b7cket", "uns", "bey", "die\u00b7sem", "Spa\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein gut und starck gef\u00fclltes Glas.", "tokens": ["Ein", "gut", "und", "starck", "ge\u00b7f\u00fcll\u00b7tes", "Glas", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}