{"textgrid.poem.36979": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "Die Gr\u00e4fin Lotte", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Morgen war's; der Mond stand hoch im Westen;", "tokens": ["Mor\u00b7gen", "wa\u00b7r's", ";", "der", "Mond", "stand", "hoch", "im", "Wes\u00b7ten", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$.", "ART", "NN", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Auf sprang ich vom Federposen-Lager,", "tokens": ["Auf", "sprang", "ich", "vom", "Fe\u00b7der\u00b7po\u00b7sen\u00b7La\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und stieg schnell in das Champagnerbad,", "tokens": ["Und", "stieg", "schnell", "in", "das", "Cham\u00b7pag\u00b7ner\u00b7bad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das die Gr\u00e4fin schon bereitet hatte,", "tokens": ["Das", "die", "Gr\u00e4\u00b7fin", "schon", "be\u00b7rei\u00b7tet", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Welche Lotte von der Lottburg hie\u00df,", "tokens": ["Wel\u00b7che", "Lot\u00b7te", "von", "der", "Lott\u00b7burg", "hie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "APPR", "ART", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Treu als Magd mir diente und daf\u00fcr", "tokens": ["Treu", "als", "Magd", "mir", "dien\u00b7te", "und", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "NN", "PPER", "VVFIN", "KON", "PAV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Monatlich mir drei\u00dfig Scudi zahlte.", "tokens": ["Mo\u00b7nat\u00b7lich", "mir", "drei\u00b7\u00dfig", "Scu\u00b7di", "zahl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "CARD", "NE", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "\u00bbherr!\u00ab sprach sie, mit feinen schwarzen Linnen", "tokens": ["\u00bb", "herr", "!", "\u00ab", "sprach", "sie", ",", "mit", "fei\u00b7nen", "schwar\u00b7zen", "Lin\u00b7nen"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PTKVZ", "$.", "$(", "VVFIN", "PPER", "$,", "APPR", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Sich den zarten K\u00f6rper eifrig reibend,", "tokens": ["Sich", "den", "zar\u00b7ten", "K\u00f6r\u00b7per", "eif\u00b7rig", "rei\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Um den meinigen zu trocknen: \u00bbHerr!", "tokens": ["Um", "den", "mei\u00b7ni\u00b7gen", "zu", "trock\u00b7nen", ":", "\u00bb", "Herr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KOUI", "ART", "PPOSS", "PTKZU", "VVINF", "$.", "$(", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Eh' der Ewigkeiten Stunden Eine", "tokens": ["Eh'", "der", "E\u00b7wig\u00b7kei\u00b7ten", "Stun\u00b7den", "Ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Sechzig der Minuten ausgeathmet;", "tokens": ["Sech\u00b7zig", "der", "Mi\u00b7nu\u00b7ten", "aus\u00b7ge\u00b7ath\u00b7met", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Eh' der m\u00fcde Mond sich noch gelegt hat", "tokens": ["Eh'", "der", "m\u00fc\u00b7de", "Mond", "sich", "noch", "ge\u00b7legt", "hat"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PRF", "ADV", "VVPP", "VAFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "In der Wolkenkissen Purpurlager,", "tokens": ["In", "der", "Wol\u00b7ken\u00b7kis\u00b7sen", "Pur\u00b7pur\u00b7la\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Und der sch\u00f6ne, finstre Tag heraufkommt:", "tokens": ["Und", "der", "sch\u00f6\u00b7ne", ",", "finst\u00b7re", "Tag", "her\u00b7auf\u00b7kommt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Wird die Zwanzig Zehen seiner F\u00fc\u00dfe,", "tokens": ["Wird", "die", "Zwan\u00b7zig", "Ze\u00b7hen", "sei\u00b7ner", "F\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "CARD", "CARD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Unser Land durch ihren Tritt begl\u00fcckend,", "tokens": ["Un\u00b7ser", "Land", "durch", "ih\u00b7ren", "Tritt", "be\u00b7gl\u00fc\u00b7ckend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Sultan Pumpel-Pampel von Dummdummdumm,", "tokens": ["Sul\u00b7tan", "Pum\u00b7pel\u00b7Pam\u00b7pel", "von", "Dumm\u00b7dumm\u00b7dumm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "NE", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Der Beherrscher aller Dummdummdummer,", "tokens": ["Der", "Be\u00b7herr\u00b7scher", "al\u00b7ler", "Dumm\u00b7dumm\u00b7dum\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Richten her nach diesem Deinem Stalle,", "tokens": ["Rich\u00b7ten", "her", "nach", "die\u00b7sem", "Dei\u00b7nem", "Stal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APZR", "APPR", "PDAT", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Unter der Kanonen Donnerknalle!\u00ab", "tokens": ["Un\u00b7ter", "der", "Ka\u00b7no\u00b7nen", "Don\u00b7ner\u00b7knal\u00b7le", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "\u00bbk\u00fcrzer, glaub' ich, gn\u00e4dige Comtesse,", "tokens": ["\u00bb", "k\u00fcr\u00b7zer", ",", "glaub'", "ich", ",", "gn\u00e4\u00b7di\u00b7ge", "Com\u00b7tes\u00b7se", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "H\u00e4tten Sie mir dieses melden k\u00f6nnen,", "tokens": ["H\u00e4t\u00b7ten", "Sie", "mir", "die\u00b7ses", "mel\u00b7den", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PDS", "VVINF", "VMINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wenn die Denkkraft dieser edeln Stirne", "tokens": ["Wenn", "die", "Denk\u00b7kraft", "die\u00b7ser", "e\u00b7deln", "Stir\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Meines sch\u00f6nen Hauptes sich nicht irret.", "tokens": ["Mei\u00b7nes", "sch\u00f6\u00b7nen", "Haup\u00b7tes", "sich", "nicht", "ir\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Doch: ist's wahr, da\u00df Seine Hoheit selber", "tokens": ["Doch", ":", "ist's", "wahr", ",", "da\u00df", "Sei\u00b7ne", "Ho\u00b7heit", "sel\u00b7ber"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$.", "VAFIN", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Sich h\u00f6chsteigenf\u00fc\u00dfig zu bem\u00fchen", "tokens": ["Sich", "h\u00f6chs\u00b7tei\u00b7gen\u00b7f\u00fc\u00b7\u00dfig", "zu", "be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "ADJD", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Her zu mir die hohe Absicht haben?\u00ab", "tokens": ["Her", "zu", "mir", "die", "ho\u00b7he", "Ab\u00b7sicht", "ha\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "ADJA", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "\u00bbherr, es ist so,\u00ab gab die Magd zur Antwort:", "tokens": ["\u00bb", "herr", ",", "es", "ist", "so", ",", "\u00ab", "gab", "die", "Magd", "zur", "Ant\u00b7wort", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PPER", "VAFIN", "ADV", "$,", "$(", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbganz, wie ich durch meine Lippenrose", "tokens": ["\u00bb", "ganz", ",", "wie", "ich", "durch", "mei\u00b7ne", "Lip\u00b7pen\u00b7ro\u00b7se"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "$,", "PWAV", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Silberklingenden Organs gemeldet.", "tokens": ["Sil\u00b7ber\u00b7klin\u00b7gen\u00b7den", "Or\u00b7gans", "ge\u00b7mel\u00b7det", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Ja, es wird der Sultan von Dummdummdumm", "tokens": ["Ja", ",", "es", "wird", "der", "Sul\u00b7tan", "von", "Dumm\u00b7dumm\u00b7dumm"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ART", "NN", "APPR", "NE"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Deinen Stall betreten, Dich, den Fremden,", "tokens": ["Dei\u00b7nen", "Stall", "be\u00b7tre\u00b7ten", ",", "Dich", ",", "den", "Frem\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "PPER", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Hier begr\u00fc\u00dfen und die saure Gurke", "tokens": ["Hier", "be\u00b7gr\u00fc\u00b7\u00dfen", "und", "die", "sau\u00b7re", "Gur\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVINF", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Und den Pampel-Orden dar Dir reichen,", "tokens": ["Und", "den", "Pam\u00b7pel\u00b7Or\u00b7den", "dar", "Dir", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKVZ", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Wie es dessen Schuldigkeit und Amt ist", "tokens": ["Wie", "es", "des\u00b7sen", "Schul\u00b7dig\u00b7keit", "und", "Amt", "ist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PDS", "NN", "KON", "NN", "VAFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Seit Jahrtausenden, der von den G\u00f6ttern,", "tokens": ["Seit", "Jahr\u00b7tau\u00b7sen\u00b7den", ",", "der", "von", "den", "G\u00f6t\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Wahrhaft konstitutionell zu herrschen", "tokens": ["Wahr\u00b7haft", "kons\u00b7ti\u00b7tu\u00b7ti\u00b7o\u00b7nell", "zu", "herr\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "PTKZU", "VVINF"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.11": {"text": "Ueber die verkehrte Welt, verdammt ist.\u00ab", "tokens": ["Ue\u00b7ber", "die", "ver\u00b7kehr\u00b7te", "Welt", ",", "ver\u00b7dammt", "ist", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "VVPP", "VAFIN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Also sprechend hatte die Comtesse", "tokens": ["Al\u00b7so", "spre\u00b7chend", "hat\u00b7te", "die", "Com\u00b7tes\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "VAFIN", "ART", "NN"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Einen goldnen Frack mit Silberkn\u00f6pfen,", "tokens": ["Ei\u00b7nen", "gold\u00b7nen", "Frack", "mit", "Sil\u00b7ber\u00b7kn\u00f6p\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Als bequeme leichte Morgenh\u00fclle", "tokens": ["Als", "be\u00b7que\u00b7me", "leich\u00b7te", "Mor\u00b7gen\u00b7h\u00fcl\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dargereicht mir freundlich, um in solcher", "tokens": ["Dar\u00b7ge\u00b7reicht", "mir", "freund\u00b7lich", ",", "um", "in", "sol\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KOUI", "APPR", "PIAT"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Nun das leck're Fr\u00fchst\u00fcck, das bereit schon,", "tokens": ["Nun", "das", "leck'\u00b7re", "Fr\u00fch\u00b7st\u00fcck", ",", "das", "be\u00b7reit", "schon", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "ADV", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Vor des Sultans Ankunft einzunehmen.", "tokens": ["Vor", "des", "Sul\u00b7tans", "An\u00b7kunft", "ein\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVIZU", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Aber hell auf schlug sie eine Lache,", "tokens": ["A\u00b7ber", "hell", "auf", "schlug", "sie", "ei\u00b7ne", "La\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Als ich jetzt nach einer Schaale w\u00fcrz'gen", "tokens": ["Als", "ich", "jetzt", "nach", "ei\u00b7ner", "Schaa\u00b7le", "w\u00fcrz'\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Kaffee's griff und solchen trinken wollte.", "tokens": ["Kaf\u00b7fee's", "griff", "und", "sol\u00b7chen", "trin\u00b7ken", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VMFIN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "\u00bbnein, bei allen G\u00f6ttern\u00ab, rief sie lachend,", "tokens": ["\u00bb", "nein", ",", "bei", "al\u00b7len", "G\u00f6t\u00b7tern", "\u00ab", ",", "rief", "sie", "la\u00b7chend", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "APPR", "PIAT", "NN", "$(", "$,", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbsolche Huld darf ich Dir nicht erlauben,", "tokens": ["\u00bb", "sol\u00b7che", "Huld", "darf", "ich", "Dir", "nicht", "er\u00b7lau\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Deiner niedern Gr\u00e4fin zu erweisen.", "tokens": ["Dei\u00b7ner", "nie\u00b7dern", "Gr\u00e4\u00b7fin", "zu", "er\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Wie, Du wolltest selber, hi, hi, hi!", "tokens": ["Wie", ",", "Du", "woll\u00b7test", "sel\u00b7ber", ",", "hi", ",", "hi", ",", "hi", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "$,", "PPER", "VMFIN", "ADV", "$,", "VVFIN", "$,", "VVFIN", "$,", "ITJ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Deine Lippen mit dem Tranke netzen?", "tokens": ["Dei\u00b7ne", "Lip\u00b7pen", "mit", "dem", "Tran\u00b7ke", "net\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Nein, Herr, das ist Sache Deiner Magd!", "tokens": ["Nein", ",", "Herr", ",", "das", "ist", "Sa\u00b7che", "Dei\u00b7ner", "Magd", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "PDS", "VAFIN", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Dir geb\u00fchrt als Fr\u00fchst\u00fcck dieser Rauch!", "tokens": ["Dir", "ge\u00b7b\u00fchrt", "als", "Fr\u00fch\u00b7st\u00fcck", "die\u00b7ser", "Rauch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "KOKOM", "NN", "PDAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Du erquickst Dich an dem kr\u00e4ft'gen Gase,", "tokens": ["Du", "er\u00b7quickst", "Dich", "an", "dem", "kr\u00e4ft'\u00b7gen", "Ga\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Welches, wie du siehst, aufkreiselnd zieht", "tokens": ["Wel\u00b7ches", ",", "wie", "du", "siehst", ",", "auf\u00b7krei\u00b7selnd", "zieht"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVPP", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "In den Schornstein Deiner edeln Nase.\u00ab", "tokens": ["In", "den", "Schorn\u00b7stein", "Dei\u00b7ner", "e\u00b7deln", "Na\u00b7se", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Und mich schnuppernd lie\u00df die Gr\u00e4fin stehen;", "tokens": ["Und", "mich", "schnup\u00b7pernd", "lie\u00df", "die", "Gr\u00e4\u00b7fin", "ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Setzte sich in eine Sammt-Berg\u00e8re;", "tokens": ["Setz\u00b7te", "sich", "in", "ei\u00b7ne", "Samm\u00b7tBer\u00b7g\u00e8\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Trank drei Schaalen w\u00fcrz'gen Moccakaffee's,", "tokens": ["Trank", "drei", "Schaa\u00b7len", "w\u00fcrz'\u00b7gen", "Moc\u00b7ca\u00b7kaf\u00b7fee's", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Noch durch Zucker, Mandelkuchenschnitte", "tokens": ["Noch", "durch", "Zu\u00b7cker", ",", "Man\u00b7del\u00b7ku\u00b7chen\u00b7schnit\u00b7te"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "APPR", "NN", "$,", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Wie durch sch\u00f6nen, fetten Rahm gek\u00f6stlicht.", "tokens": ["Wie", "durch", "sch\u00f6\u00b7nen", ",", "fet\u00b7ten", "Rahm", "ge\u00b7k\u00f6st\u00b7licht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "$,", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Als ich so auf allerdings bequeme", "tokens": ["Als", "ich", "so", "auf", "al\u00b7ler\u00b7dings", "be\u00b7que\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADV", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und sublime Art gefr\u00fchst\u00fcckt hatte,", "tokens": ["Und", "sub\u00b7li\u00b7me", "Art", "ge\u00b7fr\u00fch\u00b7st\u00fcckt", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "H\u00f6rten wir: \u00bbHeil unserm dummen Sultan!\u00ab", "tokens": ["H\u00f6r\u00b7ten", "wir", ":", "\u00bb", "Heil", "un\u00b7serm", "dum\u00b7men", "Sul\u00b7tan", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "NN", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Unterbrochen von Kanonendonner,", "tokens": ["Un\u00b7ter\u00b7bro\u00b7chen", "von", "Ka\u00b7no\u00b7nen\u00b7don\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Jauchzend auf der Stra\u00dfe unten schreien.", "tokens": ["Jauch\u00b7zend", "auf", "der", "Stra\u00b7\u00dfe", "un\u00b7ten", "schrei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "\u00bbeiligst Deinen Frack fort!\u00ab rief die Gr\u00e4fin.", "tokens": ["\u00bb", "ei\u00b7ligst", "Dei\u00b7nen", "Frack", "fort", "!", "\u00ab", "rief", "die", "Gr\u00e4\u00b7fin", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbwirf den Schlafrock hier, den buntgebl\u00fcmten,", "tokens": ["\u00bb", "wirf", "den", "Schla\u00b7frock", "hier", ",", "den", "bunt\u00b7ge\u00b7bl\u00fcm\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "ART", "NN", "ADV", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ueber Deines K\u00f6rpers holde Glieder!", "tokens": ["Ue\u00b7ber", "Dei\u00b7nes", "K\u00f6r\u00b7pers", "hol\u00b7de", "Glie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dunkle mit dem kecken Calabreser", "tokens": ["Dunk\u00b7le", "mit", "dem", "ke\u00b7cken", "Ca\u00b7lab\u00b7re\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--++-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Den romant'schen Mondschein Deines Hauptes;", "tokens": ["Den", "ro\u00b7mant'\u00b7schen", "Mond\u00b7schein", "Dei\u00b7nes", "Haup\u00b7tes", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Leime \u2013 da Dir Keiner ist gewachsen \u2013", "tokens": ["Lei\u00b7me", "\u2013", "da", "Dir", "Kei\u00b7ner", "ist", "ge\u00b7wach\u00b7sen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "PPER", "PIS", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Diesen Knebelbart Dir in das Antlitz;", "tokens": ["Die\u00b7sen", "Kne\u00b7bel\u00b7bart", "Dir", "in", "das", "Ant\u00b7litz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Stecke Deine F\u00fc\u00dfe in Pantoffeln,", "tokens": ["Ste\u00b7cke", "Dei\u00b7ne", "F\u00fc\u00b7\u00dfe", "in", "Pan\u00b7tof\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "+-+-+--++-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Und den Dolch hier in den Gurt des Schlafrocks!\u00ab", "tokens": ["Und", "den", "Dolch", "hier", "in", "den", "Gurt", "des", "Schla\u00b7frocks", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "ADV", "APPR", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "\u00bbwie\u00ab, rief ich, \u00bbin solcher Kleidung sollt' ich...?\u00ab", "tokens": ["\u00bb", "wie", "\u00ab", ",", "rief", "ich", ",", "\u00bb", "in", "sol\u00b7cher", "Klei\u00b7dung", "sollt'", "ich", "...", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PWAV", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "APPR", "PIAT", "NN", "VMFIN", "PPER", "$(", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "\u00bbniemand\u00ab, unterbrach mich die Comtesse,", "tokens": ["\u00bb", "nie\u00b7mand", "\u00ab", ",", "un\u00b7ter\u00b7brach", "mich", "die", "Com\u00b7tes\u00b7se", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "$(", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "\u00bbdarf den Sultan anders je empfangen", "tokens": ["\u00bb", "darf", "den", "Sul\u00b7tan", "an\u00b7ders", "je", "emp\u00b7fan\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VMFIN", "ART", "NN", "ADV", "ADV", "VVPP"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Noch sich Seiner dummen Hoheit nahen!", "tokens": ["Noch", "sich", "Sei\u00b7ner", "dum\u00b7men", "Ho\u00b7heit", "na\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "PPOSAT", "ADJA", "NN", "ADJA", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Wagt' es Einer ohne Calabreser!", "tokens": ["Wagt'", "es", "Ei\u00b7ner", "oh\u00b7ne", "Ca\u00b7lab\u00b7re\u00b7ser", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "APPR", "NN", "$."], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Ohne Dolch und Schlafrock und Pantoffeln,", "tokens": ["Oh\u00b7ne", "Dolch", "und", "Schla\u00b7frock", "und", "Pan\u00b7tof\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Oder bartlos vor ihm zu erscheinen,", "tokens": ["O\u00b7der", "bart\u00b7los", "vor", "ihm", "zu", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "So verurtheilt das Gesetz, o Jammer!", "tokens": ["So", "ver\u00b7urt\u00b7heilt", "das", "Ge\u00b7setz", ",", "o", "Jam\u00b7mer", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "FM", "NN", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "Ihn: Zehn Jahr lang t\u00e4glich zuzuh\u00f6ren", "tokens": ["Ihn", ":", "Zehn", "Jahr", "lang", "t\u00e4g\u00b7lich", "zu\u00b7zu\u00b7h\u00f6\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$.", "CARD", "NN", "ADJD", "ADJD", "VVIZU"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Den Verhandlungen der Ersten Kammer!\u00ab", "tokens": ["Den", "Ver\u00b7hand\u00b7lun\u00b7gen", "der", "Ers\u00b7ten", "Kam\u00b7mer", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.13": {"line.1": {"text": "Eiligst lie\u00df hierauf von meiner Gr\u00e4fin", "tokens": ["Ei\u00b7ligst", "lie\u00df", "hier\u00b7auf", "von", "mei\u00b7ner", "Gr\u00e4\u00b7fin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PAV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ich mich putzen und zurecht mich stutzen,", "tokens": ["Ich", "mich", "put\u00b7zen", "und", "zu\u00b7recht", "mich", "stut\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVINF", "KON", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und von Allem g'nau mich unterrichten,", "tokens": ["Und", "von", "Al\u00b7lem", "g'\u00b7nau", "mich", "un\u00b7ter\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was die strenge Etikette fordert", "tokens": ["Was", "die", "stren\u00b7ge", "E\u00b7ti\u00b7ket\u00b7te", "for\u00b7dert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Hier im Reiche der Verkehrten Welt.", "tokens": ["Hier", "im", "Rei\u00b7che", "der", "Ver\u00b7kehr\u00b7ten", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}