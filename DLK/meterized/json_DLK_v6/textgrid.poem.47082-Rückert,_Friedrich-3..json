{"textgrid.poem.47082": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "3.", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Will denn kein Stern von Himmelszinnen fallen", "tokens": ["Will", "denn", "kein", "Stern", "von", "Him\u00b7mels\u00b7zin\u00b7nen", "fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PIAT", "NN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zum Zeichen, da\u00df ", "tokens": ["Zum", "Zei\u00b7chen", ",", "da\u00df"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPRART", "NN", "$,", "KOUS"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Willst Erde du, da deine sch\u00f6nste Eiche", "tokens": ["Willst", "Er\u00b7de", "du", ",", "da", "dei\u00b7ne", "sch\u00f6ns\u00b7te", "Ei\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "NN", "PPER", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Entwurzelt sank, nicht seufzend wiederhallen?", "tokens": ["Ent\u00b7wur\u00b7zelt", "sank", ",", "nicht", "seuf\u00b7zend", "wie\u00b7der\u00b7hal\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Soll von des tauben Uhrwerks R\u00e4dern allen", "tokens": ["Soll", "von", "des", "tau\u00b7ben", "Uhr\u00b7werks", "R\u00e4\u00b7dern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "NN", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kein Rad denn stocken, brechen keine Speiche,", "tokens": ["Kein", "Rad", "denn", "sto\u00b7cken", ",", "bre\u00b7chen", "kei\u00b7ne", "Spei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "VVINF", "$,", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df alles fort im alten Kreislauf schleiche,", "tokens": ["Da\u00df", "al\u00b7les", "fort", "im", "al\u00b7ten", "Kreis\u00b7lauf", "schlei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKVZ", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}}, "stanza.3": {"line.1": {"text": "Ach nur ein Herz, nichts weiter, wird zerrieben;", "tokens": ["Ach", "nur", "ein", "Herz", ",", "nichts", "wei\u00b7ter", ",", "wird", "zer\u00b7rie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "ADV", "ART", "NN", "$,", "PIS", "PTKVZ", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Leben nur, nichts weiter, wird zersplittert;", "tokens": ["Ein", "Le\u00b7ben", "nur", ",", "nichts", "wei\u00b7ter", ",", "wird", "zer\u00b7split\u00b7tert", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PIS", "PTKVZ", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sonst alles geht, wie vor, so nachher wieder:", "tokens": ["Sonst", "al\u00b7les", "geht", ",", "wie", "vor", ",", "so", "nach\u00b7her", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "$,", "PWAV", "PTKVZ", "$,", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und keine Spur ist sonst von ", "tokens": ["Und", "kei\u00b7ne", "Spur", "ist", "sonst", "von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als da\u00df ein armes Espenbl\u00e4ttchen zittert,", "tokens": ["Als", "da\u00df", "ein", "ar\u00b7mes", "Es\u00b7pen\u00b7bl\u00e4tt\u00b7chen", "zit\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als sei's ger\u00fchrt vom Odem meiner Lieder.", "tokens": ["Als", "sei's", "ge\u00b7r\u00fchrt", "vom", "O\u00b7dem", "mei\u00b7ner", "Lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VVPP", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}