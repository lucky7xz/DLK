{"textgrid.poem.32530": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "Xi. Das Kruzifix", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hans, spricht der Pater, du mu\u00dft laufen,", "tokens": ["Hans", ",", "spricht", "der", "Pa\u00b7ter", ",", "du", "mu\u00dft", "lau\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ART", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Uns in der n\u00e4chsten Stadt ein Kruzifix zu kaufen.", "tokens": ["Uns", "in", "der", "n\u00e4chs\u00b7ten", "Stadt", "ein", "Kru\u00b7zi\u00b7fix", "zu", "kau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nimm Matzen mit, hier hast du Geld.", "tokens": ["Nimm", "Mat\u00b7zen", "mit", ",", "hier", "hast", "du", "Geld", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du wirst wohl sehn, wie teuer man es h\u00e4lt.", "tokens": ["Du", "wirst", "wohl", "sehn", ",", "wie", "teu\u00b7er", "man", "es", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVINF", "$,", "PWAV", "ADJD", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Hans k\u00f6mmt mit Matzen nach der Stadt.", "tokens": ["Hans", "k\u00f6mmt", "mit", "Mat\u00b7zen", "nach", "der", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der erste K\u00fcnstler war der beste.", "tokens": ["Der", "ers\u00b7te", "K\u00fcnst\u00b7ler", "war", "der", "bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbherr, wenn Er Kruzifixe hat,", "tokens": ["\u00bb", "herr", ",", "wenn", "Er", "Kru\u00b7zi\u00b7fi\u00b7xe", "hat", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "So la\u00df' Er uns doch eins zum heil'gen Osterfeste.\u00ab", "tokens": ["So", "la\u00df'", "Er", "uns", "doch", "eins", "zum", "heil'\u00b7gen", "Os\u00b7ter\u00b7fes\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PPER", "ADV", "PIS", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der K\u00fcnstler war ein schalkscher Mann,", "tokens": ["Der", "K\u00fcnst\u00b7ler", "war", "ein", "schalk\u00b7scher", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der gern der Einfalt lachte,", "tokens": ["Der", "gern", "der", "Ein\u00b7falt", "lach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Dumme gern noch d\u00fcmmer machte,", "tokens": ["Und", "Dum\u00b7me", "gern", "noch", "d\u00fcm\u00b7mer", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und fing im Scherz zu fragen an:", "tokens": ["Und", "fing", "im", "Scherz", "zu", "fra\u00b7gen", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbwas wollt ihr denn f\u00fcr eines?\u00ab", "tokens": ["\u00bb", "was", "wollt", "ihr", "denn", "f\u00fcr", "ei\u00b7nes", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "ADV", "APPR", "PIS", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbje nun, spricht Matz, ein wacker feines.", "tokens": ["\u00bb", "je", "nun", ",", "spricht", "Matz", ",", "ein", "wa\u00b7cker", "fei\u00b7nes", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "VVFIN", "NE", "$,", "ART", "ADJD", "ADJA", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wir werden sehn, was Ihr uns gebt.\u00ab", "tokens": ["Wir", "wer\u00b7den", "sehn", ",", "was", "Ihr", "uns", "gebt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "VVINF", "$,", "PWS", "PPER", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}}, "stanza.5": {"line.1": {"text": "Hans guckte Matzen und Matz Hansen ins Gesicht.", "tokens": ["Hans", "guck\u00b7te", "Mat\u00b7zen", "und", "Matz", "Han\u00b7sen", "ins", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "KON", "NN", "NE", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie \u00f6ffneten das Maul, allein es redte nicht.", "tokens": ["Sie", "\u00f6ff\u00b7ne\u00b7ten", "das", "Maul", ",", "al\u00b7lein", "es", "red\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.4": {"text": "\u00bbmein Blut! spricht endlich Hans, der aus dem Traum erwachte,", "tokens": ["\u00bb", "mein", "Blut", "!", "spricht", "end\u00b7lich", "Hans", ",", "der", "aus", "dem", "Traum", "er\u00b7wach\u00b7te", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$.", "VVFIN", "ADV", "NE", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mein Blut! er hat uns nichts gesagt.", "tokens": ["Mein", "Blut", "!", "er", "hat", "uns", "nichts", "ge\u00b7sagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wei\u00dft du es, Matz?\u00ab \u2013 \u00bblch dachte;", "tokens": ["Wei\u00dft", "du", "es", ",", "Matz", "?", "\u00ab", "\u2013", "\u00bb", "lch", "dach\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "NN", "$.", "$(", "$(", "$(", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wenn du's nicht wei\u00dft; wie soll ich's wissen?\u00ab", "tokens": ["Wenn", "du's", "nicht", "wei\u00dft", ";", "wie", "soll", "ich's", "wis\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "VVFIN", "$.", "PWAV", "VMFIN", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.9": {"text": "\u00bbdas wollen wir wohl bleiben lassen.", "tokens": ["\u00bb", "das", "wol\u00b7len", "wir", "wohl", "blei\u00b7ben", "las\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "PPER", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ja, wenn es nicht zur Frone w\u00e4r.\u00ab", "tokens": ["Ja", ",", "wenn", "es", "nicht", "zur", "Fro\u00b7ne", "w\u00e4r", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PTKNEG", "APPRART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sie denken lange hin und her,", "tokens": ["Sie", "den\u00b7ken", "lan\u00b7ge", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wissen keinen Rat zu fassen.", "tokens": ["Und", "wis\u00b7sen", "kei\u00b7nen", "Rat", "zu", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch endlich f\u00e4llt es Matzen ein:", "tokens": ["Doch", "end\u00b7lich", "f\u00e4llt", "es", "Mat\u00b7zen", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbje! Hans, sollt's nicht am besten sein,", "tokens": ["\u00bb", "je", "!", "Hans", ",", "sollt's", "nicht", "am", "bes\u00b7ten", "sein", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "NE", "$,", "VMFIN", "PTKNEG", "PTKA", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir kauften eins das lebt? \u2013 Denn sieh,", "tokens": ["Wir", "kauf\u00b7ten", "eins", "das", "lebt", "?", "\u2013", "Denn", "sieh", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PDS", "VVFIN", "$.", "$(", "KON", "VVIMP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist's ihm nicht recht, so macht's ja wenig M\u00fch,", "tokens": ["Ist's", "ihm", "nicht", "recht", ",", "so", "macht's", "ja", "we\u00b7nig", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PTKNEG", "ADJD", "$,", "ADV", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "W\u00e4r's auch ein Ochs, es tot zu schlagen.\u00ab", "tokens": ["W\u00e4r's", "auch", "ein", "Ochs", ",", "es", "tot", "zu", "schla\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbnu ja, spricht Hans, das wollt' ich eben sagen:", "tokens": ["\u00bb", "nu", "ja", ",", "spricht", "Hans", ",", "das", "wollt'", "ich", "e\u00b7ben", "sa\u00b7gen", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "VVFIN", "NE", "$,", "PDS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "So haben wir nicht viel zu wagen.\u00ab", "tokens": ["So", "ha\u00b7ben", "wir", "nicht", "viel", "zu", "wa\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Das war ein Argument, ihr Herren Theologen,", "tokens": ["Das", "war", "ein", "Ar\u00b7gu\u00b7ment", ",", "ihr", "Her\u00b7ren", "Theo\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das Hans und Matz ex tuto zogen.", "tokens": ["Das", "Hans", "und", "Matz", "ex", "tu\u00b7to", "zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NN", "FM", "FM", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}