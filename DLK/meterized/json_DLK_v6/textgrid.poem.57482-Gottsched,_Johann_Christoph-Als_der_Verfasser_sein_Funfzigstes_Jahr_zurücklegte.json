{"textgrid.poem.57482": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "Als der Verfasser sein Funfzigstes Jahr zur\u00fccklegte", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Erhabner Sch\u00f6pfer aller Welt!", "tokens": ["Er\u00b7hab\u00b7ner", "Sch\u00f6p\u00b7fer", "al\u00b7ler", "Welt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die so viel Wunder in sich h\u00e4lt,", "tokens": ["Die", "so", "viel", "Wun\u00b7der", "in", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als auf dem Erdball Thiere leben;", "tokens": ["Als", "auf", "dem", "Erd\u00b7ball", "Thie\u00b7re", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als Sterne gl\u00e4nzen in der H\u00f6h;", "tokens": ["Als", "Ster\u00b7ne", "gl\u00e4n\u00b7zen", "in", "der", "H\u00f6h", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als K\u00f6rner hegt der Strand der See;", "tokens": ["Als", "K\u00f6r\u00b7ner", "hegt", "der", "Strand", "der", "See", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als St\u00e4ubchen in den L\u00fcften schweben.", "tokens": ["Als", "St\u00e4ub\u00b7chen", "in", "den", "L\u00fcf\u00b7ten", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wie ungemein hat deine Macht", "tokens": ["Wie", "un\u00b7ge\u00b7mein", "hat", "dei\u00b7ne", "Macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die\u00df Meisterst\u00fcck hervor gebracht!", "tokens": ["Die\u00df", "Meis\u00b7ter\u00b7st\u00fcck", "her\u00b7vor", "ge\u00b7bracht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wo w\u00e4ren Erde, Luft und Meer,", "tokens": ["Wo", "w\u00e4\u00b7ren", "Er\u00b7de", ",", "Luft", "und", "Meer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo aller Himmelslichter Heer,", "tokens": ["Wo", "al\u00b7ler", "Him\u00b7mels\u00b7lich\u00b7ter", "Heer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dafern sie nicht von Dir entsprungen?", "tokens": ["Da\u00b7fern", "sie", "nicht", "von", "Dir", "ent\u00b7sprun\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer rief sie aus dem alten Nichts?", "tokens": ["Wer", "rief", "sie", "aus", "dem", "al\u00b7ten", "Nichts", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer schuff den Glanz des ersten Lichts,", "tokens": ["Wer", "schuff", "den", "Glanz", "des", "ers\u00b7ten", "Lichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das durch die l\u00e4ngste Nacht gedrungen?", "tokens": ["Das", "durch", "die", "l\u00e4ngs\u00b7te", "Nacht", "ge\u00b7drun\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hast Du, o Gott! durch Deine Macht", "tokens": ["Hast", "Du", ",", "o", "Gott", "!", "durch", "Dei\u00b7ne", "Macht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "FM", "NN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die\u00df alles nicht hervor gebracht?", "tokens": ["Die\u00df", "al\u00b7les", "nicht", "her\u00b7vor", "ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PTKNEG", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du warst ja schon von Ewigkeit,", "tokens": ["Du", "warst", "ja", "schon", "von", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel \u00e4lter, als Natur und Zeit,", "tokens": ["Viel", "\u00e4l\u00b7ter", ",", "als", "Na\u00b7tur", "und", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein unumschr\u00e4nkt begl\u00fccktes Wesen.", "tokens": ["Ein", "un\u00b7um\u00b7schr\u00e4nkt", "be\u00b7gl\u00fcck\u00b7tes", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du warst ja selig, auch allein!", "tokens": ["Du", "warst", "ja", "se\u00b7lig", ",", "auch", "al\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was brauchtest Du der Dinge Seyn,", "tokens": ["Was", "brauch\u00b7test", "Du", "der", "Din\u00b7ge", "Seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Deine Weisheit sich erlesen?", "tokens": ["Die", "Dei\u00b7ne", "Weis\u00b7heit", "sich", "er\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Gebrach Dir was, als Dein Verstand", "tokens": ["Ge\u00b7brach", "Dir", "was", ",", "als", "Dein", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "PIS", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Weltbau schaffensw\u00fcrdig fand?", "tokens": ["Den", "Welt\u00b7bau", "schaf\u00b7fens\u00b7w\u00fcr\u00b7dig", "fand", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "O nein! o nein! aus G\u00fcte blo\u00df,", "tokens": ["O", "nein", "!", "o", "nein", "!", "aus", "G\u00fc\u00b7te", "blo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "FM", "PTKANT", "$.", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hast Du die Welt, so sch\u00f6n, so gro\u00df,", "tokens": ["Hast", "Du", "die", "Welt", ",", "so", "sch\u00f6n", ",", "so", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So unerme\u00dflich dargestellet;", "tokens": ["So", "un\u00b7er\u00b7me\u00df\u00b7lich", "dar\u00b7ge\u00b7stel\u00b7let", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer z\u00e4hlt der hellen Kugeln Zahl,", "tokens": ["Wer", "z\u00e4hlt", "der", "hel\u00b7len", "Ku\u00b7geln", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Daraus des regen Lichtes Stral,", "tokens": ["Da\u00b7raus", "des", "re\u00b7gen", "Lich\u00b7tes", "Stral", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Bey Nacht das Firmament erhellet?", "tokens": ["Bey", "Nacht", "das", "Fir\u00b7ma\u00b7ment", "er\u00b7hel\u00b7let", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie gl\u00e4nzen stets: wie wohl den Tag", "tokens": ["Sie", "gl\u00e4n\u00b7zen", "stets", ":", "wie", "wohl", "den", "Tag"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PWAV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ihr Glanz nicht \u00fcberwinden mag.", "tokens": ["Ihr", "Glanz", "nicht", "\u00fc\u00b7berw\u00b7in\u00b7den", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PPOSAT", "NN", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wer hing der Wandelsterne Lauf", "tokens": ["Wer", "hing", "der", "Wan\u00b7dels\u00b7ter\u00b7ne", "Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In ungleich gro\u00dfen H\u00f6hen auf,", "tokens": ["In", "un\u00b7gleich", "gro\u00b7\u00dfen", "H\u00f6\u00b7hen", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hie\u00df sie um die Sonne flie\u00dfen?", "tokens": ["Und", "hie\u00df", "sie", "um", "die", "Son\u00b7ne", "flie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer wies doch jedem seinen Kreis,", "tokens": ["Wer", "wies", "doch", "je\u00b7dem", "sei\u00b7nen", "Kreis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So kr\u00e4ftig, da\u00df sie Bahn und Gleis", "tokens": ["So", "kr\u00e4f\u00b7tig", ",", "da\u00df", "sie", "Bahn", "und", "Gleis"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im Schwunge nicht verlassen m\u00fcssen?", "tokens": ["Im", "Schwun\u00b7ge", "nicht", "ver\u00b7las\u00b7sen", "m\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da sonst, was sich mit Schleudern regt,", "tokens": ["Da", "sonst", ",", "was", "sich", "mit", "Schleu\u00b7dern", "regt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Mittelpunct zu fliehen pflegt.", "tokens": ["Den", "Mit\u00b7tel\u00b7punct", "zu", "flie\u00b7hen", "pflegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wer wies doch allen Achsen an,", "tokens": ["Wer", "wies", "doch", "al\u00b7len", "Ach\u00b7sen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Um die ihr K\u00f6rper wirbeln kann,", "tokens": ["Um", "die", "ihr", "K\u00f6r\u00b7per", "wir\u00b7beln", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wie sich der Erdball selbst beweget?", "tokens": ["Wie", "sich", "der", "Erd\u00b7ball", "selbst", "be\u00b7we\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wer zeichnete den Angelstern", "tokens": ["Wer", "zeich\u00b7ne\u00b7te", "den", "An\u00b7gels\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN"], "meter": "-+-+----", "measure": "unknown.measure.di"}, "line.13": {"text": "Dem einen nah, dem andern fern,", "tokens": ["Dem", "ei\u00b7nen", "nah", ",", "dem", "an\u00b7dern", "fern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "$,", "PRELS", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Von dem, der unsern Erdpol tr\u00e4get?", "tokens": ["Von", "dem", ",", "der", "un\u00b7sern", "Erd\u00b7pol", "tr\u00e4\u00b7get", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Der uns die Zeit von Tag und Nacht,", "tokens": ["Der", "uns", "die", "Zeit", "von", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Zwar ungleich, doch best\u00e4ndig macht.", "tokens": ["Zwar", "un\u00b7gleich", ",", "doch", "be\u00b7st\u00e4n\u00b7dig", "macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "O Sch\u00f6pfer! Deine Weisheit blo\u00df", "tokens": ["O", "Sch\u00f6p\u00b7fer", "!", "Dei\u00b7ne", "Weis\u00b7heit", "blo\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab dort und hier den ersten Sto\u00df,", "tokens": ["Gab", "dort", "und", "hier", "den", "ers\u00b7ten", "Sto\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Davon die Kugeln seitw\u00e4rts rollten;", "tokens": ["Da\u00b7von", "die", "Ku\u00b7geln", "seit\u00b7w\u00e4rts", "roll\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das machts, wenn sich der Erdball dreht,", "tokens": ["Das", "machts", ",", "wenn", "sich", "der", "Erd\u00b7ball", "dreht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Lenz und Sommer erst entsteht,", "tokens": ["Da\u00df", "Lenz", "und", "Som\u00b7mer", "erst", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dann Herbst und Winter folgen sollten;", "tokens": ["Dann", "Herbst", "und", "Win\u00b7ter", "fol\u00b7gen", "soll\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Indem die Nord- und S\u00fcderwelt,", "tokens": ["In\u00b7dem", "die", "Nord", "und", "S\u00fc\u00b7der\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich wechselnd nach der Sonne stellt.", "tokens": ["Sich", "wech\u00b7selnd", "nach", "der", "Son\u00b7ne", "stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der hei\u00dfe Weltstrich nicht allein,", "tokens": ["Der", "hei\u00b7\u00dfe", "Welt\u00b7strich", "nicht", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sollt reich an Thier und Pflanzen seyn,", "tokens": ["Sollt", "reich", "an", "Thier", "und", "Pflan\u00b7zen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "APPR", "NN", "KON", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und stets von hei\u00dfen Stralen schmelzen.", "tokens": ["Und", "stets", "von", "hei\u00b7\u00dfen", "Stra\u00b7len", "schmel\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nein! auch das Nord- und S\u00fcderland", "tokens": ["Nein", "!", "auch", "das", "Nord", "und", "S\u00fc\u00b7der\u00b7land"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADV", "ART", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "War eignen B\u00fcrgern zuerkannt;", "tokens": ["War", "eig\u00b7nen", "B\u00fcr\u00b7gern", "zu\u00b7er\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum mu\u00df die Erde so sich w\u00e4lzen;", "tokens": ["Drum", "mu\u00df", "die", "Er\u00b7de", "so", "sich", "w\u00e4l\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ART", "NN", "ADV", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df jeder Theil zu seiner Zeit,", "tokens": ["Da\u00df", "je\u00b7der", "Theil", "zu", "sei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Durch gr\u00f6\u00dfrer W\u00e4rme Kraft gedeiht.", "tokens": ["Durch", "gr\u00f6\u00df\u00b7rer", "W\u00e4r\u00b7me", "Kraft", "ge\u00b7deiht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nicht kleiner ist der Kugeln Werth,", "tokens": ["Nicht", "klei\u00b7ner", "ist", "der", "Ku\u00b7geln", "Werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die unsre Sonne noch verkl\u00e4rt,", "tokens": ["Die", "uns\u00b7re", "Son\u00b7ne", "noch", "ver\u00b7kl\u00e4rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So nah und weit sie immer schweben!", "tokens": ["So", "nah", "und", "weit", "sie", "im\u00b7mer", "schwe\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie w\u00e4rmen sich an ihrem Licht,", "tokens": ["Sie", "w\u00e4r\u00b7men", "sich", "an", "ih\u00b7rem", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem auch der Wechsel nicht gebricht;", "tokens": ["Dem", "auch", "der", "Wech\u00b7sel", "nicht", "ge\u00b7bricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie sollte kein Gesch\u00f6pf da leben?", "tokens": ["Wie", "soll\u00b7te", "kein", "Ge\u00b7sch\u00f6pf", "da", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wie sollte nur die Erd allein,", "tokens": ["Wie", "soll\u00b7te", "nur", "die", "Erd", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "An Thier und Menschen fruchtbar seyn?", "tokens": ["An", "Thier", "und", "Men\u00b7schen", "frucht\u00b7bar", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Nein nein! umsonst lie\u00df Gott gewi\u00df", "tokens": ["Nein", "nein", "!", "um\u00b7sonst", "lie\u00df", "Gott", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "PTKANT", "$.", "ADV", "VVFIN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcnf Kugeln, Licht und Finsterni\u00df,", "tokens": ["F\u00fcnf", "Ku\u00b7geln", ",", "Licht", "und", "Fins\u00b7ter\u00b7ni\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In festgesetzter Zeit nicht f\u00fchlen:", "tokens": ["In", "fest\u00b7ge\u00b7setz\u00b7ter", "Zeit", "nicht", "f\u00fch\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Umsonst schuff Er nicht W\u00e4rm und Frost,", "tokens": ["Um\u00b7sonst", "schuff", "Er", "nicht", "W\u00e4rm", "und", "Frost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr L\u00e4nder wo Er keine Kost,", "tokens": ["F\u00fcr", "L\u00e4n\u00b7der", "wo", "Er", "kei\u00b7ne", "Kost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PWAV", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr Thier und Menschen, wollt erzielen!", "tokens": ["F\u00fcr", "Thier", "und", "Men\u00b7schen", ",", "wollt", "er\u00b7zie\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wo Winter, Lenz, und Sommer ist,", "tokens": ["Wo", "Win\u00b7ter", ",", "Lenz", ",", "und", "Som\u00b7mer", "ist", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "$,", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wird was beseeltes nicht vermi\u00dft.", "tokens": ["Wird", "was", "be\u00b7seel\u00b7tes", "nicht", "ver\u00b7mi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJA", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "O! Jupitern mu\u00df offenbar,", "tokens": ["O", "!", "Ju\u00b7pi\u00b7tern", "mu\u00df", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "VMFIN", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Der sch\u00f6nsten Monden doppelt Paar,", "tokens": ["Der", "sch\u00f6ns\u00b7ten", "Mon\u00b7den", "dop\u00b7pelt", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht ganz umsonst die Nacht erfreuen!", "tokens": ["Nicht", "ganz", "um\u00b7sonst", "die", "Nacht", "er\u00b7freu\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo z\u00fcndet wohl ein kluger Mann", "tokens": ["Wo", "z\u00fcn\u00b7det", "wohl", "ein", "klu\u00b7ger", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In w\u00fcsten Feldern Fackeln an,", "tokens": ["In", "w\u00fcs\u00b7ten", "Fel\u00b7dern", "Fa\u00b7ckeln", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Finsternisse zu zerstreuen?", "tokens": ["Die", "Fins\u00b7ter\u00b7nis\u00b7se", "zu", "zer\u00b7streu\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "O Sch\u00f6pfer! Deiner Weisheit Pflicht,", "tokens": ["O", "Sch\u00f6p\u00b7fer", "!", "Dei\u00b7ner", "Weis\u00b7heit", "Pflicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Thut wahrlich was vergeblichs nicht.", "tokens": ["Thut", "wahr\u00b7lich", "was", "ver\u00b7geb\u00b7lichs", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PWS", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Erdkreis ist so reich bewohnt,", "tokens": ["Der", "Erd\u00b7kreis", "ist", "so", "reich", "be\u00b7wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch gl\u00e4nzt ihm nur ein kleiner Mond:", "tokens": ["Doch", "gl\u00e4nzt", "ihm", "nur", "ein", "klei\u00b7ner", "Mond", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort hast Du viere dran gewendet.", "tokens": ["Dort", "hast", "Du", "vie\u00b7re", "dran", "ge\u00b7wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Saturn hat kaum an f\u00fcnfen gnug,", "tokens": ["Sa\u00b7turn", "hat", "kaum", "an", "f\u00fcn\u00b7fen", "gnug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "APPR", "VVFIN", "ADV", "$,"], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "Davon der ungleich schnelle Flug", "tokens": ["Da\u00b7von", "der", "un\u00b7gleich", "schnel\u00b7le", "Flug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich in sehr kurzer Zeit vollendet;", "tokens": ["Sich", "in", "sehr", "kur\u00b7zer", "Zeit", "voll\u00b7en\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wer glaubt nun, da\u00df ihr Silberlicht", "tokens": ["Wer", "glaubt", "nun", ",", "da\u00df", "ihr", "Sil\u00b7ber\u00b7licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Umsonst der N\u00e4chte Schatten bricht?", "tokens": ["Um\u00b7sonst", "der", "N\u00e4ch\u00b7te", "Schat\u00b7ten", "bricht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Und welch ein seltnes Wunderding", "tokens": ["Und", "welch", "ein", "selt\u00b7nes", "Wun\u00b7der\u00b7ding"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist dieses Irrsterns heller Ring,", "tokens": ["Ist", "die\u00b7ses", "Irrs\u00b7terns", "hel\u00b7ler", "Ring", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der rings umher in L\u00fcften schwebet?", "tokens": ["Der", "rings", "um\u00b7her", "in", "L\u00fcf\u00b7ten", "schwe\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKVZ", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bald selber gl\u00e4nzt, bald dunkel macht;", "tokens": ["Bald", "sel\u00b7ber", "gl\u00e4nzt", ",", "bald", "dun\u00b7kel", "macht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$,", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn er der hellen Monden Pracht", "tokens": ["Wenn", "er", "der", "hel\u00b7len", "Mon\u00b7den", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In seiner Schatten Flor begr\u00e4bet.", "tokens": ["In", "sei\u00b7ner", "Schat\u00b7ten", "Flor", "be\u00b7gr\u00e4\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wer hieng ihn zum Saturnus auf?", "tokens": ["Wer", "hieng", "ihn", "zum", "Sa\u00b7tur\u00b7nus", "auf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wie folgt er des Planeten Lauf?", "tokens": ["Wie", "folgt", "er", "des", "Pla\u00b7ne\u00b7ten", "Lauf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.13": {"line.1": {"text": "O Wunderth\u00e4ter! Herr und Gott!", "tokens": ["O", "Wun\u00b7der\u00b7th\u00e4\u00b7ter", "!", "Herr", "und", "Gott", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie unbesonnen ist der Spott,", "tokens": ["Wie", "un\u00b7be\u00b7son\u00b7nen", "ist", "der", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Thoren, die Dein Thun nicht merken?", "tokens": ["Der", "Tho\u00b7ren", ",", "die", "Dein", "Thun", "nicht", "mer\u00b7ken", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Des Schwarms, der Deine Hand nicht sieht,", "tokens": ["Des", "Schwarms", ",", "der", "Dei\u00b7ne", "Hand", "nicht", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sich voll Aberwitz bem\u00fcht,", "tokens": ["Und", "sich", "voll", "A\u00b7ber\u00b7witz", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des blinden Zufalls Macht zu st\u00e4rken!", "tokens": ["Des", "blin\u00b7den", "Zu\u00b7falls", "Macht", "zu", "st\u00e4r\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der doch mit aller seiner Kraft,", "tokens": ["Der", "doch", "mit", "al\u00b7ler", "sei\u00b7ner", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur Abscheu und Verwirrung schafft.", "tokens": ["Nur", "Ab\u00b7scheu", "und", "Ver\u00b7wir\u00b7rung", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Sagt! war der Zufall denn so klug,", "tokens": ["Sagt", "!", "war", "der", "Zu\u00b7fall", "denn", "so", "klug", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "VAFIN", "ART", "NN", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als er die Bahn des Mondes schlug,", "tokens": ["Als", "er", "die", "Bahn", "des", "Mon\u00b7des", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihm so die feste Spur zu zeigen;", "tokens": ["Ihm", "so", "die", "fes\u00b7te", "Spur", "zu", "zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er, wenn uns der Winter dr\u00fcckt,", "tokens": ["Da\u00df", "er", ",", "wenn", "uns", "der", "Win\u00b7ter", "dr\u00fcckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit vollem Antlitz zu uns r\u00fcckt,", "tokens": ["Mit", "vol\u00b7lem", "Ant\u00b7litz", "zu", "uns", "r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Norderhimmel zu besteigen;", "tokens": ["Den", "Nor\u00b7der\u00b7him\u00b7mel", "zu", "be\u00b7stei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bey unsrer l\u00e4ngsten Tage Pracht,", "tokens": ["Bey", "uns\u00b7rer", "l\u00e4ngs\u00b7ten", "Ta\u00b7ge", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Am S\u00fcdpol helle N\u00e4chte macht?", "tokens": ["Am", "S\u00fcd\u00b7pol", "hel\u00b7le", "N\u00e4ch\u00b7te", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Geh! sch\u00e4me dich, verirrte Zunft!", "tokens": ["Geh", "!", "sch\u00e4\u00b7me", "dich", ",", "ver\u00b7irr\u00b7te", "Zunft", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die du mit blinder Unvernunft", "tokens": ["Die", "du", "mit", "blin\u00b7der", "Un\u00b7ver\u00b7nunft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Finstern tappst, wo Sonnen gl\u00e4nzen:", "tokens": ["Im", "Fins\u00b7tern", "tappst", ",", "wo", "Son\u00b7nen", "gl\u00e4n\u00b7zen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PWAV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Siehst du denn nicht der Allmacht Kraft,", "tokens": ["Siehst", "du", "denn", "nicht", "der", "All\u00b7macht", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die stets des Erdballs bestes schafft,", "tokens": ["Die", "stets", "des", "Erd\u00b7balls", "bes\u00b7tes", "schafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn Sommer, Winter, Herbst und Lenzen,", "tokens": ["Wenn", "Som\u00b7mer", ",", "Win\u00b7ter", ",", "Herbst", "und", "Len\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das ganze Volk bewohnter Welt,", "tokens": ["Das", "gan\u00b7ze", "Volk", "be\u00b7wohn\u00b7ter", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Im Wechsel \u00fcberall erh\u00e4lt?", "tokens": ["Im", "Wech\u00b7sel", "\u00fc\u00b7be\u00b7rall", "er\u00b7h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Und w\u00e4r auch unser Silbermond", "tokens": ["Und", "w\u00e4r", "auch", "un\u00b7ser", "Sil\u00b7ber\u00b7mond"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht von Gesch\u00f6pfen reich bewohnt,", "tokens": ["Nicht", "von", "Ge\u00b7sch\u00f6p\u00b7fen", "reich", "be\u00b7wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So m\u00fc\u00dft er uns best\u00e4ndig leuchten.", "tokens": ["So", "m\u00fc\u00dft", "er", "uns", "be\u00b7st\u00e4n\u00b7dig", "leuch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Warum zeigt uns sein Angesicht,", "tokens": ["Wa\u00b7rum", "zeigt", "uns", "sein", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Nicht allemal ein volles Licht,", "tokens": ["Nicht", "al\u00b7le\u00b7mal", "ein", "vol\u00b7les", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn Thau und Nebel ihn nicht feuchten?", "tokens": ["Wenn", "Thau", "und", "Ne\u00b7bel", "ihn", "nicht", "feuch\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ist auch ein leerer Klump wohl werth,", "tokens": ["Ist", "auch", "ein", "lee\u00b7rer", "Klump", "wohl", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df ihn die Sonn ringsum verkl\u00e4rt?", "tokens": ["Da\u00df", "ihn", "die", "Sonn", "ring\u00b7sum", "ver\u00b7kl\u00e4rt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Gieb Acht auf ihn! wie kehrt er sich", "tokens": ["Gieb", "Acht", "auf", "ihn", "!", "wie", "kehrt", "er", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "CARD", "APPR", "PPER", "$.", "PWAV", "VVFIN", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Monatsfrist so ordentlich,", "tokens": ["In", "Mo\u00b7nats\u00b7frist", "so", "or\u00b7dent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach dem beliebten Sonnenlichte!", "tokens": ["Nach", "dem", "be\u00b7lieb\u00b7ten", "Son\u00b7nen\u00b7lich\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man sieht, da\u00df er nach W\u00e4rme strebt,", "tokens": ["Man", "sieht", ",", "da\u00df", "er", "nach", "W\u00e4r\u00b7me", "strebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und so wird er ringsum belebt;", "tokens": ["Und", "so", "wird", "er", "ring\u00b7sum", "be\u00b7lebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Und nichts geht ihm vor Frost zunichte.", "tokens": ["Und", "nichts", "geht", "ihm", "vor", "Frost", "zu\u00b7nich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Da\u00df auch sein B\u00fcrger leben soll;", "tokens": ["Da\u00df", "auch", "sein", "B\u00fcr\u00b7ger", "le\u00b7ben", "soll", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Drum scheint er uns nicht t\u00e4glich voll.", "tokens": ["Drum", "scheint", "er", "uns", "nicht", "t\u00e4g\u00b7lich", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "PTKNEG", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ein mindrer Grad Geschwindigkeit,", "tokens": ["Ein", "mind\u00b7rer", "Grad", "Ge\u00b7schwin\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6nnt ihn mit uns in gleicher Zeit,", "tokens": ["K\u00f6nnt", "ihn", "mit", "uns", "in", "glei\u00b7cher", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um unsers Kreises Brennpunct f\u00fchren.", "tokens": ["Um", "un\u00b7sers", "Krei\u00b7ses", "Brenn\u00b7punct", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So blieb er wohl ein Wandelstern;", "tokens": ["So", "blieb", "er", "wohl", "ein", "Wan\u00b7dels\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Und d\u00f6rfte doch, wie Mars, von fern,", "tokens": ["Und", "d\u00f6rf\u00b7te", "doch", ",", "wie", "Mars", ",", "von", "fern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PWAV", "NN", "$,", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein rundes Antlitz nie verlieren;", "tokens": ["Sein", "run\u00b7des", "Ant\u00b7litz", "nie", "ver\u00b7lie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auf unsrer H\u00e4lfte voller Schein,", "tokens": ["Auf", "uns\u00b7rer", "H\u00e4lf\u00b7te", "vol\u00b7ler", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Auf jener ewig finster seyn.", "tokens": ["Auf", "je\u00b7ner", "e\u00b7wig", "fins\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Genug! die Weisheit schuff die Welt,", "tokens": ["Ge\u00b7nug", "!", "die", "Weis\u00b7heit", "schuff", "die", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die doch viel mehr noch in sich h\u00e4lt,", "tokens": ["Die", "doch", "viel", "mehr", "noch", "in", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "ADV", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als lauter Sonnen und Planeten.", "tokens": ["Als", "lau\u00b7ter", "Son\u00b7nen", "und", "Pla\u00b7ne\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wo bleibt die ungemeine Zahl", "tokens": ["Wo", "bleibt", "die", "un\u00b7ge\u00b7mei\u00b7ne", "Zahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der durch den blassen Dunst und Stral,", "tokens": ["Der", "durch", "den", "blas\u00b7sen", "Dunst", "und", "Stral", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geschw\u00e4nzt und b\u00e4rtigen Kometen?", "tokens": ["Ge\u00b7schw\u00e4nzt", "und", "b\u00e4r\u00b7ti\u00b7gen", "Ko\u00b7me\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Darauf, o Gott! Dein Allmachtruff,", "tokens": ["Da\u00b7rauf", ",", "o", "Gott", "!", "Dein", "All\u00b7mach\u00b7truff", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "$,", "FM", "NN", "$.", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht minder Creaturen schuff.", "tokens": ["Nicht", "min\u00b7der", "Crea\u00b7tu\u00b7ren", "schuff", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Ihr seltner Lauf entr\u00fcckt sie nur,", "tokens": ["Ihr", "selt\u00b7ner", "Lauf", "ent\u00b7r\u00fcckt", "sie", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Auf einer langgestreckten Spur,", "tokens": ["Auf", "ei\u00b7ner", "lang\u00b7ge\u00b7streck\u00b7ten", "Spur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Viel Jahre durch, dem Blick der Erden.", "tokens": ["Viel", "Jah\u00b7re", "durch", ",", "dem", "Blick", "der", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Doch k\u00f6nnen sie, bald kalt, bald warm,", "tokens": ["Doch", "k\u00f6n\u00b7nen", "sie", ",", "bald", "kalt", ",", "bald", "warm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Durch Deiner G\u00fcte Vaterarm,", "tokens": ["Durch", "Dei\u00b7ner", "G\u00fc\u00b7te", "Va\u00b7te\u00b7rarm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wohl an Gesch\u00f6pfen fruchtbar werden:", "tokens": ["Wohl", "an", "Ge\u00b7sch\u00f6p\u00b7fen", "frucht\u00b7bar", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Wenn selbst der Dampf, der uns erschreckt,", "tokens": ["Wenn", "selbst", "der", "Dampf", ",", "der", "uns", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Sie vor der Sonnenhitze deckt.", "tokens": ["Sie", "vor", "der", "Son\u00b7nen\u00b7hit\u00b7ze", "deckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Schon mehr als drey\u00dfig sind gez\u00e4hlt,", "tokens": ["Schon", "mehr", "als", "drey\u00b7\u00dfig", "sind", "ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "CARD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo unsrer Sonne Licht nicht fehlt.", "tokens": ["Wo", "uns\u00b7rer", "Son\u00b7ne", "Licht", "nicht", "fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer weis? ob wir die H\u00e4lfte kennen?", "tokens": ["Wer", "weis", "?", "ob", "wir", "die", "H\u00e4lf\u00b7te", "ken\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$.", "KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir wissen ja das Zehntheil kaum,", "tokens": ["Wir", "wis\u00b7sen", "ja", "das", "Zehn\u00b7theil", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von dem, was in des Himmels Raum,", "tokens": ["Von", "dem", ",", "was", "in", "des", "Him\u00b7mels", "Raum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "APPR", "ART", "NN", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "F\u00fcr flammenreiche Kugeln brennen:", "tokens": ["F\u00fcr", "flam\u00b7men\u00b7rei\u00b7che", "Ku\u00b7geln", "bren\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die doch der Ausspruch kluger Welt", "tokens": ["Die", "doch", "der", "Aus\u00b7spruch", "klu\u00b7ger", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Schon l\u00e4ngst f\u00fcr lauter Sonnen h\u00e4lt.", "tokens": ["Schon", "l\u00e4ngst", "f\u00fcr", "lau\u00b7ter", "Son\u00b7nen", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und wenn nun dieser Sonnen Heer,", "tokens": ["Und", "wenn", "nun", "die\u00b7ser", "Son\u00b7nen", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht mindern Welten dienstbar w\u00e4r,", "tokens": ["Nicht", "min\u00b7dern", "Wel\u00b7ten", "dienst\u00b7bar", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als unser Sonnenball belebet?", "tokens": ["Als", "un\u00b7ser", "Son\u00b7nen\u00b7ball", "be\u00b7le\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie gro\u00df wird da die Anzahl seyn,", "tokens": ["Wie", "gro\u00df", "wird", "da", "die", "An\u00b7zahl", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Kugeln, die ihr blasser Schein,", "tokens": ["Der", "Ku\u00b7geln", ",", "die", "ihr", "blas\u00b7ser", "Schein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In tiefer Himmel Nacht begr\u00e4bet?", "tokens": ["In", "tie\u00b7fer", "Him\u00b7mel", "Nacht", "be\u00b7gr\u00e4\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ach! in wie vieler Welten Schoo\u00df,", "tokens": ["Ach", "!", "in", "wie", "vie\u00b7ler", "Wel\u00b7ten", "Schoo\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "APPR", "KOKOM", "PIAT", "NN", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Bist Du, o Gott! an Wundern gro\u00df!", "tokens": ["Bist", "Du", ",", "o", "Gott", "!", "an", "Wun\u00b7dern", "gro\u00df", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "FM", "NN", "$.", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Dich lobt der K\u00f6rper gro\u00dfe Zahl,", "tokens": ["Dich", "lobt", "der", "K\u00f6r\u00b7per", "gro\u00b7\u00dfe", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Du, mit tadelfreyer Wahl,", "tokens": ["Die", "Du", ",", "mit", "ta\u00b7del\u00b7fre\u00b7yer", "Wahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus ihrem alten Nichts gezogen.", "tokens": ["Aus", "ih\u00b7rem", "al\u00b7ten", "Nichts", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dich lobt der Geister freyer Mund;", "tokens": ["Dich", "lobt", "der", "Geis\u00b7ter", "frey\u00b7er", "Mund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird ihm Gesetz und Ordnung kund,", "tokens": ["Wird", "ihm", "Ge\u00b7setz", "und", "Ord\u00b7nung", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Darnach Du alles abgewogen.", "tokens": ["Dar\u00b7nach", "Du", "al\u00b7les", "ab\u00b7ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dich lobt, o Gott! Dein weites Reich:", "tokens": ["Dich", "lobt", ",", "o", "Gott", "!", "Dein", "wei\u00b7tes", "Reich", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "FM", "NN", "$.", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ja, Sch\u00f6pfer, Dir ist niemand gleich!", "tokens": ["Ja", ",", "Sch\u00f6p\u00b7fer", ",", "Dir", "ist", "nie\u00b7mand", "gleich", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "PPER", "VAFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Bey so viel tausend Wundern nun,", "tokens": ["Bey", "so", "viel", "tau\u00b7send", "Wun\u00b7dern", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Was ist der Mensch, und all sein Thun,", "tokens": ["Was", "ist", "der", "Mensch", ",", "und", "all", "sein", "Thun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "KON", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Du, o H\u00f6chster! sein gedenkest?", "tokens": ["Da\u00df", "Du", ",", "o", "H\u00f6chs\u00b7ter", "!", "sein", "ge\u00b7den\u00b7kest", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "FM", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verdient ers, da\u00df ihm Deine Hand", "tokens": ["Ver\u00b7di\u00b7ent", "ers", ",", "da\u00df", "ihm", "Dei\u00b7ne", "Hand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "So manche Wohlthat zugewandt,", "tokens": ["So", "man\u00b7che", "Wohlt\u00b7hat", "zu\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Womit Du st\u00fcndlich ihn beschenkest?", "tokens": ["Wo\u00b7mit", "Du", "st\u00fcnd\u00b7lich", "ihn", "be\u00b7schen\u00b7kest", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "War ers in seinem Nichts wohl werth,", "tokens": ["War", "ers", "in", "sei\u00b7nem", "Nichts", "wohl", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "PPOSAT", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df Du auch ihn zum Seyn begehrt?", "tokens": ["Da\u00df", "Du", "auch", "ihn", "zum", "Seyn", "be\u00b7gehrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Der trefflichsten Gesch\u00f6pfe Zier,", "tokens": ["Der", "treff\u00b7lichs\u00b7ten", "Ge\u00b7sch\u00f6p\u00b7fe", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Viel tausend Geister dienen Dir,", "tokens": ["Viel", "tau\u00b7send", "Geis\u00b7ter", "die\u00b7nen", "Dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die dort in h\u00f6hern Sph\u00e4ren wohnen.", "tokens": ["Die", "dort", "in", "h\u00f6\u00b7hern", "Sph\u00e4\u00b7ren", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erhabne Seelen be\u00dfrer Kraft,", "tokens": ["Er\u00b7hab\u00b7ne", "See\u00b7len", "be\u00df\u00b7rer", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von ungleich gr\u00f6\u00dfrer Eigenschaft,", "tokens": ["Von", "un\u00b7gleich", "gr\u00f6\u00df\u00b7rer", "Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verehren Dich zu Millionen.", "tokens": ["Ver\u00b7eh\u00b7ren", "Dich", "zu", "Mil\u00b7lion\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Wie k\u00f6nnen wir uns unterstehn,", "tokens": ["Wie", "k\u00f6n\u00b7nen", "wir", "uns", "un\u00b7ter\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Unendlicher! Dich zu erh\u00f6hn?", "tokens": ["Un\u00b7end\u00b7li\u00b7cher", "!", "Dich", "zu", "er\u00b7h\u00f6hn", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Ist unsers Lebens l\u00e4ngste Zeit", "tokens": ["Ist", "un\u00b7sers", "Le\u00b7bens", "l\u00e4ngs\u00b7te", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor Dir wohl einer Spanne breit?", "tokens": ["Vor", "Dir", "wohl", "ei\u00b7ner", "Span\u00b7ne", "breit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "W\u00e4hrt unser Hauch wohl wenig Stunden?", "tokens": ["W\u00e4hrt", "un\u00b7ser", "Hauch", "wohl", "we\u00b7nig", "Stun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00e4hrt unser Seyn nicht wie der Wind?", "tokens": ["F\u00e4hrt", "un\u00b7ser", "Seyn", "nicht", "wie", "der", "Wind", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn eh ein d\u00fcnner Rauch verschwindt,", "tokens": ["Denn", "eh", "ein", "d\u00fcn\u00b7ner", "Rauch", "ver\u00b7schwindt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist unser Odem schon verschwunden;", "tokens": ["Ist", "un\u00b7ser", "O\u00b7dem", "schon", "ver\u00b7schwun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vor Dir, o Gott, dem tausend Jahr", "tokens": ["Vor", "Dir", ",", "o", "Gott", ",", "dem", "tau\u00b7send", "Jahr"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "FM", "NN", "$,", "PRELS", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Tag ja noch viel minder war.", "tokens": ["Ein", "Tag", "ja", "noch", "viel", "min\u00b7der", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Sind tausend Jahre Dir ein Tag?", "tokens": ["Sind", "tau\u00b7send", "Jah\u00b7re", "Dir", "ein", "Tag", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie k\u00f6mmts, da\u00df man sich schm\u00e4ucheln mag,", "tokens": ["Wie", "k\u00f6mmts", ",", "da\u00df", "man", "sich", "schm\u00e4u\u00b7cheln", "mag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "KOUS", "PIS", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf dieser Flucht noch alt zu werden?", "tokens": ["Auf", "die\u00b7ser", "Flucht", "noch", "alt", "zu", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kaum einer lebt den zehnten Theil!", "tokens": ["Kaum", "ei\u00b7ner", "lebt", "den", "zehn\u00b7ten", "Theil", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die gr\u00f6\u00dfte Meng entflieht in Eil", "tokens": ["Die", "gr\u00f6\u00df\u00b7te", "Meng", "ent\u00b7flieht", "in", "Eil"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Eitelkeit bewohnter Erden.", "tokens": ["Der", "Ei\u00b7tel\u00b7keit", "be\u00b7wohn\u00b7ter", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Kaum hat sie funfzig Jahr erstrebt,", "tokens": ["Kaum", "hat", "sie", "funf\u00b7zig", "Jahr", "er\u00b7strebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So hat sie v\u00f6llig ausgelebt.", "tokens": ["So", "hat", "sie", "v\u00f6l\u00b7lig", "aus\u00b7ge\u00b7lebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Die\u00df Ziel, o Gott, Dem niemand gleicht!", "tokens": ["Die\u00df", "Ziel", ",", "o", "Gott", ",", "Dem", "nie\u00b7mand", "gleicht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "FM", "NN", "$,", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat meiner Tage Lauf erreicht,", "tokens": ["Hat", "mei\u00b7ner", "Ta\u00b7ge", "Lauf", "er\u00b7reicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat itzt Dein Knecht begl\u00fcckt errungen!", "tokens": ["Hat", "itzt", "Dein", "Knecht", "be\u00b7gl\u00fcckt", "er\u00b7run\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Wink hat meine Kraft gest\u00e4rkt,", "tokens": ["Dein", "Wink", "hat", "mei\u00b7ne", "Kraft", "ge\u00b7st\u00e4rkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Seel und K\u00f6rper unvermerkt", "tokens": ["Da\u00df", "Seel", "und", "K\u00f6r\u00b7per", "un\u00b7ver\u00b7merkt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein halb Jahrhundert durchgedrungen;", "tokens": ["Ein", "halb", "Jahr\u00b7hun\u00b7dert", "durch\u00b7ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bevor, was Geist und Glieder r\u00fchrt,", "tokens": ["Be\u00b7vor", ",", "was", "Geist", "und", "Glie\u00b7der", "r\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der mindsten Schw\u00e4chung Grad gesp\u00fcrt.", "tokens": ["Der", "minds\u00b7ten", "Schw\u00e4\u00b7chung", "Grad", "ge\u00b7sp\u00fcrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Wie manchen Freund hab ich gekannt,", "tokens": ["Wie", "man\u00b7chen", "Freund", "hab", "ich", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der sich bey gleichen Kr\u00e4ften fand;", "tokens": ["Der", "sich", "bey", "glei\u00b7chen", "Kr\u00e4f\u00b7ten", "fand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und gleichwohl l\u00e4ngst vor mir erblichen?", "tokens": ["Und", "gleich\u00b7wohl", "l\u00e4ngst", "vor", "mir", "er\u00b7bli\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In frischer Jugend, voller Saft,", "tokens": ["In", "fri\u00b7scher", "Ju\u00b7gend", ",", "vol\u00b7ler", "Saft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verlohr so mancher Geist und Kraft,", "tokens": ["Ver\u00b7lohr", "so", "man\u00b7cher", "Geist", "und", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist mancher schnell der Welt entwichen.", "tokens": ["Ist", "man\u00b7cher", "schnell", "der", "Welt", "ent\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auch manch Geschwister wird vermi\u00dft,", "tokens": ["Auch", "manch", "Ge\u00b7schwis\u00b7ter", "wird", "ver\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das mir sehr jung entrissen ist.", "tokens": ["Das", "mir", "sehr", "jung", "ent\u00b7ris\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Herr! war ichs vor so vielen werth,", "tokens": ["Herr", "!", "war", "ichs", "vor", "so", "vie\u00b7len", "werth", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VAFIN", "PIS", "APPR", "ADV", "PIAT", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df meine Kraft sich nicht verzehrt,", "tokens": ["Da\u00df", "mei\u00b7ne", "Kraft", "sich", "nicht", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Lampen deren Tocht verglimmet.", "tokens": ["Wie", "Lam\u00b7pen", "de\u00b7ren", "Tocht", "ver\u00b7glim\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PRELAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Deine Vorsicht mich ersehn,", "tokens": ["Hat", "Dei\u00b7ne", "Vor\u00b7sicht", "mich", "er\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu Diensten, die noch nicht geschehn,", "tokens": ["Zu", "Diens\u00b7ten", ",", "die", "noch", "nicht", "ge\u00b7schehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und die Dein Rathschlu\u00df schon bestimmet?", "tokens": ["Und", "die", "Dein", "Rath\u00b7schlu\u00df", "schon", "be\u00b7stim\u00b7met", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bin ich geschickt dazu erkannt?", "tokens": ["Bin", "ich", "ge\u00b7schickt", "da\u00b7zu", "er\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sieh, Herr! ich bin in Deiner Hand.", "tokens": ["Sieh", ",", "Herr", "!", "ich", "bin", "in", "Dei\u00b7ner", "Hand", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$.", "PPER", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Du bist der T\u00f6pfer, ich der Thon;", "tokens": ["Du", "bist", "der", "T\u00f6p\u00b7fer", ",", "ich", "der", "Thon", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Herr! der Vater; ich der Sohn;", "tokens": ["Du", "Herr", "!", "der", "Va\u00b7ter", ";", "ich", "der", "Sohn", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "ART", "NN", "$.", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin das Werkzeug, Du der Meister!", "tokens": ["Ich", "bin", "das", "Werk\u00b7zeug", ",", "Du", "der", "Meis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mach alles, was Du willst, mit mir!", "tokens": ["Mach", "al\u00b7les", ",", "was", "Du", "willst", ",", "mit", "mir", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWS", "PPER", "VMFIN", "$,", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur wirf mich nicht erz\u00fcrnt von Dir,", "tokens": ["Nur", "wirf", "mich", "nicht", "er\u00b7z\u00fcrnt", "von", "Dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PTKNEG", "VVPP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du h\u00f6chstes Gut erschaffner Geister!", "tokens": ["Du", "h\u00f6chs\u00b7tes", "Gut", "er\u00b7schaff\u00b7ner", "Geis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "La\u00df meinen Dienst nur nicht gemein,", "tokens": ["La\u00df", "mei\u00b7nen", "Dienst", "nur", "nicht", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht sch\u00e4ndlich, nicht verwerflich seyn.", "tokens": ["Nicht", "sch\u00e4nd\u00b7lich", ",", "nicht", "ver\u00b7werf\u00b7lich", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Mein Zweck war schon von Kindheit an,", "tokens": ["Mein", "Zweck", "war", "schon", "von", "Kind\u00b7heit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So viel ich mich besinnen kann,", "tokens": ["So", "viel", "ich", "mich", "be\u00b7sin\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Ernst der Welt und Dir zu dienen.", "tokens": ["Mit", "Ernst", "der", "Welt", "und", "Dir", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "KON", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du weist, da\u00df meiner jungen Brust,", "tokens": ["Du", "weist", ",", "da\u00df", "mei\u00b7ner", "jun\u00b7gen", "Brust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Reizung lasterhafter Lust", "tokens": ["Die", "Rei\u00b7zung", "las\u00b7ter\u00b7haf\u00b7ter", "Lust"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schon als ein s\u00fc\u00dfes Gift geschienen:", "tokens": ["Schon", "als", "ein", "s\u00fc\u00b7\u00dfes", "Gift", "ge\u00b7schie\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was mancher h\u00f6chst bem\u00fcht gesucht,", "tokens": ["Was", "man\u00b7cher", "h\u00f6chst", "be\u00b7m\u00fcht", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Davor nahm ich sehr oft die Flucht.", "tokens": ["Da\u00b7vor", "nahm", "ich", "sehr", "oft", "die", "Flucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Dein Geist hat mich getreu regiert,", "tokens": ["Dein", "Geist", "hat", "mich", "ge\u00b7treu", "re\u00b7giert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und mancher Tugend zugef\u00fchrt,", "tokens": ["Und", "man\u00b7cher", "Tu\u00b7gend", "zu\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die sonst der Jugend Trieb verfehlet.", "tokens": ["Die", "sonst", "der", "Ju\u00b7gend", "Trieb", "ver\u00b7feh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem dank ichs, nicht der eignen Kraft,", "tokens": ["Dem", "dank", "ichs", ",", "nicht", "der", "eig\u00b7nen", "Kraft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIS", "$,", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ich den Weg der Wissenschaft", "tokens": ["Da\u00df", "ich", "den", "Weg", "der", "Wis\u00b7sen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf meines Vaters Wink erw\u00e4hlet.", "tokens": ["Auf", "mei\u00b7nes", "Va\u00b7ters", "Wink", "er\u00b7w\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die erste Wohlthat Deiner Hand", "tokens": ["Die", "ers\u00b7te", "Wohlt\u00b7hat", "Dei\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Hat mir den F\u00fchrer zugewandt.", "tokens": ["Hat", "mir", "den", "F\u00fch\u00b7rer", "zu\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Der lenkte mich von Jugend auf", "tokens": ["Der", "lenk\u00b7te", "mich", "von", "Ju\u00b7gend", "auf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von jener Bahn, wo sonst der Lauf", "tokens": ["Von", "je\u00b7ner", "Bahn", ",", "wo", "sonst", "der", "Lauf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "PWAV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch viele Lasterpf\u00fctzen leitet:", "tokens": ["Durch", "vie\u00b7le", "Las\u00b7ter\u00b7pf\u00fct\u00b7zen", "lei\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn junger Herzen L\u00fcsternheit", "tokens": ["Wenn", "jun\u00b7ger", "Her\u00b7zen", "L\u00fcs\u00b7tern\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In gro\u00dfer St\u00e4dte Wildigkeit", "tokens": ["In", "gro\u00b7\u00dfer", "St\u00e4d\u00b7te", "Wil\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr B\u00f6ses lernt, als Kunst erbeutet.", "tokens": ["Mehr", "B\u00f6\u00b7ses", "lernt", ",", "als", "Kunst", "er\u00b7beu\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Gott! vor Gefahren solcher Art,", "tokens": ["Gott", "!", "vor", "Ge\u00b7fah\u00b7ren", "sol\u00b7cher", "Art", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "NN", "PIAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Hat mich des Vaters Flei\u00df bewahrt.", "tokens": ["Hat", "mich", "des", "Va\u00b7ters", "Flei\u00df", "be\u00b7wahrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sein treugemeynter Unterricht,", "tokens": ["Sein", "treu\u00b7ge\u00b7meyn\u00b7ter", "Un\u00b7ter\u00b7richt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wies mir der freyen K\u00fcnste Licht,", "tokens": ["Wies", "mir", "der", "frey\u00b7en", "K\u00fcns\u00b7te", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und was die alten Sprachen n\u00fctzen.", "tokens": ["Und", "was", "die", "al\u00b7ten", "Spra\u00b7chen", "n\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Er selber legte so den Grund,", "tokens": ["Er", "sel\u00b7ber", "leg\u00b7te", "so", "den", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Er selber that mir spielend kund,", "tokens": ["Er", "sel\u00b7ber", "that", "mir", "spie\u00b7lend", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wobey sonst Knaben m\u00fchsam schwitzen;", "tokens": ["Wo\u00b7bey", "sonst", "Kna\u00b7ben", "m\u00fch\u00b7sam", "schwit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Bis ich im dreymal f\u00fcnften Jahr,", "tokens": ["Bis", "ich", "im", "drey\u00b7mal", "f\u00fcnf\u00b7ten", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Zu h\u00f6hern Schulen t\u00fcchtig war.", "tokens": ["Zu", "h\u00f6\u00b7hern", "Schu\u00b7len", "t\u00fcch\u00b7tig", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Hier wiesest du mir G\u00f6nner an,", "tokens": ["Hier", "wie\u00b7sest", "du", "mir", "G\u00f6n\u00b7ner", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die meines armen Flei\u00dfes Bahn", "tokens": ["Die", "mei\u00b7nes", "ar\u00b7men", "Flei\u00b7\u00dfes", "Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Huld und Wohlthun unterst\u00fctzten.", "tokens": ["Durch", "Huld", "und", "Wohl\u00b7thun", "un\u00b7ter\u00b7st\u00fctz\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Mangel ward durch Zuschub leicht,", "tokens": ["Mein", "Man\u00b7gel", "ward", "durch", "Zu\u00b7schub", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Lehrer wurden mir geneigt,", "tokens": ["Die", "Leh\u00b7rer", "wur\u00b7den", "mir", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Indem sie meinen Eifer sch\u00fctzten;", "tokens": ["In\u00b7dem", "sie", "mei\u00b7nen", "Ei\u00b7fer", "sch\u00fctz\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bis ihre Hand mir noch zuletzt", "tokens": ["Bis", "ih\u00b7re", "Hand", "mir", "noch", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Hut der Lehrer aufgesetzt.", "tokens": ["Den", "Hut", "der", "Leh\u00b7rer", "auf\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Bisher sah mich mein Preu\u00dfenland;", "tokens": ["Bis\u00b7her", "sah", "mich", "mein", "Preu\u00b7\u00dfen\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als deine weise Vaterhand", "tokens": ["Als", "dei\u00b7ne", "wei\u00b7se", "Va\u00b7ter\u00b7hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich auch durch Tr\u00fcbsal pr\u00fcfen wollte.", "tokens": ["Mich", "auch", "durch", "Tr\u00fcb\u00b7sal", "pr\u00fc\u00b7fen", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Unfall, welcher mich bedroht,", "tokens": ["Ein", "Un\u00b7fall", ",", "wel\u00b7cher", "mich", "be\u00b7droht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ward mir ein Ruf, der schnell geboth,", "tokens": ["Ward", "mir", "ein", "Ruf", ",", "der", "schnell", "ge\u00b7both", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df ich die Fremde suchen sollte.", "tokens": ["Da\u00df", "ich", "die", "Frem\u00b7de", "su\u00b7chen", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Woselbst mir doch, kaum auf ein Jahr,", "tokens": ["Wo\u00b7selbst", "mir", "doch", ",", "kaum", "auf", "ein", "Jahr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "$,", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Unterhalt in H\u00e4nden war.", "tokens": ["Der", "Un\u00b7ter\u00b7halt", "in", "H\u00e4n\u00b7den", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Herr! der Du auch die Raben h\u00f6rst,", "tokens": ["Herr", "!", "der", "Du", "auch", "die", "Ra\u00b7ben", "h\u00f6rst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PRELS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und oft der Armen Kad vermehrst,", "tokens": ["Und", "oft", "der", "Ar\u00b7men", "Kad", "ver\u00b7mehrst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch mir hat nichts gebrechen m\u00fcssen!", "tokens": ["Auch", "mir", "hat", "nichts", "ge\u00b7bre\u00b7chen", "m\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PIS", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du reichtest mir so Kleid als Brodt,", "tokens": ["Du", "reich\u00b7test", "mir", "so", "Kleid", "als", "Brodt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In Mei\u00dfen traf mich keine Noth;", "tokens": ["In", "Mei\u00b7\u00dfen", "traf", "mich", "kei\u00b7ne", "Noth", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hier war ich aller Furcht entrissen!", "tokens": ["Hier", "war", "ich", "al\u00b7ler", "Furcht", "ent\u00b7ris\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hier gab der Flei\u00df durch Mund und Hand", "tokens": ["Hier", "gab", "der", "Flei\u00df", "durch", "Mund", "und", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mir fast ein neues Vaterland.", "tokens": ["Mir", "fast", "ein", "neu\u00b7es", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Was sag ich? Nein! Wer sonst, als Du,", "tokens": ["Was", "sag", "ich", "?", "Nein", "!", "Wer", "sonst", ",", "als", "Du", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PTKANT", "$.", "PWS", "ADV", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wandt mir der Gro\u00dfen Neigung zu,", "tokens": ["Wandt", "mir", "der", "Gro\u00b7\u00dfen", "Nei\u00b7gung", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die f\u00fcr der Musen Wohlfahrt wachen?", "tokens": ["Die", "f\u00fcr", "der", "Mu\u00b7sen", "Wohl\u00b7fahrt", "wa\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bald weist ", "tokens": ["Bald", "weist"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Sich auch geneigt, mein Gl\u00fcck zu machen;", "tokens": ["Sich", "auch", "ge\u00b7neigt", ",", "mein", "Gl\u00fcck", "zu", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie wiesen mir ein Lehramt an,", "tokens": ["Sie", "wie\u00b7sen", "mir", "ein", "Le\u00b7hramt", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das M\u00fch und Flei\u00df ermuntern kann.", "tokens": ["Das", "M\u00fch", "und", "Flei\u00df", "er\u00b7mun\u00b7tern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Wenn Mund und Kiel sich manches Jahr", "tokens": ["Wenn", "Mund", "und", "Kiel", "sich", "man\u00b7ches", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NE", "PRF", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bestrebt, die Weisheit recht zu lehren;", "tokens": ["Be\u00b7strebt", ",", "die", "Weis\u00b7heit", "recht", "zu", "leh\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So ward mein Eifer sehr gest\u00e4rkt,", "tokens": ["So", "ward", "mein", "Ei\u00b7fer", "sehr", "ge\u00b7st\u00e4rkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So oft ich dankbar angemerkt,", "tokens": ["So", "oft", "ich", "dank\u00b7bar", "an\u00b7ge\u00b7merkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df sich Dein Segen schien zu mehren:", "tokens": ["Da\u00df", "sich", "Dein", "Se\u00b7gen", "schien", "zu", "meh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn Adel, Graf und Prinz sogar", "tokens": ["Wenn", "A\u00b7del", ",", "Graf", "und", "Prinz", "so\u00b7gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NE", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Um meinen H\u00f6rsaal eifrig war.", "tokens": ["Um", "mei\u00b7nen", "H\u00f6r\u00b7saal", "eif\u00b7rig", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Der hohen Schulen Purpurtracht", "tokens": ["Der", "ho\u00b7hen", "Schu\u00b7len", "Pur\u00b7pur\u00b7tracht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hast Du mir viermal zugedacht,", "tokens": ["Hast", "Du", "mir", "vier\u00b7mal", "zu\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das edle ", "tokens": ["Das", "ed\u00b7le"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wenn mir der gr\u00f6\u00dften M\u00e4nner Wahl,", "tokens": ["Wenn", "mir", "der", "gr\u00f6\u00df\u00b7ten", "M\u00e4n\u00b7ner", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Musen Zepter anbefahl,", "tokens": ["Der", "Mu\u00b7sen", "Zep\u00b7ter", "an\u00b7be\u00b7fahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Pindus-B\u00fcrger einzuschr\u00e4nken;", "tokens": ["Die", "Pin\u00b7dus\u00b7B\u00fcr\u00b7ger", "ein\u00b7zu\u00b7schr\u00e4n\u00b7ken", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die mir doch oft, bey stiller Nacht,", "tokens": ["Die", "mir", "doch", "oft", ",", "bey", "stil\u00b7ler", "Nacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Seytenspiele Dank gebracht.", "tokens": ["Der", "Sey\u00b7ten\u00b7spie\u00b7le", "Dank", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Wie vieler Gro\u00dfen Huld und Gunst", "tokens": ["Wie", "vie\u00b7ler", "Gro\u00b7\u00dfen", "Huld", "und", "Gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat mir nicht Wissenschaft und Kunst,", "tokens": ["Hat", "mir", "nicht", "Wis\u00b7sen\u00b7schaft", "und", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Deine F\u00fcgung, zugezogen!", "tokens": ["Durch", "Dei\u00b7ne", "F\u00fc\u00b7gung", ",", "zu\u00b7ge\u00b7zo\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch F\u00fcrsten wurden mir geneigt,", "tokens": ["Auch", "F\u00fcrs\u00b7ten", "wur\u00b7den", "mir", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Habens in der That gezeigt,", "tokens": ["Und", "Ha\u00b7bens", "in", "der", "That", "ge\u00b7zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sind mir itzo noch gewogen.", "tokens": ["Und", "sind", "mir", "it\u00b7zo", "noch", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des ", "tokens": ["Des"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Hat mir den Zutritt j\u00fcngst erlaubt.", "tokens": ["Hat", "mir", "den", "Zu\u00b7tritt", "j\u00fcngst", "er\u00b7laubt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Was sag ich von der s\u00fc\u00dfen Eh,", "tokens": ["Was", "sag", "ich", "von", "der", "s\u00fc\u00b7\u00dfen", "Eh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Darinn ich durch Dein F\u00fcgen steh,", "tokens": ["Da\u00b7rinn", "ich", "durch", "Dein", "F\u00fc\u00b7gen", "steh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O Vater! der Du Herzen bindest!", "tokens": ["O", "Va\u00b7ter", "!", "der", "Du", "Her\u00b7zen", "bin\u00b7dest", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PRELS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du hast die Gattinn mir ersehn,", "tokens": ["Du", "hast", "die", "Gat\u00b7tinn", "mir", "er\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Du in Gram und Wohlergehn", "tokens": ["Die", "Du", "in", "Gram", "und", "Woh\u00b7ler\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mir treugesinnt und redlich findest;", "tokens": ["Mir", "treu\u00b7ge\u00b7sinnt", "und", "red\u00b7lich", "fin\u00b7dest", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So da\u00df ich ihren edlen Sinn", "tokens": ["So", "da\u00df", "ich", "ih\u00b7ren", "ed\u00b7len", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dir zu verdanken schuldig bin.", "tokens": ["Dir", "zu", "ver\u00b7dan\u00b7ken", "schul\u00b7dig", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Zwar hat es mir, nach Art der Welt,", "tokens": ["Zwar", "hat", "es", "mir", ",", "nach", "Art", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "$,", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die nichts vollkommnes in sich h\u00e4lt,", "tokens": ["Die", "nichts", "voll\u00b7komm\u00b7nes", "in", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJA", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch nicht an Ha\u00df und Neid gefehlet.", "tokens": ["Auch", "nicht", "an", "Ha\u00df", "und", "Neid", "ge\u00b7feh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch hab ich gegen manchen Feind,", "tokens": ["Doch", "hab", "ich", "ge\u00b7gen", "man\u00b7chen", "Feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Brust, die sonst nicht f\u00fchllos scheint,", "tokens": ["Die", "Brust", ",", "die", "sonst", "nicht", "f\u00fchl\u00b7los", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Gro\u00dfmuth und Geduld umst\u00e4hlet;", "tokens": ["Mit", "Gro\u00df\u00b7muth", "und", "Ge\u00b7duld", "um\u00b7st\u00e4h\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und was die L\u00e4stersucht erdacht,", "tokens": ["Und", "was", "die", "L\u00e4s\u00b7ter\u00b7sucht", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Durch sanftes Schweigen stumpf gemacht.", "tokens": ["Durch", "sanf\u00b7tes", "Schwei\u00b7gen", "stumpf", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Die\u00df sag ich nicht, als ob ich frey", "tokens": ["Die\u00df", "sag", "ich", "nicht", ",", "als", "ob", "ich", "frey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$,", "KOKOM", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Fehlern, Maal und Narben sey,", "tokens": ["Von", "Feh\u00b7lern", ",", "Maal", "und", "Nar\u00b7ben", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die diesen mehr, als den, beflecken:", "tokens": ["Die", "die\u00b7sen", "mehr", ",", "als", "den", ",", "be\u00b7fle\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PDS", "ADV", "$,", "KOUS", "ART", "$,", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Nein Herr! Du kennest Herz und Sinn!", "tokens": ["Nein", "Herr", "!", "Du", "ken\u00b7nest", "Herz", "und", "Sinn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$.", "PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und weist schon, wo ich schuldig bin:", "tokens": ["Und", "weist", "schon", ",", "wo", "ich", "schul\u00b7dig", "bin", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was darf ichs Dir noch erst entdecken?", "tokens": ["Was", "darf", "ichs", "Dir", "noch", "erst", "ent\u00b7de\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du weist, da\u00df ichs geduldig trug,", "tokens": ["Du", "weist", ",", "da\u00df", "ichs", "ge\u00b7dul\u00b7dig", "trug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So oft mich deine Ruthe schlug.", "tokens": ["So", "oft", "mich", "dei\u00b7ne", "Ru\u00b7the", "schlug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Ich k\u00fcsse deine Vaterhand,", "tokens": ["Ich", "k\u00fcs\u00b7se", "dei\u00b7ne", "Va\u00b7ter\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ich noch stets gesch\u00e4fftig fand,", "tokens": ["Die", "ich", "noch", "stets", "ge\u00b7sch\u00e4ff\u00b7tig", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein unverr\u00fccktes Wohl zu bauen.", "tokens": ["Mein", "un\u00b7ver\u00b7r\u00fcck\u00b7tes", "Wohl", "zu", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der will ich ferner was ich bin,", "tokens": ["Der", "will", "ich", "fer\u00b7ner", "was", "ich", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Gl\u00fcck und Leben, Leib und Sinn,", "tokens": ["Mein", "Gl\u00fcck", "und", "Le\u00b7ben", ",", "Leib", "und", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kurz, was nur mein ist, anvertrauen.", "tokens": ["Kurz", ",", "was", "nur", "mein", "ist", ",", "an\u00b7ver\u00b7trau\u00b7en", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "PRELS", "ADV", "PPOSAT", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Jedoch, o Gott! was ist wohl mein?", "tokens": ["Je\u00b7doch", ",", "o", "Gott", "!", "was", "ist", "wohl", "mein", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "NN", "$.", "PWS", "VAFIN", "ADV", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich, Welt und Himmel sind ja dein.", "tokens": ["Ich", ",", "Welt", "und", "Him\u00b7mel", "sind", "ja", "dein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "KON", "NN", "VAFIN", "ADV", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Kann ich hier noch was Gutes thun,", "tokens": ["Kann", "ich", "hier", "noch", "was", "Gu\u00b7tes", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "PWS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So la\u00df mich, H\u00f6chster! niemals ruhn,", "tokens": ["So", "la\u00df", "mich", ",", "H\u00f6chs\u00b7ter", "!", "nie\u00b7mals", "ruhn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "$,", "NN", "$.", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was Dir gef\u00e4llt, ins Werk zu setzen!", "tokens": ["Was", "Dir", "ge\u00b7f\u00e4llt", ",", "ins", "Werk", "zu", "set\u00b7zen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch l\u00e4uft mein Stundenglas bald aus:", "tokens": ["Doch", "l\u00e4uft", "mein", "Stun\u00b7den\u00b7glas", "bald", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So f\u00fchre mich in jenes Haus,", "tokens": ["So", "f\u00fch\u00b7re", "mich", "in", "je\u00b7nes", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo Du die Deinen wirst ergetzen!", "tokens": ["Wo", "Du", "die", "Dei\u00b7nen", "wirst", "er\u00b7get\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da will ich mehr, als hier geschehn,", "tokens": ["Da", "will", "ich", "mehr", ",", "als", "hier", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "$,", "KOUS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Wunder Deiner Weisheit sehn.", "tokens": ["Die", "Wun\u00b7der", "Dei\u00b7ner", "Weis\u00b7heit", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}