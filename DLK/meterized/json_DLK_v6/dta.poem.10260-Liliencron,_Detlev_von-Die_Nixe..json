{"dta.poem.10260": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "Die Nixe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1883", "urn": "urn:nbn:de:kobv:b4-200905197184", "language": ["de:0.99"], "booktitle": "Liliencron, Detlev von: Adjutantenritte und andere Gedichte. Leipzig, [1883]."}, "poem": {"stanza.1": {"line.1": {"text": "Der Tag ist aus, und letzt' Gel&#228;ut             ", "tokens": ["Der", "Tag", "ist", "aus", ",", "und", "letzt'", "Gel", "&#228;", "ut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "XML_entity", "word"], "pos": ["ART", "NN", "VAFIN", "PTKVZ", "$,", "KON", "ADJA", "NN", "$(", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verk\u00fcndet uns: Genug f\u00fcr heut.", "tokens": ["Ver\u00b7k\u00fcn\u00b7det", "uns", ":", "Ge\u00b7nug", "f\u00fcr", "heut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Fort legt der Schuster seinen Pfriemen,", "tokens": ["Fort", "legt", "der", "Schus\u00b7ter", "sei\u00b7nen", "Pfrie\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und der den Hobel, der den Riemen.", "tokens": ["Und", "der", "den", "Ho\u00b7bel", ",", "der", "den", "Rie\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "$,", "PRELS", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Bauer trennt sich von der Sense,", "tokens": ["Der", "Bau\u00b7er", "trennt", "sich", "von", "der", "Sen\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Knecht h\u00e4ngt an den Pflock die Trense.", "tokens": ["Der", "Knecht", "h\u00e4ngt", "an", "den", "Pflock", "die", "Tren\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der Schreiber selbst, der arme Mann,", "tokens": ["Der", "Schrei\u00b7ber", "selbst", ",", "der", "ar\u00b7me", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er sieht die Welt sich drau\u00dfen an.", "tokens": ["Er", "sieht", "die", "Welt", "sich", "drau\u00b7\u00dfen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Bekanntlich ist bei uns der Mai", "tokens": ["Be\u00b7kannt\u00b7lich", "ist", "bei", "uns", "der", "Mai"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Eis und Schnee nie g\u00e4nzlich frei,", "tokens": ["Von", "Eis", "und", "Schnee", "nie", "g\u00e4nz\u00b7lich", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch ist es heut ein Sommerabend,", "tokens": ["Doch", "ist", "es", "heut", "ein", "Som\u00b7mer\u00b7a\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der alte Reim darauf ist labend.", "tokens": ["Der", "al\u00b7te", "Reim", "da\u00b7rauf", "ist", "la\u00b7bend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Viel Liebesp\u00e4rchen sind bereit,", "tokens": ["Viel", "Lie\u00b7be\u00b7sp\u00e4r\u00b7chen", "sind", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Um, kommt die liebe Dunkelheit,", "tokens": ["Um", ",", "kommt", "die", "lie\u00b7be", "Dun\u00b7kel\u00b7heit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu scherzen viel und viel zu fl\u00fcstern,", "tokens": ["Zu", "scher\u00b7zen", "viel", "und", "viel", "zu", "fl\u00fcs\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "KON", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nat\u00fcrlich unter d\u00fcstern R\u00fcstern.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "un\u00b7ter", "d\u00fcs\u00b7tern", "R\u00fcs\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein Jeder sucht von Dissonanzen,", "tokens": ["Ein", "Je\u00b7der", "sucht", "von", "Dis\u00b7so\u00b7nan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die selbst den hellsten Tag verschnein,", "tokens": ["Die", "selbst", "den", "hells\u00b7ten", "Tag", "ver\u00b7schnein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei Tagesschlu\u00df sich zu befrein.", "tokens": ["Bei", "Ta\u00b7ges\u00b7schlu\u00df", "sich", "zu", "be\u00b7fr\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In Spanien durch Fandangotanzen,", "tokens": ["In", "Spa\u00b7ni\u00b7en", "durch", "Fan\u00b7dan\u00b7go\u00b7tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Wir sitzen hinter Flaschenschanzen.", "tokens": ["Wir", "sit\u00b7zen", "hin\u00b7ter", "Fla\u00b7schen\u00b7schan\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Auch ist\u2019s behaglich, wenn Lakaien", "tokens": ["Auch", "ist's", "be\u00b7hag\u00b7lich", ",", "wenn", "La\u00b7kai\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "ADJD", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Recht warme Sch\u00fcsseln vor uns setzen,", "tokens": ["Recht", "war\u00b7me", "Sch\u00fcs\u00b7seln", "vor", "uns", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und wir den Braten dann zerfetzen,", "tokens": ["Und", "wir", "den", "Bra\u00b7ten", "dann", "zer\u00b7fet\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "In Honolulu mit den N\u00e4geln,", "tokens": ["In", "Ho\u00b7no\u00b7lu\u00b7lu", "mit", "den", "N\u00e4\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wir nach bekannten Anstandsregeln.", "tokens": ["Wir", "nach", "be\u00b7kann\u00b7ten", "An\u00b7stands\u00b7re\u00b7geln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Ich lobe mir die Tafelfreuden,", "tokens": ["Ich", "lo\u00b7be", "mir", "die", "Ta\u00b7fel\u00b7freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wenn nicht zuviel wir d\u2019ran vergeuden,", "tokens": ["Wenn", "nicht", "zu\u00b7viel", "wir", "d'\u00b7ran", "ver\u00b7geu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "VVFIN", "PPER", "PAV", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.13": {"text": "Als angenehmste Zeit am Tage,", "tokens": ["Als", "an\u00b7ge\u00b7nehms\u00b7te", "Zeit", "am", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Vergessen Schema F und Plage.", "tokens": ["Ver\u00b7ges\u00b7sen", "Sche\u00b7ma", "F", "und", "Pla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch mehr Gen\u00fcsse giebt es noch", "tokens": ["Doch", "mehr", "Ge\u00b7n\u00fcs\u00b7se", "giebt", "es", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach Lebenslast und Tagesjoch.", "tokens": ["Nach", "Le\u00b7bens\u00b7last", "und", "Ta\u00b7ges\u00b7joch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Beispiel der Natur sich freuen,", "tokens": ["Zum", "Bei\u00b7spiel", "der", "Na\u00b7tur", "sich", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sich im Wandern zu zerstreuen.", "tokens": ["Und", "sich", "im", "Wan\u00b7dern", "zu", "zer\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So fand ich heut, ich wei\u00df nicht wie,", "tokens": ["So", "fand", "ich", "heut", ",", "ich", "wei\u00df", "nicht", "wie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vielleicht auf meiner Baronie,", "tokens": ["Viel\u00b7leicht", "auf", "mei\u00b7ner", "Ba\u00b7ro\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Auf einer Wiese weit und breit", "tokens": ["Auf", "ei\u00b7ner", "Wie\u00b7se", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die stille Blume Einsamkeit.", "tokens": ["Die", "stil\u00b7le", "Blu\u00b7me", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zwei braune K\u00fche rupften dort,", "tokens": ["Zwei", "brau\u00b7ne", "K\u00fc\u00b7he", "rupf\u00b7ten", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Fl\u00fc\u00dfchen schwatzte fort und fort,", "tokens": ["Ein", "Fl\u00fc\u00df\u00b7chen", "schwatz\u00b7te", "fort", "und", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und aus den Buchen an der Heide,", "tokens": ["Und", "aus", "den", "Bu\u00b7chen", "an", "der", "Hei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Zwar Walter von der Vogelweide", "tokens": ["Zwar", "Wal\u00b7ter", "von", "der", "Vo\u00b7gel\u00b7wei\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Sagt Linden, sang die Nachtigall", "tokens": ["Sagt", "Lin\u00b7den", ",", "sang", "die", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NE", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Tandaradei!", "tokens": ["Tan\u00b7da\u00b7ra\u00b7dei", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "++-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Und stiller ward es rings umher.", "tokens": ["Und", "stil\u00b7ler", "ward", "es", "rings", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich streckte mich ins junge Gras,", "tokens": ["Ich", "streck\u00b7te", "mich", "ins", "jun\u00b7ge", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dachte dieses, dachte das.", "tokens": ["Und", "dach\u00b7te", "die\u00b7ses", ",", "dach\u00b7te", "das", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "$,", "VVFIN", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die K\u00fche lagen, wiederk\u00e4uend,", "tokens": ["Die", "K\u00fc\u00b7he", "la\u00b7gen", ",", "wie\u00b7der\u00b7k\u00e4u\u00b7end", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Sich schon auf neue Kr\u00e4uter freuend.", "tokens": ["Sich", "schon", "auf", "neu\u00b7e", "Kr\u00e4u\u00b7ter", "freu\u00b7end", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wie kam ich pl\u00f6tzlich auf Homer?", "tokens": ["Wie", "kam", "ich", "pl\u00f6tz\u00b7lich", "auf", "Ho\u00b7mer", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADJD", "APPR", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Es fiel mir aus der Ilias", "tokens": ["Es", "fiel", "mir", "aus", "der", "I\u00b7lias"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Achilleus ein. Ich mag ihn nicht,", "tokens": ["A\u00b7chil\u00b7leus", "ein", ".", "Ich", "mag", "ihn", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und leiste gern auf ihn Verzicht.", "tokens": ["Und", "leis\u00b7te", "gern", "auf", "ihn", "Ver\u00b7zicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sprach jemals einer solche Worte", "tokens": ["Sprach", "je\u00b7mals", "ei\u00b7ner", "sol\u00b7che", "Wor\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu seinem Feinde, wenn die Pforte", "tokens": ["Zu", "sei\u00b7nem", "Fein\u00b7de", ",", "wenn", "die", "Pfor\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des Todes sich ihm \u00f6ffnen will.", "tokens": ["Des", "To\u00b7des", "sich", "ihm", "\u00f6ff\u00b7nen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Es h\u00f6hnt der Fleischerknecht Achill,", "tokens": ["Es", "h\u00f6hnt", "der", "Flei\u00b7scher\u00b7knecht", "A\u00b7chill", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als Hektor sterbend vor ihm lag:", "tokens": ["Als", "Hek\u00b7tor", "ster\u00b7bend", "vor", "ihm", "lag", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "\u201enun hast du deinen letzten Tag.", "tokens": ["\u201e", "nun", "hast", "du", "dei\u00b7nen", "letz\u00b7ten", "Tag", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die Hunde sollen dich zerbei\u00dfen,", "tokens": ["Die", "Hun\u00b7de", "sol\u00b7len", "dich", "zer\u00b7bei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und wilde Geier dich zerrei\u00dfen.\u201c", "tokens": ["Und", "wil\u00b7de", "Gei\u00b7er", "dich", "zer\u00b7rei\u00b7\u00dfen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und keine Kunst! Pallas Athene", "tokens": ["Und", "kei\u00b7ne", "Kunst", "!", "Pal\u00b7las", "A\u00b7the\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIAT", "NN", "$.", "NE", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Stand Seit\u2019 ihm in der Schlachtenscene,", "tokens": ["Stand", "Seit'", "ihm", "in", "der", "Schlach\u00b7ten\u00b7sce\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und reicht\u2019, verh\u00fcllt, ihm wieder her", "tokens": ["Und", "reicht'", ",", "ver\u00b7h\u00fcllt", ",", "ihm", "wie\u00b7der", "her"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "VVPP", "$,", "PPER", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Das schon verschleuderte Gewehr.", "tokens": ["Das", "schon", "ver\u00b7schleu\u00b7der\u00b7te", "Ge\u00b7wehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und Hektor starb.", "tokens": ["Und", "Hek\u00b7tor", "starb", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Bin ich von dieser Welt geschieden?", "tokens": ["Bin", "ich", "von", "die\u00b7ser", "Welt", "ge\u00b7schie\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort auf dem Flusse den Peliden", "tokens": ["Dort", "auf", "dem", "Flus\u00b7se", "den", "Pe\u00b7li\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Seh\u2019, drohend mir, zur Schlacht bereit,", "tokens": ["Seh'", ",", "dro\u00b7hend", "mir", ",", "zur", "Schlacht", "be\u00b7reit", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "$,", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich stehn in hoher Herrlichkeit.", "tokens": ["Ich", "stehn", "in", "ho\u00b7her", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bin ich denn bei den Spiritisten,", "tokens": ["Bin", "ich", "denn", "bei", "den", "Spi\u00b7ri\u00b7tis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die \u00fcberall sich einzunisten", "tokens": ["Die", "\u00fc\u00b7be\u00b7rall", "sich", "ein\u00b7zu\u00b7nis\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Gesonnen sind. Ich denke: nein \u2014", "tokens": ["Ge\u00b7son\u00b7nen", "sind", ".", "Ich", "den\u00b7ke", ":", "nein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "$.", "PPER", "VVFIN", "$.", "PTKANT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein neues Bild: Held Don Quixote.", "tokens": ["Ein", "neu\u00b7es", "Bild", ":", "Held", "Don", "Qui\u00b7xo\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "NN", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Hadrianus, Ebers, Nero, Heine,", "tokens": ["Had\u00b7ri\u00b7a\u00b7nus", ",", "E\u00b7bers", ",", "Ne\u00b7ro", ",", "Hei\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ADV", "$,", "NE", "$,", "NE", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Bald wechseln Lebende, bald Tote,", "tokens": ["Bald", "wech\u00b7seln", "Le\u00b7ben\u00b7de", ",", "bald", "To\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.11": {"text": "Bald gro\u00dfe M\u00e4nner, bald auch kleine.", "tokens": ["Bald", "gro\u00b7\u00dfe", "M\u00e4n\u00b7ner", ",", "bald", "auch", "klei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Lord Byron kam und schwand alsdann.", "tokens": ["Lord", "By\u00b7ron", "kam", "und", "schwand", "als\u00b7dann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "(ich liebe seinen \u201eDon Juan\u201c.)", "tokens": ["(", "ich", "lie\u00b7be", "sei\u00b7nen", "\u201e", "Don", "Juan", "\u201c", ".", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPOSAT", "$(", "NE", "NE", "$(", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.14": {"text": "Und weiter zogen Helden, Dichter,", "tokens": ["Und", "wei\u00b7ter", "zo\u00b7gen", "Hel\u00b7den", ",", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Gesetzesgeber, gro\u00dfe Richter.", "tokens": ["Ge\u00b7set\u00b7zes\u00b7ge\u00b7ber", ",", "gro\u00b7\u00dfe", "Rich\u00b7ter", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Bis endlich noch Fritz K\u00e4pernick", "tokens": ["Bis", "end\u00b7lich", "noch", "Fritz", "K\u00e4\u00b7per\u00b7nick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und Caesar \u201emit dem Greifenblick.\u201c", "tokens": ["Und", "Cae\u00b7sar", "\u201e", "mit", "dem", "Grei\u00b7fen\u00b7blick", ".", "\u201c"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "$(", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dann zum Beschlu\u00df der gro\u00dfe Dante,", "tokens": ["Dann", "zum", "Be\u00b7schlu\u00df", "der", "gro\u00b7\u00dfe", "Dan\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der leider noch sehr unbekannte.", "tokens": ["Der", "lei\u00b7der", "noch", "sehr", "un\u00b7be\u00b7kann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(soll ich mich ganz dem Dichter geben,", "tokens": ["(", "soll", "ich", "mich", "ganz", "dem", "Dich\u00b7ter", "ge\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PRF", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Will ich kein Kommentar daneben.)", "tokens": ["Will", "ich", "kein", "Kom\u00b7men\u00b7tar", "da\u00b7ne\u00b7ben", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "NN", "PAV", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es f\u00fchrten ihn in ihrer Mitt\u2019", "tokens": ["Es", "f\u00fchr\u00b7ten", "ihn", "in", "ih\u00b7rer", "Mitt'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Herr Meierleben und Herr Schmitt. \u2014", "tokens": ["Herr", "Mei\u00b7er\u00b7le\u00b7ben", "und", "Herr", "Schmitt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "KON", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und eine Leere trat nun ein,", "tokens": ["Und", "ei\u00b7ne", "Lee\u00b7re", "trat", "nun", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Vom Flusse schwand der Phosphorschein.", "tokens": ["Vom", "Flus\u00b7se", "schwand", "der", "Phos\u00b7phor\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es rauschte Welle nur auf Welle", "tokens": ["Es", "rauschte", "Wel\u00b7le", "nur", "auf", "Wel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Gem\u00fctlich durch die Mondeshelle.", "tokens": ["Ge\u00b7m\u00fct\u00b7lich", "durch", "die", "Mon\u00b7des\u00b7hel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Da sieh! Beim heiligen Krucifixe!", "tokens": ["Da", "sieh", "!", "Beim", "hei\u00b7li\u00b7gen", "Kru\u00b7ci\u00b7fi\u00b7xe", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$.", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Es taucht hervor die Wassernixe.", "tokens": ["Es", "taucht", "her\u00b7vor", "die", "Was\u00b7ser\u00b7ni\u00b7xe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "War das ein wundervolles Weib,", "tokens": ["War", "das", "ein", "wun\u00b7der\u00b7vol\u00b7les", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War das ein wundervoller Leib.", "tokens": ["War", "das", "ein", "wun\u00b7der\u00b7vol\u00b7ler", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als sie dem Schilf entstieg und Rohr,", "tokens": ["Als", "sie", "dem", "Schilf", "ent\u00b7stieg", "und", "Rohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da brach erschreckt ein Kranich vor,", "tokens": ["Da", "brach", "er\u00b7schreckt", "ein", "Kra\u00b7nich", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und spannte schwer die breiten Fl\u00fcgel,", "tokens": ["Und", "spann\u00b7te", "schwer", "die", "brei\u00b7ten", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und hob sich \u00fcber Holz und H\u00fcgel.", "tokens": ["Und", "hob", "sich", "\u00fc\u00b7ber", "Holz", "und", "H\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch als ich n\u00e4her ging und sah,", "tokens": ["Doch", "als", "ich", "n\u00e4\u00b7her", "ging", "und", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und endlich ganz der Nixe nah,", "tokens": ["Und", "end\u00b7lich", "ganz", "der", "Ni\u00b7xe", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wen mu\u00dft\u2019 ich sehen! Gott der Gnade!", "tokens": ["Wen", "mu\u00dft'", "ich", "se\u00b7hen", "!", "Gott", "der", "Gna\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wen fand ich hier am Schilfgestade \u2014", "tokens": ["Wen", "fand", "ich", "hier", "am", "Schilf\u00b7ge\u00b7sta\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die einst ich liebte warm und wahr.", "tokens": ["Die", "einst", "ich", "lieb\u00b7te", "warm", "und", "wahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Doch damals hing das blonde Haar", "tokens": ["Doch", "da\u00b7mals", "hing", "das", "blon\u00b7de", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So lang noch nicht, wie nun es war.", "tokens": ["So", "lang", "noch", "nicht", ",", "wie", "nun", "es", "war", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Es flie\u00dft ihr \u00fcber Hals und Nacken,", "tokens": ["Es", "flie\u00dft", "ihr", "\u00fc\u00b7ber", "Hals", "und", "Na\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Bis leicht es lose Wellen packen.", "tokens": ["Bis", "leicht", "es", "lo\u00b7se", "Wel\u00b7len", "pa\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Die Kleidung schlo\u00df sich mehr decent", "tokens": ["Die", "Klei\u00b7dung", "schlo\u00df", "sich", "mehr", "de\u00b7cent"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Als hier im feuchten Element,", "tokens": ["Als", "hier", "im", "feuch\u00b7ten", "E\u00b7le\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Wenn ihre Arme auch und H\u00e4nde", "tokens": ["Wenn", "ih\u00b7re", "Ar\u00b7me", "auch", "und", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Sich kreuzen vor der Brust als W\u00e4nde.", "tokens": ["Sich", "kreu\u00b7zen", "vor", "der", "Brust", "als", "W\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "APPR", "ART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "\u201eo sprich, o sprich ein einzig Wort,", "tokens": ["\u201e", "o", "sprich", ",", "o", "sprich", "ein", "ein\u00b7zig", "Wort", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "ADJD", "$,", "FM", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wie kamst du her an diesen Ort?\u201c", "tokens": ["Wie", "kamst", "du", "her", "an", "die\u00b7sen", "Ort", "?", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Doch blieb sie stumm und sah mich an,", "tokens": ["Doch", "blieb", "sie", "stumm", "und", "sah", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Da\u00df mir die Thr\u00e4ne niederrann.", "tokens": ["Da\u00df", "mir", "die", "Thr\u00e4\u00b7ne", "nie\u00b7der\u00b7rann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Und wurde blasser, immer blasser,", "tokens": ["Und", "wur\u00b7de", "blas\u00b7ser", ",", "im\u00b7mer", "blas\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Und sank allm\u00e4hlig in die Wasser. \u2014", "tokens": ["Und", "sank", "all\u00b7m\u00e4h\u00b7lig", "in", "die", "Was\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Ich wandte mich und ging feldein,", "tokens": ["Ich", "wand\u00b7te", "mich", "und", "ging", "feld\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Doch eh ich hundert Schritte kaum", "tokens": ["Doch", "eh", "ich", "hun\u00b7dert", "Schrit\u00b7te", "kaum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "CARD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Gegangen war in schwerem Traum,", "tokens": ["Ge\u00b7gan\u00b7gen", "war", "in", "schwe\u00b7rem", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Kehrt\u2019 ich mich um im Mondenschein.", "tokens": ["Kehrt'", "ich", "mich", "um", "im", "Mon\u00b7den\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Da stand sie wieder, doch bewegt,", "tokens": ["Da", "stand", "sie", "wie\u00b7der", ",", "doch", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "In ihren Mienen aufgeregt.", "tokens": ["In", "ih\u00b7ren", "Mie\u00b7nen", "auf\u00b7ge\u00b7regt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Ein Schrei drang gellend her von ihr,", "tokens": ["Ein", "Schrei", "drang", "gel\u00b7lend", "her", "von", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Wie Ruf und Schrei von einem Tier.", "tokens": ["Wie", "Ruf", "und", "Schrei", "von", "ei\u00b7nem", "Tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "In B\u00f6hmen einst, in Junitagen,", "tokens": ["In", "B\u00f6h\u00b7men", "einst", ",", "in", "Ju\u00b7ni\u00b7ta\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In hei\u00dfer Schlacht, in hei\u00dfer Schlacht,", "tokens": ["In", "hei\u00b7\u00dfer", "Schlacht", ",", "in", "hei\u00b7\u00dfer", "Schlacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00f6rt\u2019 ich ein Pferd im Tode klagen,", "tokens": ["H\u00f6rt'", "ich", "ein", "Pferd", "im", "To\u00b7de", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das klang durch all\u2019 die hei\u00dfe Schlacht.", "tokens": ["Das", "klang", "durch", "all'", "die", "hei\u00b7\u00dfe", "Schlacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir k\u00e4mpften um ein Dorf mit Wut", "tokens": ["Wir", "k\u00e4mpf\u00b7ten", "um", "ein", "Dorf", "mit", "Wut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In dickem Staub und Sonnenglut.", "tokens": ["In", "di\u00b7ckem", "Staub", "und", "Son\u00b7nen\u00b7glut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mann gegen Mann, in Haus und Garten,", "tokens": ["Mann", "ge\u00b7gen", "Mann", ",", "in", "Haus", "und", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Um Knick und Mauer, Dach und Scharten.", "tokens": ["Um", "Knick", "und", "Mau\u00b7er", ",", "Dach", "und", "Schar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Da, mitten drin im Pulverdampf,", "tokens": ["Da", ",", "mit\u00b7ten", "drin", "im", "Pul\u00b7ver\u00b7dampf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Kommandoruf und Ro\u00dfgestampf,", "tokens": ["Kom\u00b7man\u00b7do\u00b7ruf", "und", "Ro\u00df\u00b7ge\u00b7stampf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.11": {"text": "Durch Trommelwirbel, H\u00f6rnerschall,", "tokens": ["Durch", "Trom\u00b7mel\u00b7wir\u00b7bel", ",", "H\u00f6r\u00b7ner\u00b7schall", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Durch Mordgeheul und Donnerknall,", "tokens": ["Durch", "Mord\u00b7ge\u00b7heul", "und", "Don\u00b7ner\u00b7knall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "H\u00f6rt\u2019 ich aus einem Stall, der brannte,", "tokens": ["H\u00f6rt'", "ich", "aus", "ei\u00b7nem", "Stall", ",", "der", "brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Ein Schreien, das mich \u00fcbermannte.", "tokens": ["Ein", "Schrei\u00b7en", ",", "das", "mich", "\u00fc\u00b7berm\u00b7ann\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "\u201ehierher, rief ich mit heiserer Stimme,", "tokens": ["\u201e", "hier\u00b7her", ",", "rief", "ich", "mit", "hei\u00b7se\u00b7rer", "Stim\u00b7me", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.16": {"text": "Hierher zu mir im letzten Lauf,", "tokens": ["Hier\u00b7her", "zu", "mir", "im", "letz\u00b7ten", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Hierher! und schlagt die Th\u00fcren auf!\u201c", "tokens": ["Hier\u00b7her", "!", "und", "schlagt", "die", "Th\u00fc\u00b7ren", "auf", "!", "\u201c"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Sie kamen schnell in Sturm und Grimme,", "tokens": ["Sie", "ka\u00b7men", "schnell", "in", "Sturm", "und", "Grim\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Und als wir in die Scheune drangen,", "tokens": ["Und", "als", "wir", "in", "die", "Scheu\u00b7ne", "dran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Sah bald an einer Kett\u2019 ich hangen", "tokens": ["Sah", "bald", "an", "ei\u00b7ner", "Kett'", "ich", "han\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Ein halbverkohltes Pferd, das schrie,", "tokens": ["Ein", "halb\u00b7ver\u00b7kohl\u00b7tes", "Pferd", ",", "das", "schrie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und ich vergess\u2019 es im Leben nie. \u2014", "tokens": ["Und", "ich", "ver\u00b7ge\u00b7ss'", "es", "im", "Le\u00b7ben", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPRART", "NN", "ADV", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "Habt einen Menschen ihr geh\u00f6rt,", "tokens": ["Habt", "ei\u00b7nen", "Men\u00b7schen", "ihr", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Hat euer Blut sich nicht emp\u00f6rt,", "tokens": ["Hat", "eu\u00b7er", "Blut", "sich", "nicht", "em\u00b7p\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PRF", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Wenn ihm, vor allzugro\u00dfem Schmerz", "tokens": ["Wenn", "ihm", ",", "vor", "all\u00b7zu\u00b7gro\u00b7\u00dfem", "Schmerz"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Nicht brechen Auge kann und Herz?", "tokens": ["Nicht", "bre\u00b7chen", "Au\u00b7ge", "kann", "und", "Herz", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VMFIN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "In Frankreich war es. Blutbespritzt,", "tokens": ["In", "Fran\u00b7kreich", "war", "es", ".", "Blut\u00b7be\u00b7spritzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "$.", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Schwei\u00df\u00fcbergossen, \u00fcberhitzt,", "tokens": ["Schwei\u00df\u00b7\u00fc\u00b7ber\u00b7gos\u00b7sen", ",", "\u00fc\u00b7berh\u00b7itzt", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Just um des Schlachtentages Mitte.", "tokens": ["Just", "um", "des", "Schlach\u00b7ten\u00b7ta\u00b7ges", "Mit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.30": {"text": "Von meinen Pferden schon das dritte,", "tokens": ["Von", "mei\u00b7nen", "Pfer\u00b7den", "schon", "das", "drit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Das ich bestiegen im Gefechte.", "tokens": ["Das", "ich", "be\u00b7stie\u00b7gen", "im", "Ge\u00b7fech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Den hungrigen Degen hielt die Rechte,", "tokens": ["Den", "hung\u00b7ri\u00b7gen", "De\u00b7gen", "hielt", "die", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Und meine herrliche Kompagnie,", "tokens": ["Und", "mei\u00b7ne", "herr\u00b7li\u00b7che", "Kom\u00b7pag\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.34": {"text": "Zu sattem Siege f\u00fchr\u2019 ich sie.", "tokens": ["Zu", "sat\u00b7tem", "Sie\u00b7ge", "f\u00fchr'", "ich", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Da, als wir \u00fcber Leichen stolpern,", "tokens": ["Da", ",", "als", "wir", "\u00fc\u00b7ber", "Lei\u00b7chen", "stol\u00b7pern", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Durch Stein und Buschwerk weiter holpern,", "tokens": ["Durch", "Stein", "und", "Busc\u00b7hwerk", "wei\u00b7ter", "hol\u00b7pern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Und nur die freie Bahn ersehnen,", "tokens": ["Und", "nur", "die", "frei\u00b7e", "Bahn", "er\u00b7seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Den Feind zu packen mit den Z\u00e4hnen,", "tokens": ["Den", "Feind", "zu", "pa\u00b7cken", "mit", "den", "Z\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Erschrak ein Schrei mich in der N\u00e4he,", "tokens": ["Er\u00b7schrak", "ein", "Schrei", "mich", "in", "der", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Der klang so gr\u00e4\u00dflich, klang so j\u00e4he,", "tokens": ["Der", "klang", "so", "gr\u00e4\u00df\u00b7lich", ",", "klang", "so", "j\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "$,", "VVFIN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Da\u00df ich entsetzt vom Pferde sprang,", "tokens": ["Da\u00df", "ich", "ent\u00b7setzt", "vom", "Pfer\u00b7de", "sprang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Und keuchend an die Stelle drang,", "tokens": ["Und", "keu\u00b7chend", "an", "die", "Stel\u00b7le", "drang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Woher er kam.", "tokens": ["Wo\u00b7her", "er", "kam", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Da lag mein Freund, zerrissen, blo\u00df,", "tokens": ["Da", "lag", "mein", "Freund", ",", "zer\u00b7ris\u00b7sen", ",", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "VVPP", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Sonnenfeuer, das ihn sott,", "tokens": ["Im", "Son\u00b7nen\u00b7feu\u00b7er", ",", "das", "ihn", "sott", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch mit Besinnung, rettungslos.", "tokens": ["Noch", "mit", "Be\u00b7sin\u00b7nung", ",", "ret\u00b7tungs\u00b7los", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Das Eingeweide hing heraus,", "tokens": ["Das", "Ein\u00b7ge\u00b7wei\u00b7de", "hing", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er starrt mich an im Sterbegraus,", "tokens": ["Er", "starrt", "mich", "an", "im", "Ster\u00b7be\u00b7graus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ich verstand den stummen Blick:", "tokens": ["Und", "ich", "ver\u00b7stand", "den", "stum\u00b7men", "Blick", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u201ethu\u2019 deine letzte Freundespflicht.\u201c", "tokens": ["\u201e", "thu'", "dei\u00b7ne", "letz\u00b7te", "Freun\u00b7des\u00b7pflicht", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und lange war mein Z\u00f6gern nicht,", "tokens": ["Und", "lan\u00b7ge", "war", "mein", "Z\u00f6\u00b7gern", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Schon spannt\u2019 ich den Revolverhahn,", "tokens": ["Schon", "spannt'", "ich", "den", "Re\u00b7vol\u00b7ver\u00b7hahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Da lehnt er sich im letzten Wahn", "tokens": ["Da", "lehnt", "er", "sich", "im", "letz\u00b7ten", "Wahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "An meine Brust. Und Gott sei Dank!", "tokens": ["An", "mei\u00b7ne", "Brust", ".", "Und", "Gott", "sei", "Dank", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "KON", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Von seinem Schiff ins Todesmeer", "tokens": ["Von", "sei\u00b7nem", "Schiff", "ins", "To\u00b7des\u00b7meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Des Mastes Wimpel untersank.", "tokens": ["Des", "Mas\u00b7tes", "Wim\u00b7pel", "un\u00b7ter\u00b7sank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Noch stammelt er: \u201eSiegt unser Heer? \u2014", "tokens": ["Noch", "stam\u00b7melt", "er", ":", "\u201e", "Siegt", "un\u00b7ser", "Heer", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.15": {"text": "Schnellfeuer \u2014 dort \u2014 der K\u00f6nig \u2014 Sein", "tokens": ["Schnell\u00b7feu\u00b7er", "dort", "der", "K\u00f6\u00b7nig", "Sein"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$(", "ADV", "$(", "ART", "NN", "$(", "PPOSAT"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.16": {"text": "Im Tod \u2026\u201c \u2026 und ruhig schlief er ein.", "tokens": ["Im", "Tod", "\u2026", "\u201c", "\u2026", "und", "ru\u00b7hig", "schlief", "er", "ein", "."], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "$(", "$(", "KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Ich k\u00fc\u00dfte seinen bleichen Mund,", "tokens": ["Ich", "k\u00fc\u00df\u00b7te", "sei\u00b7nen", "blei\u00b7chen", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Und st\u00fcrzte wieder in die Schlacht,", "tokens": ["Und", "st\u00fcrz\u00b7te", "wie\u00b7der", "in", "die", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "In den quirlenden, qualmenden H\u00f6llenschlund,", "tokens": ["In", "den", "quir\u00b7len\u00b7den", ",", "qual\u00b7men\u00b7den", "H\u00f6l\u00b7len\u00b7schlund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.20": {"text": "Bis uns der Tag den Sieg gebracht. \u2014", "tokens": ["Bis", "uns", "der", "Tag", "den", "Sieg", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch grauenvoller war der Schrei,", "tokens": ["Doch", "grau\u00b7en\u00b7vol\u00b7ler", "war", "der", "Schrei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den eben schrie die Wasserfei:", "tokens": ["Den", "e\u00b7ben", "schrie", "die", "Was\u00b7ser\u00b7fei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eo wehe, weh, die Stund\u2019 ist da.\u201c", "tokens": ["\u201e", "o", "we\u00b7he", ",", "weh", ",", "die", "Stund'", "ist", "da", ".", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "ADJD", "$,", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gleich nachdem der Ruf geschah,", "tokens": ["Und", "gleich", "nach\u00b7dem", "der", "Ruf", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "H\u00f6rt\u2019 ich es hinterm H\u00fcgel nah,", "tokens": ["H\u00f6rt'", "ich", "es", "hin\u00b7term", "H\u00fc\u00b7gel", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und trab, trab kommt es n\u00e4her schon,", "tokens": ["Und", "trab", ",", "trab", "kommt", "es", "n\u00e4\u00b7her", "schon", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und n\u00e4her, n\u00e4her schwillt der Ton,", "tokens": ["Und", "n\u00e4\u00b7her", ",", "n\u00e4\u00b7her", "schwillt", "der", "Ton", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da, auf des H\u00fcgels breiter Kuppe,", "tokens": ["Da", ",", "auf", "des", "H\u00fc\u00b7gels", "brei\u00b7ter", "Kup\u00b7pe", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Links blieb die kleine Tannengruppe,", "tokens": ["Links", "blieb", "die", "klei\u00b7ne", "Tan\u00b7nen\u00b7grup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Ein Mensch, am Himmel ausgeschnitten,", "tokens": ["Ein", "Mensch", ",", "am", "Him\u00b7mel", "aus\u00b7ge\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Ein Pulsschlag war es, dann herab,", "tokens": ["Ein", "Puls\u00b7schlag", "war", "es", ",", "dann", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "So l\u00e4uft er auf sein nasses Grab.", "tokens": ["So", "l\u00e4uft", "er", "auf", "sein", "nas\u00b7ses", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Halt! Halt! und bald steh\u2019 ich in Mitten", "tokens": ["Halt", "!", "Halt", "!", "und", "bald", "steh'", "ich", "in", "Mit\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "$.", "NN", "$.", "KON", "ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Von Wasserweib und Menschenkind,", "tokens": ["Von", "Was\u00b7ser\u00b7weib", "und", "Men\u00b7schen\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und fing den St\u00fcrmer auf geschwind.", "tokens": ["Und", "fing", "den", "St\u00fcr\u00b7mer", "auf", "ge\u00b7schwind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Der wehrte sich und wollte fort,", "tokens": ["Der", "wehr\u00b7te", "sich", "und", "woll\u00b7te", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "KON", "VMFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Er m\u00fcsse zu der Nixe dort.", "tokens": ["Er", "m\u00fcs\u00b7se", "zu", "der", "Ni\u00b7xe", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Ich hielt ihn wie mit Eisenklammern,", "tokens": ["Ich", "hielt", "ihn", "wie", "mit", "Ei\u00b7sen\u00b7klam\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Es half ihm Klagen nicht und Jammern.", "tokens": ["Es", "half", "ihm", "Kla\u00b7gen", "nicht", "und", "Jam\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "PTKNEG", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Da, gr\u00e4\u00dflich, schreit es noch einmal,", "tokens": ["Da", ",", "gr\u00e4\u00df\u00b7lich", ",", "schreit", "es", "noch", "ein\u00b7mal", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "$,", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Im Echo ruft das ganze Thal,", "tokens": ["Im", "E\u00b7cho", "ruft", "das", "gan\u00b7ze", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und wunderbar, wie vordem schon,", "tokens": ["Und", "wun\u00b7der\u00b7bar", ",", "wie", "vor\u00b7dem", "schon", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "T\u00f6nt trab, trab, trab der alte Ton,", "tokens": ["T\u00f6nt", "trab", ",", "trab", ",", "trab", "der", "al\u00b7te", "Ton", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Erst hinterm H\u00fcgel, dann hoch oben,", "tokens": ["Erst", "hin\u00b7term", "H\u00fc\u00b7gel", ",", "dann", "hoch", "o\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Die Augen stier, die H\u00e4nd\u2019 erhoben.", "tokens": ["Die", "Au\u00b7gen", "stier", ",", "die", "H\u00e4nd'", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "So st\u00fcrzt der L\u00e4ufer niederw\u00e4rts,", "tokens": ["So", "st\u00fcrzt", "der", "L\u00e4u\u00b7fer", "nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Dem sch\u00f6nen Nixenweib ans Herz.", "tokens": ["Dem", "sch\u00f6\u00b7nen", "Ni\u00b7xen\u00b7weib", "ans", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Ich sah, eh\u2019 ich den Sinn verlor,", "tokens": ["Ich", "sah", ",", "eh'", "ich", "den", "Sinn", "ver\u00b7lor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Die Nixe dr\u00e4ngt ans Ufer vor", "tokens": ["Die", "Ni\u00b7xe", "dr\u00e4ngt", "ans", "U\u00b7fer", "vor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Und spannte weit den sch\u00f6nen Arm \u2014", "tokens": ["Und", "spann\u00b7te", "weit", "den", "sch\u00f6\u00b7nen", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Da scho\u00df auf mich ein Sternenschwarm.", "tokens": ["Da", "scho\u00df", "auf", "mich", "ein", "Ster\u00b7nen\u00b7schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Am andern Tag in fr\u00fcher Stund\u2019", "tokens": ["Am", "an\u00b7dern", "Tag", "in", "fr\u00fc\u00b7her", "Stund'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erwacht\u2019 ich auf dem Wiesengrund.", "tokens": ["Er\u00b7wacht'", "ich", "auf", "dem", "Wie\u00b7sen\u00b7grund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die beiden K\u00fche rupften wieder \u2014", "tokens": ["Die", "bei\u00b7den", "K\u00fc\u00b7he", "rupf\u00b7ten", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch dort, sie suchen was im Flu\u00df,", "tokens": ["Doch", "dort", ",", "sie", "su\u00b7chen", "was", "im", "Flu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PPER", "VVINF", "PRELS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und tauchen ihre Stangen nieder \u2014", "tokens": ["Und", "tau\u00b7chen", "ih\u00b7re", "Stan\u00b7gen", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "War das des Traumes herber Schlu\u00df?", "tokens": ["War", "das", "des", "Trau\u00b7mes", "her\u00b7ber", "Schlu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und sieh! Wen tragen dort die H\u00e4nde,", "tokens": ["Und", "sieh", "!", "Wen", "tra\u00b7gen", "dort", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$.", "PWS", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie trugen einen, der versank", "tokens": ["Sie", "tru\u00b7gen", "ei\u00b7nen", ",", "der", "ver\u00b7sank"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und diese Nacht im Flu\u00df ertrank.", "tokens": ["Und", "die\u00b7se", "Nacht", "im", "Flu\u00df", "er\u00b7trank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das war des schweren Traumes Ende.", "tokens": ["Das", "war", "des", "schwe\u00b7ren", "Trau\u00b7mes", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}