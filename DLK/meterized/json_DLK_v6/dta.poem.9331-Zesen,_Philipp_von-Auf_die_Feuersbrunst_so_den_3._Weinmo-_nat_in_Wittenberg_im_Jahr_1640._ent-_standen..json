{"dta.poem.9331": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "Auf die Feuersbrunst/ so den 3. Weinmo-  \n nat in Wittenberg im Jahr 1640. ent-  \n standen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.85", "pl:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wje warstu so best\u00fcrtzt? wie war dier doch zu muthe/", "tokens": ["Wie", "wars\u00b7tu", "so", "be\u00b7st\u00fcrtzt", "?", "wie", "war", "dier", "doch", "zu", "mu\u00b7the", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "VVPP", "$.", "PWAV", "VAFIN", "PPER", "ADV", "APPR", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "du edles Wittenberg/ was sah ich doch in Dier?", "tokens": ["du", "ed\u00b7les", "Wit\u00b7ten\u00b7berg", "/", "was", "sah", "ich", "doch", "in", "Dier", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "PWS", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach weh! ach immer weh! Gott zeigt dir eine ruthe/", "tokens": ["Ach", "weh", "!", "ach", "im\u00b7mer", "weh", "!", "Gott", "zeigt", "dir", "ei\u00b7ne", "ru\u00b7the", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "$.", "ADV", "ADV", "PTKVZ", "$.", "NN", "VVFIN", "PPER", "ART", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "f\u00e4ht an zu strafen dicht; Ein Feuer bricht herf\u00fcr", "tokens": ["f\u00e4ht", "an", "zu", "stra\u00b7fen", "dicht", ";", "Ein", "Feu\u00b7er", "bricht", "her\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "PTKZU", "VVFIN", "ADJD", "$.", "ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "und nimmet \u00fcberhand! Wie hastu das verdienet/", "tokens": ["und", "nim\u00b7met", "\u00fc\u00b7ber\u00b7hand", "!", "Wie", "has\u00b7tu", "das", "ver\u00b7die\u00b7net", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$.", "PWAV", "VAFIN", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "du heiliger Altar? Da\u00df eine solche gluth", "tokens": ["du", "hei\u00b7li\u00b7ger", "Al\u00b7tar", "?", "Da\u00df", "ei\u00b7ne", "sol\u00b7che", "gluth"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$.", "KOUS", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "dich also gar \u00fcmbgab? und sich (ach leid!) erk\u00fchnet", "tokens": ["dich", "al\u00b7so", "gar", "\u00fcmb\u00b7gab", "?", "und", "sich", "(", "ach", "leid", "!", ")", "er\u00b7k\u00fch\u00b7net"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "word"], "pos": ["PPER", "ADV", "ADV", "VVFIN", "$.", "KON", "PRF", "$(", "ADV", "ADJD", "$.", "$(", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "zu steigen auf das Hau\u00df darinnen uns zu guth", "tokens": ["zu", "stei\u00b7gen", "auf", "das", "Hau\u00df", "da\u00b7rin\u00b7nen", "uns", "zu", "guth"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "ADV", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Lutherus angez\u00fcnde die Fackel reiner Lehre/", "tokens": ["Lu\u00b7the\u00b7rus", "an\u00b7ge\u00b7z\u00fcn\u00b7de", "die", "Fa\u00b7ckel", "rei\u00b7ner", "Leh\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "darinnen Babilon zum ersten mahl erlag/", "tokens": ["da\u00b7rin\u00b7nen", "Ba\u00b7bi\u00b7lon", "zum", "ers\u00b7ten", "mahl", "er\u00b7lag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "APPRART", "ADJA", "ADV", "VVFIN", "$("], "meter": "-+-----+-+-+", "measure": "dactylic.init"}, "line.11": {"text": "darin\u0303en selbst der Mann der Deutschen ruhm und ehre", "tokens": ["dari\u00f1en", "selbst", "der", "Mann", "der", "Deut\u00b7schen", "ruhm", "und", "eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "ART", "NN", "ART", "ADJA", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Lutherus steht und ruht: ach welch ein tr\u00fcber tag!", "tokens": ["Lu\u00b7the\u00b7rus", "steht", "und", "ruht", ":", "ach", "welch", "ein", "tr\u00fc\u00b7ber", "tag", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "$.", "XY", "PWAT", "ART", "ADJA", "NN", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.13": {"text": "Welch eine b\u00f6se post wer Euch vor augen kommen/", "tokens": ["Welch", "ei\u00b7ne", "b\u00f6\u00b7se", "post", "wer", "Euch", "vor", "au\u00b7gen", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "ADJA", "NN", "PWS", "PPER", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Jhr Anverwanten Jhr! wo Gott es nicht gewehrt/", "tokens": ["Ihr", "An\u00b7ver\u00b7wan\u00b7ten", "Ihr", "!", "wo", "Gott", "es", "nicht", "ge\u00b7wehrt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "$.", "PWAV", "NN", "PPER", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "es hatte ja die gluth so \u00fcberhand genommen/", "tokens": ["es", "hat\u00b7te", "ja", "die", "gluth", "so", "\u00fc\u00b7ber\u00b7hand", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "da\u00df menschen h\u00fclff und rath so gar von uns gekehrt", "tokens": ["da\u00df", "men\u00b7schen", "h\u00fclff", "und", "rath", "so", "gar", "von", "uns", "ge\u00b7kehrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "KON", "NN", "ADV", "ADV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "und nichts mehr fruchten wolt: die bach war abgela\u00dfen/", "tokens": ["und", "nichts", "mehr", "fruch\u00b7ten", "wolt", ":", "die", "bach", "war", "ab\u00b7ge\u00b7la\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "VVINF", "VMFIN", "$.", "ART", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "am wasser es gebrach/ mann konte leschen nicht/", "tokens": ["am", "was\u00b7ser", "es", "ge\u00b7brach", "/", "mann", "kon\u00b7te", "le\u00b7schen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PPER", "VVFIN", "$(", "NN", "VMFIN", "VVINF", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "die b\u00fcrger in der Stadt in furcht und schrecken sa\u00dfen/", "tokens": ["die", "b\u00fcr\u00b7ger", "in", "der", "Stadt", "in", "furcht", "und", "schre\u00b7cken", "sa\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "NN", "APPR", "NN", "KON", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "bi\u00df wieder brach herf\u00fcr das rothe morgenlicht.", "tokens": ["bi\u00df", "wie\u00b7der", "brach", "her\u00b7f\u00fcr", "das", "ro\u00b7the", "mor\u00b7gen\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Da schon ein guter theil in asche war verkehret/", "tokens": ["Da", "schon", "ein", "gu\u00b7ter", "theil", "in", "asc\u00b7he", "war", "ver\u00b7keh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "da legte sich die gluth/ das feuer ward gestillt/", "tokens": ["da", "leg\u00b7te", "sich", "die", "gluth", "/", "das", "feu\u00b7er", "ward", "ge\u00b7stillt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$(", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "der Armen angst geschrey und bethen war erh\u00f6ret/", "tokens": ["der", "Ar\u00b7men", "angst", "ge\u00b7schrey", "und", "be\u00b7then", "war", "er\u00b7h\u00f6\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "VVPP", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Gott selbsten stund dabey/ der war der beste schild/", "tokens": ["Gott", "selbs\u00b7ten", "stund", "da\u00b7bey", "/", "der", "war", "der", "bes\u00b7te", "schild", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PAV", "$(", "ART", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "und sprach dem Feuer zu/ hier sey euch stoltzen flammen", "tokens": ["und", "sprach", "dem", "Feu\u00b7er", "zu", "/", "hier", "sey", "euch", "stolt\u00b7zen", "flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKZU", "$(", "ADV", "VAFIN", "PPER", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "der grentzestein gesetzt; nicht weiter solt jhr gehn.", "tokens": ["der", "grent\u00b7zes\u00b7tein", "ge\u00b7setzt", ";", "nicht", "wei\u00b7ter", "solt", "jhr", "gehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "PTKNEG", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Drauf d\u00e4mpfte sich mit macht das Feuer allzusammen", "tokens": ["Drauf", "d\u00e4mpf\u00b7te", "sich", "mit", "macht", "das", "Feu\u00b7er", "all\u00b7zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PRF", "APPR", "VVFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "und brante nicht wie vor mit schrecklichem geth\u00f6n.", "tokens": ["und", "bran\u00b7te", "nicht", "wie", "vor", "mit", "schreck\u00b7li\u00b7chem", "ge\u00b7th\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "KOKOM", "APPR", "APPR", "ADJA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wie aber? war es dann am Himmel angeschrieben?", "tokens": ["Wie", "a\u00b7ber", "?", "war", "es", "dann", "am", "Him\u00b7mel", "an\u00b7ge\u00b7schrie\u00b7ben", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$.", "VAFIN", "PPER", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Stund etwan dazumahl ein feuriger Planet/", "tokens": ["Stund", "et\u00b7wan", "da\u00b7zu\u00b7mahl", "ein", "feu\u00b7ri\u00b7ger", "Pla\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "da\u00df du durch feuersgluth solt werden aufgerieben/", "tokens": ["da\u00df", "du", "durch", "feu\u00b7ers\u00b7gluth", "solt", "wer\u00b7den", "auf\u00b7ge\u00b7rie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VMFIN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "O heiliges gesch\u00f6pf/ wie jtzt die rede geht/", "tokens": ["O", "hei\u00b7li\u00b7ges", "ge\u00b7sch\u00f6pf", "/", "wie", "jtzt", "die", "re\u00b7de", "geht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$(", "KOKOM", "ADV", "ART", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "und must es also seyn? ach nein. Die schweren s\u00fcnden/", "tokens": ["und", "must", "es", "al\u00b7so", "seyn", "?", "ach", "nein", ".", "Die", "schwe\u00b7ren", "s\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "VAINF", "$.", "XY", "PTKANT", "$.", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "die \u00fcberh\u00e4nffte schuld/ damit du deinen Gott", "tokens": ["die", "\u00fc\u00b7ber\u00b7h\u00e4nff\u00b7te", "schuld", "/", "da\u00b7mit", "du", "dei\u00b7nen", "Gott"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "zu z\u00fcrnen angereitzt/ selbst dier die ruthe binden;", "tokens": ["zu", "z\u00fcr\u00b7nen", "an\u00b7ge\u00b7reitzt", "/", "selbst", "dier", "die", "ru\u00b7the", "bin\u00b7den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVPP", "$(", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wie oftermahls hastu verla\u00dfen sein gebott/", "tokens": ["Wie", "of\u00b7ter\u00b7mahls", "has\u00b7tu", "ver\u00b7la\u00b7\u00dfen", "sein", "ge\u00b7bott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "VVPP", "VAINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "wie oftermahls hastu mit schrecklichem verbrechen", "tokens": ["wie", "of\u00b7ter\u00b7mahls", "has\u00b7tu", "mit", "schreck\u00b7li\u00b7chem", "ver\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.38": {"text": "den H\u00f6chsten angeflam\u0303t; Dr\u00fcmb weiset er nun dier/", "tokens": ["den", "H\u00f6chs\u00b7ten", "an\u00b7ge\u00b7flam\u0303t", ";", "Dr\u00fcmb", "wei\u00b7set", "er", "nun", "dier", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "PAV", "VVFIN", "PPER", "ADV", "PDAT", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "da\u00df er auch strafen kan un\u0303 deinen hochmut schw\u00e4chen;", "tokens": ["da\u00df", "er", "auch", "stra\u00b7fen", "kan", "u\u00f1", "dei\u00b7nen", "hoch\u00b7mut", "schw\u00e4\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Wer hette dis gedacht/ Gott wohnet selbsten hier;", "tokens": ["Wer", "het\u00b7te", "dis", "ge\u00b7dacht", "/", "Gott", "woh\u00b7net", "selbs\u00b7ten", "hier", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "VVPP", "$(", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Dis ist die heilge Stadt/ da Gottes quell entsprungen/", "tokens": ["Dis", "ist", "die", "heil\u00b7ge", "Stadt", "/", "da", "Got\u00b7tes", "quell", "ent\u00b7sprun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "KOUS", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "und durch das Deutsche Land mit vollen str\u00f6men", "tokens": ["und", "durch", "das", "Deut\u00b7sche", "Land", "mit", "vol\u00b7len", "str\u00f6\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "dringt/", "tokens": ["dringt", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.44": {"text": "hier ists zum ersten mahl der Christenheit gelungen/", "tokens": ["hier", "ists", "zum", "ers\u00b7ten", "mahl", "der", "Chris\u00b7ten\u00b7heit", "ge\u00b7lun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "ADJA", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "hier ist dieselbe Burg so alle Ketzer zwingt.", "tokens": ["hier", "ist", "die\u00b7sel\u00b7be", "Burg", "so", "al\u00b7le", "Ket\u00b7zer", "zwingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDAT", "NN", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Ja freylich ist es war; da\u00df hier des HErren Tempel/", "tokens": ["Ja", "frey\u00b7lich", "ist", "es", "war", ";", "da\u00df", "hier", "des", "Her\u00b7ren", "Tem\u00b7pel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "VAFIN", "PPER", "VAFIN", "$.", "KOUS", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "doch sol man dencken nicht/ da\u00df wir vo\u0303 straffen frey/", "tokens": ["doch", "sol", "man", "den\u00b7cken", "nicht", "/", "da\u00df", "wir", "v\u00f5", "straf\u00b7fen", "frey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVFIN", "PTKNEG", "$(", "KOUS", "PPER", "NE", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "wann wir verbrochen uns: Ein trauriges Exempel", "tokens": ["wann", "wir", "ver\u00b7bro\u00b7chen", "uns", ":", "Ein", "trau\u00b7ri\u00b7ges", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "PPER", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.49": {"text": "stellt uns der H\u00f6chste f\u00fcr; wie er so zornig sey/", "tokens": ["stellt", "uns", "der", "H\u00f6chs\u00b7te", "f\u00fcr", ";", "wie", "er", "so", "zor\u00b7nig", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "$.", "PWAV", "PPER", "ADV", "ADJD", "VAFIN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.50": {"text": "doch ist es nicht fein ernst/ er will uns so nur leiten", "tokens": ["doch", "ist", "es", "nicht", "fein", "ernst", "/", "er", "will", "uns", "so", "nur", "lei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADJD", "ADJD", "$(", "PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "zur rechten Gottesfurcht/ zur wahren fr\u00f6mmigkeit/", "tokens": ["zur", "rech\u00b7ten", "Got\u00b7tes\u00b7furcht", "/", "zur", "wah\u00b7ren", "fr\u00f6m\u00b7mig\u00b7keit", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$(", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "und da\u00df wir unsre schuld erkennten ja bey zeiten/", "tokens": ["und", "da\u00df", "wir", "uns\u00b7re", "schuld", "er\u00b7kenn\u00b7ten", "ja", "bey", "zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "ADJD", "VVFIN", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "und nicht so lebten fort in solcher sicherheit:", "tokens": ["und", "nicht", "so", "leb\u00b7ten", "fort", "in", "sol\u00b7cher", "si\u00b7cher\u00b7heit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVFIN", "PTKVZ", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Dis war des H\u00f6chsten Sinn. Dr\u00fcmb wir Jhn Va-", "tokens": ["Dis", "war", "des", "H\u00f6chs\u00b7ten", "Sinn", ".", "Dr\u00fcmb", "wir", "Jhn", "Va"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "PAV", "PPER", "PPER", "TRUNC"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.55": {"text": "ter nennen/", "tokens": ["ter", "nen\u00b7nen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$("], "meter": "---", "measure": "unknown.measure.zero"}, "line.56": {"text": "und billich danckbar seyn/ da\u00df er nicht also gar/", "tokens": ["und", "bil\u00b7lich", "dan\u00b7ck\u00b7bar", "seyn", "/", "da\u00df", "er", "nicht", "al\u00b7so", "gar", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VAINF", "$(", "KOUS", "PPER", "PTKNEG", "ADV", "ADV", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.57": {"text": "wie wir es wohl verdient/ hatt la\u00dfen ferner brennen/", "tokens": ["wie", "wir", "es", "wohl", "ver\u00b7dient", "/", "hatt", "la\u00b7\u00dfen", "fer\u00b7ner", "bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "VVPP", "$(", "VAFIN", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "den angeflam\u0303ten zorn. Da\u00df er uns noch bewar", "tokens": ["den", "an\u00b7ge\u00b7flam\u0303ten", "zorn", ".", "Da\u00df", "er", "uns", "noch", "be\u00b7war"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "KOUS", "PPER", "PRF", "ADV", "ADJD"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.59": {"text": "vor feuersnoth und krieg/ last uns ein frommes Leben", "tokens": ["vor", "feu\u00b7ers\u00b7noth", "und", "krieg", "/", "last", "uns", "ein", "from\u00b7mes", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "KON", "NN", "$(", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "hinf\u00fcro stellen an/ da\u00df Gott dem HErrn allein", "tokens": ["hin\u00b7f\u00fc\u00b7ro", "stel\u00b7len", "an", "/", "da\u00df", "Gott", "dem", "Herrn", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PTKVZ", "$(", "KOUS", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "stets unser Seel und Leib und alles sey ergeben/", "tokens": ["stets", "un\u00b7ser", "Seel", "und", "Leib", "und", "al\u00b7les", "sey", "er\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "KON", "NN", "KON", "PIS", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "so wird er unser Gott und tre\u00fcer Vater seyn.", "tokens": ["so", "wird", "er", "un\u00b7ser", "Gott", "und", "tre\u00b7\u00fcer", "Va\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "KON", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}