{"textgrid.poem.66794": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Schleiche auf dunklem Flur,", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schleiche auf dunklem Flur,", "tokens": ["Schlei\u00b7che", "auf", "dunk\u00b7lem", "Flur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Schleppe grauen Gram.", "tokens": ["Schlep\u00b7pe", "grau\u00b7en", "Gram", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Bin ja, bin ja nur", "tokens": ["Bin", "ja", ",", "bin", "ja", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "$,", "VAFIN", "ADV", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Eine alte Hur':", "tokens": ["Ei\u00b7ne", "al\u00b7te", "Hur'", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Habt mich f\u00fcr Geld.", "tokens": ["Habt", "mich", "f\u00fcr", "Geld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Kenne auf der Welt", "tokens": ["Ken\u00b7ne", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Keine Scham \u2013", "tokens": ["Kei\u00b7ne", "Scham", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Ein Tier!", "tokens": ["Ein", "Tier", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "War doch auch ein Kind,", "tokens": ["War", "doch", "auch", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Rein wie ihr,", "tokens": ["Rein", "wie", "ihr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Las in dem Angebind,", "tokens": ["Las", "in", "dem", "An\u00b7ge\u00b7bind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Dem Samtbrevier:", "tokens": ["Dem", "Samt\u00b7bre\u00b7vier", ":"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Herrgott, dich loben wir \u2013", "tokens": ["Herr\u00b7gott", ",", "dich", "lo\u00b7ben", "wir", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Bin wie ihr gesprungen", "tokens": ["Bin", "wie", "ihr", "ge\u00b7sprun\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "KOKOM", "PPER", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Zu Spiel und Tanz,", "tokens": ["Zu", "Spiel", "und", "Tanz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Habe so hell gesungen", "tokens": ["Ha\u00b7be", "so", "hell", "ge\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ADJD", "VVPP"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.9": {"text": "Auf sonniger Heide:", "tokens": ["Auf", "son\u00b7ni\u00b7ger", "Hei\u00b7de", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Wir winden dir den Jungfernkranz \u2013", "tokens": ["Wir", "win\u00b7den", "dir", "den", "Jung\u00b7fern\u00b7kranz", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Jungfernkranz! \u2013", "tokens": ["Jung\u00b7fern\u00b7kranz", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "Mit veilchenblauer Seide ...", "tokens": ["Mit", "veil\u00b7chen\u00b7blau\u00b7er", "Sei\u00b7de", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Schleiche auf dunklem Flur,", "tokens": ["Schlei\u00b7che", "auf", "dunk\u00b7lem", "Flur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.14": {"text": "H\u00e4\u00dfliche, alte Hur',", "tokens": ["H\u00e4\u00df\u00b7li\u00b7che", ",", "al\u00b7te", "Hur'", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.15": {"text": "Gehorsamer Diener!", "tokens": ["Ge\u00b7hor\u00b7sa\u00b7mer", "Die\u00b7ner", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.16": {"text": "Gehorsamer Diener! \u2013", "tokens": ["Ge\u00b7hor\u00b7sa\u00b7mer", "Die\u00b7ner", "!", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.17": {"text": "Gott!! \u2013", "tokens": ["Gott", "!!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$.", "$("], "meter": "+", "measure": "single.up"}, "line.18": {"text": "M\u00fctterchen, was sagt der liebe Gott?", "tokens": ["M\u00fct\u00b7ter\u00b7chen", ",", "was", "sagt", "der", "lie\u00b7be", "Gott", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.19": {"text": "\u00bbbeten, beten!\u00ab", "tokens": ["\u00bb", "be\u00b7ten", ",", "be\u00b7ten", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "VVINF", "$,", "VVFIN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Hei\u00dfa, hei\u00dfa, hopsassa!", "tokens": ["Hei\u00b7\u00dfa", ",", "hei\u00b7\u00dfa", ",", "hop\u00b7sas\u00b7sa", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "ITJ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La la la ...", "tokens": ["La", "la", "la", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.es", "FM.es", "FM.es", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Hopsassa!", "tokens": ["Hop\u00b7sas\u00b7sa", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Sch\u00f6ner gr\u00fcner,", "tokens": ["Sch\u00f6\u00b7ner", "gr\u00fc\u00b7ner", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJA", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Sch\u00f6ner gr\u00fcner Jungfernkranz!", "tokens": ["Sch\u00f6\u00b7ner", "gr\u00fc\u00b7ner", "Jung\u00b7fern\u00b7kranz", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u2013 \u2013 Mir wird schlecht. \u2013", "tokens": ["\u2013", "\u2013", "Mir", "wird", "schlecht", ".", "\u2013"], "token_info": ["punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "$(", "PPER", "VAFIN", "ADJD", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Hunger \u2013 Brot! Brot!", "tokens": ["Hun\u00b7ger", "\u2013", "Brot", "!", "Brot", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$.", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Liebste f\u00fcr'n Lumpengeld,", "tokens": ["Liebs\u00b7te", "f\u00fcr'n", "Lum\u00b7pen\u00b7geld", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Ist doch 'ne elende Welt! \u2013", "tokens": ["Ist", "doch", "'ne", "e\u00b7len\u00b7de", "Welt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "O l\u00e4g' ich tot ...!", "tokens": ["O", "l\u00e4g'", "ich", "tot", "...", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADJD", "$(", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}