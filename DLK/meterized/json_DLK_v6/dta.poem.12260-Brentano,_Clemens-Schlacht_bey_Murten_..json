{"dta.poem.12260": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Schlacht bey Murten .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die Zeitung flog von Land zu Land,               ", "tokens": ["Die", "Zei\u00b7tung", "flog", "von", "Land", "zu", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor Murten liegt Burgund!", "tokens": ["Vor", "Mur\u00b7ten", "liegt", "Bur\u00b7gund", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und jeder eilt f\u00fcrs Vaterland,", "tokens": ["Und", "je\u00b7der", "eilt", "f\u00fcrs", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu streiten mit Burgund.", "tokens": ["Zu", "strei\u00b7ten", "mit", "Bur\u00b7gund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "APPR", "NE", "$."], "meter": "-+-++-", "measure": "unknown.measure.tri"}}, "stanza.2": {"line.1": {"text": "Im Feld vor einem gr\u00fcnen Wald,", "tokens": ["Im", "Feld", "vor", "ei\u00b7nem", "gr\u00fc\u00b7nen", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rief Knecht und Reutersmann,", "tokens": ["Rief", "Knecht", "und", "Reu\u00b7ters\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Laut rief von Lothringen Renald:", "tokens": ["Laut", "rief", "von", "Loth\u00b7rin\u00b7gen", "Re\u00b7nald", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "APPR", "NE", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "\u201ewir wollen vorne dran.", "tokens": ["\u201e", "wir", "wol\u00b7len", "vor\u00b7ne", "dran", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u201edie F\u00fchrer hielten kurzen Rath,", "tokens": ["\u201e", "die", "F\u00fch\u00b7rer", "hiel\u00b7ten", "kur\u00b7zen", "Rath", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edoch d\u00fcnkt er uns zu lang;", "tokens": ["\u201e", "doch", "d\u00fcnkt", "er", "uns", "zu", "lang", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PRF", "PTKA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201ewann endigt sich der lange Rath,", "tokens": ["\u201e", "wann", "en\u00b7digt", "sich", "der", "lan\u00b7ge", "Rath", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eist ihnen etwa bang?", "tokens": ["\u201e", "ist", "ih\u00b7nen", "et\u00b7wa", "bang", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u201eschon steht die Sonn am Himmel hoch,", "tokens": ["\u201e", "schon", "steht", "die", "Sonn", "am", "Him\u00b7mel", "hoch", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201enicht tr\u00e4g im blauen Zelt,", "tokens": ["\u201e", "nicht", "tr\u00e4g", "im", "blau\u00b7en", "Zelt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eund wir verziehen immer noch,", "tokens": ["\u201e", "und", "wir", "ver\u00b7zie\u00b7hen", "im\u00b7mer", "noch", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "VVPP", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201ezu hauen in dem Feld!", "tokens": ["\u201e", "zu", "hau\u00b7en", "in", "dem", "Feld", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u201ezwar furchtbar knallte Karls Gesch\u00fctz,", "tokens": ["\u201e", "zwar", "furcht\u00b7bar", "knall\u00b7te", "Karls", "Ge\u00b7sch\u00fctz", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eman gab darum nicht viel;", "tokens": ["\u201e", "man", "gab", "da\u00b7rum", "nicht", "viel", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "PAV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eman achtete nicht in der Hitz,", "tokens": ["\u201e", "man", "ach\u00b7te\u00b7te", "nicht", "in", "der", "Hitz", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "\u201eob der und jener fiel.", "tokens": ["\u201e", "ob", "der", "und", "je\u00b7ner", "fiel", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "KON", "PDS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u201eim weiten Kreise blizt das Schwerdt,", "tokens": ["\u201e", "im", "wei\u00b7ten", "Krei\u00b7se", "blizt", "das", "Schwerdt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eauslangt der lange Spie\u00df;", "tokens": ["\u201e", "aus\u00b7langt", "der", "lan\u00b7ge", "Spie\u00df", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eblut d\u00fcrstete das breite Schwerdt,", "tokens": ["\u201e", "blut", "d\u00fcrs\u00b7te\u00b7te", "das", "brei\u00b7te", "Schwerdt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eblut trank der lange Spie\u00df.", "tokens": ["\u201e", "blut", "trank", "der", "lan\u00b7ge", "Spie\u00df", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u201eder Welsche k\u00e4mpfte kurze Zeit,", "tokens": ["\u201e", "der", "Wel\u00b7sche", "k\u00e4mpf\u00b7te", "kur\u00b7ze", "Zeit", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eder Knecht und Ritter lief;", "tokens": ["\u201e", "der", "Knecht", "und", "Rit\u00b7ter", "lief", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201edas weite Feld ward \u00fcberstreut", "tokens": ["\u201e", "das", "wei\u00b7te", "Feld", "ward", "\u00fc\u00b7bers\u00b7treut"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201emit Speeren Kniees tief.", "tokens": ["\u201e", "mit", "Spee\u00b7ren", "Kni\u00b7ees", "tief", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "\u201eder floh zum Strauch \u2014 der floh zum Hayn", "tokens": ["\u201e", "der", "floh", "zum", "Strauch", "der", "floh", "zum", "Hayn"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "VVFIN", "APPRART", "NN", "$(", "ART", "VVFIN", "APPRART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "\u201evorm hellen Sonnen-Licht,", "tokens": ["\u201e", "vorm", "hel\u00b7len", "Son\u00b7nen\u00b7Licht", ","], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eviel sprangen in die See hinein,", "tokens": ["\u201e", "viel", "spran\u00b7gen", "in", "die", "See", "hin\u00b7ein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund d\u00fcrsteten doch nicht.", "tokens": ["\u201e", "und", "d\u00fcrs\u00b7te\u00b7ten", "doch", "nicht", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VMFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "\u201esie schwammen wie der Enten Schaar", "tokens": ["\u201e", "sie", "schwam\u00b7men", "wie", "der", "En\u00b7ten", "Schaar"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eim Wasser hin und her,", "tokens": ["\u201e", "im", "Was\u00b7ser", "hin", "und", "her", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eals w\u00e4r es wilder Entenschaar", "tokens": ["\u201e", "als", "w\u00e4r", "es", "wil\u00b7der", "En\u00b7ten\u00b7schaar"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KOKOM", "VAFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201escho\u00df man sie im Ger\u00f6hr.", "tokens": ["\u201e", "scho\u00df", "man", "sie", "im", "Ge\u00b7r\u00f6hr", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "PPER", "APPRART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.10": {"line.1": {"text": "\u201eauf Schiffen fuhr man in den See,", "tokens": ["\u201e", "auf", "Schif\u00b7fen", "fuhr", "man", "in", "den", "See", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eschlug sie mit Rudern todt.", "tokens": ["\u201e", "schlug", "sie", "mit", "Ru\u00b7dern", "todt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPR", "NN", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u201edas Waidwort war nur Ach und Weh,", "tokens": ["\u201e", "das", "Waid\u00b7wort", "war", "nur", "Ach", "und", "Weh", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edie gr\u00fcne See ward roth.", "tokens": ["\u201e", "die", "gr\u00fc\u00b7ne", "See", "ward", "roth", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u201eviel klommen auf die B\u00e4ume hoch,", "tokens": ["\u201e", "viel", "klom\u00b7men", "auf", "die", "B\u00e4u\u00b7me", "hoch", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edie scho\u00df man wie die Kr\u00e4hn;", "tokens": ["\u201e", "die", "scho\u00df", "man", "wie", "die", "Kr\u00e4hn", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201edie Fittich fehlten ihnen noch,", "tokens": ["\u201e", "die", "Fit\u00b7tich", "fehl\u00b7ten", "ih\u00b7nen", "noch", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201esie mocht der Wind nicht wehn.", "tokens": ["\u201e", "sie", "mocht", "der", "Wind", "nicht", "wehn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u201ezwo Meilen lang bedeckte sich,", "tokens": ["\u201e", "zwo", "Mei\u00b7len", "lang", "be\u00b7deck\u00b7te", "sich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "CARD", "NN", "ADJD", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edas Land mit Tod und Blut", "tokens": ["\u201e", "das", "Land", "mit", "Tod", "und", "Blut"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201edas Land, der Strauch, die Rose glich", "tokens": ["\u201e", "das", "Land", ",", "der", "Strauch", ",", "die", "Ro\u00b7se", "glich"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edem schwarzen Menschenblut.", "tokens": ["\u201e", "dem", "schwar\u00b7zen", "Men\u00b7schen\u00b7blut", "."], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u201eden Bergen war die Sonne nah,", "tokens": ["\u201e", "den", "Ber\u00b7gen", "war", "die", "Son\u00b7ne", "nah", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edie uns den Sieg gebracht;", "tokens": ["\u201e", "die", "uns", "den", "Sieg", "ge\u00b7bracht", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201edie Welschen, die man leben sah,", "tokens": ["\u201e", "die", "Wel\u00b7schen", ",", "die", "man", "le\u00b7ben", "sah", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edie dankten es der Nacht.", "tokens": ["\u201e", "die", "dank\u00b7ten", "es", "der", "Nacht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u201eein Lager einem Marktplatz gleich", "tokens": ["\u201e", "ein", "La\u00b7ger", "ei\u00b7nem", "Markt\u00b7platz", "gleich"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ekam in der Schweizer Hand.", "tokens": ["\u201e", "kam", "in", "der", "Schwei\u00b7zer", "Hand", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201ekarl machte schnell den Bettler reich,", "tokens": ["\u201e", "karl", "mach\u00b7te", "schnell", "den", "Bett\u00b7ler", "reich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "ADJD", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eim armen Schweizerland.", "tokens": ["\u201e", "im", "ar\u00b7men", "Schwei\u00b7zer\u00b7land", "."], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "\u201eschachzabel ist ein K\u00f6nigsspiel,", "tokens": ["\u201e", "schach\u00b7za\u00b7bel", "ist", "ein", "K\u00f6\u00b7nigs\u00b7spiel", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ejezt spielts der Eidgeno\u00df,", "tokens": ["\u201e", "jezt", "spielts", "der", "Eid\u00b7ge\u00b7no\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eer nahm ihm seiner Fenden viel,", "tokens": ["\u201e", "er", "nahm", "ihm", "sei\u00b7ner", "Fen\u00b7den", "viel", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edie Seite stand ihm blo\u00df.", "tokens": ["\u201e", "die", "Sei\u00b7te", "stand", "ihm", "blo\u00df", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "\u201edie Rochen halfen ihm nicht viel,", "tokens": ["\u201e", "die", "Ro\u00b7chen", "hal\u00b7fen", "ihm", "nicht", "viel", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edie Rosse litten Noth;", "tokens": ["\u201e", "die", "Ros\u00b7se", "lit\u00b7ten", "Noth", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eer wende sich, wohin er will,", "tokens": ["\u201e", "er", "wen\u00b7de", "sich", ",", "wo\u00b7hin", "er", "will", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eschachmatt ist ihm gedroht.\u201c", "tokens": ["\u201e", "schach\u00b7matt", "ist", "ihm", "ge\u00b7droht", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-----+", "measure": "unknown.measure.single"}}, "stanza.17": {"line.1": {"text": "Der hatte selbst die Hand am Schwerdt,", "tokens": ["Der", "hat\u00b7te", "selbst", "die", "Hand", "am", "Schwerdt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der diesen Reim gemacht;", "tokens": ["Der", "die\u00b7sen", "Reim", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis Abends m\u00e4ht' er mit dem Schwerdt,", "tokens": ["Bis", "A\u00b7bends", "m\u00e4ht'", "er", "mit", "dem", "Schwerdt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Nachte sang er die Schlacht.", "tokens": ["Des", "Nach\u00b7te", "sang", "er", "die", "Schlacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.18": {"line.1": {"text": "Er schwang die Saiten und das Schwerdt,", "tokens": ["Er", "schwang", "die", "Sai\u00b7ten", "und", "das", "Schwerdt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Fiedler und Soldat,", "tokens": ["Ein", "Fied\u00b7ler", "und", "Sol\u00b7dat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den Herren und den M\u00e4dchen werth,", "tokens": ["Den", "Her\u00b7ren", "und", "den", "M\u00e4d\u00b7chen", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem T\u00e4nzer und Pr\u00e4lat.", "tokens": ["Dem", "T\u00e4n\u00b7zer", "und", "Pr\u00e4\u00b7lat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Die mich gebahr, das gute Weib,", "tokens": ["Die", "mich", "ge\u00b7bahr", ",", "das", "gu\u00b7te", "Weib", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie k\u00fc\u00dfte mich, und Veit,", "tokens": ["Sie", "k\u00fc\u00df\u00b7te", "mich", ",", "und", "Veit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hei\u00df Veit, so sprach das gute Weib!", "tokens": ["Hei\u00df", "Veit", ",", "so", "sprach", "das", "gu\u00b7te", "Weib", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Veit hei\u00df ich immerseit.", "tokens": ["Veit", "hei\u00df", "ich", "im\u00b7mer\u00b7seit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}