{"dta.poem.798": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XxXIV.  \n Auff den Todt de\u00df Hertzogs von Buckingam.  \n Au\u00df eines andern Frantz\u00f6sischen.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Das Gl\u00fcck/ so fruchtbar ist nur wunder zu gebehren/ ", "tokens": ["Das", "Gl\u00fcck", "/", "so", "frucht\u00b7bar", "ist", "nur", "wun\u00b7der", "zu", "ge\u00b7beh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADJD", "VAFIN", "ADV", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat mich so hoch gef\u00fchrt/ al\u00df keiner je gesetzt/", "tokens": ["Hat", "mich", "so", "hoch", "ge\u00b7f\u00fchrt", "/", "al\u00df", "kei\u00b7ner", "je", "ge\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$(", "KOUS", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zwey K\u00f6nig\u2019haben mein gebott f\u00fcr noth geschetzt/", "tokens": ["Zwey", "K\u00f6\u00b7nig'\u00b7ha\u00b7ben", "mein", "ge\u00b7bott", "f\u00fcr", "noth", "ge\u00b7schetzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vnd musteu jhren platz mir in der Welt gewehren.", "tokens": ["Vnd", "mus\u00b7teu", "jhren", "platz", "mir", "in", "der", "Welt", "ge\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Was Ehr vnd Vberflu\u00df/ mocht Engelland bescheren:", "tokens": ["Was", "Ehr", "vnd", "Vberf\u00b7lu\u00df", "/", "mocht", "En\u00b7gel\u00b7land", "be\u00b7sche\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "$(", "VVFIN", "NE", "VVINF", "$."], "meter": "-+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Hat mein freygebig seyn/ vnendlich auffgesetzt/", "tokens": ["Hat", "mein", "frey\u00b7ge\u00b7big", "seyn", "/", "vnend\u00b7lich", "auff\u00b7ge\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJD", "VAINF", "$(", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Trotz meinem Vaterland! vnd dem es leid! zu letzt/", "tokens": ["Trotz", "mei\u00b7nem", "Va\u00b7ter\u00b7land", "!", "vnd", "dem", "es", "leid", "!", "zu", "letzt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "KON", "ART", "PPER", "ADJD", "$.", "APPR", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "That ich doch auff der Erd vnd See nur mein begehren.", "tokens": ["That", "ich", "doch", "auff", "der", "Erd", "vnd", "See", "nur", "mein", "be\u00b7geh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "ART", "NN", "KON", "NN", "ADV", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Endlich! entbrand von lust nach ewig-hohem prei\u00df", "tokens": ["End\u00b7lich", "!", "ent\u00b7brand", "von", "lust", "nach", "e\u00b7wig\u00b7ho\u00b7hem", "prei\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "VVFIN", "APPR", "NN", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Setzt\u2019 ich mit Franckreich an/ vnd wagte so viel Schwei\u00df.", "tokens": ["Setzt'", "ich", "mit", "Fran\u00b7ck\u00b7reich", "an", "/", "vnd", "wag\u00b7te", "so", "viel", "Schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$(", "KON", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Das wer den anschlag schmeht; den Vorsatz mu\u00df beneyden.", "tokens": ["Das", "wer", "den", "an\u00b7schlag", "schmeht", ";", "den", "Vor\u00b7satz", "mu\u00df", "be\u00b7ney\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PWS", "ART", "NN", "VVFIN", "$.", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch hab ich vrsach/ gl\u00fcck/ zu klagen \u00fcber dich/", "tokens": ["Doch", "hab", "ich", "vr\u00b7sach", "/", "gl\u00fcck", "/", "zu", "kla\u00b7gen", "\u00fc\u00b7ber", "dich", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NE", "$(", "XY", "$(", "PTKZU", "VVINF", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich habe nicht verdint di\u00df leben sonder leiden:", "tokens": ["Ich", "ha\u00b7be", "nicht", "ver\u00b7dint", "di\u00df", "le\u00b7ben", "son\u00b7der", "lei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVFIN", "PDS", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich habe nicht verhofft so grimmen Todesstich.", "tokens": ["Ich", "ha\u00b7be", "nicht", "ver\u00b7hofft", "so", "grim\u00b7men", "To\u00b7des\u00b7stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}