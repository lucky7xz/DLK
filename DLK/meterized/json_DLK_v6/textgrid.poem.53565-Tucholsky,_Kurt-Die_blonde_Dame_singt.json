{"textgrid.poem.53565": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Die blonde Dame singt", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe mir mein Deutschland angesehen", "tokens": ["Ich", "ha\u00b7be", "mir", "mein", "Deutschland", "an\u00b7ge\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "in seiner gro\u00dfen, in der kleinen Zeit.", "tokens": ["in", "sei\u00b7ner", "gro\u00b7\u00dfen", ",", "in", "der", "klei\u00b7nen", "Zeit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich sah den Kaiser in die Oper gehen;", "tokens": ["Ich", "sah", "den", "Kai\u00b7ser", "in", "die", "O\u00b7per", "ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der Hermelin war diesem Mann zu weit.", "tokens": ["der", "Her\u00b7me\u00b7lin", "war", "die\u00b7sem", "Mann", "zu", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PDAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und dann die Schranzen! und die Gener\u00e4le!", "tokens": ["Und", "dann", "die", "Schran\u00b7zen", "!", "und", "die", "Ge\u00b7ne\u00b7r\u00e4\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Grau an Humor, am Rock indianerbunt . . .", "tokens": ["Grau", "an", "Hu\u00b7mor", ",", "am", "Rock", "in\u00b7di\u00b7a\u00b7ner\u00b7bunt", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "APPRART", "NN", "ADJD", "$.", "$.", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Und leicht entt\u00e4uscht fragt meine liebe Seele:", "tokens": ["Und", "leicht", "ent\u00b7t\u00e4uscht", "fragt", "mei\u00b7ne", "lie\u00b7be", "See\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbna und . . . ?\u00ab", "tokens": ["\u00bb", "na", "und", ".", ".", ".", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "ITJ", "KON", "$.", "$.", "$.", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.2": {"line.1": {"text": "Das w\u00fchlt und wimmelt in den gro\u00dfen St\u00e4dten.", "tokens": ["Das", "w\u00fchlt", "und", "wim\u00b7melt", "in", "den", "gro\u00b7\u00dfen", "St\u00e4d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Proletarier schuftet wie ein Tier.", "tokens": ["Der", "Pro\u00b7le\u00b7ta\u00b7rier", "schuf\u00b7tet", "wie", "ein", "Tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der deutsche B\u00fcrger l\u00e4\u00dft sich ruhig treten,", "tokens": ["Der", "deut\u00b7sche", "B\u00fcr\u00b7ger", "l\u00e4\u00dft", "sich", "ru\u00b7hig", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "er macht Gesch\u00e4fte und schluckt biedres Bier.", "tokens": ["er", "macht", "Ge\u00b7sch\u00e4f\u00b7te", "und", "schluckt", "bie\u00b7dres", "Bier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und Kunst und immer diese selben Jungen,", "tokens": ["Und", "Kunst", "und", "im\u00b7mer", "die\u00b7se", "sel\u00b7ben", "Jun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "ADV", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "nur Not und Kummer h\u00e4lt die Brut gesund.", "tokens": ["nur", "Not", "und", "Kum\u00b7mer", "h\u00e4lt", "die", "Brut", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Erfolg? Dann haben sie bald ausgesungen.", "tokens": ["Er\u00b7folg", "?", "Dann", "ha\u00b7ben", "sie", "bald", "aus\u00b7ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich frage mich, wenn all der L\u00e4rm verklungen:", "tokens": ["Ich", "fra\u00b7ge", "mich", ",", "wenn", "all", "der", "L\u00e4rm", "ver\u00b7klun\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PIAT", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbna und . . . ?\u00ab", "tokens": ["\u00bb", "na", "und", ".", ".", ".", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "ITJ", "KON", "$.", "$.", "$.", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "Dann gab es Krieg und hohe Butterpreise.", "tokens": ["Dann", "gab", "es", "Krieg", "und", "ho\u00b7he", "But\u00b7ter\u00b7prei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es deliriert das Land. Revolution!", "tokens": ["Es", "de\u00b7li\u00b7riert", "das", "Land", ".", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "NN", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Dem ganzen deutschen B\u00fcrgerstand geht leise", "tokens": ["Dem", "gan\u00b7zen", "deut\u00b7schen", "B\u00fcr\u00b7ger\u00b7stand", "geht", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der Stuhl mit Grundeis, nun, man kennt das schon.", "tokens": ["der", "Stuhl", "mit", "Grun\u00b7deis", ",", "nun", ",", "man", "kennt", "das", "schon", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ADV", "$,", "PIS", "VVFIN", "ART", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Es rufen hier und da Idealisten,", "tokens": ["Es", "ru\u00b7fen", "hier", "und", "da", "I\u00b7dea\u00b7lis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "KOUS", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "man gr\u00fcndet R\u00e4te, Gruppen, einen Bund . . .", "tokens": ["man", "gr\u00fcn\u00b7det", "R\u00e4\u00b7te", ",", "Grup\u00b7pen", ",", "ei\u00b7nen", "Bund", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PIS", "VVFIN", "NN", "$,", "NN", "$,", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich sehe Bolschewiki, Spartakisten \u2013", "tokens": ["Ich", "se\u00b7he", "Bol\u00b7sche\u00b7wi\u00b7ki", ",", "Spar\u00b7ta\u00b7kis\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$,", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Na und . . . ?", "tokens": ["Na", "und", ".", ".", ".", "?"], "token_info": ["word", "word", "punct", "punct", "punct", "punct"], "pos": ["NE", "KON", "$.", "$.", "$.", "$."], "meter": "--", "measure": "unknown.measure.zero"}}, "stanza.4": {"line.1": {"text": "Und steh ich einstmals vor dem Weltenrichter,", "tokens": ["Und", "steh", "ich", "einst\u00b7mals", "vor", "dem", "Wel\u00b7ten\u00b7rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(der liebe Gott ist schlie\u00dflich auch ein Mann),", "tokens": ["(", "der", "lie\u00b7be", "Gott", "ist", "schlie\u00df\u00b7lich", "auch", "ein", "Mann", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "ADV", "ADV", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "streckt er sein Flammenschwert steil hoch und spricht er:", "tokens": ["streckt", "er", "sein", "Flam\u00b7men\u00b7schwert", "steil", "hoch", "und", "spricht", "er", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "ADJD", "KON", "VVFIN", "PPER", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "\u00bbdich b\u00f6ses M\u00e4dchen seh ich nicht mehr an!", "tokens": ["\u00bb", "dich", "b\u00f6\u00b7ses", "M\u00e4d\u00b7chen", "seh", "ich", "nicht", "mehr", "an", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Hinweg, du sollst ins Fegefeuer pultern!", "tokens": ["Hin\u00b7weg", ",", "du", "sollst", "ins", "Fe\u00b7ge\u00b7feu\u00b7er", "pul\u00b7tern", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VMFIN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Werft sie mir in den tiefsten H\u00f6llenschlund!\u00ab", "tokens": ["Werft", "sie", "mir", "in", "den", "tiefs\u00b7ten", "H\u00f6l\u00b7len\u00b7schlund", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.7": {"text": "Dann sag ich leis und hebe m\u00fcd die Schultern:", "tokens": ["Dann", "sag", "ich", "leis", "und", "he\u00b7be", "m\u00fcd", "die", "Schul\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbna und . . . ?\u00ab", "tokens": ["\u00bb", "na", "und", ".", ".", ".", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "ITJ", "KON", "$.", "$.", "$.", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}}}}