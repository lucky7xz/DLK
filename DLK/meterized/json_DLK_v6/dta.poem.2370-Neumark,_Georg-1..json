{"dta.poem.2370": {"metadata": {"author": {"name": "Neumark, Georg", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1652", "urn": "urn:nbn:de:kobv:b4-20428-0", "language": ["de:0.99"], "booktitle": "Neumark, Georg: Poetisch- und Musikalisches Lustw\u00e4ldchen. Hamburg, 1652."}, "poem": {"stanza.1": {"line.1": {"text": "Sein Thyrsis der itzund hier bey der Weisset wohnet/", "tokens": ["Sein", "Thyr\u00b7sis", "der", "it\u00b7zund", "hier", "bey", "der", "Weis\u00b7set", "woh\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der sich nicht selbst so sehr als dich sein Kind geliebt/", "tokens": ["Der", "sich", "nicht", "selbst", "so", "sehr", "als", "dich", "sein", "Kind", "ge\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PTKNEG", "ADV", "ADV", "ADV", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird noch nicht von der Angst der Liebeslast verschonet/", "tokens": ["Wird", "noch", "nicht", "von", "der", "Angst", "der", "Lie\u00b7bes\u00b7last", "ver\u00b7scho\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Lebt offtmals wegen dein von Hertzen hochbetr\u00fcbt.", "tokens": ["Lebt", "offt\u00b7mals", "we\u00b7gen", "dein", "von", "Hert\u00b7zen", "hoch\u00b7be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Er d\u00e4nket Tag und Nacht an jene s\u00fcsse Stunden/", "tokens": ["Er", "d\u00e4n\u00b7ket", "Tag", "und", "Nacht", "an", "je\u00b7ne", "s\u00fcs\u00b7se", "Stun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie Er vor sieben Jahr sich offt zu dir gefunden", "tokens": ["Wie", "Er", "vor", "sie\u00b7ben", "Jahr", "sich", "offt", "zu", "dir", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "CARD", "NN", "PRF", "ADV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie du Jhn und Er Dich in keuscher Gunst gehertzt.", "tokens": ["Wie", "du", "Jhn", "und", "Er", "Dich", "in", "keu\u00b7scher", "Gunst", "ge\u00b7hertzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "KON", "PPER", "PRF", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "Er d\u00e4nket Tag und Nacht an deine Heldenaugen/", "tokens": ["Er", "d\u00e4n\u00b7ket", "Tag", "und", "Nacht", "an", "dei\u00b7ne", "Hel\u00b7den\u00b7au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An deinen Zukkermund/ an deine Marmolbrust", "tokens": ["An", "dei\u00b7nen", "Zuk\u00b7ker\u00b7mund", "/", "an", "dei\u00b7ne", "Mar\u00b7mol\u00b7brust"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An deine H\u00f6fligkeit/ dr\u00fcm wil ihm nichtes taugen/", "tokens": ["An", "dei\u00b7ne", "H\u00f6f\u00b7lig\u00b7keit", "/", "dr\u00fcm", "wil", "ihm", "nich\u00b7tes", "tau\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ADV", "VMFIN", "PPER", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das andre Jungfer Volk ist ihm nur lauter Wust.", "tokens": ["Das", "and\u00b7re", "Jung\u00b7fer", "Volk", "ist", "ihm", "nur", "lau\u00b7ter", "Wust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VAFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie die\u00df sein Paradie\u00df/ o G\u00f6ttinn/ vor gewesen/", "tokens": ["Wie", "die\u00df", "sein", "Pa\u00b7ra\u00b7die\u00df", "/", "o", "G\u00f6t\u00b7tinn", "/", "vor", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PDS", "PPOSAT", "NN", "$(", "FM", "NN", "$(", "APPR", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So ist dein Absein itzt ihm lauter Helt\u2019 und Pein/", "tokens": ["So", "ist", "dein", "Ab\u00b7sein", "itzt", "ihm", "lau\u00b7ter", "Helt'", "und", "Pein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "PPER", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wird auch ehe nicht von dieser Brunst genesen/", "tokens": ["Und", "wird", "auch", "e\u00b7he", "nicht", "von", "die\u00b7ser", "Brunst", "ge\u00b7ne\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOUS", "PTKNEG", "APPR", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er werde denn zuvor vermodert m\u00fcssen sein.", "tokens": ["Er", "wer\u00b7de", "denn", "zu\u00b7vor", "ver\u00b7mo\u00b7dert", "m\u00fcs\u00b7sen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Was sag\u2019 ich kan der Tod wol solche Liebe t\u00f6dten/", "tokens": ["Was", "sag'", "ich", "kan", "der", "Tod", "wol", "sol\u00b7che", "Lie\u00b7be", "t\u00f6d\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "VMFIN", "ART", "NN", "ADV", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die nach dem Tod\u2019 erst recht als lebhafft reden kan?", "tokens": ["Die", "nach", "dem", "Tod'", "erst", "recht", "als", "leb\u00b7hafft", "re\u00b7den", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "ADJD", "KOKOM", "VVFIN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nein dieser Versche krafft wird ihn mit Scham ber\u00f6hten!", "tokens": ["Nein", "die\u00b7ser", "Ver\u00b7sche", "krafft", "wird", "ihn", "mit", "Scham", "be\u00b7r\u00f6h\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PDAT", "ADJA", "NN", "VAFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Er die Gunst nicht nur auf Lebenszeit gewann.", "tokens": ["Da\u00df", "Er", "die", "Gunst", "nicht", "nur", "auf", "Le\u00b7bens\u00b7zeit", "ge\u00b7wann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ob Er schon Sterblicher dich Sterbliche geliebet! (sp\u00fchrt.", "tokens": ["Ob", "Er", "schon", "Sterb\u00b7li\u00b7cher", "dich", "Sterb\u00b7li\u00b7che", "ge\u00b7lie\u00b7bet", "!", "(", "sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "PPER", "NN", "VVPP", "$.", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "So wird nichts Sterblichs doch an beyder Tre\u00fc ver-", "tokens": ["So", "wird", "nichts", "Sterb\u00b7lichs", "doch", "an", "bey\u00b7der", "Tre\u00fc", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "NN", "ADV", "APPR", "PIAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn Lieb\u2019 und Gegenlieb\u2019 auf Ernst wird ausge\u00fcbet/", "tokens": ["Wenn", "Lieb'", "und", "Ge\u00b7gen\u00b7lieb'", "auf", "Ernst", "wird", "aus\u00b7ge\u00b7\u00fc\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "APPR", "NE", "VAFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird Sie durch keinen Mord des Todes anger\u00fchrt.", "tokens": ["Wird", "Sie", "durch", "kei\u00b7nen", "Mord", "des", "To\u00b7des", "an\u00b7ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PIAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Kein Frauenzimmer solt so weit beruffen werden/", "tokens": ["Kein", "Frau\u00b7en\u00b7zim\u00b7mer", "solt", "so", "weit", "be\u00b7ruf\u00b7fen", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Karitillchen du/ du edler Tugendschein!", "tokens": ["Als", "Ka\u00b7ri\u00b7till\u00b7chen", "du", "/", "du", "ed\u00b7ler", "Tu\u00b7gend\u00b7schein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "$(", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du solst weit h\u00f6her stehn als dieser Ball der Erden/", "tokens": ["Du", "solst", "weit", "h\u00f6\u00b7her", "stehn", "als", "die\u00b7ser", "Ball", "der", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "ADJD", "VVINF", "KOKOM", "PDAT", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Himmel selbst wird auch vor dich zu niedrig sein,", "tokens": ["Der", "Him\u00b7mel", "selbst", "wird", "auch", "vor", "dich", "zu", "nied\u00b7rig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADV", "APPR", "PPER", "PTKA", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Weich R\u00f6msche Lupia bistu schon hochgeehret/", "tokens": ["Weich", "R\u00f6m\u00b7sche", "Lu\u00b7pia", "bis\u00b7tu", "schon", "hoch\u00b7geeh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mein Karitilchen soll doch \u00fcber dir nun stehn/", "tokens": ["Mein", "Ka\u00b7ri\u00b7til\u00b7chen", "soll", "doch", "\u00fc\u00b7ber", "dir", "nun", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "APPR", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr Griechschen Jungfern auch seit immerhin gelehret/", "tokens": ["Ihr", "Griech\u00b7schen", "Jung\u00b7fern", "auch", "seit", "im\u00b7mer\u00b7hin", "ge\u00b7leh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "ADV", "APPR", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein trautster Hertzenstrost soll euch all\u2019 \u00fcbergehn.", "tokens": ["Mein", "trauts\u00b7ter", "Hert\u00b7zens\u00b7trost", "soll", "euch", "all'", "\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Er setzet dich/ sein Hertz/ dich liebste Karitillen/", "tokens": ["Er", "set\u00b7zet", "dich", "/", "sein", "Hertz", "/", "dich", "liebs\u00b7te", "Ka\u00b7ri\u00b7til\u00b7len", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PPOSAT", "NN", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dort jener Fillis vor/ dort jener Galathe/", "tokens": ["Dort", "je\u00b7ner", "Fil\u00b7lis", "vor", "/", "dort", "je\u00b7ner", "Ga\u00b7la\u00b7the", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NE", "PTKVZ", "$(", "ADV", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dort jener Le\u00dfbien/ dort jener Amarillen/", "tokens": ["Dort", "je\u00b7ner", "Le\u00df\u00b7bi\u00b7en", "/", "dort", "je\u00b7ner", "A\u00b7ma\u00b7ril\u00b7len", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "$(", "ADV", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dort jener Bellisell\u2019/ auch jener Argine!", "tokens": ["Dort", "je\u00b7ner", "Bel\u00b7li\u00b7sell'", "/", "auch", "je\u00b7ner", "Ar\u00b7gi\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "$(", "ADV", "PDAT", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "In dessen weil Er nichts von dir itzt kan genie\u00dfen/", "tokens": ["In", "des\u00b7sen", "weil", "Er", "nichts", "von", "dir", "itzt", "kan", "ge\u00b7nie\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "KOUS", "PPER", "PIS", "APPR", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als da\u00df du seiner wollst imgleichen eindenk sein/", "tokens": ["Als", "da\u00df", "du", "sei\u00b7ner", "wollst", "im\u00b7glei\u00b7chen", "ein\u00b7denk", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPOSAT", "VMFIN", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So pflegt Er deinen Ring vor deinen Mund zu k\u00fcssen/", "tokens": ["So", "pflegt", "Er", "dei\u00b7nen", "Ring", "vor", "dei\u00b7nen", "Mund", "zu", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und taucht ihn wenn Er trinkt gar oft im Becher ein.", "tokens": ["Und", "taucht", "ihn", "wenn", "Er", "trinkt", "gar", "oft", "im", "Be\u00b7cher", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOUS", "PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Dein liebstes Ebenbild das liebe Liebeszeichen/", "tokens": ["Dein", "liebs\u00b7tes", "E\u00b7ben\u00b7bild", "das", "lie\u00b7be", "Lie\u00b7bes\u00b7zei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Tr\u00e4gt Er auf seiner Brust und nimmt ein Merkmahl", "tokens": ["Tr\u00e4gt", "Er", "auf", "sei\u00b7ner", "Brust", "und", "nimmt", "ein", "Merk\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "dran/", "tokens": ["dran", "/"], "token_info": ["word", "punct"], "pos": ["PAV", "$("], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Dann geht es dir nicht wohl so wird es bald verbleichen/", "tokens": ["Dann", "geht", "es", "dir", "nicht", "wohl", "so", "wird", "es", "bald", "ver\u00b7blei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "ADV", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ists gut so gl\u00e4ntzt das Gold und zeigts dem Hertzen an.", "tokens": ["Ists", "gut", "so", "gl\u00e4ntzt", "das", "Gold", "und", "zeigts", "dem", "Hert\u00b7zen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Was nun sein Zeitvertreib wilstu vielleichte wissen/", "tokens": ["Was", "nun", "sein", "Zeit\u00b7ver\u00b7treib", "wils\u00b7tu", "viel\u00b7leich\u00b7te", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "VMFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Morgens ists ein Buch/ Ein Gang nach Mittags-", "tokens": ["Des", "Mor\u00b7gens", "ists", "ein", "Buch", "/", "Ein", "Gang", "nach", "Mit\u00b7tags"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VAFIN", "ART", "NN", "$(", "ART", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "zeit/", "tokens": ["zeit", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Hier vor die Stadt hinaus da Er dann ist beflissen/", "tokens": ["Hier", "vor", "die", "Stadt", "hin\u00b7aus", "da", "Er", "dann", "ist", "be\u00b7flis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APZR", "KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auf lauter Hertzenweh/ auf lauter Traurigkeit.", "tokens": ["Auf", "lau\u00b7ter", "Hert\u00b7zen\u00b7weh", "/", "auf", "lau\u00b7ter", "Trau\u00b7rig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$(", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Bald schaut Er den Rubin/ bald sieht Er auf das prangen/", "tokens": ["Bald", "schaut", "Er", "den", "Ru\u00b7bin", "/", "bald", "sieht", "Er", "auf", "das", "pran\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NE", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "$("], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Des sch\u00f6nen Demandrings/ bald auf das Armenband/", "tokens": ["Des", "sch\u00f6\u00b7nen", "De\u00b7mand\u00b7rings", "/", "bald", "auf", "das", "Ar\u00b7men\u00b7band", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So Er von dir mein Kind/ zum Denkmahl hat empfange\u0303/", "tokens": ["So", "Er", "von", "dir", "mein", "Kind", "/", "zum", "Denk\u00b7mahl", "hat", "emp\u00b7fang\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PPER", "PPOSAT", "NN", "$(", "APPRART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zum Zeichen deiner Gunst zum treuen Liebespfand.", "tokens": ["Zum", "Zei\u00b7chen", "dei\u00b7ner", "Gunst", "zum", "treu\u00b7en", "Lie\u00b7be\u00b7spfand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Und da\u00df Er \u00fcberal ja dein Ged\u00e4chtn\u00fc\u00df finde/", "tokens": ["Und", "da\u00df", "Er", "\u00fc\u00b7be\u00b7ral", "ja", "dein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "fin\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat Er ein Str\u00f6mchen hier/ nach dir/ mein Kind genant/", "tokens": ["Hat", "Er", "ein", "Str\u00f6m\u00b7chen", "hier", "/", "nach", "dir", "/", "mein", "Kind", "ge\u00b7nant", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "$(", "APPR", "PPER", "$(", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das rauschet Tag und Nacht durch seine tieffe Gr\u00fcnde/", "tokens": ["Das", "rau\u00b7schet", "Tag", "und", "Nacht", "durch", "sei\u00b7ne", "tief\u00b7fe", "Gr\u00fcn\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "KON", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey welchem nur auf dich sein gantzer Sinn gewandt.", "tokens": ["Bey", "wel\u00b7chem", "nur", "auf", "dich", "sein", "gant\u00b7zer", "Sinn", "ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "APPR", "PPER", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Da geht Er offtmals hin/ und setzet sich danieder/", "tokens": ["Da", "geht", "Er", "offt\u00b7mals", "hin", "/", "und", "set\u00b7zet", "sich", "da\u00b7nie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "PRF", "PAV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00e4ngt zu klagen an in tieffer Traurigkeit/", "tokens": ["Und", "f\u00e4ngt", "zu", "kla\u00b7gen", "an", "in", "tief\u00b7fer", "Trau\u00b7rig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKZU", "VVINF", "APPR", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dann singt Er bey sich selbst der Liebe Klagelieder/", "tokens": ["Dann", "singt", "Er", "bey", "sich", "selbst", "der", "Lie\u00b7be", "Kla\u00b7ge\u00b7lie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PRF", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Er von dir gemacht/ vor jener langen Zeit.", "tokens": ["Die", "Er", "von", "dir", "ge\u00b7macht", "/", "vor", "je\u00b7ner", "lan\u00b7gen", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVPP", "$(", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Auch die\u00df ist nicht genug die jung- und alten Eichen/", "tokens": ["Auch", "die\u00df", "ist", "nicht", "ge\u00b7nug", "die", "jung", "und", "al\u00b7ten", "Ei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "PTKNEG", "ADV", "ART", "TRUNC", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So ihren Unterhalt von diesem Str\u00f6hmchen ziehn/", "tokens": ["So", "ih\u00b7ren", "Un\u00b7ter\u00b7halt", "von", "die\u00b7sem", "Str\u00f6hm\u00b7chen", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die tragen eingeschnitzt des halben Mondes Zeichen/", "tokens": ["Die", "tra\u00b7gen", "ein\u00b7ge\u00b7schnitzt", "des", "hal\u00b7ben", "Mon\u00b7des", "Zei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00e4chst dein Nahme mit und kan doch nicht verbl\u00fchn.", "tokens": ["So", "w\u00e4chst", "dein", "Nah\u00b7me", "mit", "und", "kan", "doch", "nicht", "ver\u00b7bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "KON", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Die\u00df alles hat Er dir mein Seelchen zugeschrieben/", "tokens": ["Die\u00df", "al\u00b7les", "hat", "Er", "dir", "mein", "Seel\u00b7chen", "zu\u00b7ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "PPER", "PPER", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Damit du sehen solst wie hoch Er dich gesch\u00e4tzt/", "tokens": ["Da\u00b7mit", "du", "se\u00b7hen", "solst", "wie", "hoch", "Er", "dich", "ge\u00b7sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "KOKOM", "ADJD", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wie Er itzund noch so standhafft sey im Lieben", "tokens": ["Und", "wie", "Er", "it\u00b7zund", "noch", "so", "stand\u00b7hafft", "sey", "im", "Lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "ADV", "VVFIN", "VAFIN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird Er schon nicht wie vor mit Gegenwart ergetzt.", "tokens": ["Wird", "Er", "schon", "nicht", "wie", "vor", "mit", "Ge\u00b7gen\u00b7wart", "er\u00b7getzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "KOKOM", "APPR", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Es sind schon sieben Jahr da\u00df Absckied Er genommen/", "tokens": ["Es", "sind", "schon", "sie\u00b7ben", "Jahr", "da\u00df", "Ab\u00b7sckied", "Er", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "CARD", "NN", "KOUS", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von dir aus Zimrien/ o edle K\u00f6niginn/", "tokens": ["Von", "dir", "aus", "Zim\u00b7ri\u00b7en", "/", "o", "ed\u00b7le", "K\u00f6\u00b7ni\u00b7ginn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "NN", "$(", "FM", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Run hoffe Er wieder\u00fcm zu dir mein Hertz/ zu kommen/", "tokens": ["Run", "hof\u00b7fe", "Er", "wie\u00b7de\u00b7r\u00fcm", "zu", "dir", "mein", "Hertz", "/", "zu", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "$(", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "Gott gebe frische Krafft und st\u00e4rke meinen Sinn.", "tokens": ["Gott", "ge\u00b7be", "fri\u00b7sche", "Krafft", "und", "st\u00e4r\u00b7ke", "mei\u00b7nen", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.19": {"line.1": {"text": "In dessen leb erfreut/ leb tausendmal vergn\u00fcget/", "tokens": ["In", "des\u00b7sen", "leb", "er\u00b7freut", "/", "leb", "tau\u00b7send\u00b7mal", "ver\u00b7gn\u00fc\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "ADJD", "$(", "VVFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du Liebster Augentrost/ du edles Sinnenlicht/", "tokens": ["Du", "Liebs\u00b7ter", "Au\u00b7gen\u00b7trost", "/", "du", "ed\u00b7les", "Sin\u00b7nen\u00b7licht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bi\u00df sich das liebe Gl\u00fckk des treuen Thyrsis f\u00fcget/", "tokens": ["Bi\u00df", "sich", "das", "lie\u00b7be", "Gl\u00fckk", "des", "treu\u00b7en", "Thyr\u00b7sis", "f\u00fc\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bi\u00df Er mit h\u00f6chster Lust dich Liebste selber spricht.", "tokens": ["Bi\u00df", "Er", "mit", "h\u00f6chs\u00b7ter", "Lust", "dich", "Liebs\u00b7te", "sel\u00b7ber", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "PPER", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}