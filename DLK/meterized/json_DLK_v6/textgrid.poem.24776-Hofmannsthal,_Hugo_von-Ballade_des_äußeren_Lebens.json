{"textgrid.poem.24776": {"metadata": {"author": {"name": "Hofmannsthal, Hugo von", "birth": "N.A.", "death": "N.A."}, "title": "Ballade des \u00e4u\u00dferen Lebens", "genre": "verse", "period": "N.A.", "pub_year": 1901, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und Kinder wachsen auf mit tiefen Augen,", "tokens": ["Und", "Kin\u00b7der", "wach\u00b7sen", "auf", "mit", "tie\u00b7fen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die von nichts wissen, wachsen auf und sterben,", "tokens": ["Die", "von", "nichts", "wis\u00b7sen", ",", "wach\u00b7sen", "auf", "und", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIS", "VVINF", "$,", "VVFIN", "PTKVZ", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und alle Menschen gehen ihre Wege.", "tokens": ["Und", "al\u00b7le", "Men\u00b7schen", "ge\u00b7hen", "ih\u00b7re", "We\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Und s\u00fc\u00dfe Fr\u00fcchte werden aus den herben", "tokens": ["Und", "s\u00fc\u00b7\u00dfe", "Fr\u00fcch\u00b7te", "wer\u00b7den", "aus", "den", "her\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und fallen nachts wie tote V\u00f6gel nieder", "tokens": ["Und", "fal\u00b7len", "nachts", "wie", "to\u00b7te", "V\u00f6\u00b7gel", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "KOKOM", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und liegen wenig Tage und verderben.", "tokens": ["Und", "lie\u00b7gen", "we\u00b7nig", "Ta\u00b7ge", "und", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und immer weht der Wind, und immer wieder", "tokens": ["Und", "im\u00b7mer", "weht", "der", "Wind", ",", "und", "im\u00b7mer", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$,", "KON", "ADV", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vernehmen wir und reden viele Worte", "tokens": ["Ver\u00b7neh\u00b7men", "wir", "und", "re\u00b7den", "vie\u00b7le", "Wor\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und sp\u00fcren Lust und M\u00fcdigkeit der Glieder.", "tokens": ["Und", "sp\u00fc\u00b7ren", "Lust", "und", "M\u00fc\u00b7dig\u00b7keit", "der", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und Stra\u00dfen laufen durch das Gras, und Orte", "tokens": ["Und", "Stra\u00b7\u00dfen", "lau\u00b7fen", "durch", "das", "Gras", ",", "und", "Or\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sind da und dort, voll Fackeln, B\u00e4umen, Teichen,", "tokens": ["Sind", "da", "und", "dort", ",", "voll", "Fa\u00b7ckeln", ",", "B\u00e4u\u00b7men", ",", "Tei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "KON", "ADV", "$,", "ADJD", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und drohende, und totenhaft verdorrte ...", "tokens": ["Und", "dro\u00b7hen\u00b7de", ",", "und", "to\u00b7ten\u00b7haft", "ver\u00b7dorr\u00b7te", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wozu sind diese aufgebaut? und gleichen", "tokens": ["Wo\u00b7zu", "sind", "die\u00b7se", "auf\u00b7ge\u00b7baut", "?", "und", "glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "VAFIN", "PDS", "VVFIN", "$.", "KON", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Einander nie? und sind unz\u00e4hlig viele?", "tokens": ["Ein\u00b7an\u00b7der", "nie", "?", "und", "sind", "un\u00b7z\u00e4h\u00b7lig", "vie\u00b7le", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "KON", "VAFIN", "ADJD", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was wechselt Lachen, Weinen und Erbleichen?", "tokens": ["Was", "wech\u00b7selt", "La\u00b7chen", ",", "Wei\u00b7nen", "und", "Er\u00b7blei\u00b7chen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Was frommt das alles uns und diese Spiele,", "tokens": ["Was", "frommt", "das", "al\u00b7les", "uns", "und", "die\u00b7se", "Spie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "PIS", "PPER", "KON", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die wir doch gro\u00df und ewig einsam sind", "tokens": ["Die", "wir", "doch", "gro\u00df", "und", "e\u00b7wig", "ein\u00b7sam", "sind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJD", "KON", "ADJD", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wandernd nimmer suchen irgend Ziele?", "tokens": ["Und", "wan\u00b7dernd", "nim\u00b7mer", "su\u00b7chen", "ir\u00b7gend", "Zie\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Was frommts, dergleichen viel gesehen haben?", "tokens": ["Was", "frommts", ",", "derg\u00b7lei\u00b7chen", "viel", "ge\u00b7se\u00b7hen", "ha\u00b7ben", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PIS", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und dennoch sagt der viel, der \u00bbAbend\u00ab sagt,", "tokens": ["Und", "den\u00b7noch", "sagt", "der", "viel", ",", "der", "\u00bb", "A\u00b7bend", "\u00ab", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADV", "$,", "ART", "$(", "NN", "$(", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Wort, daraus Tiefsinn und Trauer rinnt", "tokens": ["Ein", "Wort", ",", "da\u00b7raus", "Tief\u00b7sinn", "und", "Trau\u00b7er", "rinnt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PAV", "NN", "KON", "NN", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.8": {"line.1": {"text": "Wie schwerer Honig aus den hohlen Waben.", "tokens": ["Wie", "schwe\u00b7rer", "Ho\u00b7nig", "aus", "den", "hoh\u00b7len", "Wa\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}