{"textgrid.poem.62442": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "Am 28. J\u00e4nner 1814", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun sind es tausend Jahr,", "tokens": ["Nun", "sind", "es", "tau\u00b7send", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df Kaiser Karl geschlafen.", "tokens": ["Da\u00df", "Kai\u00b7ser", "Karl", "ge\u00b7schla\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NE", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wer z\u00e4hlt der Gr\u00e4uel Schaar,", "tokens": ["Wer", "z\u00e4hlt", "der", "Gr\u00e4u\u00b7el", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die in der Zeit uns trafen?", "tokens": ["Die", "in", "der", "Zeit", "uns", "tra\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Hat dir von unsrer Welt", "tokens": ["Hat", "dir", "von", "uns\u00b7rer", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Im Grabe nicht getr\u00e4umet?", "tokens": ["Im", "Gra\u00b7be", "nicht", "ge\u00b7tr\u00e4u\u00b7met", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "O frommer Christenheld,", "tokens": ["O", "from\u00b7mer", "Chris\u00b7ten\u00b7held", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Du hast sehr viel vers\u00e4umet.", "tokens": ["Du", "hast", "sehr", "viel", "ver\u00b7s\u00e4u\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Das ganze Deutschland schaut", "tokens": ["Das", "gan\u00b7ze", "Deutschland", "schaut"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Voll Schmerz nach deinen Zeiten,", "tokens": ["Voll", "Schmerz", "nach", "dei\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der heil'ge Morgen graut,", "tokens": ["Der", "heil'\u00b7ge", "Mor\u00b7gen", "graut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Zu dem wir uns bereiten.", "tokens": ["Zu", "dem", "wir", "uns", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Nun rufen wir dir zu,", "tokens": ["Nun", "ru\u00b7fen", "wir", "dir", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Geliebtes Haupt, erwache,", "tokens": ["Ge\u00b7lieb\u00b7tes", "Haupt", ",", "er\u00b7wa\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ersteh' von langer Ruh,", "tokens": ["Er\u00b7steh'", "von", "lan\u00b7ger", "Ruh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Vollziehe du die Rache!", "tokens": ["Voll\u00b7zie\u00b7he", "du", "die", "Ra\u00b7che", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Steh' auf in Herrlichkeit,", "tokens": ["Steh'", "auf", "in", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nimm Schwert und Scepter wieder,", "tokens": ["Nimm", "Schwert", "und", "Scep\u00b7ter", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NN", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dann kommt die be\u00dfre Zeit", "tokens": ["Dann", "kommt", "die", "be\u00df\u00b7re", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Vom Himmel zu uns nieder.", "tokens": ["Vom", "Him\u00b7mel", "zu", "uns", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Nur einen solchen Herrn,", "tokens": ["Nur", "ei\u00b7nen", "sol\u00b7chen", "Herrn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Einmal nach tausend Jahren,", "tokens": ["Ein\u00b7mal", "nach", "tau\u00b7send", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "$,"], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "Dann soll der deutsche Stern", "tokens": ["Dann", "soll", "der", "deut\u00b7sche", "Stern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hoch leuchten in Gefahren.", "tokens": ["Hoch", "leuch\u00b7ten", "in", "Ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "La\u00df, Heil'ger, stark und weich,", "tokens": ["La\u00df", ",", "Heil'\u00b7ger", ",", "stark", "und", "weich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Dich unsre Liebe binden,", "tokens": ["Dich", "uns\u00b7re", "Lie\u00b7be", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ein tausendj\u00e4hr'ges Reich", "tokens": ["Ein", "tau\u00b7send\u00b7j\u00e4hr'\u00b7ges", "Reich"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "In Deutschland neu zu gr\u00fcnden.", "tokens": ["In", "Deutschland", "neu", "zu", "gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}