{"dta.poem.12952": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Als er auf dem wege zu Flavien  \n begriffen war.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.71", "af:0.28"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die stunden werden tage,", "tokens": ["Die", "stun\u00b7den", "wer\u00b7den", "ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Weil ich, mein Licht! von dir entfernet bin:", "tokens": ["Weil", "ich", ",", "mein", "Licht", "!", "von", "dir", "ent\u00b7fer\u00b7net", "bin", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPOSAT", "NN", "$.", "APPR", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Flieht, stunden, flieht doch bald dahin!", "tokens": ["Flieht", ",", "stun\u00b7den", ",", "flieht", "doch", "bald", "da\u00b7hin", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "$,", "VVFIN", "ADV", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich nicht mehr auf das verh\u00e4ngni\u00df klage.", "tokens": ["Da\u00df", "ich", "nicht", "mehr", "auf", "das", "ver\u00b7h\u00e4ng\u00b7ni\u00df", "kla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn l\u00e4nger ohne dich, o Flavia! zu seyn,", "tokens": ["Denn", "l\u00e4n\u00b7ger", "oh\u00b7ne", "dich", ",", "o", "Fla\u00b7via", "!", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "$,", "FM", "NE", "$.", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Ist eine h\u00f6llen-gleiche pein.", "tokens": ["Ist", "ei\u00b7ne", "h\u00f6l\u00b7len\u00b7glei\u00b7che", "pein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Indessen, sanffte winde!", "tokens": ["In\u00b7des\u00b7sen", ",", "sanff\u00b7te", "win\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die ihr vorl\u00e4ngst mein heisses sehnen wi\u00dft,", "tokens": ["Die", "ihr", "vor\u00b7l\u00e4ngst", "mein", "heis\u00b7ses", "seh\u00b7nen", "wi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PPOSAT", "ADJA", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Macht, da\u00df mein ach die lippen k\u00fc\u00dft,", "tokens": ["Macht", ",", "da\u00df", "mein", "ach", "die", "lip\u00b7pen", "k\u00fc\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPOSAT", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Auf denen ich allein mein labsal finde.", "tokens": ["Auf", "de\u00b7nen", "ich", "al\u00b7lein", "mein", "lab\u00b7sal", "fin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Du aber schicke mir, zum leit-stern meiner ruh,", "tokens": ["Du", "a\u00b7ber", "schi\u00b7cke", "mir", ",", "zum", "leit\u00b7stern", "mei\u00b7ner", "ruh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "$,", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Durch diese post ein k\u00fc\u00dfgen zu.", "tokens": ["Durch", "die\u00b7se", "post", "ein", "k\u00fc\u00df\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch weichet, ihr gedancken!", "tokens": ["Doch", "wei\u00b7chet", ",", "ihr", "ge\u00b7dan\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den mund vergn\u00fcgt kein eingebildter ku\u00df:", "tokens": ["Den", "mund", "ver\u00b7gn\u00fcgt", "kein", "ein\u00b7ge\u00b7bild\u00b7ter", "ku\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Jhr mehrt zuletzt nur den verdru\u00df,", "tokens": ["Ihr", "mehrt", "zu\u00b7letzt", "nur", "den", "ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und f\u00fchrt den geist noch weiter aus den schrancken.", "tokens": ["Und", "f\u00fchrt", "den", "geist", "noch", "wei\u00b7ter", "aus", "den", "schran\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADV", "APPR", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn k\u00fcsse, die zu uns durch winde kommen sind,", "tokens": ["Denn", "k\u00fcs\u00b7se", ",", "die", "zu", "uns", "durch", "win\u00b7de", "kom\u00b7men", "sind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "APPR", "PPER", "APPR", "ADJA", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sind auch sonst nichts als lauter wind.", "tokens": ["Sind", "auch", "sonst", "nichts", "als", "lau\u00b7ter", "wind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "KOKOM", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Drum flieht, ihr phantasien!", "tokens": ["Drum", "flieht", ",", "ihr", "phan\u00b7ta\u00b7si\u00b7en", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "PPER", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ein weiser sinn hengt keinen grillen nach:", "tokens": ["Ein", "wei\u00b7ser", "sinn", "hengt", "kei\u00b7nen", "gril\u00b7len", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "ADJA", "APPR", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Denn die vernunfft hei\u00dft allgemach", "tokens": ["Denn", "die", "ver\u00b7nunfft", "hei\u00dft", "all\u00b7ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der sorgen dampff vor ihrem lichte fliehen.", "tokens": ["Der", "sor\u00b7gen", "dampff", "vor", "ih\u00b7rem", "lich\u00b7te", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie zeigt, da\u00df die geduld auch bey den dornen lacht,", "tokens": ["Sie", "zeigt", ",", "da\u00df", "die", "ge\u00b7duld", "auch", "bey", "den", "dor\u00b7nen", "lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und aus den tagen stunden macht.", "tokens": ["Und", "aus", "den", "ta\u00b7gen", "stun\u00b7den", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}