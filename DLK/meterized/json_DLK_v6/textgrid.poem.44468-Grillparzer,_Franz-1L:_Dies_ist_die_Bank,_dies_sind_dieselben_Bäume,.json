{"textgrid.poem.44468": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dies ist die Bank, dies sind dieselben B\u00e4ume,", "genre": "verse", "period": "N.A.", "pub_year": 1831, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dies ist die Bank, dies sind dieselben B\u00e4ume,", "tokens": ["Dies", "ist", "die", "Bank", ",", "dies", "sind", "die\u00b7sel\u00b7ben", "B\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PDS", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo einst, das dunkle Schulbuch in der Hand,", "tokens": ["Wo", "einst", ",", "das", "dunk\u00b7le", "Schul\u00b7buch", "in", "der", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Pr\u00fcfung bang, den Kopf voll Fr\u00fchlingstr\u00e4ume,", "tokens": ["Der", "Pr\u00fc\u00b7fung", "bang", ",", "den", "Kopf", "voll", "Fr\u00fch\u00b7lings\u00b7tr\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vor manchem Jahr sich oft der Knabe fand.", "tokens": ["Vor", "man\u00b7chem", "Jahr", "sich", "oft", "der", "Kna\u00b7be", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wie er da sa\u00df, glitt von den finstern Lettern,", "tokens": ["Wie", "er", "da", "sa\u00df", ",", "glitt", "von", "den", "fins\u00b7tern", "Let\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu manchem fremden Worte schwer gef\u00fcgt,", "tokens": ["Zu", "man\u00b7chem", "frem\u00b7den", "Wor\u00b7te", "schwer", "ge\u00b7f\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Blick hinauf zu jenen frischen Bl\u00e4ttern,", "tokens": ["Der", "Blick", "hin\u00b7auf", "zu", "je\u00b7nen", "fri\u00b7schen", "Bl\u00e4t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In denen sich der Westwind spielend wiegt.", "tokens": ["In", "de\u00b7nen", "sich", "der", "West\u00b7wind", "spie\u00b7lend", "wiegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und k\u00fcnftiger Gestalten Geisterreigen", "tokens": ["Und", "k\u00fcnf\u00b7ti\u00b7ger", "Ge\u00b7stal\u00b7ten", "Geis\u00b7ter\u00b7rei\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und k\u00fcnftigen Vollbringens Sch\u00f6pferlust", "tokens": ["Und", "k\u00fcnf\u00b7ti\u00b7gen", "Voll\u00b7brin\u00b7gens", "Sch\u00f6p\u00b7fer\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erschienen ihm in jener Wipfel Neigen,", "tokens": ["Er\u00b7schie\u00b7nen", "ihm", "in", "je\u00b7ner", "Wip\u00b7fel", "Nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erklangen ihm in ahnungsvoller Brust.", "tokens": ["Er\u00b7klan\u00b7gen", "ihm", "in", "ah\u00b7nungs\u00b7vol\u00b7ler", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Es ward erf\u00fcllt das kaum gewagte Hoffen,", "tokens": ["Es", "ward", "er\u00b7f\u00fcllt", "das", "kaum", "ge\u00b7wag\u00b7te", "Hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Ahnung hielt, was sie vorhergesagt,", "tokens": ["Die", "Ah\u00b7nung", "hielt", ",", "was", "sie", "vor\u00b7her\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Des Wirkens goldne Tore stehen offen,", "tokens": ["Des", "Wir\u00b7kens", "gold\u00b7ne", "To\u00b7re", "ste\u00b7hen", "of\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Schritt gelang, ein zweiter ward gewagt.", "tokens": ["Ein", "Schritt", "ge\u00b7lang", ",", "ein", "zwei\u00b7ter", "ward", "ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und nun nach manchen Jahres Zwischenr\u00e4umen,", "tokens": ["Und", "nun", "nach", "man\u00b7chen", "Jah\u00b7res", "Zwi\u00b7schen\u00b7r\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zum Mann gereift, gewogen und erkannt,", "tokens": ["Zum", "Mann", "ge\u00b7reift", ",", "ge\u00b7wo\u00b7gen", "und", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Find ich mich wieder unter diesen B\u00e4umen,", "tokens": ["Find", "ich", "mich", "wie\u00b7der", "un\u00b7ter", "die\u00b7sen", "B\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Blick, wie damals, \u00fcber mir gewandt,", "tokens": ["Den", "Blick", ",", "wie", "da\u00b7mals", ",", "\u00fc\u00b7ber", "mir", "ge\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADV", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und Seufzer, so wie damals, schwellend heben", "tokens": ["Und", "Seuf\u00b7zer", ",", "so", "wie", "da\u00b7mals", ",", "schwel\u00b7lend", "he\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "ADV", "KOKOM", "ADV", "$,", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die m\u00fcde Brust, von mancher Sorge schwer,", "tokens": ["Die", "m\u00fc\u00b7de", "Brust", ",", "von", "man\u00b7cher", "Sor\u00b7ge", "schwer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bis auf die Tr\u00e4ne, die nicht mehr gegeben,", "tokens": ["Bis", "auf", "die", "Tr\u00e4\u00b7ne", ",", "die", "nicht", "mehr", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "$,", "PRELS", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist alles so wie damals, ringsumher.", "tokens": ["Ist", "al\u00b7les", "so", "wie", "da\u00b7mals", ",", "rings\u00b7um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "KOKOM", "ADV", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ungn\u00fcgsam Herz, warum bist du beklommen?", "tokens": ["Un\u00b7gn\u00fcg\u00b7sam", "Herz", ",", "wa\u00b7rum", "bist", "du", "be\u00b7klom\u00b7men", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "PWAV", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Was du so hei\u00df ersehnet, stehet da!", "tokens": ["Was", "du", "so", "hei\u00df", "er\u00b7seh\u00b7net", ",", "ste\u00b7het", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "VVFIN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Stunde der Erf\u00fcllung ist gekommen,", "tokens": ["Die", "Stun\u00b7de", "der", "Er\u00b7f\u00fcl\u00b7lung", "ist", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du ", "tokens": ["Du"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}}, "stanza.8": {"line.1": {"text": "Wie? oder war der bunten Bilder F\u00fclle", "tokens": ["Wie", "?", "o\u00b7der", "war", "der", "bun\u00b7ten", "Bil\u00b7der", "F\u00fcl\u00b7le"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "KON", "VAFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Inhalt nicht von dem, was du begehrt,", "tokens": ["Der", "In\u00b7halt", "nicht", "von", "dem", ",", "was", "du", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPR", "ART", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War nur der tiefern Sehnsucht \u00e4u\u00dfre H\u00fclle,", "tokens": ["War", "nur", "der", "tie\u00b7fern", "Sehn\u00b7sucht", "\u00e4u\u00df\u00b7re", "H\u00fcl\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Kleid nur dessen, was dir w\u00fcnschenswert?", "tokens": ["Das", "Kleid", "nur", "des\u00b7sen", ",", "was", "dir", "w\u00fcn\u00b7schens\u00b7wert", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PDS", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Hast Sch\u00f6nes du vielleicht gestrebt zu bilden,", "tokens": ["Hast", "Sch\u00f6\u00b7nes", "du", "viel\u00b7leicht", "ge\u00b7strebt", "zu", "bil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PPER", "ADV", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Um sch\u00f6ner dich zu f\u00fchlen selber mit?", "tokens": ["Um", "sch\u00f6\u00b7ner", "dich", "zu", "f\u00fch\u00b7len", "sel\u00b7ber", "mit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "PPER", "PTKZU", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War Schreiten in des Wissens Lichtgefilden", "tokens": ["War", "Schrei\u00b7ten", "in", "des", "Wis\u00b7sens", "Licht\u00b7ge\u00b7fil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Im Land des Wollens dir zugleich ein Schritt?", "tokens": ["Im", "Land", "des", "Wol\u00b7lens", "dir", "zu\u00b7gleich", "ein", "Schritt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Hast du vielleicht nach Ehr und Ruhm getrachtet,", "tokens": ["Hast", "du", "viel\u00b7leicht", "nach", "Ehr", "und", "Ruhm", "ge\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vermengend in Gedanken, jugendlich,", "tokens": ["Ver\u00b7men\u00b7gend", "in", "Ge\u00b7dan\u00b7ken", ",", "ju\u00b7gend\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Aug, mit dem die Welt den Mann betrachtet,", "tokens": ["Das", "Aug", ",", "mit", "dem", "die", "Welt", "den", "Mann", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und das, womit er selbst betrachtet sich?", "tokens": ["Und", "das", ",", "wo\u00b7mit", "er", "selbst", "be\u00b7trach\u00b7tet", "sich", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PWAV", "PPER", "ADV", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Schien dir die Welt mit ihren weiten Fernen", "tokens": ["Schien", "dir", "die", "Welt", "mit", "ih\u00b7ren", "wei\u00b7ten", "Fer\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Urbild, wert des Nachgebilds zu sein?", "tokens": ["Ein", "Ur\u00b7bild", ",", "wert", "des", "Nach\u00b7ge\u00b7bilds", "zu", "sein", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hast, wo sie schimmert, du getr\u00e4umt von Sternen?", "tokens": ["Hast", ",", "wo", "sie", "schim\u00b7mert", ",", "du", "ge\u00b7tr\u00e4umt", "von", "Ster\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "PPER", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von Wirklichkeit bei jedem holden Schein?", "tokens": ["Von", "Wirk\u00b7lich\u00b7keit", "bei", "je\u00b7dem", "hol\u00b7den", "Schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "O Tr\u00fcgerin von Anfang, du, o Leben!", "tokens": ["O", "Tr\u00fc\u00b7ge\u00b7rin", "von", "An\u00b7fang", ",", "du", ",", "o", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "NN", "$,", "PPER", "$,", "FM", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein reiner J\u00fcngling trat ich ein bei dir,", "tokens": ["Ein", "rei\u00b7ner", "J\u00fcng\u00b7ling", "trat", "ich", "ein", "bei", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Rein war mein Herz und rein war all mein Streben,", "tokens": ["Rein", "war", "mein", "Herz", "und", "rein", "war", "all", "mein", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "KON", "ADJD", "VAFIN", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du aber zahltest Trug und T\u00e4uschung mir daf\u00fcr.", "tokens": ["Du", "a\u00b7ber", "zahl\u00b7test", "Trug", "und", "T\u00e4u\u00b7schung", "mir", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "NN", "KON", "NN", "PPER", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Die Freundschaft sprach, mein Innres t\u00f6nte wieder,", "tokens": ["Die", "Freund\u00b7schaft", "sprach", ",", "mein", "Inn\u00b7res", "t\u00f6n\u00b7te", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir stie\u00dfen, zwei, k\u00fchn schwimmend ab vom Strand.", "tokens": ["Wir", "stie\u00b7\u00dfen", ",", "zwei", ",", "k\u00fchn", "schwim\u00b7mend", "ab", "vom", "Strand", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "CARD", "$,", "ADJD", "ADJD", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er sank, ich hielt ihn noch, er zog mich nieder", "tokens": ["Er", "sank", ",", "ich", "hielt", "ihn", "noch", ",", "er", "zog", "mich", "nie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und rettete ermattet sich ans Land.", "tokens": ["Und", "ret\u00b7te\u00b7te", "er\u00b7mat\u00b7tet", "sich", "ans", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Gewaltger regten sich geheimre Triebe,", "tokens": ["Ge\u00b7walt\u00b7ger", "reg\u00b7ten", "sich", "ge\u00b7heim\u00b7re", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein unbekanntes Sehnen wurde wach,", "tokens": ["Ein", "un\u00b7be\u00b7kann\u00b7tes", "Seh\u00b7nen", "wur\u00b7de", "wach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie nannten es, ich selber nannt es Liebe,", "tokens": ["Sie", "nann\u00b7ten", "es", ",", "ich", "sel\u00b7ber", "nannt", "es", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und einer Holden ging mein Streben nach.", "tokens": ["Und", "ei\u00b7ner", "Hol\u00b7den", "ging", "mein", "Stre\u00b7ben", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Kaum nur gesehn, kein Wort von ihr vernommen,", "tokens": ["Kaum", "nur", "ge\u00b7sehn", ",", "kein", "Wort", "von", "ihr", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "PIAT", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schien sie entstammt aus h\u00f6herm Lichtgefild,", "tokens": ["Schien", "sie", "ent\u00b7stammt", "aus", "h\u00f6\u00b7herm", "Licht\u00b7ge\u00b7fild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Durch Berg und Tal, vom innern Brand entglommen,", "tokens": ["Durch", "Berg", "und", "Tal", ",", "vom", "in\u00b7nern", "Brand", "ent\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Verfolgt ich, das mich floh, ihr holdes Bild.", "tokens": ["Ver\u00b7folgt", "ich", ",", "das", "mich", "floh", ",", "ihr", "hol\u00b7des", "Bild", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Da kam der Tag, der Schleier war zerrissen,", "tokens": ["Da", "kam", "der", "Tag", ",", "der", "Schlei\u00b7er", "war", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gemeinheit stand, wo erst ein Engel flog.", "tokens": ["Ge\u00b7mein\u00b7heit", "stand", ",", "wo", "erst", "ein", "En\u00b7gel", "flog", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sich selber tr\u00e4umte Sehnsucht, gleich Narzissen,", "tokens": ["Sich", "sel\u00b7ber", "tr\u00e4um\u00b7te", "Sehn\u00b7sucht", ",", "gleich", "Nar\u00b7zis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJA", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und starb, wie er, am Quell, der sie betrog.", "tokens": ["Und", "starb", ",", "wie", "er", ",", "am", "Quell", ",", "der", "sie", "be\u00b7trog", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "$,", "APPRART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Ein Vorhang deckt, die darauf folgt, die Stelle;", "tokens": ["Ein", "Vor\u00b7hang", "deckt", ",", "die", "da\u00b7rauf", "folgt", ",", "die", "Stel\u00b7le", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "PAV", "VVFIN", "$,", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich l\u00fcft ihn nicht, Erw\u00e4hnung schon gen\u00fcgt,", "tokens": ["Ich", "l\u00fcft", "ihn", "nicht", ",", "Er\u00b7w\u00e4h\u00b7nung", "schon", "ge\u00b7n\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Zwei Sphingen ruhn an der verborgnen Schwelle,", "tokens": ["Zwei", "Sphin\u00b7gen", "ruhn", "an", "der", "ver\u00b7borg\u00b7nen", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVINF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-----+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Das G\u00f6tterhaupt dem Tierleib angef\u00fcgt.", "tokens": ["Das", "G\u00f6t\u00b7ter\u00b7haupt", "dem", "Tier\u00b7leib", "an\u00b7ge\u00b7f\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Der Eintritt scheint zu Hoffnungen berechtigt,", "tokens": ["Der", "Ein\u00b7tritt", "scheint", "zu", "Hoff\u00b7nun\u00b7gen", "be\u00b7rech\u00b7tigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Ende w\u00e4r als Anfang gut genug,", "tokens": ["Das", "En\u00b7de", "w\u00e4r", "als", "An\u00b7fang", "gut", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "NN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch eh der Geist der Folge sich bem\u00e4chtigt,", "tokens": ["Doch", "eh", "der", "Geist", "der", "Fol\u00b7ge", "sich", "be\u00b7m\u00e4ch\u00b7tigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist auch vor\u00fcber schon der grobe Trug.", "tokens": ["Ist", "auch", "vor\u00b7\u00fc\u00b7ber", "schon", "der", "gro\u00b7be", "Trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Da fand ich sie, die nimmer mir entschwinden,", "tokens": ["Da", "fand", "ich", "sie", ",", "die", "nim\u00b7mer", "mir", "ent\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "PRELS", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sich mir ersetzen wird im Leben nie,", "tokens": ["Sich", "mir", "er\u00b7set\u00b7zen", "wird", "im", "Le\u00b7ben", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPER", "VVINF", "VAFIN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich glaubte meine Seligkeit zu finden,", "tokens": ["Ich", "glaub\u00b7te", "mei\u00b7ne", "Se\u00b7lig\u00b7keit", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und mein geheimstes Wesen rief: nur sie!", "tokens": ["Und", "mein", "ge\u00b7heims\u00b7tes", "We\u00b7sen", "rief", ":", "nur", "sie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "$.", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Gef\u00fchl, das sich in Herzensw\u00e4rme sonnte,", "tokens": ["Ge\u00b7f\u00fchl", ",", "das", "sich", "in", "Her\u00b7zens\u00b7w\u00e4r\u00b7me", "sonn\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verstand, wenngleich von G\u00fcte \u00fcberragt;", "tokens": ["Ver\u00b7stand", ",", "wenn\u00b7gleich", "von", "G\u00fc\u00b7te", "\u00fc\u00b7berr\u00b7agt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ans M\u00e4rchen grenzt, was sie f\u00fcr andre konnte,", "tokens": ["Ans", "M\u00e4r\u00b7chen", "grenzt", ",", "was", "sie", "f\u00fcr", "and\u00b7re", "konn\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PRELS", "PPER", "APPR", "PIS", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An Heilgenschein, was sie sich selbst versagt.", "tokens": ["An", "Heil\u00b7gen\u00b7schein", ",", "was", "sie", "sich", "selbst", "ver\u00b7sagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Der Zweifel, der mir schwarz oft nachgestrebet:", "tokens": ["Der", "Zwei\u00b7fel", ",", "der", "mir", "schwarz", "oft", "nach\u00b7ge\u00b7stre\u00b7bet", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ob G\u00fcte ", "tokens": ["Ob", "G\u00fc\u00b7te"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Der Mensch ist gut, ich wei\u00df es, denn sie lebet,", "tokens": ["Der", "Mensch", "ist", "gut", ",", "ich", "wei\u00df", "es", ",", "denn", "sie", "le\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PPER", "$,", "KON", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihr Herz ist B\u00fcrge mir f\u00fcr eine Welt.", "tokens": ["Ihr", "Herz", "ist", "B\u00fcr\u00b7ge", "mir", "f\u00fcr", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "In Glutumfassen st\u00fcrzten wir zusammen,", "tokens": ["In", "Glu\u00b7tum\u00b7fas\u00b7sen", "st\u00fcrz\u00b7ten", "wir", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein jeder Schlag gab Funken und gab Licht;", "tokens": ["Ein", "je\u00b7der", "Schlag", "gab", "Fun\u00b7ken", "und", "gab", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "NN", "KON", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch unzerst\u00f6rbar fanden uns die Flammen,", "tokens": ["Doch", "un\u00b7zer\u00b7st\u00f6r\u00b7bar", "fan\u00b7den", "uns", "die", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir gl\u00fchten, aber ach, wir schmolzen nicht.", "tokens": ["Wir", "gl\u00fch\u00b7ten", ",", "a\u00b7ber", "ach", ",", "wir", "schmol\u00b7zen", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Ich war ein Ganzes und auch sie war ganz,", "tokens": ["Ich", "war", "ein", "Gan\u00b7zes", "und", "auch", "sie", "war", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "ADV", "PPER", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie wollte gern ihr tiefstes Wesen lassen,", "tokens": ["Sie", "woll\u00b7te", "gern", "ihr", "tiefs\u00b7tes", "We\u00b7sen", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch allzufest geschlungen war der Kranz.", "tokens": ["Doch", "all\u00b7zu\u00b7fest", "ge\u00b7schlun\u00b7gen", "war", "der", "Kranz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "So standen beide, suchten sich zu einen,", "tokens": ["So", "stan\u00b7den", "bei\u00b7de", ",", "such\u00b7ten", "sich", "zu", "ei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "VVFIN", "PRF", "APPR", "ART", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das andre aufzunehmen ganz in sich,", "tokens": ["Das", "and\u00b7re", "auf\u00b7zu\u00b7neh\u00b7men", "ganz", "in", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVIZU", "ADV", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch all umsonst, trotz Ringen, St\u00fcrmen, Weinen,", "tokens": ["Doch", "all", "um\u00b7sonst", ",", "trotz", "Rin\u00b7gen", ",", "St\u00fcr\u00b7men", ",", "Wei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PIAT", "ADV", "$,", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie blieb ein Weib, und ich war immer ich.", "tokens": ["Sie", "blieb", "ein", "Weib", ",", "und", "ich", "war", "im\u00b7mer", "ich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "PPER", "VAFIN", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Ja, bis zum Grimme ward erh\u00f6ht das M\u00fchen,", "tokens": ["Ja", ",", "bis", "zum", "Grim\u00b7me", "ward", "er\u00b7h\u00f6ht", "das", "M\u00fc\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "APPRART", "NN", "VAFIN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gesucht im Einzeln, was im Ganzen lag,", "tokens": ["Ge\u00b7sucht", "im", "Ein\u00b7zeln", ",", "was", "im", "Gan\u00b7zen", "lag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kein Fehler ward, kein Wort ward mehr verziehen,", "tokens": ["Kein", "Feh\u00b7ler", "ward", ",", "kein", "Wort", "ward", "mehr", "ver\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$,", "PIAT", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und neues Qu\u00e4len brachte jeder Tag.", "tokens": ["Und", "neu\u00b7es", "Qu\u00e4\u00b7len", "brach\u00b7te", "je\u00b7der", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Da ward ich hart. Im ewgen Spiel der Winde,", "tokens": ["Da", "ward", "ich", "hart", ".", "Im", "ew\u00b7gen", "Spiel", "der", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$.", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Wettersturm, von Sonne nie durchblickt,", "tokens": ["Im", "Wet\u00b7ter\u00b7sturm", ",", "von", "Son\u00b7ne", "nie", "durch\u00b7blickt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Umzog das st\u00e4rkre B\u00e4umchen sich mit Rinde,", "tokens": ["Um\u00b7zog", "das", "st\u00e4r\u00b7kre", "B\u00e4um\u00b7chen", "sich", "mit", "Rin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das schw\u00e4chre neigte sich und war zerknickt.", "tokens": ["Das", "schw\u00e4ch\u00b7re", "neig\u00b7te", "sich", "und", "war", "zer\u00b7knickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "PRF", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "O seliges Gef\u00fchl der ersten Tage,", "tokens": ["O", "se\u00b7li\u00b7ges", "Ge\u00b7f\u00fchl", "der", "ers\u00b7ten", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Warum mu\u00dft du ein Traum gewesen sein?", "tokens": ["Wa\u00b7rum", "mu\u00dft", "du", "ein", "Traum", "ge\u00b7we\u00b7sen", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "VAPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Lebt denn das Sch\u00f6ne nur in Bild und Sage,", "tokens": ["Lebt", "denn", "das", "Sch\u00f6\u00b7ne", "nur", "in", "Bild", "und", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schl\u00fcrfts die Wirklichkeit wie Nebel ein?", "tokens": ["Und", "schl\u00fcrfts", "die", "Wirk\u00b7lich\u00b7keit", "wie", "Ne\u00b7bel", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KOKOM", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Auch dort nicht heimatlos in Bild und Worte,", "tokens": ["Auch", "dort", "nicht", "hei\u00b7mat\u00b7los", "in", "Bild", "und", "Wor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Floh ich, dem meerbedr\u00e4ngten Schiffer gleich,", "tokens": ["Floh", "ich", ",", "dem", "meer\u00b7be\u00b7dr\u00e4ng\u00b7ten", "Schif\u00b7fer", "gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sooft den St\u00fcrmen aufgetan die Pforte,", "tokens": ["Sooft", "den", "St\u00fcr\u00b7men", "auf\u00b7ge\u00b7tan", "die", "Pfor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "In jenes Hafens sch\u00fctzenden Bereich.", "tokens": ["In", "je\u00b7nes", "Ha\u00b7fens", "sch\u00fct\u00b7zen\u00b7den", "Be\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Gelagert in dem Dufte fremder Kr\u00e4uter,", "tokens": ["Ge\u00b7la\u00b7gert", "in", "dem", "Duf\u00b7te", "frem\u00b7der", "Kr\u00e4u\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Umspielt von fremder Wipfel leisem Wehn,", "tokens": ["Um\u00b7spielt", "von", "frem\u00b7der", "Wip\u00b7fel", "lei\u00b7sem", "Wehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sah ich im Traum die hohe Himmelsleiter,", "tokens": ["Sah", "ich", "im", "Traum", "die", "ho\u00b7he", "Him\u00b7mels\u00b7lei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An der die Geister ab- und aufw\u00e4rts gehn.", "tokens": ["An", "der", "die", "Geis\u00b7ter", "ab", "und", "auf\u00b7w\u00e4rts", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "TRUNC", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Und angeregt, sie selber zu besteigen,", "tokens": ["Und", "an\u00b7ge\u00b7regt", ",", "sie", "sel\u00b7ber", "zu", "be\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Umherzuschauen in dem weiten Raum,", "tokens": ["Um\u00b7her\u00b7zu\u00b7schau\u00b7en", "in", "dem", "wei\u00b7ten", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Versucht ich, r\u00fcckgekehrt, es anzuzeigen,", "tokens": ["Ver\u00b7sucht", "ich", ",", "r\u00fcck\u00b7ge\u00b7kehrt", ",", "es", "an\u00b7zu\u00b7zei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "$,", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was ich gesehn, halb Wahrheit und halb Traum.", "tokens": ["Was", "ich", "ge\u00b7sehn", ",", "halb", "Wahr\u00b7heit", "und", "halb", "Traum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "ADJD", "NN", "KON", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "\u00bbden Armen, dem sich ab ein Gott gewendet,", "tokens": ["\u00bb", "den", "Ar\u00b7men", ",", "dem", "sich", "ab", "ein", "Gott", "ge\u00b7wen\u00b7det", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Dichters blendend, trauriges Geschick,", "tokens": ["Des", "Dich\u00b7ters", "blen\u00b7dend", ",", "trau\u00b7ri\u00b7ges", "Ge\u00b7schick", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie das Gem\u00fct im eignen Abgrund endet,", "tokens": ["Wie", "das", "Ge\u00b7m\u00fct", "im", "eig\u00b7nen", "Ab\u00b7grund", "en\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Erdengr\u00f6\u00dfe schnellverwelktes Gl\u00fcck.\u00ab", "tokens": ["Der", "Er\u00b7den\u00b7gr\u00f6\u00b7\u00dfe", "schnell\u00b7ver\u00b7welk\u00b7tes", "Gl\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Und flammend gab ich das Geschaute wieder,", "tokens": ["Und", "flam\u00b7mend", "gab", "ich", "das", "Ge\u00b7schau\u00b7te", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der H\u00f6rer, ob auch kalt, entging mir nicht,", "tokens": ["Der", "H\u00f6\u00b7rer", ",", "ob", "auch", "kalt", ",", "ent\u00b7ging", "mir", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "ADV", "ADJD", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Denn Lebenspulsschlag zog durch meine Lieder,", "tokens": ["Denn", "Le\u00b7bens\u00b7puls\u00b7schlag", "zog", "durch", "mei\u00b7ne", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wahr, wie mein Gef\u00fchl, war mein Gedicht.", "tokens": ["Und", "wahr", ",", "wie", "mein", "Ge\u00b7f\u00fchl", ",", "war", "mein", "Ge\u00b7dicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOKOM", "PPOSAT", "NN", "$,", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Vorahnend durft ich zu den Gro\u00dfen sagen,", "tokens": ["Vor\u00b7ah\u00b7nend", "durft", "ich", "zu", "den", "Gro\u00b7\u00dfen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die l\u00e4ngst umwallt der Ruhm wie Opferrauch:", "tokens": ["Die", "l\u00e4ngst", "um\u00b7wallt", "der", "Ruhm", "wie", "Op\u00b7fer\u00b7rauch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "ART", "NN", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So hoch als euch mag mich kein Fl\u00fcgel tragen,", "tokens": ["So", "hoch", "als", "euch", "mag", "mich", "kein", "Fl\u00fc\u00b7gel", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch, Meister, schaut! ein Maler bin ich auch.", "tokens": ["Doch", ",", "Meis\u00b7ter", ",", "schaut", "!", "ein", "Ma\u00b7ler", "bin", "ich", "auch", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "VVFIN", "$.", "ART", "NN", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Da kam die N\u00fcchternheit in ihrer Bl\u00f6\u00dfe,", "tokens": ["Da", "kam", "die", "N\u00fcch\u00b7tern\u00b7heit", "in", "ih\u00b7rer", "Bl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die gro\u00df sich d\u00fcnkt, weil hohl sie zwar, doch weit;", "tokens": ["Die", "gro\u00df", "sich", "d\u00fcnkt", ",", "weil", "hohl", "sie", "zwar", ",", "doch", "weit", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "VVFIN", "$,", "KOUS", "ADJD", "PPER", "ADV", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nach Ellen ma\u00df sie meiner Menschen Gr\u00f6\u00dfe,", "tokens": ["Nach", "El\u00b7len", "ma\u00df", "sie", "mei\u00b7ner", "Men\u00b7schen", "Gr\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach Pfund und Lot der Stoffe H\u00e4ltigkeit.", "tokens": ["Nach", "Pfund", "und", "Lot", "der", "Stof\u00b7fe", "H\u00e4l\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Doch kann die Formel Leben je bereiten?", "tokens": ["Doch", "kann", "die", "For\u00b7mel", "Le\u00b7ben", "je", "be\u00b7rei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Was ungeheuer, ist darum nicht gro\u00df.", "tokens": ["Was", "un\u00b7ge\u00b7heu\u00b7er", ",", "ist", "da\u00b7rum", "nicht", "gro\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "$,", "VAFIN", "PAV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein M\u00f6gliches ragt \u00fcber alle Weiten,", "tokens": ["Ein", "M\u00f6g\u00b7li\u00b7ches", "ragt", "\u00fc\u00b7ber", "al\u00b7le", "Wei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Wirkliche zeigt sich im Raume blo\u00df.", "tokens": ["Das", "Wirk\u00b7li\u00b7che", "zeigt", "sich", "im", "Rau\u00b7me", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPRART", "NN", "ADV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.36": {"line.1": {"text": "Wo tausend Tinten meine Blicke sp\u00fcrten,", "tokens": ["Wo", "tau\u00b7send", "Tin\u00b7ten", "mei\u00b7ne", "Bli\u00b7cke", "sp\u00fcr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "CARD", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da sah der Stumpfsinn schroffes Gr\u00fcn und Blau,", "tokens": ["Da", "sah", "der", "Stumpf\u00b7sinn", "schrof\u00b7fes", "Gr\u00fcn", "und", "Blau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo R\u00e4tsel mich zu neuen R\u00e4tseln f\u00fchrten,", "tokens": ["Wo", "R\u00e4t\u00b7sel", "mich", "zu", "neu\u00b7en", "R\u00e4t\u00b7seln", "f\u00fchr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da wu\u00dften sie die L\u00f6sung ganz genau.", "tokens": ["Da", "wu\u00df\u00b7ten", "sie", "die", "L\u00f6\u00b7sung", "ganz", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "War eine Wiese, wo ich Blumen pfl\u00fcckte,", "tokens": ["War", "ei\u00b7ne", "Wie\u00b7se", ",", "wo", "ich", "Blu\u00b7men", "pfl\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Rinderzucht drauf hingetrieben frisch!", "tokens": ["Die", "Rin\u00b7der\u00b7zucht", "drauf", "hin\u00b7ge\u00b7trie\u00b7ben", "frisch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo nur ihr Fu\u00dftritt in den Boden dr\u00fcckte,", "tokens": ["Wo", "nur", "ihr", "Fu\u00df\u00b7tritt", "in", "den", "Bo\u00b7den", "dr\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Lag Schlamm und Gras in ekligem Gemisch.", "tokens": ["Lag", "Schlamm", "und", "Gras", "in", "ek\u00b7li\u00b7gem", "Ge\u00b7misch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Was nicht zu sagen, davon ging die Rede,", "tokens": ["Was", "nicht", "zu", "sa\u00b7gen", ",", "da\u00b7von", "ging", "die", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "PTKZU", "VVINF", "$,", "PAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Was auszusprechen nicht, das sprach ihr Wort;", "tokens": ["Was", "aus\u00b7zu\u00b7spre\u00b7chen", "nicht", ",", "das", "sprach", "ihr", "Wort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVIZU", "PTKNEG", "$,", "PDS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verschm\u00e4hst du ihre Waffen auch zur Fehde,", "tokens": ["Ver\u00b7schm\u00e4hst", "du", "ih\u00b7re", "Waf\u00b7fen", "auch", "zur", "Feh\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schon Unsinn ists, zu w\u00e4hlen ihren Ort.", "tokens": ["Schon", "Un\u00b7sinn", "ists", ",", "zu", "w\u00e4h\u00b7len", "ih\u00b7ren", "Ort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "$,", "PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Gestalten, die mein Geist in Glut umfangen,", "tokens": ["Ge\u00b7stal\u00b7ten", ",", "die", "mein", "Geist", "in", "Glut", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Roheit legte dran die schmutzge Hand,", "tokens": ["Die", "Ro\u00b7heit", "leg\u00b7te", "dran", "die", "schmutz\u00b7ge", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich sah die Spur auf den entweihten Wangen,", "tokens": ["Ich", "sah", "die", "Spur", "auf", "den", "ent\u00b7weih\u00b7ten", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und mein Gem\u00fct, es f\u00fchlte sich entwandt.", "tokens": ["Und", "mein", "Ge\u00b7m\u00fct", ",", "es", "f\u00fchl\u00b7te", "sich", "ent\u00b7wandt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Und wie der Mensch den Ort, den sch\u00f6nsten, werten,", "tokens": ["Und", "wie", "der", "Mensch", "den", "Ort", ",", "den", "sch\u00f6ns\u00b7ten", ",", "wer\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht mehr betritt, wenn Gr\u00e4ulichs ihn betrat,", "tokens": ["Nicht", "mehr", "be\u00b7tritt", ",", "wenn", "Gr\u00e4u\u00b7lichs", "ihn", "be\u00b7trat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "$,", "KOUS", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So floh mein Geist aus meiner Jugend G\u00e4rten,", "tokens": ["So", "floh", "mein", "Geist", "aus", "mei\u00b7ner", "Ju\u00b7gend", "G\u00e4r\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Emp\u00f6rt von seines Heiligsten Verrat.", "tokens": ["Em\u00b7p\u00f6rt", "von", "sei\u00b7nes", "Hei\u00b7ligs\u00b7ten", "Ver\u00b7rat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+---+", "measure": "zehnsilber"}}, "stanza.41": {"line.1": {"text": "Hart hinterher der Mi\u00dfgunst lange Zeile,", "tokens": ["Hart", "hin\u00b7ter\u00b7her", "der", "Mi\u00df\u00b7gunst", "lan\u00b7ge", "Zei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Neid, der Ha\u00df, bewaffnet anzusehn,", "tokens": ["Der", "Neid", ",", "der", "Ha\u00df", ",", "be\u00b7waff\u00b7net", "an\u00b7zu\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit dopplem Eindruck trafen ihre Pfeile,", "tokens": ["Mit", "dopp\u00b7lem", "Ein\u00b7druck", "tra\u00b7fen", "ih\u00b7re", "Pfei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn, ach, wer singt, kann nicht im Harnisch gehn;", "tokens": ["Denn", ",", "ach", ",", "wer", "singt", ",", "kann", "nicht", "im", "Har\u00b7nisch", "gehn", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ITJ", "$,", "PWS", "VVFIN", "$,", "VMFIN", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "Und stellt er ihnen sich, die nach ihm zielen,", "tokens": ["Und", "stellt", "er", "ih\u00b7nen", "sich", ",", "die", "nach", "ihm", "zie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PRF", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ergreift des Streites zorniges Ger\u00e4t,", "tokens": ["Er\u00b7greift", "des", "Strei\u00b7tes", "zor\u00b7ni\u00b7ges", "Ge\u00b7r\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der schwere Panzer dr\u00fccket harte Schwielen,", "tokens": ["Der", "schwe\u00b7re", "Pan\u00b7zer", "dr\u00fc\u00b7cket", "har\u00b7te", "Schwie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Drob des Empfindens weicher Sinn entgeht.", "tokens": ["Drob", "des", "Emp\u00b7fin\u00b7dens", "wei\u00b7cher", "Sinn", "ent\u00b7geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "So floh ich aus des Kampfes Glutbeschwerde", "tokens": ["So", "floh", "ich", "aus", "des", "Kamp\u00b7fes", "Glut\u00b7be\u00b7schwer\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hin zur Natur, wo Leben neu sich schafft,", "tokens": ["Hin", "zur", "Na\u00b7tur", ",", "wo", "Le\u00b7ben", "neu", "sich", "schafft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "PWAV", "NN", "ADJD", "PRF", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Den Busen dr\u00fcckt ich an die Mutter Erde,", "tokens": ["Den", "Bu\u00b7sen", "dr\u00fcckt", "ich", "an", "die", "Mut\u00b7ter", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Um, wie Ant\u00e4us, zu erstehn in Kraft.", "tokens": ["Um", ",", "wie", "An\u00b7t\u00e4us", ",", "zu", "er\u00b7stehn", "in", "Kraft", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "$,", "PWAV", "NE", "$,", "PTKZU", "VVINF", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.44": {"line.1": {"text": "Doch sie, die oft gef\u00fchrt schon meine Sache,", "tokens": ["Doch", "sie", ",", "die", "oft", "ge\u00b7f\u00fchrt", "schon", "mei\u00b7ne", "Sa\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PRELS", "ADV", "VVPP", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Getr\u00f6stet mich so oft und gern zuvor,", "tokens": ["Ge\u00b7tr\u00f6s\u00b7tet", "mich", "so", "oft", "und", "gern", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "ADV", "ADV", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verloren hatte sie f\u00fcr mich die Sprache,", "tokens": ["Ver\u00b7lo\u00b7ren", "hat\u00b7te", "sie", "f\u00fcr", "mich", "die", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Sprache, oder ich f\u00fcr sie das Ohr.", "tokens": ["Die", "Spra\u00b7che", ",", "o\u00b7der", "ich", "f\u00fcr", "sie", "das", "Ohr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PPER", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Gelehrig sonst an ihrer frommen Seite,", "tokens": ["Ge\u00b7leh\u00b7rig", "sonst", "an", "ih\u00b7rer", "from\u00b7men", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schien jetzt nur trotzig Schaffen mir Gewinn,", "tokens": ["Schien", "jetzt", "nur", "trot\u00b7zig", "Schaf\u00b7fen", "mir", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADJD", "NN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihr Wort verklang in meines Busens Weite,", "tokens": ["Ihr", "Wort", "ver\u00b7klang", "in", "mei\u00b7nes", "Bu\u00b7sens", "Wei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihr Wink verschwand vor meinem stumpfen Sinn.", "tokens": ["Ihr", "Wink", "ver\u00b7schwand", "vor", "mei\u00b7nem", "stump\u00b7fen", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "Und schaudernd vor der Welt und ihrem Treiben,", "tokens": ["Und", "schau\u00b7dernd", "vor", "der", "Welt", "und", "ih\u00b7rem", "Trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein jedes Band verschm\u00e4hend, das sie flicht,", "tokens": ["Ein", "je\u00b7des", "Band", "ver\u00b7schm\u00e4\u00b7hend", ",", "das", "sie", "flicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mocht ichs nicht leben, konnt ichs nicht beschreiben,", "tokens": ["Mocht", "ichs", "nicht", "le\u00b7ben", ",", "konnt", "ichs", "nicht", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKNEG", "VVINF", "$,", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Und selbst den Anblick fast ertragen nicht.", "tokens": ["Und", "selbst", "den", "An\u00b7blick", "fast", "er\u00b7tra\u00b7gen", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "VVINF", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.47": {"line.1": {"text": "Ja, horchend auf des Innern leise Zungen,", "tokens": ["Ja", ",", "hor\u00b7chend", "auf", "des", "In\u00b7nern", "lei\u00b7se", "Zun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Erschaudert mein Gem\u00fct, wenn es ihm d\u00e4ucht,", "tokens": ["Er\u00b7schau\u00b7dert", "mein", "Ge\u00b7m\u00fct", ",", "wenn", "es", "ihm", "d\u00e4ucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es kling ein Ton, den T\u00f6nen nachgeklungen,", "tokens": ["Es", "kling", "ein", "Ton", ",", "den", "T\u00f6\u00b7nen", "nach\u00b7ge\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit denen das Gemeine mich verscheucht.", "tokens": ["Mit", "de\u00b7nen", "das", "Ge\u00b7mei\u00b7ne", "mich", "ver\u00b7scheucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "Und also sitz ich an derselben St\u00e4tte,", "tokens": ["Und", "al\u00b7so", "sitz", "ich", "an", "der\u00b7sel\u00b7ben", "St\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVIMP", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo schon der Knabe tr\u00e4umte, sa\u00df und sann.", "tokens": ["Wo", "schon", "der", "Kna\u00b7be", "tr\u00e4um\u00b7te", ",", "sa\u00df", "und", "sann", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn erst ich das Verlorne wieder h\u00e4tte,", "tokens": ["Wenn", "erst", "ich", "das", "Ver\u00b7lor\u00b7ne", "wie\u00b7der", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ART", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie g\u00e4b ich gern, was ich seitdem gewann.", "tokens": ["Wie", "g\u00e4b", "ich", "gern", ",", "was", "ich", "seit\u00b7dem", "ge\u00b7wann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}