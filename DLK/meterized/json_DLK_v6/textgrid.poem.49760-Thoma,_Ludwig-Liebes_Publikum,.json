{"textgrid.poem.49760": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Liebes Publikum,", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zehn Jahre sind gewi\u00df kein hohes,", "tokens": ["Zehn", "Jah\u00b7re", "sind", "ge\u00b7wi\u00df", "kein", "ho\u00b7hes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ADV", "PIAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Alter nicht f\u00fcr mich und Sie.", "tokens": ["Kein", "Al\u00b7ter", "nicht", "f\u00fcr", "mich", "und", "Sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKNEG", "APPR", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch ist's nicht wenig f\u00fcr ein rohes", "tokens": ["Doch", "ist's", "nicht", "we\u00b7nig", "f\u00fcr", "ein", "ro\u00b7hes"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und schwer gepr\u00fcftes Hundevieh.", "tokens": ["Und", "schwer", "ge\u00b7pr\u00fcf\u00b7tes", "Hun\u00b7de\u00b7vieh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Drum kommt nur her zum Gratulieren!", "tokens": ["Drum", "kommt", "nur", "her", "zum", "Gra\u00b7tu\u00b7lie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es bildet ja kein Hindernis,", "tokens": ["Es", "bil\u00b7det", "ja", "kein", "Hin\u00b7der\u00b7nis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es wird euch alle nicht schenieren,", "tokens": ["Es", "wird", "euch", "al\u00b7le", "nicht", "sche\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df euch das Luder \u00f6fter bi\u00df??", "tokens": ["Da\u00df", "euch", "das", "Lu\u00b7der", "\u00f6f\u00b7ter", "bi\u00df", "??"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Geehrtes Fr\u00e4ulein, Ihre Gaben", "tokens": ["Ge\u00b7ehr\u00b7tes", "Fr\u00e4u\u00b7lein", ",", "Ih\u00b7re", "Ga\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erfreuen das gemeine Biest,", "tokens": ["Er\u00b7freu\u00b7en", "das", "ge\u00b7mei\u00b7ne", "Biest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sollt' er Sie mal beleidigt haben,", "tokens": ["Sollt'", "er", "Sie", "mal", "be\u00b7lei\u00b7digt", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So hoff' ich, da\u00df Sie's nicht verdrie\u00dft.", "tokens": ["So", "hoff'", "ich", ",", "da\u00df", "Sie's", "nicht", "ver\u00b7drie\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "PTKNEG", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Herr Staatsanwalt?! Sie sind ein Schmeichler!", "tokens": ["Herr", "Staats\u00b7an\u00b7walt", "?!", "Sie", "sind", "ein", "Schmeich\u00b7ler", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn nur kein Arg dahinter steckt!", "tokens": ["Wenn", "nur", "kein", "Arg", "da\u00b7hin\u00b7ter", "steckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie w\u00fcnschen doch, Sie kleiner Heuchler,", "tokens": ["Sie", "w\u00fcn\u00b7schen", "doch", ",", "Sie", "klei\u00b7ner", "Heuch\u00b7ler", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df unser Hundchen bald verreckt?!", "tokens": ["Da\u00df", "un\u00b7ser", "Hund\u00b7chen", "bald", "ver\u00b7reckt", "?!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Na ja, nun schweigen Sie mal stille!", "tokens": ["Na", "ja", ",", "nun", "schwei\u00b7gen", "Sie", "mal", "stil\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "$,", "ADV", "VVFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Anstand hat es keine Spur.", "tokens": ["Von", "An\u00b7stand", "hat", "es", "kei\u00b7ne", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gewi\u00df! Doch ist es Gottes Wille,", "tokens": ["Ge\u00b7wi\u00df", "!", "Doch", "ist", "es", "Got\u00b7tes", "Wil\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "KON", "VAFIN", "PPER", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er schuf auch diese Kreatur.", "tokens": ["Er", "schuf", "auch", "die\u00b7se", "Kre\u00b7a\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Herr Pfarrer auch! Und \u2013 Stillgestanden!", "tokens": ["Herr", "Pfar\u00b7rer", "auch", "!", "Und", "\u2013", "Still\u00b7ge\u00b7stan\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "ADV", "$.", "KON", "$(", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jetzt pr\u00e4sentiert mir das Gewehr!", "tokens": ["Jetzt", "pr\u00e4\u00b7sen\u00b7tiert", "mir", "das", "Ge\u00b7wehr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Hoheit uns f\u00fcr w\u00fcrdig fanden,", "tokens": ["Da\u00df", "Ho\u00b7heit", "uns", "f\u00fcr", "w\u00fcr\u00b7dig", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist wirklich unverdiente Ehr'!", "tokens": ["Ist", "wirk\u00b7lich", "un\u00b7ver\u00b7dien\u00b7te", "Ehr'", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ach, da\u00df kein Groll uns l\u00e4nger trenne,", "tokens": ["Ach", ",", "da\u00df", "kein", "Groll", "uns", "l\u00e4n\u00b7ger", "tren\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KOUS", "PIAT", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gelobt' ich gerne frommen Geist,", "tokens": ["Ge\u00b7lobt'", "ich", "ger\u00b7ne", "from\u00b7men", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch wie ich dieses Hundsvieh kenne,", "tokens": ["Doch", "wie", "ich", "die\u00b7ses", "Hunds\u00b7vieh", "ken\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hilft alles nichts. Das Luder bei\u00dft.", "tokens": ["Hilft", "al\u00b7les", "nichts", ".", "Das", "Lu\u00b7der", "bei\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIS", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}