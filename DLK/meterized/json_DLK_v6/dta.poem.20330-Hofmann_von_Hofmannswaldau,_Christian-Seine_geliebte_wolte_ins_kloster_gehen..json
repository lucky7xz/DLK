{"dta.poem.20330": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Seine geliebte wolte ins kloster  \n gehen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Lisippe will der erden sich entreissen/", "tokens": ["Li\u00b7sip\u00b7pe", "will", "der", "er\u00b7den", "sich", "en\u00b7treis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ART", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihr edler geist geht zu der ruh/", "tokens": ["Ihr", "ed\u00b7ler", "geist", "geht", "zu", "der", "ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er eilt der reinen sonnen zu/", "tokens": ["Er", "eilt", "der", "rei\u00b7nen", "son\u00b7nen", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und will/ was himmlisch ist/ zu k\u00fcssen sich befleissen/", "tokens": ["Und", "will", "/", "was", "himm\u00b7lisch", "ist", "/", "zu", "k\u00fcs\u00b7sen", "sich", "be\u00b7fleis\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$(", "PWS", "ADJD", "VAFIN", "$(", "PTKZU", "VVINF", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie st\u00f6st die erde hin/ und suchet allzu viel/", "tokens": ["Sie", "st\u00f6st", "die", "er\u00b7de", "hin", "/", "und", "su\u00b7chet", "all\u00b7zu", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$(", "KON", "VVFIN", "PTKA", "PIS", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weil sie bey fleisch und blut als engel leben will.", "tokens": ["Weil", "sie", "bey", "fleisch", "und", "blut", "als", "en\u00b7gel", "le\u00b7ben", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJD", "KON", "NN", "KOUS", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Schau doch zuvor ein wenig noch zur\u00fccke/", "tokens": ["Schau", "doch", "zu\u00b7vor", "ein", "we\u00b7nig", "noch", "zu\u00b7r\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "PIS", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Entlauff dir doch nicht vor der zeit;", "tokens": ["Ent\u00b7lauff", "dir", "doch", "nicht", "vor", "der", "zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der sch\u00f6nen augen z\u00e4rtlichkeit", "tokens": ["Der", "sch\u00f6\u00b7nen", "au\u00b7gen", "z\u00e4rt\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vertr\u00e4get nicht so bald die heissen sonnen-blicke.", "tokens": ["Ver\u00b7tr\u00e4\u00b7get", "nicht", "so", "bald", "die", "heis\u00b7sen", "son\u00b7nen\u00b7bli\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du kanst nicht Enoch seyn/ noch des Elias art/", "tokens": ["Du", "kanst", "nicht", "E\u00b7noch", "seyn", "/", "noch", "des", "E\u00b7lias", "art", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "VAINF", "$(", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-++--", "measure": "unknown.measure.penta"}, "line.6": {"text": "Und ehe man verstirbt/ wird keine himmelfahrt.", "tokens": ["Und", "e\u00b7he", "man", "ver\u00b7stirbt", "/", "wird", "kei\u00b7ne", "him\u00b7mel\u00b7fahrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "$(", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Mit was hat doch die erde dich verletzet/", "tokens": ["Mit", "was", "hat", "doch", "die", "er\u00b7de", "dich", "ver\u00b7let\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VAFIN", "ADV", "ART", "NN", "PPER", "VVFIN", "$("], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Du st\u00fcrmest wider fleisch und blut/", "tokens": ["Du", "st\u00fcr\u00b7mest", "wi\u00b7der", "fleisch", "und", "blut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich wei\u00df nicht/ was Lisippe thut/", "tokens": ["Ich", "wei\u00df", "nicht", "/", "was", "Li\u00b7sip\u00b7pe", "thut", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PWS", "NE", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die aller regung sich verwegen widersetzet.", "tokens": ["Die", "al\u00b7ler", "re\u00b7gung", "sich", "ver\u00b7we\u00b7gen", "wi\u00b7der\u00b7set\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer mit sich selber kriegt/ und sich zu schlagen tracht/", "tokens": ["Wer", "mit", "sich", "sel\u00b7ber", "kriegt", "/", "und", "sich", "zu", "schla\u00b7gen", "tracht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PRF", "ADV", "VVFIN", "$(", "KON", "PRF", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vor diesen hat der sieg die krone nicht erdacht.", "tokens": ["Vor", "die\u00b7sen", "hat", "der", "sieg", "die", "kro\u00b7ne", "nicht", "er\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "ART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Du bist zu schwer/ der erden zu entfliehen/", "tokens": ["Du", "bist", "zu", "schwer", "/", "der", "er\u00b7den", "zu", "ent\u00b7flie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$(", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du kanst noch kein gestirne seyn.", "tokens": ["Du", "kanst", "noch", "kein", "ge\u00b7stir\u00b7ne", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Komm/ sammle freudens-blumen ein/", "tokens": ["Komm", "/", "samm\u00b7le", "freu\u00b7den\u00b7sblu\u00b7men", "ein", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die dir als dienerin itzt selbst entgegen ziehen.", "tokens": ["Die", "dir", "als", "die\u00b7ne\u00b7rin", "itzt", "selbst", "ent\u00b7ge\u00b7gen", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOUS", "NN", "ADV", "ADV", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer ungezwungen ihm das marterthum begehrt/", "tokens": ["Wer", "un\u00b7ge\u00b7zwun\u00b7gen", "ihm", "das", "mar\u00b7ter\u00b7thum", "be\u00b7gehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist der erbarmung zwar/ doch keines ruhmes werth.", "tokens": ["Ist", "der", "er\u00b7bar\u00b7mung", "zwar", "/", "doch", "kei\u00b7nes", "ruh\u00b7mes", "werth", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "$(", "ADV", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Lisippe la\u00df die pr\u00e4chtigen gedancken/", "tokens": ["Li\u00b7sip\u00b7pe", "la\u00df", "die", "pr\u00e4ch\u00b7ti\u00b7gen", "ge\u00b7dan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kein mensch verengelt sich doch nicht;", "tokens": ["Kein", "mensch", "ver\u00b7en\u00b7gelt", "sich", "doch", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vernimm was deine jugend spricht/", "tokens": ["Ver\u00b7nimm", "was", "dei\u00b7ne", "ju\u00b7gend", "spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PWS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schreit itzt nicht so bald aus deinen freuden-schrancken/", "tokens": ["Und", "schreit", "itzt", "nicht", "so", "bald", "aus", "dei\u00b7nen", "freu\u00b7den\u00b7schran\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da tausend lieblichkeit auff s\u00fcsse spiele denckt/", "tokens": ["Da", "tau\u00b7send", "lieb\u00b7lich\u00b7keit", "auff", "s\u00fcs\u00b7se", "spie\u00b7le", "denckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lust-rubinen dir zu deinem schmucke schenckt.", "tokens": ["Und", "lust\u00b7ru\u00b7bi\u00b7nen", "dir", "zu", "dei\u00b7nem", "schmu\u00b7cke", "schenckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "PPER", "APPR", "PPOSAT", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Geneu\u00df doch noch der welt ambrirte fr\u00fcchte/", "tokens": ["Ge\u00b7neu\u00df", "doch", "noch", "der", "welt", "am\u00b7br\u00b7ir\u00b7te", "fr\u00fcch\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NN", "VVFIN", "ADJA", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der himmel bleibt dir unversagt.", "tokens": ["Der", "him\u00b7mel", "bleibt", "dir", "un\u00b7ver\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer allzu k\u00fchn zur sonne jagt/", "tokens": ["Wer", "all\u00b7zu", "k\u00fchn", "zur", "son\u00b7ne", "jagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKA", "ADJD", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den macht ein scharffer strahl den heissen flug zunichte.", "tokens": ["Den", "macht", "ein", "scharf\u00b7fer", "strahl", "den", "heis\u00b7sen", "flug", "zu\u00b7nich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mensch und auch engel hat uns zeitlich kund gethan/", "tokens": ["Mensch", "und", "auch", "en\u00b7gel", "hat", "uns", "zeit\u00b7lich", "kund", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "NE", "VAFIN", "PPER", "ADJD", "PTKVZ", "VVPP", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Da\u00df man im paradie\u00df und himmel fallen kan.", "tokens": ["Da\u00df", "man", "im", "pa\u00b7ra\u00b7die\u00df", "und", "him\u00b7mel", "fal\u00b7len", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}