{"textgrid.poem.39344": {"metadata": {"author": {"name": "Lavater, Johann Kaspar", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie? darf ich meinen Blick erheben?", "genre": "verse", "period": "N.A.", "pub_year": 1801, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie? darf ich meinen Blick erheben?", "tokens": ["Wie", "?", "darf", "ich", "mei\u00b7nen", "Blick", "er\u00b7he\u00b7ben", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Soll ich mit Freuden oder Beben", "tokens": ["Soll", "ich", "mit", "Freu\u00b7den", "o\u00b7der", "Be\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beginnen, o Jahrhundert, dich?", "tokens": ["Be\u00b7gin\u00b7nen", ",", "o", "Jahr\u00b7hun\u00b7dert", ",", "dich", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "FM", "NN", "$,", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Hoffens m\u00fcde, darf ich's wagen,", "tokens": ["Des", "Hof\u00b7fens", "m\u00fc\u00b7de", ",", "darf", "ich's", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von Hoffnung noch ein Wort zu sagen?", "tokens": ["Von", "Hoff\u00b7nung", "noch", "ein", "Wort", "zu", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wer lehret \u00e4chte Weisheit mich?", "tokens": ["Wer", "leh\u00b7ret", "\u00e4ch\u00b7te", "Weis\u00b7heit", "mich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADJA", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach, da\u00df ich Hoffnungsquellen f\u00e4nde!", "tokens": ["Ach", ",", "da\u00df", "ich", "Hoff\u00b7nungs\u00b7quel\u00b7len", "f\u00e4n\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch, wohin ich mein Auge wende,", "tokens": ["Doch", ",", "wo\u00b7hin", "ich", "mein", "Au\u00b7ge", "wen\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erblick ich keiner Hoffnung Spur ...", "tokens": ["Er\u00b7blick", "ich", "kei\u00b7ner", "Hoff\u00b7nung", "Spur", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIAT", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer darf mir: \u00bbHier ist Ausweg!\u00ab winken?", "tokens": ["Wer", "darf", "mir", ":", "\u00bb", "Hier", "ist", "Aus\u00b7weg", "!", "\u00ab", "win\u00b7ken", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "$.", "$(", "ADV", "VAFIN", "NN", "$.", "$(", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich seh' zur Rechten und zur Linken", "tokens": ["Ich", "seh'", "zur", "Rech\u00b7ten", "und", "zur", "Lin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nur Elend, Gram, Zerr\u00fctung nur.", "tokens": ["Nur", "E\u00b7lend", ",", "Gram", ",", "Zer\u00b7r\u00fc\u00b7tung", "nur", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "$,", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Jahrhundert, das wir heut begr\u00fc\u00dfen,", "tokens": ["Jahr\u00b7hun\u00b7dert", ",", "das", "wir", "heut", "be\u00b7gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Soll dir die Freudenz\u00e4hre flie\u00dfen?", "tokens": ["Soll", "dir", "die", "Freu\u00b7den\u00b7z\u00e4h\u00b7re", "flie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was wirst du meinen Kindern seyn?", "tokens": ["Was", "wirst", "du", "mei\u00b7nen", "Kin\u00b7dern", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird bald der Thorheit hier auf Erden,", "tokens": ["Wird", "bald", "der", "Thor\u00b7heit", "hier", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Des Elends bald ein Ende werden?", "tokens": ["Des", "E\u00b7lends", "bald", "ein", "En\u00b7de", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Des Lebens werden wir uns freu'n?", "tokens": ["Des", "Le\u00b7bens", "wer\u00b7den", "wir", "uns", "freu'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Kommst du mit kornerf\u00fcllten Halmen?", "tokens": ["Kommst", "du", "mit", "kor\u00b7ner\u00b7f\u00fcll\u00b7ten", "Hal\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kommst du, in deiner Rechten Palmen?", "tokens": ["Kommst", "du", ",", "in", "dei\u00b7ner", "Rech\u00b7ten", "Pal\u00b7men", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie? oder mit entbl\u00f6\u00dftem Schwerdt?", "tokens": ["Wie", "?", "o\u00b7der", "mit", "ent\u00b7bl\u00f6\u00df\u00b7tem", "Schwerdt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verwandelst Felder du in Anger?", "tokens": ["Ver\u00b7wan\u00b7delst", "Fel\u00b7der", "du", "in", "An\u00b7ger", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kommst du, mit neuen Greueln schwanger?", "tokens": ["Kommst", "du", ",", "mit", "neu\u00b7en", "Greu\u00b7eln", "schwan\u00b7ger", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Mord-Jahrhundert, das verheert?", "tokens": ["Ein", "Mord\u00b7Jahr\u00b7hun\u00b7dert", ",", "das", "ver\u00b7heert", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie, oder \u2013 kommst du sch\u00f6n geschm\u00fccket", "tokens": ["Wie", ",", "o\u00b7der", "\u2013", "kommst", "du", "sch\u00f6n", "ge\u00b7schm\u00fc\u00b7cket"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KON", "$(", "VVFIN", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Gott, mit Allem, was begl\u00fccket,", "tokens": ["Von", "Gott", ",", "mit", "Al\u00b7lem", ",", "was", "be\u00b7gl\u00fc\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "PIS", "$,", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was edle Seelen hoch erfreut?", "tokens": ["Was", "ed\u00b7le", "See\u00b7len", "hoch", "er\u00b7freut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ehrst du, was stets die Weisheit ehrte?", "tokens": ["Ehrst", "du", ",", "was", "stets", "die", "Weis\u00b7heit", "ehr\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Lehrst du, was kein Jahrhundert lehrte,", "tokens": ["Lehrst", "du", ",", "was", "kein", "Jahr\u00b7hun\u00b7dert", "lehr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Menschen endlich \u2013 Menschlichkeit?", "tokens": ["Die", "Men\u00b7schen", "end\u00b7lich", "\u2013", "Menschlich\u00b7keit", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Kommst du, zur Freude meiner Br\u00fcder,", "tokens": ["Kommst", "du", ",", "zur", "Freu\u00b7de", "mei\u00b7ner", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Voll Lieblichkeit vom Himmel nieder,", "tokens": ["Voll", "Lieb\u00b7lich\u00b7keit", "vom", "Him\u00b7mel", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit milder, segensvoller Hand?", "tokens": ["Mit", "mil\u00b7der", ",", "se\u00b7gens\u00b7vol\u00b7ler", "Hand", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wirst du uns freier athmen lassen?", "tokens": ["Wirst", "du", "uns", "frei\u00b7er", "ath\u00b7men", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wird Lieb' und Eintracht uns umfassen?", "tokens": ["Wird", "Lieb'", "und", "Ein\u00b7tracht", "uns", "um\u00b7fas\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird endlich frei mein Vaterland?", "tokens": ["Wird", "end\u00b7lich", "frei", "mein", "Va\u00b7ter\u00b7land", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Erwach' mit neubelebten Sinnen,", "tokens": ["Er\u00b7wach'", "mit", "neu\u00b7be\u00b7leb\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jahrhundert, das wir heut beginnen,", "tokens": ["Jahr\u00b7hun\u00b7dert", ",", "das", "wir", "heut", "be\u00b7gin\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und lern', was das Verschwundne lehrt!", "tokens": ["Und", "lern'", ",", "was", "das", "Ver\u00b7schwund\u00b7ne", "lehrt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O baue, kannst du's, weislich wieder,", "tokens": ["O", "bau\u00b7e", ",", "kannst", "du's", ",", "weis\u00b7lich", "wie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VMFIN", "PIS", "$,", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was das, was vorgieng, ri\u00df hernieder;", "tokens": ["Was", "das", ",", "was", "vor\u00b7gieng", ",", "ri\u00df", "her\u00b7nie\u00b7der", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PDS", "$,", "PWS", "VVFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sey kein Jahrhundert, das zerst\u00f6rt!", "tokens": ["Sey", "kein", "Jahr\u00b7hun\u00b7dert", ",", "das", "zer\u00b7st\u00f6rt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,", "PRELS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und willst du, mu\u00dft du je zerst\u00f6ren,", "tokens": ["Und", "willst", "du", ",", "mu\u00dft", "du", "je", "zer\u00b7st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zerst\u00f6re nicht mit Kriegesheeren,", "tokens": ["Zer\u00b7st\u00f6\u00b7re", "nicht", "mit", "Krie\u00b7ges\u00b7hee\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zerst\u00f6r' durch Gutes B\u00f6ses nur!", "tokens": ["Zer\u00b7st\u00f6r'", "durch", "Gu\u00b7tes", "B\u00f6\u00b7ses", "nur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "NE", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zerst\u00f6r' durch weise Geistesst\u00e4rke", "tokens": ["Zer\u00b7st\u00f6r'", "durch", "wei\u00b7se", "Geis\u00b7tes\u00b7st\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Bosheit hochgepriesne Werke,", "tokens": ["Der", "Bos\u00b7heit", "hoch\u00b7ge\u00b7pri\u00b7es\u00b7ne", "Wer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Von Tiranney die kleinste Spur!", "tokens": ["Von", "Ti\u00b7ran\u00b7ney", "die", "kleins\u00b7te", "Spur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Verg\u00f6tt're nicht der Menschheit Schanden,", "tokens": ["Ver\u00b7g\u00f6tt'\u00b7re", "nicht", "der", "Menschheit", "Schan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die sich zu Raub und Mord verbanden,", "tokens": ["Die", "sich", "zu", "Raub", "und", "Mord", "ver\u00b7ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und dann von Recht und Freiheit schrey'n!", "tokens": ["Und", "dann", "von", "Recht", "und", "Frei\u00b7heit", "schrey'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verehre tapfre Rechtsverehrer,", "tokens": ["Ver\u00b7eh\u00b7re", "tapf\u00b7re", "Rechts\u00b7ver\u00b7eh\u00b7rer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Des Unrechts muthige Zerst\u00f6rer,", "tokens": ["Des", "Un\u00b7rechts", "mut\u00b7hi\u00b7ge", "Zer\u00b7st\u00f6\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und deine Freude sey erfreu'n!", "tokens": ["Und", "dei\u00b7ne", "Freu\u00b7de", "sey", "er\u00b7freu'n", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Religion und Lust an allen", "tokens": ["Re\u00b7li\u00b7gi\u00b7on", "und", "Lust", "an", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "PIAT"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Bem\u00fchungen, die Gott gefallen,", "tokens": ["Be\u00b7m\u00fc\u00b7hun\u00b7gen", ",", "die", "Gott", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Sey t\u00e4glich aller Freude mehr!", "tokens": ["Sey", "t\u00e4g\u00b7lich", "al\u00b7ler", "Freu\u00b7de", "mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein voriges Jahrhundert gleiche", "tokens": ["Kein", "vo\u00b7ri\u00b7ges", "Jahr\u00b7hun\u00b7dert", "glei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dem nun begonnenen! Es weiche", "tokens": ["Dem", "nun", "be\u00b7gon\u00b7ne\u00b7nen", "!", "Es", "wei\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ADV", "VVINF", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zum Abgrund aller Laster Heer!", "tokens": ["Zum", "Ab\u00b7grund", "al\u00b7ler", "Las\u00b7ter", "Heer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Nur Menschlichkeit und Pflichttreu' rathen,", "tokens": ["Nur", "Menschlich\u00b7keit", "und", "Pflicht\u00b7treu'", "ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und Demuth kr\u00f6ne unsre Thaten!", "tokens": ["Und", "De\u00b7muth", "kr\u00f6\u00b7ne", "uns\u00b7re", "Tha\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bei'm Anfang la\u00dft auf's End uns seh'n!", "tokens": ["Bei'm", "An\u00b7fang", "la\u00dft", "auf's", "End", "uns", "seh'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Zeiten schwinden. La\u00dft uns h\u00f6ren,", "tokens": ["Die", "Zei\u00b7ten", "schwin\u00b7den", ".", "La\u00dft", "uns", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "VVIMP", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was die verschwundnen Zeiten lehren", "tokens": ["Was", "die", "ver\u00b7schwund\u00b7nen", "Zei\u00b7ten", "leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und nur der Weisheit Pfade geh'n!", "tokens": ["Und", "nur", "der", "Weis\u00b7heit", "Pfa\u00b7de", "geh'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Schwebt nicht in hohen Idealen,", "tokens": ["Schwebt", "nicht", "in", "ho\u00b7hen", "I\u00b7dea\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Die euch nur goldne Zeiten mahlen,", "tokens": ["Die", "euch", "nur", "gold\u00b7ne", "Zei\u00b7ten", "mah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bei'm Wachsthum von Vernunft und Licht.", "tokens": ["Bei'm", "Wach\u00b7sthum", "von", "Ver\u00b7nunft", "und", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es wird der Adams S\u00f6hne keiner", "tokens": ["Es", "wird", "der", "A\u00b7dams", "S\u00f6h\u00b7ne", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Durch rednersche Dekrete reiner,", "tokens": ["Durch", "red\u00b7ner\u00b7sche", "De\u00b7kre\u00b7te", "rei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gebieten l\u00e4\u00dft sich Tugend nicht.", "tokens": ["Ge\u00b7bie\u00b7ten", "l\u00e4\u00dft", "sich", "Tu\u00b7gend", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "O fordert nicht Unm\u00f6glichkeiten", "tokens": ["O", "for\u00b7dert", "nicht", "Un\u00b7m\u00f6g\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Menschen, die von allen Seiten", "tokens": ["Von", "Men\u00b7schen", ",", "die", "von", "al\u00b7len", "Sei\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Begierlichkeit zu Sklaven macht.", "tokens": ["Be\u00b7gier\u00b7lich\u00b7keit", "zu", "Skla\u00b7ven", "macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer will ohn' Adlers Aug' und Schwingen,", "tokens": ["Wer", "will", "ohn'", "Ad\u00b7lers", "Aug'", "und", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dem Adler gleich, zur Sonne dringen?", "tokens": ["Dem", "Ad\u00b7ler", "gleich", ",", "zur", "Son\u00b7ne", "drin\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist der nicht Thor, des Jeder lacht?", "tokens": ["Ist", "der", "nicht", "Thor", ",", "des", "Je\u00b7der", "lacht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PTKNEG", "NN", "$,", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "O V\u00e4ter, M\u00fctter, S\u00f6hne, T\u00f6chter,", "tokens": ["O", "V\u00e4\u00b7ter", ",", "M\u00fct\u00b7ter", ",", "S\u00f6h\u00b7ne", ",", "T\u00f6ch\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vernehmt mich, k\u00fcnftige Geschlechter!", "tokens": ["Ver\u00b7nehmt", "mich", ",", "k\u00fcnf\u00b7ti\u00b7ge", "Ge\u00b7schlech\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht wegvern\u00fcnftelt Ruh' und Gl\u00fcck!", "tokens": ["Nicht", "weg\u00b7ver\u00b7n\u00fcnf\u00b7telt", "Ruh'", "und", "Gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erfahrung lehr' euch weise werden;", "tokens": ["Er\u00b7fah\u00b7rung", "lehr'", "euch", "wei\u00b7se", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vollkommenheit ist nicht auf Erden.", "tokens": ["Voll\u00b7kom\u00b7men\u00b7heit", "ist", "nicht", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ertr\u00e4umt sie, und ihr sinkt zur\u00fcck!", "tokens": ["Er\u00b7tr\u00e4umt", "sie", ",", "und", "ihr", "sinkt", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Was helfen Freiheits-Heucheleyen?", "tokens": ["Was", "hel\u00b7fen", "Frei\u00b7heits\u00b7Heu\u00b7che\u00b7leyen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was n\u00fctzen Franken-\u00c4ffereyen?", "tokens": ["Was", "n\u00fct\u00b7zen", "Fran\u00b7ken\u00b7\u00c4f\u00b7fe\u00b7reyen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was frommt's, wenn man der Armuth lacht?", "tokens": ["Was", "frommt's", ",", "wenn", "man", "der", "Ar\u00b7muth", "lacht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer ehrt Geschw\u00e4tz von Treu' und Glauben,", "tokens": ["Wer", "ehrt", "Ge\u00b7schw\u00e4tz", "von", "Treu'", "und", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn man ein nie erh\u00f6rtes Rauben", "tokens": ["Wenn", "man", "ein", "nie", "er\u00b7h\u00f6r\u00b7tes", "Rau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gesetzlos zum Gesetze macht?", "tokens": ["Ge\u00b7setz\u00b7los", "zum", "Ge\u00b7set\u00b7ze", "macht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Gerechtigkeit! Erwache wieder!", "tokens": ["Ge\u00b7rech\u00b7tig\u00b7keit", "!", "Er\u00b7wa\u00b7che", "wie\u00b7der", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Komm' Friede, von den Himmeln nieder!", "tokens": ["Komm'", "Frie\u00b7de", ",", "von", "den", "Him\u00b7meln", "nie\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O! Sitten-Einfalt, kehr zur\u00fcck!", "tokens": ["O", "!", "Sit\u00b7ten\u00b7Ein\u00b7falt", ",", "kehr", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was Menschen-Namen tr\u00e4gt, das lebe", "tokens": ["Was", "Men\u00b7schen\u00b7Na\u00b7men", "tr\u00e4gt", ",", "das", "le\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "NN", "VVFIN", "$,", "PDS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr Wahrheit, Tugend nur, und strebe", "tokens": ["F\u00fcr", "Wahr\u00b7heit", ",", "Tu\u00b7gend", "nur", ",", "und", "stre\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "ADV", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Edelsinn nach \u00e4chtem Gl\u00fcck.", "tokens": ["Durch", "E\u00b7del\u00b7sinn", "nach", "\u00e4ch\u00b7tem", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ihr schon ge\u00fcbten Tugendehrer,", "tokens": ["Ihr", "schon", "ge\u00b7\u00fcb\u00b7ten", "Tu\u00b7gen\u00b7deh\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Seyd durch das Beispiel Tugendlehrer!", "tokens": ["Seyd", "durch", "das", "Bei\u00b7spiel", "Tu\u00b7gend\u00b7leh\u00b7rer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "APPR", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erregt zum Rechtthun Herzenslust;", "tokens": ["Er\u00b7regt", "zum", "Recht\u00b7thun", "Her\u00b7zens\u00b7lust", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zertretet, wie vorworfne Schlangen,", "tokens": ["Zer\u00b7tre\u00b7tet", ",", "wie", "vor\u00b7worf\u00b7ne", "Schlan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Herrschsucht leisestes Verlangen,", "tokens": ["Der", "Herrschsucht", "lei\u00b7ses\u00b7tes", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der H\u00e4rte Funken in der Brust!", "tokens": ["Der", "H\u00e4r\u00b7te", "Fun\u00b7ken", "in", "der", "Brust", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Uns m\u00fcssen keine Namen blenden,", "tokens": ["Uns", "m\u00fcs\u00b7sen", "kei\u00b7ne", "Na\u00b7men", "blen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kein drohend Wort uns Schrecken senden!", "tokens": ["Kein", "dro\u00b7hend", "Wort", "uns", "Schre\u00b7cken", "sen\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "NN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vor uns erschrecke Tiranney!", "tokens": ["Vor", "uns", "er\u00b7schre\u00b7cke", "Ti\u00b7ran\u00b7ney", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Matron' und Greis und Mann und Jugend,", "tokens": ["Ma\u00b7tron'", "und", "Greis", "und", "Mann", "und", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Erfahre t\u00e4glich, da\u00df nur Tugend", "tokens": ["Er\u00b7fah\u00b7re", "t\u00e4g\u00b7lich", ",", "da\u00df", "nur", "Tu\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "$,", "KOUS", "ADV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Quell von Daseyns Freude sey!", "tokens": ["Der", "Quell", "von", "Da\u00b7seyns", "Freu\u00b7de", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Nach Selbstveredlung stetes Streben,", "tokens": ["Nach", "Selbst\u00b7ve\u00b7red\u00b7lung", "ste\u00b7tes", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Religion ist wahres Leben;", "tokens": ["Re\u00b7li\u00b7gi\u00b7on", "ist", "wah\u00b7res", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sagt, was gedieh je ohne sie?", "tokens": ["Sagt", ",", "was", "ge\u00b7dieh", "je", "oh\u00b7ne", "sie", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "VVFIN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Macht sie nicht alles Dunkle helle?", "tokens": ["Macht", "sie", "nicht", "al\u00b7les", "Dunk\u00b7le", "hel\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "PIAT", "ADJA", "ADJA", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Ist sie nicht jeder Tugend Quelle?", "tokens": ["Ist", "sie", "nicht", "je\u00b7der", "Tu\u00b7gend", "Quel\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist, wo sie rein ist, Unrecht je?", "tokens": ["Ist", ",", "wo", "sie", "rein", "ist", ",", "Un\u00b7recht", "je", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$,", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Voll dieses Lustgef\u00fchls betrete,", "tokens": ["Voll", "die\u00b7ses", "Lust\u00b7ge\u00b7f\u00fchls", "be\u00b7tre\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jahrhundert, ich dich nun, und bete", "tokens": ["Jahr\u00b7hun\u00b7dert", ",", "ich", "dich", "nun", ",", "und", "be\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PPER", "PRF", "ADV", "$,", "KON", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Den Gott, der keine Zeit kennt, an!", "tokens": ["Den", "Gott", ",", "der", "kei\u00b7ne", "Zeit", "kennt", ",", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und flehe muthvoll: Deinen Willen,", "tokens": ["Und", "fle\u00b7he", "muth\u00b7voll", ":", "Dei\u00b7nen", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O lehre, Vater, mich erf\u00fcllen;", "tokens": ["O", "leh\u00b7re", ",", "Va\u00b7ter", ",", "mich", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "NN", "$,", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "O f\u00fchre mich der Wahrheit Bahn!", "tokens": ["O", "f\u00fch\u00b7re", "mich", "der", "Wahr\u00b7heit", "Bahn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Ich flehe Tag und Nacht, ich flehe,", "tokens": ["Ich", "fle\u00b7he", "Tag", "und", "Nacht", ",", "ich", "fle\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bis deine Vaterhand ich sehe,", "tokens": ["Bis", "dei\u00b7ne", "Va\u00b7ter\u00b7hand", "ich", "se\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr mein gebundnes Vaterland.", "tokens": ["F\u00fcr", "mein", "ge\u00b7bund\u00b7nes", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In welche Tiefen, welche N\u00e4chte", "tokens": ["In", "wel\u00b7che", "Tie\u00b7fen", ",", "wel\u00b7che", "N\u00e4ch\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PWAT", "NN", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Versenkten H\u00f6hner aller Rechte,", "tokens": ["Ver\u00b7senk\u00b7ten", "H\u00f6h\u00b7ner", "al\u00b7ler", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Versenkt' uns Stolz und Unverstand!", "tokens": ["Ver\u00b7senkt'", "uns", "Stolz", "und", "Un\u00b7ver\u00b7stand", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Schau huldreich, segnend auf uns nieder,", "tokens": ["Schau", "huld\u00b7reich", ",", "seg\u00b7nend", "auf", "uns", "nie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "ADJD", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vereine mit den Br\u00fcdern Br\u00fcder!", "tokens": ["Ver\u00b7ei\u00b7ne", "mit", "den", "Br\u00fc\u00b7dern", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es herrsche Fried' und Biederkeit!", "tokens": ["Es", "herr\u00b7sche", "Fried'", "und", "Bie\u00b7der\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O send' uns leuchtende Gedanken!", "tokens": ["O", "send'", "uns", "leuch\u00b7ten\u00b7de", "Ge\u00b7dan\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00df' Keinen je im Treusinn wanken!", "tokens": ["La\u00df'", "Kei\u00b7nen", "je", "im", "Treu\u00b7sinn", "wan\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bei'm Recht sey Unerschrockenheit!", "tokens": ["Bei'm", "Recht", "sey", "Un\u00b7er\u00b7schro\u00b7cken\u00b7heit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Sey nicht ein strenger Unschuld-R\u00e4cher;", "tokens": ["Sey", "nicht", "ein", "stren\u00b7ger", "Un\u00b7schuld\u00b7R\u00e4\u00b7cher", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch, schweigen mach' die frechen Sprecher", "tokens": ["Doch", ",", "schwei\u00b7gen", "mach'", "die", "fre\u00b7chen", "Spre\u00b7cher"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADJA", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Voll Rachsucht, Stolz und Bitterkeit.", "tokens": ["Voll", "Rach\u00b7sucht", ",", "Stolz", "und", "Bit\u00b7ter\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Err\u00f6then m\u00fcssen und erblassen", "tokens": ["Er\u00b7r\u00f6\u00b7then", "m\u00fcs\u00b7sen", "und", "er\u00b7blas\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VMFIN", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie Alle, die die Wahrheit hassen,", "tokens": ["Sie", "Al\u00b7le", ",", "die", "die", "Wahr\u00b7heit", "has\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und bied're Herzens-Offenheit.", "tokens": ["Und", "bie\u00b7d'\u00b7re", "Her\u00b7zens\u00b7Of\u00b7fen\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "La\u00df' reife Weisheit wiederkehren,", "tokens": ["La\u00df'", "rei\u00b7fe", "Weis\u00b7heit", "wie\u00b7der\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df' lernen uns, was du willst lehren,", "tokens": ["La\u00df'", "ler\u00b7nen", "uns", ",", "was", "du", "willst", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "PPER", "$,", "PWS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erst Treue, dann Bescheidenheit,", "tokens": ["Erst", "Treu\u00b7e", ",", "dann", "Be\u00b7schei\u00b7den\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Lust an n\u00fctzlicher Belehrung,", "tokens": ["Und", "Lust", "an", "n\u00fctz\u00b7li\u00b7cher", "Be\u00b7leh\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "An Wahrheit, Lieb' und Pflichtverehrung,", "tokens": ["An", "Wahr\u00b7heit", ",", "Lieb'", "und", "Pflicht\u00b7ver\u00b7eh\u00b7rung", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und heiliger Gerechtigkeit!", "tokens": ["Und", "hei\u00b7li\u00b7ger", "Ge\u00b7rech\u00b7tig\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "O Menschenvater in dem Himmel,", "tokens": ["O", "Men\u00b7schen\u00b7va\u00b7ter", "in", "dem", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bei'm leidenschaftlichen Get\u00fcmmel", "tokens": ["Bei'm", "lei\u00b7den\u00b7schaft\u00b7li\u00b7chen", "Ge\u00b7t\u00fcm\u00b7mel"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Freiheitsrufer, taumeln wir", "tokens": ["Der", "Frei\u00b7heits\u00b7ru\u00b7fer", ",", "tau\u00b7meln", "wir"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Unrecht, Jammer und Verbrechen.", "tokens": ["In", "Un\u00b7recht", ",", "Jam\u00b7mer", "und", "Ver\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00df' nur Vernunft und Tugend sprechen,", "tokens": ["La\u00df'", "nur", "Ver\u00b7nunft", "und", "Tu\u00b7gend", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Ehrfurcht vor dem Recht und Dir!", "tokens": ["Und", "Ehr\u00b7furcht", "vor", "dem", "Recht", "und", "Dir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "KON", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Gott, ich erhebe Herz und H\u00e4nde:", "tokens": ["Gott", ",", "ich", "er\u00b7he\u00b7be", "Herz", "und", "H\u00e4n\u00b7de", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Mach' unserm Elend bald ein Ende!", "tokens": ["Mach'", "un\u00b7serm", "E\u00b7lend", "bald", "ein", "En\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erwecke demuthvolles Fleh'n!", "tokens": ["Er\u00b7we\u00b7cke", "de\u00b7muth\u00b7vol\u00b7les", "Fleh'n", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Erwecke viel Nathanaele,", "tokens": ["Er\u00b7we\u00b7cke", "viel", "Na\u00b7tha\u00b7nae\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Hiskias, Davids, Samuele,", "tokens": ["His\u00b7ki\u00b7as", ",", "Da\u00b7vids", ",", "Sa\u00b7mu\u00b7e\u00b7le", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Die vor den Ri\u00df als Helden steh'n.", "tokens": ["Die", "vor", "den", "Ri\u00df", "als", "Hel\u00b7den", "steh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "APPR", "ART", "NN", "KOUS", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Erwecke selbst aus unserm Schoo\u00dfe", "tokens": ["Er\u00b7we\u00b7cke", "selbst", "aus", "un\u00b7serm", "Schoo\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bew\u00e4hrte, weise, edle, gro\u00dfe,", "tokens": ["Be\u00b7w\u00e4hr\u00b7te", ",", "wei\u00b7se", ",", "ed\u00b7le", ",", "gro\u00b7\u00dfe", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "ADJA", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erhabne Helden, die nichts scheu'n!", "tokens": ["Er\u00b7hab\u00b7ne", "Hel\u00b7den", ",", "die", "nichts", "scheu'n", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die unser Gl\u00fcck im Herzen tragen,", "tokens": ["Die", "un\u00b7ser", "Gl\u00fcck", "im", "Her\u00b7zen", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr sich nichts suchen, alles wagen,", "tokens": ["F\u00fcr", "sich", "nichts", "su\u00b7chen", ",", "al\u00b7les", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PRF", "PIS", "VVINF", "$,", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Um Stifter unsers Heils zu seyn.", "tokens": ["Um", "Stif\u00b7ter", "un\u00b7sers", "Heils", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "PPOSAT", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Erquicke Witwen, Waisen, Kranke!", "tokens": ["Er\u00b7qui\u00b7cke", "Wit\u00b7wen", ",", "Wai\u00b7sen", ",", "Kran\u00b7ke", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erweck' den Gl\u00fccklichen zum Danke,", "tokens": ["Er\u00b7weck'", "den", "Gl\u00fcck\u00b7li\u00b7chen", "zum", "Dan\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "APPRART", "PTKANT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gieb Tugendfreunden Heldenmuth!", "tokens": ["Gieb", "Tu\u00b7gend\u00b7freun\u00b7den", "Hel\u00b7den\u00b7muth", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entlarve Heuchler! Straf die Frechen,", "tokens": ["Ent\u00b7lar\u00b7ve", "Heuch\u00b7ler", "!", "Straf", "die", "Fre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verhind're Laster und Verbrechen,", "tokens": ["Ver\u00b7hin\u00b7d'\u00b7re", "Las\u00b7ter", "und", "Ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und zeige dich den Guten gut!", "tokens": ["Und", "zei\u00b7ge", "dich", "den", "Gu\u00b7ten", "gut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Den Tausenden, die nach Dir weinen,", "tokens": ["Den", "Tau\u00b7sen\u00b7den", ",", "die", "nach", "Dir", "wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df' Hoffnung auf dein Reich erscheinen,", "tokens": ["La\u00df'", "Hoff\u00b7nung", "auf", "dein", "Reich", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Liebe, Freude, Wahrheit ist!", "tokens": ["Das", "Lie\u00b7be", ",", "Freu\u00b7de", ",", "Wahr\u00b7heit", "ist", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O m\u00f6chte nie das Laster siegen,", "tokens": ["O", "m\u00f6ch\u00b7te", "nie", "das", "Las\u00b7ter", "sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nie Recht und Unschuld unterliegen,", "tokens": ["Nie", "Recht", "und", "Un\u00b7schuld", "un\u00b7ter\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und fern seyn Herrschsucht, Trug und List.", "tokens": ["Und", "fern", "seyn", "Herrschsucht", ",", "Trug", "und", "List", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.30": {"line.1": {"text": "So will ich flehen. Fleht vereinigt,", "tokens": ["So", "will", "ich", "fle\u00b7hen", ".", "Fleht", "ver\u00b7ei\u00b7nigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$.", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wen Vaterlandes Elend peinigt!", "tokens": ["Wen", "Va\u00b7ter\u00b7lan\u00b7des", "E\u00b7lend", "pei\u00b7nigt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00dft muthvoll uns zum Vater seh'n;", "tokens": ["La\u00dft", "muth\u00b7voll", "uns", "zum", "Va\u00b7ter", "seh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VMFIN", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erfleht, ihr Reichen und ihr Armen,", "tokens": ["Er\u00b7fleht", ",", "ihr", "Rei\u00b7chen", "und", "ihr", "Ar\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Des Himmels segnendes Erbarmen.", "tokens": ["Des", "Him\u00b7mels", "seg\u00b7nen\u00b7des", "Er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gott h\u00f6rt mit Lust vereintes Fleh'n.", "tokens": ["Gott", "h\u00f6rt", "mit", "Lust", "ver\u00b7ein\u00b7tes", "Fleh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["NN", "VVFIN", "APPR", "NN", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Nur fromme Demuth kann uns retten", "tokens": ["Nur", "from\u00b7me", "De\u00b7muth", "kann", "uns", "ret\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Von allen Lasten, allen Ketten;", "tokens": ["Von", "al\u00b7len", "Las\u00b7ten", ",", "al\u00b7len", "Ket\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur treuer Sinn macht froh und frei.", "tokens": ["Nur", "treu\u00b7er", "Sinn", "macht", "froh", "und", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum Himmel von der Erde wallen.", "tokens": ["Zum", "Him\u00b7mel", "von", "der", "Er\u00b7de", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Erwirbt uns Gottes Wohlgefallen,", "tokens": ["Er\u00b7wirbt", "uns", "Got\u00b7tes", "Wohl\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und ruft das Reich des Herrn herbei.", "tokens": ["Und", "ruft", "das", "Reich", "des", "Herrn", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Reich Gottes! Sehnsucht aller Frommen!", "tokens": ["Reich", "Got\u00b7tes", "!", "Sehn\u00b7sucht", "al\u00b7ler", "From\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wirst du mit dem Jahrhundert kommen?", "tokens": ["Wirst", "du", "mit", "dem", "Jahr\u00b7hun\u00b7dert", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "O fleht: \u00bbEs komm!\u00ab wer flehen kann.", "tokens": ["O", "fleht", ":", "\u00bb", "Es", "komm", "!", "\u00ab", "wer", "fle\u00b7hen", "kann", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "$(", "PPER", "VVFIN", "$.", "$(", "PWS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm weiche Laster, Wahn und Leiden!", "tokens": ["Ihm", "wei\u00b7che", "Las\u00b7ter", ",", "Wahn", "und", "Lei\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es kommt mit gr\u00e4nzenlosen Freuden!", "tokens": ["Es", "kommt", "mit", "gr\u00e4n\u00b7zen\u00b7lo\u00b7sen", "Freu\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Macht ihm, durch fromme Demuth, Bahn!", "tokens": ["Macht", "ihm", ",", "durch", "from\u00b7me", "De\u00b7muth", ",", "Bahn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}