{"dta.poem.23799": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Vergebliche Sorgen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Weicht eitle Grille\u0303 weicht/ ihr kr\u00e4ncket nur die Sin\u0303en/", "tokens": ["Weicht", "eit\u00b7le", "Grill\u1ebd", "weicht", "/", "ihr", "kr\u00e4n\u00b7cket", "nur", "die", "Si\u00f1en", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$(", "PPER", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihr schw\u00e4chet die Vernunft/ und schrecket das", "tokens": ["Ihr", "schw\u00e4\u00b7chet", "die", "Ver\u00b7nunft", "/", "und", "schre\u00b7cket", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "KON", "VVFIN", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Abgrund weiset ihr/ und H\u00fclffe wi\u00dft ihr nicht/", "tokens": ["Den", "Ab\u00b7grund", "wei\u00b7set", "ihr", "/", "und", "H\u00fclf\u00b7fe", "wi\u00dft", "ihr", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$(", "KON", "NN", "VVFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr schaffet M\u00fch und Schwei\u00df und k\u00f6nt doch nichts ge-", "tokens": ["Ihr", "schaf\u00b7fet", "M\u00fch", "und", "Schwei\u00df", "und", "k\u00f6nt", "doch", "nichts", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "KON", "VVFIN", "ADV", "PIS", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ihr \u00f6fnet uns die Bahn zum zeitigen Verderben/", "tokens": ["Ihr", "\u00f6f\u00b7net", "uns", "die", "Bahn", "zum", "zei\u00b7ti\u00b7gen", "Ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und macht das Leben schon in erster Bl\u00fcthe sterben!", "tokens": ["Und", "macht", "das", "Le\u00b7ben", "schon", "in", "ers\u00b7ter", "Bl\u00fc\u00b7the", "ster\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was noch geschehen soll/ das h\u00e4lt uns GOtt verborgen/", "tokens": ["Was", "noch", "ge\u00b7sche\u00b7hen", "soll", "/", "das", "h\u00e4lt", "uns", "Gott", "ver\u00b7bor\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVINF", "VMFIN", "$(", "PDS", "VVFIN", "PPER", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er wei\u00df/ ein schlimmes heut\u2019 ist an sich selber schwer;", "tokens": ["Er", "wei\u00df", "/", "ein", "schlim\u00b7mes", "heut'", "ist", "an", "sich", "sel\u00b7ber", "schwer", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "ADJA", "ADV", "VAFIN", "APPR", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir aber holen uns noch neue Dornen her/", "tokens": ["Wir", "a\u00b7ber", "ho\u00b7len", "uns", "noch", "neu\u00b7e", "Dor\u00b7nen", "her", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als w\u00e4r\u2019 es nicht genug f\u00fcr jeden Tag zu sorgen;", "tokens": ["Als", "w\u00e4r'", "es", "nicht", "ge\u00b7nug", "f\u00fcr", "je\u00b7den", "Tag", "zu", "sor\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir sincken schon aus Furcht des k\u00fcnftigen zur Erden/", "tokens": ["Wir", "sin\u00b7cken", "schon", "aus", "Furcht", "des", "k\u00fcnf\u00b7ti\u00b7gen", "zur", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "ART", "ADJA", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das nie gewesen ist/ nicht ist/ und nicht kan werden.", "tokens": ["Das", "nie", "ge\u00b7we\u00b7sen", "ist", "/", "nicht", "ist", "/", "und", "nicht", "kan", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAPP", "VAFIN", "$(", "PTKNEG", "VAFIN", "$(", "KON", "PTKNEG", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Warum verlangen wir in stetem Gl\u00fcck zu weyden/", "tokens": ["Wa\u00b7rum", "ver\u00b7lan\u00b7gen", "wir", "in", "ste\u00b7tem", "Gl\u00fcck", "zu", "wey\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und w\u00fcndschen was vorhin kein Sterblicher gethan?", "tokens": ["Und", "w\u00fcnd\u00b7schen", "was", "vor\u00b7hin", "kein", "Sterb\u00b7li\u00b7cher", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Entf\u00e4llt uns denn so gar/ da\u00df wir viel besser dran/", "tokens": ["Ent\u00b7f\u00e4llt", "uns", "denn", "so", "gar", "/", "da\u00df", "wir", "viel", "bes\u00b7ser", "dran", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "$(", "KOUS", "PPER", "ADV", "ADJD", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als tausend neben uns/ die unsern Stand beneiden?", "tokens": ["Als", "tau\u00b7send", "ne\u00b7ben", "uns", "/", "die", "un\u00b7sern", "Stand", "be\u00b7nei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "APPR", "PPER", "$(", "ART", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kan uns der Sonnen Schein so tr\u00fcbe Regung machen/", "tokens": ["Kan", "uns", "der", "Son\u00b7nen", "Schein", "so", "tr\u00fc\u00b7be", "Re\u00b7gung", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "ADV", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie wird es k\u00fcnftig gehn/ wenn erst die Wolcken krachen?", "tokens": ["Wie", "wird", "es", "k\u00fcnf\u00b7tig", "gehn", "/", "wenn", "erst", "die", "Wol\u00b7cken", "kra\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "VVINF", "$(", "KOUS", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Drum rauschet nur vorbey/ ihr Kummer-volle Fluthen/", "tokens": ["Drum", "rau\u00b7schet", "nur", "vor\u00b7bey", "/", "ihr", "Kum\u00b7mer\u00b7vol\u00b7le", "Flut\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "$(", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das ist das beste Gut was in uns selbst besteht.", "tokens": ["Das", "ist", "das", "bes\u00b7te", "Gut", "was", "in", "uns", "selbst", "be\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "PRELS", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil des Vaters Hand das Rad der Schickung", "tokens": ["Und", "weil", "des", "Va\u00b7ters", "Hand", "das", "Rad", "der", "Schi\u00b7ckung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sind K\u00fcsse noch viel ehr als Schl\u00e4ge zu vermuthen.", "tokens": ["Sind", "K\u00fcs\u00b7se", "noch", "viel", "ehr", "als", "Schl\u00e4\u00b7ge", "zu", "ver\u00b7mu\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "PIAT", "NN", "KOUS", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er schicke was Er wil/ wir k\u00f6nnen nicht entrinnen;", "tokens": ["Er", "schi\u00b7cke", "was", "Er", "wil", "/", "wir", "k\u00f6n\u00b7nen", "nicht", "ent\u00b7rin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VMFIN", "$(", "PPER", "VMFIN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weicht eitle Grillen weicht/ ihr kr\u00e4ncket nur die Sinnen.", "tokens": ["Weicht", "eit\u00b7le", "Gril\u00b7len", "weicht", "/", "ihr", "kr\u00e4n\u00b7cket", "nur", "die", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$(", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}