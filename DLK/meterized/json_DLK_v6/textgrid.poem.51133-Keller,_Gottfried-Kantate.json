{"textgrid.poem.51133": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Kantate", "genre": "verse", "period": "N.A.", "pub_year": 1883, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Urma\u00df aller Dinge ruht", "tokens": ["Das", "Ur\u00b7ma\u00df", "al\u00b7ler", "Din\u00b7ge", "ruht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In H\u00e4nden nicht, die endlich sind,", "tokens": ["In", "H\u00e4n\u00b7den", "nicht", ",", "die", "end\u00b7lich", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "$,", "PRELS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es liegt verwahrt in Schatzgew\u00f6lben,", "tokens": ["Es", "liegt", "ver\u00b7wahrt", "in", "Schatz\u00b7ge\u00b7w\u00f6l\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die kein verg\u00e4nglich Auge schaut.", "tokens": ["Die", "kein", "ver\u00b7g\u00e4ng\u00b7lich", "Au\u00b7ge", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir f\u00fchren Waage, Stab und Uhr,", "tokens": ["Wir", "f\u00fch\u00b7ren", "Waa\u00b7ge", ",", "Stab", "und", "Uhr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und was wir w\u00e4gen, schwindet hin;", "tokens": ["Und", "was", "wir", "w\u00e4\u00b7gen", ",", "schwin\u00b7det", "hin", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Darum mit ehrerbiet'ger Scheu", "tokens": ["Da\u00b7rum", "mit", "ehr\u00b7er\u00b7biet'\u00b7ger", "Scheu"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gebrauchen wir das Ma\u00df der Zeit", "tokens": ["Ge\u00b7brau\u00b7chen", "wir", "das", "Ma\u00df", "der", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und rufen hoher Jahre Zahl", "tokens": ["Und", "ru\u00b7fen", "ho\u00b7her", "Jah\u00b7re", "Zahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit Weihefesten an.", "tokens": ["Mit", "Wei\u00b7he\u00b7fes\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ein halbes Jahrhundert \u2013", "tokens": ["Ein", "hal\u00b7bes", "Jahr\u00b7hun\u00b7dert", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Was ist es, ihr Br\u00fcder?", "tokens": ["Was", "ist", "es", ",", "ihr", "Br\u00fc\u00b7der", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Ein Hauch, wie ein ganzes", "tokens": ["Ein", "Hauch", ",", "wie", "ein", "gan\u00b7zes"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und wie ein Jahrtausend!", "tokens": ["Und", "wie", "ein", "Jahr\u00b7tau\u00b7send", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Doch wenn es das erste,", "tokens": ["Doch", "wenn", "es", "das", "ers\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "ADJA", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Dann winden wir schmeichelnd", "tokens": ["Dann", "win\u00b7den", "wir", "schmei\u00b7chelnd"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Und r\u00fchmend den Kranz.", "tokens": ["Und", "r\u00fch\u00b7mend", "den", "Kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Das eigne Erinnern", "tokens": ["Das", "eig\u00b7ne", "E\u00b7rin\u00b7nern"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Umf\u00e4ngt uns die Seele,", "tokens": ["Um\u00b7f\u00e4ngt", "uns", "die", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Die Jahre der Jugend", "tokens": ["Die", "Jah\u00b7re", "der", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sind lange dahin,", "tokens": ["Sind", "lan\u00b7ge", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Indessen die neuen", "tokens": ["In\u00b7des\u00b7sen", "die", "neu\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Geschlechter erbl\u00fchten.", "tokens": ["Ge\u00b7schlech\u00b7ter", "er\u00b7bl\u00fch\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Es ragt uns die Burg mit", "tokens": ["Es", "ragt", "uns", "die", "Burg", "mit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Den \u00c4mtern des Wissens,", "tokens": ["Den", "\u00c4m\u00b7tern", "des", "Wis\u00b7sens", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Wir sahn noch die Stifter", "tokens": ["Wir", "sahn", "noch", "die", "Stif\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und sahn die Genossen", "tokens": ["Und", "sahn", "die", "Ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Die Halle durchschreiten,", "tokens": ["Die", "Hal\u00b7le", "durch\u00b7schrei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Geschlecht auf Geschlecht.", "tokens": ["Ge\u00b7schlecht", "auf", "Ge\u00b7schlecht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Wo sind sie geblieben,", "tokens": ["Wo", "sind", "sie", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Sie all, die gekommen", "tokens": ["Sie", "all", ",", "die", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "PIAT", "$,", "PRELS", "VVPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und wieder geschieden,", "tokens": ["Und", "wie\u00b7der", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Zu lehren, zu lernen?", "tokens": ["Zu", "leh\u00b7ren", ",", "zu", "ler\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Sie ruhen in Gr\u00e4bern,", "tokens": ["Sie", "ru\u00b7hen", "in", "Gr\u00e4\u00b7bern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Zerstreut auf der Erde", "tokens": ["Zer\u00b7streut", "auf", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Und hier in der Heimat.", "tokens": ["Und", "hier", "in", "der", "Hei\u00b7mat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "Doch mancher, er h\u00e4lt noch", "tokens": ["Doch", "man\u00b7cher", ",", "er", "h\u00e4lt", "noch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "In schneeigen Locken", "tokens": ["In", "schne\u00b7e\u00b7i\u00b7gen", "Lo\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "An fernen Alt\u00e4ren", "tokens": ["An", "fer\u00b7nen", "Al\u00b7t\u00e4\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Der Weisheit die Wacht;", "tokens": ["Der", "Weis\u00b7heit", "die", "Wacht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}}}}