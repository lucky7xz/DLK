{"textgrid.poem.54131": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Autarkie", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Juni hat noch keiner gewu\u00dft,", "tokens": ["Im", "Ju\u00b7ni", "hat", "noch", "kei\u00b7ner", "ge\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "was Autarkie bedeutet;", "tokens": ["was", "Au\u00b7tar\u00b7kie", "be\u00b7deu\u00b7tet", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "heut hebt sich jede deutsche Brust,", "tokens": ["heut", "hebt", "sich", "je\u00b7de", "deut\u00b7sche", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wenn das Schlagwort herunterl\u00e4utet:", "tokens": ["wenn", "das", "Schlag\u00b7wort", "her\u00b7un\u00b7ter\u00b7l\u00e4u\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Autarkie!", "tokens": ["Au\u00b7tar\u00b7kie", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.6": {"text": "Wir schlie\u00dfen einfach die Grenzen zu.", "tokens": ["Wir", "schlie\u00b7\u00dfen", "ein\u00b7fach", "die", "Gren\u00b7zen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Dann hat die liebe Seele Ruh.", "tokens": ["Dann", "hat", "die", "lie\u00b7be", "See\u00b7le", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Appelsinen, jro\u00dfe un kleene,", "tokens": ["Ap\u00b7pel\u00b7si\u00b7nen", ",", "jro\u00b7\u00dfe", "un", "klee\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.9": {"text": "die machen wir uns alleene.", "tokens": ["die", "ma\u00b7chen", "wir", "uns", "al\u00b7lee\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PRF", "ADJA", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Kohlr\u00fcben wachsen bei uns zu Hauf.", "tokens": ["Kohl\u00b7r\u00fc\u00b7ben", "wach\u00b7sen", "bei", "uns", "zu", "Hauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "F\u00fcr uns ist nichts zu schade.", "tokens": ["F\u00fcr", "uns", "ist", "nichts", "zu", "scha\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIS", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir rauchen still unser Sofa auf,", "tokens": ["Wir", "rau\u00b7chen", "still", "un\u00b7ser", "So\u00b7fa", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "mit Maik\u00e4fer-Marmelade.", "tokens": ["mit", "Mai\u00b7k\u00e4\u00b7fer\u00b7Mar\u00b7me\u00b7la\u00b7de", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Autarkie! Autarkie!", "tokens": ["Au\u00b7tar\u00b7kie", "!", "Au\u00b7tar\u00b7kie", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wir schuften f\u00fcr Zins und f\u00fcr Zinseszins,", "tokens": ["Wir", "schuf\u00b7ten", "f\u00fcr", "Zins", "und", "f\u00fcr", "Zin\u00b7ses\u00b7zins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "KON", "APPR", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "und wir bleiben eine kleine Provinz.", "tokens": ["und", "wir", "blei\u00b7ben", "ei\u00b7ne", "klei\u00b7ne", "Pro\u00b7vinz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Paris is ja so jemeene!", "tokens": ["Pa\u00b7ris", "is", "ja", "so", "je\u00b7mee\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "ADV", "ADV", "ADJA", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.9": {"text": "Wir machen uns allens alleene.", "tokens": ["Wir", "ma\u00b7chen", "uns", "al\u00b7lens", "al\u00b7lee\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJA", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Dann halten wir fest das Proletenpack:", "tokens": ["Dann", "hal\u00b7ten", "wir", "fest", "das", "Pro\u00b7le\u00b7ten\u00b7pack", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "beherrscht von B\u00fcrokraten,", "tokens": ["be\u00b7herrscht", "von", "B\u00fc\u00b7ro\u00b7kra\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "von Banken und Kn\u00fcppel aus dem Sack,", "tokens": ["von", "Ban\u00b7ken", "und", "Kn\u00fcp\u00b7pel", "aus", "dem", "Sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "von Polizei und Soldaten.", "tokens": ["von", "Po\u00b7li\u00b7zei", "und", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Kr\u00e4ht der Adler auf dem Mist:", "tokens": ["Kr\u00e4ht", "der", "Ad\u00b7ler", "auf", "dem", "Mist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Autarkie!", "tokens": ["Au\u00b7tar\u00b7kie", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "\u00e4ndert sichs Wetter, oder es bleibt wie es ist \u2013", "tokens": ["\u00e4n\u00b7dert", "sichs", "Wet\u00b7ter", ",", "o\u00b7der", "es", "bleibt", "wie", "es", "ist", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$,", "KON", "PPER", "VVFIN", "KOKOM", "PPER", "VAFIN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Autarkie!", "tokens": ["Au\u00b7tar\u00b7kie", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.9": {"text": "F\u00fcr Pleite, Not und Kirchhofsruh \u2013", "tokens": ["F\u00fcr", "Plei\u00b7te", ",", "Not", "und", "Kirch\u00b7hofs\u00b7ruh", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "brauchen wir etwa das Ausland dazu?", "tokens": ["brau\u00b7chen", "wir", "et\u00b7wa", "das", "Aus\u00b7land", "da\u00b7zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Diese Wirtschaftskapit\u00e4ne,", "tokens": ["Die\u00b7se", "Wirt\u00b7schafts\u00b7ka\u00b7pi\u00b7t\u00e4\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "die machen det janz alleene.", "tokens": ["die", "ma\u00b7chen", "det", "janz", "al\u00b7lee\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VVFIN", "ADV", "ADJA", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}