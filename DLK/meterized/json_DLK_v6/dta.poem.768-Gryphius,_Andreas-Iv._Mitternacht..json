{"dta.poem.768": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  Mitternacht.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.85", "sv:0.14"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Schrecken/ vnd stille/ vnd dunckels grausen/ finstere k\u00e4lte ", "tokens": ["Schre\u00b7cken", "/", "vnd", "stil\u00b7le", "/", "vnd", "dun\u00b7ckels", "grau\u00b7sen", "/", "fins\u00b7te\u00b7re", "k\u00e4l\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$(", "KON", "VVFIN", "$(", "KON", "ADJA", "NN", "$(", "VVFIN", "VVFIN"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "bedecket das Land/", "tokens": ["be\u00b7de\u00b7cket", "das", "Land", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Jtzt schl\u00e4fft was arbeit vnd schmertzen erm\u00fcdet/ di\u00df sind der", "tokens": ["Jtzt", "schl\u00e4fft", "was", "ar\u00b7beit", "vnd", "schmert\u00b7zen", "er\u00b7m\u00fc\u00b7det", "/", "di\u00df", "sind", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "NN", "KON", "VVINF", "VVFIN", "$(", "PDS", "VAFIN", "ART"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "trawrigen einsamkeit stunden-", "tokens": ["traw\u00b7ri\u00b7gen", "ein\u00b7sam\u00b7keit", "stun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "TRUNC"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Nunmehr ist/ was durch die L\u00fcffte sich reget/ nunmehr sind", "tokens": ["Nun\u00b7mehr", "ist", "/", "was", "durch", "die", "L\u00fcff\u00b7te", "sich", "re\u00b7get", "/", "nun\u00b7mehr", "sind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "$(", "PWS", "APPR", "ART", "NN", "PRF", "VVFIN", "$(", "ADV", "VAFIN"], "meter": "--+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Thiere vnd Menschen verschwunden.", "tokens": ["Thie\u00b7re", "vnd", "Men\u00b7schen", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "Ob zwar die jmmerdar schimmernde lichter/ der ewig", "tokens": ["Ob", "zwar", "die", "jm\u00b7mer\u00b7dar", "schim\u00b7mern\u00b7de", "lich\u00b7ter", "/", "der", "e\u00b7wig"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADV", "ART", "PIAT", "ADJA", "NN", "$(", "ART", "ADJD"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "schitternden Sterneu entbrand!", "tokens": ["schit\u00b7tern\u00b7den", "Ster\u00b7neu", "ent\u00b7brand", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.3": {"line.1": {"text": "Suchet ein flei\u00dfiger Sinn noch zu wachen? der durch be-", "tokens": ["Su\u00b7chet", "ein", "flei\u00b7\u00dfi\u00b7ger", "Sinn", "noch", "zu", "wa\u00b7chen", "?", "der", "durch", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$.", "ART", "APPR", "TRUNC"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.2": {"text": "m\u00fchung der k\u00fcnstlichen hand/", "tokens": ["m\u00fc\u00b7hung", "der", "k\u00fcnst\u00b7li\u00b7chen", "hand", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Jhm die auch nach vns ankommende Seelen/ Jhm/ die an", "tokens": ["Jhm", "die", "auch", "nach", "vns", "an\u00b7kom\u00b7men\u00b7de", "See\u00b7len", "/", "Jhm", "/", "die", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "ART", "ADV", "APPR", "PPER", "ADJA", "NN", "$(", "PPER", "$(", "ART", "APPR"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "jtzt sich hier finden verbunden?", "tokens": ["jtzt", "sich", "hier", "fin\u00b7den", "ver\u00b7bun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ADV", "VVINF", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Wetzet ein bluttiger M\u00f6rder die Klinge? wil er vnschuldiger ", "tokens": ["Wet\u00b7zet", "ein", "blut\u00b7ti\u00b7ger", "M\u00f6r\u00b7der", "die", "Klin\u00b7ge", "?", "wil", "er", "vn\u00b7schul\u00b7di\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$.", "VMFIN", "PPER", "NN"], "meter": "+--+--+--+-+-++--", "measure": "dactylic.tri.plus"}, "line.6": {"text": "Hertzen verwunden?", "tokens": ["Hert\u00b7zen", "ver\u00b7wun\u00b7den", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Sorget ein ehren-begehrende Seele/ wie zuerlangen ein", "tokens": ["Sor\u00b7get", "ein", "eh\u00b7ren\u00b7be\u00b7geh\u00b7ren\u00b7de", "See\u00b7le", "/", "wie", "zu\u00b7er\u00b7lan\u00b7gen", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$(", "KOKOM", "ADV", "ART"], "meter": "+--+--+--+-++-+-+", "measure": "dactylic.tri.plus"}, "line.8": {"text": "h\u00f6herer stand?", "tokens": ["h\u00f6\u00b7he\u00b7rer", "stand", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "Sterbliche! Sterbliche! lasset di\u00df dichten/ ", "tokens": ["Sterb\u00b7li\u00b7che", "!", "Sterb\u00b7li\u00b7che", "!", "las\u00b7set", "di\u00df", "dich\u00b7ten", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "VVFIN", "PDS", "ADJA", "$("], "meter": "+--+---+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "morgen ach! mu\u00df man hin zihn!", "tokens": ["mor\u00b7gen", "ach", "!", "mu\u00df", "man", "hin", "zihn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach wir verschwinden gleich al\u00df die gespenste/ die vmb die", "tokens": ["Ach", "wir", "ver\u00b7schwin\u00b7den", "gleich", "al\u00df", "die", "ge\u00b7spens\u00b7te", "/", "die", "vmb", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "PPER", "VVFIN", "ADV", "KOUS", "ART", "ADJA", "$(", "ART", "APPR", "ART"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "stund vn\u00df erscheinen vnd flihn.", "tokens": ["stund", "vn\u00df", "er\u00b7schei\u00b7nen", "vnd", "flihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Wenn vn\u00df die finstere gruben bedecket/ wird was wir w\u00fcnd-", "tokens": ["Wenn", "vn\u00df", "die", "fins\u00b7te\u00b7re", "gru\u00b7ben", "be\u00b7de\u00b7cket", "/", "wird", "was", "wir", "w\u00fcn\u00b7d"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$(", "VAFIN", "PWS", "PPER", "TRUNC"], "meter": "-+-+--+--+-+-+--", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "schen vnd suchen zu nichte.", "tokens": ["schen", "vnd", "su\u00b7chen", "zu", "nich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVINF", "PTKZU", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Doch wie der gl\u00e4utzende Morgen er\u00f6ffnet/ was weder", "tokens": ["Doch", "wie", "der", "gl\u00e4ut\u00b7zen\u00b7de", "Mor\u00b7gen", "er\u00b7\u00f6ff\u00b7net", "/", "was", "we\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "VVPP", "$(", "PWS", "KON"], "meter": "-+-+--+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Monde noch ", "tokens": ["Mon\u00b7de", "noch"], "token_info": ["word", "word"], "pos": ["NE", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "So wenn der pl\u00f6tzliche Tag wird anbrechen/ wird was", "tokens": ["So", "wenn", "der", "pl\u00f6tz\u00b7li\u00b7che", "Tag", "wird", "an\u00b7bre\u00b7chen", "/", "wird", "was"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "VAFIN", "VVINF", "$(", "VAFIN", "PWS"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "geredet/ gew\u00fcrcket/ gemennt.", "tokens": ["ge\u00b7re\u00b7det", "/", "ge\u00b7w\u00fcr\u00b7cket", "/", "ge\u00b7mennt", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVPP", "$(", "VVPP", "$(", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Sonder verm\u00e4nteln er\u00f6ffnet sich finden vor de\u00df erschreckli-", "tokens": ["Son\u00b7der", "ver\u00b7m\u00e4n\u00b7teln", "er\u00b7\u00f6ff\u00b7net", "sich", "fin\u00b7den", "vor", "de\u00df", "er\u00b7schreck\u00b7li"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVINF", "VVFIN", "PRF", "VVINF", "APPR", "ART", "TRUNC"], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.6": {"text": "chen GOttes Gerichte.", "tokens": ["chen", "Got\u00b7tes", "Ge\u00b7rich\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}