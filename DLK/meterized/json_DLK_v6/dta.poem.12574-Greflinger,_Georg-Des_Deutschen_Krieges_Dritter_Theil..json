{"dta.poem.12574": {"metadata": {"author": {"name": "Greflinger, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Des  \n Deutschen Krieges  \n Dritter Theil.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1657", "urn": "urn:nbn:de:kobv:b4-200905199036", "language": ["de:0.99"], "booktitle": "Celadon von der Donau [i. e. Greflinger, Georg]: Der Deutschen Drey\u00dfig-J\u00e4hriger Krjeg. [s. l.], 1657."}, "poem": {"stanza.1": {"line.1": {"text": "Der Friede war anitzt mit Dennemarck geschlos-\nsen", "tokens": ["Der", "Frie\u00b7de", "war", "a\u00b7nitzt", "mit", "Den\u00b7ne\u00b7marck", "ge\u00b7schlos", "sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "NN", "TRUNC", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und niemand hatt", "tokens": ["und", "nie\u00b7mand", "hatt"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIS", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Denn Deutschland fiel hierauff nur tieffer in den Krieg/", "tokens": ["Denn", "Deutschland", "fiel", "hier\u00b7auff", "nur", "tief\u00b7fer", "in", "den", "Krieg", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PAV", "ADV", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der K\u00e4yser aber selbst kam jetzt von seinem Sieg.", "tokens": ["Der", "K\u00e4y\u00b7ser", "a\u00b7ber", "selbst", "kam", "jetzt", "von", "sei\u00b7nem", "Sieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als nun kein Feind mehr war im Felde zu befinden/", "tokens": ["Als", "nun", "kein", "Feind", "mehr", "war", "im", "Fel\u00b7de", "zu", "be\u00b7fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "ADV", "VAFIN", "APPRART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Fieng man mit St\u00e4dten an. Von vielem \u00fcberwinden", "tokens": ["Fi\u00b7eng", "man", "mit", "St\u00e4d\u00b7ten", "an", ".", "Von", "vie\u00b7lem", "\u00fc\u00b7berw\u00b7in\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "NN", "PTKVZ", "$.", "APPR", "PIS", "VVINF"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Wuchs endlich so ein Hertz/ das jhm nicht anders dacht\u2019/", "tokens": ["Wuchs", "end\u00b7lich", "so", "ein", "Hertz", "/", "das", "jhm", "nicht", "an\u00b7ders", "dacht'", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NN", "$(", "PRELS", "PPER", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als da\u00df gantz Deutschland w\u00e4r\u2019 ein Dienst-bot seiner Macht.", "tokens": ["Als", "da\u00df", "gantz", "Deutschland", "w\u00e4r'", "ein", "Dienst\u00b7bot", "sei\u00b7ner", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ADV", "NE", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Es kam das gantze Heer ins Pommerland gegangen/", "tokens": ["Es", "kam", "das", "gant\u00b7ze", "Heer", "ins", "Pom\u00b7mer\u00b7land", "ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da hatte Wallensteins sein Hertz sich unterfangen", "tokens": ["Da", "hat\u00b7te", "Wal\u00b7len\u00b7steins", "sein", "Hertz", "sich", "un\u00b7ter\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein Meister von Stralsund und Herr der See zu seyn/", "tokens": ["Ein", "Meis\u00b7ter", "von", "Stral\u00b7sund", "und", "Herr", "der", "See", "zu", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "KON", "NN", "ART", "NN", "PTKZU", "VAINF", "$("], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die man die Oost-See nennt. Dann weil des Gl\u00fcckes", "tokens": ["Die", "man", "die", "O\u00b7ost\u00b7See", "nennt", ".", "Dann", "weil", "des", "Gl\u00fc\u00b7ckes"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ART", "NN", "VVFIN", "$.", "ADV", "KOUS", "ART", "NN"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Schein", "tokens": ["Schein"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.14": {"text": "und auch sein tapfres thun jhn hatt\u2019 empor gef\u00fchret/", "tokens": ["und", "auch", "sein", "tapf\u00b7res", "thun", "jhn", "hatt'", "em\u00b7por", "ge\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ADJA", "VVFIN", "PPER", "VAFIN", "PTKVZ", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So da\u00df die gantze Macht von jhm allein regieret", "tokens": ["So", "da\u00df", "die", "gant\u00b7ze", "Macht", "von", "jhm", "al\u00b7lein", "re\u00b7gie\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "APPR", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "und umbgef\u00fchret wurd/ erhob er sich fast sehr.", "tokens": ["und", "umb\u00b7ge\u00b7f\u00fch\u00b7ret", "wurd", "/", "er\u00b7hob", "er", "sich", "fast", "sehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VAFIN", "$(", "VVFIN", "PPER", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "War dieses viel/ so war di\u00df andre noch vielmehr/", "tokens": ["War", "die\u00b7ses", "viel", "/", "so", "war", "di\u00df", "and\u00b7re", "noch", "viel\u00b7mehr", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "$(", "ADV", "VAFIN", "PDS", "PIS", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df er gantz Mecklenburg zum Lehen hatt\u2019 empfangen.", "tokens": ["Da\u00df", "er", "gantz", "Meck\u00b7len\u00b7burg", "zum", "Le\u00b7hen", "hatt'", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NE", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "War dieser alte Stamm vielleicht mit Tod\u2019 abgangen", "tokens": ["War", "die\u00b7ser", "al\u00b7te", "Stamm", "viel\u00b7leicht", "mit", "Tod'", "ab\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "ADJA", "NN", "ADV", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der hier zu herrschen hatt? Ach nein! man bund\u2019 jhm auf", "tokens": ["Der", "hier", "zu", "herr\u00b7schen", "hatt", "?", "Ach", "nein", "!", "man", "bund'", "jhm", "auf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PTKZU", "VVINF", "VAFIN", "$.", "NN", "PTKANT", "$.", "PIS", "ADJD", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Da\u00df er dem K\u00e4yser h\u00e4tt in dieser Kriege Lauf", "tokens": ["Da\u00df", "er", "dem", "K\u00e4y\u00b7ser", "h\u00e4tt", "in", "die\u00b7ser", "Krie\u00b7ge", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "APPR", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Viel widriges gethan/ hier von ist viel geschrieben/", "tokens": ["Viel", "wid\u00b7ri\u00b7ges", "ge\u00b7than", "/", "hier", "von", "ist", "viel", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "VVPP", "$(", "ADV", "APPR", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "und darumb hat man jhn aus Mecklenburg getriben", "tokens": ["und", "da\u00b7rumb", "hat", "man", "jhn", "aus", "Meck\u00b7len\u00b7burg", "ge\u00b7tri\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VAFIN", "PIS", "PPER", "APPR", "NE", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "und diesen eingesetzt. Er hatte grosse Macht", "tokens": ["und", "die\u00b7sen", "ein\u00b7ge\u00b7setzt", ".", "Er", "hat\u00b7te", "gros\u00b7se", "Macht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVPP", "$.", "PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die alle f\u00fcr Stralsund wurd\u2019 in den Stand gebracht/", "tokens": ["Die", "al\u00b7le", "f\u00fcr", "Stral\u00b7sund", "wurd'", "in", "den", "Stand", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "NE", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+--+-++-+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Die Vestung/ welche sich ihm sperrte/ zu besiegen/", "tokens": ["Die", "Ves\u00b7tung", "/", "wel\u00b7che", "sich", "ihm", "sperr\u00b7te", "/", "zu", "be\u00b7sie\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PRF", "PPER", "VVFIN", "$(", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "und solte sie am Schlo\u00df des Himmels feste liegen/", "tokens": ["und", "sol\u00b7te", "sie", "am", "Schlo\u00df", "des", "Him\u00b7mels", "fes\u00b7te", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPRART", "NN", "ART", "NN", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wie seine Rede war. Stralsund kam in die Noth/", "tokens": ["Wie", "sei\u00b7ne", "Re\u00b7de", "war", ".", "Stral\u00b7sund", "kam", "in", "die", "Noth", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VAFIN", "$.", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "und ob schon Ferdinand dem Wallenstein gebot\u2019", "tokens": ["und", "ob", "schon", "Fer\u00b7di\u00b7nand", "dem", "Wal\u00b7len\u00b7stein", "ge\u00b7bot'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "NE", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Auf solche nicht zu scharff mit seiner Macht zu dringen/", "tokens": ["Auf", "sol\u00b7che", "nicht", "zu", "scharff", "mit", "sei\u00b7ner", "Macht", "zu", "drin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PTKNEG", "PTKZU", "VVFIN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So fuhr er gleichwol fort/ in Meynung sie zu zwingen.", "tokens": ["So", "fuhr", "er", "gleich\u00b7wol", "fort", "/", "in", "Mey\u00b7nung", "sie", "zu", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$(", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Was gibt ein solcher Mann/ der selbst wil K\u00e4yser seyn/", "tokens": ["Was", "gibt", "ein", "sol\u00b7cher", "Mann", "/", "der", "selbst", "wil", "K\u00e4y\u00b7ser", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "PIAT", "NN", "$(", "ART", "ADV", "VMFIN", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Auf eines K\u00e4ysers Wort? Man warff viel Feuer ein/", "tokens": ["Auf", "ei\u00b7nes", "K\u00e4y\u00b7sers", "Wort", "?", "Man", "warff", "viel", "Feu\u00b7er", "ein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "PIS", "VVFIN", "PIAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Man st\u00fcrmete darauf/ man drohte Schwerdt und Feuer.", "tokens": ["Man", "st\u00fcr\u00b7me\u00b7te", "da\u00b7rauf", "/", "man", "droh\u00b7te", "Schwerdt", "und", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PAV", "$(", "PIS", "VVFIN", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Stralsund hielt tapfer aus/ und gab dem grimmen Freyer", "tokens": ["Stral\u00b7sund", "hielt", "tap\u00b7fer", "aus", "/", "und", "gab", "dem", "grim\u00b7men", "Frey\u00b7er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADJD", "PTKVZ", "$(", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "So viel/ als solcher ihr. Er aber lie\u00df nicht nach.", "tokens": ["So", "viel", "/", "als", "sol\u00b7cher", "ihr", ".", "Er", "a\u00b7ber", "lie\u00df", "nicht", "nach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "KOKOM", "PIAT", "PPOSAT", "$.", "PPER", "ADV", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Da aber di\u00df und das zur Gegenwehr gebrach/", "tokens": ["Da", "a\u00b7ber", "di\u00df", "und", "das", "zur", "Ge\u00b7gen\u00b7wehr", "ge\u00b7brach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDS", "KON", "PDS", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Befohle sich Stralsund dem K\u00f6nige von Schweden/", "tokens": ["Be\u00b7foh\u00b7le", "sich", "Stral\u00b7sund", "dem", "K\u00f6\u00b7ni\u00b7ge", "von", "Schwe\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "ART", "NN", "APPR", "NE", "$("], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.39": {"text": "Von dessen Tapferkeit man damahls schon zu reden", "tokens": ["Von", "des\u00b7sen", "Tap\u00b7fer\u00b7keit", "man", "da\u00b7mahls", "schon", "zu", "re\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "PIS", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Jm Oost und Westen pflag- Es hatt\u2019 auch Christian/", "tokens": ["Jm", "O\u00b7ost", "und", "Wes\u00b7ten", "pflag", "Es", "hatt'", "auch", "Chris\u00b7ti\u00b7an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "TRUNC", "PPER", "VAFIN", "ADV", "NE", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.41": {"text": "Der Dehnen Held/ hierbey vor jhm sehr viel gethan", "tokens": ["Der", "Deh\u00b7nen", "Held", "/", "hier\u00b7bey", "vor", "jhm", "sehr", "viel", "ge\u00b7than"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$(", "ADV", "APPR", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Mit Volcke/ Kraut und Loth. Gustavus nam die Schrei-", "tokens": ["Mit", "Vol\u00b7cke", "/", "Kraut", "und", "Loth", ".", "Gus\u00b7ta\u00b7vus", "nam", "die", "Schrei"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN", "$.", "NE", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Stralsund zu sch\u00fctzen und den Feind von jhr zu treiben", "tokens": ["Stral\u00b7sund", "zu", "sch\u00fct\u00b7zen", "und", "den", "Feind", "von", "jhr", "zu", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKZU", "VVINF", "KON", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Mit allem Willen auf. Weil aber diefer Zeit", "tokens": ["Mit", "al\u00b7lem", "Wil\u00b7len", "auf", ".", "Weil", "a\u00b7ber", "die\u00b7fer", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "NN", "PTKVZ", "$.", "KOUS", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Er mit Sarmatten in einem Waffen-Streit", "tokens": ["Er", "mit", "Sar\u00b7mat\u00b7ten", "in", "ei\u00b7nem", "Waf\u00b7fen\u00b7Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Nicht weit von Dantzig lag/ wo sich auch Arnheim funde", "tokens": ["Nicht", "weit", "von", "Dant\u00b7zig", "lag", "/", "wo", "sich", "auch", "Arn\u00b7heim", "fun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "APPR", "NE", "VVFIN", "$(", "PWAV", "PRF", "ADV", "NE", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "und mit Sarmatien jhm feindlich widerstunde/", "tokens": ["und", "mit", "Sar\u00b7ma\u00b7ti\u00b7en", "jhm", "feind\u00b7lich", "wi\u00b7der\u00b7stun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Es war des K\u00e4ysers Will/ als gab er/ jhre Noth", "tokens": ["Es", "war", "des", "K\u00e4y\u00b7sers", "Will", "/", "als", "gab", "er", "/", "jhre", "Noth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "NE", "$(", "KOKOM", "VVFIN", "PPER", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.49": {"text": "Zu mindern/ eine M\u00e4ng\u2019 an Speise/ Kraut und Loth/", "tokens": ["Zu", "min\u00b7dern", "/", "ei\u00b7ne", "M\u00e4ng'", "an", "Spei\u00b7se", "/", "Kraut", "und", "Loth", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "ART", "NN", "APPR", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Darbey was Volck und Trost selbst selbst bald anzukom-", "tokens": ["Dar\u00b7bey", "was", "Volck", "und", "Trost", "selbst", "selbst", "bald", "an\u00b7zu\u00b7kom"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PWS", "NN", "KON", "NN", "ADV", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Dann aller Vorrath hatt\u2019 aufs eusserst abgenommen/", "tokens": ["Dann", "al\u00b7ler", "Vor\u00b7rath", "hatt'", "aufs", "eus\u00b7serst", "ab\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "APPRART", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Weil die Bel\u00e4gerung fast in das ander Jahr", "tokens": ["Weil", "die", "Be\u00b7l\u00e4\u00b7ge\u00b7rung", "fast", "in", "das", "an\u00b7der", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Mit gro\u00dfem ungest\u00fchm hier\u00fcmb best\u00e4ndig war.", "tokens": ["Mit", "gro\u00b7\u00dfem", "un\u00b7ge\u00b7st\u00fchm", "hie\u00b7r\u00fcmb", "be\u00b7st\u00e4n\u00b7dig", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJD", "PAV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "So bald in Pohlen war der Krieg zum Ende kommen", "tokens": ["So", "bald", "in", "Poh\u00b7len", "war", "der", "Krieg", "zum", "En\u00b7de", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NE", "VAFIN", "ART", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Wurd\u2019 \u00fcber Meer ein Zug vom K\u00f6nig vorgenommen/", "tokens": ["Wurd'", "\u00fc\u00b7ber", "Meer", "ein", "Zug", "vom", "K\u00f6\u00b7nig", "vor\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ART", "NN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Der hoch-bed\u00e4ngten Stadt sehr bald und in Person", "tokens": ["Der", "hoch\u00b7be\u00b7d\u00e4ng\u00b7ten", "Stadt", "sehr", "bald", "und", "in", "Per\u00b7son"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Gew\u00fcndschte H\u00fclf zu thun. Viel sagen viel davon/", "tokens": ["Ge\u00b7w\u00fcnd\u00b7schte", "H\u00fclf", "zu", "thun", ".", "Viel", "sa\u00b7gen", "viel", "da\u00b7von", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "$.", "ADV", "VVFIN", "PIS", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Das er ohn ", "tokens": ["Das", "er", "ohn"], "token_info": ["word", "word", "word"], "pos": ["PDS", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.59": {"text": "und andre sagen so: Wann einer wird bedr\u00e4nget", "tokens": ["und", "and\u00b7re", "sa\u00b7gen", "so", ":", "Wann", "ei\u00b7ner", "wird", "be\u00b7dr\u00e4n\u00b7get"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "ADV", "$.", "PWAV", "PIS", "VAFIN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "und zwar gantz unverschuldt/ wie diese Stadt Stralsund", "tokens": ["und", "zwar", "gantz", "un\u00b7ver\u00b7schuldt", "/", "wie", "die\u00b7se", "Stadt", "Stral\u00b7sund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADJD", "$(", "KOKOM", "PDAT", "NN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "und alles Pommerland/ das auch des Kaysers Mund", "tokens": ["und", "al\u00b7les", "Pom\u00b7mer\u00b7land", "/", "das", "auch", "des", "Kay\u00b7sers", "Mund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "$(", "PDS", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Gantz au\u00dfer aller Schuld erkannt hat/ wie zn sehen/", "tokens": ["Gantz", "au\u00b7\u00dfer", "al\u00b7ler", "Schuld", "er\u00b7kannt", "hat", "/", "wie", "zn", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVPP", "VAFIN", "$(", "KOKOM", "NE", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Hat da ein Freund nicht Macht demselben beyzustehen", "tokens": ["Hat", "da", "ein", "Freund", "nicht", "Macht", "dem\u00b7sel\u00b7ben", "bey\u00b7zu\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Auch g\u00e4ntzlich unersucht. Es war dem Kayser frey", "tokens": ["Auch", "g\u00e4ntz\u00b7lich", "un\u00b7er\u00b7sucht", ".", "Es", "war", "dem", "Kay\u00b7ser", "frey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADJD", "$.", "PPER", "VAFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Den Pohlen H\u00fclff zu thun. So kam es ja wol bey", "tokens": ["Den", "Poh\u00b7len", "H\u00fclff", "zu", "thun", ".", "So", "kam", "es", "ja", "wol", "bey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$.", "ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Da\u00df Schweden andern halff. Viel andre wollen reden", "tokens": ["Da\u00df", "Schwe\u00b7den", "an\u00b7dern", "halff", ".", "Viel", "and\u00b7re", "wol\u00b7len", "re\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ADJA", "NN", "$.", "PIAT", "PIS", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Von vieler ", "tokens": ["Von", "vie\u00b7ler"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.68": {"text": "Durch Kayserliche Macht so lang hatt\u2019 angethan.", "tokens": ["Durch", "Kay\u00b7ser\u00b7li\u00b7che", "Macht", "so", "lang", "hatt'", "an\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Es kam ein zimlich Heer vor dem Gustavus an", "tokens": ["Es", "kam", "ein", "zim\u00b7lich", "Heer", "vor", "dem", "Gus\u00b7ta\u00b7vus", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADV", "NN", "APPR", "ART", "NN", "APPR"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.70": {"text": "Aus Schweden au\u00dfger\u00fc\u00dft/ das kam auch bald zu Lande/", "tokens": ["Aus", "Schwe\u00b7den", "au\u00df\u00b7ge\u00b7r\u00fc\u00dft", "/", "das", "kam", "auch", "bald", "zu", "Lan\u00b7de", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$(", "PDS", "VVFIN", "ADV", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Wodurch die gute Stadt aus dem betr\u00fcbten Stande", "tokens": ["Wo\u00b7durch", "die", "gu\u00b7te", "Stadt", "aus", "dem", "be\u00b7tr\u00fcb\u00b7ten", "Stan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Zur alten Freyheit kam. Man sagt/ da\u00df das Geschrey", "tokens": ["Zur", "al\u00b7ten", "Frey\u00b7heit", "kam", ".", "Man", "sagt", "/", "da\u00df", "das", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$.", "PIS", "VVFIN", "$(", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Vom Schwedischen Entsatz die Kayfrische Parthey", "tokens": ["Vom", "Schwe\u00b7di\u00b7schen", "Ent\u00b7satz", "die", "Kay\u00b7fri\u00b7sche", "Par\u00b7they"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Hab\u2019 ab der Stadt gebracht. Hilff Gott in welcher Freude", "tokens": ["Hab'", "ab", "der", "Stadt", "ge\u00b7bracht", ".", "Hilff", "Gott", "in", "wel\u00b7cher", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "VVPP", "$.", "NN", "NN", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Befunde sich Stralsund/ die nun aus allem Leyde", "tokens": ["Be\u00b7fun\u00b7de", "sich", "Stral\u00b7sund", "/", "die", "nun", "aus", "al\u00b7lem", "Ley\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "NE", "$(", "PRELS", "ADV", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Durch GOtt und Gothisch Volck gew\u00fcndscht befreyet war.", "tokens": ["Durch", "Gott", "und", "Go\u00b7thisch", "Volck", "ge\u00b7w\u00fcnd\u00b7scht", "be\u00b7fre\u00b7yet", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "NN", "VVPP", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.77": {"text": "Der sie nur neulich wolt\u2019 in eu\u00dferste Gefahr.", "tokens": ["Der", "sie", "nur", "neu\u00b7lich", "wolt'", "in", "eu\u00b7\u00dfers\u00b7te", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VMFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.78": {"text": "Vnd in den \u00e4rgsten Tod ergeben/ gab den R\u00fccken", "tokens": ["Vnd", "in", "den", "\u00e4rgs\u00b7ten", "Tod", "er\u00b7ge\u00b7ben", "/", "gab", "den", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVPP", "$(", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "So wunderlich kans GOtt mit einem Feinde schicken.", "tokens": ["So", "wun\u00b7der\u00b7lich", "kans", "Gott", "mit", "ei\u00b7nem", "Fein\u00b7de", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Worauf die freye Stadt mit Schwedischer Gewalt", "tokens": ["Wo\u00b7rauf", "die", "frey\u00b7e", "Stadt", "mit", "Schwe\u00b7di\u00b7scher", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Nach R\u00fcgen \u00fcberfuhr/ woselbst ein Auffenthalt", "tokens": ["Nach", "R\u00fc\u00b7gen", "\u00fc\u00b7ber\u00b7fuhr", "/", "wo\u00b7selbst", "ein", "Auf\u00b7fent\u00b7halt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "$(", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Von vielen Feinden war/ die Feinde musten leyden", "tokens": ["Von", "vie\u00b7len", "Fein\u00b7den", "war", "/", "die", "Fein\u00b7de", "mus\u00b7ten", "ley\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "$(", "ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "und oft bey hunderten aus diesem Leben scheyden.", "tokens": ["und", "oft", "bey", "hun\u00b7der\u00b7ten", "aus", "die\u00b7sem", "Le\u00b7ben", "schey\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.84": {"text": "Die Insel wurde rein. Hier kam in jhren Freund", "tokens": ["Die", "In\u00b7sel", "wur\u00b7de", "rein", ".", "Hier", "kam", "in", "jhren", "Freund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.85": {"text": "Ein Muth/ hergegen Forcht und Schrecken in den Feind/", "tokens": ["Ein", "Muth", "/", "her\u00b7ge\u00b7gen", "Forcht", "und", "Schre\u00b7cken", "in", "den", "Feind", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "NN", "KON", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Die der Gustavus sol sehr gro\u00df vermehret haben.", "tokens": ["Die", "der", "Gus\u00b7ta\u00b7vus", "sol", "sehr", "gro\u00df", "ver\u00b7meh\u00b7ret", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VMFIN", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Der auch/ weil GOtt und Wind jhm gut Geleite gaben/", "tokens": ["Der", "auch", "/", "weil", "Gott", "und", "Wind", "jhm", "gut", "Ge\u00b7lei\u00b7te", "ga\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$(", "KOUS", "NN", "KON", "NN", "PPER", "ADJD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Mit einem grossen Heer sehr bald an R\u00fcgen kam/", "tokens": ["Mit", "ei\u00b7nem", "gros\u00b7sen", "Heer", "sehr", "bald", "an", "R\u00fc\u00b7gen", "kam", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV", "ADV", "APPR", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Wo er der Seinigen jhr Gl\u00fcck sehr froh vernam.", "tokens": ["Wo", "er", "der", "Sei\u00b7ni\u00b7gen", "jhr", "Gl\u00fcck", "sehr", "froh", "ver\u00b7nam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "PPOSS", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Ais er das Land betrat begab er das Get\u00fcmmel", "tokens": ["Ais", "er", "das", "Land", "be\u00b7trat", "be\u00b7gab", "er", "das", "Ge\u00b7t\u00fcm\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "ART", "NN", "VVFIN", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Des Volcks/ fiel auf die Kny und ruffte so gen Himmel?", "tokens": ["Des", "Volcks", "/", "fiel", "auf", "die", "Kny", "und", "ruff\u00b7te", "so", "gen", "Him\u00b7mel", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Du grosser Sieges-F\u00fcrst/ du starcker Zebaoth/", "tokens": ["Du", "gros\u00b7ser", "Sie\u00b7ges\u00b7F\u00fcrst", "/", "du", "star\u00b7cker", "Ze\u00b7bao\u00b7th", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Du aller Helden Held/ und aller G\u00f6tter GOtt/", "tokens": ["Du", "al\u00b7ler", "Hel\u00b7den", "Held", "/", "und", "al\u00b7ler", "G\u00f6t\u00b7ter", "Gott", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "NN", "$(", "KON", "PIAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Du Herscher \u00fcber Meer/ des Himmels und der Erden/", "tokens": ["Du", "Her\u00b7scher", "\u00fc\u00b7ber", "Meer", "/", "des", "Him\u00b7mels", "und", "der", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NN", "$(", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Kan dir nunmehr genug von mir gedancket werden?", "tokens": ["Kan", "dir", "nun\u00b7mehr", "ge\u00b7nug", "von", "mir", "ge\u00b7dan\u00b7cket", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Da\u00df du so gl\u00fccklich mich mit meiner Krieges Macht", "tokens": ["Da\u00df", "du", "so", "gl\u00fcck\u00b7lich", "mich", "mit", "mei\u00b7ner", "Krie\u00b7ges", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "PRF", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Durch das ergrimmte Meer hast an das Land gebracht-", "tokens": ["Durch", "das", "er\u00b7grimm\u00b7te", "Meer", "hast", "an", "das", "Land", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Ich dancke dancke dir aus meiner Seelen-grunde/", "tokens": ["Ich", "dan\u00b7cke", "dan\u00b7cke", "dir", "aus", "mei\u00b7ner", "See\u00b7len\u00b7grun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Dein Lob sol allezeit O HERR in meinem Munde", "tokens": ["Dein", "Lob", "sol", "al\u00b7le\u00b7zeit", "O", "HeRR", "in", "mei\u00b7nem", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "NE", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Vor allen V\u00f6lckern seyn. Ich bitte dich auch sehr/", "tokens": ["Vor", "al\u00b7len", "V\u00f6l\u00b7ckern", "seyn", ".", "Ich", "bit\u00b7te", "dich", "auch", "sehr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAINF", "$.", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Du wollest/ was ich noch von meinem Krieges-Heer", "tokens": ["Du", "wol\u00b7lest", "/", "was", "ich", "noch", "von", "mei\u00b7nem", "Krie\u00b7ge\u00b7sHeer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$(", "PWS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Jm R\u00fccken habe/ mich mit Freuden lassen sehen/", "tokens": ["Jm", "R\u00fc\u00b7cken", "ha\u00b7be", "/", "mich", "mit", "Freu\u00b7den", "las\u00b7sen", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "$(", "PPER", "APPR", "NN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Du wollest auch O HErr bey unsern Waffen stehen", "tokens": ["Du", "wol\u00b7lest", "auch", "O", "Herr", "bey", "un\u00b7sern", "Waf\u00b7fen", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "NE", "NN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Die deines Nahmens Ehr und deiner Kirchen Heyl", "tokens": ["Die", "dei\u00b7nes", "Nah\u00b7mens", "Ehr", "und", "dei\u00b7ner", "Kir\u00b7chen", "Heyl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "NN", "KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Zu retten/ wir zur Hand genommen. HErr zertheil", "tokens": ["Zu", "ret\u00b7ten", "/", "wir", "zur", "Hand", "ge\u00b7nom\u00b7men", ".", "Herr", "zer\u00b7theil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "PPER", "APPRART", "NN", "VVPP", "$.", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Der Feinde Macht f\u00fcr uns. Du wirst uns siegen lehren/", "tokens": ["Der", "Fein\u00b7de", "Macht", "f\u00fcr", "uns", ".", "Du", "wirst", "uns", "sie\u00b7gen", "leh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "$.", "PPER", "VAFIN", "PPER", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Zu deines H\u00e4ufleins Trost und deines Nahmens Ehren.", "tokens": ["Zu", "dei\u00b7nes", "H\u00e4uf\u00b7leins", "Trost", "und", "dei\u00b7nes", "Nah\u00b7mens", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "So fieng nun dieser Held den unerh\u00f6rten Krieg", "tokens": ["So", "fi\u00b7eng", "nun", "die\u00b7ser", "Held", "den", "un\u00b7er\u00b7h\u00f6r\u00b7ten", "Krieg"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PDAT", "NN", "ART", "ADJA", "NN"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.109": {"text": "Mit ernstem beten an. Viel beten/ halber Sieg", "tokens": ["Mit", "erns\u00b7tem", "be\u00b7ten", "an", ".", "Viel", "be\u00b7ten", "/", "hal\u00b7ber", "Sieg"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "VVFIN", "PTKVZ", "$.", "ADV", "VVINF", "$(", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.110": {"text": "War seines Mundes Lehr. Als man die Zeitung h\u00f6rte", "tokens": ["War", "sei\u00b7nes", "Mun\u00b7des", "Lehr", ".", "Als", "man", "die", "Zei\u00b7tung", "h\u00f6r\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$.", "KOUS", "PIS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Wie sich Gustavus selbst dem Feind ins Auge kehrte/", "tokens": ["Wie", "sich", "Gus\u00b7ta\u00b7vus", "selbst", "dem", "Feind", "ins", "Au\u00b7ge", "kehr\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "NE", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Wurd\u2019 alles Land best\u00fcrtzt/ die Feinde wurden zag/", "tokens": ["Wurd'", "al\u00b7les", "Land", "be\u00b7st\u00fcrtzt", "/", "die", "Fein\u00b7de", "wur\u00b7den", "zag", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVPP", "$(", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Die Freind hergegen froh/ und war an diesem Tag", "tokens": ["Die", "Freind", "her\u00b7ge\u00b7gen", "froh", "/", "und", "war", "an", "die\u00b7sem", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD", "$(", "KON", "VAFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "An welchem er vom Meer in obbesagtes R\u00fcgen/", "tokens": ["An", "wel\u00b7chem", "er", "vom", "Meer", "in", "ob\u00b7be\u00b7sag\u00b7tes", "R\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPRART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Das ein beflossen Land bey Pommern/ war gestiegen", "tokens": ["Das", "ein", "be\u00b7flos\u00b7sen", "Land", "bey", "Pom\u00b7mern", "/", "war", "ge\u00b7stie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ART", "ADJA", "NN", "APPR", "NE", "$(", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Von wegen Luthers Lehr\u2019 jhr erstes Jubel-Jahr/ ", "tokens": ["Von", "we\u00b7gen", "Lu\u00b7thers", "Lehr'", "jhr", "ers\u00b7tes", "Ju\u00b7bel\u00b7Jahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NE", "NE", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Worbey der tapfre Held selbst auch sehr eufrig war.", "tokens": ["Wor\u00b7bey", "der", "tapf\u00b7re", "Held", "selbst", "auch", "sehr", "euf\u00b7rig", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Was jener Wunder Krieg von dem gesaget worden/", "tokens": ["Was", "je\u00b7ner", "Wun\u00b7der", "Krieg", "von", "dem", "ge\u00b7sa\u00b7get", "wor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "NN", "APPR", "ART", "VVPP", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Da\u00df sich ein gro\u00dfes Heer mit streiten aus dem Norden", "tokens": ["Da\u00df", "sich", "ein", "gro\u00b7\u00dfes", "Heer", "mit", "strei\u00b7ten", "aus", "dem", "Nor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "APPR", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Nach S\u00fcden hab", "tokens": ["Nach", "S\u00fc\u00b7den", "hab"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.121": {"text": "Vom S\u00fcdischen erlangt/ was dieser Wunder-Krieg", "tokens": ["Vom", "S\u00fc\u00b7di\u00b7schen", "er\u00b7langt", "/", "was", "die\u00b7ser", "Wun\u00b7der\u00b7Krieg"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$(", "PWS", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Bedeutet habe/ sol anjetzt erkl\u00e4ret werden.", "tokens": ["Be\u00b7deu\u00b7tet", "ha\u00b7be", "/", "sol", "an\u00b7jetzt", "er\u00b7kl\u00e4\u00b7ret", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$(", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Gustavus sah die Noth und m\u00e4chtigen Beschwerden", "tokens": ["Gus\u00b7ta\u00b7vus", "sah", "die", "Noth", "und", "m\u00e4ch\u00b7ti\u00b7gen", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Die Deutschland und voraus das gute Pommerland", "tokens": ["Die", "Deutschland", "und", "vo\u00b7raus", "das", "gu\u00b7te", "Pom\u00b7mer\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.125": {"text": "und Mecklenburg erlitt. Es war ein folcher Stand", "tokens": ["und", "Meck\u00b7len\u00b7burg", "er\u00b7litt", ".", "Es", "war", "ein", "fol\u00b7cher", "Stand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Der zu erbarmen war", "tokens": ["Der", "zu", "er\u00b7bar\u00b7men", "war"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PTKZU", "VVINF", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.127": {"text": "Sein Siegs-gewohntes Schwerdt durch GOttes Krafft", "tokens": ["Sein", "Siegs\u00b7ge\u00b7wohn\u00b7tes", "Schwerdt", "durch", "Got\u00b7tes", "Krafft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.128": {"text": "bearmte", "tokens": ["be\u00b7arm\u00b7te"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.129": {"text": "und nach dem Joche hieb/ das von der P\u00e4bstlerey", "tokens": ["und", "nach", "dem", "Jo\u00b7che", "hieb", "/", "das", "von", "der", "P\u00e4bst\u00b7le\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$(", "ART", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "War auf den Hal\u00df gelegt. Viel kamen freudig frey/", "tokens": ["War", "auf", "den", "Hal\u00df", "ge\u00b7legt", ".", "Viel", "ka\u00b7men", "freu\u00b7dig", "frey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$.", "ADV", "VVFIN", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Der erste Schlag gerieth auf Wollgast und gelunge/", "tokens": ["Der", "ers\u00b7te", "Schlag", "ge\u00b7rieth", "auf", "Woll\u00b7gast", "und", "ge\u00b7lun\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NE", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Wo das erz\u00fcrnte Schwerdt in alle Feinde drunge/", "tokens": ["Wo", "das", "er\u00b7z\u00fcrn\u00b7te", "Schwerdt", "in", "al\u00b7le", "Fein\u00b7de", "drun\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Die Einnahm war mit Sturm. Als andre dieser Art", "tokens": ["Die", "Ein\u00b7nahm", "war", "mit", "Sturm", ".", "Als", "and\u00b7re", "die\u00b7ser", "Art"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$.", "KOUS", "PIS", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Vernahmen/ wie gestreng des K\u00f6nigs Gegenwart", "tokens": ["Ver\u00b7nah\u00b7men", "/", "wie", "ge\u00b7streng", "des", "K\u00f6\u00b7nigs", "Ge\u00b7gen\u00b7wart"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "PWAV", "ADJD", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Verfuhr/ verliessen sie die Schantzen an der Schweine/", "tokens": ["Ver\u00b7fuhr", "/", "ver\u00b7lies\u00b7sen", "sie", "die", "Schant\u00b7zen", "an", "der", "Schwei\u00b7ne", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Dem Hafen vor Stettin/ und brauchten jhrer Beine.", "tokens": ["Dem", "Ha\u00b7fen", "vor", "Stet\u00b7tin", "/", "und", "brauch\u00b7ten", "jhrer", "Bei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$(", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.137": {"text": "Durch solches kam Stettin in einen freyen Stand/", "tokens": ["Durch", "sol\u00b7ches", "kam", "Stet\u00b7tin", "in", "ei\u00b7nen", "frey\u00b7en", "Stand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "NE", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.138": {"text": "Dann dieses Kriegs-Volck war ein Feind an jhrer Hand", "tokens": ["Dann", "die\u00b7ses", "Kriegs\u00b7Volck", "war", "ein", "Feind", "an", "jhrer", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.139": {"text": "und jhres See Ports Schlo\u00df. Als Wollgast war er\u00f6bert/", "tokens": ["und", "jhres", "See", "Ports", "Schlo\u00df", ".", "Als", "Woll\u00b7gast", "war", "er\u00b7\u00f6\u00b7bert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "NN", "$.", "KOUS", "NE", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.140": {"text": "Bi\u00df auf das Schlo\u00df/ der Feind auch aus W\u00f6llin verst\u00f6bert", "tokens": ["Bi\u00df", "auf", "das", "Schlo\u00df", "/", "der", "Feind", "auch", "aus", "W\u00f6l\u00b7lin", "ver\u00b7st\u00f6\u00b7bert"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "$(", "ART", "NN", "ADV", "APPR", "NE", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "und auch aus ", "tokens": ["und", "auch", "aus"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.142": {"text": "Zur Zuflucht/ nahm darauf die Reise nach Stettin.", "tokens": ["Zur", "Zu\u00b7flucht", "/", "nahm", "da\u00b7rauf", "die", "Rei\u00b7se", "nach", "Stet\u00b7tin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "VVFIN", "PAV", "ART", "NN", "APPR", "NE", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.143": {"text": "Als aber sich ein Sturm vom S\u00fcdischen mit dr\u00f6uen", "tokens": ["Als", "a\u00b7ber", "sich", "ein", "Sturm", "vom", "S\u00fc\u00b7di\u00b7schen", "mit", "dr\u00f6u\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PRF", "ART", "NN", "APPRART", "NN", "APPR", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "und aller Macht erhob die Flotte zu zerstreuen/", "tokens": ["und", "al\u00b7ler", "Macht", "er\u00b7hob", "die", "Flot\u00b7te", "zu", "zer\u00b7streu\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Es kam auch zu der That/ so da\u00df bald dort ein Schiff", "tokens": ["Es", "kam", "auch", "zu", "der", "That", "/", "so", "da\u00df", "bald", "dort", "ein", "Schiff"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$(", "ADV", "KOUS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Gen Himmel flog/ bald da ein anders in die Tieff/", "tokens": ["Gen", "Him\u00b7mel", "flog", "/", "bald", "da", "ein", "an\u00b7ders", "in", "die", "Tieff", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$(", "ADV", "ADV", "ART", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Als in den H\u00f6llenschlund/ mit schrecklichem Get\u00fcmmel/", "tokens": ["Als", "in", "den", "H\u00f6l\u00b7len\u00b7schlund", "/", "mit", "schreck\u00b7li\u00b7chem", "Ge\u00b7t\u00fcm\u00b7mel", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Sah dieser fromme Held mit Seufftzen nach dem Himmel/", "tokens": ["Sah", "die\u00b7ser", "from\u00b7me", "Held", "mit", "Seufft\u00b7zen", "nach", "dem", "Him\u00b7mel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "APPR", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Fiel auch sehr hachbetr\u00fcbt mit Andacht auf die Kny", "tokens": ["Fiel", "auch", "sehr", "hach\u00b7be\u00b7tr\u00fcbt", "mit", "An\u00b7dacht", "auf", "die", "Kny"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "VVFIN", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "und ruffte so zu GOtt: Du hast mich ja noch nie/", "tokens": ["und", "ruff\u00b7te", "so", "zu", "Gott", ":", "Du", "hast", "mich", "ja", "noch", "nie", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$.", "PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Wann meine Seele dich/ mein GOtt/ hat angeflehet/", "tokens": ["Wann", "mei\u00b7ne", "See\u00b7le", "dich", "/", "mein", "Gott", "/", "hat", "an\u00b7ge\u00b7fle\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "$(", "PPOSAT", "NN", "$(", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Verlassen/ hilf auch jetzt. Du sihest wie es stehet/", "tokens": ["Ver\u00b7las\u00b7sen", "/", "hilf", "auch", "jetzt", ".", "Du", "si\u00b7hest", "wie", "es", "ste\u00b7het", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVIMP", "ADV", "ADV", "$.", "PPER", "VVFIN", "KOKOM", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Bedr\u00e4ue Merr und Wind und segne meinen Zug", "tokens": ["Be\u00b7dr\u00e4u\u00b7e", "Merr", "und", "Wind", "und", "seg\u00b7ne", "mei\u00b7nen", "Zug"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Zu deines Namens Ehr. O HERR es sey genug/", "tokens": ["Zu", "dei\u00b7nes", "Na\u00b7mens", "Ehr", ".", "O", "HeRR", "es", "sey", "ge\u00b7nug", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$.", "NE", "NN", "PPER", "VAFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "H\u00f6r auf mit deinem Zorn! Di\u00df K\u00f6nigliche Flehen", "tokens": ["H\u00f6r", "auf", "mit", "dei\u00b7nem", "Zorn", "!", "Di\u00df", "K\u00f6\u00b7nig\u00b7li\u00b7che", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPR", "APPR", "PPOSAT", "NN", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Wurd\u2019 auch sehr bald erh\u00f6rt/ der Sturm must untergehen", "tokens": ["Wurd'", "auch", "sehr", "bald", "er\u00b7h\u00f6rt", "/", "der", "Sturm", "must", "un\u00b7ter\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "VVPP", "$(", "ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "und muste zu der Reis\u2019 ein lieblich Wetter seyn.", "tokens": ["und", "mus\u00b7te", "zu", "der", "Reis'", "ein", "lieb\u00b7lich", "Wet\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "ART", "ADJD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Man kam nicht weit davon mit schwangern Segeln ein.", "tokens": ["Man", "kam", "nicht", "weit", "da\u00b7von", "mit", "schwan\u00b7gern", "Se\u00b7geln", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADJD", "PAV", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Das Volck wurd\u2019 au\u00dfgesetzt aus sechsmal zwantzig Schlf-", "tokens": ["Das", "Volck", "wurd'", "au\u00df\u00b7ge\u00b7setzt", "aus", "sechs\u00b7mal", "zwant\u00b7zig", "Schlf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "APPR", "ADV", "CARD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Bey zehen tausend Mann/ die zu den Waffen griffen.", "tokens": ["Bey", "ze\u00b7hen", "tau\u00b7send", "Mann", "/", "die", "zu", "den", "Waf\u00b7fen", "grif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "CARD", "NN", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.161": {"text": "Stettin ergab sich jhm/ dann da war keine Macht", "tokens": ["Stet\u00b7tin", "er\u00b7gab", "sich", "jhm", "/", "dann", "da", "war", "kei\u00b7ne", "Macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "PPER", "$(", "ADV", "ADV", "VAFIN", "PIAT", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.162": {"text": "Die jhm gewachsen war. Das Volck wurd\u2019 au\u00dfgebracht", "tokens": ["Die", "jhm", "ge\u00b7wach\u00b7sen", "war", ".", "Das", "Volck", "wurd'", "au\u00df\u00b7ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$.", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "und an den Wall verlegt/ die Stadt noch mehr bew\u00e4llet", "tokens": ["und", "an", "den", "Wall", "ver\u00b7legt", "/", "die", "Stadt", "noch", "mehr", "be\u00b7w\u00e4l\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$(", "ART", "NN", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "und allerley daselbst zum Feldzug angestellet.", "tokens": ["und", "al\u00b7ler\u00b7ley", "da\u00b7selbst", "zum", "Feld\u00b7zug", "an\u00b7ge\u00b7stel\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PAV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Gustavus setzte fort/ nam di\u00df und jenes ein/", "tokens": ["Gus\u00b7ta\u00b7vus", "setz\u00b7te", "fort", "/", "nam", "di\u00df", "und", "je\u00b7nes", "ein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$(", "VVFIN", "PDS", "KON", "PDS", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Worzu viel Pommern selbst bedient gewesen seyn.", "tokens": ["Wor\u00b7zu", "viel", "Pom\u00b7mern", "selbst", "be\u00b7dient", "ge\u00b7we\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADV", "VVPP", "VAPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Sie wolten lieber was als alle Last ertragen.", "tokens": ["Sie", "wol\u00b7ten", "lie\u00b7ber", "was", "als", "al\u00b7le", "Last", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "KOKOM", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Bald wurd\u2019 ein Theil mit Macht erb\u00e4rmlich todt geschla-", "tokens": ["Bald", "wurd'", "ein", "Theil", "mit", "Macht", "er\u00b7b\u00e4rm\u00b7lich", "todt", "ge\u00b7schla"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NN", "ADJD", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Bald listiglich beringt und in den Dienst gebracht.", "tokens": ["Bald", "lis\u00b7tig\u00b7lich", "be\u00b7ringt", "und", "in", "den", "Dienst", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Halff keiner Schlangen List/ so halff des L\u00f6uen Macht.", "tokens": ["Halff", "kei\u00b7ner", "Schlan\u00b7gen", "List", "/", "so", "halff", "des", "L\u00f6u\u00b7en", "Macht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "NE", "$(", "ADV", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Die List war \u00fcbergro\u00df. Sie hilfft auch viel im Kriegen.", "tokens": ["Die", "List", "war", "\u00fc\u00b7ber\u00b7gro\u00df", ".", "Sie", "hilfft", "auch", "viel", "im", "Krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Der K\u00f6nig hielte di\u00df f\u00fcr ein geringes siegen", "tokens": ["Der", "K\u00f6\u00b7nig", "hiel\u00b7te", "di\u00df", "f\u00fcr", "ein", "ge\u00b7rin\u00b7ges", "sie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PDS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Wann er ein hundert Mann von seinem Heer verlohr", "tokens": ["Wann", "er", "ein", "hun\u00b7dert", "Mann", "von", "sei\u00b7nem", "Heer", "ver\u00b7lohr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "CARD", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "und ein halb tausend schlug. Wie vielmals gab er vor:", "tokens": ["und", "ein", "halb", "tau\u00b7send", "schlug", ".", "Wie", "viel\u00b7mals", "gab", "er", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJD", "ADJD", "VVFIN", "$.", "PWAV", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Ein Mensch der koste viel bi\u00df er zum Kriege tauge/", "tokens": ["Ein", "Mensch", "der", "kos\u00b7te", "viel", "bi\u00df", "er", "zum", "Krie\u00b7ge", "tau\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "ADV", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Darumb ein jeder Herr im Krieg ein wachend Auge", "tokens": ["Da\u00b7rumb", "ein", "je\u00b7der", "Herr", "im", "Krieg", "ein", "wa\u00b7chend", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "PIAT", "NN", "APPRART", "NN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Nach solchem haben sol. Wie er dann selber that/", "tokens": ["Nach", "sol\u00b7chem", "ha\u00b7ben", "sol", ".", "Wie", "er", "dann", "sel\u00b7ber", "that", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VAINF", "VMFIN", "$.", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Er schonte seines Volcks/ und wann er eine Stadt", "tokens": ["Er", "schon\u00b7te", "sei\u00b7nes", "Volcks", "/", "und", "wann", "er", "ei\u00b7ne", "Stadt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$(", "KON", "PWAV", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "beschlo\u00df/ so sah er nach den Feind darin bey Leben", "tokens": ["be\u00b7schlo\u00df", "/", "so", "sah", "er", "nach", "den", "Feind", "da\u00b7rin", "bey", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PAV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Zu halten/ der sich dann must unter jhn begeben/", "tokens": ["Zu", "hal\u00b7ten", "/", "der", "sich", "dann", "must", "un\u00b7ter", "jhn", "be\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "PRELS", "PRF", "ADV", "VMFIN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Hiemit so wurd\u2019 er starck/ der Feind hergegen schwach.", "tokens": ["Hie\u00b7mit", "so", "wurd'", "er", "starck", "/", "der", "Feind", "her\u00b7ge\u00b7gen", "schwach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADJD", "$(", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Es halff auch viel darzu/ da\u00df er geheimb und wach", "tokens": ["Es", "halff", "auch", "viel", "dar\u00b7zu", "/", "da\u00df", "er", "ge\u00b7heimb", "und", "wach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PAV", "$(", "KOUS", "PPER", "ADJD", "KON", "XY"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "In allen H\u00e4ndeln war. Er pflag auch offt zu sagen:", "tokens": ["In", "al\u00b7len", "H\u00e4n\u00b7deln", "war", ".", "Er", "pflag", "auch", "offt", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "$.", "PPER", "VVFIN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Das Hembd/ das ein Soldat am Leibe pflegt zu tragen/", "tokens": ["Das", "Hembd", "/", "das", "ein", "Sol\u00b7dat", "am", "Lei\u00b7be", "pflegt", "zu", "tra\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PDS", "ART", "NN", "APPRART", "NN", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Sol unberichtet seyn des Jenen/ was er denckt/", "tokens": ["Sol", "un\u00b7be\u00b7rich\u00b7tet", "seyn", "des", "Je\u00b7nen", "/", "was", "er", "denckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VAINF", "ART", "NN", "$(", "PWS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Weil vielmahls aller Sieg an einem Anschlag henckt/", "tokens": ["Weil", "viel\u00b7mahls", "al\u00b7ler", "Sieg", "an", "ei\u00b7nem", "An\u00b7schlag", "henckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Auch alles ", "tokens": ["Auch", "al\u00b7les"], "token_info": ["word", "word"], "pos": ["ADV", "PIS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.188": {"text": "Dann von dem Rahtschlag kommt es endlich zu den Tha-", "tokens": ["Dann", "von", "dem", "Raht\u00b7schlag", "kommt", "es", "end\u00b7lich", "zu", "den", "Tha"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Wird der dem Feind entdeckt/ so wird die That zu nicht", "tokens": ["Wird", "der", "dem", "Feind", "ent\u00b7deckt", "/", "so", "wird", "die", "That", "zu", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ART", "NN", "VVPP", "$(", "ADV", "VAFIN", "ART", "NN", "APPR", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "und wird zum \u00f6fftern dem die Spitz ins Aug gericht", "tokens": ["und", "wird", "zum", "\u00f6ff\u00b7tern", "dem", "die", "Spitz", "ins", "Aug", "ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPRART", "VVFIN", "ART", "ART", "NN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Der vor entdecktem Raht die Feinde wolte jagen.", "tokens": ["Der", "vor", "ent\u00b7deck\u00b7tem", "Raht", "die", "Fein\u00b7de", "wol\u00b7te", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "Nach dem die Kaysrischen der Schweden List und Schla-", "tokens": ["Nach", "dem", "die", "Kays\u00b7ri\u00b7schen", "der", "Schwe\u00b7den", "List", "und", "Schla"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "ART", "NE", "NE", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "Der Vommern ", "tokens": ["Der", "Vom\u00b7mern"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.194": {"text": "Betracht- und f\u00fchleten/ ergrimmte derer Wehr", "tokens": ["Be\u00b7tracht", "und", "f\u00fch\u00b7le\u00b7ten", "/", "er\u00b7grimm\u00b7te", "de\u00b7rer", "Wehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["TRUNC", "KON", "VVFIN", "$(", "VVFIN", "PDS", "NN"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.195": {"text": "Auf alles in dem Land/ auf Menscheu/ Vieh und Felder/", "tokens": ["Auf", "al\u00b7les", "in", "dem", "Land", "/", "auf", "Men\u00b7scheu", "/", "Vieh", "und", "Fel\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "APPR", "ART", "NN", "$(", "APPR", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Man w\u00fcrgte klein und gro\u00df/ durch St\u00e4dte/ D\u00f6rff- und", "tokens": ["Man", "w\u00fcrg\u00b7te", "klein", "und", "gro\u00df", "/", "durch", "St\u00e4d\u00b7te", "/", "D\u00f6rff", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "ADJD", "KON", "ADJD", "$(", "APPR", "NN", "$(", "TRUNC", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.197": {"text": "W\u00e4lder/", "tokens": ["W\u00e4l\u00b7der", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.198": {"text": "Der Brand war \u00fcberall. Man sah auch scharff dahin", "tokens": ["Der", "Brand", "war", "\u00fc\u00b7be\u00b7rall", ".", "Man", "sah", "auch", "scharff", "da\u00b7hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "PIS", "VVFIN", "ADV", "ADJD", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Des K\u00f6nigs lo\u00df zu seyn/ zu welcher That Quintin", "tokens": ["Des", "K\u00f6\u00b7nigs", "lo\u00df", "zu", "seyn", "/", "zu", "wel\u00b7cher", "That", "Quin\u00b7tin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VAINF", "$(", "APPR", "PWAT", "NN", "NE"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.200": {"text": "Sich zwar gebrauchen lie\u00df/ die aber zu begehen", "tokens": ["Sich", "zwar", "ge\u00b7brau\u00b7chen", "lie\u00df", "/", "die", "a\u00b7ber", "zu", "be\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "ADV", "VVINF", "VVFIN", "$(", "PRELS", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "War GOtt jhm selbst im Weg/ als welcher alles sehen/", "tokens": ["War", "Gott", "jhm", "selbst", "im", "Weg", "/", "als", "wel\u00b7cher", "al\u00b7les", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PPER", "ADV", "APPRART", "NN", "$(", "KOUS", "PRELS", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Verhind- und f\u00f6rdern kan. Es kam auch eine Stund\u2019", "tokens": ["Ver\u00b7hin\u00b7d", "und", "f\u00f6r\u00b7dern", "kan", ".", "Es", "kam", "auch", "ei\u00b7ne", "Stund'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["TRUNC", "KON", "VVINF", "VMFIN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.203": {"text": "In der Gustavus sich vom Feind umbringt befund\u2019", "tokens": ["In", "der", "Gus\u00b7ta\u00b7vus", "sich", "vom", "Feind", "um\u00b7bringt", "be\u00b7fund'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PRF", "APPRART", "NN", "VVFIN", "NN"], "meter": "--+-++-+-+-+", "measure": "anapaest.init"}, "line.204": {"text": "Und in der h\u00f6chsten Noth/ der aber von den Seinen", "tokens": ["Und", "in", "der", "h\u00f6chs\u00b7ten", "Noth", "/", "der", "a\u00b7ber", "von", "den", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$(", "ART", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "Fast \u00fcber seines Sinns und aller Feinde meynen", "tokens": ["Fast", "\u00fc\u00b7ber", "sei\u00b7nes", "Sinns", "und", "al\u00b7ler", "Fein\u00b7de", "mey\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "KON", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Gew\u00fcndscht erl\u00f6set wurd\u2019 und zwar mit seinem Sieg\u2019.", "tokens": ["Ge\u00b7w\u00fcnd\u00b7scht", "er\u00b7l\u00f6\u00b7set", "wurd'", "und", "zwar", "mit", "sei\u00b7nem", "Sieg'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "KON", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.207": {"text": "Ein Feld-Herr/ der gleich frey im allersch\u00e4rffsten Krieg", "tokens": ["Ein", "Feld\u00b7Herr", "/", "der", "gleich", "frey", "im", "al\u00b7ler\u00b7sch\u00e4rffs\u00b7ten", "Krieg"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "ADV", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.208": {"text": "und lustigstem Panquet/ als dieser ist gewesen/", "tokens": ["und", "lus\u00b7tigs\u00b7tem", "Pan\u00b7quet", "/", "als", "die\u00b7ser", "ist", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "KOUS", "PDS", "VAFIN", "VAPP", "$("], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.209": {"text": "(f\u00fcrwahr man kunt\u2019 es jhm aus seinen Augen lesen", "tokens": ["(", "f\u00fcr\u00b7wahr", "man", "kunt'", "es", "jhm", "aus", "sei\u00b7nen", "Au\u00b7gen", "le\u00b7sen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PIS", "VMFIN", "PPER", "PPER", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "Da\u00df er ein K\u00f6nig war und ein behertzter Held)", "tokens": ["Da\u00df", "er", "ein", "K\u00f6\u00b7nig", "war", "und", "ein", "be\u00b7hertz\u00b7ter", "Held", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "KON", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Kommt leicht einmahl in Noht. Der di\u00df hatt\u2019 angestellt", "tokens": ["Kommt", "leicht", "ein\u00b7mahl", "in", "Noht", ".", "Der", "di\u00df", "hatt'", "an\u00b7ge\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "ADV", "APPR", "NN", "$.", "ART", "PDS", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "War eben auch Quintin. Es wolte nirgends gehen", "tokens": ["War", "e\u00b7ben", "auch", "Quin\u00b7tin", ".", "Es", "wol\u00b7te", "nir\u00b7gends", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "NE", "$.", "PPER", "VMFIN", "ADV", "VVINF"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.213": {"text": "Wie es die K\u00e4ysrischen gern hetten angesehen.", "tokens": ["Wie", "es", "die", "K\u00e4y\u00b7sri\u00b7schen", "gern", "het\u00b7ten", "an\u00b7ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Drumb brauchten sie aus Zorn sich vieler Tyranney/", "tokens": ["Drumb", "brauch\u00b7ten", "sie", "aus", "Zorn", "sich", "vie\u00b7ler", "Ty\u00b7ran\u00b7ney", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "NN", "PRF", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Von welcher Basewalck die Stadt ein Zenge sey", "tokens": ["Von", "wel\u00b7cher", "Ba\u00b7se\u00b7walck", "die", "Stadt", "ein", "Zen\u00b7ge", "sey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "und Bek\u00fcn ja vorau\u00df/ wo sie f\u00fcr bittren Thr\u00e4nen", "tokens": ["und", "Be\u00b7k\u00fcn", "ja", "vor\u00b7au\u00df", "/", "wo", "sie", "f\u00fcr", "bit\u00b7tren", "Thr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "PTKVZ", "$(", "PWAV", "PPER", "APPR", "ADJA", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.217": {"text": "Jhr au\u00dfgestanden Leyd verm\u00f6gen zu erwehnen.", "tokens": ["Ihr", "au\u00df\u00b7ge\u00b7stan\u00b7den", "Leyd", "ver\u00b7m\u00f6\u00b7gen", "zu", "er\u00b7weh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Gustavus machte fich mit Bannern von Settin", "tokens": ["Gus\u00b7ta\u00b7vus", "mach\u00b7te", "fich", "mit", "Ban\u00b7nern", "von", "Set\u00b7tin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "APPR", "NN", "APPR", "NE"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.219": {"text": "und schiffte nach Stralsund/ woselbst jhn Mund und Sinn", "tokens": ["und", "schiff\u00b7te", "nach", "Stral\u00b7sund", "/", "wo\u00b7selbst", "jhn", "Mund", "und", "Sinn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NE", "$(", "PWAV", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Von den Erl\u00f6seten dreymahl willkommen hiessen.", "tokens": ["Von", "den", "Er\u00b7l\u00f6\u00b7se\u00b7ten", "drey\u00b7mahl", "will\u00b7kom\u00b7men", "hies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.221": {"text": "Worauf die K\u00e4ysrischen umb Gartz zusammen stiessen", "tokens": ["Wo\u00b7rauf", "die", "K\u00e4y\u00b7sri\u00b7schen", "umb", "Gartz", "zu\u00b7sam\u00b7men", "sties\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "APPR", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Woselbst jhr Lager war/ und meynten an Stettin", "tokens": ["Wo\u00b7selbst", "jhr", "La\u00b7ger", "war", "/", "und", "meyn\u00b7ten", "an", "Stet\u00b7tin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "$(", "KON", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.223": {"text": "Ein m\u00e4chtiges zu thun/ sie zogen hertzhafft hin", "tokens": ["Ein", "m\u00e4ch\u00b7ti\u00b7ges", "zu", "thun", "/", "sie", "zo\u00b7gen", "hertz\u00b7hafft", "hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "PTKZU", "VVINF", "$(", "PPER", "VVFIN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Sehr traurig aber ab. Hergegen gieng der K\u00f6nig", "tokens": ["Sehr", "trau\u00b7rig", "a\u00b7ber", "ab", ".", "Her\u00b7ge\u00b7gen", "gieng", "der", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "PTKVZ", "$.", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.225": {"text": "Auf Damgart einen Pa\u00df/ gewann jhn/ wo nicht wenig", "tokens": ["Auf", "Dam\u00b7gart", "ei\u00b7nen", "Pa\u00df", "/", "ge\u00b7wann", "jhn", "/", "wo", "nicht", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "$(", "VVFIN", "PPER", "$(", "PWAV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Des Kayserlichen Volcks/ das theils in einem Thurm/", "tokens": ["Des", "Kay\u00b7ser\u00b7li\u00b7chen", "Volcks", "/", "das", "theils", "in", "ei\u00b7nem", "Thurm", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PDS", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Theils in den Schantzen lag/ in einem grossen Sturm", "tokens": ["Theils", "in", "den", "Schant\u00b7zen", "lag", "/", "in", "ei\u00b7nem", "gros\u00b7sen", "Sturm"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "$(", "APPR", "ART", "ADJA", "NN"], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.228": {"text": "Durch Schwerdt und Brand vergieng. Von allem viel zu", "tokens": ["Durch", "Schwerdt", "und", "Brand", "ver\u00b7gieng", ".", "Von", "al\u00b7lem", "viel", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$.", "APPR", "PIS", "PIS", "PTKZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.229": {"text": "sagen", "tokens": ["sa\u00b7gen"], "token_info": ["word"], "pos": ["VVINF"], "meter": "+-", "measure": "trochaic.single"}, "line.230": {"text": "Wil unsre K\u00fcrtze/ die wir brauchen/ nicht vertragen.", "tokens": ["Wil", "uns\u00b7re", "K\u00fcrt\u00b7ze", "/", "die", "wir", "brau\u00b7chen", "/", "nicht", "ver\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "$(", "PRELS", "PPER", "VVFIN", "$(", "PTKNEG", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.231": {"text": "Wir schweigen manchen Streit/ der sich begeben hat", "tokens": ["Wir", "schwei\u00b7gen", "man\u00b7chen", "Streit", "/", "der", "sich", "be\u00b7ge\u00b7ben", "hat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$(", "PRELS", "PRF", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "und offt mit grosser Macht/ in welchem stets der Schad", "tokens": ["und", "offt", "mit", "gros\u00b7ser", "Macht", "/", "in", "wel\u00b7chem", "stets", "der", "Schad"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$(", "APPR", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "Auffs K\u00e4ysers Seyten fiel. Sein Heer wurd\u2019 jmmer rin-", "tokens": ["Auffs", "K\u00e4y\u00b7sers", "Sey\u00b7ten", "fiel", ".", "Sein", "Heer", "wurd'", "jm\u00b7mer", "rin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NN", "VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Hier halffen viel darzu der m\u00e4chtige Bezwinger/", "tokens": ["Hier", "half\u00b7fen", "viel", "dar\u00b7zu", "der", "m\u00e4ch\u00b7ti\u00b7ge", "Be\u00b7zwin\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Den man den Hunger nennt/ darzu die Winterzeit/", "tokens": ["Den", "man", "den", "Hun\u00b7ger", "nennt", "/", "dar\u00b7zu", "die", "Win\u00b7ter\u00b7zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "VVFIN", "$(", "PAV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "So/ da\u00df das gantze Heer/ durch Hunger/ K\u00e4lt und Streit", "tokens": ["So", "/", "da\u00df", "das", "gant\u00b7ze", "Heer", "/", "durch", "Hun\u00b7ger", "/", "K\u00e4lt", "und", "Streit"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$(", "KOUS", "ART", "ADJA", "NN", "$(", "APPR", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Bezwungen/ endlich sich aus Pommern must\u2019 erheben", "tokens": ["Be\u00b7zwun\u00b7gen", "/", "end\u00b7lich", "sich", "aus", "Pom\u00b7mern", "must'", "er\u00b7he\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "ADV", "PRF", "APPR", "NE", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.238": {"text": "und solches seinem Feind\u2019 und Herren wieder geben/", "tokens": ["und", "sol\u00b7ches", "sei\u00b7nem", "Feind'", "und", "Her\u00b7ren", "wie\u00b7der", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "KON", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Zwar l\u00e4r und kahl genug. Es wich das gantze Heer/", "tokens": ["Zwar", "l\u00e4r", "und", "kahl", "ge\u00b7nug", ".", "Es", "wich", "das", "gant\u00b7ze", "Heer", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "ADV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Behielt auch \u00fcberall in Pommern nun nicht mehr", "tokens": ["Be\u00b7hielt", "auch", "\u00fc\u00b7be\u00b7rall", "in", "Pom\u00b7mern", "nun", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "NE", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Als Collberg und Gripswalt. Auch die au\u00df jhren H\u00e4nden", "tokens": ["Als", "Coll\u00b7berg", "und", "Grips\u00b7walt", ".", "Auch", "die", "au\u00df", "jhren", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "KON", "NN", "$.", "ADV", "ART", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.242": {"text": "Zu rei\u00dfen/ dann es war hieher auf", "tokens": ["Zu", "rei\u00b7\u00dfen", "/", "dann", "es", "war", "hie\u00b7her", "auf"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "ADV", "PPER", "VAFIN", "PAV", "APPR"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.243": {"text": "Ein gro\u00dfer Raub gef\u00fchrt/ wurd\u2019 aller Flei\u00df gethan.", "tokens": ["Ein", "gro\u00b7\u00dfer", "Raub", "ge\u00b7f\u00fchrt", "/", "wurd'", "al\u00b7ler", "Flei\u00df", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$(", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "So da\u00df man Collberg auch sehr zeitich eingewann.", "tokens": ["So", "da\u00df", "man", "Coll\u00b7berg", "auch", "sehr", "zei\u00b7tich", "ein\u00b7ge\u00b7wann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "NE", "ADV", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Nach dem die K\u00e4ysrischen umb Pommern waren kommen", "tokens": ["Nach", "dem", "die", "K\u00e4y\u00b7sri\u00b7schen", "umb", "Pom\u00b7mern", "wa\u00b7ren", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "APPR", "NE", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.246": {"text": "Wurd jhre Reise schnell auf Franckfurt zugenommen", "tokens": ["Wurd", "jhre", "Rei\u00b7se", "schnell", "auf", "Fran\u00b7ck\u00b7furt", "zu\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJD", "APPR", "NE", "VVPP"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.247": {"text": "Das an der Oder liegt. Die Schweden folgten nach/", "tokens": ["Das", "an", "der", "O\u00b7der", "liegt", ".", "Die", "Schwe\u00b7den", "folg\u00b7ten", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NE", "VVFIN", "$.", "ART", "NE", "VVFIN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "und waren jhnen stets mit w\u00fcrgen auf dem Dach.", "tokens": ["und", "wa\u00b7ren", "jh\u00b7nen", "stets", "mit", "w\u00fcr\u00b7gen", "auf", "dem", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Man nahm auch ", "tokens": ["Man", "nahm", "auch"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.250": {"text": "Seelen/", "tokens": ["See\u00b7len", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.251": {"text": "Vier tausend musten sich in Band und Kerckern qu\u00e4len/", "tokens": ["Vier", "tau\u00b7send", "mus\u00b7ten", "sich", "in", "Band", "und", "Ker\u00b7ckern", "qu\u00e4\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "VMFIN", "PRF", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Weil Tylli eben so vorher in einer Stadt/", "tokens": ["Weil", "Tyl\u00b7li", "e\u00b7ben", "so", "vor\u00b7her", "in", "ei\u00b7ner", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Neu-Brandenburg genannt/ bey tausend Schweden that.", "tokens": ["Neu\u00b7Bran\u00b7den\u00b7burg", "ge\u00b7nannt", "/", "bey", "tau\u00b7send", "Schwe\u00b7den", "that", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$(", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "Hier war Graff Tylli schon des Kaysers Feld-Herr worden", "tokens": ["Hier", "war", "Graff", "Tyl\u00b7li", "schon", "des", "Kay\u00b7sers", "Feld\u00b7Herr", "wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "NE", "ADV", "ART", "NN", "NN", "VAPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.255": {"text": "und Wallenstein entsetzt/ weil solcher in dem Orden", "tokens": ["und", "Wal\u00b7len\u00b7stein", "ent\u00b7setzt", "/", "weil", "sol\u00b7cher", "in", "dem", "Or\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVPP", "$(", "KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Der Maximinischen sich mercklich sehen lie\u00df/", "tokens": ["Der", "Ma\u00b7xi\u00b7mi\u00b7ni\u00b7schen", "sich", "merck\u00b7lich", "se\u00b7hen", "lie\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.257": {"text": "und widern K\u00e4yser sich in vielem mehr verstie\u00df.", "tokens": ["und", "wi\u00b7dern", "K\u00e4y\u00b7ser", "sich", "in", "vie\u00b7lem", "mehr", "ver\u00b7stie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PRF", "APPR", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.258": {"text": "Als Franckfurt \u00fcber war und Landsberg gleicher massen", "tokens": ["Als", "Fran\u00b7ck\u00b7furt", "\u00fc\u00b7ber", "war", "und", "Lands\u00b7berg", "glei\u00b7cher", "mas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "VAFIN", "KON", "NN", "ADJA", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.259": {"text": "Wurd auch Alt-Brandenburg vom Feinde bald verlassen/", "tokens": ["Wurd", "auch", "Al\u00b7tBran\u00b7den\u00b7burg", "vom", "Fein\u00b7de", "bald", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "APPRART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "und darauf Magdeburg vom Tylli gantz beschr\u00e4nckt/", "tokens": ["und", "da\u00b7rauf", "Mag\u00b7de\u00b7burg", "vom", "Tyl\u00b7li", "gantz", "be\u00b7schr\u00e4nckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "NE", "APPRART", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "Die alte Jungfer die/ und umb den Krantz gekr\u00e4nckt.", "tokens": ["Die", "al\u00b7te", "Jung\u00b7fer", "die", "/", "und", "umb", "den", "Krantz", "ge\u00b7kr\u00e4nckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "$(", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.262": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.263": {"text": "Vielleichte weil sie sich nicht P\u00e4bstisch wolte nennen/", "tokens": ["Viel\u00b7leich\u00b7te", "weil", "sie", "sich", "nicht", "P\u00e4bs\u00b7tisch", "wol\u00b7te", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "PRF", "PTKNEG", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "Dem K\u00e4yser that sie nichts. Es waren dero Werck", "tokens": ["Dem", "K\u00e4y\u00b7ser", "that", "sie", "nichts", ".", "Es", "wa\u00b7ren", "de\u00b7ro", "Werck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIS", "$.", "PPER", "VAFIN", "PDS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "und Mauren wol bewahrt. Herr Dietrich Falckenberck", "tokens": ["und", "Mau\u00b7ren", "wol", "be\u00b7wahrt", ".", "Herr", "Diet\u00b7rich", "Fal\u00b7cken\u00b7berck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "VVPP", "$.", "NN", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "Vom Schweden hingeschickt/ stritt wol/ auch alle B\u00fcrger/", "tokens": ["Vom", "Schwe\u00b7den", "hin\u00b7ge\u00b7schickt", "/", "stritt", "wol", "/", "auch", "al\u00b7le", "B\u00fcr\u00b7ger", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VVPP", "$(", "VVFIN", "ADV", "$(", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.267": {"text": "und zwar sehr lange Zeit. Ach aber ach! der W\u00fcrger", "tokens": ["und", "zwar", "sehr", "lan\u00b7ge", "Zeit", ".", "Ach", "a\u00b7ber", "ach", "!", "der", "W\u00fcr\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADJA", "NN", "$.", "ITJ", "ADV", "ADV", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.268": {"text": "Wurd\u2019 endlich jhrer Macht zu starck/ die sch\u00f6ne Stadt/", "tokens": ["Wurd'", "end\u00b7lich", "jhrer", "Macht", "zu", "starck", "/", "die", "sch\u00f6\u00b7ne", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.269": {"text": "(weh dir verfluchter Mund/ der sie verrahten hat", "tokens": ["(", "weh", "dir", "ver\u00b7fluch\u00b7ter", "Mund", "/", "der", "sie", "ver\u00b7rah\u00b7ten", "hat"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PPER", "ADJA", "NN", "$(", "PRELS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.270": {"text": "Es gieng verr\u00e4htrisch zu/) fiel endlich durch die Sch\u00e4rffe/", "tokens": ["Es", "gieng", "ver\u00b7r\u00e4h\u00b7trisch", "zu", "/", ")", "fiel", "end\u00b7lich", "durch", "die", "Sch\u00e4rf\u00b7fe", "/"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKZU", "$(", "$(", "VVFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "Wann ich die Augen nun auf deine Mauren werffe", "tokens": ["Wann", "ich", "die", "Au\u00b7gen", "nun", "auf", "dei\u00b7ne", "Mau\u00b7ren", "werf\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.272": {"text": "So werff ich auch zugleich viel Thr\u00e4nen in den Sand", "tokens": ["So", "werff", "ich", "auch", "zu\u00b7gleich", "viel", "Thr\u00e4\u00b7nen", "in", "den", "Sand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.273": {"text": "umb deinen hohen Fall und unerh\u00f6rten Brand/", "tokens": ["umb", "dei\u00b7nen", "ho\u00b7hen", "Fall", "und", "un\u00b7er\u00b7h\u00f6r\u00b7ten", "Brand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.274": {"text": "Du vormahls sch\u00f6ne Stadt. Dein Schmuck ist wegge-", "tokens": ["Du", "vor\u00b7mahls", "sch\u00f6\u00b7ne", "Stadt", ".", "Dein", "Schmuck", "ist", "weg\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADJA", "NN", "$.", "PPOSAT", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.275": {"text": "Du bist auf einen Tag umb dreyssig tausend kommen", "tokens": ["Du", "bist", "auf", "ei\u00b7nen", "Tag", "umb", "dreys\u00b7sig", "tau\u00b7send", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "APPR", "CARD", "CARD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.276": {"text": "Die B\u00fcrgerliche Leut in dir gewesen sind/", "tokens": ["Die", "B\u00fcr\u00b7ger\u00b7li\u00b7che", "Leut", "in", "dir", "ge\u00b7we\u00b7sen", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "VAPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.277": {"text": "Theils hat die Glut verzehrt/ die schrecklich und geschwind", "tokens": ["Theils", "hat", "die", "Glut", "ver\u00b7zehrt", "/", "die", "schreck\u00b7lich", "und", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "VVPP", "$(", "ART", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.278": {"text": "Die gantze Stadt besa\u00df. Theils fielen durch die Waffen/", "tokens": ["Die", "gant\u00b7ze", "Stadt", "be\u00b7sa\u00df", ".", "Theils", "fie\u00b7len", "durch", "die", "Waf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Theils schlung der Elbstrom ein. Was vor des W\u00fcrgers", "tokens": ["Theils", "schlung", "der", "E\u00b7lbstrom", "ein", ".", "Was", "vor", "des", "W\u00fcr\u00b7gers"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "ART", "NN", "PTKVZ", "$.", "PWS", "APPR", "ART", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.280": {"text": "raffen", "tokens": ["raf\u00b7fen"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.281": {"text": "Entwich/ fiel in die Glut. Was aus der Glut entkam", "tokens": ["Ent\u00b7wich", "/", "fiel", "in", "die", "Glut", ".", "Was", "aus", "der", "Glut", "ent\u00b7kam"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$(", "VVFIN", "APPR", "ART", "NN", "$.", "PWS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.282": {"text": "Fiel in den strengen Flu\u00df/ der alles Leben nam.", "tokens": ["Fiel", "in", "den", "stren\u00b7gen", "Flu\u00df", "/", "der", "al\u00b7les", "Le\u00b7ben", "nam", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$(", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.283": {"text": "Was derer keines fra\u00df/ das f\u00fchrte man gefangen/", "tokens": ["Was", "de\u00b7rer", "kei\u00b7nes", "fra\u00df", "/", "das", "f\u00fchr\u00b7te", "man", "ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "PIS", "VVFIN", "$(", "PDS", "VVFIN", "PIS", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.284": {"text": "Mit denen alle Schand und Tyranney begangen", "tokens": ["Mit", "de\u00b7nen", "al\u00b7le", "Schand", "und", "Ty\u00b7ran\u00b7ney", "be\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PIAT", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.285": {"text": "und au\u00dfge\u00fcbet wurd. Ein Priester am Altar", "tokens": ["und", "au\u00df\u00b7ge\u00b7\u00fc\u00b7bet", "wurd", ".", "Ein", "Pries\u00b7ter", "am", "Al\u00b7tar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVPP", "VAFIN", "$.", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "Lag in viel St\u00fccke da. Die arme Weiber-Schaar", "tokens": ["Lag", "in", "viel", "St\u00fc\u00b7cke", "da", ".", "Die", "ar\u00b7me", "Wei\u00b7ber\u00b7Schaar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "PIAT", "NN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Wurd Hunden gleich zu hauff gekuppelt und zum sch\u00e4nden", "tokens": ["Wurd", "Hun\u00b7den", "gleich", "zu", "hauff", "ge\u00b7kup\u00b7pelt", "und", "zum", "sch\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "ADV", "PTKA", "ADJD", "VVPP", "KON", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.288": {"text": "Ins Lager au\u00dfgef\u00fchrt. Viel schlossen sich mit H\u00e4nden", "tokens": ["Ins", "La\u00b7ger", "au\u00df\u00b7ge\u00b7f\u00fchrt", ".", "Viel", "schlos\u00b7sen", "sich", "mit", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$.", "ADV", "VVFIN", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.289": {"text": "und st\u00fcrtzten sich zugleich in tieffe Brunnen ein/", "tokens": ["und", "st\u00fcrtz\u00b7ten", "sich", "zu\u00b7gleich", "in", "tief\u00b7fe", "Brun\u00b7nen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "ADJA", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.290": {"text": "Der R\u00e4uber jhrer Ehr und Keuschheit frey zu seyn.", "tokens": ["Der", "R\u00e4u\u00b7ber", "jhrer", "Ehr", "und", "Keuschheit", "frey", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.291": {"text": "Was in die Keller floh verdorb durch Rauch und Flam-", "tokens": ["Was", "in", "die", "Kel\u00b7ler", "floh", "ver\u00b7dorb", "durch", "Rauch", "und", "Flam"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.292": {"text": "Dann alles Magdeburg das schmeltzete zusammen.", "tokens": ["Dann", "al\u00b7les", "Mag\u00b7de\u00b7burg", "das", "schmelt\u00b7ze\u00b7te", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PDS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.293": {"text": "Es blieb allein der Dohm und etwas vor der Stadt", "tokens": ["Es", "blieb", "al\u00b7lein", "der", "Dohm", "und", "et\u00b7was", "vor", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "KON", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.294": {"text": "Wo eine kleine Schaar sich noch gerettet hat.", "tokens": ["Wo", "ei\u00b7ne", "klei\u00b7ne", "Schaar", "sich", "noch", "ge\u00b7ret\u00b7tet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PRF", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.295": {"text": "Der Bischoff muste sich verwundt gefangen geben.", "tokens": ["Der", "Bi\u00b7schoff", "mus\u00b7te", "sich", "ver\u00b7wundt", "ge\u00b7fan\u00b7gen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.296": {"text": "Der tapfre Falckenberg kam in dem Sturm umbs Leben.", "tokens": ["Der", "tapf\u00b7re", "Fal\u00b7cken\u00b7berg", "kam", "in", "dem", "Sturm", "umbs", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "Dann ob er gleich den Feind in allen Gassen sah", "tokens": ["Dann", "ob", "er", "gleich", "den", "Feind", "in", "al\u00b7len", "Gas\u00b7sen", "sah"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADV", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.298": {"text": "Go stritt er gleichwol noch und schlug bald hie/ bald da", "tokens": ["Go", "stritt", "er", "gleich\u00b7wol", "noch", "und", "schlug", "bald", "hie", "/", "bald", "da"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "KON", "VVFIN", "ADV", "ADV", "$(", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.299": {"text": "Denselben wieder ab. Worzu jhm seine Schaaren", "tokens": ["Den\u00b7sel\u00b7ben", "wie\u00b7der", "ab", ".", "Wor\u00b7zu", "jhm", "sei\u00b7ne", "Schaa\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "PTKVZ", "$.", "PWAV", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.300": {"text": "Nechst vieler B\u00fcrgerschafft behertzt zur Seyten waren.", "tokens": ["Nechst", "vie\u00b7ler", "B\u00fcr\u00b7ger\u00b7schafft", "be\u00b7hertzt", "zur", "Sey\u00b7ten", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJD", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.301": {"text": "Sein Muht war unverzagt bi\u00df eine Kugel kam", "tokens": ["Sein", "Muht", "war", "un\u00b7ver\u00b7zagt", "bi\u00df", "ei\u00b7ne", "Ku\u00b7gel", "kam"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.302": {"text": "und jhm im sch\u00e4rffsten Streit das tapfre Leben nam.", "tokens": ["und", "jhm", "im", "sch\u00e4rffs\u00b7ten", "Streit", "das", "tapf\u00b7re", "Le\u00b7ben", "nam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.303": {"text": "Hiemit fiel auch die Stadt ", "tokens": ["Hie\u00b7mit", "fiel", "auch", "die", "Stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.304": {"text": "Da gieng es leyder an mit stechen/ sch\u00fcssen/ hauen.", "tokens": ["Da", "gieng", "es", "ley\u00b7der", "an", "mit", "ste\u00b7chen", "/", "sch\u00fcs\u00b7sen", "/", "hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "APPR", "VVINF", "$(", "VVINF", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.305": {"text": "Der Raht floh auf sein Hau\u00df/ das Rahthau\u00df kam in Brand", "tokens": ["Der", "Raht", "floh", "auf", "sein", "Hau\u00df", "/", "das", "Rah\u00b7thau\u00df", "kam", "in", "Brand"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "und kam also der Raht mit jhm in gleichen Stand.", "tokens": ["und", "kam", "al\u00b7so", "der", "Raht", "mit", "jhm", "in", "glei\u00b7chen", "Stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "APPR", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.307": {"text": "Die Tempel eben so/ man hat in einem Tempel", "tokens": ["Die", "Tem\u00b7pel", "e\u00b7ben", "so", "/", "man", "hat", "in", "ei\u00b7nem", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "$(", "PIS", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "Bey funfftzig Weibliche gek\u00f6pft/ ist ein Exempel", "tokens": ["Bey", "funfft\u00b7zig", "Weib\u00b7li\u00b7che", "ge\u00b7k\u00f6pft", "/", "ist", "ein", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "VVPP", "$(", "VAFIN", "ART", "NN"], "meter": "-+-+---+--+-+", "measure": "iambic.penta.relaxed"}, "line.309": {"text": "Dar\u00fcber man bestarrt/ das niemals ist erh\u00f6rt.", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "man", "be\u00b7starrt", "/", "das", "nie\u00b7mals", "ist", "er\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIS", "VVFIN", "$(", "PDS", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.310": {"text": "Da hat das warme Blut so h\u00e4uffig her ger\u00f6hrt/", "tokens": ["Da", "hat", "das", "war\u00b7me", "Blut", "so", "h\u00e4uf\u00b7fig", "her", "ge\u00b7r\u00f6hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADV", "ADJD", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.311": {"text": "Da\u00df endlich eine Bach im Tempel war zu sehen/", "tokens": ["Da\u00df", "end\u00b7lich", "ei\u00b7ne", "Bach", "im", "Tem\u00b7pel", "war", "zu", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.312": {"text": "Man muste hin und her auf todten K\u00f6rpern gehen.", "tokens": ["Man", "mus\u00b7te", "hin", "und", "her", "auf", "tod\u00b7ten", "K\u00f6r\u00b7pern", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "KON", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.313": {"text": "Dort lag ein Kind und sog der todten Mutter Brust/", "tokens": ["Dort", "lag", "ein", "Kind", "und", "sog", "der", "tod\u00b7ten", "Mut\u00b7ter", "Brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Hier eines in der Glut/ dort/ welches wol bewust/", "tokens": ["Hier", "ei\u00b7nes", "in", "der", "Glut", "/", "dort", "/", "wel\u00b7ches", "wol", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "APPR", "ART", "NN", "$(", "ADV", "$(", "PWS", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.315": {"text": "Nam ein verteuffelt Paar ein Kind bey seinen F\u00fc\u00dfen", "tokens": ["Nam", "ein", "ver\u00b7teuf\u00b7felt", "Paar", "ein", "Kind", "bey", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "VVPP", "NN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.316": {"text": "und ri\u00df den Leib entzwey. Dort sah man eines spie\u00dfen/", "tokens": ["und", "ri\u00df", "den", "Leib", "ent\u00b7zwey", ".", "Dort", "sah", "man", "ei\u00b7nes", "spie\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "ADV", "VVFIN", "PIS", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.317": {"text": "Hier schmi\u00df ein anderer ein anders an den Stein", "tokens": ["Hier", "schmi\u00df", "ein", "an\u00b7de\u00b7rer", "ein", "an\u00b7ders", "an", "den", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ART", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.318": {"text": "Da\u00df das Gehirne flog. Hier werden Zeugen seyn", "tokens": ["Da\u00df", "das", "Ge\u00b7hir\u00b7ne", "flog", ".", "Hier", "wer\u00b7den", "Zeu\u00b7gen", "seyn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$.", "ADV", "VAFIN", "NN", "VAINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.319": {"text": "Die Sonne/ welche lang gantz traurig hat gesehen/", "tokens": ["Die", "Son\u00b7ne", "/", "wel\u00b7che", "lang", "gantz", "trau\u00b7rig", "hat", "ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "ADJD", "ADV", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.320": {"text": "Nach dem di\u00df Blutbad war in Magdeburg geschehen.", "tokens": ["Nach", "dem", "di\u00df", "Blut\u00b7bad", "war", "in", "Mag\u00b7de\u00b7burg", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PDS", "NN", "VAFIN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.321": {"text": "Die Erde/ welche hier durch so viel Menschen-Blut", "tokens": ["Die", "Er\u00b7de", "/", "wel\u00b7che", "hier", "durch", "so", "viel", "Men\u00b7schen\u00b7Blut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "ADV", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.322": {"text": "Wurd \u00fcberf\u00e4rbt/ und auch die Elbe/ derer Fluth", "tokens": ["Wurd", "\u00fc\u00b7berf\u00b7\u00e4rbt", "/", "und", "auch", "die", "El\u00b7be", "/", "de\u00b7rer", "Fluth"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVPP", "$(", "KON", "ADV", "ART", "NE", "$(", "PDS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.323": {"text": "Vors erste blutig gieng/ vors ander f\u00fcr den Leichen", "tokens": ["Vors", "ers\u00b7te", "blu\u00b7tig", "gieng", "/", "vors", "an\u00b7der", "f\u00fcr", "den", "Lei\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "ADJD", "VVFIN", "$(", "APPRART", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.324": {"text": "Wie vor nicht lauffen kunt\u2019. Ein jedes gab ein Zeichen", "tokens": ["Wie", "vor", "nicht", "lauf\u00b7fen", "kunt'", ".", "Ein", "je\u00b7des", "gab", "ein", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "PTKNEG", "VVFIN", "PTKVZ", "$.", "ART", "PIAT", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.325": {"text": "Des traurens \u00fcber dich/ erbarmens-werthe Stad/", "tokens": ["Des", "trau\u00b7rens", "\u00fc\u00b7ber", "dich", "/", "er\u00b7bar\u00b7mens\u00b7wert\u00b7he", "Stad", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.326": {"text": "Nur der/ der deiner sich also bemeistert hat/", "tokens": ["Nur", "der", "/", "der", "dei\u00b7ner", "sich", "al\u00b7so", "be\u00b7meis\u00b7tert", "hat", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "ART", "PPOSAT", "PRF", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.327": {"text": "War g\u00e4ntzlich Felsen-gleich. Wir lesen von dem Heyden", "tokens": ["War", "g\u00e4ntz\u00b7lich", "Fel\u00b7sen\u00b7gleich", ".", "Wir", "le\u00b7sen", "von", "dem", "Hey\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "NN", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.328": {"text": "und Helden Scipio/ da\u00df er zu einem Leyden", "tokens": ["und", "Hel\u00b7den", "Sci\u00b7pio", "/", "da\u00df", "er", "zu", "ei\u00b7nem", "Ley\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "NE", "$(", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.329": {"text": "Ob der Carthager Brand und grossen Niederlag", "tokens": ["Ob", "der", "Car\u00b7tha\u00b7ger", "Brand", "und", "gros\u00b7sen", "Nie\u00b7der\u00b7lag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.330": {"text": "Sehr gro\u00df bewogen schien/ da er doch jhrer Plag\u2019", "tokens": ["Sehr", "gro\u00df", "be\u00b7wo\u00b7gen", "schien", "/", "da", "er", "doch", "jhrer", "Plag'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "VVFIN", "$(", "KOUS", "PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.331": {"text": "und Flammen Stiffter war. Hier aber war es Freude.", "tokens": ["und", "Flam\u00b7men", "Stiff\u00b7ter", "war", ".", "Hier", "a\u00b7ber", "war", "es", "Freu\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VAFIN", "$.", "ADV", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.332": {"text": "Wie hertzlich dieser Fall die Schwedischen zum Leyde", "tokens": ["Wie", "hertz\u00b7lich", "die\u00b7ser", "Fall", "die", "Schwe\u00b7di\u00b7schen", "zum", "Ley\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PDAT", "NN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.333": {"text": "und auch zur Rache tieb/ kan nicht beschrieben seyn/", "tokens": ["und", "auch", "zur", "Ra\u00b7che", "tieb", "/", "kan", "nicht", "be\u00b7schrie\u00b7ben", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ADJD", "$(", "VMFIN", "PTKNEG", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.334": {"text": "Den K\u00f6nig ja vorau\u00df. Die Schweden nicht allein/", "tokens": ["Den", "K\u00f6\u00b7nig", "ja", "vor\u00b7au\u00df", ".", "Die", "Schwe\u00b7den", "nicht", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$.", "ART", "NE", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.335": {"text": "Die gantze Christenheit/ und wer nur Menschen liebet", "tokens": ["Die", "gant\u00b7ze", "Chris\u00b7ten\u00b7heit", "/", "und", "wer", "nur", "Men\u00b7schen", "lie\u00b7bet"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "PWS", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.336": {"text": "Wurd \u00fcber diesem Fall von Magdeburg betr\u00fcbet.", "tokens": ["Wurd", "\u00fc\u00b7ber", "die\u00b7sem", "Fall", "von", "Mag\u00b7de\u00b7burg", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.337": {"text": "Gustavus schwur es hoch/ und hielt es bald darnach", "tokens": ["Gus\u00b7ta\u00b7vus", "schwur", "es", "hoch", "/", "und", "hielt", "es", "bald", "dar\u00b7nach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADJD", "$(", "KON", "VVFIN", "PPER", "ADV", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.338": {"text": "An allen Feindlichen die allersch\u00e4rffste Rach/", "tokens": ["An", "al\u00b7len", "Feind\u00b7li\u00b7chen", "die", "al\u00b7ler\u00b7sch\u00e4rffs\u00b7te", "Rach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.339": {"text": "um jhre Grausamkeit in Magdeburg/ zu \u00fcben.", "tokens": ["um", "jhre", "Grau\u00b7sam\u00b7keit", "in", "Mag\u00b7de\u00b7burg", "/", "zu", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NE", "$(", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.340": {"text": "Da\u00df er sie nicht al\u00dfbald hat von der Stad geerieben", "tokens": ["Da\u00df", "er", "sie", "nicht", "al\u00df\u00b7bald", "hat", "von", "der", "Stad", "ge\u00b7e\u00b7rie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "ADV", "VAFIN", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.341": {"text": "Ist er in keiner Schuld/ wie zu beweisen ist.", "tokens": ["Ist", "er", "in", "kei\u00b7ner", "Schuld", "/", "wie", "zu", "be\u00b7wei\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PIAT", "NN", "$(", "KOKOM", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.342": {"text": "Nu liebe Stadt/ die du verr\u00e4thrisch und mit List", "tokens": ["Nu", "lie\u00b7be", "Stadt", "/", "die", "du", "ver\u00b7r\u00e4t\u00b7hrisch", "und", "mit", "List"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "$(", "PRELS", "PPER", "ADJD", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.343": {"text": "Erobert worden bist/ GOtt tr\u00f6ste dich und heile", "tokens": ["Er\u00b7o\u00b7bert", "wor\u00b7den", "bist", "/", "Gott", "tr\u00f6s\u00b7te", "dich", "und", "hei\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VAPP", "VAFIN", "$(", "NN", "VVFIN", "PPER", "KON", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.344": {"text": "Die Wunden deines Leibs/ dem abgelebten Theile", "tokens": ["Die", "Wun\u00b7den", "dei\u00b7nes", "Leibs", "/", "dem", "ab\u00b7ge\u00b7leb\u00b7ten", "Thei\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.345": {"text": "Wird sonder Zweiffel nun sehr wol im Himmel seyn/", "tokens": ["Wird", "son\u00b7der", "Zweif\u00b7fel", "nun", "sehr", "wol", "im", "Him\u00b7mel", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "ADV", "ADV", "ADV", "APPRART", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.346": {"text": "Dein Leyd ist uns mie dir/ betr\u00fcbte Stadt/ gemein.", "tokens": ["Dein", "Leyd", "ist", "uns", "mie", "dir", "/", "be\u00b7tr\u00fcb\u00b7te", "Stadt", "/", "ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVFIN", "PPER", "$(", "ADJA", "NN", "$(", "ADJD", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}}}}