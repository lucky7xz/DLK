{"dta.poem.18520": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auf das in Schlesien sehr gew\u00f6nli-  \n che Karten spiel des trap-  \n pelirens.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1703", "urn": "urn:nbn:de:kobv:b4-200905199360", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr freunde/ kommt herbey/ der wahltag ist vorhanden/", "tokens": ["Ihr", "freun\u00b7de", "/", "kommt", "her\u00b7bey", "/", "der", "wahl\u00b7tag", "ist", "vor\u00b7han\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VVFIN", "PTKVZ", "$(", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der tag/ der uns erh\u00f6hn und wieder st\u00fcrtzen kan/", "tokens": ["Der", "tag", "/", "der", "uns", "er\u00b7h\u00f6hn", "und", "wie\u00b7der", "st\u00fcrt\u00b7zen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVINF", "KON", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drauf unser wohl und weh das gantze jahr gestanden/", "tokens": ["Drauf", "un\u00b7ser", "wohl", "und", "weh", "das", "gant\u00b7ze", "jahr", "ge\u00b7stan\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "ADV", "KON", "ADV", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den ieder sieht von uns mit furcht und hofnung an.", "tokens": ["Den", "ie\u00b7der", "sieht", "von", "uns", "mit", "furcht", "und", "hof\u00b7nung", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPER", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer diesen zeichen wird mit einem weissen steine/", "tokens": ["Wer", "die\u00b7sen", "zei\u00b7chen", "wird", "mit", "ei\u00b7nem", "weis\u00b7sen", "stei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VAFIN", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wen der verbuhlte mund des gl\u00fcckes heute k\u00fcst/", "tokens": ["Wen", "der", "ver\u00b7buhl\u00b7te", "mund", "des", "gl\u00fc\u00b7ckes", "heu\u00b7te", "k\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "ART", "ADJA", "ADV", "VVFIN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Der kan nach hause gehn mit solchem ehrenscheine/", "tokens": ["Der", "kan", "nach", "hau\u00b7se", "gehn", "mit", "sol\u00b7chem", "eh\u00b7ren\u00b7schei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "NN", "VVFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den selbst der Preto Jan und Mogol nicht genist.", "tokens": ["Den", "selbst", "der", "Pre\u00b7to", "Jan", "und", "Mo\u00b7gol", "nicht", "ge\u00b7nist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NE", "NE", "KON", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es lache/ wer da wil/ so mu\u00df er doch bekennen/", "tokens": ["Es", "la\u00b7che", "/", "wer", "da", "wil", "/", "so", "mu\u00df", "er", "doch", "be\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWS", "ADV", "VMFIN", "$(", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df die vergn\u00fcgung offt in eignem wahn besteht/", "tokens": ["Da\u00df", "die", "ver\u00b7gn\u00fc\u00b7gung", "offt", "in", "eig\u00b7nem", "wahn", "be\u00b7steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und der mit besserm fug ein k\u00f6nig ist zu nennen/", "tokens": ["Und", "der", "mit", "bes\u00b7serm", "fug", "ein", "k\u00f6\u00b7nig", "ist", "zu", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "ADJA", "NN", "ART", "ADJD", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So frey in mesolan/ als selav in purpur geht.", "tokens": ["So", "frey", "in", "me\u00b7so\u00b7lan", "/", "als", "se\u00b7lav", "in", "pur\u00b7pur", "geht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NE", "$(", "KOUS", "ADJD", "APPR", "ADJD", "VVFIN", "$."], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Wer wei\u00df/ ob ich nicht oft viel gr\u00f6\u00dfre lust empfunden/", "tokens": ["Wer", "wei\u00df", "/", "ob", "ich", "nicht", "oft", "viel", "gr\u00f6\u00df\u00b7re", "lust", "emp\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "KOUS", "PPER", "PTKNEG", "ADV", "PIAT", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wenn mir der Kuppidu nach hertzens wunsch gel\u00fcckt/", "tokens": ["Wenn", "mir", "der", "Kup\u00b7pi\u00b7du", "nach", "hert\u00b7zens", "wunsch", "ge\u00b7l\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Als Ludwig/ da er Gent und Stra\u00dfburg \u00fcberwunden/", "tokens": ["Als", "Lud\u00b7wig", "/", "da", "er", "Gent", "und", "Stra\u00df\u00b7burg", "\u00fc\u00b7berw\u00b7un\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$(", "KOUS", "PPER", "NN", "KON", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ob ieder gleich vor ihm/ vor mir sich keiner b\u00fcckt.", "tokens": ["Ob", "ie\u00b7der", "gleich", "vor", "ihm", "/", "vor", "mir", "sich", "kei\u00b7ner", "b\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "PPER", "$(", "APPR", "PPER", "PRF", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Gewi\u00df der beste wein ist meist in irdnen schalen/", "tokens": ["Ge\u00b7wi\u00df", "der", "bes\u00b7te", "wein", "ist", "meist", "in", "ird\u00b7nen", "scha\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAFIN", "ADV", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der unmuhts-wurm befleckt den sch\u00f6nsten Porcellan/", "tokens": ["Der", "unm\u00b7uhts\u00b7wurm", "be\u00b7fleckt", "den", "sch\u00f6ns\u00b7ten", "Por\u00b7cel\u00b7lan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ein hau\u00df in Bre\u00dflau zeigt uns gr\u00f6\u00dfre freuden-stralen/", "tokens": ["Ein", "hau\u00df", "in", "Bre\u00df\u00b7lau", "zeigt", "uns", "gr\u00f6\u00df\u00b7re", "freu\u00b7den\u00b7stra\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Al\u00df kein Eseurial/ kein Louvre geben kan.", "tokens": ["Al\u00df", "kein", "E\u00b7seu\u00b7ri\u00b7al", "/", "kein", "Louv\u00b7re", "ge\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "$(", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.21": {"text": "Ein wohlgesagter schertz kan uns so gut erg\u00f6tzen/", "tokens": ["Ein", "wohl\u00b7ge\u00b7sag\u00b7ter", "schertz", "kan", "uns", "so", "gut", "er\u00b7g\u00f6t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Als Molierens geist sich zu Paris bem\u00fcht/", "tokens": ["Als", "Mo\u00b7lie\u00b7rens", "geist", "sich", "zu", "Pa\u00b7ris", "be\u00b7m\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VVFIN", "PRF", "APPR", "NE", "VVPP", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.23": {"text": "Wir k\u00f6nnen seel und hertz in bessre freude setzen/", "tokens": ["Wir", "k\u00f6n\u00b7nen", "seel", "und", "hertz", "in", "bess\u00b7re", "freu\u00b7de", "set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Als wenn man Ro\u00dfballet und stiergefechte sieht.", "tokens": ["Als", "wenn", "man", "Ro\u00df\u00b7bal\u00b7let", "und", "stier\u00b7ge\u00b7fech\u00b7te", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "NN", "KON", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Das macht/ der freundschafft saltz w\u00fcrtzt lieblich unfre speisen/", "tokens": ["Das", "macht", "/", "der", "freund\u00b7schafft", "saltz", "w\u00fcrtzt", "lieb\u00b7lich", "un\u00b7fre", "spei\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "ART", "NN", "ADJD", "VVFIN", "ADJD", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Lust und vertrauligkeit ist unser mode-band/", "tokens": ["Lust", "und", "ver\u00b7trau\u00b7lig\u00b7keit", "ist", "un\u00b7ser", "mo\u00b7de\u00b7band", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.27": {"text": "Der redligkeit tinetur macht gold aus unserm eisen/", "tokens": ["Der", "red\u00b7lig\u00b7keit", "ti\u00b7ne\u00b7tur", "macht", "gold", "aus", "un\u00b7serm", "ei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "Wir brauchen zum salgt der liebe zuckerkant.", "tokens": ["Wir", "brau\u00b7chen", "zum", "salgt", "der", "lie\u00b7be", "zu\u00b7cker\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Wir fechten ohne blut/ wir schlagen doch die bl\u00e4tter/", "tokens": ["Wir", "fech\u00b7ten", "oh\u00b7ne", "blut", "/", "wir", "schla\u00b7gen", "doch", "die", "bl\u00e4t\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$(", "PPER", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Wir kriegeu/ aber nur mit schwerdtern/ so gemahlt/", "tokens": ["Wir", "krie\u00b7geu", "/", "a\u00b7ber", "nur", "mit", "schwerd\u00b7tern", "/", "so", "ge\u00b7mahlt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ADV", "ADV", "APPR", "VVINF", "$(", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wir zancken/ doch entsteht kein blitz und donnerwetter/", "tokens": ["Wir", "zan\u00b7cken", "/", "doch", "ent\u00b7steht", "kein", "blitz", "und", "don\u00b7ner\u00b7wet\u00b7ter", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ADV", "VVFIN", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Wir nehmen/ und es lacht/ wer auch das meiste zahlt.", "tokens": ["Wir", "neh\u00b7men", "/", "und", "es", "lacht", "/", "wer", "auch", "das", "meis\u00b7te", "zahlt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$(", "KON", "PPER", "VVFIN", "$(", "PWS", "ADV", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Welch Cato wil sich nun das edle trappeliren/", "tokens": ["Welch", "Ca\u00b7to", "wil", "sich", "nun", "das", "ed\u00b7le", "trap\u00b7pe\u00b7li\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NE", "VMFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Das grosse heldenspiel zu tadeln unterstehn?", "tokens": ["Das", "gros\u00b7se", "hel\u00b7den\u00b7spiel", "zu", "ta\u00b7deln", "un\u00b7ter\u00b7stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Wir lernen land und stadt durch dieses spiel regieren/", "tokens": ["Wir", "ler\u00b7nen", "land", "und", "stadt", "durch", "die\u00b7ses", "spiel", "re\u00b7gie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "ADJD", "APPR", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und wie es \u00fcberal pflegt auf der welt zu gehn.", "tokens": ["Und", "wie", "es", "\u00fc\u00b7be\u00b7ral", "pflegt", "auf", "der", "welt", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADJD", "VVFIN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Denn was der mund nicht kan/ das m\u00fcssen pr\u00fcgel zwingen/", "tokens": ["Denn", "was", "der", "mund", "nicht", "kan", "/", "das", "m\u00fcs\u00b7sen", "pr\u00fc\u00b7gel", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "PTKNEG", "VMFIN", "$(", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Seind diese denn zu schwach/ so greifft man nach dem schwerd/", "tokens": ["Seind", "die\u00b7se", "denn", "zu", "schwach", "/", "so", "greifft", "man", "nach", "dem", "schwerd", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "PTKA", "ADJD", "$(", "ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Was beiden noch zu schwer/ mu\u00df geld zuwege bringen/", "tokens": ["Was", "bei\u00b7den", "noch", "zu", "schwer", "/", "mu\u00df", "geld", "zu\u00b7we\u00b7ge", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "PTKA", "ADJD", "$(", "VMFIN", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Was hat ein becher nicht f\u00fcr gutes offt gewehrt.", "tokens": ["Was", "hat", "ein", "be\u00b7cher", "nicht", "f\u00fcr", "gu\u00b7tes", "offt", "ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "PTKNEG", "APPR", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Ich gehe weiter fort/ ist es nicht eh geschehen/", "tokens": ["Ich", "ge\u00b7he", "wei\u00b7ter", "fort", "/", "ist", "es", "nicht", "eh", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$(", "VAFIN", "PPER", "PTKNEG", "KOUS", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Da\u00df ein geringer mensch/ so nichts als ich und du/", "tokens": ["Da\u00df", "ein", "ge\u00b7rin\u00b7ger", "mensch", "/", "so", "nichts", "als", "ich", "und", "du", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$(", "ADV", "PIS", "KOKOM", "PPER", "KON", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Sich durch subtilen witz in solcher macht gesehen/", "tokens": ["Sich", "durch", "sub\u00b7ti\u00b7len", "witz", "in", "sol\u00b7cher", "macht", "ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADJA", "NN", "APPR", "PIAT", "VVFIN", "VVPP", "$("], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.44": {"text": "Da\u00df k\u00f6nige vor ihm gemacht die augen zu.", "tokens": ["Da\u00df", "k\u00f6\u00b7ni\u00b7ge", "vor", "ihm", "ge\u00b7macht", "die", "au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "APPR", "PPER", "VVPP", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.45": {"text": "Ein fu\u00dfknecht geht oft mehr in einer viertelstunde/", "tokens": ["Ein", "fu\u00df\u00b7knecht", "geht", "oft", "mehr", "in", "ei\u00b7ner", "vier\u00b7tel\u00b7stun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Als der zu pferde nicht in einer woche kan/", "tokens": ["Als", "der", "zu", "pfer\u00b7de", "nicht", "in", "ei\u00b7ner", "wo\u00b7che", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PTKZU", "VVFIN", "PTKNEG", "APPR", "ART", "ADJA", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wer itzund obenliegt/ geht augenblicks zu grunde/", "tokens": ["Wer", "it\u00b7zund", "o\u00b7ben\u00b7liegt", "/", "geht", "au\u00b7gen\u00b7blicks", "zu", "grun\u00b7de", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$(", "VVFIN", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Vor zehen sieht man neun/ vor neune zehen an.", "tokens": ["Vor", "ze\u00b7hen", "sieht", "man", "neun", "/", "vor", "neu\u00b7ne", "ze\u00b7hen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "VVFIN", "PIS", "CARD", "$(", "APPR", "CARD", "CARD", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.49": {"text": "Wir finden/ wenn wir offt im geist was grosses kochen/", "tokens": ["Wir", "fin\u00b7den", "/", "wenn", "wir", "offt", "im", "geist", "was", "gros\u00b7ses", "ko\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "ADV", "APPRART", "NN", "PWS", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Da\u00df doch ein schlechtes blat und b\u00f6se sieben macht/", "tokens": ["Da\u00df", "doch", "ein", "schlech\u00b7tes", "blat", "und", "b\u00f6\u00b7se", "sie\u00b7ben", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Da\u00df unser anschlag fehlt auff zwey und funfzig wochen/", "tokens": ["Da\u00df", "un\u00b7ser", "an\u00b7schlag", "fehlt", "auff", "zwey", "und", "funf\u00b7zig", "wo\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "APPR", "CARD", "KON", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Und wir vor alle m\u00fch nur werden ausgelacht.", "tokens": ["Und", "wir", "vor", "al\u00b7le", "m\u00fch", "nur", "wer\u00b7den", "aus\u00b7ge\u00b7lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PIS", "ADJD", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Der hofnung blauer dunst pflegt meistens uns zu blenden/", "tokens": ["Der", "hof\u00b7nung", "blau\u00b7er", "dunst", "pflegt", "meis\u00b7tens", "uns", "zu", "blen\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ADV", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Da\u00df man was guts verwirft und nach dem schlimmen greift/", "tokens": ["Da\u00df", "man", "was", "guts", "ver\u00b7wirft", "und", "nach", "dem", "schlim\u00b7men", "greift", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PWS", "NN", "VVFIN", "KON", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Da doch viel besser ist ein sperling in den h\u00e4nden/", "tokens": ["Da", "doch", "viel", "bes\u00b7ser", "ist", "ein", "sper\u00b7ling", "in", "den", "h\u00e4n\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "VAFIN", "ART", "VVFIN", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Als rebhun und fasan/ so in dem walde l\u00e4ufft.", "tokens": ["Als", "reb\u00b7hun", "und", "fa\u00b7san", "/", "so", "in", "dem", "wal\u00b7de", "l\u00e4ufft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "KON", "ADV", "$(", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Ist einer/ der das gl\u00fcck kan zur gemahlin finden;", "tokens": ["Ist", "ei\u00b7ner", "/", "der", "das", "gl\u00fcck", "kan", "zur", "ge\u00b7mah\u00b7lin", "fin\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "$(", "ART", "ART", "NN", "VMFIN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und dessen hofnungs baum beginnet sch\u00f6n zu bl\u00fchn/", "tokens": ["Und", "des\u00b7sen", "hof\u00b7nungs", "baum", "be\u00b7gin\u00b7net", "sch\u00f6n", "zu", "bl\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ADV", "VVFIN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "So wird sich alle welt gleich wider ihn verbinden/", "tokens": ["So", "wird", "sich", "al\u00b7le", "welt", "gleich", "wi\u00b7der", "ihn", "ver\u00b7bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "PIAT", "NN", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Und mit gesamter hand ihn pl\u00f6tzlich \u00fcberziehn.", "tokens": ["Und", "mit", "ge\u00b7sam\u00b7ter", "hand", "ihn", "pl\u00f6tz\u00b7lich", "\u00fc\u00b7ber\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Wir m\u00fcssen offt bald di\u00df/ bald jenes wiedergeben/", "tokens": ["Wir", "m\u00fcs\u00b7sen", "offt", "bald", "di\u00df", "/", "bald", "je\u00b7nes", "wie\u00b7der\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PDS", "$(", "ADV", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Das man nicht ohne grund vor schon gewonnen hielt/", "tokens": ["Das", "man", "nicht", "oh\u00b7ne", "grund", "vor", "schon", "ge\u00b7won\u00b7nen", "hielt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PTKNEG", "APPR", "NN", "APPR", "ADV", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Weil unsre freunde selbst sich wider uns erheben/", "tokens": ["Weil", "uns\u00b7re", "freun\u00b7de", "selbst", "sich", "wi\u00b7der", "uns", "er\u00b7he\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PRF", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Wenn gifft der eifersucht aus ihren hertzen quillt.", "tokens": ["Wenn", "gifft", "der", "ei\u00b7fer\u00b7sucht", "aus", "ih\u00b7ren", "hert\u00b7zen", "quillt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Di\u00df alles und noch mehr kan unser spiel uns lehren:", "tokens": ["Di\u00df", "al\u00b7les", "und", "noch", "mehr", "kan", "un\u00b7ser", "spiel", "uns", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "KON", "ADV", "ADV", "VMFIN", "PPOSAT", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Jhr/ die ihr euch mit m\u00fch der rechenkunst befleist/", "tokens": ["Ihr", "/", "die", "ihr", "euch", "mit", "m\u00fch", "der", "re\u00b7chen\u00b7kunst", "be\u00b7fleist", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PRELS", "PPER", "PRF", "APPR", "ADJD", "ART", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Kommt insgesammt zu uns/ hier k\u00f6nnt ihr zahlen h\u00f6ren/", "tokens": ["Kommt", "ins\u00b7ge\u00b7sammt", "zu", "uns", "/", "hier", "k\u00f6nnt", "ihr", "zah\u00b7len", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "$(", "ADV", "VVFIN", "PPER", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die euch kein Seckerwitz/ kein Adam Riese weist.", "tokens": ["Die", "euch", "kein", "Se\u00b7cker\u00b7witz", "/", "kein", "A\u00b7dam", "Rie\u00b7se", "weist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "NN", "$(", "PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ein iedes liebes glied wird hier vergn\u00fcgung finden/", "tokens": ["Ein", "ie\u00b7des", "lie\u00b7bes", "glied", "wird", "hier", "ver\u00b7gn\u00fc\u00b7gung", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VAFIN", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Das auge sieht sich nicht der sch\u00f6nen bilder satt/", "tokens": ["Das", "au\u00b7ge", "sieht", "sich", "nicht", "der", "sch\u00f6\u00b7nen", "bil\u00b7der", "satt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKNEG", "ART", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Das ohre kan vom thon der bl\u00e4tter lust empfinden/", "tokens": ["Das", "oh\u00b7re", "kan", "vom", "thon", "der", "bl\u00e4t\u00b7ter", "lust", "emp\u00b7fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Der arm wird hoch erh\u00f6ht/ wenn man gesieget hat.", "tokens": ["Der", "arm", "wird", "hoch", "er\u00b7h\u00f6ht", "/", "wenn", "man", "ge\u00b7sie\u00b7get", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "ADJD", "VVPP", "$(", "KOUS", "PIS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Jedoch/ was m\u00fch ich mich/ das spiel recht zu erheben/", "tokens": ["Je\u00b7doch", "/", "was", "m\u00fch", "ich", "mich", "/", "das", "spiel", "recht", "zu", "er\u00b7he\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PWS", "VMFIN", "PPER", "PRF", "$(", "PDS", "VVFIN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Ich finde meine faust vor dieses werck zu klein/", "tokens": ["Ich", "fin\u00b7de", "mei\u00b7ne", "faust", "vor", "die\u00b7ses", "werck", "zu", "klein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PDAT", "NN", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Ein knorr ist viel zu d\u00fcrr rechtschafnen glantz zu geben/", "tokens": ["Ein", "knorr", "ist", "viel", "zu", "d\u00fcrr", "recht\u00b7schaf\u00b7nen", "glantz", "zu", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Es mu\u00df ein Stein der Loh/ ein Wald des Hofes seyn.", "tokens": ["Es", "mu\u00df", "ein", "Stein", "der", "Loh", "/", "ein", "Wald", "des", "Ho\u00b7fes", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN", "$(", "ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Weg Hor/ weg Bindari/ Bassette und Tricheken/", "tokens": ["Weg", "Hor", "/", "weg", "Bin\u00b7da\u00b7ri", "/", "Bas\u00b7set\u00b7te", "und", "Tri\u00b7che\u00b7ken", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$(", "ADV", "NE", "$(", "NE", "KON", "NN", "$("], "meter": "+-+-+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.78": {"text": "Weg Hornbre/ contra/ kauff- und Lanterlilabet/", "tokens": ["Weg", "Horn\u00b7bre", "/", "cont\u00b7ra", "/", "kauff", "und", "Lan\u00b7ter\u00b7li\u00b7la\u00b7bet", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$(", "NE", "$(", "TRUNC", "KON", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.79": {"text": "Es saget Schlefien mit Preussen und Polacken/", "tokens": ["Es", "sa\u00b7get", "Schle\u00b7fi\u00b7en", "mit", "Preus\u00b7sen", "und", "Po\u00b7la\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Da\u00df \u00fcber alles spiel das Trappeliren geht.", "tokens": ["Da\u00df", "\u00fc\u00b7ber", "al\u00b7les", "spiel", "das", "Trap\u00b7pe\u00b7li\u00b7ren", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PIS", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Kommt freunde/ last uns nur heut mit einander freuen/", "tokens": ["Kommt", "freun\u00b7de", "/", "last", "uns", "nur", "heut", "mit", "ein\u00b7an\u00b7der", "freu\u00b7en", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$(", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Und nehmet g\u00fcnstig an/ was hier mein geist erdacht;", "tokens": ["Und", "neh\u00b7met", "g\u00fcns\u00b7tig", "an", "/", "was", "hier", "mein", "geist", "er\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$(", "PWS", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Geschichts so sol mein mund mit vollem halse schreyen;", "tokens": ["Ge\u00b7schichts", "so", "sol", "mein", "mund", "mit", "vol\u00b7lem", "hal\u00b7se", "schre\u00b7yen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Mein sechsundzwantziger ist redlich angebracht.", "tokens": ["Mein", "sech\u00b7sund\u00b7zwant\u00b7zi\u00b7ger", "ist", "red\u00b7lich", "an\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}