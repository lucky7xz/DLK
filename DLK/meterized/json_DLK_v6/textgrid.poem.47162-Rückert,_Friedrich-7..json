{"textgrid.poem.47162": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "7.", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eines hat mich oft erstaunet,", "tokens": ["Ei\u00b7nes", "hat", "mich", "oft", "er\u00b7stau\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebste! wenn die Fremden nahn,", "tokens": ["Liebs\u00b7te", "!", "wenn", "die", "Frem\u00b7den", "nahn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "ART", "NN", "ADJA", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie du scherzen frohgelaunet", "tokens": ["Wie", "du", "scher\u00b7zen", "froh\u00b7ge\u00b7lau\u00b7net"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVINF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kannst, als sei dir nichts gethan.", "tokens": ["Kannst", ",", "als", "sei", "dir", "nichts", "ge\u00b7than", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "KOKOM", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Durch die tausend Nichtigkeiten", "tokens": ["Durch", "die", "tau\u00b7send", "Nich\u00b7tig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00f6rmlicher Geselligkeit", "tokens": ["F\u00f6rm\u00b7li\u00b7cher", "Ge\u00b7sel\u00b7lig\u00b7keit"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Wei\u00dft du heiter hinzugleiten,", "tokens": ["Wei\u00dft", "du", "hei\u00b7ter", "hin\u00b7zu\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rechts und links Aufmerksamkeit.", "tokens": ["Rechts", "und", "links", "Auf\u00b7merk\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ist dir nicht, seit du empfangen", "tokens": ["Ist", "dir", "nicht", ",", "seit", "du", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "VVINF"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.2": {"text": "Diesen Himmel in der Brust,", "tokens": ["Die\u00b7sen", "Him\u00b7mel", "in", "der", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr die Welt der Sinn vergangen", "tokens": ["F\u00fcr", "die", "Welt", "der", "Sinn", "ver\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und f\u00fcr ihren Tand die Lust?", "tokens": ["Und", "f\u00fcr", "ih\u00b7ren", "Tand", "die", "Lust", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Liebste! mir, seit ich getrunken", "tokens": ["Liebs\u00b7te", "!", "mir", ",", "seit", "ich", "ge\u00b7trun\u00b7ken"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "$,", "KOUS", "PPER", "VVPP"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Habe deinen heil'gen Ku\u00df,", "tokens": ["Ha\u00b7be", "dei\u00b7nen", "heil'\u00b7gen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist das Irdische versunken", "tokens": ["Ist", "das", "Ir\u00b7di\u00b7sche", "ver\u00b7sun\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Welt ein \u00dcberflu\u00df.", "tokens": ["Und", "die", "Welt", "ein", "\u00dc\u00b7berf\u00b7lu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Sie zu sehen, sie zu h\u00f6ren,", "tokens": ["Sie", "zu", "se\u00b7hen", ",", "sie", "zu", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihr gesehn, geh\u00f6rt zu sein,", "tokens": ["Ihr", "ge\u00b7sehn", ",", "ge\u00b7h\u00f6rt", "zu", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "VVFIN", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kann nur das Bewu\u00dftsein st\u00f6ren,", "tokens": ["Kann", "nur", "das", "Be\u00b7wu\u00df\u00b7tsein", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ich lebe dir allein.", "tokens": ["Da\u00df", "ich", "le\u00b7be", "dir", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "La\u00df mich diese Last nicht tragen,", "tokens": ["La\u00df", "mich", "die\u00b7se", "Last", "nicht", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PDAT", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den andern umzugehn,", "tokens": ["Mit", "den", "an\u00b7dern", "um\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVIZU", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denen ich doch nicht darf sagen,", "tokens": ["De\u00b7nen", "ich", "doch", "nicht", "darf", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie durch dich mir ist geschehn.", "tokens": ["Wie", "durch", "dich", "mir", "ist", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPER", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Aber du vermagst im Herzen", "tokens": ["A\u00b7ber", "du", "ver\u00b7magst", "im", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tief zu bergen dies Gef\u00fchl,", "tokens": ["Tief", "zu", "ber\u00b7gen", "dies", "Ge\u00b7f\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "PDS", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Au\u00dfen munter fort zu scherzen", "tokens": ["Au\u00b7\u00dfen", "mun\u00b7ter", "fort", "zu", "scher\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PTKVZ", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In dem muntern Weltgew\u00fchl.", "tokens": ["In", "dem", "mun\u00b7tern", "Welt\u00b7ge\u00b7w\u00fchl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}