{"textgrid.poem.56263": {"metadata": {"author": {"name": "Chamisso, Adelbert von", "birth": "N.A.", "death": "N.A."}, "title": "Polterabend", "genre": "verse", "period": "N.A.", "pub_year": 1809, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Woher, Alte, deine sch\u00f6nen", "tokens": ["Wo\u00b7her", ",", "Al\u00b7te", ",", "dei\u00b7ne", "sch\u00f6\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["PWAV", "$,", "NN", "$,", "PPOSAT", "ADJA"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Launen? willst du uns erfreuen?", "tokens": ["Lau\u00b7nen", "?", "willst", "du", "uns", "er\u00b7freu\u00b7en", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Willst du dich mit uns vers\u00f6hnen?", "tokens": ["Willst", "du", "dich", "mit", "uns", "ver\u00b7s\u00f6h\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nein, die Alte will noch freien,", "tokens": ["Nein", ",", "die", "Al\u00b7te", "will", "noch", "frei\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VMFIN", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, sie will, vor Toresschlusse,", "tokens": ["Nein", ",", "sie", "will", ",", "vor", "To\u00b7res\u00b7schlus\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Humpeln noch mit lahmem Fu\u00dfe,", "tokens": ["Hum\u00b7peln", "noch", "mit", "lah\u00b7mem", "Fu\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und um welchen Preis es sei,", "tokens": ["Und", "um", "wel\u00b7chen", "Preis", "es", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PWAT", "NN", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ei, ei!", "tokens": ["Ei", ",", "ei", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Noch ein T\u00e4nzlein, oder zwei.", "tokens": ["Noch", "ein", "T\u00e4nz\u00b7lein", ",", "o\u00b7der", "zwei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "KON", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hurtig, hurtig! liebe Lene,", "tokens": ["Hur\u00b7tig", ",", "hur\u00b7tig", "!", "lie\u00b7be", "Le\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$.", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Her die Schminke, die Per\u00fccke;", "tokens": ["Her", "die", "Schmin\u00b7ke", ",", "die", "Pe\u00b7r\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bringe her mir meine Z\u00e4hne,", "tokens": ["Brin\u00b7ge", "her", "mir", "mei\u00b7ne", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APZR", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meinen Busen, meine Kr\u00fccke;", "tokens": ["Mei\u00b7nen", "Bu\u00b7sen", ",", "mei\u00b7ne", "Kr\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also will ich seiner harren. \u2013", "tokens": ["Al\u00b7so", "will", "ich", "sei\u00b7ner", "har\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "H\u00f6r ich nicht die T\u00fcre knarren? \u2013", "tokens": ["H\u00f6r", "ich", "nicht", "die", "T\u00fc\u00b7re", "knar\u00b7ren", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist er's? \u2013 Nein \u2013 es geht vorbei.", "tokens": ["Ist", "er's", "?", "\u2013", "Nein", "\u2013", "es", "geht", "vor\u00b7bei", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$.", "$(", "PTKANT", "$(", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ei, ei!", "tokens": ["Ei", ",", "ei", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "T\u00f6pfe werfen sie entzwei.", "tokens": ["T\u00f6p\u00b7fe", "wer\u00b7fen", "sie", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Testament und Ehepakten", "tokens": ["Tes\u00b7ta\u00b7ment", "und", "E\u00b7he\u00b7pak\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat der Schreiber wohl geschrieben;", "tokens": ["Hat", "der", "Schrei\u00b7ber", "wohl", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Beides nahm er zu den Akten,", "tokens": ["Bei\u00b7des", "nahm", "er", "zu", "den", "Ak\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Also darf ich frei ihn lieben.", "tokens": ["Al\u00b7so", "darf", "ich", "frei", "ihn", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also will ich seiner harren. \u2013", "tokens": ["Al\u00b7so", "will", "ich", "sei\u00b7ner", "har\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "H\u00f6r ich nicht die T\u00fcre knarren? \u2013", "tokens": ["H\u00f6r", "ich", "nicht", "die", "T\u00fc\u00b7re", "knar\u00b7ren", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist er's? \u2013 Nein \u2013 es geht vorbei.", "tokens": ["Ist", "er's", "?", "\u2013", "Nein", "\u2013", "es", "geht", "vor\u00b7bei", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$.", "$(", "PTKANT", "$(", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ei, ei!", "tokens": ["Ei", ",", "ei", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "T\u00f6pfe werfen sie entzwei.", "tokens": ["T\u00f6p\u00b7fe", "wer\u00b7fen", "sie", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wird der Priester, wird der K\u00fcster,", "tokens": ["Wird", "der", "Pries\u00b7ter", ",", "wird", "der", "K\u00fcs\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Werden bald die G\u00e4ste kommen?", "tokens": ["Wer\u00b7den", "bald", "die", "G\u00e4s\u00b7te", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "Und mein Br\u00e4utigam! o w\u00fc\u00dft er,", "tokens": ["Und", "mein", "Br\u00e4u\u00b7ti\u00b7gam", "!", "o", "w\u00fc\u00dft", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$.", "FM", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie ich seiner, liebentglommen,", "tokens": ["Wie", "ich", "sei\u00b7ner", ",", "lie\u00b7bent\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bangend harre, wie ich schmachte? \u2013 \u2013", "tokens": ["Ban\u00b7gend", "har\u00b7re", ",", "wie", "ich", "schmach\u00b7te", "?", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Klopft er? \u2013 Ist er's? \u2013 Sachte, sachte!", "tokens": ["Klopft", "er", "?", "\u2013", "Ist", "er's", "?", "\u2013", "Sach\u00b7te", ",", "sach\u00b7te", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "VAFIN", "PIS", "$.", "$(", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ungebetne sind dabei.", "tokens": ["Un\u00b7ge\u00b7bet\u00b7ne", "sind", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ei, ei!", "tokens": ["Ei", ",", "ei", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Sind die Leichentr\u00e4ger frei.", "tokens": ["Sind", "die", "Lei\u00b7chen\u00b7tr\u00e4\u00b7ger", "frei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Legen mich die schwarzen Leute", "tokens": ["Le\u00b7gen", "mich", "die", "schwar\u00b7zen", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einsam in ein enges Bette,", "tokens": ["Ein\u00b7sam", "in", "ein", "en\u00b7ges", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schleppen sich mit ihrer Beute", "tokens": ["Schlep\u00b7pen", "sich", "mit", "ih\u00b7rer", "Beu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Langsam nach der Ruhest\u00e4tte;", "tokens": ["Lang\u00b7sam", "nach", "der", "Ru\u00b7he\u00b7st\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Priester, Br\u00e4utigam und G\u00e4ste", "tokens": ["Pries\u00b7ter", ",", "Br\u00e4u\u00b7ti\u00b7gam", "und", "G\u00e4s\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NE", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Singen fr\u00f6hlich bei dem Feste, \u2013", "tokens": ["Sin\u00b7gen", "fr\u00f6h\u00b7lich", "bei", "dem", "Fes\u00b7te", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Auch die Rede war vorbei \u2013", "tokens": ["Auch", "die", "Re\u00b7de", "war", "vor\u00b7bei", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ei, ei!", "tokens": ["Ei", ",", "ei", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Nicht ein T\u00e4nzlein, oder zwei!", "tokens": ["Nicht", "ein", "T\u00e4nz\u00b7lein", ",", "o\u00b7der", "zwei", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "KON", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}