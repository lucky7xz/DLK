{"textgrid.poem.41435": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der L\u00f6we", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr R\u00e4the, merkt in diesem Jahre,", "tokens": ["Ihr", "R\u00e4\u00b7the", ",", "merkt", "in", "die\u00b7sem", "Jah\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Merkt, was die treue Fabel schreibt,", "tokens": ["Merkt", ",", "was", "die", "treu\u00b7e", "Fa\u00b7bel", "schreibt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Der Clio Schwester, die das Wahre", "tokens": ["Der", "Clio", "Schwes\u00b7ter", ",", "die", "das", "Wah\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NE", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch diesem M\u00e4hrchen einverleibt.", "tokens": ["Auch", "die\u00b7sem", "M\u00e4hr\u00b7chen", "ein\u00b7ver\u00b7leibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df sie den Hochmuth nicht verletze,", "tokens": ["Da\u00df", "sie", "den", "Hoch\u00b7muth", "nicht", "ver\u00b7let\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nimmt sie den Schein der Einfalt an,", "tokens": ["Nimmt", "sie", "den", "Schein", "der", "Ein\u00b7falt", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Obgleich die Weisheit ihrer S\u00e4tze", "tokens": ["Ob\u00b7gleich", "die", "Weis\u00b7heit", "ih\u00b7rer", "S\u00e4t\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Orakel \u00fcbertreffen kann.", "tokens": ["O\u00b7ra\u00b7kel", "\u00fc\u00b7bert\u00b7ref\u00b7fen", "kann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Es herrschte, stolz auf Stand und Ahnen,", "tokens": ["Es", "herrschte", ",", "stolz", "auf", "Stand", "und", "Ah\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der gro\u00dfe Sultan Leopard,", "tokens": ["Der", "gro\u00b7\u00dfe", "Sul\u00b7tan", "Le\u00b7o\u00b7pard", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der, stark durch Reich und Unterthanen,", "tokens": ["Der", ",", "stark", "durch", "Reich", "und", "Un\u00b7ter\u00b7tha\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Bundsgenossen st\u00e4rker ward.", "tokens": ["Durch", "Bunds\u00b7ge\u00b7nos\u00b7sen", "st\u00e4r\u00b7ker", "ward", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm huldigten die schw\u00e4chern Thiere,", "tokens": ["Ihm", "hul\u00b7dig\u00b7ten", "die", "schw\u00e4\u00b7chern", "Thie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vasallisch und mit banger Pflicht;", "tokens": ["Va\u00b7sal\u00b7lisch", "und", "mit", "ban\u00b7ger", "Pflicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Wollenvieh und Hirsch und Stiere", "tokens": ["Das", "Wol\u00b7len\u00b7vieh", "und", "Hirsch", "und", "Stie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Geh\u00f6rten vor sein Halsgericht.", "tokens": ["Ge\u00b7h\u00f6r\u00b7ten", "vor", "sein", "Hals\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dem L\u00f6wen ward ein Prinz geboren,", "tokens": ["Dem", "L\u00f6\u00b7wen", "ward", "ein", "Prinz", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Ruf erscholl im Augenblick.", "tokens": ["Der", "Ruf", "er\u00b7scholl", "im", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ward auch keine Zeit verloren;", "tokens": ["Es", "ward", "auch", "kei\u00b7ne", "Zeit", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man schickt Gesandten, und w\u00fcnscht Gl\u00fcck.", "tokens": ["Man", "schickt", "Ge\u00b7sand\u00b7ten", ",", "und", "w\u00fcnscht", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "$,", "KON", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Schrecken m\u00e4chtiger Regenten,", "tokens": ["Das", "Schre\u00b7cken", "m\u00e4ch\u00b7ti\u00b7ger", "Re\u00b7gen\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Der Vater, starb, nicht sehr betagt.", "tokens": ["Der", "Va\u00b7ter", ",", "starb", ",", "nicht", "sehr", "be\u00b7tagt", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "$,", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Man \u00fcbte sich in Complimenten,", "tokens": ["Man", "\u00fcb\u00b7te", "sich", "in", "Com\u00b7pli\u00b7men\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Man schickt Gesandten, lobt und klagt.", "tokens": ["Man", "schickt", "Ge\u00b7sand\u00b7ten", ",", "lobt", "und", "klagt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Sultan l\u00e4\u00dft den Brandfuchs kommen,", "tokens": ["Der", "Sul\u00b7tan", "l\u00e4\u00dft", "den", "Brand\u00b7fuchs", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn dieser Schalk war sein Vizir.", "tokens": ["Denn", "die\u00b7ser", "Schalk", "war", "sein", "Vi\u00b7zir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du wei\u00dft, spricht er, was wir vernommen:", "tokens": ["Du", "wei\u00dft", ",", "spricht", "er", ",", "was", "wir", "ver\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Der L\u00f6w' ist todt; was f\u00fcrchten wir?", "tokens": ["Der", "L\u00f6\u00b7w'", "ist", "todt", ";", "was", "f\u00fcrch\u00b7ten", "wir", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der Waise mu\u00df sich schon bequemen,", "tokens": ["Der", "Wai\u00b7se", "mu\u00df", "sich", "schon", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und ihn beklag' ich in der That:", "tokens": ["Und", "ihn", "be\u00b7klag'", "ich", "in", "der", "That", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Uns kann er auch kein Zicklein nehmen;", "tokens": ["Uns", "kann", "er", "auch", "kein", "Zic\u00b7klein", "neh\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Er h\u00fcte das nur, was er hat.", "tokens": ["Er", "h\u00fc\u00b7te", "das", "nur", ",", "was", "er", "hat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "ADV", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Herr, sagt der Fuchs, spart eure G\u00fcte", "tokens": ["Herr", ",", "sagt", "der", "Fuchs", ",", "spart", "eu\u00b7re", "G\u00fc\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "ART", "NE", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr andre Waisen, als f\u00fcr ihn.", "tokens": ["F\u00fcr", "and\u00b7re", "Wai\u00b7sen", ",", "als", "f\u00fcr", "ihn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUS", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr zieht wol nicht in sein Gebiete;", "tokens": ["Ihr", "zieht", "wol", "nicht", "in", "sein", "Ge\u00b7bie\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er kann, vielleicht, in eures ziehn.", "tokens": ["Er", "kann", ",", "viel\u00b7leicht", ",", "in", "eu\u00b7res", "ziehn", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "ADV", "$,", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Entschmeichelt euch dem nahen Rachen,", "tokens": ["Ent\u00b7schmei\u00b7chelt", "euch", "dem", "na\u00b7hen", "Ra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Macht ihn zum nachbarlichen Freund;", "tokens": ["Macht", "ihn", "zum", "nach\u00b7bar\u00b7li\u00b7chen", "Freund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Wollt ihr ihn nicht zum Freunde machen,", "tokens": ["Wollt", "ihr", "ihn", "nicht", "zum", "Freun\u00b7de", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "PTKNEG", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So eilt, und schw\u00e4chet diesen Feind.", "tokens": ["So", "eilt", ",", "und", "schw\u00e4\u00b7chet", "die\u00b7sen", "Feind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KON", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar bin ich kein Aspectenmesser,", "tokens": ["Zwar", "bin", "ich", "kein", "A\u00b7spec\u00b7ten\u00b7mes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Allein ich wittre Zank und Krieg,", "tokens": ["Al\u00b7lein", "ich", "witt\u00b7re", "Zank", "und", "Krieg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und unsre b\u00e4rtchen Menschenfresser", "tokens": ["Und", "uns\u00b7re", "b\u00e4rt\u00b7chen", "Men\u00b7schen\u00b7fres\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verhindern nicht des L\u00f6wen Sieg.", "tokens": ["Ver\u00b7hin\u00b7dern", "nicht", "des", "L\u00f6\u00b7wen", "Sieg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm ist das Gl\u00fcck der Waffen eigen,", "tokens": ["Ihm", "ist", "das", "Gl\u00fcck", "der", "Waf\u00b7fen", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nie wird er, eingeschl\u00e4fert, ruhn,", "tokens": ["Nie", "wird", "er", ",", "ein\u00b7ge\u00b7schl\u00e4\u00b7fert", ",", "ruhn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "VVPP", "$,", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und, wann sich seine Rotten zeigen,", "tokens": ["Und", ",", "wann", "sich", "sei\u00b7ne", "Rot\u00b7ten", "zei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PRF", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ach! so behalten wir kein Huhn.", "tokens": ["Ach", "!", "so", "be\u00b7hal\u00b7ten", "wir", "kein", "Huhn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der Sultan h\u00e4lt die Furcht f\u00fcr eitel,", "tokens": ["Der", "Sul\u00b7tan", "h\u00e4lt", "die", "Furcht", "f\u00fcr", "ei\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und, so wie Mupf die Lehrer h\u00f6rt,", "tokens": ["Und", ",", "so", "wie", "Mupf", "die", "Leh\u00b7rer", "h\u00f6rt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "KOKOM", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vernimmt er Worte, kratzt die Scheitel,", "tokens": ["Ver\u00b7nimmt", "er", "Wor\u00b7te", ",", "kratzt", "die", "Schei\u00b7tel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "G\u00e4hnt, und entschlummert unbekehrt.", "tokens": ["G\u00e4hnt", ",", "und", "ent\u00b7schlum\u00b7mert", "un\u00b7be\u00b7kehrt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "VVFIN", "ADJD", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bald aber zeigt die schnelle Strafe", "tokens": ["Bald", "a\u00b7ber", "zeigt", "die", "schnel\u00b7le", "Stra\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Folgen gro\u00dfer Sicherheit.", "tokens": ["Die", "Fol\u00b7gen", "gro\u00b7\u00dfer", "Si\u00b7cher\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der L\u00f6we weckt ihn aus dem Schlafe:", "tokens": ["Der", "L\u00f6\u00b7we", "weckt", "ihn", "aus", "dem", "Schla\u00b7fe", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Er k\u00f6mmt, und mit ihm Muth und Streit.", "tokens": ["Er", "k\u00f6mmt", ",", "und", "mit", "ihm", "Muth", "und", "Streit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "APPR", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Man meldet das den Bundsgenossen,", "tokens": ["Man", "mel\u00b7det", "das", "den", "Bunds\u00b7ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Macht L\u00e4rm, und schreit verwirrungvoll.", "tokens": ["Macht", "L\u00e4rm", ",", "und", "schreit", "ver\u00b7wir\u00b7rung\u00b7voll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "KON", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lang' ist der Divan unentschlossen,", "tokens": ["Lang'", "ist", "der", "Di\u00b7van", "un\u00b7ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie man den Einfall hemmen soll.", "tokens": ["Wie", "man", "den", "Ein\u00b7fall", "hem\u00b7men", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Man fragt den Fuchs. Wie sehr gew\u00f6hnen", "tokens": ["Man", "fragt", "den", "Fuchs", ".", "Wie", "sehr", "ge\u00b7w\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NE", "$.", "PWAV", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wir uns zur blinden Zuversicht!", "tokens": ["Wir", "uns", "zur", "blin\u00b7den", "Zu\u00b7ver\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Spricht er. La\u00dft uns den Feind vers\u00f6hnen,", "tokens": ["Spricht", "er", ".", "La\u00dft", "uns", "den", "Feind", "ver\u00b7s\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "VVIMP", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und fremder Hilfe trauet nicht.", "tokens": ["Und", "frem\u00b7der", "Hil\u00b7fe", "trau\u00b7et", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Thun viele Helfer Wunderwerke?", "tokens": ["Thun", "vie\u00b7le", "Hel\u00b7fer", "Wun\u00b7der\u00b7wer\u00b7ke", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NN", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "O nein. Der L\u00f6we hat nur drei:", "tokens": ["O", "nein", ".", "Der", "L\u00f6\u00b7we", "hat", "nur", "drei", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "ART", "NE", "VAFIN", "ADV", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Muth, die Wachsamkeit, die St\u00e4rke,", "tokens": ["Den", "Muth", ",", "die", "Wach\u00b7sam\u00b7keit", ",", "die", "St\u00e4r\u00b7ke", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und siegreich stehn ihm diese bei.", "tokens": ["Und", "sieg\u00b7reich", "stehn", "ihm", "die\u00b7se", "bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gebt ihm, da\u00df er nicht mehr entf\u00fchre,", "tokens": ["Gebt", "ihm", ",", "da\u00df", "er", "nicht", "mehr", "ent\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Schaf, ein Reh, ein feistes Rind:", "tokens": ["Ein", "Schaf", ",", "ein", "Reh", ",", "ein", "feis\u00b7tes", "Rind", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kurz, eines der geringern Thiere,", "tokens": ["Kurz", ",", "ei\u00b7nes", "der", "ge\u00b7rin\u00b7gern", "Thie\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die unserm Reich entbehrlich sind.", "tokens": ["Die", "un\u00b7serm", "Reich", "ent\u00b7behr\u00b7lich", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sein Vorschlag wird verzagt befunden:", "tokens": ["Sein", "Vor\u00b7schlag", "wird", "ver\u00b7zagt", "be\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Reichsrath dachte nicht, wie er.", "tokens": ["Der", "Reichs\u00b7rath", "dach\u00b7te", "nicht", ",", "wie", "er", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man r\u00fcstet sich, wird \u00fcberwunden,", "tokens": ["Man", "r\u00fcs\u00b7tet", "sich", ",", "wird", "\u00fc\u00b7berw\u00b7un\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und macht sich Krieg und Frieden schwer.", "tokens": ["Und", "macht", "sich", "Krieg", "und", "Frie\u00b7den", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dies lehrt uns eine Wahrheit fassen,", "tokens": ["Dies", "lehrt", "uns", "ei\u00b7ne", "Wahr\u00b7heit", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Regel der Regierungskunst:", "tokens": ["Die", "Re\u00b7gel", "der", "Re\u00b7gie\u00b7rungs\u00b7kunst", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wollt ihr den L\u00f6wen wachsen lassen,", "tokens": ["Wollt", "ihr", "den", "L\u00f6\u00b7wen", "wach\u00b7sen", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So suchet zeitig seine Gunst.", "tokens": ["So", "su\u00b7chet", "zei\u00b7tig", "sei\u00b7ne", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}