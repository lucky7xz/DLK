{"textgrid.poem.67783": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Jesus", "genre": "verse", "period": "N.A.", "pub_year": 1780, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sei gegr\u00fc\u00dfet, sch\u00f6nste Blume,", "tokens": ["Sei", "ge\u00b7gr\u00fc\u00b7\u00dfet", ",", "sch\u00f6ns\u00b7te", "Blu\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aller Menschheit Blume Du!", "tokens": ["Al\u00b7ler", "Menschheit", "Blu\u00b7me", "Du", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Zu Dir kommen alle Frommen;", "tokens": ["Zu", "Dir", "kom\u00b7men", "al\u00b7le", "From\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gottes Gnade, Himmels Zier", "tokens": ["Got\u00b7tes", "Gna\u00b7de", ",", "Him\u00b7mels", "Zier"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$,", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wohnt in Dir.", "tokens": ["Wohnt", "in", "Dir", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Ich komm' auch; o, w\u00e4r' ich kommen", "tokens": ["Ich", "komm'", "auch", ";", "o", ",", "w\u00e4r'", "ich", "kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$.", "FM", "$,", "VAFIN", "PPER", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Lange schon und h\u00e4tte Ruh!", "tokens": ["Lan\u00b7ge", "schon", "und", "h\u00e4t\u00b7te", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Lange bin ich irrgegangen,", "tokens": ["Lan\u00b7ge", "bin", "ich", "irr\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Suchte Ruh an falschem Ort.", "tokens": ["Such\u00b7te", "Ruh", "an", "fal\u00b7schem", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine Augen gehn mir \u00fcber,", "tokens": ["Mei\u00b7ne", "Au\u00b7gen", "gehn", "mir", "\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und voll Wehmuth ist mein Herz,", "tokens": ["Und", "voll", "Weh\u00b7muth", "ist", "mein", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist voll Schmerz;", "tokens": ["Ist", "voll", "Schmerz", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Denn ich suchte ", "tokens": ["Denn", "ich", "such\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Suchte ", "tokens": ["Such\u00b7te"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "Konnt' ich, was ich suchte, finden?", "tokens": ["Konnt'", "ich", ",", "was", "ich", "such\u00b7te", ",", "fin\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo ist Ruhe ohne Dich?", "tokens": ["Wo", "ist", "Ru\u00b7he", "oh\u00b7ne", "Dich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geistesqu\u00e4len, Herzensqu\u00e4len,", "tokens": ["Geis\u00b7tes\u00b7qu\u00e4\u00b7len", ",", "Her\u00b7zens\u00b7qu\u00e4\u00b7len", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Brunnen fand ich ohne Trank!", "tokens": ["Brun\u00b7nen", "fand", "ich", "oh\u00b7ne", "Trank", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ohne Dank", "tokens": ["Oh\u00b7ne", "Dank"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Martern sich der Menschen Seelen,", "tokens": ["Mar\u00b7tern", "sich", "der", "Men\u00b7schen", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Martern oft sich ewiglich.", "tokens": ["Mar\u00b7tern", "oft", "sich", "e\u00b7wig\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PRF", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbin die Sch\u00f6pfung will ich gehen,\u00ab", "tokens": ["\u00bb", "in", "die", "Sch\u00f6p\u00b7fung", "will", "ich", "ge\u00b7hen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach ich, \u00bbda ist Gott gewi\u00df.", "tokens": ["Sprach", "ich", ",", "\u00bb", "da", "ist", "Gott", "ge\u00b7wi\u00df", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "$(", "ADV", "VAFIN", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unter Blumen werd' ich finden,", "tokens": ["Un\u00b7ter", "Blu\u00b7men", "werd'", "ich", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der der Blumen Vater ist.", "tokens": ["Der", "der", "Blu\u00b7men", "Va\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo Du bist,", "tokens": ["Wo", "Du", "bist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "La\u00df Dich, Vater, la\u00df Dich finden!", "tokens": ["La\u00df", "Dich", ",", "Va\u00b7ter", ",", "la\u00df", "Dich", "fin\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "NN", "$,", "VVIMP", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Hier, o Gott, bist Du gewi\u00df.\u00ab", "tokens": ["Hier", ",", "o", "Gott", ",", "bist", "Du", "ge\u00b7wi\u00df", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "FM", "NN", "$,", "VAFIN", "PPER", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ueberall sah ich die Spuren", "tokens": ["Ue\u00b7be\u00b7rall", "sah", "ich", "die", "Spu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Seiner nahen Gegenwart;", "tokens": ["Sei\u00b7ner", "na\u00b7hen", "Ge\u00b7gen\u00b7wart", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ahnet' ihn auf Thal und H\u00f6hen,", "tokens": ["Ah\u00b7net'", "ihn", "auf", "Thal", "und", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fragte rings die Creatur:", "tokens": ["Frag\u00b7te", "rings", "die", "Crea\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "\u00bbseine Spur", "tokens": ["\u00bb", "sei\u00b7ne", "Spur"], "token_info": ["punct", "word", "word"], "pos": ["$(", "PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Sah ich; habt Ihr ihn gesehen?", "tokens": ["Sah", "ich", ";", "habt", "Ihr", "ihn", "ge\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wo ist seine Gegenwart?\u00ab", "tokens": ["Wo", "ist", "sei\u00b7ne", "Ge\u00b7gen\u00b7wart", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sei gegr\u00fc\u00dfet, sch\u00f6nste Blume,", "tokens": ["Sei", "ge\u00b7gr\u00fc\u00b7\u00dfet", ",", "sch\u00f6ns\u00b7te", "Blu\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du, der Gottheit Abbild, Du!", "tokens": ["Du", ",", "der", "Got\u00b7theit", "Ab\u00b7bild", ",", "Du", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "NN", "$,", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lilien und Rosen bl\u00fchen", "tokens": ["Li\u00b7li\u00b7en", "und", "Ro\u00b7sen", "bl\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um Dich, und Dein Dornenkranz", "tokens": ["Um", "Dich", ",", "und", "Dein", "Dor\u00b7nen\u00b7kranz"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "PPER", "$,", "KON", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ist voll Glanz.", "tokens": ["Ist", "voll", "Glanz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Was soll ich mich weiter m\u00fchen?", "tokens": ["Was", "soll", "ich", "mich", "wei\u00b7ter", "m\u00fc\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Den ich suchte, Gott, ist hier!", "tokens": ["Den", "ich", "such\u00b7te", ",", "Gott", ",", "ist", "hier", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "$,", "NN", "$,", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Kommt zu ihm, die Ihr, m\u00fchselig", "tokens": ["Kommt", "zu", "ihm", ",", "die", "Ihr", ",", "m\u00fch\u00b7se\u00b7lig"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "PPER", "$,", "PRELS", "PPER", "$,", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und beladen, suchet Ruh!", "tokens": ["Und", "be\u00b7la\u00b7den", ",", "su\u00b7chet", "Ruh", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVPP", "$,", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Er, er wird Euch Geistesleben,", "tokens": ["Er", ",", "er", "wird", "Euch", "Geis\u00b7tes\u00b7le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unschuld, Liebe, s\u00fc\u00dfe Kraft,", "tokens": ["Un\u00b7schuld", ",", "Lie\u00b7be", ",", "s\u00fc\u00b7\u00dfe", "Kraft", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Herzenssaft,", "tokens": ["Her\u00b7zens\u00b7saft", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Gottes Ruh wird er Euch geben!", "tokens": ["Got\u00b7tes", "Ruh", "wird", "er", "Euch", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Gott im Menschen \u2013 das giebst Du!", "tokens": ["Gott", "im", "Men\u00b7schen", "\u2013", "das", "giebst", "Du", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$(", "PDS", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}