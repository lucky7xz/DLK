{"dta.poem.13030": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "Siebendes Buch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20535-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "\u201erecht \u201e, sprach Aufrichtigkeit, ich halff getreu dazu;", "tokens": ["\u201e", "recht", "\u201e", ",", "sprach", "Auf\u00b7rich\u00b7tig\u00b7keit", ",", "ich", "halff", "ge\u00b7treu", "da\u00b7zu", ";"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$(", "$,", "VVFIN", "NN", "$,", "PPER", "VVFIN", "ADJD", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eso hat die Wachsamkeit und ich, nicht aber du", "tokens": ["\u201e", "so", "hat", "die", "Wach\u00b7sam\u00b7keit", "und", "ich", ",", "nicht", "a\u00b7ber", "du"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "KON", "PPER", "$,", "PTKNEG", "ADV", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201edu Staats-Kunst dieses Buch, das Staats-Gesez erfunden:", "tokens": ["\u201e", "du", "Staats\u00b7Kunst", "die\u00b7ses", "Buch", ",", "das", "Staats\u00b7Ge\u00b7sez", "er\u00b7fun\u00b7den", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "NN", "PDAT", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eso ist man uns, nicht dir, f\u00fcr dieses Werck verbunden.", "tokens": ["\u201e", "so", "ist", "man", "uns", ",", "nicht", "dir", ",", "f\u00fcr", "die\u00b7ses", "Werck", "ver\u00b7bun\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PIS", "PPER", "$,", "PTKNEG", "PPER", "$,", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "185\u201dDie Feinde lockten zwar, wir aber trauten nicht;", "tokens": ["\"", "Die", "Fein\u00b7de", "lock\u00b7ten", "zwar", ",", "wir", "a\u00b7ber", "trau\u00b7ten", "nicht", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "$,", "PPER", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201edas ist, warum wir es zur Brustwehr aufgericht.", "tokens": ["\u201e", "das", "ist", ",", "wa\u00b7rum", "wir", "es", "zur", "Brust\u00b7wehr", "auf\u00b7ge\u00b7richt", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "$,", "PWAV", "PPER", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201edie Unaufrichtigkeit so gar hat beygetragen,", "tokens": ["\u201e", "die", "Un\u00b7auf\u00b7rich\u00b7tig\u00b7keit", "so", "gar", "hat", "bey\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201edie Feinde mu\u00dften auch verschiedne Pfeiler schlagen.", "tokens": ["\u201e", "die", "Fein\u00b7de", "mu\u00df\u00b7ten", "auch", "ver\u00b7schied\u00b7ne", "Pfei\u00b7ler", "schla\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201eso ward ", "tokens": ["\u201e", "so", "ward"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.10": {"text": "190\u201dBevor du deinen Rath zu diesem Werck erkl\u00e4rt.", "tokens": ["\"", "Be\u00b7vor", "du", "dei\u00b7nen", "Rath", "zu", "die\u00b7sem", "Werck", "er\u00b7kl\u00e4rt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201edich hatten alle die, so deiner Kunst gehorchten,", "tokens": ["\u201e", "dich", "hat\u00b7ten", "al\u00b7le", "die", ",", "so", "dei\u00b7ner", "Kunst", "ge\u00b7horch\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PIS", "ART", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201emi\u00dftrauend, zweifelhaft und Sorgen-voll geforchten,", "tokens": ["\u201e", "mi\u00df\u00b7trau\u00b7end", ",", "zwei\u00b7fel\u00b7haft", "und", "Sor\u00b7gen\u00b7voll", "ge\u00b7forch\u00b7ten", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "$,", "ADJD", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201eals Offenherzigkeit den Willen und die That", "tokens": ["\u201e", "als", "Of\u00b7fen\u00b7her\u00b7zig\u00b7keit", "den", "Wil\u00b7len", "und", "die", "That"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201everschiedner anderer dahin bewogen hat,", "tokens": ["\u201e", "ver\u00b7schied\u00b7ner", "an\u00b7de\u00b7rer", "da\u00b7hin", "be\u00b7wo\u00b7gen", "hat", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "ADJA", "PAV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "195\u201dDa\u00df sie mit Herz und Macht sich unser angenommen,", "tokens": ["\"", "Da\u00df", "sie", "mit", "Herz", "und", "Macht", "sich", "un\u00b7ser", "an\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "APPR", "NN", "KON", "NN", "PRF", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201euns und der K\u00f6niginn zum Schuz seynd angekommen.", "tokens": ["\u201e", "uns", "und", "der", "K\u00f6\u00b7ni\u00b7ginn", "zum", "Schuz", "seynd", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "KON", "ART", "NN", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}