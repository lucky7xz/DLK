{"textgrid.poem.52824": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Welch' eine Freud' in einem Buch zu bl\u00e4ttern,", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Welch' eine Freud' in einem Buch zu bl\u00e4ttern,", "tokens": ["Welch'", "ei\u00b7ne", "Freud'", "in", "ei\u00b7nem", "Buch", "zu", "bl\u00e4t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das einen sch\u00f6nen festen Einband hat,", "tokens": ["Das", "ei\u00b7nen", "sch\u00f6\u00b7nen", "fes\u00b7ten", "Ein\u00b7band", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und einen Inhalt, der mit saubern Lettern", "tokens": ["Und", "ei\u00b7nen", "In\u00b7halt", ",", "der", "mit", "sau\u00b7bern", "Let\u00b7tern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach allen Flanken streut des Guten Saat;", "tokens": ["Nach", "al\u00b7len", "Flan\u00b7ken", "streut", "des", "Gu\u00b7ten", "Saat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wie mu\u00df erst Der vor Lust die H\u00e4nd' sich reiben,", "tokens": ["Wie", "mu\u00df", "erst", "Der", "vor", "Lust", "die", "H\u00e4nd'", "sich", "rei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "ART", "APPR", "NN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der ein so gutes Buch vermag zu schreiben!", "tokens": ["Der", "ein", "so", "gu\u00b7tes", "Buch", "ver\u00b7mag", "zu", "schrei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Da nehmen wir z.B. K\u00f6rner's Werke,", "tokens": ["Da", "neh\u00b7men", "wir", "z.", "B.", "K\u00f6r\u00b7ner's", "Wer\u00b7ke", ","], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "NE", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wo jedes Blatt ist seinen Goldschnitt werth,", "tokens": ["Wo", "je\u00b7des", "Blatt", "ist", "sei\u00b7nen", "Gold\u00b7schnitt", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dies edle Zeugni\u00df von Characterst\u00e4rke,", "tokens": ["Dies", "ed\u00b7le", "Zeug\u00b7ni\u00df", "von", "Cha\u00b7rac\u00b7ter\u00b7st\u00e4r\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von k\u00fchnem Sinn, von Leier und von Schwert;", "tokens": ["Von", "k\u00fch\u00b7nem", "Sinn", ",", "von", "Lei\u00b7er", "und", "von", "Schwert", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "NN", "KON", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Man k\u00f6nnte sich vor Freud' bewogen finden", "tokens": ["Man", "k\u00f6nn\u00b7te", "sich", "vor", "Freud'", "be\u00b7wo\u00b7gen", "fin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PRF", "APPR", "NN", "VVPP", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sch\u00f6ne B\u00fccher gratis einzubinden.", "tokens": ["So", "sch\u00f6\u00b7ne", "B\u00fc\u00b7cher", "gra\u00b7tis", "ein\u00b7zu\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Den Seume sollte auch kein Mensch vergessen,", "tokens": ["Den", "Seu\u00b7me", "soll\u00b7te", "auch", "kein", "Mensch", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der auf die Tugend heut noch etwas h\u00e4lt,", "tokens": ["Der", "auf", "die", "Tu\u00b7gend", "heut", "noch", "et\u00b7was", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der an Neuschottlands Strand betr\u00fcbt gesessen,", "tokens": ["Der", "an", "Neu\u00b7schott\u00b7lands", "Strand", "be\u00b7tr\u00fcbt", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVPP", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ein Biedermann, ein Dichter und ein Held,", "tokens": ["Ein", "Bie\u00b7der\u00b7mann", ",", "ein", "Dich\u00b7ter", "und", "ein", "Held", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und der das gro\u00dfe Werk sich unterfangen", "tokens": ["Und", "der", "das", "gro\u00b7\u00dfe", "Werk", "sich", "un\u00b7ter\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ART", "ADJA", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und ist zu Fu\u00df nach Syrakus gegangen!", "tokens": ["Und", "ist", "zu", "Fu\u00df", "nach", "Sy\u00b7ra\u00b7kus", "ge\u00b7gan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und auch den alten Vo\u00df, der die Luise", "tokens": ["Und", "auch", "den", "al\u00b7ten", "Vo\u00df", ",", "der", "die", "Lu\u00b7i\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NE", "$,", "PRELS", "ART", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Besungen hat und ihres Vaters Rock,", "tokens": ["Be\u00b7sun\u00b7gen", "hat", "und", "ih\u00b7res", "Va\u00b7ters", "Rock", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Schlafrock und den Flausrock und die Lise;", "tokens": ["Den", "Schla\u00b7frock", "und", "den", "Flaus\u00b7rock", "und", "die", "Li\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die gute Kuh, und den Kartoffelstock,", "tokens": ["Die", "gu\u00b7te", "Kuh", ",", "und", "den", "Kar\u00b7tof\u00b7fel\u00b7stock", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich w\u00fcrde gern noch heute Essig schl\u00fcrfen,", "tokens": ["Ich", "w\u00fcr\u00b7de", "gern", "noch", "heu\u00b7te", "Es\u00b7sig", "schl\u00fcr\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "H\u00e4tt' ich ein einzigmal ihn binden d\u00fcrfen.", "tokens": ["H\u00e4tt'", "ich", "ein", "ein\u00b7zig\u00b7mal", "ihn", "bin\u00b7den", "d\u00fcr\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADV", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ja, es ist wahr, was ich erst j\u00fcngst gelesen,", "tokens": ["Ja", ",", "es", "ist", "wahr", ",", "was", "ich", "erst", "j\u00fcngst", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "$,", "PWS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df gute B\u00fccher gute Freunde sind,", "tokens": ["Da\u00df", "gu\u00b7te", "B\u00fc\u00b7cher", "gu\u00b7te", "Freun\u00b7de", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was ist der Mensch doch ein betr\u00fcbtes Wesen,", "tokens": ["Was", "ist", "der", "Mensch", "doch", "ein", "be\u00b7tr\u00fcb\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn er nicht Freund' und gute B\u00fccher find't?", "tokens": ["Wenn", "er", "nicht", "Freund'", "und", "gu\u00b7te", "B\u00fc\u00b7cher", "find't", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Viel lieber schl\u00e4ng' ich Gras und tr\u00fcge H\u00f6rner,", "tokens": ["Viel", "lie\u00b7ber", "schl\u00e4ng'", "ich", "Gras", "und", "tr\u00fc\u00b7ge", "H\u00f6r\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als ohne Seume sein und Vo\u00df und K\u00f6rner.", "tokens": ["Als", "oh\u00b7ne", "Seu\u00b7me", "sein", "und", "Vo\u00df", "und", "K\u00f6r\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "VAINF", "KON", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ja, es ist wahr, und lieber will ich sterben,", "tokens": ["Ja", ",", "es", "ist", "wahr", ",", "und", "lie\u00b7ber", "will", "ich", "ster\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "$,", "KON", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn der Gedanke macht mich beben schon,", "tokens": ["Denn", "der", "Ge\u00b7dan\u00b7ke", "macht", "mich", "be\u00b7ben", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Menschen trifft kein gr\u00f6\u00dferes Verderben,", "tokens": ["Den", "Men\u00b7schen", "trifft", "kein", "gr\u00f6\u00b7\u00dfe\u00b7res", "Ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als einsam sein, wie einstens Robinson,", "tokens": ["Als", "ein\u00b7sam", "sein", ",", "wie", "eins\u00b7tens", "Ro\u00b7bin\u00b7son", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "VAINF", "$,", "PWAV", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und also hab' ich dieses Lied gedichtet,", "tokens": ["Und", "al\u00b7so", "hab'", "ich", "die\u00b7ses", "Lied", "ge\u00b7dich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Noch eh' mein Weib das Fr\u00fchst\u00fcck zugerichtet.", "tokens": ["Noch", "eh'", "mein", "Weib", "das", "Fr\u00fch\u00b7st\u00fcck", "zu\u00b7ge\u00b7rich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}