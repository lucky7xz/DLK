{"dta.poem.5489": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Betrachtung wallender Wasser-Wogen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Auf einem sichern Schif, worauf ich mich befinde,", "tokens": ["Auf", "ei\u00b7nem", "si\u00b7chern", "Schif", ",", "wo\u00b7rauf", "ich", "mich", "be\u00b7fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Betracht\u2019 ich jetzt die, durch die wilden Winde,", "tokens": ["Be\u00b7tracht'", "ich", "jetzt", "die", ",", "durch", "die", "wil\u00b7den", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Starck aufgebrachte Fluth, die sich gewaltig b\u00e4umet,", "tokens": ["Starck", "auf\u00b7ge\u00b7brach\u00b7te", "Fluth", ",", "die", "sich", "ge\u00b7wal\u00b7tig", "b\u00e4u\u00b7met", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "PRELS", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Entsetzlich wallet, braus\u2019t, und sch\u00e4umet.", "tokens": ["Ent\u00b7setz\u00b7lich", "wal\u00b7let", ",", "braus't", ",", "und", "sch\u00e4u\u00b7met", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "VVFIN", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Wellen drohen sich einander zu verschlingen;", "tokens": ["Die", "Wel\u00b7len", "dro\u00b7hen", "sich", "ein\u00b7an\u00b7der", "zu", "ver\u00b7schlin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die suchet jene zu bezwingen;", "tokens": ["Die", "su\u00b7chet", "je\u00b7ne", "zu", "be\u00b7zwin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PDS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dort sieht man Berge schnell sich neigen,", "tokens": ["Dort", "sieht", "man", "Ber\u00b7ge", "schnell", "sich", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "ADJD", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dort tieffe Th\u00e4ler pl\u00f6tzlich steigen.", "tokens": ["Dort", "tief\u00b7fe", "Th\u00e4\u00b7ler", "pl\u00f6tz\u00b7lich", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Es w\u00fcthet, w\u00fchlt und wallt die Fluth. So weit wir sehn", "tokens": ["Es", "w\u00fct\u00b7het", ",", "w\u00fchlt", "und", "wallt", "die", "Fluth", ".", "So", "weit", "wir", "sehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "ART", "NN", "$.", "ADV", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sucht alles sich zu sencken, zu erh\u00f6hn.", "tokens": ["Sucht", "al\u00b7les", "sich", "zu", "sen\u00b7cken", ",", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Hier siehet man von unten dicke Wellen", "tokens": ["Hier", "sie\u00b7het", "man", "von", "un\u00b7ten", "di\u00b7cke", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Sich auf einmahl erheben, b\u00e4umen, schwellen.", "tokens": ["Sich", "auf", "ein\u00b7mahl", "er\u00b7he\u00b7ben", ",", "b\u00e4u\u00b7men", ",", "schwel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "APPR", "ADV", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Wenn nun in ihrer Fahrt ein\u2019 ander\u2019 ihr begegnet,", "tokens": ["Wenn", "nun", "in", "ih\u00b7rer", "Fahrt", "ein'", "an\u00b7der'", "ihr", "be\u00b7geg\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "ART", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Sieht man sie sich so heftig drengen,", "tokens": ["Sieht", "man", "sie", "sich", "so", "hef\u00b7tig", "dren\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PRF", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Da\u00df sie, besch\u00e4umt, als wenn es regnet,", "tokens": ["Da\u00df", "sie", ",", "be\u00b7sch\u00e4umt", ",", "als", "wenn", "es", "reg\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "VVPP", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Rings um sich grosse Tropfen sprengen.", "tokens": ["Rings", "um", "sich", "gros\u00b7se", "Trop\u00b7fen", "spren\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Hier w\u00f6lben sich die regen Wogen,", "tokens": ["Hier", "w\u00f6l\u00b7ben", "sich", "die", "re\u00b7gen", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.18": {"text": "Formiren umgekehrte Bogen;", "tokens": ["For\u00b7mi\u00b7ren", "um\u00b7ge\u00b7kehr\u00b7te", "Bo\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Dann steigen graue Berg\u2019 allm\u00e4hlig in die H\u00f6h,", "tokens": ["Dann", "stei\u00b7gen", "grau\u00b7e", "Ber\u00b7g'", "all\u00b7m\u00e4h\u00b7lig", "in", "die", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Mit weissen Schaum bedeckt, als wie mit Schnee.", "tokens": ["Mit", "weis\u00b7sen", "Schaum", "be\u00b7deckt", ",", "als", "wie", "mit", "Schnee", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "KOUS", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Oft sincken sie, zerborsten, pl\u00f6tzlich nieder,", "tokens": ["Oft", "sin\u00b7cken", "sie", ",", "zer\u00b7bors\u00b7ten", ",", "pl\u00f6tz\u00b7lich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "$,", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Oft heben sie sich schnell und steigen pl\u00f6tzlich wieder.", "tokens": ["Oft", "he\u00b7ben", "sie", "sich", "schnell", "und", "stei\u00b7gen", "pl\u00f6tz\u00b7lich", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "KON", "VVFIN", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Indem ich meine Blicke nun", "tokens": ["In\u00b7dem", "ich", "mei\u00b7ne", "Bli\u00b7cke", "nun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Auf diesem Platz der Unruh liesse ruhn;", "tokens": ["Auf", "die\u00b7sem", "Platz", "der", "Un\u00b7ruh", "lies\u00b7se", "ruhn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Entstunden bey der Wellen Wancken", "tokens": ["Ent\u00b7stun\u00b7den", "bey", "der", "Wel\u00b7len", "Wan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Bey mir die folgenden Gedancken:", "tokens": ["Bey", "mir", "die", "fol\u00b7gen\u00b7den", "Ge\u00b7dan\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Wann aus der tieffen Fluth sich eine Well\u2019 erhebt,", "tokens": ["Wann", "aus", "der", "tief\u00b7fen", "Fluth", "sich", "ei\u00b7ne", "Well'", "er\u00b7hebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich abgesondert, hoch zu steigen,", "tokens": ["Sich", "ab\u00b7ge\u00b7son\u00b7dert", ",", "hoch", "zu", "stei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vor andern schw\u00fclstig sich zu zeigen", "tokens": ["Vor", "an\u00b7dern", "schw\u00fcls\u00b7tig", "sich", "zu", "zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "ADJD", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Oft sanft, oft ungest\u00fcm bestrebt,", "tokens": ["Oft", "sanft", ",", "oft", "un\u00b7ge\u00b7st\u00fcm", "be\u00b7strebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch pl\u00f6tzlich sinckt, vergehet und verschwindet", "tokens": ["Doch", "pl\u00f6tz\u00b7lich", "sinckt", ",", "ver\u00b7ge\u00b7het", "und", "ver\u00b7schwin\u00b7det"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und mit derselben Fluth, aus welcher sie entsprungen,", "tokens": ["Und", "mit", "der\u00b7sel\u00b7ben", "Fluth", ",", "aus", "wel\u00b7cher", "sie", "ent\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "$,", "APPR", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So bald sie von ihr eingeschlungen,", "tokens": ["So", "bald", "sie", "von", "ihr", "ein\u00b7ge\u00b7schlun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich wieder, wie zuvor, vermischt befindet;", "tokens": ["Sich", "wie\u00b7der", ",", "wie", "zu\u00b7vor", ",", "ver\u00b7mischt", "be\u00b7fin\u00b7det", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "ADV", "$,", "PWAV", "ADV", "$,", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "So kommt solch eine Welle mir", "tokens": ["So", "kommt", "solch", "ei\u00b7ne", "Wel\u00b7le", "mir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als wie ein Bild von unserm Leben f\u00fcr.", "tokens": ["Als", "wie", "ein", "Bild", "von", "un\u00b7serm", "Le\u00b7ben", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "APPR", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Indem wir mit den Stoff der Erden,", "tokens": ["In\u00b7dem", "wir", "mit", "den", "Stoff", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Aus welchem wir entstehen und bestehn,", "tokens": ["Aus", "wel\u00b7chem", "wir", "ent\u00b7ste\u00b7hen", "und", "be\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Nachdem man uns hier kurtze Zeit gesehn,", "tokens": ["Nach\u00b7dem", "man", "uns", "hier", "kurt\u00b7ze", "Zeit", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Jm Grabe wiederum vermischet werden.", "tokens": ["Jm", "Gra\u00b7be", "wie\u00b7de\u00b7rum", "ver\u00b7mi\u00b7schet", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Noch dacht ich bey der Fluth und dem erblickten", "tokens": ["Noch", "dacht", "ich", "bey", "der", "Fluth", "und", "dem", "er\u00b7blick\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "KON", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bestehet nicht das feste Land", "tokens": ["Be\u00b7ste\u00b7het", "nicht", "das", "fes\u00b7te", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus lauter kleinen K\u00f6rnchen Sand?", "tokens": ["Aus", "lau\u00b7ter", "klei\u00b7nen", "K\u00f6rn\u00b7chen", "Sand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wie das tieff\u2019 und weite Meer", "tokens": ["So", "wie", "das", "tief\u00b7f'", "und", "wei\u00b7te", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Aus einem grossen Tropfen-Heer?", "tokens": ["Aus", "ei\u00b7nem", "gros\u00b7sen", "Trop\u00b7fen\u00b7Heer", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mir f\u00e4llt bey diesem Dencken bey:", "tokens": ["Mir", "f\u00e4llt", "bey", "die\u00b7sem", "Den\u00b7cken", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ob nicht vor GOtt die gantze Erde", "tokens": ["Ob", "nicht", "vor", "Gott", "die", "gant\u00b7ze", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "APPR", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zum Sand-Korn, und das Meer zu einem Tropfen", "tokens": ["Zum", "San\u00b7dKorn", ",", "und", "das", "Meer", "zu", "ei\u00b7nem", "Trop\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ob beides, gegen GOtt, wol mehr zu rechnen sey?", "tokens": ["Ob", "bei\u00b7des", ",", "ge\u00b7gen", "Gott", ",", "wol", "mehr", "zu", "rech\u00b7nen", "sey", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "APPR", "NN", "$,", "ADV", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}