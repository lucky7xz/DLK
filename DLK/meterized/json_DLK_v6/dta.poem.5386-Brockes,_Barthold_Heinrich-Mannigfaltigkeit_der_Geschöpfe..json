{"dta.poem.5386": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Mannigfaltigkeit der Gesch\u00f6pfe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Indem ich j\u00fcngst, gestreckt im Blumen reichen Grase,", "tokens": ["In\u00b7dem", "ich", "j\u00fcngst", ",", "ge\u00b7streckt", "im", "Blu\u00b7men", "rei\u00b7chen", "Gra\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "VVPP", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey k\u00fchler Abend-Zeit was ich einst schriebe, lase:", "tokens": ["Bey", "k\u00fch\u00b7ler", "A\u00b7ben\u00b7dZeit", "was", "ich", "einst", "schrie\u00b7be", ",", "la\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PWS", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201dbetrachtet dort, betrachtet hier,", "tokens": ["\"", "be\u00b7trach\u00b7tet", "dort", ",", "be\u00b7trach\u00b7tet", "hier", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201din aller Creaturen Zier,", "tokens": ["\"", "in", "al\u00b7ler", "Crea\u00b7tu\u00b7ren", "Zier", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u201ddes Sch\u00f6pfers Weisheit Macht und G\u00fcte;", "tokens": ["\"", "des", "Sch\u00f6p\u00b7fers", "Weis\u00b7heit", "Macht", "und", "G\u00fc\u00b7te", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ward neben mir, als ich bald hin, bald her,", "tokens": ["Ward", "ne\u00b7ben", "mir", ",", "als", "ich", "bald", "hin", ",", "bald", "her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "$,", "KOUS", "PPER", "ADV", "PTKVZ", "$,", "ADV", "PTKVZ", "$,"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.7": {"text": "Die sanften Blicke wandt\u2019, von mir von ungefehr", "tokens": ["Die", "sanf\u00b7ten", "Bli\u00b7cke", "wandt'", ",", "von", "mir", "von", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "APPR", "PPER", "APPR", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein kleiner Frosch erblickt,", "tokens": ["Ein", "klei\u00b7ner", "Frosch", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Der gleichsam zahm, mich gar nicht scheute,", "tokens": ["Der", "gleich\u00b7sam", "zahm", ",", "mich", "gar", "nicht", "scheu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$,", "PPER", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und, wenn ich ihn mit sanften Fingern rieb,", "tokens": ["Und", ",", "wenn", "ich", "ihn", "mit", "sanf\u00b7ten", "Fin\u00b7gern", "rieb", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Best\u00e4ndig stille sitzen blieb,", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "stil\u00b7le", "sit\u00b7zen", "blieb", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wor\u00fcber ich mich denn verwundert\u2019 und erfreute.", "tokens": ["Wo\u00b7r\u00fc\u00b7ber", "ich", "mich", "denn", "ver\u00b7wun\u00b7dert'", "und", "er\u00b7freu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er gab mir Stunden-lang Gelegenheit,", "tokens": ["Er", "gab", "mir", "Stun\u00b7den\u00b7lang", "Ge\u00b7le\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Auf seine Farb\u2019 und seinen Stand zu achten,", "tokens": ["Auf", "sei\u00b7ne", "Fa\u00b7rb'", "und", "sei\u00b7nen", "Stand", "zu", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Und die besondre Seltsamkeit,", "tokens": ["Und", "die", "be\u00b7sond\u00b7re", "Selt\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit welcher er gebildet, zu betrachten.", "tokens": ["Mit", "wel\u00b7cher", "er", "ge\u00b7bil\u00b7det", ",", "zu", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVPP", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Hier\u00fcber schw\u00e4chte sich des sp\u00e4ten Tages Schein,", "tokens": ["Hier\u00b7\u00fc\u00b7ber", "schw\u00e4ch\u00b7te", "sich", "des", "sp\u00e4\u00b7ten", "Ta\u00b7ges", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Es brach die D\u00e4mmerung herein;", "tokens": ["Es", "brach", "die", "D\u00e4m\u00b7me\u00b7rung", "her\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Als eine andre Creatur,", "tokens": ["Als", "ei\u00b7ne", "and\u00b7re", "Crea\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.20": {"text": "Noch sonderlicher von Figur,", "tokens": ["Noch", "son\u00b7der\u00b7li\u00b7cher", "von", "Fi\u00b7gur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "Mein\u2019 Augen auf sich zog:", "tokens": ["Mein'", "Au\u00b7gen", "auf", "sich", "zog", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.22": {"text": "Ein Flederm\u00e4uschen schw\u00e4rmt\u2019 und flog,", "tokens": ["Ein", "Fle\u00b7der\u00b7m\u00e4us\u00b7chen", "schw\u00e4rmt'", "und", "flog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Mit unbefiedertem Gefieder,", "tokens": ["Mit", "un\u00b7be\u00b7fie\u00b7der\u00b7tem", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "In tausend Kreisen hin und wieder,", "tokens": ["In", "tau\u00b7send", "Krei\u00b7sen", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "PTKVZ", "KON", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Auf eine zitternde geschwinde Weise,", "tokens": ["Auf", "ei\u00b7ne", "zit\u00b7tern\u00b7de", "ge\u00b7schwin\u00b7de", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "In grossem bald, und bald in kleinem Kreise,", "tokens": ["In", "gros\u00b7sem", "bald", ",", "und", "bald", "in", "klei\u00b7nem", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADV", "$,", "KON", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Um meinen Sitz herum. Indem mir nun bekannt,", "tokens": ["Um", "mei\u00b7nen", "Sitz", "he\u00b7rum", ".", "In\u00b7dem", "mir", "nun", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKVZ", "$.", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wie dieses Thierchens Form so sonderlich bewandt,", "tokens": ["Wie", "die\u00b7ses", "Thier\u00b7chens", "Form", "so", "son\u00b7der\u00b7lich", "be\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Bewundert\u2019 ich das grosse Wunder-Wesen,", "tokens": ["Be\u00b7wun\u00b7dert'", "ich", "das", "gros\u00b7se", "Wun\u00b7der\u00b7We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Stoff und Geistigkeit so wunderbar erlesen,", "tokens": ["Das", "Stoff", "und", "Geis\u00b7tig\u00b7keit", "so", "wun\u00b7der\u00b7bar", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sie in diesem Thier so wunderbar verband;", "tokens": ["Und", "sie", "in", "die\u00b7sem", "Thier", "so", "wun\u00b7der\u00b7bar", "ver\u00b7band", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PDAT", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df, wenn wir sie mit ernstem Flei\u00df besehn,", "tokens": ["Da\u00df", ",", "wenn", "wir", "sie", "mit", "erns\u00b7tem", "Flei\u00df", "be\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir, mit gegr\u00fcndeten und wol-verbundnen Schl\u00fcssen,", "tokens": ["Wir", ",", "mit", "ge\u00b7gr\u00fcn\u00b7de\u00b7ten", "und", "wol\u00b7ver\u00b7bund\u00b7nen", "Schl\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Unwiedersprechlich die\u00df gestehn", "tokens": ["Un\u00b7wie\u00b7der\u00b7sprech\u00b7lich", "die\u00df", "ge\u00b7stehn"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "PDS", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und folgern m\u00fcssen:", "tokens": ["Und", "fol\u00b7gern", "m\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Die Sch\u00f6pf- und Bildung sey nicht ungefehr geschehn,", "tokens": ["Die", "Sch\u00f6pf", "und", "Bil\u00b7dung", "sey", "nicht", "un\u00b7ge\u00b7fehr", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "VAFIN", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da sie so wunderbar, nach Regeln, Maa\u00df, Gewicht,", "tokens": ["Da", "sie", "so", "wun\u00b7der\u00b7bar", ",", "nach", "Re\u00b7geln", ",", "Maa\u00df", ",", "Ge\u00b7wicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie alles ander\u2019, ein und zugericht.", "tokens": ["Wie", "al\u00b7les", "an\u00b7der'", ",", "ein", "und", "zu\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "$,", "PTKVZ", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Indem ich also sitz\u2019 und dencke,", "tokens": ["In\u00b7dem", "ich", "al\u00b7so", "sitz'", "und", "den\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und meinen Geist auf diesen Vorwurf lencke,", "tokens": ["Und", "mei\u00b7nen", "Geist", "auf", "die\u00b7sen", "Vor\u00b7wurf", "len\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Wie unbegreiflich vielerley", "tokens": ["Wie", "un\u00b7be\u00b7greif\u00b7lich", "vie\u00b7ler\u00b7ley"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADJD", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Der Creaturen Bildung sey?", "tokens": ["Der", "Crea\u00b7tu\u00b7ren", "Bil\u00b7dung", "sey", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Durchdringt mein Aug\u2019 ein schnell und helles Licht.", "tokens": ["Durch\u00b7dringt", "mein", "Aug'", "ein", "schnell", "und", "hel\u00b7les", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Der aufgegangne Mond fiel mit geschwindem Blitzen,", "tokens": ["Der", "auf\u00b7ge\u00b7gang\u00b7ne", "Mond", "fiel", "mit", "ge\u00b7schwin\u00b7dem", "Blit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Durchs schattigte Geb\u00fcsch und seiner Bl\u00e4tter Ritzen", "tokens": ["Durchs", "schat\u00b7tig\u00b7te", "Ge\u00b7b\u00fcsch", "und", "sei\u00b7ner", "Bl\u00e4t\u00b7ter", "Rit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Mir unvermuthet ins Gesicht.", "tokens": ["Mir", "un\u00b7ver\u00b7mu\u00b7thet", "ins", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Ich stand denn auf, besahe seinen Glantz,", "tokens": ["Ich", "stand", "denn", "auf", ",", "be\u00b7sa\u00b7he", "sei\u00b7nen", "Glantz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Indem er eben gantz,", "tokens": ["In\u00b7dem", "er", "e\u00b7ben", "gantz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Mit ungemeiner Lust. Hier\u00fcber fiel mir ein:", "tokens": ["Mit", "un\u00b7ge\u00b7mei\u00b7ner", "Lust", ".", "Hier\u00b7\u00fc\u00b7ber", "fiel", "mir", "ein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "PAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wie mu\u00df es dorten doch beschaffen seyn!", "tokens": ["Wie", "mu\u00df", "es", "dor\u00b7ten", "doch", "be\u00b7schaf\u00b7fen", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Was mu\u00df des Monden Welt f\u00fcr mancherley Gestalten,", "tokens": ["Was", "mu\u00df", "des", "Mon\u00b7den", "Welt", "f\u00fcr", "man\u00b7cher\u00b7ley", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "In seinem grossen Kreis\u2019 enthalten,", "tokens": ["In", "sei\u00b7nem", "gros\u00b7sen", "Kreis'", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Die abermahl von allem, was hienieden,", "tokens": ["Die", "a\u00b7ber\u00b7mahl", "von", "al\u00b7lem", ",", "was", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PIS", "$,", "PRELS", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Vermuthlich unterschieden!", "tokens": ["Ver\u00b7muth\u00b7lich", "un\u00b7ter\u00b7schie\u00b7den", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "Wer fasset die Verschiedenheit", "tokens": ["Wer", "fas\u00b7set", "die", "Ver\u00b7schie\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Der gantz von hiesigen Figuren", "tokens": ["Der", "gantz", "von", "hie\u00b7si\u00b7gen", "Fi\u00b7gu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "An Form und Farb\u2019 entfernten Creaturen!", "tokens": ["An", "Form", "und", "Fa\u00b7rb'", "ent\u00b7fern\u00b7ten", "Crea\u00b7tu\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Ist uns nun gleich der Creaturen Stand", "tokens": ["Ist", "uns", "nun", "gleich", "der", "Crea\u00b7tu\u00b7ren", "Stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.31": {"text": "In andern Welten nicht bekannt;", "tokens": ["In", "an\u00b7dern", "Wel\u00b7ten", "nicht", "be\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So stellet meine Seele mir", "tokens": ["So", "stel\u00b7let", "mei\u00b7ne", "See\u00b7le", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dennoch, zu unsers Sch\u00f6pfers Ehre,", "tokens": ["Den\u00b7noch", ",", "zu", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Eh\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Unersch\u00f6pflichkeit der Aenderungen f\u00fcr,", "tokens": ["Die", "Un\u00b7er\u00b7sch\u00f6pf\u00b7lich\u00b7keit", "der", "A\u00b7en\u00b7de\u00b7run\u00b7gen", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und hoff\u2019 ich, da\u00df, durch diese Lehre,", "tokens": ["Und", "hoff'", "ich", ",", "da\u00df", ",", "durch", "die\u00b7se", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bey andern, wie bey mir, sein Ruhm sich stets verehre.", "tokens": ["Bey", "an\u00b7dern", ",", "wie", "bey", "mir", ",", "sein", "Ruhm", "sich", "stets", "ver\u00b7eh\u00b7re", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "PWAV", "APPR", "PPER", "$,", "PPOSAT", "NN", "PRF", "ADV", "VVFIN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Nun deucht mich, lieber Mensch, da\u00df ich dich sprechen", "tokens": ["Nun", "deucht", "mich", ",", "lie\u00b7ber", "Mensch", ",", "da\u00df", "ich", "dich", "spre\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "NN", "$,", "KOUS", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201eich wei\u00df nicht wie ich GOtt auf solche Weise ehre,", "tokens": ["\u201e", "ich", "wei\u00df", "nicht", "wie", "ich", "Gott", "auf", "sol\u00b7che", "Wei\u00b7se", "eh\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "PWAV", "PPER", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eman hat mich\u2019s nicht gelehrt; wie mu\u00df ich\u2019s machen?", "tokens": ["\u201e", "man", "hat", "mich's", "nicht", "ge\u00b7lehrt", ";", "wie", "mu\u00df", "ich's", "ma\u00b7chen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VAFIN", "PIS", "PTKNEG", "VVPP", "$.", "PWAV", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir m\u00fcssen unsern Geist bey den erblickten Sachen", "tokens": ["Wir", "m\u00fcs\u00b7sen", "un\u00b7sern", "Geist", "bey", "den", "er\u00b7blick\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In einen solchen Stand bem\u00fchet seyn zu setzen,", "tokens": ["In", "ei\u00b7nen", "sol\u00b7chen", "Stand", "be\u00b7m\u00fc\u00b7het", "seyn", "zu", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN", "VAINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df wir den Sch\u00f6pfer hoch, in dem Gesch\u00f6pfe, sch\u00e4tzen;", "tokens": ["Da\u00df", "wir", "den", "Sch\u00f6p\u00b7fer", "hoch", ",", "in", "dem", "Ge\u00b7sch\u00f6p\u00b7fe", ",", "sch\u00e4t\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir m\u00fcssen de\u00dffals erstlich finden,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "de\u00df\u00b7fals", "erst\u00b7lich", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie sehr es n\u00f6thig sey, das Dencken", "tokens": ["Wie", "sehr", "es", "n\u00f6\u00b7thig", "sey", ",", "das", "Den\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "PPER", "ADJD", "VAFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mit unsern Sinnen zu verbinden.", "tokens": ["Mit", "un\u00b7sern", "Sin\u00b7nen", "zu", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wir m\u00f6gen unsern Sinn, worauf wir wollen, lencken;", "tokens": ["Wir", "m\u00f6\u00b7gen", "un\u00b7sern", "Sinn", ",", "wo\u00b7rauf", "wir", "wol\u00b7len", ",", "len\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VMFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Es m\u00f6gen Feld und Wald, Sand, Blumen, Holtz und", "tokens": ["Es", "m\u00f6\u00b7gen", "Feld", "und", "Wald", ",", "Sand", ",", "Blu\u00b7men", ",", "Holtz", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Geb\u00e4ude, Thiere, Gra\u00df, Metall, ein schnell Gefl\u00fcgel,", "tokens": ["Ge\u00b7b\u00e4u\u00b7de", ",", "Thie\u00b7re", ",", "Gra\u00df", ",", "Me\u00b7tall", ",", "ein", "schnell", "Ge\u00b7fl\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein Regen-Wurm, ein Fisch, das Meer, ein Thal, ein", "tokens": ["Ein", "Re\u00b7gen\u00b7Wurm", ",", "ein", "Fisch", ",", "das", "Meer", ",", "ein", "Thal", ",", "ein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Ein Bach, das Firmament, ein Mensch, gesehen seyn;", "tokens": ["Ein", "Bach", ",", "das", "Fir\u00b7ma\u00b7ment", ",", "ein", "Mensch", ",", "ge\u00b7se\u00b7hen", "seyn", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So stimmet alles doch hierin stets \u00fcberein:", "tokens": ["So", "stim\u00b7met", "al\u00b7les", "doch", "hie\u00b7rin", "stets", "\u00fc\u00b7be\u00b7re\u00b7in", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.16": {"text": "Es ist ein G\u00f6ttlich Werck, es ist von ihm entstanden,", "tokens": ["Es", "ist", "ein", "G\u00f6tt\u00b7lich", "Werck", ",", "es", "ist", "von", "ihm", "ent\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ein jedes lehret uns, es sey ein GOtt vorhanden!", "tokens": ["Ein", "je\u00b7des", "leh\u00b7ret", "uns", ",", "es", "sey", "ein", "Gott", "vor\u00b7han\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Gott zeiget seine Macht durch alles, was man sieht,", "tokens": ["Gott", "zei\u00b7get", "sei\u00b7ne", "Macht", "durch", "al\u00b7les", ",", "was", "man", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "APPR", "PIS", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wem aber zeigt er sich, wenn wir nicht das Gem\u00fcth", "tokens": ["Wem", "a\u00b7ber", "zeigt", "er", "sich", ",", "wenn", "wir", "nicht", "das", "Ge\u00b7m\u00fcth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "PRF", "$,", "KOUS", "PPER", "PTKNEG", "ART", "NN"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Mit unsrer Sinnen Kraft verbinden,", "tokens": ["Mit", "uns\u00b7rer", "Sin\u00b7nen", "Kraft", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Und, da\u00df der Sch\u00f6pfer wehrt, da\u00df man ihn ehre, finden.", "tokens": ["Und", ",", "da\u00df", "der", "Sch\u00f6p\u00b7fer", "wehrt", ",", "da\u00df", "man", "ihn", "eh\u00b7re", ",", "fin\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "\u201dmir kommt, seh ich der Creaturen Zier", "tokens": ["\"", "mir", "kommt", ",", "seh", "ich", "der", "Crea\u00b7tu\u00b7ren", "Zier"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201dbedachtsam an, nicht anders f\u00fcr,", "tokens": ["\"", "be\u00b7dacht\u00b7sam", "an", ",", "nicht", "an\u00b7ders", "f\u00fcr", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "PTKVZ", "$,", "PTKNEG", "ADV", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201dals sprech' ein jeder Ding zu mir:", "tokens": ["\"", "als", "sprech'", "ein", "je\u00b7der", "Ding", "zu", "mir", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "VVFIN", "ART", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201des ist ein GOtt, ich zeig ihn dir!", "tokens": ["\"", "es", "ist", "ein", "Gott", ",", "ich", "zeig", "ihn", "dir", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "La\u00dft uns denn, wo wir gehn und stehen,", "tokens": ["La\u00dft", "uns", "denn", ",", "wo", "wir", "gehn", "und", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "PWAV", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch alles, was wir sehn, bem\u00fcht seyn anzusehen", "tokens": ["Doch", "al\u00b7les", ",", "was", "wir", "sehn", ",", "be\u00b7m\u00fcht", "seyn", "an\u00b7zu\u00b7se\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "$,", "PRELS", "PPER", "VVINF", "$,", "VVPP", "VAINF", "VVIZU"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als etwas, so von GOtt hervorgebracht,", "tokens": ["Als", "et\u00b7was", ",", "so", "von", "Gott", "her\u00b7vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Als etwas, welches GOtt erh\u00e4lt, das seine Macht", "tokens": ["Als", "et\u00b7was", ",", "wel\u00b7ches", "Gott", "er\u00b7h\u00e4lt", ",", "das", "sei\u00b7ne", "Macht"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "$,", "PWAT", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und seine Lieb\u2019 und seine Weisheit weiset,", "tokens": ["Und", "sei\u00b7ne", "Lieb'", "und", "sei\u00b7ne", "Weis\u00b7heit", "wei\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ja seine Gegenwart; das folglich alles wehrt,", "tokens": ["Ja", "sei\u00b7ne", "Ge\u00b7gen\u00b7wart", ";", "das", "folg\u00b7lich", "al\u00b7les", "wehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPOSAT", "NN", "$.", "PDS", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df man darum, darin darbey, den Sch\u00f6pfer preiset.", "tokens": ["Da\u00df", "man", "da\u00b7rum", ",", "da\u00b7rin", "dar\u00b7bey", ",", "den", "Sch\u00f6p\u00b7fer", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "$,", "PAV", "PAV", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nun wird er, wie er will geehret seyn, geehret,", "tokens": ["Nun", "wird", "er", ",", "wie", "er", "will", "ge\u00b7eh\u00b7ret", "seyn", ",", "ge\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "VVPP", "VAINF", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn man, dadurch ger\u00fchrt, den Geist zum Geber lencket,", "tokens": ["Wenn", "man", ",", "da\u00b7durch", "ge\u00b7r\u00fchrt", ",", "den", "Geist", "zum", "Ge\u00b7ber", "len\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PAV", "VVPP", "$,", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In froher Achtsamkeit an ihn gedencket,", "tokens": ["In", "fro\u00b7her", "Acht\u00b7sam\u00b7keit", "an", "ihn", "ge\u00b7den\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und ein\u2019 in uns dadurch erregte Lust ihm schencket.", "tokens": ["Und", "ein'", "in", "uns", "da\u00b7durch", "er\u00b7reg\u00b7te", "Lust", "ihm", "schen\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PRF", "PAV", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}