{"textgrid.poem.53218": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Meine F\u00fcrsten und F\u00fcrstinnen", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Meine F\u00fcrsten und F\u00fcrstinnen", "tokens": ["Mei\u00b7ne", "F\u00fcrs\u00b7ten", "und", "F\u00fcrs\u00b7tin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fahren ins Galinder Land,", "tokens": ["Fah\u00b7ren", "ins", "Ga\u00b7lin\u00b7der", "Land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Und man hat schon vorgespannt:", "tokens": ["Und", "man", "hat", "schon", "vor\u00b7ge\u00b7spannt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lasst uns bald ein Lied beginnen!", "tokens": ["Lasst", "uns", "bald", "ein", "Lied", "be\u00b7gin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Preussen und du K\u00f6nigsberg,", "tokens": ["Preus\u00b7sen", "und", "du", "K\u00f6\u00b7nigs\u00b7berg", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sing' in meiner Seiten Werck.", "tokens": ["Sing'", "in", "mei\u00b7ner", "Sei\u00b7ten", "Werck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ortelsburg hat hoch zu prangen,", "tokens": ["Or\u00b7tels\u00b7burg", "hat", "hoch", "zu", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tr\u00e4gt sein Lob den Sternen ein,", "tokens": ["Tr\u00e4gt", "sein", "Lob", "den", "Ster\u00b7nen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df es dieser Lichter Schein,", "tokens": ["Da\u00df", "es", "die\u00b7ser", "Lich\u00b7ter", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsre H\u00e4upter, sol umbfangen,", "tokens": ["Uns\u00b7re", "H\u00e4up\u00b7ter", ",", "sol", "umb\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Rom, dein Capitolium", "tokens": ["Rom", ",", "dein", "Ca\u00b7pi\u00b7to\u00b7li\u00b7um"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Giebt Ihm selbst des Vorzugs Ruhm,", "tokens": ["Giebt", "Ihm", "selbst", "des", "Vor\u00b7zugs", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wenn vorau\u00df die Krafft der Helden,", "tokens": ["Wenn", "vor\u00b7au\u00df", "die", "Krafft", "der", "Hel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Unser grosse Vladisla", "tokens": ["Un\u00b7ser", "gros\u00b7se", "Vla\u00b7dis\u00b7la"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nebenst Dir, Cecilia,", "tokens": ["Ne\u00b7benst", "Dir", ",", "Ce\u00b7ci\u00b7lia", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Welcher Prei\u00df kein Sinn kan melden,", "tokens": ["Wel\u00b7cher", "Prei\u00df", "kein", "Sinn", "kan", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und der Edlen Pohlen Pracht", "tokens": ["Und", "der", "Ed\u00b7len", "Poh\u00b7len", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich wird haben hingemacht.", "tokens": ["Sich", "wird", "ha\u00b7ben", "hin\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VAFIN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wol den angenehmen Tagen,", "tokens": ["Wol", "den", "an\u00b7ge\u00b7neh\u00b7men", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wann der Kronen Hertz und Licht", "tokens": ["Wann", "der", "Kro\u00b7nen", "Hertz", "und", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich mit Brandenburg bespricht!", "tokens": ["Sich", "mit", "Bran\u00b7den\u00b7burg", "be\u00b7spricht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach-Welt wiss hievon zu sagen,", "tokens": ["Nach\u00b7Welt", "wiss", "hie\u00b7von", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil es Fama schallen l\u00e4sst", "tokens": ["Weil", "es", "Fa\u00b7ma", "schal\u00b7len", "l\u00e4sst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "VVINF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bi\u00df durch Nord, S\u00fcd, Ost und West.", "tokens": ["Bi\u00df", "durch", "Nord", ",", "S\u00fcd", ",", "Ost", "und", "West", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NE", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Freundligkeit, Schertz, Lust und Lachen", "tokens": ["Freund\u00b7lig\u00b7keit", ",", "Schertz", ",", "Lust", "und", "La\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Frewden gantze Schaar", "tokens": ["Und", "der", "Frew\u00b7den", "gant\u00b7ze", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden st\u00fcndlich hier und dar", "tokens": ["Wer\u00b7den", "st\u00fcnd\u00b7lich", "hier", "und", "dar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "ADV", "KON", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen newen Auffzug machen,", "tokens": ["Ei\u00b7nen", "ne\u00b7wen", "Auff\u00b7zug", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jagt, Turniren, Tantz und Wein", "tokens": ["Jagt", ",", "Tur\u00b7ni\u00b7ren", ",", "Tantz", "und", "Wein"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Werden stets da Wirthe seyn.", "tokens": ["Wer\u00b7den", "stets", "da", "Wirt\u00b7he", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KOUS", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Auff! Ihr Reuter und Trabanten,", "tokens": ["Auff", "!", "Ihr", "Reu\u00b7ter", "und", "Tra\u00b7ban\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Hoff wil numehr fort,", "tokens": ["Un\u00b7ser", "Hoff", "wil", "nu\u00b7mehr", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber schawt! was seh ich dort?", "tokens": ["A\u00b7ber", "schawt", "!", "was", "seh", "ich", "dort", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00f6lckt es doch von allen Kanten,", "tokens": ["W\u00f6lckt", "es", "doch", "von", "al\u00b7len", "Kan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Haltet nur ein wenig still,", "tokens": ["Hal\u00b7tet", "nur", "ein", "we\u00b7nig", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ob es sich verziehen wil!", "tokens": ["Ob", "es", "sich", "ver\u00b7zie\u00b7hen", "wil", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ach, ich irr, es ist kein Wetter,", "tokens": ["Ach", ",", "ich", "irr", ",", "es", "ist", "kein", "Wet\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "ADJD", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein gew\u00fcnschter Ost k\u00f6mpt an", "tokens": ["Ein", "ge\u00b7w\u00fcnschter", "Ost", "k\u00f6mpt", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und bringt durch der L\u00fcffte Bahn", "tokens": ["Und", "bringt", "durch", "der", "L\u00fcff\u00b7te", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Eine Wolcke Rosenbl\u00e4tter,", "tokens": ["Ei\u00b7ne", "Wol\u00b7cke", "Ro\u00b7sen\u00b7bl\u00e4t\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die, O thewre F\u00fcrsten, wol", "tokens": ["Die", ",", "O", "thew\u00b7re", "F\u00fcrs\u00b7ten", ",", "wol"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "$,", "NE", "ADJA", "NN", "$,", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ewren Weg bestrewen sol.", "tokens": ["Ew\u00b7ren", "Weg", "be\u00b7stre\u00b7wen", "sol", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nun wolan! so viel ich mercke,", "tokens": ["Nun", "wo\u00b7lan", "!", "so", "viel", "ich", "mer\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wartet Euch der Himmel auff,", "tokens": ["War\u00b7tet", "Euch", "der", "Him\u00b7mel", "auff", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fahrt! der Sonnen Licht und Lauff", "tokens": ["Fahrt", "!", "der", "Son\u00b7nen", "Licht", "und", "Lauff"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "ART", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist mit allem Thun zu wercke,", "tokens": ["Ist", "mit", "al\u00b7lem", "Thun", "zu", "wer\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIS", "NN", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die in Euch sich umb und an,", "tokens": ["Die", "in", "Euch", "sich", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PRF", "APPR", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Glantz der Welt, bespiegeln kan.", "tokens": ["Glantz", "der", "Welt", ",", "be\u00b7spie\u00b7geln", "kan", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}