{"dta.poem.19109": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "XcI.   Auf des Mannes GOttes, Paul An-  \n tonii zu Halle, Auflosung.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Vater! Paulus Antonius, Theol. D. P. P. O. und Inspector des\nSaal-Creyses, war ein gebohrner Ober-Lausitzer von Hirsch-\nfelde bey Zittau, ein gantz ungemeiner Geist, der in der\nKraft besessen, was so viele mystische Lehrer beschrieben\nhaben. Seine von GOtt beschiedene Gabe war, nach-\ndr\u00fccklich und kurtz zu reden. Er war ein sehr unpartheyi-\nscher Mann. Er lobte das Gute an denen, so er sonst\nnicht loben konte. ey wohin,", "tokens": ["Va\u00b7ter", "!", "Pau\u00b7lus", "An\u00b7to\u00b7ni\u00b7us", ",", "The\u00b7ol", ".", "D.", "P.", "P.", "O.", "und", "In\u00b7spec\u00b7tor", "des", "Saa\u00b7lCrey\u00b7ses", ",", "war", "ein", "ge\u00b7bohr\u00b7ner", "O\u00b7ber\u00b7Lau\u00b7sit\u00b7zer", "von", "Hirsch", "fel\u00b7de", "bey", "Zit\u00b7tau", ",", "ein", "gantz", "un\u00b7ge\u00b7mei\u00b7ner", "Geist", ",", "der", "in", "der", "Kraft", "be\u00b7ses\u00b7sen", ",", "was", "so", "vie\u00b7le", "mys\u00b7ti\u00b7sche", "Leh\u00b7rer", "be\u00b7schrie\u00b7ben", "ha\u00b7ben", ".", "Sei\u00b7ne", "von", "Gott", "be\u00b7schie\u00b7de\u00b7ne", "Ga\u00b7be", "war", ",", "nach", "dr\u00fcck\u00b7lich", "und", "kurtz", "zu", "re\u00b7den", ".", "Er", "war", "ein", "sehr", "un\u00b7par\u00b7theyi", "scher", "Mann", ".", "Er", "lob\u00b7te", "das", "Gu\u00b7te", "an", "de\u00b7nen", ",", "so", "er", "sonst", "nicht", "lo\u00b7ben", "kon\u00b7te", ".", "ey", "wo\u00b7hin", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "abbreviation", "abbreviation", "abbreviation", "abbreviation", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "NE", "NE", "$,", "NE", "$.", "NE", "NE", "NE", "NE", "KON", "NN", "ART", "NN", "$,", "VAFIN", "ART", "ADJA", "NN", "APPR", "TRUNC", "NN", "APPR", "NE", "$,", "ART", "ADV", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVPP", "$,", "PRELS", "ADV", "PIAT", "ADJA", "NN", "VVPP", "VAINF", "$.", "PPOSAT", "APPR", "NN", "ADJA", "NN", "VAFIN", "$,", "TRUNC", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ART", "ADV", "TRUNC", "ADJA", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "APPR", "PRELS", "$,", "ADV", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$.", "XY", "PWAV", "$,"], "meter": "+-+-+--+-+-+-+-+---+-+-+-++--+-+-+-+-+-+-+-+-+-+-+-+-+--+--+-+-+--+-+--+---+--+-+-+---+-+-+-+--+----+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Mit so sanftem Sinn?", "tokens": ["Mit", "so", "sanf\u00b7tem", "Sinn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Zum Genu\u00df der sieben Bitten,", "tokens": ["Zum", "Ge\u00b7nu\u00df", "der", "sie\u00b7ben", "Bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und des Theils des Stamms,", "tokens": ["Und", "des", "Theils", "des", "Stamms", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Und des gantzen Lamms.", "tokens": ["Und", "des", "gant\u00b7zen", "Lamms", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Heute geht mit mir", "tokens": ["Heu\u00b7te", "geht", "mit", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Etwas Grosses f\u00fcr:", "tokens": ["Et\u00b7was", "Gros\u00b7ses", "f\u00fcr", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Denn ein Theil von meiner Seele", "tokens": ["Denn", "ein", "Theil", "von", "mei\u00b7ner", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zeucht dahin aus dieser H\u00f6hle;", "tokens": ["Zeucht", "da\u00b7hin", "aus", "die\u00b7ser", "H\u00f6h\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber wo dann hin?", "tokens": ["A\u00b7ber", "wo", "dann", "hin", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Wo ich auch schon bin.", "tokens": ["Wo", "ich", "auch", "schon", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Wer beschreibt den Flei\u00df,", "tokens": ["Wer", "be\u00b7schreibt", "den", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Unbefleckter Grei\u00df!", "tokens": ["Un\u00b7be\u00b7fleck\u00b7ter", "Grei\u00df", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Deinen Flei\u00df vor Christi Schule,", "tokens": ["Dei\u00b7nen", "Flei\u00df", "vor", "Chris\u00b7ti", "Schu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wider die vons Satans Stuhle?", "tokens": ["Wi\u00b7der", "die", "vons", "Sa\u00b7tans", "Stuh\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer dich recht geh\u00f6rt,", "tokens": ["Wer", "dich", "recht", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Wurde tief gelehrt.", "tokens": ["Wur\u00b7de", "tief", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "H\u00e4tt\u2019st du nichts gethan,", "tokens": ["H\u00e4tt'st", "du", "nichts", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Als der Glaubens Bahn,", "tokens": ["Als", "der", "Glau\u00b7bens", "Bahn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Unsers ", "tokens": ["Un\u00b7sers"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "So nat\u00fcrlich abzudancken,", "tokens": ["So", "na\u00b7t\u00fcr\u00b7lich", "ab\u00b7zu\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und so eigentlich;", "tokens": ["Und", "so", "ei\u00b7gent\u00b7lich", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "So besang ich dich.", "tokens": ["So", "be\u00b7sang", "ich", "dich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Fahre hin, o Licht!", "tokens": ["Fah\u00b7re", "hin", ",", "o", "Licht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "FM", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Dessen gleichen nicht!", "tokens": ["Des\u00b7sen", "glei\u00b7chen", "nicht", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "PTKNEG", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Licht, das nie umsonst geschienen,", "tokens": ["Licht", ",", "das", "nie", "um\u00b7sonst", "ge\u00b7schie\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fahre hin, dem Stuhl zu dienen,", "tokens": ["Fah\u00b7re", "hin", ",", "dem", "Stuhl", "zu", "die\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo der Fackeln Pracht", "tokens": ["Wo", "der", "Fa\u00b7ckeln", "Pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "In die Sonne lacht.", "tokens": ["In", "die", "Son\u00b7ne", "lacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Mosis Angesicht,\n(Und er wust es nicht,)", "tokens": ["Mo\u00b7sis", "An\u00b7ge\u00b7sicht", ",", "(", "Und", "er", "wust", "es", "nicht", ",", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NN", "$,", "$(", "KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Gl\u00e4ntzete bi\u00df zum Verblenden.", "tokens": ["Gl\u00e4nt\u00b7ze\u00b7te", "bi\u00df", "zum", "Ver\u00b7blen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPRART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Seiner Thaten, an:", "tokens": ["Sei\u00b7ner", "Tha\u00b7ten", ",", "an", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Paul Antonius,", "tokens": ["Paul", "An\u00b7to\u00b7ni\u00b7us", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Dieser Uberflu\u00df", "tokens": ["Die\u00b7ser", "U\u00b7ber\u00b7flu\u00df"], "token_info": ["word", "word"], "pos": ["PDAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Der verhei\u00dfnen Lebens-Wasser,", "tokens": ["Der", "ver\u00b7hei\u00df\u00b7nen", "Le\u00b7bens\u00b7Was\u00b7ser", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach dem Zeugni\u00df unsrer Hasser:", "tokens": ["Nach", "dem", "Zeug\u00b7ni\u00df", "uns\u00b7rer", "Has\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Setzts in guten Stand.", "tokens": ["Setzts", "in", "gu\u00b7ten", "Stand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Kriegt er Widerspruch,", "tokens": ["Kriegt", "er", "Wi\u00b7der\u00b7spruch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df ja der Geruch", "tokens": ["Da\u00df", "ja", "der", "Ge\u00b7ruch"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Von in GOtt geschehnen Wercken,", "tokens": ["Von", "in", "Gott", "ge\u00b7scheh\u00b7nen", "Wer\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Allenthalben zu vermercken;", "tokens": ["Al\u00b7len\u00b7thal\u00b7ben", "zu", "ver\u00b7mer\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gab er bald zur\u00fcck:", "tokens": ["Gab", "er", "bald", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Da\u00df er Netze flick.", "tokens": ["Da\u00df", "er", "Net\u00b7ze", "flick", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Du beschreibest dich", "tokens": ["Du", "be\u00b7schrei\u00b7best", "dich"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Unverbesserlich,", "tokens": ["Un\u00b7ver\u00b7bes\u00b7ser\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Tausend B\u00f6ses zu verriegeln,", "tokens": ["Tau\u00b7send", "B\u00f6\u00b7ses", "zu", "ver\u00b7rie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tausend Gutes zu versiegeln,", "tokens": ["Tau\u00b7send", "Gu\u00b7tes", "zu", "ver\u00b7sie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das war deine St\u00e4rck,", "tokens": ["Das", "war", "dei\u00b7ne", "St\u00e4rck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Und dein Tage-Werck.", "tokens": ["Und", "dein", "Ta\u00b7ge\u00b7\u00b7Werck", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Ausgestreckte Hand!", "tokens": ["Aus\u00b7ge\u00b7streck\u00b7te", "Hand", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Die das Liebes-Band", "tokens": ["Die", "das", "Lie\u00b7bes\u00b7Band"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Mein und meiner Mitgenossen,", "tokens": ["Mein", "und", "mei\u00b7ner", "Mit\u00b7ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die im HErrn zusammen flossen,", "tokens": ["Die", "im", "Herrn", "zu\u00b7sam\u00b7men", "flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vor die Liebe trug,", "tokens": ["Vor", "die", "Lie\u00b7be", "trug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Und zusammen schlug.", "tokens": ["Und", "zu\u00b7sam\u00b7men", "schlug", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Ich bewundre dich,", "tokens": ["Ich", "be\u00b7wund\u00b7re", "dich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Wie so meisterlich", "tokens": ["Wie", "so", "meis\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADV", "ADJD"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Du die Tiefen kontest deuten,", "tokens": ["Du", "die", "Tie\u00b7fen", "kon\u00b7test", "deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zum rechten Sinne leiten;", "tokens": ["Und", "zum", "rech\u00b7ten", "Sin\u00b7ne", "lei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und dein Finger-Zeig", "tokens": ["Und", "dein", "Fin\u00b7ger\u00b7Zeig"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Uberzeugte gleich.", "tokens": ["Ub\u00b7er\u00b7zeug\u00b7te", "gleich", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Als ich dir zuletzt", "tokens": ["Als", "ich", "dir", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Sehnlich zugesetzt,", "tokens": ["Sehn\u00b7lich", "zu\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wie doch unsre Creutz-Gemeine", "tokens": ["Wie", "doch", "uns\u00b7re", "Creutz\u00b7Ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Andern so bedencklich scheine,", "tokens": ["An\u00b7dern", "so", "be\u00b7denck\u00b7lich", "schei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die nur JEsum nennt.)", "tokens": ["Die", "nur", "Je\u00b7sum", "nennt", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "NE", "VVFIN", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Suchen sie die Spur,", "tokens": ["Su\u00b7chen", "sie", "die", "Spur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Gideons und seines Knaben,", "tokens": ["Gi\u00b7de\u00b7ons", "und", "sei\u00b7nes", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Midian im Schlaf begraben;", "tokens": ["Mi\u00b7di\u00b7an", "im", "Schlaf", "be\u00b7gra\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00e4umt vom Gersten-Brod,", "tokens": ["Tr\u00e4umt", "vom", "Gers\u00b7ten\u00b7Brod", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Das den Zelten droht.", "tokens": ["Das", "den", "Zel\u00b7ten", "droht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Als erinnert ward,", "tokens": ["Als", "e\u00b7rin\u00b7nert", "ward", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "VVPP", "VAFIN", "$,"], "meter": "-++-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "In der Gegenwart", "tokens": ["In", "der", "Ge\u00b7gen\u00b7wart"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Eines gar getreuen Zeugen,", "tokens": ["Ei\u00b7nes", "gar", "ge\u00b7treu\u00b7en", "Zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll man reden oder schweigen?", "tokens": ["Soll", "man", "re\u00b7den", "o\u00b7der", "schwei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sprachst du, ", "tokens": ["Sprachst", "du", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Man ", "tokens": ["Man"], "token_info": ["word"], "pos": ["PIS"], "meter": "+", "measure": "single.up"}}, "stanza.15": {"line.1": {"text": "Sage deinen Sinn:", "tokens": ["Sa\u00b7ge", "dei\u00b7nen", "Sinn", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ist es auch Gewinn,", "tokens": ["Ist", "es", "auch", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Was in deinem Vaterlande ", "tokens": ["Was", "in", "dei\u00b7nem", "Va\u00b7ter\u00b7lan\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Christus wirckt durch Ehr und Schande?", "tokens": ["Chris\u00b7tus", "wirckt", "durch", "Ehr", "und", "Schan\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich bin, sprachst du, Knecht,", "tokens": ["Ich", "bin", ",", "sprachst", "du", ",", "Knecht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "VVFIN", "PPER", "$,", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.16": {"line.1": {"text": "O so siegle zu", "tokens": ["O", "so", "sieg\u00b7le", "zu"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "In der stillen Ruh,", "tokens": ["In", "der", "stil\u00b7len", "Ruh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Das Gesch\u00e4fte unsrer Glieder,", "tokens": ["Das", "Ge\u00b7sch\u00e4f\u00b7te", "uns\u00b7rer", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und erkenne sie vor Br\u00fcder;", "tokens": ["Und", "er\u00b7ken\u00b7ne", "sie", "vor", "Br\u00fc\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Pl\u00f6tzlich hielt\u2019st du Stand:", "tokens": ["Pl\u00f6tz\u00b7lich", "hielt'st", "du", "Stand", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Wer sich matt geredt,", "tokens": ["Wer", "sich", "matt", "ge\u00b7redt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADJD", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Den verlangt ins Bett,", "tokens": ["Den", "ver\u00b7langt", "ins", "Bett", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Und mich in die Felsen-Ritzen,", "tokens": ["Und", "mich", "in", "die", "Fel\u00b7sen\u00b7Rit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da die m\u00fcden Tauben sitzen.", "tokens": ["Da", "die", "m\u00fc\u00b7den", "Tau\u00b7ben", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja, ich eil der Ruh,", "tokens": ["Ja", ",", "ich", "eil", "der", "Ruh", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "La\u00df mir deinen Geist,", "tokens": ["La\u00df", "mir", "dei\u00b7nen", "Geist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Der so k\u00f6stlich heist,", "tokens": ["Der", "so", "k\u00f6st\u00b7lich", "heist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df ich ohne Worte spreche,", "tokens": ["Da\u00df", "ich", "oh\u00b7ne", "Wor\u00b7te", "spre\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ich ohne Sturm zerbreche,", "tokens": ["Da\u00df", "ich", "oh\u00b7ne", "Sturm", "zer\u00b7bre\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich Sorgen frey,", "tokens": ["Da\u00df", "ich", "Sor\u00b7gen", "frey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Und doch sorgsam sey.", "tokens": ["Und", "doch", "sorg\u00b7sam", "sey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Du warst ja gewohnt,", "tokens": ["Du", "warst", "ja", "ge\u00b7wohnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Den, der droben thront", "tokens": ["Den", ",", "der", "dro\u00b7ben", "thront"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "ADV", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Auch vor K\u00f6nige zu fassen: ", "tokens": ["Auch", "vor", "K\u00f6\u00b7ni\u00b7ge", "zu", "fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kaum, da\u00df du den Platz verlassen,", "tokens": ["Kaum", ",", "da\u00df", "du", "den", "Platz", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Oefnet seine Bahn", "tokens": ["Oef\u00b7net", "sei\u00b7ne", "Bahn"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "K\u00f6nig ", "tokens": ["K\u00f6\u00b7nig"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.20": {"line.1": {"text": "Sag ichs, oder nicht,", "tokens": ["Sag", "ichs", ",", "o\u00b7der", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "KON", "PTKNEG", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Aufgefahrnes Licht!", "tokens": ["Auf\u00b7ge\u00b7fahr\u00b7nes", "Licht", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df wir deiner Seufzer Rauchen,", "tokens": ["Da\u00df", "wir", "dei\u00b7ner", "Seuf\u00b7zer", "Rau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch vor diese Seele brauchen;", "tokens": ["Auch", "vor", "die\u00b7se", "See\u00b7le", "brau\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich verschone dich,", "tokens": ["Ich", "ver\u00b7scho\u00b7ne", "dich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Jesus h\u00f6ret mich.", "tokens": ["Je\u00b7sus", "h\u00f6\u00b7ret", "mich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Drum gerade zu", "tokens": ["Drum", "ge\u00b7ra\u00b7de", "zu"], "token_info": ["word", "word", "word"], "pos": ["PAV", "ADV", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Auf die stoltze Ruh,", "tokens": ["Auf", "die", "stolt\u00b7ze", "Ruh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Schlaf, nach unterbrochner Stille,", "tokens": ["Schlaf", ",", "nach", "un\u00b7ter\u00b7broch\u00b7ner", "Stil\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das ist GOttes guter Wille,", "tokens": ["Das", "ist", "Got\u00b7tes", "gu\u00b7ter", "Wil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lieb, (es ist erlaubt,)", "tokens": ["Lieb", ",", "(", "es", "ist", "er\u00b7laubt", ",", ")"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "$(", "PPER", "VAFIN", "VVPP", "$,", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Was an JEsum glaubt.", "tokens": ["Was", "an", "Je\u00b7sum", "glaubt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "K\u00f6nig Christian,", "tokens": ["K\u00f6\u00b7nig", "Chris\u00b7ti\u00b7an", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Gottes Unterthan,", "tokens": ["Got\u00b7tes", "Un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Der auch seine Last geladen,", "tokens": ["Der", "auch", "sei\u00b7ne", "Last", "ge\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebe nun von GOttes Gnaden!", "tokens": ["Le\u00b7be", "nun", "von", "Got\u00b7tes", "Gna\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine Majest\u00e4t", "tokens": ["Sei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Wird ans Creutz erh\u00f6ht.", "tokens": ["Wird", "ans", "Creutz", "er\u00b7h\u00f6ht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}