{"textgrid.poem.47999": {"metadata": {"author": {"name": "M\u00fcller-Jahnke, Clara", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dornige Wege", "genre": "verse", "period": "N.A.", "pub_year": 1882, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dornige Wege", "tokens": ["Dor\u00b7ni\u00b7ge", "We\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "bin ich gewandelt,", "tokens": ["bin", "ich", "ge\u00b7wan\u00b7delt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "blutende Wunden", "tokens": ["blu\u00b7ten\u00b7de", "Wun\u00b7den"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "trag ich im Herzen,", "tokens": ["trag", "ich", "im", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "lichtlose Tiefen", "tokens": ["licht\u00b7lo\u00b7se", "Tie\u00b7fen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "hab ich durchmessen . . . .", "tokens": ["hab", "ich", "durch\u00b7mes\u00b7sen", ".", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "$.", "$.", "$.", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "In Wogen des Schmerzes,", "tokens": ["In", "Wo\u00b7gen", "des", "Schmer\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "im Abgrund der Qual", "tokens": ["im", "Ab\u00b7grund", "der", "Qual"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "fand ich eine Perle:", "tokens": ["fand", "ich", "ei\u00b7ne", "Per\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Dich, Margarete!", "tokens": ["Dich", ",", "Mar\u00b7ga\u00b7re\u00b7te", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["PPER", "$,", "NE", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Wir schreiten \u00fcber den D\u00fcnenweg,", "tokens": ["Wir", "schrei\u00b7ten", "\u00fc\u00b7ber", "den", "D\u00fc\u00b7nen\u00b7weg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "als g\u00e4lt' es das Gl\u00fcck zu packen \u2013", "tokens": ["als", "g\u00e4lt'", "es", "das", "Gl\u00fcck", "zu", "pa\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "die Zweige schlagen uns ins Gesicht,", "tokens": ["die", "Zwei\u00b7ge", "schla\u00b7gen", "uns", "ins", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "der Sturm sitzt uns im Nacken.", "tokens": ["der", "Sturm", "sitzt", "uns", "im", "Na\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Vor\u00fcber geht es am gr\u00fcnen Grund,", "tokens": ["Vor\u00b7\u00fc\u00b7ber", "geht", "es", "am", "gr\u00fc\u00b7nen", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "am riedbewachsenen Hange,", "tokens": ["am", "ried\u00b7be\u00b7wach\u00b7se\u00b7nen", "Han\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "vor\u00fcber am Siebenbirkenplatz . . . .", "tokens": ["vor\u00b7\u00fc\u00b7ber", "am", "Sie\u00b7ben\u00b7bir\u00b7ken\u00b7platz", ".", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["ADV", "APPRART", "NN", "$.", "$.", "$.", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Wellen murmeln so bange.", "tokens": ["Die", "Wel\u00b7len", "mur\u00b7meln", "so", "ban\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Zur Linken ein steinernes Festungstor;", "tokens": ["Zur", "Lin\u00b7ken", "ein", "stei\u00b7ner\u00b7nes", "Fes\u00b7tungs\u00b7tor", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "aus moosiger Mauern Kranze", "tokens": ["aus", "moo\u00b7si\u00b7ger", "Mau\u00b7ern", "Kran\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "blickt das Gesicht der alten Zeit \u2013", "tokens": ["blickt", "das", "Ge\u00b7sicht", "der", "al\u00b7ten", "Zeit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "das ist die Heydenschanze.", "tokens": ["das", "ist", "die", "Hey\u00b7den\u00b7schan\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Zur Rechten das weite, blauende Meer,", "tokens": ["Zur", "Rech\u00b7ten", "das", "wei\u00b7te", ",", "blau\u00b7en\u00b7de", "Meer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "dar\u00fcber die M\u00f6wen kreisen,", "tokens": ["da\u00b7r\u00fc\u00b7ber", "die", "M\u00f6\u00b7wen", "krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "drauf spielt der trotzige Harfner Sturm", "tokens": ["drauf", "spielt", "der", "trot\u00b7zi\u00b7ge", "Harf\u00b7ner", "Sturm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "uralte Freiheitsweisen.", "tokens": ["ur\u00b7al\u00b7te", "Frei\u00b7heits\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und nun ein bl\u00fchender Schlehdornhag \u2013", "tokens": ["Und", "nun", "ein", "bl\u00fc\u00b7hen\u00b7der", "Schleh\u00b7dorn\u00b7hag", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "der Fink schl\u00e4gt in den Wipfeln,", "tokens": ["der", "Fink", "schl\u00e4gt", "in", "den", "Wip\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "dann geht es aus schattigem Grund empor", "tokens": ["dann", "geht", "es", "aus", "schat\u00b7ti\u00b7gem", "Grund", "em\u00b7por"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "zu leuchtenden Bergesgipfeln.", "tokens": ["zu", "leuch\u00b7ten\u00b7den", "Ber\u00b7ges\u00b7gip\u00b7feln", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Und fragen wir schier erstaunt, wohin", "tokens": ["Und", "fra\u00b7gen", "wir", "schier", "er\u00b7staunt", ",", "wo\u00b7hin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "VVPP", "$,", "PWAV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "der Weg uns endlich f\u00fchre: \u2013", "tokens": ["der", "Weg", "uns", "end\u00b7lich", "f\u00fch\u00b7re", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "da sind wir schon am Ziel, da stehn", "tokens": ["da", "sind", "wir", "schon", "am", "Ziel", ",", "da", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPRART", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wir an der Friedhofst\u00fcre.", "tokens": ["wir", "an", "der", "Fried\u00b7hofs\u00b7t\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Rotbl\u00fchende Tannen nicken scheu", "tokens": ["Rot\u00b7bl\u00fc\u00b7hen\u00b7de", "Tan\u00b7nen", "ni\u00b7cken", "scheu"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVINF", "VVFIN"], "meter": "++--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "uns zu mit dumpfem Gefl\u00fcster \u2013", "tokens": ["uns", "zu", "mit", "dum\u00b7pfem", "Ge\u00b7fl\u00fcs\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "APPR", "ADJA", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "und dr\u00fcben gr\u00fc\u00dft vom Leichenhaus", "tokens": ["und", "dr\u00fc\u00b7ben", "gr\u00fc\u00dft", "vom", "Lei\u00b7chen\u00b7haus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "das Kreuz uns ernst und d\u00fcster.", "tokens": ["das", "Kreuz", "uns", "ernst", "und", "d\u00fcs\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ich lasse dich nicht, mein letztes Gl\u00fcck,", "tokens": ["Ich", "las\u00b7se", "dich", "nicht", ",", "mein", "letz\u00b7tes", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "ich halte dich fest mit kr\u00e4ftiger Hand:", "tokens": ["ich", "hal\u00b7te", "dich", "fest", "mit", "kr\u00e4f\u00b7ti\u00b7ger", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "schaumspr\u00fchende Woge kehrst du zur\u00fcck", "tokens": ["schaum\u00b7spr\u00fc\u00b7hen\u00b7de", "Wo\u00b7ge", "kehrst", "du", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "an meines Lebens verlassenen Strand.", "tokens": ["an", "mei\u00b7nes", "Le\u00b7bens", "ver\u00b7las\u00b7se\u00b7nen", "Strand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Du nie versiegendes tiefes Meer,", "tokens": ["Du", "nie", "ver\u00b7sie\u00b7gen\u00b7des", "tie\u00b7fes", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "du Abgrund der Liebe, ich lasse dich nicht, \u2013", "tokens": ["du", "Ab\u00b7grund", "der", "Lie\u00b7be", ",", "ich", "las\u00b7se", "dich", "nicht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "NN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "meine Stirn so hei\u00df und mein Auge schwer,", "tokens": ["mei\u00b7ne", "Stirn", "so", "hei\u00df", "und", "mein", "Au\u00b7ge", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "KON", "PPOSAT", "NN", "ADJD", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "du gibst mir K\u00fchlung, du gibst mir Licht!", "tokens": ["du", "gibst", "mir", "K\u00fch\u00b7lung", ",", "du", "gibst", "mir", "Licht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Ob, was ich baute, in Tr\u00fcmmer bricht,", "tokens": ["Ob", ",", "was", "ich", "bau\u00b7te", ",", "in", "Tr\u00fcm\u00b7mer", "bricht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "PPER", "VVFIN", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "wonach ich fa\u00dfte, wie Schaum zerstiebt:", "tokens": ["wo\u00b7nach", "ich", "fa\u00df\u00b7te", ",", "wie", "Schaum", "zer\u00b7stiebt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "NN", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "der sich mein Wesen zu eigen gibt,", "tokens": ["der", "sich", "mein", "We\u00b7sen", "zu", "ei\u00b7gen", "gibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PPOSAT", "NN", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "du meine Seele, ich lasse dich nicht!", "tokens": ["du", "mei\u00b7ne", "See\u00b7le", ",", "ich", "las\u00b7se", "dich", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.12": {"line.1": {"text": "Im fernen Westen ein blasses Rot,", "tokens": ["Im", "fer\u00b7nen", "Wes\u00b7ten", "ein", "blas\u00b7ses", "Rot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "auf schimmernden Wassern ein Fischerboot.", "tokens": ["auf", "schim\u00b7mern\u00b7den", "Was\u00b7sern", "ein", "Fi\u00b7scher\u00b7boot", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.13": {"line.1": {"text": "Von den Gr\u00e4bern \u00fcber die D\u00fcnen her", "tokens": ["Von", "den", "Gr\u00e4\u00b7bern", "\u00fc\u00b7ber", "die", "D\u00fc\u00b7nen", "her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "APZR"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "weht Blumenduft, so schw\u00fcl und schwer.", "tokens": ["weht", "Blu\u00b7men\u00b7duft", ",", "so", "schw\u00fcl", "und", "schwer", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ein Vogel mit m\u00fcdem Fl\u00fcgelschlag", "tokens": ["Ein", "Vo\u00b7gel", "mit", "m\u00fc\u00b7dem", "Fl\u00fc\u00b7gel\u00b7schlag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "irrt durch den bl\u00fchenden Brombeerhag \u2013", "tokens": ["irrt", "durch", "den", "bl\u00fc\u00b7hen\u00b7den", "Brom\u00b7beer\u00b7hag", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.15": {"line.1": {"text": "Und es f\u00e4llt der Tau, und der Tag schl\u00e4ft ein . . .", "tokens": ["Und", "es", "f\u00e4llt", "der", "Tau", ",", "und", "der", "Tag", "schl\u00e4ft", "ein", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,", "KON", "ART", "NN", "VVFIN", "PTKVZ", "$.", "$.", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "wir beide hier oben ganz allein.", "tokens": ["wir", "bei\u00b7de", "hier", "o\u00b7ben", "ganz", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "ADV", "ADV", "ADV", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Wir beide hier oben Hand in Hand", "tokens": ["Wir", "bei\u00b7de", "hier", "o\u00b7ben", "Hand", "in", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PIS", "ADV", "ADV", "NN", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "schaun stille hinab ins verd\u00e4mmernde Land:", "tokens": ["schaun", "stil\u00b7le", "hin\u00b7ab", "ins", "ver\u00b7d\u00e4m\u00b7mern\u00b7de", "Land", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.17": {"line.1": {"text": "In blassen Nebeln die Welt versinkt,", "tokens": ["In", "blas\u00b7sen", "Ne\u00b7beln", "die", "Welt", "ver\u00b7sinkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "die letzten Laute die Stille trinkt.", "tokens": ["die", "letz\u00b7ten", "Lau\u00b7te", "die", "Stil\u00b7le", "trinkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Nun gleitet \u00fcber das dunkle Meer", "tokens": ["Nun", "glei\u00b7tet", "\u00fc\u00b7ber", "das", "dunk\u00b7le", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "mit Sternensegeln die Nacht daher,", "tokens": ["mit", "Ster\u00b7nen\u00b7se\u00b7geln", "die", "Nacht", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "PAV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Und wo sie landet, wird Fried und Ruh, \u2013", "tokens": ["Und", "wo", "sie", "lan\u00b7det", ",", "wird", "Fried", "und", "Ruh", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "VAFIN", "NN", "KON", "NN", "$,", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und einsam hier oben ich und du . . . . . . .", "tokens": ["und", "ein\u00b7sam", "hier", "o\u00b7ben", "ich", "und", "du", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["KON", "ADJD", "ADV", "ADV", "PPER", "KON", "PPER", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "So fass' ich deine beiden H\u00e4nde", "tokens": ["So", "fass'", "ich", "dei\u00b7ne", "bei\u00b7den", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und blick ins Auge dir ohne Laut:", "tokens": ["und", "blick", "ins", "Au\u00b7ge", "dir", "oh\u00b7ne", "Laut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "du bist mein eigen bis ans Ende,", "tokens": ["du", "bist", "mein", "ei\u00b7gen", "bis", "ans", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mir Schwesterseele, tiefvertraut.", "tokens": ["mir", "Schwes\u00b7ter\u00b7see\u00b7le", ",", "tief\u00b7ver\u00b7traut", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Kein Trauern kenn ich, kein Begehren,", "tokens": ["Kein", "Trau\u00b7ern", "kenn", "ich", ",", "kein", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "nickst du mir lieb und l\u00e4chelnd zu: \u2013", "tokens": ["nickst", "du", "mir", "lieb", "und", "l\u00e4\u00b7chelnd", "zu", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "KON", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "es ist, als ob wir fern auf blauen Inseln w\u00e4ren,", "tokens": ["es", "ist", ",", "als", "ob", "wir", "fern", "auf", "blau\u00b7en", "In\u00b7seln", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "PPER", "ADJD", "APPR", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "als \u00fcberfl\u00f6sse nun ein abendlich Verkl\u00e4ren", "tokens": ["als", "\u00fc\u00b7berf\u00b7l\u00f6s\u00b7se", "nun", "ein", "a\u00b7bend\u00b7lich", "Ver\u00b7kl\u00e4\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "die sturmesm\u00fcde Welt \u2013 ein Traum von Sonnenruh.", "tokens": ["die", "stur\u00b7mes\u00b7m\u00fc\u00b7de", "Welt", "\u2013", "ein", "Traum", "von", "Son\u00b7nen\u00b7ruh", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}