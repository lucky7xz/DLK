{"textgrid.poem.59977": {"metadata": {"author": {"name": "Herwegh, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Ordonnanzen!", "genre": "verse", "period": "N.A.", "pub_year": 1846, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ordonnanzen! Ordonnanzen!", "tokens": ["Or\u00b7don\u00b7nan\u00b7zen", "!", "Or\u00b7don\u00b7nan\u00b7zen", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine V\u00f6lker m\u00fcssen tanzen,", "tokens": ["Mei\u00b7ne", "V\u00f6l\u00b7ker", "m\u00fcs\u00b7sen", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich ihnen aufgespielt!", "tokens": ["Wie", "ich", "ih\u00b7nen", "auf\u00b7ge\u00b7spielt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eins \u2013 zwei \u2013 drei \u2013 und Runde! Runde!", "tokens": ["Eins", "\u2013", "zwei", "\u2013", "drei", "\u2013", "und", "Run\u00b7de", "!", "Run\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "CARD", "$(", "CARD", "$(", "KON", "NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tanzet, ihr getreuen Hunde,", "tokens": ["Tan\u00b7zet", ",", "ihr", "ge\u00b7treu\u00b7en", "Hun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Wenn der K\u00f6nig es befiehlt. :|", "tokens": ["|", ":", "Wenn", "der", "K\u00f6\u00b7nig", "es", "be\u00b7fiehlt", ".", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "KOUS", "ART", "NN", "PPER", "VVFIN", "$.", "$.", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Lernt des Lebens Lust begreifen,", "tokens": ["Lernt", "des", "Le\u00b7bens", "Lust", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euer K\u00f6nig wird euch pfeifen \u2013", "tokens": ["Eu\u00b7er", "K\u00f6\u00b7nig", "wird", "euch", "pfei\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ihr werdet ihn verstehn.", "tokens": ["Und", "ihr", "wer\u00b7det", "ihn", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur im Kreise, nur im Kreise,", "tokens": ["Nur", "im", "Krei\u00b7se", ",", "nur", "im", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nach dem Takt der Russenweise,", "tokens": ["Nach", "dem", "Takt", "der", "Rus\u00b7sen\u00b7wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Nur um mich sollt ihr euch drehn. :|", "tokens": ["|", ":", "Nur", "um", "mich", "sollt", "ihr", "euch", "drehn", ".", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "ADV", "APPR", "PPER", "VMFIN", "PPER", "PRF", "VVINF", "$.", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Ich bin euer Kopf und Magen,", "tokens": ["Ich", "bin", "eu\u00b7er", "Kopf", "und", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Antwort Ich auf alle Fragen,", "tokens": ["Ant\u00b7wort", "Ich", "auf", "al\u00b7le", "Fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Aller Rede letzter Sinn;", "tokens": ["Al\u00b7ler", "Re\u00b7de", "letz\u00b7ter", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr der Abglanz nur des F\u00fcrsten \u2013", "tokens": ["Ihr", "der", "Ab\u00b7glanz", "nur", "des", "F\u00fcrs\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wer wagte noch zu d\u00fcrsten,", "tokens": ["Und", "wer", "wag\u00b7te", "noch", "zu", "d\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Wenn ich selber trunken bin? :|", "tokens": ["|", ":", "Wenn", "ich", "sel\u00b7ber", "trun\u00b7ken", "bin", "?", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$.", "$.", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Volksvertreten? Volksvertreten?", "tokens": ["Volks\u00b7ver\u00b7tre\u00b7ten", "?", "Volks\u00b7ver\u00b7tre\u00b7ten", "?"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Beten sollt ihr, ruf ich, beten!", "tokens": ["Be\u00b7ten", "sollt", "ihr", ",", "ruf", "ich", ",", "be\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bin Solon und Lykurg!", "tokens": ["Ich", "bin", "So\u00b7lon", "und", "Ly\u00b7kurg", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "KON", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Brecht mir nicht des Schweigens Siegel,", "tokens": ["Brecht", "mir", "nicht", "des", "Schwei\u00b7gens", "Sie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn ich habe Schlo\u00df und Riegel;", "tokens": ["Denn", "ich", "ha\u00b7be", "Schlo\u00df", "und", "Rie\u00b7gel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Gott ist eine feste Burg! :|", "tokens": ["|", ":", "Gott", "ist", "ei\u00b7ne", "fes\u00b7te", "Burg", "!", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "NN", "VAFIN", "ART", "ADJA", "NN", "$.", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ordonnanzen! Ordonnanzen!", "tokens": ["Or\u00b7don\u00b7nan\u00b7zen", "!", "Or\u00b7don\u00b7nan\u00b7zen", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine V\u00f6lker m\u00fcssen tanzen,", "tokens": ["Mei\u00b7ne", "V\u00f6l\u00b7ker", "m\u00fcs\u00b7sen", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich ihnen aufgespielt!", "tokens": ["Wie", "ich", "ih\u00b7nen", "auf\u00b7ge\u00b7spielt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tanzt, o Polen \u2013 tanzt, o Deutsche,", "tokens": ["Tanzt", ",", "o", "Po\u00b7len", "\u2013", "tanzt", ",", "o", "Deut\u00b7sche", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "FM", "NE", "$(", "VVFIN", "$,", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle nach derselben Peitsche,", "tokens": ["Al\u00b7le", "nach", "der\u00b7sel\u00b7ben", "Peit\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Wenn der K\u00f6nig es befiehlt! :|", "tokens": ["|", ":", "Wenn", "der", "K\u00f6\u00b7nig", "es", "be\u00b7fiehlt", "!", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "KOUS", "ART", "NN", "PPER", "VVFIN", "$.", "$.", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Ich bin K\u00f6nig, meine Gr\u00fcnde", "tokens": ["Ich", "bin", "K\u00f6\u00b7nig", ",", "mei\u00b7ne", "Gr\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Donnern durch Kanonenschl\u00fcnde", "tokens": ["Don\u00b7nern", "durch", "Ka\u00b7no\u00b7nen\u00b7schl\u00fcn\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In des P\u00f6bels taubes Ohr;", "tokens": ["In", "des", "P\u00f6\u00b7bels", "tau\u00b7bes", "Ohr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Rasselt irgendwo die Kette,", "tokens": ["Ras\u00b7selt", "ir\u00b7gend\u00b7wo", "die", "Ket\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hunderttausend Bajonette", "tokens": ["Hun\u00b7dert\u00b7tau\u00b7send", "Ba\u00b7jo\u00b7net\u00b7te"], "token_info": ["word", "word"], "pos": ["CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Schaffen Ruhe wie zuvor. :|", "tokens": ["|", ":", "Schaf\u00b7fen", "Ru\u00b7he", "wie", "zu\u00b7vor", ".", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "NN", "NN", "KOKOM", "ADV", "$.", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Wer sich r\u00fchret, wird geschlossen", "tokens": ["Wer", "sich", "r\u00fch\u00b7ret", ",", "wird", "ge\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PRF", "VVFIN", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und wo m\u00f6glich schon erschossen,", "tokens": ["Und", "wo", "m\u00f6g\u00b7lich", "schon", "er\u00b7schos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eh man ihm das Urteil f\u00e4llt.", "tokens": ["Eh", "man", "ihm", "das", "Ur\u00b7teil", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Justiz \u2013 geheim und schnelle,", "tokens": ["Die", "Jus\u00b7tiz", "\u2013", "ge\u00b7heim", "und", "schnel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "F\u00f6rdert noch vor Tageshelle", "tokens": ["F\u00f6r\u00b7dert", "noch", "vor", "Ta\u00b7ges\u00b7hel\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Jeden Meutrer aus der Welt. :|", "tokens": ["|", ":", "Je\u00b7den", "Meut\u00b7rer", "aus", "der", "Welt", ".", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "PIAT", "NN", "APPR", "ART", "NN", "$.", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Freiheit \u2013 welch ein toll Begehren!", "tokens": ["Frei\u00b7heit", "\u2013", "welch", "ein", "toll", "Be\u00b7geh\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PWAT", "ART", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ja, der Henker soll sie lehren", "tokens": ["Ja", ",", "der", "Hen\u00b7ker", "soll", "sie", "leh\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Euch zum Schrecken und zum Graus;", "tokens": ["Euch", "zum", "Schre\u00b7cken", "und", "zum", "Graus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird der Vorrat hier zu mager,", "tokens": ["Wird", "der", "Vor\u00b7rat", "hier", "zu", "ma\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hilft ja gern mein lieber Schwager", "tokens": ["Hilft", "ja", "gern", "mein", "lie\u00b7ber", "Schwa\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Mir mit seinen Galgen aus. :|", "tokens": ["|", ":", "Mir", "mit", "sei\u00b7nen", "Gal\u00b7gen", "aus", ".", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "NE", "APPR", "PPOSAT", "NN", "PTKVZ", "$.", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Ordonnanzen! Ordonnanzen!", "tokens": ["Or\u00b7don\u00b7nan\u00b7zen", "!", "Or\u00b7don\u00b7nan\u00b7zen", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine V\u00f6lker m\u00fcssen tanzen,", "tokens": ["Mei\u00b7ne", "V\u00f6l\u00b7ker", "m\u00fcs\u00b7sen", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich ihnen aufgespielt!", "tokens": ["Wie", "ich", "ih\u00b7nen", "auf\u00b7ge\u00b7spielt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tanzt, ihr Deutschen \u2013 tanzt, ihr Polen,", "tokens": ["Tanzt", ",", "ihr", "Deut\u00b7schen", "\u2013", "tanzt", ",", "ihr", "Po\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$(", "VVFIN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie der Zar es mir befohlen,", "tokens": ["Wie", "der", "Zar", "es", "mir", "be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Wie's der K\u00f6nig euch befiehlt! :|", "tokens": ["|", ":", "Wie's", "der", "K\u00f6\u00b7nig", "euch", "be\u00b7fiehlt", "!", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "NN", "ART", "NN", "PPER", "VVFIN", "$.", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.10": {"line.1": {"text": "Jeder Fl\u00fcgel sei beschnitten,", "tokens": ["Je\u00b7der", "Fl\u00fc\u00b7gel", "sei", "be\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch dem Amor \u2013 der die Sitten", "tokens": ["Auch", "dem", "A\u00b7mor", "\u2013", "der", "die", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NE", "$(", "ART", "ART", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Unsres Reichs kompromittiert.", "tokens": ["Uns\u00b7res", "Reichs", "kom\u00b7pro\u00b7mit\u00b7tiert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und von nun an sei bewu\u00dftes", "tokens": ["Und", "von", "nun", "an", "sei", "be\u00b7wu\u00df\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "APZR", "VAFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bett von weiland Herrn Prokrustes", "tokens": ["Bett", "von", "wei\u00b7land", "Herrn", "Pro\u00b7krus\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ADV", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: Als Reichsehbett eingef\u00fchrt. :|", "tokens": ["|", ":", "Als", "Reich\u00b7seh\u00b7bett", "ein\u00b7ge\u00b7f\u00fchrt", ".", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "KOUS", "NN", "VVPP", "$.", "$.", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Nur ein Vorurteil ist Liebe;", "tokens": ["Nur", "ein", "Vor\u00b7ur\u00b7teil", "ist", "Lie\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre ungest\u00fcmen Triebe", "tokens": ["Uns\u00b7re", "un\u00b7ge\u00b7st\u00fc\u00b7men", "Trie\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Z\u00fcgl ich durch ein christlich Joch.", "tokens": ["Z\u00fcgl", "ich", "durch", "ein", "christ\u00b7lich", "Joch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich bin Herr von allen Sachen,", "tokens": ["Ich", "bin", "Herr", "von", "al\u00b7len", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und allein das \u2013 Kindermachen", "tokens": ["Und", "al\u00b7lein", "das", "\u2013", "Kin\u00b7der\u00b7ma\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "ART", "$(", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "|: La\u00df ich euch in Gnaden noch. :|", "tokens": ["|", ":", "La\u00df", "ich", "euch", "in", "Gna\u00b7den", "noch", ".", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$(", "VVIMP", "PPER", "PRF", "APPR", "NN", "ADV", "$.", "$.", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Ich verbiete, ich erlaube,", "tokens": ["Ich", "ver\u00b7bie\u00b7te", ",", "ich", "er\u00b7lau\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich nur denke, ich nur glaube,", "tokens": ["Ich", "nur", "den\u00b7ke", ",", "ich", "nur", "glau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ihr alle seid bekehrt.", "tokens": ["Und", "ihr", "al\u00b7le", "seid", "be\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jeden Zweifel l\u00f6st die Knute:", "tokens": ["Je\u00b7den", "Zwei\u00b7fel", "l\u00f6st", "die", "Knu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hat man denn das Absolute", "tokens": ["Hat", "man", "denn", "das", "Ab\u00b7so\u00b7lu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "|: In Berlin umsonst gelehrt? :|", "tokens": ["|", ":", "In", "Ber\u00b7lin", "um\u00b7sonst", "ge\u00b7lehrt", "?", ":", "|"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "$.", "APPR", "NE", "ADV", "VVPP", "$.", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Seid ihr denn nicht meine Knechte?", "tokens": ["Seid", "ihr", "denn", "nicht", "mei\u00b7ne", "Knech\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und ihr fragt nach einem Rechte,", "tokens": ["Und", "ihr", "fragt", "nach", "ei\u00b7nem", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn der K\u00f6nig was befiehlt?", "tokens": ["Wenn", "der", "K\u00f6\u00b7nig", "was", "be\u00b7fiehlt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ordonnanzen! Ordonnanzen!", "tokens": ["Or\u00b7don\u00b7nan\u00b7zen", "!", "Or\u00b7don\u00b7nan\u00b7zen", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meine V\u00f6lker m\u00fcssen tanzen,", "tokens": ["Mei\u00b7ne", "V\u00f6l\u00b7ker", "m\u00fcs\u00b7sen", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie ich ihnen aufgespielt!", "tokens": ["Wie", "ich", "ih\u00b7nen", "auf\u00b7ge\u00b7spielt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}