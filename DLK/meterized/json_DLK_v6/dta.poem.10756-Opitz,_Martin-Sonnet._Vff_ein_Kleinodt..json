{"dta.poem.10756": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Sonnet.  \n  Vff ein Kleinodt.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Fahr hin/ du stoltz Geschmeidt/ da\u00df du mich wilt Braviren/", "tokens": ["Fahr", "hin", "/", "du", "stoltz", "Ge\u00b7schmeidt", "/", "da\u00df", "du", "mich", "wilt", "Bra\u00b7vi\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$(", "PPER", "ADJD", "NN", "$(", "KOUS", "PPER", "PPER", "VMFIN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fahr hin/ seh\u2019 aber zu/ da\u00df es dir nicht mi\u00dfling/", "tokens": ["Fahr", "hin", "/", "seh'", "a\u00b7ber", "zu", "/", "da\u00df", "es", "dir", "nicht", "mi\u00df\u00b7ling", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$(", "VVFIN", "ADV", "PTKZU", "$(", "KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd du dich achtest hoch/ vnd sie dich acht gering/", "tokens": ["Vnd", "du", "dich", "ach\u00b7test", "hoch", "/", "vnd", "sie", "dich", "acht", "ge\u00b7ring", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "ADV", "ADJD", "$(", "KON", "PPER", "PRF", "CARD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du kanst sie doch in nichts/ sie kan dich aber zieren/", "tokens": ["Du", "kanst", "sie", "doch", "in", "nichts", "/", "sie", "kan", "dich", "a\u00b7ber", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPR", "PIS", "$(", "PPER", "VMFIN", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wann dich die Edle Zier wolt vf der Bruste f\u00fchren;", "tokens": ["Wann", "dich", "die", "Ed\u00b7le", "Zier", "wolt", "vf", "der", "Brus\u00b7te", "f\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mir ist gar wohl bewust/ da\u00df kein erw\u00fcnschter ding", "tokens": ["Mir", "ist", "gar", "wohl", "be\u00b7wust", "/", "da\u00df", "kein", "er\u00b7w\u00fcnschter", "ding"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "$(", "KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Dir widerfahren k\u00f6nt/ vff diesem Erdenring/", "tokens": ["Dir", "wi\u00b7der\u00b7fah\u00b7ren", "k\u00f6nt", "/", "vff", "die\u00b7sem", "Er\u00b7den\u00b7ring", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VVFIN", "$(", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als wann du also nah\u2019 jhr Hertze soltest r\u00fchren.", "tokens": ["Als", "wann", "du", "al\u00b7so", "nah'", "jhr", "Hert\u00b7ze", "sol\u00b7test", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "ADV", "VVFIN", "PPER", "VVFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dann w\u00fcrdest du dich erst erheben vber mich/", "tokens": ["Dann", "w\u00fcr\u00b7dest", "du", "dich", "erst", "er\u00b7he\u00b7ben", "vber", "mich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ADV", "VVFIN", "APPR", "PPER", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Wann dir das keusche Hertz so blo\u00df verg\u00f6nnet sich/", "tokens": ["Wann", "dir", "das", "keu\u00b7sche", "Hertz", "so", "blo\u00df", "ver\u00b7g\u00f6n\u00b7net", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "ADV", "ADV", "VVFIN", "PRF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da\u00df du es d\u00f6rfftest ja genug genug zerk\u00fcssen/", "tokens": ["Da\u00df", "du", "es", "d\u00f6rff\u00b7test", "ja", "ge\u00b7nug", "ge\u00b7nug", "zer\u00b7k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da ich zufrieden wer/ wann mir das Vorgemach/", "tokens": ["Da", "ich", "zu\u00b7frie\u00b7den", "wer", "/", "wann", "mir", "das", "Vor\u00b7ge\u00b7mach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PWS", "$(", "PWAV", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Den zarten rothen Mundt/ den s\u00fcssen Honigbach/", "tokens": ["Den", "zar\u00b7ten", "ro\u00b7then", "Mundt", "/", "den", "s\u00fcs\u00b7sen", "Ho\u00b7nig\u00b7bach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Erlaubet wer so keck nur einmahl zubegr\u00fcssen.", "tokens": ["Er\u00b7lau\u00b7bet", "wer", "so", "keck", "nur", "ein\u00b7mahl", "zu\u00b7be\u00b7gr\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ADV", "ADJD", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}