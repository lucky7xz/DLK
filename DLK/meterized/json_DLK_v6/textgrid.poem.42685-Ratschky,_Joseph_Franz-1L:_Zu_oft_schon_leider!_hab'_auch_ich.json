{"textgrid.poem.42685": {"metadata": {"author": {"name": "Ratschky, Joseph Franz", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zu oft schon leider! hab' auch ich", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu oft schon leider! hab' auch ich", "tokens": ["Zu", "oft", "schon", "lei\u00b7der", "!", "hab'", "auch", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "ADV", "$.", "VAFIN", "ADV", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der M\u00f6nche Kunden freventlich", "tokens": ["Der", "M\u00f6n\u00b7che", "Kun\u00b7den", "fre\u00b7vent\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bisher bezweifelt und bewitzelt.", "tokens": ["Bis\u00b7her", "be\u00b7zwei\u00b7felt", "und", "be\u00b7wit\u00b7zelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr andachtsvollen Herrn und Fraun,", "tokens": ["Ihr", "an\u00b7dachts\u00b7vol\u00b7len", "Herrn", "und", "Fraun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vergebt mir's! von des Teufels Klaun", "tokens": ["Ver\u00b7gebt", "mir's", "!", "von", "des", "Teu\u00b7fels", "Klaun"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ward, was ich schrieb, mir vorgekritzelt.", "tokens": ["Ward", ",", "was", "ich", "schrieb", ",", "mir", "vor\u00b7ge\u00b7krit\u00b7zelt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch reuig leg' ich mich zum Ziel:", "tokens": ["Doch", "reu\u00b7ig", "leg'", "ich", "mich", "zum", "Ziel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Zukunft soll aus meinem Kiel", "tokens": ["In", "Zu\u00b7kunft", "soll", "aus", "mei\u00b7nem", "Kiel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gewiss kein arges Wort mehr triefen.", "tokens": ["Ge\u00b7wiss", "kein", "ar\u00b7ges", "Wort", "mehr", "trie\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von wahrem Eifer angefacht,", "tokens": ["Von", "wah\u00b7rem", "Ei\u00b7fer", "an\u00b7ge\u00b7facht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Will ich von nun an Tag und Nacht", "tokens": ["Will", "ich", "von", "nun", "an", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In Kochems Schriften mich vertiefen.", "tokens": ["In", "Ko\u00b7chems", "Schrif\u00b7ten", "mich", "ver\u00b7tie\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dank sey dir, Fast! dein Unterricht", "tokens": ["Dank", "sey", "dir", ",", "Fast", "!", "dein", "Un\u00b7ter\u00b7richt"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "VAFIN", "PPER", "$,", "NN", "$.", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Erf\u00fcllte meinen Geist mit Licht:", "tokens": ["Er\u00b7f\u00fcll\u00b7te", "mei\u00b7nen", "Geist", "mit", "Licht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bussfertig k\u00fcss' ich dir die H\u00e4nde", "tokens": ["Buss\u00b7fer\u00b7tig", "k\u00fcss'", "ich", "dir", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Zum Zeichen meiner Huldigung.", "tokens": ["Zum", "Zei\u00b7chen", "mei\u00b7ner", "Hul\u00b7di\u00b7gung", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die \u00c4chtheit meiner Besserung", "tokens": ["Die", "\u00c4cht\u00b7heit", "mei\u00b7ner", "Bes\u00b7se\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Bew\u00e4hrt dir folgende Legende.", "tokens": ["Be\u00b7w\u00e4hrt", "dir", "fol\u00b7gen\u00b7de", "Le\u00b7gen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "In einem \u00f6den Zedernhain", "tokens": ["In", "ei\u00b7nem", "\u00f6\u00b7den", "Ze\u00b7dern\u00b7hain"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4hlt' einst auf einem Felsenstein,", "tokens": ["W\u00e4hlt'", "einst", "auf", "ei\u00b7nem", "Fel\u00b7sen\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bewohnt von Schlangen und von Drachen,", "tokens": ["Be\u00b7wohnt", "von", "Schlan\u00b7gen", "und", "von", "Dra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich Pachon, der Anachoret,", "tokens": ["Sich", "Pa\u00b7chon", ",", "der", "A\u00b7nac\u00b7ho\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein Pl\u00e4tzchen, um durch sein Gebet", "tokens": ["Ein", "Pl\u00e4tz\u00b7chen", ",", "um", "durch", "sein", "Ge\u00b7bet"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUI", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verj\u00e4hrte S\u00fcnden gutzumachen.", "tokens": ["Ver\u00b7j\u00e4hr\u00b7te", "S\u00fcn\u00b7den", "gut\u00b7zu\u00b7ma\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Eingang in die Felsenkluft,", "tokens": ["Der", "Ein\u00b7gang", "in", "die", "Fel\u00b7sen\u00b7kluft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Worin er, wie in einer Gruft,", "tokens": ["Wo\u00b7rin", "er", ",", "wie", "in", "ei\u00b7ner", "Gruft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich einschloss, mass kaum eine Elle.", "tokens": ["Sich", "ein\u00b7schloss", ",", "mass", "kaum", "ei\u00b7ne", "El\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Kreutz, ein Betstuhl und ein Paar", "tokens": ["Ein", "Kreutz", ",", "ein", "Bet\u00b7stuhl", "und", "ein", "Paar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vermorschter Todtenk\u00f6pfe war", "tokens": ["Ver\u00b7morschter", "Tod\u00b7ten\u00b7k\u00f6p\u00b7fe", "war"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Der ganze Hausrath seiner Zelle.", "tokens": ["Der", "gan\u00b7ze", "Haus\u00b7rath", "sei\u00b7ner", "Zel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ein enges h\u00e4rnes Wamms zerrieb", "tokens": ["Ein", "en\u00b7ges", "h\u00e4r\u00b7nes", "Wamms", "zer\u00b7rieb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm mit der Haut zugleich den Trieb", "tokens": ["Ihm", "mit", "der", "Haut", "zu\u00b7gleich", "den", "Trieb"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zur Unzucht und zu b\u00f6sen L\u00fcsten.", "tokens": ["Zur", "Un\u00b7zucht", "und", "zu", "b\u00f6\u00b7sen", "L\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er als nur Wurzeln, und genoss", "tokens": ["Er", "als", "nur", "Wur\u00b7zeln", ",", "und", "ge\u00b7noss"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "KOKOM", "ADV", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie nie aus Essgier, sondern bloss", "tokens": ["Sie", "nie", "aus", "Ess\u00b7gier", ",", "son\u00b7dern", "bloss"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "APPR", "NN", "$,", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein B\u00fcsserleben sich zu fristen.", "tokens": ["Sein", "B\u00fcs\u00b7ser\u00b7le\u00b7ben", "sich", "zu", "fris\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Durch diese strenge Disciplin", "tokens": ["Durch", "die\u00b7se", "stren\u00b7ge", "Dis\u00b7cip\u00b7lin"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bracht' es der heil'ge Mann dahin,", "tokens": ["Bracht'", "es", "der", "heil'\u00b7ge", "Mann", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das geile Fleisch im Zaum zu halten.", "tokens": ["Das", "gei\u00b7le", "Fleisch", "im", "Zaum", "zu", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Umsonst versuchte Lucifer,", "tokens": ["Um\u00b7sonst", "ver\u00b7such\u00b7te", "Lu\u00b7ci\u00b7fer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Erbfeind frommer B\u00fcssender,", "tokens": ["Der", "Erb\u00b7feind", "from\u00b7mer", "B\u00fcs\u00b7sen\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn unter mancherley Gestalten.", "tokens": ["Ihn", "un\u00b7ter", "man\u00b7cher\u00b7ley", "Ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Einst abends um die Vesperzeit", "tokens": ["Einst", "a\u00b7bends", "um", "die", "Ves\u00b7per\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stellt', in das sch\u00f6nste Frauenkleid", "tokens": ["Stellt'", ",", "in", "das", "sch\u00f6ns\u00b7te", "Frau\u00b7en\u00b7kleid"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus Satans reicher Garderobe", "tokens": ["Aus", "Sa\u00b7tans", "rei\u00b7cher", "Gar\u00b7de\u00b7ro\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vermummt, ein junges Teufelchen", "tokens": ["Ver\u00b7mummt", ",", "ein", "jun\u00b7ges", "Teu\u00b7fel\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Von schlankem Wuchs des heiligen", "tokens": ["Von", "schlan\u00b7kem", "Wuchs", "des", "hei\u00b7li\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Waldbruders Keuschheit auf die Probe.", "tokens": ["Wald\u00b7bru\u00b7ders", "Keuschheit", "auf", "die", "Pro\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.9": {"line.1": {"text": "Es trat die saubre H\u00f6llenbraut", "tokens": ["Es", "trat", "die", "saub\u00b7re", "H\u00f6l\u00b7len\u00b7braut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Negerinn mit schwarzer Haut,", "tokens": ["Als", "Ne\u00b7ge\u00b7rinn", "mit", "schwar\u00b7zer", "Haut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die von Natur den H\u00f6llenschaaren", "tokens": ["Die", "von", "Na\u00b7tur", "den", "H\u00f6l\u00b7len\u00b7schaa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gemein ist, zur Klausur hinein.", "tokens": ["Ge\u00b7mein", "ist", ",", "zur", "Klau\u00b7sur", "hin\u00b7ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Man sagt, dass damals allgemein", "tokens": ["Man", "sagt", ",", "dass", "da\u00b7mals", "all\u00b7ge\u00b7mein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die schwarzen Damen Mode waren.", "tokens": ["Die", "schwar\u00b7zen", "Da\u00b7men", "Mo\u00b7de", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Erst suchte sie durch dreisten Scherz", "tokens": ["Erst", "such\u00b7te", "sie", "durch", "dreis\u00b7ten", "Scherz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und freche Zoten Pachons Herz", "tokens": ["Und", "fre\u00b7che", "Zo\u00b7ten", "Pa\u00b7chons", "Herz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vom Weg der Tugend abzuleiten,", "tokens": ["Vom", "Weg", "der", "Tu\u00b7gend", "ab\u00b7zu\u00b7lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und dann, als unser Eremit", "tokens": ["Und", "dann", ",", "als", "un\u00b7ser", "E\u00b7re\u00b7mit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Dirne kein Geh\u00f6r gab, schritt", "tokens": ["Der", "Dir\u00b7ne", "kein", "Ge\u00b7h\u00f6r", "gab", ",", "schritt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "PIAT", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie zu den k\u00fchnsten Th\u00e4tlichkeiten.", "tokens": ["Sie", "zu", "den", "k\u00fchns\u00b7ten", "Th\u00e4t\u00b7lich\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Mit schlauem L\u00e4cheln setzte sie", "tokens": ["Mit", "schlau\u00b7em", "L\u00e4\u00b7cheln", "setz\u00b7te", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich auf des spr\u00f6den Klausners Knie,", "tokens": ["Sich", "auf", "des", "spr\u00f6\u00b7den", "Klaus\u00b7ners", "Knie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Strich buhlerisch ihm Kinn und Wangen,", "tokens": ["Strich", "buh\u00b7le\u00b7risch", "ihm", "Kinn", "und", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und hielt mit geilem Ungest\u00fcm", "tokens": ["Und", "hielt", "mit", "gei\u00b7lem", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihn fest umschlungen, um von ihm", "tokens": ["Ihn", "fest", "um\u00b7schlun\u00b7gen", ",", "um", "von", "ihm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADJD", "VVINF", "$,", "KOUI", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Raub ein Schm\u00e4tzchen zu erlangen.", "tokens": ["Durch", "Raub", "ein", "Schm\u00e4tz\u00b7chen", "zu", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch Pachons nervenvolle Hand", "tokens": ["Doch", "Pa\u00b7chons", "ner\u00b7ven\u00b7vol\u00b7le", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Vertrieb dem k\u00fchnen H\u00f6llenbrand", "tokens": ["Ver\u00b7trieb", "dem", "k\u00fch\u00b7nen", "H\u00f6l\u00b7len\u00b7brand"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit ein paar wackern Backenstreichen", "tokens": ["Mit", "ein", "paar", "wa\u00b7ckern", "Ba\u00b7cken\u00b7strei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die L\u00fcsternheit nach einem Kuss,", "tokens": ["Die", "L\u00fcs\u00b7tern\u00b7heit", "nach", "ei\u00b7nem", "Kuss", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und zwang durch diesen derben Gruss", "tokens": ["Und", "zwang", "durch", "die\u00b7sen", "der\u00b7ben", "Gruss"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das schwarze Fr\u00e4ulein zu entweichen.", "tokens": ["Das", "schwar\u00b7ze", "Fr\u00e4u\u00b7lein", "zu", "ent\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "O frommer J\u00fcngling, spiegle dich", "tokens": ["O", "from\u00b7mer", "J\u00fcng\u00b7ling", ",", "spieg\u00b7le", "dich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An diesem Beyspiel! Ritterlich", "tokens": ["An", "die\u00b7sem", "Bey\u00b7spiel", "!", "Rit\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "PDAT", "NN", "$.", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verfocht der strenge Mann die Tugend.", "tokens": ["Ver\u00b7focht", "der", "stren\u00b7ge", "Mann", "die", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn sich ein sch\u00f6nes Kind dir naht,", "tokens": ["Wenn", "sich", "ein", "sch\u00f6\u00b7nes", "Kind", "dir", "naht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So sch\u00fctz' auch du, wie Pachon that,", "tokens": ["So", "sch\u00fctz'", "auch", "du", ",", "wie", "Pa\u00b7chon", "that", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "$,", "PWAV", "NN", "VVFIN", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Mit Backenstreichen deine Jugend!", "tokens": ["Mit", "Ba\u00b7cken\u00b7strei\u00b7chen", "dei\u00b7ne", "Ju\u00b7gend", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wenn dich auch drob die b\u00f6se Welt", "tokens": ["Wenn", "dich", "auch", "drob", "die", "b\u00f6\u00b7se", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vielleicht f\u00fcr ungesittet h\u00e4lt,", "tokens": ["Viel\u00b7leicht", "f\u00fcr", "un\u00b7ge\u00b7sit\u00b7tet", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So schweig, und lass dich's nicht verdriessen!", "tokens": ["So", "schweig", ",", "und", "lass", "dich's", "nicht", "ver\u00b7dries\u00b7sen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer nach der Gunst des Himmels strebt,", "tokens": ["Wer", "nach", "der", "Gunst", "des", "Him\u00b7mels", "strebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Darf, weil er jener Welt nur lebt,", "tokens": ["Darf", ",", "weil", "er", "je\u00b7ner", "Welt", "nur", "lebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "KOUS", "PPER", "PDAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In dieser nicht zu leben wissen.", "tokens": ["In", "die\u00b7ser", "nicht", "zu", "le\u00b7ben", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PTKNEG", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}