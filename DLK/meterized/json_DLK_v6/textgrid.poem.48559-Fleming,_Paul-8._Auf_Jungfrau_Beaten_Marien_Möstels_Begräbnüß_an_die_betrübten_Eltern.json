{"textgrid.poem.48559": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "8. Auf Jungfrau Beaten Marien M\u00f6stels Begr\u00e4bn\u00fc\u00df an die betr\u00fcbten Eltern", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Freilich, freilich m\u00fc\u00dft ihr klagen,", "tokens": ["Frei\u00b7lich", ",", "frei\u00b7lich", "m\u00fc\u00dft", "ihr", "kla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihr betr\u00fcbten Herzen ihr,", "tokens": ["ihr", "be\u00b7tr\u00fcb\u00b7ten", "Her\u00b7zen", "ihr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df fast inner zweier Tagen", "tokens": ["da\u00df", "fast", "in\u00b7ner", "zwei\u00b7er", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJD", "ADJA", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "euch ein zweifach Leid st\u00f6\u00dft f\u00fcr,", "tokens": ["euch", "ein", "zwei\u00b7fach", "Leid", "st\u00f6\u00dft", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "APPR", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da ein einzigs dieser beiden", "tokens": ["da", "ein", "ein\u00b7zigs", "die\u00b7ser", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "PIS", "PDAT", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mehr kr\u00e4nkt als sonst hundert Leiden.", "tokens": ["mehr", "kr\u00e4nkt", "als", "sonst", "hun\u00b7dert", "Lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOKOM", "ADV", "CARD", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Und ach! w\u00e4r' es doch noch blieben", "tokens": ["Und", "ach", "!", "w\u00e4r'", "es", "doch", "noch", "blie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "VAFIN", "PPER", "ADV", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bei dem einen nur allein,", "tokens": ["bei", "dem", "ei\u00b7nen", "nur", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "das euch hat von uns getrieben", "tokens": ["das", "euch", "hat", "von", "uns", "ge\u00b7trie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "VAFIN", "APPR", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und nicht lie\u00dfe sicher sein,", "tokens": ["und", "nicht", "lie\u00b7\u00dfe", "si\u00b7cher", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVFIN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "das des sch\u00f6nen ", "tokens": ["das", "des", "sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "nunmehr setzt in Furcht und Trauren.", "tokens": ["nun\u00b7mehr", "setzt", "in", "Furcht", "und", "Trau\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Weil ihr gro\u00dfer Not entgehet,", "tokens": ["Weil", "ihr", "gro\u00b7\u00dfer", "Not", "ent\u00b7ge\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so fallt ihr in gr\u00f6\u00dfre Strick',", "tokens": ["so", "fallt", "ihr", "in", "gr\u00f6\u00df\u00b7re", "Strick'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "nun ihr seht, wie vor euch stehet", "tokens": ["nun", "ihr", "seht", ",", "wie", "vor", "euch", "ste\u00b7het"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$,", "PWAV", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nur auf einen Augenblick", "tokens": ["nur", "auf", "ei\u00b7nen", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "lebend, frisch, krank und erlegen", "tokens": ["le\u00b7bend", ",", "frisch", ",", "krank", "und", "er\u00b7le\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "eurer Ehe s\u00fc\u00dfer Segen.", "tokens": ["eu\u00b7rer", "E\u00b7he", "s\u00fc\u00b7\u00dfer", "Se\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Satten Fug habt ihr zu zagen", "tokens": ["Sat\u00b7ten", "Fug", "habt", "ihr", "zu", "za\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bevoraus um letzten Fall,", "tokens": ["be\u00b7vo\u00b7raus", "um", "letz\u00b7ten", "Fall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "doch ihr m\u00fcsset selbsten sagen,", "tokens": ["doch", "ihr", "m\u00fcs\u00b7set", "selbs\u00b7ten", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df es nichts hilft \u00fcberall.", "tokens": ["da\u00df", "es", "nichts", "hilft", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Blos auf den nur mu\u00df man sehen,", "tokens": ["Blos", "auf", "den", "nur", "mu\u00df", "man", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADV", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "der di\u00df Alles l\u00e4\u00dft geschehen.", "tokens": ["der", "di\u00df", "Al\u00b7les", "l\u00e4\u00dft", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "PIS", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Gott der pflegets so zu machen,", "tokens": ["Gott", "der", "pfle\u00b7gets", "so", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "rei\u00dft oft unser Liebstes hin", "tokens": ["rei\u00dft", "oft", "un\u00b7ser", "Liebs\u00b7tes", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und will sogestalter Sachen", "tokens": ["und", "will", "so\u00b7ge\u00b7stal\u00b7ter", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "uns ihm nach und zu sich ziehn,", "tokens": ["uns", "ihm", "nach", "und", "zu", "sich", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "APPR", "KON", "APPR", "PRF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "weil wir stets die Sinnen haben", "tokens": ["weil", "wir", "stets", "die", "Sin\u00b7nen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da, wo unser Schatz vergraben.", "tokens": ["da", ",", "wo", "un\u00b7ser", "Schatz", "ver\u00b7gra\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Tauret mich die frische Jugend,", "tokens": ["Tau\u00b7ret", "mich", "die", "fri\u00b7sche", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihrer Sch\u00f6nheit sondre Zier", "tokens": ["ih\u00b7rer", "Sch\u00f6n\u00b7heit", "sond\u00b7re", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und die nicht gemeine Tugend,", "tokens": ["und", "die", "nicht", "ge\u00b7mei\u00b7ne", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die so sch\u00f6ne schien herf\u00fcr,", "tokens": ["die", "so", "sch\u00f6\u00b7ne", "schien", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "so verge\u00dft auch nicht beineben,", "tokens": ["so", "ver\u00b7ge\u00dft", "auch", "nicht", "bei\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.6": {"text": "wie sie sind der Flucht ergeben!", "tokens": ["wie", "sie", "sind", "der", "Flucht", "er\u00b7ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Kaja w\u00e4re nicht verdorben,", "tokens": ["Ka\u00b7ja", "w\u00e4\u00b7re", "nicht", "ver\u00b7dor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wehrte Tugend letzter Not.", "tokens": ["wehr\u00b7te", "Tu\u00b7gend", "letz\u00b7ter", "Not", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Helene lebt' ungestorben,", "tokens": ["He\u00b7le\u00b7ne", "lebt'", "un\u00b7ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "h\u00fclfe Sch\u00f6nheit f\u00fcr den Tod.", "tokens": ["h\u00fcl\u00b7fe", "Sch\u00f6n\u00b7heit", "f\u00fcr", "den", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und was soll hier Sch\u00f6nheit t\u00fcgen?", "tokens": ["Und", "was", "soll", "hier", "Sch\u00f6n\u00b7heit", "t\u00fc\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie sagt selbst ihr Unvergn\u00fcgen.", "tokens": ["Sie", "sagt", "selbst", "ihr", "Un\u00b7ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Ie subtiler ausgeschm\u00fccket", "tokens": ["Ie", "sub\u00b7ti\u00b7ler", "aus\u00b7ge\u00b7schm\u00fc\u00b7cket"], "token_info": ["word", "word", "word"], "pos": ["NE", "NE", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "den beleibten Wind, sein Glas,", "tokens": ["den", "be\u00b7leib\u00b7ten", "Wind", ",", "sein", "Glas", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "uns Venedig \u00fcberschicket,", "tokens": ["uns", "Ve\u00b7ne\u00b7dig", "\u00fc\u00b7bersc\u00b7hi\u00b7cket", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NE", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "ie geschwinder bricht auch das;", "tokens": ["ie", "ge\u00b7schwin\u00b7der", "bricht", "auch", "das", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "PDS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und ie z\u00e4rter ist der Faden,", "tokens": ["und", "ie", "z\u00e4r\u00b7ter", "ist", "der", "Fa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ie behender nimmt er Schaden.", "tokens": ["ie", "be\u00b7hen\u00b7der", "nimmt", "er", "Scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wenn die keuschen Lilgen prangen", "tokens": ["Wenn", "die", "keu\u00b7schen", "Lil\u00b7gen", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und in h\u00f6chstem Schmucke stehn,", "tokens": ["und", "in", "h\u00f6chs\u00b7tem", "Schmu\u00b7cke", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "weil noch auf ihr' hellen Wangen", "tokens": ["weil", "noch", "auf", "ih\u00b7r'", "hel\u00b7len", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die gelinden Westen wehn,", "tokens": ["die", "ge\u00b7lin\u00b7den", "Wes\u00b7ten", "wehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sind sie frisch auch funden worden", "tokens": ["sind", "sie", "frisch", "auch", "fun\u00b7den", "wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "VVFIN", "VAPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gegen einen strengen Norden.", "tokens": ["ge\u00b7gen", "ei\u00b7nen", "stren\u00b7gen", "Nor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Kr\u00e4nket euch ihr pl\u00f6tzlichs Ende,", "tokens": ["Kr\u00e4n\u00b7ket", "euch", "ihr", "pl\u00f6tz\u00b7lichs", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df sie nicht gab gute Nacht,", "tokens": ["da\u00df", "sie", "nicht", "gab", "gu\u00b7te", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wer kan wider Gottes H\u00e4nde,", "tokens": ["wer", "kan", "wi\u00b7der", "Got\u00b7tes", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der ja alles gut sonst macht?", "tokens": ["der", "ja", "al\u00b7les", "gut", "sonst", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "ADJD", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ohne Pein ist sie verschieden;", "tokens": ["Oh\u00b7ne", "Pein", "ist", "sie", "ver\u00b7schie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das geschicht nicht einem Ieden.", "tokens": ["das", "ge\u00b7schicht", "nicht", "ei\u00b7nem", "Ie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Kein behender Tod ist b\u00f6se", "tokens": ["Kein", "be\u00b7hen\u00b7der", "Tod", "ist", "b\u00f6\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "als der auf die B\u00f6sen f\u00e4lt.", "tokens": ["als", "der", "auf", "die", "B\u00f6\u00b7sen", "f\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df auch uns Gott bald erl\u00f6se,", "tokens": ["Da\u00df", "auch", "uns", "Gott", "bald", "er\u00b7l\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ist der h\u00f6chste Wundsch der Welt.", "tokens": ["ist", "der", "h\u00f6chs\u00b7te", "Wund\u00b7sch", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "So vielmehr ist sie genesen,", "tokens": ["So", "viel\u00b7mehr", "ist", "sie", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "weil sie niemals krank gewesen.", "tokens": ["weil", "sie", "nie\u00b7mals", "krank", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Oder schmerzt euch ihr Erliegen", "tokens": ["O\u00b7der", "schmerzt", "euch", "ihr", "Er\u00b7lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und die Art des Todes mehr?", "tokens": ["und", "die", "Art", "des", "To\u00b7des", "mehr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seht doch, wie durch itzigs Kriegen", "tokens": ["Seht", "doch", ",", "wie", "durch", "it\u00b7zigs", "Krie\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "manche Stadt liegt tot und leer!", "tokens": ["man\u00b7che", "Stadt", "liegt", "tot", "und", "leer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und was ist ein Mensch zu nennen", "tokens": ["Und", "was", "ist", "ein", "Mensch", "zu", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gegen dem, das einst soll brennen?", "tokens": ["ge\u00b7gen", "dem", ",", "das", "einst", "soll", "bren\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Als sie noch am Eiteln klebte,", "tokens": ["Als", "sie", "noch", "am", "Ei\u00b7teln", "kleb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "war ihr Eitels nicht gemein.", "tokens": ["war", "ihr", "Ei\u00b7tels", "nicht", "ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Selig war sie, weil sie lebte;", "tokens": ["Se\u00b7lig", "war", "sie", ",", "weil", "sie", "leb\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "solte sie es itzt nicht sein?", "tokens": ["sol\u00b7te", "sie", "es", "itzt", "nicht", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PTKNEG", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Itzt, da sie nun ewig bleibet,", "tokens": ["Itzt", ",", "da", "sie", "nun", "e\u00b7wig", "blei\u00b7bet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo man seligs Leben treibet,", "tokens": ["wo", "man", "se\u00b7ligs", "Le\u00b7ben", "trei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "wo die gro\u00dfen ", "tokens": ["wo", "die", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "neben greiser Ewigkeit", "tokens": ["ne\u00b7ben", "grei\u00b7ser", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und in jener Zeit bestehen,", "tokens": ["und", "in", "je\u00b7ner", "Zeit", "be\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so doch kennet keine Zeit?", "tokens": ["so", "doch", "ken\u00b7net", "kei\u00b7ne", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "In die Scharen aller Frommen", "tokens": ["In", "die", "Scha\u00b7ren", "al\u00b7ler", "From\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ist sie herrlich eingenommen.", "tokens": ["ist", "sie", "herr\u00b7lich", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "La\u00dft Gott euren Sinn sich geben", "tokens": ["La\u00dft", "Gott", "eu\u00b7ren", "Sinn", "sich", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "NN", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und verwirrt euch nicht zu sehr!", "tokens": ["und", "ver\u00b7wirrt", "euch", "nicht", "zu", "sehr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "PTKA", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "G\u00f6nnet ihr das ander' Leben", "tokens": ["G\u00f6n\u00b7net", "ihr", "das", "an\u00b7der'", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und gedenkt um so viel mehr,", "tokens": ["und", "ge\u00b7denkt", "um", "so", "viel", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "weil Gott zweifach euch betr\u00fcbet,", "tokens": ["weil", "Gott", "zwei\u00b7fach", "euch", "be\u00b7tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df er euch auch zweifach liebet!", "tokens": ["da\u00df", "er", "euch", "auch", "zwei\u00b7fach", "lie\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}