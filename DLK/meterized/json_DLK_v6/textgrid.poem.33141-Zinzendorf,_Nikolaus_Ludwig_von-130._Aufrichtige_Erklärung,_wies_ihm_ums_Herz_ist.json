{"textgrid.poem.33141": {"metadata": {"author": {"name": "Zinzendorf, Nikolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "130. Aufrichtige Erkl\u00e4rung, wies ihm ums Herz ist", "genre": "verse", "period": "N.A.", "pub_year": 1730, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du unser auserwehltes Haupt,", "tokens": ["Du", "un\u00b7ser", "au\u00b7ser\u00b7wehl\u00b7tes", "Haupt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An welches unsre Seele glaubt!", "tokens": ["An", "wel\u00b7ches", "uns\u00b7re", "See\u00b7le", "glaubt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df uns in Deiner N\u00e4gel Maal", "tokens": ["La\u00df", "uns", "in", "Dei\u00b7ner", "N\u00e4\u00b7gel", "Maal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erblikken die Genaden-Wahl,", "tokens": ["Er\u00b7blik\u00b7ken", "die", "Ge\u00b7na\u00b7den\u00b7Wahl", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und durch der aufgespaltnen Seite Bahn", "tokens": ["Und", "durch", "der", "auf\u00b7ge\u00b7spalt\u00b7nen", "Sei\u00b7te", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "F\u00fchr unsre Seelen aus und durch und an.", "tokens": ["F\u00fchr", "uns\u00b7re", "See\u00b7len", "aus", "und", "durch", "und", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKVZ", "KON", "APPR", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Dis ist das wunder-volle Ding:", "tokens": ["Dis", "ist", "das", "wun\u00b7der\u00b7vol\u00b7le", "Ding", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erst d\u00fcnkts f\u00fcr Kinder zu gering;", "tokens": ["Erst", "d\u00fcnkts", "f\u00fcr", "Kin\u00b7der", "zu", "ge\u00b7ring", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dann zerglaubt ein Mann sich dran,", "tokens": ["Und", "dann", "zer\u00b7glaubt", "ein", "Mann", "sich", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PRF", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und stirbt wol, eh ers glauben kan,", "tokens": ["Und", "stirbt", "wol", ",", "eh", "ers", "glau\u00b7ben", "kan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es sind die Sephiroth am gl\u00e4sern Meer,", "tokens": ["Es", "sind", "die", "Se\u00b7phi\u00b7roth", "am", "gl\u00e4\u00b7sern", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Es ist das Schibboleth vom kleinen Heer.", "tokens": ["Es", "ist", "das", "Schib\u00b7bo\u00b7leth", "vom", "klei\u00b7nen", "Heer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Solange eine Menschheit ist,", "tokens": ["So\u00b7lan\u00b7ge", "ei\u00b7ne", "Menschheit", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Solange Jesus bleibt der Christ,", "tokens": ["So\u00b7lan\u00b7ge", "Je\u00b7sus", "bleibt", "der", "Christ", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So bleibet di\u00df das A und O", "tokens": ["So", "blei\u00b7bet", "di\u00df", "das", "A", "und", "O"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDS", "ART", "NE", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom ganzen Evangelio,", "tokens": ["Vom", "gan\u00b7zen", "E\u00b7van\u00b7ge\u00b7lio", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.5": {"text": "Und da\u00df dasselbige die Weisheit ist,", "tokens": ["Und", "da\u00df", "das\u00b7sel\u00b7bi\u00b7ge", "die", "Weis\u00b7heit", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das wi\u00dft ihr alle, die ihr Wahrheit wi\u00dft.", "tokens": ["Das", "wi\u00dft", "ihr", "al\u00b7le", ",", "die", "ihr", "Wahr\u00b7heit", "wi\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Mein Heiland! w\u00e4r ich armes Kind,", "tokens": ["Mein", "Hei\u00b7land", "!", "w\u00e4r", "ich", "ar\u00b7mes", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VAFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sich um Deine F\u00fcsse windt,", "tokens": ["Das", "sich", "um", "Dei\u00b7ne", "F\u00fcs\u00b7se", "windt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Dich, du Seelen-Ehemann,", "tokens": ["Das", "Dich", ",", "du", "See\u00b7len\u00b7E\u00b7he\u00b7mann", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PPER", "$,", "PPER", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Nicht eine Stunde missen kan,", "tokens": ["Nicht", "ei\u00b7ne", "Stun\u00b7de", "mis\u00b7sen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und das Dich \u00fcber sich und alles liebt,", "tokens": ["Und", "das", "Dich", "\u00fc\u00b7ber", "sich", "und", "al\u00b7les", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "APPR", "PRF", "KON", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "In Deiner Sprache etwas mehr ge\u00fcbt.", "tokens": ["In", "Dei\u00b7ner", "Spra\u00b7che", "et\u00b7was", "mehr", "ge\u00b7\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Doch la\u00df die Lippen trokken seyn,", "tokens": ["Doch", "la\u00df", "die", "Lip\u00b7pen", "trok\u00b7ken", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Geistes Hauch darf nur hinein,", "tokens": ["Des", "Geis\u00b7tes", "Hauch", "darf", "nur", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der vor dem Thron der Majest\u00e4t", "tokens": ["Der", "vor", "dem", "Thron", "der", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Donnern und Posaunen geht,", "tokens": ["In", "Don\u00b7nern", "und", "Po\u00b7sau\u00b7nen", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und eine Kohle vom Altar gebraucht,", "tokens": ["Und", "ei\u00b7ne", "Koh\u00b7le", "vom", "Al\u00b7tar", "ge\u00b7braucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So r\u00fchren sich die Lippen, da\u00df es raucht.", "tokens": ["So", "r\u00fch\u00b7ren", "sich", "die", "Lip\u00b7pen", ",", "da\u00df", "es", "raucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "So zeug ich dann, wer h\u00f6rt mir zu?", "tokens": ["So", "zeug", "ich", "dann", ",", "wer", "h\u00f6rt", "mir", "zu", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer hat im Herzen keine Ruh?", "tokens": ["Wer", "hat", "im", "Her\u00b7zen", "kei\u00b7ne", "Ruh", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPRART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer wei\u00df, wie tief die S\u00fcnde fri\u00dft,", "tokens": ["Wer", "wei\u00df", ",", "wie", "tief", "die", "S\u00fcn\u00b7de", "fri\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und da\u00df er nichts als S\u00fcnde ist,", "tokens": ["Und", "da\u00df", "er", "nichts", "als", "S\u00fcn\u00b7de", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "KOKOM", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wei\u00df sich keinen Rath, wo ein noch aus,", "tokens": ["Und", "wei\u00df", "sich", "kei\u00b7nen", "Rath", ",", "wo", "ein", "noch", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PIAT", "NN", "$,", "PWAV", "ART", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der h\u00f6re zu! denn da wird etwas draus.", "tokens": ["Der", "h\u00f6\u00b7re", "zu", "!", "denn", "da", "wird", "et\u00b7was", "draus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "$.", "KON", "ADV", "VAFIN", "PIS", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "Wer aber von der Mutter her", "tokens": ["Wer", "a\u00b7ber", "von", "der", "Mut\u00b7ter", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vielleicht noch unbescholten w\u00e4r,", "tokens": ["Viel\u00b7leicht", "noch", "un\u00b7be\u00b7schol\u00b7ten", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fc\u00dfte kaum was Fleisch und Blut,", "tokens": ["Und", "w\u00fc\u00df\u00b7te", "kaum", "was", "Fleisch", "und", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PWS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was Geitz sey oder hoher Muth,", "tokens": ["Was", "Geitz", "sey", "o\u00b7der", "ho\u00b7her", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sich in allem selber helfen kan,", "tokens": ["Und", "sich", "in", "al\u00b7lem", "sel\u00b7ber", "hel\u00b7fen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der ist ein blinder und ein tauber Mann.", "tokens": ["Der", "ist", "ein", "blin\u00b7der", "und", "ein", "tau\u00b7ber", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ein heiliger und reiner Geist,", "tokens": ["Ein", "hei\u00b7li\u00b7ger", "und", "rei\u00b7ner", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und was man einen Heilgen hei\u00dft,", "tokens": ["Und", "was", "man", "ei\u00b7nen", "Heil\u00b7gen", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind vor dem Herrn der Creatur,", "tokens": ["Sind", "vor", "dem", "Herrn", "der", "Crea\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Und vor dem Meister der Natur", "tokens": ["Und", "vor", "dem", "Meis\u00b7ter", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von keinem andern Zeuge, als ein Blat", "tokens": ["Von", "kei\u00b7nem", "an\u00b7dern", "Zeu\u00b7ge", ",", "als", "ein", "Blat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das auch sein Wesen von dem Sch\u00f6pfer hat.", "tokens": ["Das", "auch", "sein", "We\u00b7sen", "von", "dem", "Sch\u00f6p\u00b7fer", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Auch ist ein Rath der Ewigkeit", "tokens": ["Auch", "ist", "ein", "Rath", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel \u00e4lter als die graue Zeit,", "tokens": ["Viel", "\u00e4l\u00b7ter", "als", "die", "grau\u00b7e", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wer den Rathschlu\u00df meistern will,", "tokens": ["Und", "wer", "den", "Rath\u00b7schlu\u00df", "meis\u00b7tern", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df Satan seyn, sonst schweigt er still:", "tokens": ["Mu\u00df", "Sa\u00b7tan", "seyn", ",", "sonst", "schweigt", "er", "still", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VAINF", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein T\u00f6pfer macht aus einem allerley,", "tokens": ["Ein", "T\u00f6p\u00b7fer", "macht", "aus", "ei\u00b7nem", "al\u00b7ler\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "PIAT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und das ists, was er machet, da\u00df es sey.", "tokens": ["Und", "das", "ists", ",", "was", "er", "ma\u00b7chet", ",", "da\u00df", "es", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Das Leben ist von oben her,", "tokens": ["Das", "Le\u00b7ben", "ist", "von", "o\u00b7ben", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tod ist auch nicht ohngefehr,", "tokens": ["Der", "Tod", "ist", "auch", "nicht", "ohn\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Darzu verdammet das Gericht,", "tokens": ["Dar\u00b7zu", "ver\u00b7dam\u00b7met", "das", "Ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Herze Gottes aber nicht.", "tokens": ["Das", "Her\u00b7ze", "Got\u00b7tes", "a\u00b7ber", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer Gottes Wesen wei\u00df, wei\u00df Seinen Tod,", "tokens": ["Wer", "Got\u00b7tes", "We\u00b7sen", "wei\u00df", ",", "wei\u00df", "Sei\u00b7nen", "Tod", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "NN", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wers Herze kennt, der ist aus aller Noth.", "tokens": ["Wers", "Her\u00b7ze", "kennt", ",", "der", "ist", "aus", "al\u00b7ler", "Noth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVFIN", "$,", "PRELS", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Wir sehen wol die Geister nicht,", "tokens": ["Wir", "se\u00b7hen", "wol", "die", "Geis\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die erst die S\u00fcnde angericht't;", "tokens": ["Die", "erst", "die", "S\u00fcn\u00b7de", "an\u00b7ge\u00b7richt't", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch sehe sich nur jedermann,", "tokens": ["Doch", "se\u00b7he", "sich", "nur", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der bey sich selbst ist, selber an.", "tokens": ["Der", "bey", "sich", "selbst", "ist", ",", "sel\u00b7ber", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "PRF", "ADV", "VAFIN", "$,", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn keine S\u00fcnde in der Menschheit w\u00e4r,", "tokens": ["Wenn", "kei\u00b7ne", "S\u00fcn\u00b7de", "in", "der", "Menschheit", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wo h\u00e4tten ich und er die S\u00fcnde her?", "tokens": ["Wo", "h\u00e4t\u00b7ten", "ich", "und", "er", "die", "S\u00fcn\u00b7de", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "KON", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Wie weislich ist der Rath bestellt,", "tokens": ["Wie", "weis\u00b7lich", "ist", "der", "Rath", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Rath der W\u00e4chter aller Welt,", "tokens": ["Der", "Rath", "der", "W\u00e4ch\u00b7ter", "al\u00b7ler", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das meiste ist nicht offenbar,", "tokens": ["Das", "meis\u00b7te", "ist", "nicht", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und was man wei\u00df, ist Sonnen-klar,", "tokens": ["Und", "was", "man", "wei\u00df", ",", "ist", "Son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "VVFIN", "$,", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Thorheit fragt den Herrn: Was machest du:", "tokens": ["Die", "Thor\u00b7heit", "fragt", "den", "Herrn", ":", "Was", "ma\u00b7chest", "du", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Weisheit glaubt und denkt: Du Liebe Du!", "tokens": ["Die", "Weis\u00b7heit", "glaubt", "und", "denkt", ":", "Du", "Lie\u00b7be", "Du", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$.", "PPER", "NN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Gelobet sey das Lebens-Buch", "tokens": ["Ge\u00b7lo\u00b7bet", "sey", "das", "Le\u00b7bens\u00b7Buch"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor dem verh\u00fcllt in Mosis Tuch,", "tokens": ["Vor", "dem", "ver\u00b7h\u00fcllt", "in", "Mo\u00b7sis", "Tuch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit sieben Siegeln zugemacht,", "tokens": ["Mit", "sie\u00b7ben", "Sie\u00b7geln", "zu\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis man das Lamm herzugebracht,", "tokens": ["Bis", "man", "das", "Lamm", "her\u00b7zu\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Lamm, den Welt-bekanten S\u00fcnder-Freund,", "tokens": ["Das", "Lamm", ",", "den", "Welt\u00b7be\u00b7kan\u00b7ten", "S\u00fcn\u00b7der\u00b7Freund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der selbstgewachsnen Tugend ihren Feind.", "tokens": ["Der", "selbst\u00b7ge\u00b7wachs\u00b7nen", "Tu\u00b7gend", "ih\u00b7ren", "Feind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Das Wort, das an das Creutz gemahlt,", "tokens": ["Das", "Wort", ",", "das", "an", "das", "Creutz", "ge\u00b7mahlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Blut-Rubinen-Feuer strahlt,", "tokens": ["Im", "Blut\u00b7Ru\u00b7bi\u00b7nen\u00b7Feu\u00b7er", "strahlt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das hei\u00dft: Hier h\u00e4ngt Immanuel!", "tokens": ["Das", "hei\u00dft", ":", "Hier", "h\u00e4ngt", "Im\u00b7ma\u00b7nu\u00b7el", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "(das Gegenbild des Hazazel,)", "tokens": ["(", "das", "Ge\u00b7gen\u00b7bild", "des", "Ha\u00b7za\u00b7zel", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dar\u00fcber stutzt und fluchet die Natur,", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "stutzt", "und", "flu\u00b7chet", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und Gott betheuert es mit einem Schwur.", "tokens": ["Und", "Gott", "be\u00b7theu\u00b7ert", "es", "mit", "ei\u00b7nem", "Schwur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "So wahr ich lebe! spricht der Mann,", "tokens": ["So", "wahr", "ich", "le\u00b7be", "!", "spricht", "der", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der nichts als Amen sagen kan,", "tokens": ["Der", "nichts", "als", "A\u00b7men", "sa\u00b7gen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "KOKOM", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und der unfehlbar Wort und That", "tokens": ["Und", "der", "un\u00b7fehl\u00b7bar", "Wort", "und", "That"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJD", "NN", "KON", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Im Augenblik beysammen hat,", "tokens": ["Im", "Au\u00b7gen\u00b7blik", "bey\u00b7sam\u00b7men", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und was Er will, das l\u00e4\u00dft Er sich nicht reun;", "tokens": ["Und", "was", "Er", "will", ",", "das", "l\u00e4\u00dft", "Er", "sich", "nicht", "reun", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VMFIN", "$,", "PDS", "VVFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mein Sohn, mein Sohn soll Hoherpriester seyn!", "tokens": ["Mein", "Sohn", ",", "mein", "Sohn", "soll", "Ho\u00b7her\u00b7pries\u00b7ter", "seyn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VMFIN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Er kommt, der Sohn, Er sagts uns an,", "tokens": ["Er", "kommt", ",", "der", "Sohn", ",", "Er", "sagts", "uns", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wies mit dem Priester-Amt gethan:", "tokens": ["Wies", "mit", "dem", "Pries\u00b7ter\u00b7Amt", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Vater hat den Erben lieb;", "tokens": ["Der", "Va\u00b7ter", "hat", "den", "Er\u00b7ben", "lieb", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dazu kommt ein neuer Trieb,", "tokens": ["Und", "da\u00b7zu", "kommt", "ein", "neu\u00b7er", "Trieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ich den ew'gen Rath und Recht erf\u00fcll,", "tokens": ["Da\u00df", "ich", "den", "ew'\u00b7gen", "Rath", "und", "Recht", "er\u00b7f\u00fcll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und f\u00fcr der Menschen Leben sterben will.", "tokens": ["Und", "f\u00fcr", "der", "Men\u00b7schen", "Le\u00b7ben", "ster\u00b7ben", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Die Worte sind unleugbar da;", "tokens": ["Die", "Wor\u00b7te", "sind", "un\u00b7leug\u00b7bar", "da", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die That war denen Worten nah:", "tokens": ["Die", "That", "war", "de\u00b7nen", "Wor\u00b7ten", "nah", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PDS", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Probe, ob es Wahrheit ist,", "tokens": ["Die", "Pro\u00b7be", ",", "ob", "es", "Wahr\u00b7heit", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was man im Buch geschrieben liest,", "tokens": ["Was", "man", "im", "Buch", "ge\u00b7schrie\u00b7ben", "liest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPRART", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da spricht der grosse Gnaden-Bundes-Mann,", "tokens": ["Da", "spricht", "der", "gros\u00b7se", "Gna\u00b7den\u00b7Bun\u00b7des\u00b7Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df sie ein jeder selber machen kan.", "tokens": ["Da\u00df", "sie", "ein", "je\u00b7der", "sel\u00b7ber", "ma\u00b7chen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PIS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Man macht sie dann auf solche Art,", "tokens": ["Man", "macht", "sie", "dann", "auf", "sol\u00b7che", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sich im Herzen offenbart,", "tokens": ["Da\u00df", "sich", "im", "Her\u00b7zen", "of\u00b7fen\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob Jesus Christus, Gottes Lamm,", "tokens": ["Ob", "Je\u00b7sus", "Chris\u00b7tus", ",", "Got\u00b7tes", "Lamm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wahrhaftig starb am Creutzes-Stamm.", "tokens": ["Wahr\u00b7haf\u00b7tig", "starb", "am", "Creut\u00b7zes\u00b7Stamm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Art der Probe theilt sich \u00fcberaus,", "tokens": ["Die", "Art", "der", "Pro\u00b7be", "theilt", "sich", "\u00fc\u00b7be\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Probe aber lauft auf eins hinaus.", "tokens": ["Die", "Pro\u00b7be", "a\u00b7ber", "lauft", "auf", "eins", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Wenn einer in dem Glanz des Lichts", "tokens": ["Wenn", "ei\u00b7ner", "in", "dem", "Glanz", "des", "Lichts"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich sieht, und sieht, er tauge nichts,", "tokens": ["Sich", "sieht", ",", "und", "sieht", ",", "er", "tau\u00b7ge", "nichts", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "KON", "VVFIN", "$,", "PPER", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und geht und greifft die Sache an,", "tokens": ["Und", "geht", "und", "greifft", "die", "Sa\u00b7che", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und thut nicht, was er sonst gethan,", "tokens": ["Und", "thut", "nicht", ",", "was", "er", "sonst", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und m\u00fcht sich selber viel und mancherley,", "tokens": ["Und", "m\u00fcht", "sich", "sel\u00b7ber", "viel", "und", "man\u00b7cher\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV", "KON", "PIS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der lernet nie, was ein Erl\u00f6ser sey.", "tokens": ["Der", "ler\u00b7net", "nie", ",", "was", "ein", "Er\u00b7l\u00f6\u00b7ser", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$,", "PRELS", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Wenn aber ein verlornes Kind", "tokens": ["Wenn", "a\u00b7ber", "ein", "ver\u00b7lor\u00b7nes", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Tod erwacht, sich kr\u00fcmmt und windt,", "tokens": ["Vom", "Tod", "er\u00b7wacht", ",", "sich", "kr\u00fcmmt", "und", "windt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "PRF", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sieht das B\u00f6se b\u00f6se an,", "tokens": ["Und", "sieht", "das", "B\u00f6\u00b7se", "b\u00f6\u00b7se", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und glaubet, da\u00df es sonst nichts kan,", "tokens": ["Und", "glau\u00b7bet", ",", "da\u00df", "es", "sonst", "nichts", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "PIS", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verzagt an sich, es geht ihm aber nah;", "tokens": ["Ver\u00b7zagt", "an", "sich", ",", "es", "geht", "ihm", "a\u00b7ber", "nah", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PRF", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Kaum sieht sichs um, so steht der Heiland da.", "tokens": ["Kaum", "sieht", "sichs", "um", ",", "so", "steht", "der", "Hei\u00b7land", "da", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Wie geht dirs? O es geht nicht gut!", "tokens": ["Wie", "geht", "dirs", "?", "O", "es", "geht", "nicht", "gut", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "$.", "NE", "PPER", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich liege hie in meinem Blut.", "tokens": ["Ich", "lie\u00b7ge", "hie", "in", "mei\u00b7nem", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da spricht der Seelen-Freund: Mein Sohn!", "tokens": ["Da", "spricht", "der", "See\u00b7len\u00b7Freund", ":", "Mein", "Sohn", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nim hin die Absolution,", "tokens": ["Nim", "hin", "die", "Ab\u00b7so\u00b7lu\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sieh mich an, und glaub, und stehe auf,", "tokens": ["Und", "sieh", "mich", "an", ",", "und", "glaub", ",", "und", "ste\u00b7he", "auf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "$,", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und freue dich, und zieh dich an, und lauf.", "tokens": ["Und", "freu\u00b7e", "dich", ",", "und", "zieh", "dich", "an", ",", "und", "lauf", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KON", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Die Seele krigt den neuen Geist,", "tokens": ["Die", "See\u00b7le", "krigt", "den", "neu\u00b7en", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie glaubt und thut, was Jesus hei\u00dft,", "tokens": ["Sie", "glaubt", "und", "thut", ",", "was", "Je\u00b7sus", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "PRELS", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sieht das Lamm mit Augen an,", "tokens": ["Sie", "sieht", "das", "Lamm", "mit", "Au\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die kein Erfahrnes leugnen kan;", "tokens": ["Die", "kein", "Er\u00b7fahr\u00b7nes", "leug\u00b7nen", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Steht auf, bekommt ein unsichtbar Gewand,", "tokens": ["Steht", "auf", ",", "be\u00b7kommt", "ein", "un\u00b7sicht\u00b7bar", "Ge\u00b7wand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ist auf einmal mit dem Lamm bekant.", "tokens": ["Und", "ist", "auf", "ein\u00b7mal", "mit", "dem", "Lamm", "be\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ADV", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Die Schaam, die Beugung und die Kraft,", "tokens": ["Die", "Schaam", ",", "die", "Beu\u00b7gung", "und", "die", "Kraft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die machen gleichsam Schwesterschaft,", "tokens": ["Die", "ma\u00b7chen", "gleich\u00b7sam", "Schwes\u00b7ter\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schliessen sich ins Herze ein,", "tokens": ["Und", "schlies\u00b7sen", "sich", "ins", "Her\u00b7ze", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPRART", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wollen nicht getrennet seyn;", "tokens": ["Und", "wol\u00b7len", "nicht", "ge\u00b7tren\u00b7net", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da geht kein guter Wille mehr zur\u00fck,", "tokens": ["Da", "geht", "kein", "gu\u00b7ter", "Wil\u00b7le", "mehr", "zu\u00b7r\u00fck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Denn ihre Arbeit ist ein ewigs Gl\u00fck.", "tokens": ["Denn", "ih\u00b7re", "Ar\u00b7beit", "ist", "ein", "e\u00b7wigs", "Gl\u00fck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Erst hei\u00dft der Freund die Seele ruhn,", "tokens": ["Erst", "hei\u00dft", "der", "Freund", "die", "See\u00b7le", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann essen, und darnach was thun;", "tokens": ["Dann", "es\u00b7sen", ",", "und", "dar\u00b7nach", "was", "thun", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "KON", "PAV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da steiffet sie die Glaubens-Kraft", "tokens": ["Da", "steif\u00b7fet", "sie", "die", "Glau\u00b7bens\u00b7Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einer treuen Ritterschaft;", "tokens": ["Zu", "ei\u00b7ner", "treu\u00b7en", "Rit\u00b7ter\u00b7schaft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie thut, und wenn sie dann ihr Werk gethan,", "tokens": ["Sie", "thut", ",", "und", "wenn", "sie", "dann", "ihr", "Werk", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Denkt sie gemeiniglich nicht weiter dran.", "tokens": ["Denkt", "sie", "ge\u00b7mei\u00b7nig\u00b7lich", "nicht", "wei\u00b7ter", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Und w\u00fcrde sie ja irgendwo", "tokens": ["Und", "w\u00fcr\u00b7de", "sie", "ja", "ir\u00b7gend\u00b7wo"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der eignen Gnaden-Arbeit froh,", "tokens": ["Der", "eig\u00b7nen", "Gna\u00b7den\u00b7A\u00b7rbeit", "froh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So kommt die heilge Schaam herbey", "tokens": ["So", "kommt", "die", "heil\u00b7ge", "Schaam", "her\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zeiget ihr so mancherley,", "tokens": ["Und", "zei\u00b7get", "ihr", "so", "man\u00b7cher\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df sie Gott dankt, wenn sie sich selbst vergi\u00dft,", "tokens": ["Da\u00df", "sie", "Gott", "dankt", ",", "wenn", "sie", "sich", "selbst", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$,", "KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und denkt an nichts, als da\u00df ein Heiland ist.", "tokens": ["Und", "denkt", "an", "nichts", ",", "als", "da\u00df", "ein", "Hei\u00b7land", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIS", "$,", "KOKOM", "KOUS", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Und allenthalben steht der Sinn", "tokens": ["Und", "al\u00b7len\u00b7thal\u00b7ben", "steht", "der", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Gl\u00e4ubigen zur Gnade hin,", "tokens": ["Der", "Gl\u00e4u\u00b7bi\u00b7gen", "zur", "Gna\u00b7de", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sinnet, wie er Nacht und Tag", "tokens": ["Und", "sin\u00b7net", ",", "wie", "er", "Nacht", "und", "Tag"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Br\u00e4utigam gefallen mag,", "tokens": ["Dem", "Br\u00e4u\u00b7ti\u00b7gam", "ge\u00b7fal\u00b7len", "mag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der ihn von dem Verderben los gemacht,", "tokens": ["Der", "ihn", "von", "dem", "Ver\u00b7der\u00b7ben", "los", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und sichtbarlich zu Kron und Thron gebracht.", "tokens": ["Und", "sicht\u00b7bar\u00b7lich", "zu", "Kron", "und", "Thron", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NE", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Herr Jesu! wenn der Zeugen Heer", "tokens": ["Herr", "Je\u00b7su", "!", "wenn", "der", "Zeu\u00b7gen", "Heer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$.", "KOUS", "ART", "NN", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Nicht eine Donner-Wolke w\u00e4r,", "tokens": ["Nicht", "ei\u00b7ne", "Don\u00b7ner\u00b7Wol\u00b7ke", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So k\u00f6nte man es noch verstehn,", "tokens": ["So", "k\u00f6n\u00b7te", "man", "es", "noch", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df viele sie nicht h\u00f6rn und sehn.", "tokens": ["Da\u00df", "vie\u00b7le", "sie", "nicht", "h\u00f6rn", "und", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "PTKNEG", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch, was ists endlich Wunder? denn es sind", "tokens": ["Doch", ",", "was", "ists", "end\u00b7lich", "Wun\u00b7der", "?", "denn", "es", "sind"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "PWS", "VAFIN", "ADV", "NN", "$.", "KON", "PPER", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Menschen von Natur get\u00e4ubt und blind.", "tokens": ["Die", "Men\u00b7schen", "von", "Na\u00b7tur", "ge\u00b7t\u00e4ubt", "und", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Darum befiehlt uns Jesus nun", "tokens": ["Da\u00b7rum", "be\u00b7fiehlt", "uns", "Je\u00b7sus", "nun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Blinden Augen aufzuthun;", "tokens": ["Der", "Blin\u00b7den", "Au\u00b7gen", "auf\u00b7zu\u00b7thun", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wenn wir rufen, ist Er da,", "tokens": ["Und", "wenn", "wir", "ru\u00b7fen", ",", "ist", "Er", "da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ruft dem Tauben: Hephathah!", "tokens": ["Und", "ruft", "dem", "Tau\u00b7ben", ":", "He\u00b7phat\u00b7hah", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$.", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wird das Evangelium geh\u00f6rt,", "tokens": ["So", "wird", "das", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So wird das Auge auf das Lamm gekehrt.", "tokens": ["So", "wird", "das", "Au\u00b7ge", "auf", "das", "Lamm", "ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Da bin ich auch, Dein Unterthan,", "tokens": ["Da", "bin", "ich", "auch", ",", "Dein", "Un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und melde meine Gaben an,", "tokens": ["Und", "mel\u00b7de", "mei\u00b7ne", "Ga\u00b7ben", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Du mir Armen mitgetheilt;", "tokens": ["Die", "Du", "mir", "Ar\u00b7men", "mit\u00b7ge\u00b7theilt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seitdem Dein Pfeil mein Herz ereilt.", "tokens": ["Seit\u00b7dem", "Dein", "Pfeil", "mein", "Herz", "er\u00b7eilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun s\u00e4h ich gern ein gutes Theil der Welt", "tokens": ["Nun", "s\u00e4h", "ich", "gern", "ein", "gu\u00b7tes", "Theil", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Gerettet und zur Rechten hingestellt.", "tokens": ["Ge\u00b7ret\u00b7tet", "und", "zur", "Rech\u00b7ten", "hin\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Wenn mich der Haus-Herr Boten schikt;", "tokens": ["Wenn", "mich", "der", "Haus\u00b7Herr", "Bo\u00b7ten", "schikt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So halt ich mich f\u00fcr h\u00f6chst-begl\u00fckt.", "tokens": ["So", "halt", "ich", "mich", "f\u00fcr", "h\u00f6chst\u00b7be\u00b7gl\u00fc\u00b7kt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O! unser allgemeines Haupt", "tokens": ["O", "!", "un\u00b7ser", "all\u00b7ge\u00b7mei\u00b7nes", "Haupt"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gib, da\u00df man meiner Botschaft glaubt;", "tokens": ["Gib", ",", "da\u00df", "man", "mei\u00b7ner", "Bot\u00b7schaft", "glaubt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Rufen dring in Herz und Ohren ein,", "tokens": ["Mein", "Ru\u00b7fen", "dring", "in", "Herz", "und", "Oh\u00b7ren", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und wenn ich auf Dich weise: So erschein.", "tokens": ["Und", "wenn", "ich", "auf", "Dich", "wei\u00b7se", ":", "So", "er\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$.", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}