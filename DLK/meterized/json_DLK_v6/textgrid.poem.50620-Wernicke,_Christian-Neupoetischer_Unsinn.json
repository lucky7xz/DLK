{"textgrid.poem.50620": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Neupoetischer Unsinn", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Artemon hat gelernt, an mehr als einem Ort'", "tokens": ["Ar\u00b7te\u00b7mon", "hat", "ge\u00b7lernt", ",", "an", "mehr", "als", "ei\u00b7nem", "Ort'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "VVPP", "$,", "APPR", "PIAT", "KOKOM", "ART", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ein unverst\u00e4ndlich Nichts durch aufgeblas'ne Wort'", "tokens": ["Ein", "un\u00b7ver\u00b7st\u00e4nd\u00b7lich", "Nichts", "durch", "auf\u00b7ge\u00b7blas'\u00b7ne", "Wort'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In wohlgez\u00e4hlte Reim' ohn' allen Zwang zu bringen;", "tokens": ["In", "wohl\u00b7ge\u00b7z\u00e4hl\u00b7te", "Reim'", "ohn'", "al\u00b7len", "Zwang", "zu", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In jedem Abschnitt h\u00f6rt man klingen:", "tokens": ["In", "je\u00b7dem", "Ab\u00b7schnitt", "h\u00f6rt", "man", "klin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.6": {"text": "Die sich in Unverstand verschanzen", "tokens": ["Die", "sich", "in", "Un\u00b7ver\u00b7stand", "ver\u00b7schan\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und in geschlo\u00dfner Reihe tanzen.", "tokens": ["Und", "in", "ge\u00b7schlo\u00df\u00b7ner", "Rei\u00b7he", "tan\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zwar les' ich selten sie vom Anfang bis an's Ende;", "tokens": ["Zwar", "les'", "ich", "sel\u00b7ten", "sie", "vom", "An\u00b7fang", "bis", "an's", "En\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "PPER", "APPRART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch klopf' ich lachend in die H\u00e4nde", "tokens": ["Doch", "klopf'", "ich", "la\u00b7chend", "in", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und denk': es sind nicht schlechte Sachen,", "tokens": ["Und", "denk'", ":", "es", "sind", "nicht", "schlech\u00b7te", "Sa\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VAFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Aus ", "tokens": ["Aus"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}}}}