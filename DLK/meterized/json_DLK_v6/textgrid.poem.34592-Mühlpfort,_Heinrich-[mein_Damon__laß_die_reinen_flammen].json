{"textgrid.poem.34592": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "[mein Damon / la\u00df die reinen flammen]", "genre": "verse", "period": "N.A.", "pub_year": 1660, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Damon / la\u00df die reinen flammen", "tokens": ["Mein", "Da\u00b7mon", "/", "la\u00df", "die", "rei\u00b7nen", "flam\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "VVIMP", "ART", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht laulicht und getheilet seyn.", "tokens": ["Nicht", "lau\u00b7licht", "und", "ge\u00b7thei\u00b7let", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "KON", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nichts bessers schicket sich zusammen /", "tokens": ["Nichts", "bes\u00b7sers", "schi\u00b7cket", "sich", "zu\u00b7sam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "PRF", "PTKVZ", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als guter grunf und gleicher schein.", "tokens": ["Als", "gu\u00b7ter", "grunf", "und", "glei\u00b7cher", "schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was ist das lieben?", "tokens": ["Was", "ist", "das", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Ein Spiel der zeit /", "tokens": ["Ein", "Spiel", "der", "zeit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wo man soll \u00fcben /", "tokens": ["Wo", "man", "soll", "\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VMFIN", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Bey noth und leyd /", "tokens": ["Bey", "noth", "und", "leyd", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Best\u00e4ndigkeit.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig\u00b7keit", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Nicht z\u00fcrne / da\u00df ich so gesungen /", "tokens": ["Nicht", "z\u00fcr\u00b7ne", "/", "da\u00df", "ich", "so", "ge\u00b7sun\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$(", "KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein hertze / das von liebe qvill't /", "tokens": ["Ein", "hert\u00b7ze", "/", "das", "von", "lie\u00b7be", "qvill't", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird leichtlich mit verdacht beschwungen /", "tokens": ["Wird", "leicht\u00b7lich", "mit", "ver\u00b7dacht", "be\u00b7schwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und mit der bleichen furcht erf\u00fcll't.", "tokens": ["Und", "mit", "der", "blei\u00b7chen", "furcht", "er\u00b7f\u00fcll'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bey lichten steinen", "tokens": ["Bey", "lich\u00b7ten", "stei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "VVINF"], "meter": "---+-", "measure": "unknown.measure.single"}, "line.6": {"text": "Liegt kein verdacht;", "tokens": ["Liegt", "kein", "ver\u00b7dacht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Bey ungemeinen", "tokens": ["Bey", "un\u00b7ge\u00b7mei\u00b7nen"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Wird tag und nacht", "tokens": ["Wird", "tag", "und", "nacht"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Mit flei\u00df gewacht.", "tokens": ["Mit", "flei\u00df", "ge\u00b7wacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Hielt Aetna nicht so lange feuer /", "tokens": ["Hielt", "A\u00b7et\u00b7na", "nicht", "so", "lan\u00b7ge", "feu\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Es kenn't ihn nicht die gantze welt;", "tokens": ["Es", "kenn't", "ihn", "nicht", "die", "gant\u00b7ze", "welt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der s\u00e4ulen sch\u00f6nes ungeheuer /", "tokens": ["Der", "s\u00e4u\u00b7len", "sch\u00f6\u00b7nes", "un\u00b7ge\u00b7heu\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So Rom in ihrem scho\u00df\u00df erh\u00e4lt /", "tokens": ["So", "Rom", "in", "ih\u00b7rem", "scho\u00df\u00df", "er\u00b7h\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird itzt geehret /", "tokens": ["Wird", "itzt", "ge\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Weil keine macht", "tokens": ["Weil", "kei\u00b7ne", "macht"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIAT", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Es hat zerst\u00f6ret /", "tokens": ["Es", "hat", "zer\u00b7st\u00f6\u00b7ret", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und dessen pracht", "tokens": ["Und", "des\u00b7sen", "pracht"], "token_info": ["word", "word", "word"], "pos": ["KON", "PDS", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Nicht umgebracht.", "tokens": ["Nicht", "um\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Mein Damon / wilt du mich nicht h\u00f6ren /", "tokens": ["Mein", "Da\u00b7mon", "/", "wilt", "du", "mich", "nicht", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So schau auff s\u00e4ulen / berg und stein /", "tokens": ["So", "schau", "auff", "s\u00e4u\u00b7len", "/", "berg", "und", "stein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "VVINF", "$(", "NE", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df dich durch ihre wercke lehren /", "tokens": ["La\u00df", "dich", "durch", "ih\u00b7re", "wer\u00b7cke", "leh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df sie die stummen meister seyn.", "tokens": ["La\u00df", "sie", "die", "stum\u00b7men", "meis\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Blick / wort und schertzen", "tokens": ["Blick", "/", "wort", "und", "schert\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "KON", "VVINF"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Erbauet nicht /", "tokens": ["Er\u00b7bau\u00b7et", "nicht", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wenn unsern hertzen", "tokens": ["Wenn", "un\u00b7sern", "hert\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Das gleiche licht /", "tokens": ["Das", "glei\u00b7che", "licht", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Bestand / gebricht.", "tokens": ["Be\u00b7stand", "/", "ge\u00b7bricht", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Die blumen werden zwar gepriesen /", "tokens": ["Die", "blu\u00b7men", "wer\u00b7den", "zwar", "ge\u00b7prie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch w\u00fcrd' ihr name h\u00f6her gehn /", "tokens": ["Doch", "w\u00fcrd'", "ihr", "na\u00b7me", "h\u00f6\u00b7her", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn sie in g\u00e4rten und auff wiesen", "tokens": ["Wenn", "sie", "in", "g\u00e4r\u00b7ten", "und", "auff", "wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "KON", "APPR", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem winter k\u00f6nten widerstehn.", "tokens": ["Dem", "win\u00b7ter", "k\u00f6n\u00b7ten", "wi\u00b7der\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gla\u00df und crystallen", "tokens": ["Gla\u00df", "und", "crys\u00b7tal\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Ehrt iedes land /", "tokens": ["Ehrt", "ie\u00b7des", "land", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Doch ziert vor allen", "tokens": ["Doch", "ziert", "vor", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Der grossen hand", "tokens": ["Der", "gros\u00b7sen", "hand"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Ein Diamant.", "tokens": ["Ein", "Di\u00b7a\u00b7mant", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Der zierrath / den die liebe tr\u00e4get /", "tokens": ["Der", "zier\u00b7rath", "/", "den", "die", "lie\u00b7be", "tr\u00e4\u00b7get", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist reuer geist / und gleicher sinn /", "tokens": ["Ist", "reu\u00b7er", "geist", "/", "und", "glei\u00b7cher", "sinn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den purpur / den sie um sich leget /", "tokens": ["Den", "pur\u00b7pur", "/", "den", "sie", "um", "sich", "le\u00b7get", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$(", "ART", "PPER", "APPR", "PRF", "VVFIN", "$("], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sticht keine heisse sonne hin.", "tokens": ["Sticht", "kei\u00b7ne", "heis\u00b7se", "son\u00b7ne", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer gleiche liebet", "tokens": ["Wer", "glei\u00b7che", "lie\u00b7bet"], "token_info": ["word", "word", "word"], "pos": ["PWS", "ADJA", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "In freud und noth /", "tokens": ["In", "freud", "und", "noth", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und zeichen giebet", "tokens": ["Und", "zei\u00b7chen", "gie\u00b7bet"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Bis in den tod /", "tokens": ["Bis", "in", "den", "tod", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Ist fast ein gott.", "tokens": ["Ist", "fast", "ein", "gott", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}