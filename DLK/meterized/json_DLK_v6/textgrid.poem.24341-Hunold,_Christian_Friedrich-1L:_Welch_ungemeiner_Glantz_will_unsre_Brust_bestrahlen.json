{"textgrid.poem.24341": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Welch ungemeiner Glantz will unsre Brust bestrahlen/", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Welch ungemeiner Glantz will unsre Brust bestrahlen/", "tokens": ["Welch", "un\u00b7ge\u00b7mei\u00b7ner", "Glantz", "will", "uns\u00b7re", "Brust", "be\u00b7strah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Welch Sonnen-reines Licht mag unsre Felder mahlen/", "tokens": ["Welch", "Son\u00b7nen\u00b7rei\u00b7nes", "Licht", "mag", "uns\u00b7re", "Fel\u00b7der", "mah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und f\u00fcllt durch seinen Schein das Chur- und F\u00fcrsten-Hau\u00df!", "tokens": ["Und", "f\u00fcllt", "durch", "sei\u00b7nen", "Schein", "das", "Chur", "und", "F\u00fcrs\u00b7ten\u00b7Hau\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So rief Hanover jetzt mit seinen Landen aus.", "tokens": ["So", "rief", "Ha\u00b7no\u00b7ver", "jetzt", "mit", "sei\u00b7nen", "Lan\u00b7den", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie? sprach die Tugend drauf/ die mit zur\u00fcck gekommen/", "tokens": ["Wie", "?", "sprach", "die", "Tu\u00b7gend", "drauf", "/", "die", "mit", "zu\u00b7r\u00fcck", "ge\u00b7kom\u00b7men", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "ART", "NN", "PTKVZ", "$(", "ART", "APPR", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist dein Erlauchter Held dir aus der Brust genommen/", "tokens": ["Ist", "dein", "Er\u00b7lauch\u00b7ter", "Held", "dir", "aus", "der", "Brust", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "PPER", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da Ihn des Reiches Noth aus deinen Augen trennt?", "tokens": ["Da", "Ihn", "des", "Rei\u00b7ches", "Noth", "aus", "dei\u00b7nen", "Au\u00b7gen", "trennt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nein/ nur die Freude fragt/ die keines gleichen kennt.", "tokens": ["Nein", "/", "nur", "die", "Freu\u00b7de", "fragt", "/", "die", "kei\u00b7nes", "glei\u00b7chen", "kennt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "ART", "NN", "VVFIN", "$(", "ART", "PIAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Freude wei\u00df sich nicht vollkommen auszulassen/", "tokens": ["Die", "Freu\u00b7de", "wei\u00df", "sich", "nicht", "voll\u00b7kom\u00b7men", "aus\u00b7zu\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKNEG", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Augen/ Scho\u00df und Land den F\u00fcrsten einzufassen/", "tokens": ["In", "Au\u00b7gen", "/", "Scho\u00df", "und", "Land", "den", "F\u00fcrs\u00b7ten", "ein\u00b7zu\u00b7fas\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der dich zu reicher Lust und h\u00f6chstem Ruhm gebracht/", "tokens": ["Der", "dich", "zu", "rei\u00b7cher", "Lust", "und", "h\u00f6chs\u00b7tem", "Ruhm", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKA", "ADJD", "NN", "KON", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und als ein Salomon vor deine Ruhe wacht.", "tokens": ["Und", "als", "ein", "Sa\u00b7lo\u00b7mon", "vor", "dei\u00b7ne", "Ru\u00b7he", "wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Di\u00df ist/ begl\u00fccktes Land/ der Chur-F\u00fcrst von den Welfen/", "tokens": ["Di\u00df", "ist", "/", "be\u00b7gl\u00fcck\u00b7tes", "Land", "/", "der", "Chur\u00b7F\u00fcrst", "von", "den", "Wel\u00b7fen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "ADJA", "NN", "$(", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So dir zu allem kan durch Seine Klugheit helffen;", "tokens": ["So", "dir", "zu", "al\u00b7lem", "kan", "durch", "Sei\u00b7ne", "Klug\u00b7heit", "helf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PIS", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er h\u00e4lt den Feind zur\u00fcck/ denn kommt Er/ da\u00df Er sieht/", "tokens": ["Er", "h\u00e4lt", "den", "Feind", "zu\u00b7r\u00fcck", "/", "denn", "kommt", "Er", "/", "da\u00df", "Er", "sieht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$(", "KON", "VVFIN", "PPER", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob noch die g\u00fcldne Zeit in seinen Landen bl\u00fcth.", "tokens": ["Ob", "noch", "die", "g\u00fcld\u00b7ne", "Zeit", "in", "sei\u00b7nen", "Lan\u00b7den", "bl\u00fcth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Komm/ Gro\u00dfer F\u00fcrst und Herr/ betrachte diese Gaben/", "tokens": ["Komm", "/", "Gro\u00b7\u00dfer", "F\u00fcrst", "und", "Herr", "/", "be\u00b7trach\u00b7te", "die\u00b7se", "Ga\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "ADJA", "NN", "KON", "NN", "$(", "VVFIN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die wir von deiner Hand und weisen Anstalt haben.", "tokens": ["Die", "wir", "von", "dei\u00b7ner", "Hand", "und", "wei\u00b7sen", "An\u00b7stalt", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vernim/ wie sich dein Lob in allen St\u00fccken zeigt/", "tokens": ["Ver\u00b7nim", "/", "wie", "sich", "dein", "Lob", "in", "al\u00b7len", "St\u00fc\u00b7cken", "zeigt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PWAV", "PRF", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das weder Berg noch Thal/ noch Land und Stadt verschweigt", "tokens": ["Das", "we\u00b7der", "Berg", "noch", "Thal", "/", "noch", "Land", "und", "Stadt", "ver\u00b7schweigt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "KON", "NN", "ADV", "NN", "$(", "ADV", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Berge sind begl\u00fcckt/ und mehr als ", "tokens": ["Die", "Ber\u00b7ge", "sind", "be\u00b7gl\u00fcckt", "/", "und", "mehr", "als"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "KON", "PIAT", "KOKOM"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ob gleich die Musen da mit ihren Liedern stehen:", "tokens": ["Ob", "gleich", "die", "Mu\u00b7sen", "da", "mit", "ih\u00b7ren", "Lie\u00b7dern", "ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil man den Uberflu\u00df (davon die Muse lebt", "tokens": ["Weil", "man", "den", "U\u00b7ber\u00b7flu\u00df", "(", "da\u00b7von", "die", "Mu\u00b7se", "lebt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "NN", "$(", "PAV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der/ so sie besch\u00fctzt) in ihren Kl\u00fcfften gr\u00e4bt.", "tokens": ["Und", "der", "/", "so", "sie", "be\u00b7sch\u00fctzt", ")", "in", "ih\u00b7ren", "Kl\u00fcff\u00b7ten", "gr\u00e4bt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$(", "ADV", "PPER", "VVPP", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Die Th\u00e4ler bl\u00fchen auch von angenehmer Weide;", "tokens": ["Die", "Th\u00e4\u00b7ler", "bl\u00fc\u00b7hen", "auch", "von", "an\u00b7ge\u00b7neh\u00b7mer", "Wei\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Wild bewohnt den Wald; das Feld tr\u00e4gt sein Getr\u00e4yde;", "tokens": ["Das", "Wild", "be\u00b7wohnt", "den", "Wald", ";", "das", "Feld", "tr\u00e4gt", "sein", "Ge\u00b7tr\u00e4y\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Brunnen geben Saltz; die Weser ist beschifft,", "tokens": ["Die", "Brun\u00b7nen", "ge\u00b7ben", "Saltz", ";", "die", "We\u00b7ser", "ist", "be\u00b7schifft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "NN", "$.", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man sieht/ da\u00df alles hier des Himmels Seegen trifft.", "tokens": ["Man", "sieht", "/", "da\u00df", "al\u00b7les", "hier", "des", "Him\u00b7mels", "See\u00b7gen", "trifft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "KOUS", "PIS", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Die Ruhe macht/ da\u00df man kan sein Gewerbe treiben.", "tokens": ["Die", "Ru\u00b7he", "macht", "/", "da\u00df", "man", "kan", "sein", "Ge\u00b7wer\u00b7be", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "KOUS", "PIS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und diese Ruhe w\u00e4chst/ weil deine Klugheit bl\u00fcth/", "tokens": ["Und", "die\u00b7se", "Ru\u00b7he", "w\u00e4chst", "/", "weil", "dei\u00b7ne", "Klug\u00b7heit", "bl\u00fcth", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "$(", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und auf Magneten Art die Wohlfarth an sich zieht.", "tokens": ["Und", "auf", "Mag\u00b7ne\u00b7ten", "Art", "die", "Wohl\u00b7farth", "an", "sich", "zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.9": {"line.1": {"text": "Da\u00df er dir auch den Weg zur Ewigkeit gewiesen.", "tokens": ["Da\u00df", "er", "dir", "auch", "den", "Weg", "zur", "E\u00b7wig\u00b7keit", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wahr ist es/ was dein Hau\u00df/ dein Helden Hau\u00df gethan/", "tokens": ["Wahr", "ist", "es", "/", "was", "dein", "Hau\u00df", "/", "dein", "Hel\u00b7den", "Hau\u00df", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$(", "PWS", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein unerschrockner Muth/ das schreibt man ewig an.", "tokens": ["Dein", "un\u00b7er\u00b7schrock\u00b7ner", "Muth", "/", "das", "schreibt", "man", "e\u00b7wig", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "PDS", "VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Allein/ das ist vielmehr: Wenn deine gro\u00dfe G\u00fcte/", "tokens": ["Al\u00b7lein", "/", "das", "ist", "viel\u00b7mehr", ":", "Wenn", "dei\u00b7ne", "gro\u00b7\u00dfe", "G\u00fc\u00b7te", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PDS", "VAFIN", "ADV", "$.", "KOUS", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein allzeit kluger Rath/ Dein v\u00e4terlich Gem\u00fcthe/", "tokens": ["Dein", "all\u00b7zeit", "klu\u00b7ger", "Rath", "/", "Dein", "v\u00e4\u00b7ter\u00b7lich", "Ge\u00b7m\u00fc\u00b7the", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "$(", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und was sonst unsern Staat vor anderen erhebt/", "tokens": ["Und", "was", "sonst", "un\u00b7sern", "Staat", "vor", "an\u00b7de\u00b7ren", "er\u00b7hebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PPOSAT", "NN", "APPR", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als wie ", "tokens": ["Als", "wie"], "token_info": ["word", "word"], "pos": ["KOUS", "KOKOM"], "meter": "-+", "measure": "iambic.single"}}, "stanza.11": {"line.1": {"text": "In diesem Stande hast du Herr uns angetroffen.", "tokens": ["In", "die\u00b7sem", "Stan\u00b7de", "hast", "du", "Herr", "uns", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PPER", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir waren recht begl\u00fcckt/ und konten nichts mehr hoffen/", "tokens": ["Wir", "wa\u00b7ren", "recht", "be\u00b7gl\u00fcckt", "/", "und", "kon\u00b7ten", "nichts", "mehr", "hof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$(", "KON", "VMFIN", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als deine Gegenwart/ die uns nunmehr ergetzt/", "tokens": ["Als", "dei\u00b7ne", "Ge\u00b7gen\u00b7wart", "/", "die", "uns", "nun\u00b7mehr", "er\u00b7getzt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$(", "PRELS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die Vollkommenheit zu unsrer Wonne setzt.", "tokens": ["Und", "die", "Voll\u00b7kom\u00b7men\u00b7heit", "zu", "uns\u00b7rer", "Won\u00b7ne", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wir k\u00f6nnen nichts als dis zu unsrem Wohl erdencken:", "tokens": ["Wir", "k\u00f6n\u00b7nen", "nichts", "als", "dis", "zu", "uns\u00b7rem", "Wohl", "er\u00b7den\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "KOKOM", "PDS", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Himmel wolle dir auch das Vergn\u00fcgen schencken/", "tokens": ["Der", "Him\u00b7mel", "wol\u00b7le", "dir", "auch", "das", "Ver\u00b7gn\u00fc\u00b7gen", "schen\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df dich Dein treues Land mit Ehrfurcht so erfreut/", "tokens": ["Da\u00df", "dich", "Dein", "treu\u00b7es", "Land", "mit", "Ehr\u00b7furcht", "so", "er\u00b7freut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "APPR", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als du dasselbe hast mit Freuden \u00fcberstreut.", "tokens": ["Als", "du", "das\u00b7sel\u00b7be", "hast", "mit", "Freu\u00b7den", "\u00fc\u00b7bers\u00b7treut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Da\u00df deiner Jahre Zahl die Stuffen mag ersteigen.", "tokens": ["Da\u00df", "dei\u00b7ner", "Jah\u00b7re", "Zahl", "die", "Stuf\u00b7fen", "mag", "er\u00b7stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Worauff sich Ehr und Ruhm und deine Klugheit zeigen.", "tokens": ["Wo\u00b7rauff", "sich", "Ehr", "und", "Ruhm", "und", "dei\u00b7ne", "Klug\u00b7heit", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "NN", "KON", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df/ wie die Tugend dir des Gl\u00fcckes Thron gebaut/", "tokens": ["Da\u00df", "/", "wie", "die", "Tu\u00b7gend", "dir", "des", "Gl\u00fc\u00b7ckes", "Thron", "ge\u00b7baut", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "KOKOM", "ART", "NN", "PPER", "ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich dein Erlauchtes Hau\u00df noch mehr als F\u00fcrstlich schaut;", "tokens": ["Sich", "dein", "Er\u00b7lauch\u00b7tes", "Hau\u00df", "noch", "mehr", "als", "F\u00fcrst\u00b7lich", "schaut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "ADJA", "NN", "ADV", "PIAT", "KOKOM", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Da\u00df/ Gott erh\u00f6re doch den Wunsch getreuer Hertzen/", "tokens": ["Da\u00df", "/", "Gott", "er\u00b7h\u00f6\u00b7re", "doch", "den", "Wunsch", "ge\u00b7treu\u00b7er", "Hert\u00b7zen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "NN", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir unter Dir noch mehr im Gl\u00fcck und Friede schertzen/", "tokens": ["Wir", "un\u00b7ter", "Dir", "noch", "mehr", "im", "Gl\u00fcck", "und", "Frie\u00b7de", "schert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "ADV", "ADV", "APPRART", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df Du der Vater bleibst/ (ihr Sternen stimmt mit ein/)", "tokens": ["Da\u00df", "Du", "der", "Va\u00b7ter", "bleibst", "/", "(", "ihr", "Ster\u00b7nen", "stimmt", "mit", "ein", "/", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$(", "$(", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir aber l\u00e4nger noch Augusti Kinder seyn.", "tokens": ["Wir", "a\u00b7ber", "l\u00e4n\u00b7ger", "noch", "Au\u00b7gus\u00b7ti", "Kin\u00b7der", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "ADV", "NE", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}