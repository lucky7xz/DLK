{"textgrid.poem.35150": {"metadata": {"author": {"name": "May, Karl", "birth": "N.A.", "death": "N.A."}, "title": "Entwickelung", "genre": "verse", "period": "N.A.", "pub_year": 1877, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kennst du den Stoff? Ich kenne ihn noch nicht;", "tokens": ["Kennst", "du", "den", "Stoff", "?", "Ich", "ken\u00b7ne", "ihn", "noch", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich hab noch kein Atom, kein Molek\u00fcl gesehen.", "tokens": ["Ich", "hab", "noch", "kein", "A\u00b7tom", ",", "kein", "Mo\u00b7le\u00b7k\u00fcl", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "$,", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er liegt zwar vor mir, schwer genug und dicht,", "tokens": ["Er", "liegt", "zwar", "vor", "mir", ",", "schwer", "ge\u00b7nug", "und", "dicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "$,", "ADJD", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch sein Entstehn ist leider ohne mich geschehen.", "tokens": ["Doch", "sein", "Ent\u00b7stehn", "ist", "lei\u00b7der", "oh\u00b7ne", "mich", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wei\u00df nur, da\u00df er sich ver\u00e4ndert, schwindet,", "tokens": ["Ich", "wei\u00df", "nur", ",", "da\u00df", "er", "sich", "ver\u00b7\u00e4n\u00b7dert", ",", "schwin\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PRF", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und frage flei\u00dfig mich: Wozu, wohin?", "tokens": ["Und", "fra\u00b7ge", "flei\u00b7\u00dfig", "mich", ":", "Wo\u00b7zu", ",", "wo\u00b7hin", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PPER", "$.", "PWAV", "$,", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wenn dann meine Kraft die Antwort findet,", "tokens": ["Und", "wenn", "dann", "mei\u00b7ne", "Kraft", "die", "Ant\u00b7wort", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Erfahr ich nur, da\u00df ich ein Stoff auch bin.", "tokens": ["Er\u00b7fahr", "ich", "nur", ",", "da\u00df", "ich", "ein", "Stoff", "auch", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Kennst du die Kraft? Ich kenne sie noch nicht;", "tokens": ["Kennst", "du", "die", "Kraft", "?", "Ich", "ken\u00b7ne", "sie", "noch", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich hab von ihr bisher die Wirkung nur gesehen.", "tokens": ["Ich", "hab", "von", "ihr", "bis\u00b7her", "die", "Wir\u00b7kung", "nur", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zwar h\u00f6r ich's, da\u00df sie Stahl und Felsen bricht,", "tokens": ["Zwar", "h\u00f6r", "ich's", ",", "da\u00df", "sie", "Stahl", "und", "Fel\u00b7sen", "bricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KOUS", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch ihr Entstehn ist leider ohne mich geschehen.", "tokens": ["Doch", "ihr", "Ent\u00b7stehn", "ist", "lei\u00b7der", "oh\u00b7ne", "mich", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wei\u00df nur, da\u00df sie mir zuweilen schwindet", "tokens": ["Ich", "wei\u00df", "nur", ",", "da\u00df", "sie", "mir", "zu\u00b7wei\u00b7len", "schwin\u00b7det"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und frage forschend mich: Warum, wohin?", "tokens": ["Und", "fra\u00b7ge", "for\u00b7schend", "mich", ":", "Wa\u00b7rum", ",", "wo\u00b7hin", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PPER", "$.", "PWAV", "$,", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wenn sodann mein Geist die Antwort findet,", "tokens": ["Und", "wenn", "so\u00b7dann", "mein", "Geist", "die", "Ant\u00b7wort", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Erfahr ich nichts, als da\u00df auch Kraft ich bin.", "tokens": ["Er\u00b7fahr", "ich", "nichts", ",", "als", "da\u00df", "auch", "Kraft", "ich", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "$,", "KOKOM", "KOUS", "ADV", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Kennst du den Geist? Ich kenne ihn noch nicht,", "tokens": ["Kennst", "du", "den", "Geist", "?", "Ich", "ken\u00b7ne", "ihn", "noch", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich habe nur Beweise, da\u00df er wirkt, gesehen.", "tokens": ["Ich", "ha\u00b7be", "nur", "Be\u00b7wei\u00b7se", ",", "da\u00df", "er", "wirkt", ",", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zwar h\u00f6r ich seine Stimme, wenn er spricht,", "tokens": ["Zwar", "h\u00f6r", "ich", "sei\u00b7ne", "Stim\u00b7me", ",", "wenn", "er", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch sein Entstehn ist leider ohne mich geschehen.", "tokens": ["Doch", "sein", "Ent\u00b7stehn", "ist", "lei\u00b7der", "oh\u00b7ne", "mich", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wei\u00df nur, da\u00df auch er dem Menschen schwindet,", "tokens": ["Ich", "wei\u00df", "nur", ",", "da\u00df", "auch", "er", "dem", "Men\u00b7schen", "schwin\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und frage mich erstaunt: Weshalb, wohin?", "tokens": ["Und", "fra\u00b7ge", "mich", "er\u00b7staunt", ":", "We\u00b7shalb", ",", "wo\u00b7hin", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$.", "PWAV", "$,", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wenn die Seele dann die Antwort findet,", "tokens": ["Und", "wenn", "die", "See\u00b7le", "dann", "die", "Ant\u00b7wort", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Erfahr ich nichts, als da\u00df auch Geist ich bin.", "tokens": ["Er\u00b7fahr", "ich", "nichts", ",", "als", "da\u00df", "auch", "Geist", "ich", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "$,", "KOKOM", "KOUS", "ADV", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Kennst du die Seele? Nein, du kennst sie nicht,", "tokens": ["Kennst", "du", "die", "See\u00b7le", "?", "Nein", ",", "du", "kennst", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und auch mein Auge hat noch keine je gesehen.", "tokens": ["Und", "auch", "mein", "Au\u00b7ge", "hat", "noch", "kei\u00b7ne", "je", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VAFIN", "ADV", "PIAT", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie ist zwar meines Daseins Zuversicht,", "tokens": ["Sie", "ist", "zwar", "mei\u00b7nes", "Da\u00b7seins", "Zu\u00b7ver\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch ihr Entstehn ist leider ohne mich geschehen.", "tokens": ["Doch", "ihr", "Ent\u00b7stehn", "ist", "lei\u00b7der", "oh\u00b7ne", "mich", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wei\u00df nur, da\u00df sie uns nie, niemals schwindet,", "tokens": ["Ich", "wei\u00df", "nur", ",", "da\u00df", "sie", "uns", "nie", ",", "nie\u00b7mals", "schwin\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPER", "ADV", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Schwebt sie auch oft zu ihrem Ursprung hin,", "tokens": ["Schwebt", "sie", "auch", "oft", "zu", "ih\u00b7rem", "Ur\u00b7sprung", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und weil mein Glaube mich mit ihm verbindet,", "tokens": ["Und", "weil", "mein", "Glau\u00b7be", "mich", "mit", "ihm", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wei\u00df ich von dort, da\u00df ich auch Seele bin.", "tokens": ["Wei\u00df", "ich", "von", "dort", ",", "da\u00df", "ich", "auch", "See\u00b7le", "bin", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "$,", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}