{"dta.poem.9126": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  \n Der lustige spa\u00df-galan.  \n Auf die melodey:  \n Jungfer Lie\u00dfgen wei\u00df es wohl/ rc.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Es steht in der welt doch aus der massen fein/", "tokens": ["Es", "steht", "in", "der", "welt", "doch", "aus", "der", "mas\u00b7sen", "fein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "ADJD", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wann zwey junge leute recht vertraulich seyn!", "tokens": ["Wann", "zwey", "jun\u00b7ge", "leu\u00b7te", "recht", "ver\u00b7trau\u00b7lich", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "CARD", "ADJA", "NN", "ADV", "ADJD", "VAINF", "$."], "meter": "-++-+-+-+-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Sie sind drum nicht flugs verliebt/", "tokens": ["Sie", "sind", "drum", "nicht", "flugs", "ver\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "PTKNEG", "ADV", "VVPP", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wann sie gleich von hertzen", "tokens": ["Wann", "sie", "gleich", "von", "hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Freundlich k\u00f6nnen schertzen.", "tokens": ["Freund\u00b7lich", "k\u00f6n\u00b7nen", "schert\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "2. Manchem m\u00e4dgen wird was b\u00f6ses zugedacht/", "tokens": ["Man\u00b7chem", "m\u00e4d\u00b7gen", "wird", "was", "b\u00f6\u00b7ses", "zu\u00b7ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "VAFIN", "PIS", "ADJA", "VVPP", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Wann sie etwan mit den junggesellen lacht/", "tokens": ["Wann", "sie", "et\u00b7wan", "mit", "den", "jung\u00b7ge\u00b7sel\u00b7len", "lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Doch darum kein bein entzwey:", "tokens": ["Doch", "da\u00b7rum", "kein", "bein", "ent\u00b7zwey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Wer fragt nach den schwencken", "tokens": ["Wer", "fragt", "nach", "den", "schwen\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "ART", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Was die leute dencken?", "tokens": ["Was", "die", "leu\u00b7te", "den\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "3. Ein rechtschaffnes b\u00fcfgen das versteht doch wol/", "tokens": ["Ein", "recht\u00b7schaff\u00b7nes", "b\u00fcf\u00b7gen", "das", "ver\u00b7steht", "doch", "wol", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PDS", "VVFIN", "ADV", "ADV", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Was es bey der m\u00e4dgen freude dencken soll.", "tokens": ["Was", "es", "bey", "der", "m\u00e4d\u00b7gen", "freu\u00b7de", "den\u00b7cken", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Wer nicht schimpf und ernst versteht/", "tokens": ["Wer", "nicht", "schimpf", "und", "ernst", "ver\u00b7steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ADJD", "KON", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird mit schlechten frommen", "tokens": ["Wird", "mit", "schlech\u00b7ten", "from\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADJA", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Von dem m\u00e4dgen kommen.", "tokens": ["Von", "dem", "m\u00e4d\u00b7gen", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "4. Wan man gleich einander noch so freundlich heist/", "tokens": ["Wan", "man", "gleich", "ein\u00b7an\u00b7der", "noch", "so", "freund\u00b7lich", "heist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADV", "ADV", "ADV", "ADJD", "VAFIN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und wohl gar die armen in einander schleust:", "tokens": ["Und", "wohl", "gar", "die", "ar\u00b7men", "in", "ein\u00b7an\u00b7der", "schleust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "ADJA", "APPR", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Darff ein b\u00fcfgen gleich wol nicht", "tokens": ["Darff", "ein", "b\u00fcf\u00b7gen", "gleich", "wol", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADJA", "ADV", "ADV", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auff verliebte sachen", "tokens": ["Auff", "ver\u00b7lieb\u00b7te", "sa\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "VVFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Sich die rechnung machen.", "tokens": ["Sich", "die", "rech\u00b7nung", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "5. Ach wie schl\u00e4gelt mancher armer spa\u00df- galan/", "tokens": ["Ach", "wie", "schl\u00e4\u00b7gelt", "man\u00b7cher", "ar\u00b7mer", "spa\u00df", "ga\u00b7lan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "VVFIN", "PIAT", "ADJA", "TRUNC", "ADV", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Der sich in die freundlichkeit nicht finden kan", "tokens": ["Der", "sich", "in", "die", "freund\u00b7lich\u00b7keit", "nicht", "fin\u00b7den", "kan"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "ART", "NN", "PTKNEG", "VVINF", "VMFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Und der allen zeitvertreib", "tokens": ["Und", "der", "al\u00b7len", "zeit\u00b7ver\u00b7treib"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor ein liebes-zeichen", "tokens": ["Vor", "ein", "lie\u00b7bes\u00b7zei\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Heimlich will vergleichen:", "tokens": ["Heim\u00b7lich", "will", "ver\u00b7glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "6. Nein f\u00fcrwar/ beym frauenzim\u0303er gehts so nicht/", "tokens": ["Nein", "f\u00fcr\u00b7war", "/", "beym", "frau\u00b7en\u00b7zim\u0303er", "gehts", "so", "nicht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$(", "APPRART", "NN", "VVFIN", "ADV", "PTKNEG", "$("], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wann das lose m\u00e4ulgen gleich mein liebgen spricht/", "tokens": ["Wann", "das", "lo\u00b7se", "m\u00e4ul\u00b7gen", "gleich", "mein", "lieb\u00b7gen", "spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADV", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ist es drum nicht so gemeynt/", "tokens": ["Ist", "es", "drum", "nicht", "so", "ge\u00b7meynt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "PTKNEG", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als m\u00fcst er vor allen", "tokens": ["Als", "m\u00fcst", "er", "vor", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "PPER", "APPR", "PIAT"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Jhr so wohl gefallen.", "tokens": ["Ihr", "so", "wohl", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "7. Ich bin endlich allen feinen m\u00e4dgen gut/", "tokens": ["Ich", "bin", "end\u00b7lich", "al\u00b7len", "fei\u00b7nen", "m\u00e4d\u00b7gen", "gut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "ADJD", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und bin gerne da man sch\u00f6n und freundlich thut;", "tokens": ["Und", "bin", "ger\u00b7ne", "da", "man", "sch\u00f6n", "und", "freund\u00b7lich", "thut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOUS", "PIS", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Doch bild ich mir nichts ein/", "tokens": ["Doch", "bild", "ich", "mir", "nichts", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "PPER", "PIS", "ART", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wann ich gleich die s\u00fcsse", "tokens": ["Wann", "ich", "gleich", "die", "s\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Gegengunst geniesse.", "tokens": ["Ge\u00b7gen\u00b7gunst", "ge\u00b7nies\u00b7se", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "8. Endlich/ wer verschwiegen ist der geht noch hin/", "tokens": ["End\u00b7lich", "/", "wer", "ver\u00b7schwie\u00b7gen", "ist", "der", "geht", "noch", "hin", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PWS", "VVPP", "VAFIN", "ART", "VVFIN", "ADV", "PTKVZ", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Hat er sonsten gleich nicht einen hohen sinn:", "tokens": ["Hat", "er", "sons\u00b7ten", "gleich", "nicht", "ei\u00b7nen", "ho\u00b7hen", "sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Stille/ fromm und lustig seyn", "tokens": ["Stil\u00b7le", "/", "fromm", "und", "lus\u00b7tig", "seyn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "ADJD", "KON", "ADJD", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kan die junggesellen", "tokens": ["Kan", "die", "jung\u00b7ge\u00b7sel\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Niemahls sehr verstellen.", "tokens": ["Nie\u00b7mahls", "sehr", "ver\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "9. Ach wohl dem der in der jugend lustig ist/", "tokens": ["Ach", "wohl", "dem", "der", "in", "der", "ju\u00b7gend", "lus\u00b7tig", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "ART", "ART", "APPR", "ART", "NN", "ADJD", "VAFIN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Eh er in dem alter allen spa\u00df vergist!", "tokens": ["Eh", "er", "in", "dem", "al\u00b7ter", "al\u00b7len", "spa\u00df", "ver\u00b7gist", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Doch die liebe brauche man", "tokens": ["Doch", "die", "lie\u00b7be", "brau\u00b7che", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "VVFIN", "PIS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur zum blossen possen/", "tokens": ["Nur", "zum", "blos\u00b7sen", "pos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Sonst ist man geschossen.", "tokens": ["Sonst", "ist", "man", "ge\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}