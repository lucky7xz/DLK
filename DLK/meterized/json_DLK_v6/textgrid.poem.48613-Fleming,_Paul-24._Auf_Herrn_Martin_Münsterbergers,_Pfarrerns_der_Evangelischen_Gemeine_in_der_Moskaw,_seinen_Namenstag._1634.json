{"textgrid.poem.48613": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "24. Auf Herrn Martin M\u00fcnsterbergers, Pfarrerns der Evangelischen Gemeine in der Moskaw, seinen Namenstag. 1634", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Er, der liebste deiner Tage,", "tokens": ["Er", ",", "der", "liebs\u00b7te", "dei\u00b7ner", "Ta\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "den der g\u00fcldne Titan tr\u00e4gt", "tokens": ["den", "der", "g\u00fcld\u00b7ne", "Ti\u00b7tan", "tr\u00e4gt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "auf der hohen Sternenwage", "tokens": ["auf", "der", "ho\u00b7hen", "Ster\u00b7nen\u00b7wa\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und in diese Stunden legt,", "tokens": ["und", "in", "die\u00b7se", "Stun\u00b7den", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "er, der liebste, hei\u00dft uns lachen", "tokens": ["er", ",", "der", "liebs\u00b7te", ",", "hei\u00dft", "uns", "la\u00b7chen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ART", "ADJA", "$,", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und mit dir uns lustig machen.", "tokens": ["und", "mit", "dir", "uns", "lus\u00b7tig", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wol! Damit du seist gebunden,", "tokens": ["Wol", "!", "Da\u00b7mit", "du", "seist", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KOUS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so sei dieser Eppichstrau\u00df", "tokens": ["so", "sei", "die\u00b7ser", "Ep\u00b7pich\u00b7strau\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PDAT", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "in dein wei\u00dfes Haar gewunden!", "tokens": ["in", "dein", "wei\u00b7\u00dfes", "Haar", "ge\u00b7wun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Freund, es geht auf L\u00f6sen aus!", "tokens": ["Freund", ",", "es", "geht", "auf", "L\u00f6\u00b7sen", "aus", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du wirst nicht ohn' deinen Schaden", "tokens": ["Du", "wirst", "nicht", "ohn'", "dei\u00b7nen", "Scha\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "uns darf\u00fcr ein m\u00fcssen laden.", "tokens": ["uns", "dar\u00b7f\u00fcr", "ein", "m\u00fcs\u00b7sen", "la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PAV", "PTKVZ", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wir sind da, wir treuen Dreie,", "tokens": ["Wir", "sind", "da", ",", "wir", "treu\u00b7en", "Drei\u00b7e", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die du mehr als vor nun kennst,", "tokens": ["die", "du", "mehr", "als", "vor", "nun", "kennst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "KOKOM", "APPR", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "die du dir verkn\u00fcpfst aufs Neue,", "tokens": ["die", "du", "dir", "ver\u00b7kn\u00fcpfst", "aufs", "Neu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVFIN", "APPRART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df du sie mehr deine nennst.", "tokens": ["da\u00df", "du", "sie", "mehr", "dei\u00b7ne", "nennst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wir sind da mit dem Verlangen,", "tokens": ["Wir", "sind", "da", "mit", "dem", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "was du denn nun an wirst fangen.", "tokens": ["was", "du", "denn", "nun", "an", "wirst", "fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "APZR", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Folge, Bruder, was zu \u00fcben", "tokens": ["Fol\u00b7ge", ",", "Bru\u00b7der", ",", "was", "zu", "\u00fc\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "PRELS", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wir und Zeit und Himmel hei\u00dft!", "tokens": ["wir", "und", "Zeit", "und", "Him\u00b7mel", "hei\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein! wer wolte Den doch lieben,", "tokens": ["Mein", "!", "wer", "wol\u00b7te", "Den", "doch", "lie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VMFIN", "ART", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der sich stets der Lust entrei\u00dft?", "tokens": ["der", "sich", "stets", "der", "Lust", "ent\u00b7rei\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn ists Zeit, da\u00df wir uns gr\u00e4men,", "tokens": ["Denn", "ists", "Zeit", ",", "da\u00df", "wir", "uns", "gr\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wenn wir unsers Gl\u00fccks uns sch\u00e4men?", "tokens": ["wenn", "wir", "un\u00b7sers", "Gl\u00fccks", "uns", "sch\u00e4\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Brauch' der Zeit! Die leichten Stunden", "tokens": ["Brauch'", "der", "Zeit", "!", "Die", "leich\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "schie\u00dfen schneller als kein Flu\u00df.", "tokens": ["schie\u00b7\u00dfen", "schnel\u00b7ler", "als", "kein", "Flu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KOKOM", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zeit hat Fl\u00fcgel angebunden,", "tokens": ["Zeit", "hat", "Fl\u00fc\u00b7gel", "an\u00b7ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gl\u00fccke steht auf glattem Fu\u00df,", "tokens": ["Gl\u00fc\u00b7cke", "steht", "auf", "glat\u00b7tem", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und die hat nur vornen Haare,", "tokens": ["und", "die", "hat", "nur", "vor\u00b7nen", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die nicht allzeit k\u00f6mpt im Jahre.", "tokens": ["die", "nicht", "all\u00b7zeit", "k\u00f6mpt", "im", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.6": {"line.1": {"text": "Gott wei\u00df was wir morgen machen;", "tokens": ["Gott", "wei\u00df", "was", "wir", "mor\u00b7gen", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PWS", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "heute la\u00df uns lustig sein!", "tokens": ["heu\u00b7te", "la\u00df", "uns", "lus\u00b7tig", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Trauren, Frohsein, Weinen, Lachen,", "tokens": ["Trau\u00b7ren", ",", "Froh\u00b7sein", ",", "Wei\u00b7nen", ",", "La\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ziehn bald bei uns aus, bald ein.", "tokens": ["ziehn", "bald", "bei", "uns", "aus", ",", "bald", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "PTKVZ", "$,", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wol dem, welcher ist vergn\u00fcget,", "tokens": ["Wol", "dem", ",", "wel\u00b7cher", "ist", "ver\u00b7gn\u00fc\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PWAT", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wie sich sein Verh\u00e4ngn\u00fc\u00df f\u00fcget!", "tokens": ["wie", "sich", "sein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "f\u00fc\u00b7get", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Bringt uns Lauten, Geigen, Fl\u00f6ten!", "tokens": ["Bringt", "uns", "Lau\u00b7ten", ",", "Gei\u00b7gen", ",", "Fl\u00f6\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Junger, hole das Regal!", "tokens": ["Jun\u00b7ger", ",", "ho\u00b7le", "das", "Re\u00b7gal", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Die Musik kan Trauren t\u00f6ten,", "tokens": ["Die", "Mu\u00b7sik", "kan", "Trau\u00b7ren", "t\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "VVFIN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "sie zertreibt der Sinnen Qual.", "tokens": ["sie", "zer\u00b7treibt", "der", "Sin\u00b7nen", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch die G\u00f6tter sind betr\u00fcbet,", "tokens": ["Auch", "die", "G\u00f6t\u00b7ter", "sind", "be\u00b7tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo nicht sie die Freude giebet.", "tokens": ["wo", "nicht", "sie", "die", "Freu\u00b7de", "gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wenn wir edlen Menschen sitzen", "tokens": ["Wenn", "wir", "ed\u00b7len", "Men\u00b7schen", "sit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "umb den Ofen und ein Glas,", "tokens": ["umb", "den", "O\u00b7fen", "und", "ein", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und an Seel' und Leibern hitzen,", "tokens": ["und", "an", "Seel'", "und", "Lei\u00b7bern", "hit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so ist besser Nichts als das,", "tokens": ["so", "ist", "bes\u00b7ser", "Nichts", "als", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "PIS", "KOKOM", "PDS", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "da\u00df man bei so s\u00fc\u00dfen Dingen", "tokens": ["da\u00df", "man", "bei", "so", "s\u00fc\u00b7\u00dfen", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "auch l\u00e4\u00dft s\u00fc\u00dfe Lieder klingen.", "tokens": ["auch", "l\u00e4\u00dft", "s\u00fc\u00b7\u00dfe", "Lie\u00b7der", "klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Her die Schalen! Frisch, ihr Br\u00fcder!", "tokens": ["Her", "die", "Scha\u00b7len", "!", "Frisch", ",", "ihr", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "NE", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir sind heut' und morgen hier.", "tokens": ["Wir", "sind", "heut'", "und", "mor\u00b7gen", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KON", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich warlich komme wieder,", "tokens": ["Da\u00df", "ich", "war\u00b7lich", "kom\u00b7me", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so gilt, Herr ", "tokens": ["so", "gilt", ",", "Herr"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "der Trunk dieses weiten R\u00f6mers", "tokens": ["der", "Trunk", "die\u00b7ses", "wei\u00b7ten", "R\u00f6\u00b7mers"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PDAT", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "auf Gesundheit unsers ", "tokens": ["auf", "Ge\u00b7sund\u00b7heit", "un\u00b7sers"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}