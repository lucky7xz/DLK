{"textgrid.poem.56805": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbspringst auch zum Bader?\u00ab", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbspringst auch zum Bader?\u00ab", "tokens": ["\u00bb", "springst", "auch", "zum", "Ba\u00b7der", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "APPRART", "NN", "$.", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "\u00bbja!\u00ab", "tokens": ["\u00bb", "ja", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$.", "$("], "meter": "-", "measure": "single.down"}, "line.3": {"text": "\u00bbspring'n wir zusammen!\u00ab", "tokens": ["\u00bb", "spring'n", "wir", "zu\u00b7sam\u00b7men", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u00bbein sch\u00f6ner Sonntag heut \u2013\u00ab", "tokens": ["\u00bb", "ein", "sch\u00f6\u00b7ner", "Sonn\u00b7tag", "heut", "\u2013", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "ADV", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbduck dich!\u00ab", "tokens": ["\u00bb", "duck", "dich", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "\u00bbwas ist?\u00ab", "tokens": ["\u00bb", "was", "ist", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VAFIN", "$.", "$("], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "\u00bbein Has!\u00ab", "tokens": ["\u00bb", "ein", "Has", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$.", "$("], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "\u00bbein Has! das ist 'was Recht's!\u00ab", "tokens": ["\u00bb", "ein", "Has", "!", "das", "ist", "'was", "Recht's", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$.", "PDS", "VAFIN", "NE", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "\u00bbsei still! wenn er dich h\u00f6rt, so \u2013\u00ab", "tokens": ["\u00bb", "sei", "still", "!", "wenn", "er", "dich", "h\u00f6rt", ",", "so", "\u2013", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "ADJD", "$.", "KOUS", "PPER", "PRF", "VVFIN", "$,", "ADV", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.10": {"text": "\u00bbnun?\u00ab", "tokens": ["\u00bb", "nun", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "$.", "$("], "meter": "-", "measure": "single.down"}, "line.11": {"text": "\u00bbverklagt er uns beim Raben!\u00ab", "tokens": ["\u00bb", "ver\u00b7klagt", "er", "uns", "beim", "Ra\u00b7ben", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "PRF", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "\u00bbdu!\u00ab", "tokens": ["\u00bb", "du", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "PPER", "$.", "$("], "meter": "-", "measure": "single.down"}, "line.13": {"text": "\u00bbwas hast? ein Korn?\u00ab", "tokens": ["\u00bb", "was", "hast", "?", "ein", "Korn", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VAFIN", "$.", "ART", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "\u00bbhihi! die H\u00e4lfte fress' ich \u2013\u00ab", "tokens": ["\u00bb", "hi\u00b7hi", "!", "die", "H\u00e4lf\u00b7te", "fress'", "ich", "\u2013", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$.", "ART", "NN", "VVFIN", "PPER", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.15": {"text": "\u00bbmehlgebacknes?\u00ab", "tokens": ["\u00bb", "mehl\u00b7ge\u00b7back\u00b7nes", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "PIS", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.16": {"text": "\u00bbund mit der andern zahl' ich \u2013\u00ab", "tokens": ["\u00bb", "und", "mit", "der", "an\u00b7dern", "zahl'", "ich", "\u2013", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "APPR", "ART", "ADJA", "VVFIN", "PPER", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "\u00bbden Barbier? Und ich?\u00ab", "tokens": ["\u00bb", "den", "Bar\u00b7bier", "?", "Und", "ich", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$.", "KON", "PPER", "$.", "$("], "meter": "--+-+", "measure": "anapaest.init"}, "line.18": {"text": "\u00bbhi! wenn du noch dein Weibchen w\u00e4rst!\u00ab", "tokens": ["\u00bb", "hi", "!", "wenn", "du", "noch", "dein", "Weib\u00b7chen", "w\u00e4rst", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$.", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "\u00bbich bei\u00df' dich \u2013\u00ab", "tokens": ["\u00bb", "ich", "bei\u00df'", "dich", "\u2013", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$(", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "\u00bbstill! da sind wir!\u00ab", "tokens": ["\u00bb", "still", "!", "da", "sind", "wir", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "$.", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.21": {"text": "\u00bbguten Morgen!\u00ab", "tokens": ["\u00bb", "gu\u00b7ten", "Mor\u00b7gen", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Aus einem Erdloch", "tokens": ["Aus", "ei\u00b7nem", "Erd\u00b7loch"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "unter einer Wurzel", "tokens": ["un\u00b7ter", "ei\u00b7ner", "Wur\u00b7zel"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "verbeugt sich tief", "tokens": ["ver\u00b7beugt", "sich", "tief"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PRF", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "ein alter Mausekopf \u2013:", "tokens": ["ein", "al\u00b7ter", "Mau\u00b7se\u00b7kopf", "\u2013", ":"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbfrisieren? brennen?", "tokens": ["\u00bb", "fri\u00b7sie\u00b7ren", "?", "bren\u00b7nen", "?"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "VVINF", "$.", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Bitte, nur herein!\u00ab", "tokens": ["Bit\u00b7te", ",", "nur", "her\u00b7ein", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "PTKVZ", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Die M\u00e4uslein nehmen Platz", "tokens": ["Die", "M\u00e4us\u00b7lein", "neh\u00b7men", "Platz"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "auf einer Moosbank", "tokens": ["auf", "ei\u00b7ner", "Moos\u00b7bank"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "und harren stumm", "tokens": ["und", "har\u00b7ren", "stumm"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "in saubern Spinnwebm\u00e4nteln,", "tokens": ["in", "sau\u00b7bern", "Spinn\u00b7web\u00b7m\u00e4n\u00b7teln", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "indes der Alte", "tokens": ["in\u00b7des", "der", "Al\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "seine Eisen drau\u00dfen", "tokens": ["sei\u00b7ne", "Ei\u00b7sen", "drau\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "auf einen Stein", "tokens": ["auf", "ei\u00b7nen", "Stein"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "ins Sonnenfeuer legt.", "tokens": ["ins", "Son\u00b7nen\u00b7feu\u00b7er", "legt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbdie H\u00e4rchen ausziehn?\u00ab", "tokens": ["\u00bb", "die", "H\u00e4r\u00b7chen", "aus\u00b7ziehn", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "\u00bbnach der Mode!\u00ab", "tokens": ["\u00bb", "nach", "der", "Mo\u00b7de", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "\u00bbbitte! ...\u00ab", "tokens": ["\u00bb", "bit\u00b7te", "!", "...", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct"], "pos": ["$(", "PTKANT", "$.", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Bed\u00e4chtig zieht", "tokens": ["Be\u00b7d\u00e4ch\u00b7tig", "zieht"], "token_info": ["word", "word"], "pos": ["ADJD", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "der alte Mausbarbier", "tokens": ["der", "al\u00b7te", "Maus\u00b7bar\u00b7bier"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "die Schnurrbartf\u00e4dchen", "tokens": ["die", "Schnurr\u00b7bart\u00b7f\u00e4d\u00b7chen"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "durch das warme Scherlein.", "tokens": ["durch", "das", "war\u00b7me", "Scher\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Dann wichst er sie", "tokens": ["Dann", "wichst", "er", "sie"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "ein wenig noch mit Harz", "tokens": ["ein", "we\u00b7nig", "noch", "mit", "Harz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "APPR", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "und w\u00e4scht zum \u00dcberflu\u00df", "tokens": ["und", "w\u00e4scht", "zum", "\u00dc\u00b7berf\u00b7lu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "die samtnen K\u00f6pfchen", "tokens": ["die", "samt\u00b7nen", "K\u00f6pf\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "mit Birken\u00f6l", "tokens": ["mit", "Bir\u00b7ken\u00b7\u00f6l"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "und scheitelt sie geschickt.", "tokens": ["und", "schei\u00b7telt", "sie", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Dann kn\u00fcpft er flink", "tokens": ["Dann", "kn\u00fcpft", "er", "flink"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "die M\u00e4ntel ab", "tokens": ["die", "M\u00e4n\u00b7tel", "ab"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "PTKVZ"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "und b\u00fcrstet", "tokens": ["und", "b\u00fcrs\u00b7tet"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "die sonnt\u00e4glichen W\u00e4mser", "tokens": ["die", "sonn\u00b7t\u00e4g\u00b7li\u00b7chen", "W\u00e4m\u00b7ser"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "spiegelglatt.", "tokens": ["spie\u00b7gel\u00b7glatt", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Mit Anstand holt", "tokens": ["Mit", "An\u00b7stand", "holt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "das eine M\u00e4uslein drauf", "tokens": ["das", "ei\u00b7ne", "M\u00e4us\u00b7lein", "drauf"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "PAV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "den Kuchen aus der Tasche:", "tokens": ["den", "Ku\u00b7chen", "aus", "der", "Ta\u00b7sche", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbbitte!\u00ab", "tokens": ["\u00bb", "bit\u00b7te", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "\u00bbdanke!\u00ab ...", "tokens": ["\u00bb", "dan\u00b7ke", "!", "\u00ab", "..."], "token_info": ["punct", "word", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.8": {"line.1": {"text": "Von seinem Loch aus", "tokens": ["Von", "sei\u00b7nem", "Loch", "aus"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "guckt der Mausbarbier", "tokens": ["guckt", "der", "Maus\u00b7bar\u00b7bier"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "dem stolzen Paar", "tokens": ["dem", "stol\u00b7zen", "Paar"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "behaglich knabbernd nach", "tokens": ["be\u00b7hag\u00b7lich", "knab\u00b7bernd", "nach"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ADJD", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "und lugt vergn\u00fcgt", "tokens": ["und", "lugt", "ver\u00b7gn\u00fcgt"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "VVPP"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "zum blauen Himmel auf,", "tokens": ["zum", "blau\u00b7en", "Him\u00b7mel", "auf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "der reiche Kundschaft", "tokens": ["der", "rei\u00b7che", "Kund\u00b7schaft"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "heute noch verspricht.", "tokens": ["heu\u00b7te", "noch", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}