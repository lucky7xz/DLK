{"textgrid.poem.53935": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Olympiade", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Heute ist infolge von Olympia-Siegen", "tokens": ["Heu\u00b7te", "ist", "in\u00b7fol\u00b7ge", "von", "O\u00b7lym\u00b7pia\u00b7Sie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "unsere Flagge sieben Mal hochgestiegen!", "tokens": ["un\u00b7se\u00b7re", "Flag\u00b7ge", "sie\u00b7ben", "Mal", "hoch\u00b7ges\u00b7tie\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "CARD", "NN", "VVINF", "$."], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Demzufolge la\u00dft uns br\u00fcllen:", "tokens": ["Dem\u00b7zu\u00b7fol\u00b7ge", "la\u00dft", "uns", "br\u00fcl\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbhoch . . . !\u00ab", "tokens": ["\u00bb", "hoch", ".", ".", ".", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "$.", "$.", "$.", "$("], "meter": "+", "measure": "single.up"}, "line.5": {"text": "(nach Belieben auszuf\u00fcllen).", "tokens": ["(", "nach", "Be\u00b7lie\u00b7ben", "aus\u00b7zu\u00b7f\u00fcl\u00b7len", ")", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NN", "VVIZU", "$(", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da schl\u00e4gt jede Nation Kobolz \u2013", "tokens": ["Da", "schl\u00e4gt", "je\u00b7de", "Na\u00b7tion", "Ko\u00b7bolz", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "worauf sind die eigentlich stolz?", "tokens": ["wo\u00b7rauf", "sind", "die", "ei\u00b7gent\u00b7lich", "stolz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADV", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.2": {"line.1": {"text": "Wenn Herr K\u00f6rnig erster Mann wird,", "tokens": ["Wenn", "Herr", "K\u00f6r\u00b7nig", "ers\u00b7ter", "Mann", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "ADJA", "NN", "VAFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "haben sie gesiegt.", "tokens": ["ha\u00b7ben", "sie", "ge\u00b7siegt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn er nur als Zweiter anschwirrt,", "tokens": ["Wenn", "er", "nur", "als", "Zwei\u00b7ter", "an\u00b7schwirrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "KOUS", "NN", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "haben sie gesiegt.", "tokens": ["ha\u00b7ben", "sie", "ge\u00b7siegt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wird er Dritter, wird er Vierter,", "tokens": ["Wird", "er", "Drit\u00b7ter", ",", "wird", "er", "Vier\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$,", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "haben sie gesiegt.", "tokens": ["ha\u00b7ben", "sie", "ge\u00b7siegt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Wird er aber Letztchargierter,", "tokens": ["Wird", "er", "a\u00b7ber", "Letzt\u00b7char\u00b7gier\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "haben sie auch gesiegt.", "tokens": ["ha\u00b7ben", "sie", "auch", "ge\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ob sie vorne oder hinten liegen,", "tokens": ["Ob", "sie", "vor\u00b7ne", "o\u00b7der", "hin\u00b7ten", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "KON", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "sie tun egalweg nur siegen.", "tokens": ["sie", "tun", "e\u00b7gal\u00b7weg", "nur", "sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und damit es jeden mal ereilt,", "tokens": ["Und", "da\u00b7mit", "es", "je\u00b7den", "mal", "er\u00b7eilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "wird der Stolz h\u00fcbsch sauber aufgeteilt:", "tokens": ["wird", "der", "Stolz", "h\u00fcbsch", "sau\u00b7ber", "auf\u00b7ge\u00b7teilt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "L\u00e4uft ein Mann aus Japan durch das Ziel,", "tokens": ["L\u00e4uft", "ein", "Mann", "aus", "Ja\u00b7pan", "durch", "das", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "schrein die Japaner.", "tokens": ["schrein", "die", "Ja\u00b7pa\u00b7ner", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Siegt ein USA-Mann in dem Spiel,", "tokens": ["Siegt", "ein", "U\u00b7sA\u00b7Mann", "in", "dem", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "br\u00fcllen die Amerikaner.", "tokens": ["br\u00fcl\u00b7len", "die", "A\u00b7me\u00b7ri\u00b7ka\u00b7ner", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Siegt ein Fechter von den Herrn Faschisten,", "tokens": ["Siegt", "ein", "Fech\u00b7ter", "von", "den", "Herrn", "Fa\u00b7schis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "steigt ein brausender Chor;", "tokens": ["steigt", "ein", "brau\u00b7sen\u00b7der", "Chor", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "siegt ein Jude, nehmen die Zionisten", "tokens": ["siegt", "ein", "Ju\u00b7de", ",", "neh\u00b7men", "die", "Zi\u00b7o\u00b7nis\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.8": {"text": "eine doppelte Beschneidung vor.", "tokens": ["ei\u00b7ne", "dop\u00b7pel\u00b7te", "Be\u00b7schnei\u00b7dung", "vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "So l\u00e4\u00dft jeder von den bunten Gruppen", "tokens": ["So", "l\u00e4\u00dft", "je\u00b7der", "von", "den", "bun\u00b7ten", "Grup\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "seinen h\u00f6chst privaten Vogel huppen.", "tokens": ["sei\u00b7nen", "h\u00f6chst", "pri\u00b7va\u00b7ten", "Vo\u00b7gel", "hup\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Sagt mal, habt ihr Nurmis Beine?", "tokens": ["Sagt", "mal", ",", "habt", "ihr", "Nur\u00b7mis", "Bei\u00b7ne", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "VAFIN", "PPER", "ADV", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seid ihr stolz auf Peltzern seine?", "tokens": ["Seid", "ihr", "stolz", "auf", "Pelt\u00b7zern", "sei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ADJD", "APPR", "NN", "PPOSAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seid ihr stolz auf das, was andere tun?", "tokens": ["Seid", "ihr", "stolz", "auf", "das", ",", "was", "an\u00b7de\u00b7re", "tun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ADJD", "APPR", "ART", "$,", "PRELS", "PIS", "VVINF", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.6": {"line.1": {"text": "Lassen wir die Stadion-Helden ruhn.", "tokens": ["Las\u00b7sen", "wir", "die", "Sta\u00b7dion\u00b7Hel\u00b7den", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Denn dies amsterdamer Treiben, wie ich meine,", "tokens": ["Denn", "dies", "ams\u00b7ter\u00b7da\u00b7mer", "Trei\u00b7ben", ",", "wie", "ich", "mei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADJA", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "ist das Spa\u00dfvergn\u00fcgen aufgeregter Skatvereine.", "tokens": ["ist", "das", "Spa\u00df\u00b7ver\u00b7gn\u00fc\u00b7gen", "auf\u00b7ge\u00b7reg\u00b7ter", "Skat\u00b7ver\u00b7ei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}}}}