{"dta.poem.10762": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  \n C\u0153li & F\u0153min\u00e6 rotunditas.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "De\u00df Himmels blawe Feld befleckt mit keinen Meckeln/", "tokens": ["De\u00df", "Him\u00b7mels", "bla\u00b7we", "Feld", "be\u00b7fleckt", "mit", "kei\u00b7nen", "Me\u00b7ckeln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.2": {"text": "Bestecket hier vnd da mithellen Sterne Fackeln/", "tokens": ["Be\u00b7ste\u00b7cket", "hier", "vnd", "da", "mi\u00b7thel\u00b7len", "Ster\u00b7ne", "Fa\u00b7ckeln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ADV", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Beschlossen von sich selbst/ bestehend ohne grund/", "tokens": ["Be\u00b7schlos\u00b7sen", "von", "sich", "selbst", "/", "be\u00b7ste\u00b7hend", "oh\u00b7ne", "grund", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "ADV", "$(", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist allenthalben gantz volkommen kugelrund.", "tokens": ["Ist", "al\u00b7len\u00b7thal\u00b7ben", "gantz", "vol\u00b7kom\u00b7men", "ku\u00b7gel\u00b7rund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Frawen mehrertheils/ de\u00df Himmels sch\u00f6ne Kinder/", "tokens": ["Die", "Fra\u00b7wen", "meh\u00b7rer\u00b7theils", "/", "de\u00df", "Him\u00b7mels", "sch\u00f6\u00b7ne", "Kin\u00b7der", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Befinden an fich die volkommenheit nicht minder/", "tokens": ["Be\u00b7fin\u00b7den", "an", "fich", "die", "vol\u00b7kom\u00b7men\u00b7heit", "nicht", "min\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "ART", "NN", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In dreyen sind sierund/ das erste sind die Br\u00fcst/", "tokens": ["In", "drey\u00b7en", "sind", "sie\u00b7rund", "/", "das", "ers\u00b7te", "sind", "die", "Br\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "VAFIN", "ADJD", "$(", "ART", "ADJA", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Das ander ist das Haupt/ der Bauch das dritte ist.", "tokens": ["Das", "an\u00b7der", "ist", "das", "Haupt", "/", "der", "Bauch", "das", "drit\u00b7te", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VAFIN", "ART", "NN", "$(", "ART", "NN", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die erste pflegen in die runde sich zu f\u00fcegen/", "tokens": ["Die", "ers\u00b7te", "pfle\u00b7gen", "in", "die", "run\u00b7de", "sich", "zu", "f\u00fce\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "PRF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn sie zu harte nicht daheim gefangen liegen/", "tokens": ["Wenn", "sie", "zu", "har\u00b7te", "nicht", "da\u00b7heim", "ge\u00b7fan\u00b7gen", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKZU", "VVFIN", "PTKNEG", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie die Jungfrawen jetz sehr vabarmhertzig sein/", "tokens": ["Wie", "die", "Jung\u00b7fra\u00b7wen", "jetz", "sehr", "va\u00b7barm\u00b7hert\u00b7zig", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADV", "ADJD", "VAINF", "$("], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Vnd jhre Kindlein gar zu harte windelnein.", "tokens": ["Vnd", "jhre", "Kin\u00b7dlein", "gar", "zu", "har\u00b7te", "win\u00b7deln\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.13": {"text": "Dem andern st\u00fccke wird die runde nicht benommen", "tokens": ["Dem", "an\u00b7dern", "st\u00fc\u00b7cke", "wird", "die", "run\u00b7de", "nicht", "be\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "VAFIN", "ART", "ADJA", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Durch vngehewre b\u00fcrd/ die von vns M\u00e4nnern kommen/", "tokens": ["Durch", "vn\u00b7ge\u00b7hew\u00b7re", "b\u00fcrd", "/", "die", "von", "vns", "M\u00e4n\u00b7nern", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ART", "APPR", "PPER", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das sch\u00f6ne Leibes Schlo\u00df sch\u00f6n rund vnd artig steht/", "tokens": ["Das", "sch\u00f6\u00b7ne", "Lei\u00b7bes", "Schlo\u00df", "sch\u00f6n", "rund", "vnd", "ar\u00b7tig", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "ADJD", "ADJD", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Vnd seinem Himmel gleich sacht hin vnd wieder geht.", "tokens": ["Vnd", "sei\u00b7nem", "Him\u00b7mel", "gleich", "sacht", "hin", "vnd", "wie\u00b7der", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVFIN", "PTKVZ", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Das drit ist von Natur zur runde nicht erkoren/", "tokens": ["Das", "drit", "ist", "von", "Na\u00b7tur", "zur", "run\u00b7de", "nicht", "er\u00b7ko\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAFIN", "APPR", "NN", "APPRART", "ADJA", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch hat/ wie ich geh\u00f6rt/ der Breutigam geschworen/", "tokens": ["Doch", "hat", "/", "wie", "ich", "ge\u00b7h\u00f6rt", "/", "der", "Breu\u00b7ti\u00b7gam", "ge\u00b7schwo\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "PWAV", "PPER", "VVFIN", "$(", "ART", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Da\u00df nicht ein halbes Jahr soll recht vor\u00fcber gehn/", "tokens": ["Da\u00df", "nicht", "ein", "hal\u00b7bes", "Jahr", "soll", "recht", "vor\u00b7\u00fc\u00b7ber", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "VMFIN", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Sosoll dasselbe theil gantz kugelrund da stehn.", "tokens": ["So\u00b7soll", "das\u00b7sel\u00b7be", "theil", "gantz", "ku\u00b7gel\u00b7rund", "da", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "ADV", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}