{"textgrid.poem.34500": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "1", "genre": "verse", "period": "N.A.", "pub_year": 1888, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In das Land der Moabiter zogen", "tokens": ["In", "das", "Land", "der", "Mo\u00b7a\u00b7bi\u00b7ter", "zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Elimelech und sein Weib Naemi", "tokens": ["E\u00b7li\u00b7me\u00b7lech", "und", "sein", "Weib", "Nae\u00b7mi"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "PPOSAT", "NN", "NE"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "und mit ihnen ihre beiden S\u00f6hne.", "tokens": ["und", "mit", "ih\u00b7nen", "ih\u00b7re", "bei\u00b7den", "S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Eine Theurung, die der Herr gesendet,", "tokens": ["Ei\u00b7ne", "Theu\u00b7rung", ",", "die", "der", "Herr", "ge\u00b7sen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "trieb sie aus dem Lande ihrer V\u00e4ter.", "tokens": ["trieb", "sie", "aus", "dem", "Lan\u00b7de", "ih\u00b7rer", "V\u00e4\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Doch in fremdem Boden kein Gedeihen", "tokens": ["Doch", "in", "frem\u00b7dem", "Bo\u00b7den", "kein", "Ge\u00b7dei\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "PIAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "fand der Stamm, aus Judas Grund gerissen,", "tokens": ["fand", "der", "Stamm", ",", "aus", "Ju\u00b7das", "Grund", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "APPR", "NE", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "und es sank zu Grabe Elimelech", "tokens": ["und", "es", "sank", "zu", "Gra\u00b7be", "E\u00b7li\u00b7me\u00b7lech"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "NE"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "und es starben seine beiden S\u00f6hne.", "tokens": ["und", "es", "star\u00b7ben", "sei\u00b7ne", "bei\u00b7den", "S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Einsam blieb die Mutter, nur die Frauen,", "tokens": ["Ein\u00b7sam", "blieb", "die", "Mut\u00b7ter", ",", "nur", "die", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "die die S\u00f6hne freiten in der Fremde,", "tokens": ["die", "die", "S\u00f6h\u00b7ne", "frei\u00b7ten", "in", "der", "Frem\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Ruth und Arpa weinten mit Naemi.", "tokens": ["Ruth", "und", "Ar\u00b7pa", "wein\u00b7ten", "mit", "Nae\u00b7mi", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "VVFIN", "APPR", "NE", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Doch Jehova wandte seinem Volke", "tokens": ["Doch", "Je\u00b7ho\u00b7va", "wand\u00b7te", "sei\u00b7nem", "Vol\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "wiederum sein Antlitz zu in Gnaden:", "tokens": ["wie\u00b7de\u00b7rum", "sein", "Ant\u00b7litz", "zu", "in", "Gna\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKZU", "APPR", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "und die Noth der Theurung war vor\u00fcber", "tokens": ["und", "die", "Noth", "der", "Theu\u00b7rung", "war", "vor\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN", "VAFIN", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und den M\u00e4nnern wieder Brot gegeben.", "tokens": ["und", "den", "M\u00e4n\u00b7nern", "wie\u00b7der", "Brot", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Da gedachte ihres Volks Naemi!", "tokens": ["Da", "ge\u00b7dach\u00b7te", "ih\u00b7res", "Volks", "Nae\u00b7mi", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "NE", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Aus der Moabiter Lande wieder", "tokens": ["Aus", "der", "Mo\u00b7a\u00b7bi\u00b7ter", "Lan\u00b7de", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "machte sie sich auf und mit ihr zogen", "tokens": ["mach\u00b7te", "sie", "sich", "auf", "und", "mit", "ihr", "zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "PTKVZ", "KON", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ruth und Arpa. Und sie sprach zu ihnen:", "tokens": ["Ruth", "und", "Ar\u00b7pa", ".", "Und", "sie", "sprach", "zu", "ih\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$.", "KON", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Kehret um, o ihr geliebten T\u00f6chter!", "tokens": ["Keh\u00b7ret", "um", ",", "o", "ihr", "ge\u00b7lieb\u00b7ten", "T\u00f6ch\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "FM", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gehet, jede in das Haus der Mutter,", "tokens": ["Ge\u00b7het", ",", "je\u00b7de", "in", "das", "Haus", "der", "Mut\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PIAT", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "und es thu der Herr an euch das Gute,", "tokens": ["und", "es", "thu", "der", "Herr", "an", "euch", "das", "Gu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "das ihr thatet mir und meinen Toten.", "tokens": ["das", "ihr", "tha\u00b7tet", "mir", "und", "mei\u00b7nen", "To\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Kann euch f\u00fcrder Kinder nicht geb\u00e4ren,", "tokens": ["Kann", "euch", "f\u00fcr\u00b7der", "Kin\u00b7der", "nicht", "ge\u00b7b\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "die euch wieder M\u00e4nner werden m\u00f6chten.", "tokens": ["die", "euch", "wie\u00b7der", "M\u00e4n\u00b7ner", "wer\u00b7den", "m\u00f6ch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "NN", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Kehret um, o ihr geliebten T\u00f6chter!", "tokens": ["Keh\u00b7ret", "um", ",", "o", "ihr", "ge\u00b7lieb\u00b7ten", "T\u00f6ch\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "FM", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Euer Jammer frisst an meinem Herzen:", "tokens": ["Eu\u00b7er", "Jam\u00b7mer", "frisst", "an", "mei\u00b7nem", "Her\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "denn des Herren Hand hat mich geschlagen,", "tokens": ["denn", "des", "Her\u00b7ren", "Hand", "hat", "mich", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und des Herren Hand hat euch getroffen!", "tokens": ["und", "des", "Her\u00b7ren", "Hand", "hat", "euch", "ge\u00b7trof\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Laut erhoben jene ihre Klagen,", "tokens": ["Laut", "er\u00b7ho\u00b7ben", "je\u00b7ne", "ih\u00b7re", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PDS", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Arpa k\u00fcsste sie und wandte weinend", "tokens": ["Ar\u00b7pa", "k\u00fcss\u00b7te", "sie", "und", "wand\u00b7te", "wei\u00b7nend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "KON", "VVFIN", "VVPP"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "drauf sich um zu ihrem Gott und Volke.", "tokens": ["drauf", "sich", "um", "zu", "ih\u00b7rem", "Gott", "und", "Vol\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "APPR", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ruth blieb bei ihr und Naemi sagte:", "tokens": ["Ruth", "blieb", "bei", "ihr", "und", "Nae\u00b7mi", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "KON", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Siehe, Ruth! So thu auch du, wie jene,", "tokens": ["Sie\u00b7he", ",", "Ruth", "!", "So", "thu", "auch", "du", ",", "wie", "je\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NN", "$.", "ADV", "VVFIN", "ADV", "PPER", "$,", "PWAV", "PDS", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "gehe nun und lass mich weiter wandern!", "tokens": ["ge\u00b7he", "nun", "und", "lass", "mich", "wei\u00b7ter", "wan\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Aber Ruth erwiderte der Mutter:", "tokens": ["A\u00b7ber", "Ruth", "er\u00b7wi\u00b7der\u00b7te", "der", "Mut\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+---+-", "measure": "unknown.measure.tetra"}}, "stanza.10": {"line.1": {"text": "Rede mir von gehen nicht noch lassen!", "tokens": ["Re\u00b7de", "mir", "von", "ge\u00b7hen", "nicht", "noch", "las\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "VVFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wo du hingehst, will ich auch hingehen,", "tokens": ["Wo", "du", "hin\u00b7gehst", ",", "will", "ich", "auch", "hin\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "wo du bleibst, da werd ich bei dir bleiben.", "tokens": ["wo", "du", "bleibst", ",", "da", "werd", "ich", "bei", "dir", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dein Volk ist das meine nun geworden,", "tokens": ["Dein", "Volk", "ist", "das", "mei\u00b7ne", "nun", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PDS", "VVFIN", "ADV", "VAPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "dein Gott soll auch mein Gott f\u00fcrder heissen.", "tokens": ["dein", "Gott", "soll", "auch", "mein", "Gott", "f\u00fcr\u00b7der", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-++-+---+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Wo du stirbst, da werd auch ich begraben,", "tokens": ["Wo", "du", "stirbst", ",", "da", "werd", "auch", "ich", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "ADV", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "und der Herr, der unser Leben leitet,", "tokens": ["und", "der", "Herr", ",", "der", "un\u00b7ser", "Le\u00b7ben", "lei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "m\u00f6ge dies und jenes mir verh\u00e4ngen \u2013", "tokens": ["m\u00f6\u00b7ge", "dies", "und", "je\u00b7nes", "mir", "ver\u00b7h\u00e4n\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "KON", "PDS", "PPER", "VVINF", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "doch der Tod muss kommen, uns zu scheiden!", "tokens": ["doch", "der", "Tod", "muss", "kom\u00b7men", ",", "uns", "zu", "schei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "VVINF", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}