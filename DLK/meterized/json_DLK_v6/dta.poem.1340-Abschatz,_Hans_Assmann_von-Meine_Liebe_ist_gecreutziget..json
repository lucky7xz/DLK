{"dta.poem.1340": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Meine Liebe ist gecreutziget.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Weine Zion du Betr\u00fcbte/", "tokens": ["Wei\u00b7ne", "Zi\u00b7on", "du", "Be\u00b7tr\u00fcb\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil dein Heyland der Geliebte", "tokens": ["Weil", "dein", "Hey\u00b7land", "der", "Ge\u00b7lieb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun aus Creutzes Stamm verschmacht!", "tokens": ["Nun", "aus", "Creut\u00b7zes", "Stamm", "ver\u00b7schmacht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Stirbt der Sch\u00f6pffer aller Dinge?", "tokens": ["Stirbt", "der", "Sch\u00f6pf\u00b7fer", "al\u00b7ler", "Din\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Rei\u00df o Himmel! Fel\u00df zerspringe!", "tokens": ["Rei\u00df", "o", "Him\u00b7mel", "!", "Fel\u00df", "zer\u00b7sprin\u00b7ge", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "FM", "NN", "$.", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sonn erschwartz/ und Tag sey Nacht!", "tokens": ["Sonn", "er\u00b7schwartz", "/", "und", "Tag", "sey", "Nacht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "KON", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "An dem Creutz wird meine Liebe/", "tokens": ["An", "dem", "Creutz", "wird", "mei\u00b7ne", "Lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einem M\u00f6rder oder Diebe", "tokens": ["Ei\u00b7nem", "M\u00f6r\u00b7der", "o\u00b7der", "Die\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleich/ die Unschuld umgebracht.", "tokens": ["Gleich", "/", "die", "Un\u00b7schuld", "um\u00b7ge\u00b7bracht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Billich lieb ich den von Hertzen", "tokens": ["Bil\u00b7lich", "lieb", "ich", "den", "von", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "ART", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der in tausend Angst und Schmertzen", "tokens": ["Der", "in", "tau\u00b7send", "Angst", "und", "Schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "CARD", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Meine Schuld hat gut gemacht.", "tokens": ["Mei\u00b7ne", "Schuld", "hat", "gut", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Der am Creutz ist meine Liebe/", "tokens": ["Der", "am", "Creutz", "ist", "mei\u00b7ne", "Lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er mich vom Tod erh\u00fcbe/", "tokens": ["Da\u00df", "er", "mich", "vom", "Tod", "er\u00b7h\u00fc\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird er hier mit Schmach erh\u00f6ht/", "tokens": ["Wird", "er", "hier", "mit", "Schmach", "er\u00b7h\u00f6ht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schau/ wie meine S\u00fcnden-Flecken", "tokens": ["Schau", "/", "wie", "mei\u00b7ne", "S\u00fcn\u00b7den\u00b7Fle\u00b7cken"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "KOKOM", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Abzuwaschen und zu decken/", "tokens": ["Ab\u00b7zu\u00b7wa\u00b7schen", "und", "zu", "de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Blutt aus seiner Seite geht.", "tokens": ["Blutt", "aus", "sei\u00b7ner", "Sei\u00b7te", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Meine Liebe h\u00e4ngt am Creutze/", "tokens": ["Mei\u00b7ne", "Lie\u00b7be", "h\u00e4ngt", "am", "Creut\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPRART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach! da\u00df seine Noth mich reitze/", "tokens": ["Ach", "!", "da\u00df", "sei\u00b7ne", "Noth", "mich", "reit\u00b7ze", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu leben mit der Welt!", "tokens": ["Nicht", "zu", "le\u00b7ben", "mit", "der", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hier will ich mich niederlassen/", "tokens": ["Hier", "will", "ich", "mich", "nie\u00b7der\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Diesen Lebens-Baum umfassen", "tokens": ["Die\u00b7sen", "Le\u00b7bens\u00b7Baum", "um\u00b7fas\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn mich lezte Noth bef\u00e4llt!", "tokens": ["Wenn", "mich", "lez\u00b7te", "Noth", "be\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}