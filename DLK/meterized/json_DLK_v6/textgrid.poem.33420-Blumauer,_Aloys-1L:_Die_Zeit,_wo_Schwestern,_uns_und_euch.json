{"textgrid.poem.33420": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Zeit, wo Schwestern, uns und euch", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Zeit, wo Schwestern, uns und euch", "tokens": ["Die", "Zeit", ",", "wo", "Schwes\u00b7tern", ",", "uns", "und", "euch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "NN", "$,", "PPER", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Geist der Gleichheit wehte,", "tokens": ["Ein", "Geist", "der", "Gleich\u00b7heit", "weh\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo sich kein Frosch in seinem Teich", "tokens": ["Wo", "sich", "kein", "Frosch", "in", "sei\u00b7nem", "Teich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mehr als ein and'rer bl\u00e4hte,", "tokens": ["Mehr", "als", "ein", "an\u00b7d'\u00b7rer", "bl\u00e4h\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "ADJA", "VVFIN", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.5": {"text": "Die gold'ne Zeit, wenn ihr sie kennt,", "tokens": ["Die", "gold'\u00b7ne", "Zeit", ",", "wenn", "ihr", "sie", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dort in dem alten Testament,", "tokens": ["Dort", "in", "dem", "al\u00b7ten", "Tes\u00b7ta\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die soll durch uns auf Erden", "tokens": ["Die", "soll", "durch", "uns", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "APPR", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Einst wieder Mode werden.", "tokens": ["Einst", "wie\u00b7der", "Mo\u00b7de", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wir k\u00f6nnten aus Arkadien", "tokens": ["Wir", "k\u00f6nn\u00b7ten", "aus", "Ar\u00b7ka\u00b7di\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Mode zwar verschreiben;", "tokens": ["Die", "Mo\u00b7de", "zwar", "ver\u00b7schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein ein Maurer, Schwesterchen,", "tokens": ["Al\u00b7lein", "ein", "Mau\u00b7rer", ",", "Schwes\u00b7ter\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Mu\u00df bei der Bibel bleiben;", "tokens": ["Mu\u00df", "bei", "der", "Bi\u00b7bel", "blei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "D'rum, Schwestern, denkt mit uns euch fein", "tokens": ["D'\u00b7rum", ",", "Schwes\u00b7tern", ",", "denkt", "mit", "uns", "euch", "fein"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "$,", "NN", "$,", "VVFIN", "APPR", "PPER", "PPER", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "In jene Lebensart hinein,", "tokens": ["In", "je\u00b7ne", "Le\u00b7ben\u00b7sart", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die uns're ersten Hirten,", "tokens": ["Die", "un\u00b7s'\u00b7re", "ers\u00b7ten", "Hir\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Die Patriarchen, f\u00fchrten.", "tokens": ["Die", "Pat\u00b7ri\u00b7ar\u00b7chen", ",", "f\u00fchr\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die M\u00e4dchen lebten da fortan", "tokens": ["Die", "M\u00e4d\u00b7chen", "leb\u00b7ten", "da", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein paradiesisch Leben:", "tokens": ["Ein", "pa\u00b7ra\u00b7die\u00b7sisch", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie durften sich um einen Mann", "tokens": ["Sie", "durf\u00b7ten", "sich", "um", "ei\u00b7nen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar nicht viel M\u00fche geben;", "tokens": ["Gar", "nicht", "viel", "M\u00fc\u00b7he", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn gleich kein Baron Abraham,", "tokens": ["Wenn", "gleich", "kein", "Ba\u00b7ron", "Ab\u00b7ra\u00b7ham", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Herr von Isaac um sie kam,", "tokens": ["Kein", "Herr", "von", "I\u00b7saac", "um", "sie", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NE", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So gab's doch an der Tr\u00e4nke", "tokens": ["So", "gab's", "doch", "an", "der", "Tr\u00e4n\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Oft M\u00e4nner und Geschenke.", "tokens": ["Oft", "M\u00e4n\u00b7ner", "und", "Ge\u00b7schen\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und kamen nicht sogleich im Trott", "tokens": ["Und", "ka\u00b7men", "nicht", "sog\u00b7leich", "im", "Trott"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die M\u00e4nner angeritten,", "tokens": ["Die", "M\u00e4n\u00b7ner", "an\u00b7ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So durfte man wohl auch zur Noth", "tokens": ["So", "durf\u00b7te", "man", "wohl", "auch", "zur", "Noth"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den n\u00e4chsten besten \u2013 bitten:", "tokens": ["Den", "n\u00e4chs\u00b7ten", "bes\u00b7ten", "\u2013", "bit\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mi\u00df Ruth, zum Beispiel, macht' es so;", "tokens": ["Mi\u00df", "Ruth", ",", "zum", "Bei\u00b7spiel", ",", "macht'", "es", "so", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "APPRART", "NN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie legte sich zu Botz auf's Stroh,", "tokens": ["Sie", "leg\u00b7te", "sich", "zu", "Botz", "auf's", "Stroh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ist doch, wie wir lesen,", "tokens": ["Und", "ist", "doch", ",", "wie", "wir", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die Unschuld selbst gewesen.", "tokens": ["Die", "Un\u00b7schuld", "selbst", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Auch pflegte sich das Gl\u00fcck der Eh'", "tokens": ["Auch", "pfleg\u00b7te", "sich", "das", "Gl\u00fcck", "der", "Eh'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht so geschwind zu enden;", "tokens": ["Nicht", "so", "ge\u00b7schwind", "zu", "en\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn Schnellkraft f\u00fcr Jahrhunderte", "tokens": ["Denn", "Schnell\u00b7kraft", "f\u00fcr", "Jahr\u00b7hun\u00b7der\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lag in der M\u00e4nner Lenden:", "tokens": ["Lag", "in", "der", "M\u00e4n\u00b7ner", "Len\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was jetzo kaum ein Funfziger", "tokens": ["Was", "jet\u00b7zo", "kaum", "ein", "Funf\u00b7zi\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr kann, hat als F\u00fcnfhunderter", "tokens": ["Mehr", "kann", ",", "hat", "als", "F\u00fcnf\u00b7hun\u00b7der\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VMFIN", "$,", "VAFIN", "KOKOM", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Durch Buben, stark wie Riesen,", "tokens": ["Durch", "Bu\u00b7ben", ",", "stark", "wie", "Rie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Herr Abraham bewiesen.", "tokens": ["Herr", "Ab\u00b7ra\u00b7ham", "be\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die Hausfrau wu\u00dfte da nicht viel", "tokens": ["Die", "Haus\u00b7frau", "wu\u00df\u00b7te", "da", "nicht", "viel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Zwang und Etikette,", "tokens": ["Von", "Zwang", "und", "E\u00b7ti\u00b7ket\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ging, so lang es ihr gefiel,", "tokens": ["Und", "ging", ",", "so", "lang", "es", "ihr", "ge\u00b7fiel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "ADJD", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit ihrem Mann zu Bette;", "tokens": ["Mit", "ih\u00b7rem", "Mann", "zu", "Bet\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und war sie nun des Dinges satt,", "tokens": ["Und", "war", "sie", "nun", "des", "Din\u00b7ges", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So konnte sie, wie Sara that,", "tokens": ["So", "konn\u00b7te", "sie", ",", "wie", "Sa\u00b7ra", "that", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "PWAV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dem Manne nach Belieben", "tokens": ["Dem", "Man\u00b7ne", "nach", "Be\u00b7lie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ihr M\u00e4dchen unterschieben.", "tokens": ["Ihr", "M\u00e4d\u00b7chen", "un\u00b7ter\u00b7schie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Den Namen Schwester selbst erfand", "tokens": ["Den", "Na\u00b7men", "Schwes\u00b7ter", "selbst", "er\u00b7fand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Patriarchen gr\u00f6\u00dfter;", "tokens": ["Der", "Pat\u00b7ri\u00b7ar\u00b7chen", "gr\u00f6\u00df\u00b7ter", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er war gen Pharao galant,", "tokens": ["Er", "war", "gen", "Pha\u00b7rao", "ga\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und hie\u00df sein Weibchen Schwester:", "tokens": ["Und", "hie\u00df", "sein", "Weib\u00b7chen", "Schwes\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und seit der Zeit wird jedes Weib,", "tokens": ["Und", "seit", "der", "Zeit", "wird", "je\u00b7des", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem der Gemahl zum Zeitvertreib", "tokens": ["Dem", "der", "Ge\u00b7mahl", "zum", "Zeit\u00b7ver\u00b7treib"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "APPRART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Mehr Br\u00fcderchen verg\u00f6nnet,", "tokens": ["Mehr", "Br\u00fc\u00b7der\u00b7chen", "ver\u00b7g\u00f6n\u00b7net", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.8": {"text": "Ein Schwesterchen genennet.", "tokens": ["Ein", "Schwes\u00b7ter\u00b7chen", "ge\u00b7nen\u00b7net", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}}, "stanza.8": {"line.1": {"text": "Wohlfeil war alles desperat:", "tokens": ["Wohl\u00b7feil", "war", "al\u00b7les", "des\u00b7pe\u00b7rat", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man zahlte keine Zinsen,", "tokens": ["Man", "zahl\u00b7te", "kei\u00b7ne", "Zin\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und kauft' ein ganzes Majorat", "tokens": ["Und", "kauft'", "ein", "gan\u00b7zes", "Ma\u00b7jo\u00b7rat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um eine Sch\u00fcssel Linsen;", "tokens": ["Um", "ei\u00b7ne", "Sch\u00fcs\u00b7sel", "Lin\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das sch\u00f6nste Weib sammt Unterrock,", "tokens": ["Das", "sch\u00f6ns\u00b7te", "Weib", "sammt", "Un\u00b7ter\u00b7rock", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Galt h\u00f6chstens einen Ziegenbock,", "tokens": ["Galt", "h\u00f6chs\u00b7tens", "ei\u00b7nen", "Zie\u00b7gen\u00b7bock", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Jungfern sah man bersten", "tokens": ["Und", "Jung\u00b7fern", "sah", "man", "bers\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PIS", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Um einen Sch\u00e4ffel Gersten.", "tokens": ["Um", "ei\u00b7nen", "Sch\u00e4f\u00b7fel", "Gers\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "O lebtet ihr nur, Schwesterchen,", "tokens": ["O", "leb\u00b7tet", "ihr", "nur", ",", "Schwes\u00b7ter\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "In diesen gold'nen Tagen,", "tokens": ["In", "die\u00b7sen", "gold'\u00b7nen", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es w\u00fcrden da die z\u00e4rtlichen", "tokens": ["Es", "w\u00fcr\u00b7den", "da", "die", "z\u00e4rt\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vapeurs euch nicht mehr plagen;", "tokens": ["Va\u00b7peurs", "euch", "nicht", "mehr", "pla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ihr w\u00e4ret gl\u00fccklich f\u00fcr und f\u00fcr:", "tokens": ["Ihr", "w\u00e4\u00b7ret", "gl\u00fcck\u00b7lich", "f\u00fcr", "und", "f\u00fcr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "KON", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Statt M\u00e4nnerherzen w\u00fcrdet ihr", "tokens": ["Statt", "M\u00e4n\u00b7ner\u00b7her\u00b7zen", "w\u00fcr\u00b7det", "ihr"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NN", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zuweilen Butter r\u00fchren,", "tokens": ["Zu\u00b7wei\u00b7len", "But\u00b7ter", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Um euch zu divertiren.", "tokens": ["Um", "euch", "zu", "di\u00b7ver\u00b7ti\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.10": {"line.1": {"text": "Es w\u00fcrd' euch da kein Darat zwar", "tokens": ["Es", "w\u00fcrd'", "euch", "da", "kein", "Da\u00b7rat", "zwar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PIAT", "NN", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von Ku\u00df und Liebe schreiben;", "tokens": ["Von", "Ku\u00df", "und", "Lie\u00b7be", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch w\u00fcrdet ihr nicht ganz und gar", "tokens": ["Doch", "w\u00fcr\u00b7det", "ihr", "nicht", "ganz", "und", "gar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ununterrichtet bleiben:", "tokens": ["Un\u00b7un\u00b7ter\u00b7rich\u00b7tet", "blei\u00b7ben", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ihr k\u00e4met darum doch an's Ziel,", "tokens": ["Ihr", "k\u00e4\u00b7met", "da\u00b7rum", "doch", "an's", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und lerntet beides, ohne viel", "tokens": ["Und", "lern\u00b7tet", "bei\u00b7des", ",", "oh\u00b7ne", "viel"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "$,", "KOUI", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Franz\u00f6sische Strapatzen", "tokens": ["Fran\u00b7z\u00f6\u00b7si\u00b7sche", "Stra\u00b7pat\u00b7zen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Von Tauben und von Spatzen.", "tokens": ["Von", "Tau\u00b7ben", "und", "von", "Spat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Ihr d\u00fcrftet da, vom Zwange frei,", "tokens": ["Ihr", "d\u00fcrf\u00b7tet", "da", ",", "vom", "Zwan\u00b7ge", "frei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "$,", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht sorgsam calculiren,", "tokens": ["Nicht", "sorg\u00b7sam", "cal\u00b7cu\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie weit es Wohlstandsregel sei,", "tokens": ["Wie", "weit", "es", "Wohl\u00b7stands\u00b7re\u00b7gel", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Busen zu verschn\u00fcren;", "tokens": ["Den", "Bu\u00b7sen", "zu", "ver\u00b7schn\u00fc\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn in dem Stand der Unschuld war", "tokens": ["Denn", "in", "dem", "Stand", "der", "Un\u00b7schuld", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es Mode, blo\u00df in Haut und Haar", "tokens": ["Es", "Mo\u00b7de", ",", "blo\u00df", "in", "Haut", "und", "Haar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "$,", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Herumzugeh'n auf Erden,", "tokens": ["Her\u00b7um\u00b7zu\u00b7geh'n", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und d'rob nicht roth zu werden.", "tokens": ["Und", "d'\u00b7rob", "nicht", "roth", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "D'rum la\u00dft uns bald mit Sack und Pack", "tokens": ["D'\u00b7rum", "la\u00dft", "uns", "bald", "mit", "Sack", "und", "Pack"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "In diese L\u00e4nder reisen:", "tokens": ["In", "die\u00b7se", "L\u00e4n\u00b7der", "rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bei Meister Jubal's Dudelsack", "tokens": ["Bei", "Meis\u00b7ter", "Ju\u00b7bal's", "Du\u00b7del\u00b7sack"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4\u00dft sich's vortrefflich speisen;", "tokens": ["L\u00e4\u00dft", "sich's", "vor\u00b7treff\u00b7lich", "spei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dann wollen wir ohn' Unterla\u00df", "tokens": ["Dann", "wol\u00b7len", "wir", "ohn'", "Un\u00b7ter\u00b7la\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus Vater Noah's vollem Fa\u00df", "tokens": ["Aus", "Va\u00b7ter", "No\u00b7ah's", "vol\u00b7lem", "Fa\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein lautes Salve geben,", "tokens": ["Ein", "lau\u00b7tes", "Sal\u00b7ve", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und singen \u2013 ihr sollt leben!", "tokens": ["Und", "sin\u00b7gen", "\u2013", "ihr", "sollt", "le\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}