{"textgrid.poem.24249": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Fatales Abenteuer einer Dame, die einen neuen Hut aufhatte", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eine sch\u00f6ne Dame ging,", "tokens": ["Ei\u00b7ne", "sch\u00f6\u00b7ne", "Da\u00b7me", "ging", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Trippeltripp,", "tokens": ["Trip\u00b7pel\u00b7tripp", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Spazieren.", "tokens": ["Spa\u00b7zie\u00b7ren", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Ach, was f\u00fcr ein sch\u00f6ner Hut", "tokens": ["Ach", ",", "was", "f\u00fcr", "ein", "sch\u00f6\u00b7ner", "Hut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PRELS", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "T\u00e4t das Haupt ihr zieren!", "tokens": ["T\u00e4t", "das", "Haupt", "ihr", "zie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "War aus Nichts der Hut gemacht,", "tokens": ["War", "aus", "Nichts", "der", "Hut", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War erdichtet, war erdacht,", "tokens": ["War", "er\u00b7dich\u00b7tet", ",", "war", "er\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein seliger Traum, eine reine Idee.", "tokens": ["Ein", "se\u00b7li\u00b7ger", "Traum", ",", "ei\u00b7ne", "rei\u00b7ne", "I\u00b7dee", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Aber ein jeder mu\u00dfte sich sagen:", "tokens": ["A\u00b7ber", "ein", "je\u00b7der", "mu\u00df\u00b7te", "sich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "VMFIN", "PRF", "VVINF", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "O gl\u00fccklich, die ", "tokens": ["O", "gl\u00fcck\u00b7lich", ",", "die"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "ADJD", "$,", "PRELS"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Er stammt aus einem guten Atelier!", "tokens": ["Er", "stammt", "aus", "ei\u00b7nem", "gu\u00b7ten", "A\u00b7te\u00b7lier", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sie m\u00f6chten wissen, woraus er bestand,", "tokens": ["Sie", "m\u00f6ch\u00b7ten", "wis\u00b7sen", ",", "wo\u00b7raus", "er", "be\u00b7stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und denken sicher an allerhand:", "tokens": ["Und", "den\u00b7ken", "si\u00b7cher", "an", "al\u00b7ler\u00b7hand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PIS", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Spitzen, Blumen, Samt, Mull, Stroh", "tokens": ["Spit\u00b7zen", ",", "Blu\u00b7men", ",", "Samt", ",", "Mull", ",", "Stroh"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "VMFIN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder so,", "tokens": ["O\u00b7der", "so", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Seide, Pelzwerk, Filz, Pl\u00fcsch, Band,", "tokens": ["Sei\u00b7de", ",", "Pelz\u00b7werk", ",", "Filz", ",", "Pl\u00fcsch", ",", "Band", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,", "NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und was immer sonst f\u00fcr Tand", "tokens": ["Und", "was", "im\u00b7mer", "sonst", "f\u00fcr", "Tand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "K\u00fcnstlergeist und K\u00fcnstlerhand", "tokens": ["K\u00fcnst\u00b7ler\u00b7geist", "und", "K\u00fcnst\u00b7ler\u00b7hand"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Hold erfand, \u2013", "tokens": ["Hold", "er\u00b7fand", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "$,", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Aber no:", "tokens": ["A\u00b7ber", "no", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Dieser ganze Hut bestand", "tokens": ["Die\u00b7ser", "gan\u00b7ze", "Hut", "be\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Aus dem Vogel T\u00fctr\u00fco,", "tokens": ["Aus", "dem", "Vo\u00b7gel", "T\u00fct\u00b7r\u00fco", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "NE", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.12": {"text": "Der im fernen Inderland", "tokens": ["Der", "im", "fer\u00b7nen", "In\u00b7der\u00b7land"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Irgendwo", "tokens": ["Ir\u00b7gend\u00b7wo"], "token_info": ["word"], "pos": ["ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.14": {"text": "Sich von s\u00fc\u00dfen Fr\u00fcchten n\u00e4hrte,", "tokens": ["Sich", "von", "s\u00fc\u00b7\u00dfen", "Fr\u00fcch\u00b7ten", "n\u00e4hr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Bis das Gl\u00fcck es ihm bescherte,", "tokens": ["Bis", "das", "Gl\u00fcck", "es", "ihm", "be\u00b7scher\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Da\u00df auf einer Prachtfrisur", "tokens": ["Da\u00df", "auf", "ei\u00b7ner", "Pracht\u00b7fri\u00b7sur"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Nicht mehr blo\u00dfe Kreatur,", "tokens": ["Nicht", "mehr", "blo\u00b7\u00dfe", "Kre\u00b7a\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Nein: zur reinen Kunst er werde,", "tokens": ["Nein", ":", "zur", "rei\u00b7nen", "Kunst", "er", "wer\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "APPRART", "ADJA", "NN", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Bl\u00fcte edelster Kultur.", "tokens": ["Bl\u00fc\u00b7te", "e\u00b7dels\u00b7ter", "Kul\u00b7tur", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Seiner fr\u00fcheren Natur", "tokens": ["Sei\u00b7ner", "fr\u00fc\u00b7he\u00b7ren", "Na\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wurde insoferne nur", "tokens": ["Wur\u00b7de", "in\u00b7so\u00b7fer\u00b7ne", "nur"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Etwas Rechnung noch getragen,", "tokens": ["Et\u00b7was", "Rech\u00b7nung", "noch", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als vier Weinbeerln vor ihm lagen.", "tokens": ["Als", "vier", "Wein\u00b7beerln", "vor", "ihm", "la\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Es wird Sie wohl nicht wundernehmen,", "tokens": ["Es", "wird", "Sie", "wohl", "nicht", "wun\u00b7der\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df unsre Dame zufrieden war", "tokens": ["Da\u00df", "uns\u00b7re", "Da\u00b7me", "zu\u00b7frie\u00b7den", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VAFIN"], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Mit diesem ebensowohl bequemen", "tokens": ["Mit", "die\u00b7sem", "e\u00b7ben\u00b7so\u00b7wohl", "be\u00b7que\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADV", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie geschmackvollen Schmuck auf ihrem Haar.", "tokens": ["Wie", "ge\u00b7schmack\u00b7vol\u00b7len", "Schmuck", "auf", "ih\u00b7rem", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Sie konnte sich selbst nicht satt dran sehen", "tokens": ["Sie", "konn\u00b7te", "sich", "selbst", "nicht", "satt", "dran", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "PTKNEG", "ADJD", "PAV", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und blieb, wo nur ein Spiegel war,", "tokens": ["Und", "blieb", ",", "wo", "nur", "ein", "Spie\u00b7gel", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit heitrem Antlitz selig stehen", "tokens": ["Mit", "heit\u00b7rem", "Ant\u00b7litz", "se\u00b7lig", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und fand ihn wieder und immer wieder,", "tokens": ["Und", "fand", "ihn", "wie\u00b7der", "und", "im\u00b7mer", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "KON", "ADV", "ADV", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Vorm Juwelier wie vorm Konditer,", "tokens": ["Vorm", "Ju\u00b7we\u00b7lier", "wie", "vorm", "Kon\u00b7di\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Einfach s\u00fc\u00df und wunderbar.", "tokens": ["Ein\u00b7fach", "s\u00fc\u00df", "und", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Der sch\u00f6ne Vogel T\u00fctr\u00fco", "tokens": ["Der", "sch\u00f6\u00b7ne", "Vo\u00b7gel", "T\u00fct\u00b7r\u00fco"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "War aber nicht vollkommen so", "tokens": ["War", "a\u00b7ber", "nicht", "voll\u00b7kom\u00b7men", "so"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie seine Dame des Daseins froh:", "tokens": ["Wie", "sei\u00b7ne", "Da\u00b7me", "des", "Da\u00b7seins", "froh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "NN", "ADJD", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Er fand es vielmehr bl\u00f6de", "tokens": ["Er", "fand", "es", "viel\u00b7mehr", "bl\u00f6\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und \u00f6de,", "tokens": ["Und", "\u00f6\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Ganz ohne Unterlage von Stroh", "tokens": ["Ganz", "oh\u00b7ne", "Un\u00b7ter\u00b7la\u00b7ge", "von", "Stroh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Allein mit seinem Fl\u00fcgelpaar", "tokens": ["Al\u00b7lein", "mit", "sei\u00b7nem", "Fl\u00fc\u00b7gel\u00b7paar"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Einen Hut zu bilden auf blo\u00dfem Haar,", "tokens": ["Ei\u00b7nen", "Hut", "zu", "bil\u00b7den", "auf", "blo\u00b7\u00dfem", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Und zwar", "tokens": ["Und", "zwar"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "(was ihm besonders peinlich war)", "tokens": ["(", "was", "ihm", "be\u00b7son\u00b7ders", "pein\u00b7lich", "war", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PPER", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Gratis und ohne Honorar.", "tokens": ["Gra\u00b7tis", "und", "oh\u00b7ne", "Ho\u00b7no\u00b7rar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Drum nahm er die Gelegenheit wahr,", "tokens": ["Drum", "nahm", "er", "die", "Ge\u00b7le\u00b7gen\u00b7heit", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Als seine Dame mit einem Herren konversierte,", "tokens": ["Als", "sei\u00b7ne", "Da\u00b7me", "mit", "ei\u00b7nem", "Her\u00b7ren", "kon\u00b7ver\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ART", "NN", "VMFIN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der auf einem stattlichen Rotfuchs sa\u00df,", "tokens": ["Der", "auf", "ei\u00b7nem", "statt\u00b7li\u00b7chen", "Rot\u00b7fuchs", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und fra\u00df", "tokens": ["Und", "fra\u00df"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Eine der Weinbeerln, die ihn schon lange intrigierte;", "tokens": ["Ei\u00b7ne", "der", "Wein\u00b7beerln", ",", "die", "ihn", "schon", "lan\u00b7ge", "int\u00b7ri\u00b7gier\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+--++-+-+-+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Wobei es ihn im mindesten nicht genierte,", "tokens": ["Wo\u00b7bei", "es", "ihn", "im", "min\u00b7des\u00b7ten", "nicht", "ge\u00b7nier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "APPRART", "ADJA", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Da\u00df sie aus Wachs war oder Glas.", "tokens": ["Da\u00df", "sie", "aus", "Wachs", "war", "o\u00b7der", "Glas", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VAFIN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Im Gegenteil, sie schmeckte ihm sehr gut", "tokens": ["Im", "Ge\u00b7gen\u00b7teil", ",", "sie", "schmeck\u00b7te", "ihm", "sehr", "gut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "(vielleicht in seiner Eigenschaft als Hut),", "tokens": ["(", "viel\u00b7leicht", "in", "sei\u00b7ner", "Ei\u00b7gen\u00b7schaft", "als", "Hut", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "APPR", "PPOSAT", "NN", "KOUS", "NN", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und so fra\u00df er auch die zweite, die dritte, die vierte.", "tokens": ["Und", "so", "fra\u00df", "er", "auch", "die", "zwei\u00b7te", ",", "die", "drit\u00b7te", ",", "die", "vier\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "$,", "ART", "ADJA", "$,", "ART", "ADJA", "$."], "meter": "--+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Und, wie die Dame weiter kokettierte,", "tokens": ["Und", ",", "wie", "die", "Da\u00b7me", "wei\u00b7ter", "ko\u00b7ket\u00b7tier\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Tat er, was jeder Vogel tut,", "tokens": ["Tat", "er", ",", "was", "je\u00b7der", "Vo\u00b7gel", "tut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Der sich an Fr\u00fcchten delektierte", "tokens": ["Der", "sich", "an", "Fr\u00fcch\u00b7ten", "de\u00b7lek\u00b7tier\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "NN", "VVFIN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.14": {"text": "(glas oder Wachs geht ebenso ins Blut),", "tokens": ["(", "glas", "o\u00b7der", "Wachs", "geht", "e\u00b7ben\u00b7so", "ins", "Blut", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "KON", "NN", "VVFIN", "ADV", "APPRART", "NN", "$(", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.15": {"text": "Das hei\u00dft: er lud", "tokens": ["Das", "hei\u00dft", ":", "er", "lud"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "$.", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Ein gr\u00fcnlich-wei\u00dfes H\u00e4ufchen ab und sang", "tokens": ["Ein", "gr\u00fcn\u00b7lich\u00b7wei\u00b7\u00dfes", "H\u00e4uf\u00b7chen", "ab", "und", "sang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Kwit\u00fc \u2013 tr\u00fco! Kwit\u00fc \u2013 tr\u00fco!", "tokens": ["Kwi\u00b7t\u00fc", "\u2013", "tr\u00fco", "!", "Kwi\u00b7t\u00fc", "\u2013", "tr\u00fco", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "FM", "$.", "NE", "$(", "FM", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.18": {"text": "(daher der Name T\u00fctr\u00fco!)", "tokens": ["(", "da\u00b7her", "der", "Na\u00b7me", "T\u00fct\u00b7r\u00fco", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "ART", "NN", "NE", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Und schwang", "tokens": ["Und", "schwang"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.20": {"text": "Sich in die heitre Bl\u00e4ue", "tokens": ["Sich", "in", "die", "heit\u00b7re", "Bl\u00e4u\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Ganz ohne Scheu und Treue", "tokens": ["Ganz", "oh\u00b7ne", "Scheu", "und", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.22": {"text": "Und Reue.", "tokens": ["Und", "Reu\u00b7e", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.8": {"line.1": {"text": "O himmlische Gnade! O g\u00fctiger Gott!", "tokens": ["O", "himm\u00b7li\u00b7sche", "Gna\u00b7de", "!", "O", "g\u00fc\u00b7ti\u00b7ger", "Gott", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "NE", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Dame war nun ohne Kapott.", "tokens": ["Die", "Da\u00b7me", "war", "nun", "oh\u00b7ne", "Ka\u00b7pott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Hutlos,", "tokens": ["Hut\u00b7los", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Mutlos,", "tokens": ["Mut\u00b7los", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Schwere Not,", "tokens": ["Schwe\u00b7re", "Not", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Stand sie auf der Stra\u00dfe,", "tokens": ["Stand", "sie", "auf", "der", "Stra\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Und, weil es November war,", "tokens": ["Und", ",", "weil", "es", "No\u00b7vem\u00b7ber", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Fuhr der Wind ihr durch das Haar", "tokens": ["Fuhr", "der", "Wind", "ihr", "durch", "das", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "W\u00fctend mit Geblase.", "tokens": ["W\u00fc\u00b7tend", "mit", "Ge\u00b7bla\u00b7se", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Wie der Rotfuchs das erblickte,", "tokens": ["Wie", "der", "Rot\u00b7fuchs", "das", "er\u00b7blick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "ADJA", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Drauf der Reiter sa\u00df,", "tokens": ["Drauf", "der", "Rei\u00b7ter", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Blicke der Wehmut gen Himmel er schickte,", "tokens": ["Bli\u00b7cke", "der", "Weh\u00b7mut", "gen", "Him\u00b7mel", "er", "schick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Tr\u00e4nen er sechse im Auge zerdr\u00fcckte,", "tokens": ["Tr\u00e4\u00b7nen", "er", "sech\u00b7se", "im", "Au\u00b7ge", "zer\u00b7dr\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Aber das Haar er ", "tokens": ["A\u00b7ber", "das", "Haar", "er"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPER"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.10": {"line.1": {"text": "Denn sein Sohnesherz erkannte:", "tokens": ["Denn", "sein", "Soh\u00b7nes\u00b7herz", "er\u00b7kann\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Derer, die er Mutter nannte,", "tokens": ["De\u00b7rer", ",", "die", "er", "Mut\u00b7ter", "nann\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Roter Schweif war dies,", "tokens": ["Ro\u00b7ter", "Schweif", "war", "dies", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PDS", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Eh der Menschen Eigennutz und T\u00fccke,", "tokens": ["Eh", "der", "Men\u00b7schen", "Ei\u00b7gen\u00b7nutz", "und", "T\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Kalt der andren Gottgesch\u00f6pfe Gl\u00fccke,", "tokens": ["Kalt", "der", "an\u00b7dren", "Gott\u00b7ge\u00b7sch\u00f6p\u00b7fe", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Unbarmherzig hin sie morden lie\u00df,", "tokens": ["Un\u00b7barm\u00b7her\u00b7zig", "hin", "sie", "mor\u00b7den", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PPER", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Da\u00df des stolzen Schweifes R\u00f6te", "tokens": ["Da\u00df", "des", "stol\u00b7zen", "Schwei\u00b7fes", "R\u00f6\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Als Per\u00fccke", "tokens": ["Als", "Pe\u00b7r\u00fc\u00b7cke"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Jener Dame Hauptschmuck b\u00f6te.", "tokens": ["Je\u00b7ner", "Da\u00b7me", "Haupt\u00b7schmuck", "b\u00f6\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ja, er fra\u00df es ganz und gar,", "tokens": ["Ja", ",", "er", "fra\u00df", "es", "ganz", "und", "gar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADV", "KON", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Piet\u00e4tvoll, wie er war,", "tokens": ["Pie\u00b7t\u00e4t\u00b7voll", ",", "wie", "er", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dieses sch\u00f6ne rote Haar.", "tokens": ["Die\u00b7ses", "sch\u00f6\u00b7ne", "ro\u00b7te", "Haar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Die Dame aber bekam einen Katarrh.", "tokens": ["Die", "Da\u00b7me", "a\u00b7ber", "be\u00b7kam", "ei\u00b7nen", "Ka\u00b7tarrh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Denn der November ist nicht zart", "tokens": ["Denn", "der", "No\u00b7vem\u00b7ber", "ist", "nicht", "zart"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit denen, welche unbehaart", "tokens": ["Mit", "de\u00b7nen", ",", "wel\u00b7che", "un\u00b7be\u00b7haart"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und unbehutet sind.", "tokens": ["Und", "un\u00b7be\u00b7hu\u00b7tet", "sind", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da schadet schon der kleinste Wind.", "tokens": ["Da", "scha\u00b7det", "schon", "der", "kleins\u00b7te", "Wind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Sie f\u00fchlt sich auch heute noch gar nicht wohl,", "tokens": ["Sie", "f\u00fchlt", "sich", "auch", "heu\u00b7te", "noch", "gar", "nicht", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "ADV", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Trotz Antikatarrhin und Sozojodol.", "tokens": ["Trotz", "An\u00b7ti\u00b7ka\u00b7tar\u00b7rhin", "und", "So\u00b7zo\u00b7jo\u00b7dol", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}}}}