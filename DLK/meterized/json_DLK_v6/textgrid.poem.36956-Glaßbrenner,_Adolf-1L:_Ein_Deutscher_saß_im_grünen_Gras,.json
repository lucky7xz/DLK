{"textgrid.poem.36956": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Deutscher sa\u00df im gr\u00fcnen Gras,", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Deutscher sa\u00df im gr\u00fcnen Gras,", "tokens": ["Ein", "Deut\u00b7scher", "sa\u00df", "im", "gr\u00fc\u00b7nen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wollte da studiren was,", "tokens": ["Und", "woll\u00b7te", "da", "stu\u00b7di\u00b7ren", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lateinisch und auch griechisch", "tokens": ["La\u00b7tei\u00b7nisch", "und", "auch", "grie\u00b7chisch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und etwas philosophisch.", "tokens": ["Und", "et\u00b7was", "phi\u00b7lo\u00b7so\u00b7phisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Da kam eine Fliege und kitzelt ihn,", "tokens": ["Da", "kam", "ei\u00b7ne", "Flie\u00b7ge", "und", "kit\u00b7zelt", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Da\u00df er mu\u00dft's Gesicht verziehn:", "tokens": ["Da\u00df", "er", "mu\u00dft's", "Ge\u00b7sicht", "ver\u00b7ziehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "\u00bbfliege, la\u00df' das Kitzeln!\u00ab", "tokens": ["\u00bb", "flie\u00b7ge", ",", "la\u00df'", "das", "Kit\u00b7zeln", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVIMP", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Die Fliege kitzelt weiter.", "tokens": ["Die", "Flie\u00b7ge", "kit\u00b7zelt", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ein Deutscher sa\u00df im gr\u00fcnen Gras,", "tokens": ["Ein", "Deut\u00b7scher", "sa\u00df", "im", "gr\u00fc\u00b7nen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wollte da studiren was,", "tokens": ["Und", "woll\u00b7te", "da", "stu\u00b7di\u00b7ren", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lateinisch und auch griechisch", "tokens": ["La\u00b7tei\u00b7nisch", "und", "auch", "grie\u00b7chisch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und etwas philosophisch.", "tokens": ["Und", "et\u00b7was", "phi\u00b7lo\u00b7so\u00b7phisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Da flog eine Wesp' ihm auf die Nas',", "tokens": ["Da", "flog", "ei\u00b7ne", "Wesp'", "ihm", "auf", "die", "Nas'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und stach ihm eine gro\u00dfe Blas',", "tokens": ["Und", "stach", "ihm", "ei\u00b7ne", "gro\u00b7\u00dfe", "Blas'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbwespe, la\u00df' das Stechen!\u00ab", "tokens": ["\u00bb", "wes\u00b7pe", ",", "la\u00df'", "das", "Ste\u00b7chen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVIMP", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Die Fliege kitzelt weiter,", "tokens": ["Die", "Flie\u00b7ge", "kit\u00b7zelt", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die Wespe sticht ihm Blasen.", "tokens": ["Die", "Wes\u00b7pe", "sticht", "ihm", "Bla\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ein Deutscher sa\u00df im gr\u00fcnen Gras,", "tokens": ["Ein", "Deut\u00b7scher", "sa\u00df", "im", "gr\u00fc\u00b7nen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wollte da studiren was,", "tokens": ["Und", "woll\u00b7te", "da", "stu\u00b7di\u00b7ren", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lateinisch und auch griechisch", "tokens": ["La\u00b7tei\u00b7nisch", "und", "auch", "grie\u00b7chisch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und etwas philosophisch.", "tokens": ["Und", "et\u00b7was", "phi\u00b7lo\u00b7so\u00b7phisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Da sprang ein Floh ihm auf die Brust;", "tokens": ["Da", "sprang", "ein", "Floh", "ihm", "auf", "die", "Brust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und peinigt ihn nach Herzenslust:", "tokens": ["Und", "pei\u00b7nigt", "ihn", "nach", "Her\u00b7zens\u00b7lust", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbfloh, la\u00df' mich zufrieden!\u00ab", "tokens": ["\u00bb", "floh", ",", "la\u00df'", "mich", "zu\u00b7frie\u00b7den", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVIMP", "PPER", "ADJD", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Die Fliege kitzelt weiter,", "tokens": ["Die", "Flie\u00b7ge", "kit\u00b7zelt", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die Wespe sticht ihm Blasen,", "tokens": ["Die", "Wes\u00b7pe", "sticht", "ihm", "Bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der Floh, der peinigt st\u00e4rker.", "tokens": ["Der", "Floh", ",", "der", "pei\u00b7nigt", "st\u00e4r\u00b7ker", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ein Deutscher sa\u00df im gr\u00fcnen Gras,", "tokens": ["Ein", "Deut\u00b7scher", "sa\u00df", "im", "gr\u00fc\u00b7nen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wollte da studiren was,", "tokens": ["Und", "woll\u00b7te", "da", "stu\u00b7di\u00b7ren", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lateinisch und auch griechisch", "tokens": ["La\u00b7tei\u00b7nisch", "und", "auch", "grie\u00b7chisch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und etwas philosophisch.", "tokens": ["Und", "et\u00b7was", "phi\u00b7lo\u00b7so\u00b7phisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Da kam ein gro\u00dfer Hund daher,", "tokens": ["Da", "kam", "ein", "gro\u00b7\u00dfer", "Hund", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der bi\u00df in's Bein ihm gar zu sehr:", "tokens": ["Der", "bi\u00df", "in's", "Bein", "ihm", "gar", "zu", "sehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "APPRART", "NN", "PPER", "ADV", "PTKA", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbhund, du l\u00e4\u00dft das Bei\u00dfen!\u00ab", "tokens": ["\u00bb", "hund", ",", "du", "l\u00e4\u00dft", "das", "Bei\u00b7\u00dfen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Die Fliege kitzelt weiter,", "tokens": ["Die", "Flie\u00b7ge", "kit\u00b7zelt", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die Wespe sticht ihm Blasen,", "tokens": ["Die", "Wes\u00b7pe", "sticht", "ihm", "Bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der Floh, der peinigt st\u00e4rker,", "tokens": ["Der", "Floh", ",", "der", "pei\u00b7nigt", "st\u00e4r\u00b7ker", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der Hund, der bei\u00dft gewaltig.", "tokens": ["Der", "Hund", ",", "der", "bei\u00dft", "ge\u00b7wal\u00b7tig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ein Deutscher sa\u00df im gr\u00fcnen Gras,", "tokens": ["Ein", "Deut\u00b7scher", "sa\u00df", "im", "gr\u00fc\u00b7nen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wollte da studiren was,", "tokens": ["Und", "woll\u00b7te", "da", "stu\u00b7di\u00b7ren", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lateinisch und auch griechisch", "tokens": ["La\u00b7tei\u00b7nisch", "und", "auch", "grie\u00b7chisch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und etwas philosophisch.", "tokens": ["Und", "et\u00b7was", "phi\u00b7lo\u00b7so\u00b7phisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Da kroch ein Egel ihm auf's Herz,", "tokens": ["Da", "kroch", "ein", "E\u00b7gel", "ihm", "auf's", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sog ihm Blut zu gro\u00dfem Schmerz:", "tokens": ["Und", "sog", "ihm", "Blut", "zu", "gro\u00b7\u00dfem", "Schmerz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbegel, la\u00df' das Saugen!\u00ab", "tokens": ["\u00bb", "e\u00b7gel", ",", "la\u00df'", "das", "Sau\u00b7gen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "$,", "VVIMP", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Die Fliege kitzelt weiter,", "tokens": ["Die", "Flie\u00b7ge", "kit\u00b7zelt", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die Wespe sticht ihm Blasen,", "tokens": ["Die", "Wes\u00b7pe", "sticht", "ihm", "Bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der Floh, der peinigt st\u00e4rker,", "tokens": ["Der", "Floh", ",", "der", "pei\u00b7nigt", "st\u00e4r\u00b7ker", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der Hund, der bei\u00dft gewaltig,", "tokens": ["Der", "Hund", ",", "der", "bei\u00dft", "ge\u00b7wal\u00b7tig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Der Egel saugt am Herzen.", "tokens": ["Der", "E\u00b7gel", "saugt", "am", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ein Deutscher sa\u00df im gr\u00fcnen Gras,", "tokens": ["Ein", "Deut\u00b7scher", "sa\u00df", "im", "gr\u00fc\u00b7nen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wollte da studiren was,", "tokens": ["Und", "woll\u00b7te", "da", "stu\u00b7di\u00b7ren", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lateinisch und auch griechisch", "tokens": ["La\u00b7tei\u00b7nisch", "und", "auch", "grie\u00b7chisch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und etwas philosophisch.", "tokens": ["Und", "et\u00b7was", "phi\u00b7lo\u00b7so\u00b7phisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Da stie\u00df ein Ochs ihm vor den Kopf,", "tokens": ["Da", "stie\u00df", "ein", "Ochs", "ihm", "vor", "den", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbochse, la\u00df' das Sto\u00dfen!\u00ab", "tokens": ["\u00bb", "oc\u00b7hse", ",", "la\u00df'", "das", "Sto\u00b7\u00dfen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVIMP", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Die Fliege kitzelt weiter,", "tokens": ["Die", "Flie\u00b7ge", "kit\u00b7zelt", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die Wespe sticht ihm Blasen,", "tokens": ["Die", "Wes\u00b7pe", "sticht", "ihm", "Bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Der Floh, der peinigt st\u00e4rker,", "tokens": ["Der", "Floh", ",", "der", "pei\u00b7nigt", "st\u00e4r\u00b7ker", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der Hund, der bei\u00dft gewaltig,", "tokens": ["Der", "Hund", ",", "der", "bei\u00dft", "ge\u00b7wal\u00b7tig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der Egel saugt am Herzen,", "tokens": ["Der", "E\u00b7gel", "saugt", "am", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Der Ochs st\u00f6\u00dft vor den Kopf ihm.", "tokens": ["Der", "Ochs", "st\u00f6\u00dft", "vor", "den", "Kopf", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Zuletzt ist er gestorben nun,", "tokens": ["Zu\u00b7letzt", "ist", "er", "ge\u00b7stor\u00b7ben", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um von den Qualen auszuruhn,", "tokens": ["Um", "von", "den", "Qua\u00b7len", "aus\u00b7zu\u00b7ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sah' ich auf dem Denkmal stahn:", "tokens": ["Da", "sah'", "ich", "auf", "dem", "Denk\u00b7mal", "stahn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdas war ein braver Unterthan.", "tokens": ["\u00bb", "das", "war", "ein", "bra\u00b7ver", "Un\u00b7ter\u00b7than", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Fliege th\u00e4t ihn kitzeln,", "tokens": ["Die", "Flie\u00b7ge", "th\u00e4t", "ihn", "kit\u00b7zeln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die Wespe th\u00e4t ihn stechen,", "tokens": ["Die", "Wes\u00b7pe", "th\u00e4t", "ihn", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der Floh hat ihn gepeinigt,", "tokens": ["Der", "Floh", "hat", "ihn", "ge\u00b7pei\u00b7nigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Der Hund hat ihn gebi\u00dfen,", "tokens": ["Der", "Hund", "hat", "ihn", "ge\u00b7bi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Der Egel sog ihm's Blut aus,", "tokens": ["Der", "E\u00b7gel", "sog", "ihm's", "Blut", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der Ochse th\u00e4t ihn sto\u00dfen:", "tokens": ["Der", "O\u00b7chse", "th\u00e4t", "ihn", "sto\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Es that ihn Nichts erbo\u00dfen.\u00ab", "tokens": ["Es", "that", "ihn", "Nichts", "er\u00b7bo\u00b7\u00dfen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}