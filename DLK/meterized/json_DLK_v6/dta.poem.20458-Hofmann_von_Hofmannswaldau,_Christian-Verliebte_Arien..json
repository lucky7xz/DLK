{"dta.poem.20458": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Verliebte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich singe tauben ohren/", "tokens": ["Ich", "sin\u00b7ge", "tau\u00b7ben", "oh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dein sch\u00f6nes antlitz kennt mich nicht/", "tokens": ["Dein", "sch\u00f6\u00b7nes", "ant\u00b7litz", "kennt", "mich", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hab ich der freundschafft s\u00fcsses licht/", "tokens": ["Hab", "ich", "der", "freund\u00b7schafft", "s\u00fcs\u00b7ses", "licht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein bestes kleinod gantz verlohren?", "tokens": ["Mein", "bes\u00b7tes", "klei\u00b7nod", "gantz", "ver\u00b7loh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wird denn mein tag zu d\u00fcstrer nacht?", "tokens": ["Wird", "denn", "mein", "tag", "zu", "d\u00fcst\u00b7rer", "nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Soll ich mich lebendig begraben?", "tokens": ["Soll", "ich", "mich", "le\u00b7ben\u00b7dig", "be\u00b7gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADJD", "VVPP", "$."], "meter": "---+---+-", "measure": "unknown.measure.di"}, "line.7": {"text": "Und deiner augen sch\u00f6ne pracht/", "tokens": ["Und", "dei\u00b7ner", "au\u00b7gen", "sch\u00f6\u00b7ne", "pracht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So vormahls sonne war/ itzt zu cometen haben?", "tokens": ["So", "vor\u00b7mahls", "son\u00b7ne", "war", "/", "itzt", "zu", "co\u00b7me\u00b7ten", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "$(", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was sind es doch f\u00fcr s\u00fcnden/", "tokens": ["Was", "sind", "es", "doch", "f\u00fcr", "s\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Davor ich peinlich b\u00fcssen mu\u00df/", "tokens": ["Da\u00b7vor", "ich", "pein\u00b7lich", "b\u00fcs\u00b7sen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und aller schmertzen \u00fcberflu\u00df/", "tokens": ["Und", "al\u00b7ler", "schmert\u00b7zen", "\u00fc\u00b7berf\u00b7lu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als \u00fcbelth\u00e4ter/ itzt empfinden?", "tokens": ["Als", "\u00fc\u00b7belt\u00b7h\u00e4\u00b7ter", "/", "itzt", "emp\u00b7fin\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$(", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch la\u00df der \u00fcbelth\u00e4ter recht", "tokens": ["Doch", "la\u00df", "der", "\u00fc\u00b7belt\u00b7h\u00e4\u00b7ter", "recht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich/ eh\u2019 ich sterbe/ nur geniessen!", "tokens": ["Mich", "/", "eh'", "ich", "ster\u00b7be", "/", "nur", "ge\u00b7nies\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$(", "KOUS", "PPER", "VVFIN", "$(", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und mache/ da\u00df dein armer knecht/", "tokens": ["Und", "ma\u00b7che", "/", "da\u00df", "dein", "ar\u00b7mer", "knecht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was er verbrochen hat/ mag vor dem tode wissen.", "tokens": ["Was", "er", "ver\u00b7bro\u00b7chen", "hat", "/", "mag", "vor", "dem", "to\u00b7de", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$(", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Vor was hab ich zu b\u00fcssen?", "tokens": ["Vor", "was", "hab", "ich", "zu", "b\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VAFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Vor g\u00f6ttin hab ich dich erkennt/", "tokens": ["Vor", "g\u00f6t\u00b7tin", "hab", "ich", "dich", "er\u00b7kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein hertz als weyrauch dir gebrennt/", "tokens": ["Mein", "hertz", "als", "wey\u00b7rauch", "dir", "ge\u00b7brennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOUS", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mich gelegt zu deinen f\u00fcssen.", "tokens": ["Und", "mich", "ge\u00b7legt", "zu", "dei\u00b7nen", "f\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Strafft mich der himmel oder du?", "tokens": ["Strafft", "mich", "der", "him\u00b7mel", "o\u00b7der", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "KON", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir hab ich mich in mir verzehret!", "tokens": ["Dir", "hab", "ich", "mich", "in", "mir", "ver\u00b7zeh\u00b7ret", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der himmel st\u00fcrmet auff mich zu/", "tokens": ["Der", "him\u00b7mel", "st\u00fcr\u00b7met", "auff", "mich", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dieweil ich dir zu viel/ und ihm fast nichts gew\u00e4hret.", "tokens": ["Die\u00b7weil", "ich", "dir", "zu", "viel", "/", "und", "ihm", "fast", "nichts", "ge\u00b7w\u00e4h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "PIAT", "$(", "KON", "PPER", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ach z\u00fcrne nicht/ Melinde/", "tokens": ["Ach", "z\u00fcr\u00b7ne", "nicht", "/", "Me\u00b7lin\u00b7de", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "VVFIN", "PTKNEG", "$(", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So mir di\u00df freche wort entf\u00e4hrt!", "tokens": ["So", "mir", "di\u00df", "fre\u00b7che", "wort", "ent\u00b7f\u00e4hrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PDS", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein s\u00fcnder ist erbarmens werth.", "tokens": ["Ein", "s\u00fcn\u00b7der", "ist", "er\u00b7bar\u00b7mens", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du f\u00fchlest nicht/ was ich empfinde!", "tokens": ["Du", "f\u00fch\u00b7lest", "nicht", "/", "was", "ich", "emp\u00b7fin\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht lache/ wenn dein sclave f\u00e4llt/", "tokens": ["Nicht", "la\u00b7che", "/", "wenn", "dein", "scla\u00b7ve", "f\u00e4llt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$(", "KOUS", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du weist/ verwirret seyn/ und lieben", "tokens": ["Du", "weist", "/", "ver\u00b7wir\u00b7ret", "seyn", "/", "und", "lie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "VAINF", "$(", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hat allbereit die erste welt", "tokens": ["Hat", "all\u00b7be\u00b7reit", "die", "ers\u00b7te", "welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit schrifft/ die nicht verlescht/ zusam\u0303en eingeschrieben.", "tokens": ["Mit", "schrifft", "/", "die", "nicht", "ver\u00b7lescht", "/", "zu\u00b7sam\u0303en", "ein\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "$(", "PRELS", "PTKNEG", "VVPP", "$(", "ADV", "VVPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Doch wilt du g\u00f6ttin heissen/", "tokens": ["Doch", "wilt", "du", "g\u00f6t\u00b7tin", "heis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "NE", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu der dich deine tugend macht?", "tokens": ["Zu", "der", "dich", "dei\u00b7ne", "tu\u00b7gend", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So must du auch bey solcher pracht", "tokens": ["So", "must", "du", "auch", "bey", "sol\u00b7cher", "pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dich der erbarmung stets befleissen.", "tokens": ["Dich", "der", "er\u00b7bar\u00b7mung", "stets", "be\u00b7fleis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Rei\u00df deinen kalten f\u00fcrwitz ein/", "tokens": ["Rei\u00df", "dei\u00b7nen", "kal\u00b7ten", "f\u00fcr\u00b7witz", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und mache meine noth zum schertze/", "tokens": ["Und", "ma\u00b7che", "mei\u00b7ne", "noth", "zum", "schert\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die h\u00f6lle lehret grausam seyn/", "tokens": ["Die", "h\u00f6l\u00b7le", "leh\u00b7ret", "grau\u00b7sam", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der himmel/ den du gleichst/ vertr\u00e4gt kein steinern hertze.", "tokens": ["Der", "him\u00b7mel", "/", "den", "du", "gleichst", "/", "ver\u00b7tr\u00e4gt", "kein", "stei\u00b7nern", "hert\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "PPER", "ADV", "$(", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}