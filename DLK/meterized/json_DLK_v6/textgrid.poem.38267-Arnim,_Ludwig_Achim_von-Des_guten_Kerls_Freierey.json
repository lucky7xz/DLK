{"textgrid.poem.38267": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Des guten Kerls Freierey", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einstens, da ich Lust bekam,", "tokens": ["Eins\u00b7tens", ",", "da", "ich", "Lust", "be\u00b7kam", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir zu freien eine Dam,", "tokens": ["Mir", "zu", "frei\u00b7en", "ei\u00b7ne", "Dam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sie freundlich fragte,", "tokens": ["Und", "sie", "freund\u00b7lich", "frag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ob ich ihr auch wohl gefiel;", "tokens": ["Ob", "ich", "ihr", "auch", "wohl", "ge\u00b7fiel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wahrlich nicht besonder viel!", "tokens": ["Wahr\u00b7lich", "nicht", "be\u00b7son\u00b7der", "viel", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie gar sp\u00f6ttisch sagte.", "tokens": ["Sie", "gar", "sp\u00f6t\u00b7tisch", "sag\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Ich sprach wieder: Bin ich nicht", "tokens": ["Ich", "sprach", "wie\u00b7der", ":", "Bin", "ich", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$.", "VAFIN", "PPER", "PTKNEG"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ein gut Kerle, gebt Bericht.", "tokens": ["Ein", "gut", "Ker\u00b7le", ",", "gebt", "Be\u00b7richt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Drauf fragt sie mich wieder:", "tokens": ["Drauf", "fragt", "sie", "mich", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Was dann ein gut Kerle w\u00e4r?", "tokens": ["Was", "dann", "ein", "gut", "Ker\u00b7le", "w\u00e4r", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJD", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich sprach: Sezt euch unbeschwert", "tokens": ["Ich", "sprach", ":", "Sezt", "euch", "un\u00b7be\u00b7schwert"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PPER", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Etwas zu mir nieder.", "tokens": ["Et\u00b7was", "zu", "mir", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "F\u00fcr das Erst so bin ich recht,", "tokens": ["F\u00fcr", "das", "Erst", "so", "bin", "ich", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und von ehrlichem Geschlecht,", "tokens": ["Und", "von", "ehr\u00b7li\u00b7chem", "Ge\u00b7schlecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hab auch aller Orten", "tokens": ["Hab", "auch", "al\u00b7ler", "Or\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mich ge\u00fcbt von Jugend auf,", "tokens": ["Mich", "ge\u00b7\u00fcbt", "von", "Ju\u00b7gend", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nach der Welt Gebrauch und Lauf,", "tokens": ["Nach", "der", "Welt", "Ge\u00b7brauch", "und", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ich gro\u00df bin worden.", "tokens": ["Da\u00df", "ich", "gro\u00df", "bin", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "VAPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Habe auch nicht viel studiert,", "tokens": ["Ha\u00b7be", "auch", "nicht", "viel", "stu\u00b7diert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bin nicht sch\u00f6n von Leib geziert,", "tokens": ["Bin", "nicht", "sch\u00f6n", "von", "Leib", "ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch nicht reich von Gelde;", "tokens": ["Auch", "nicht", "reich", "von", "Gel\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "APPR", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Dennoch bin ich auch nicht dumm,", "tokens": ["Den\u00b7noch", "bin", "ich", "auch", "nicht", "dumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Blind, lahm, sprachlos oder krumm,", "tokens": ["Blind", ",", "lahm", ",", "sprach\u00b7los", "o\u00b7der", "krumm", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sondern frisch zu Felde.", "tokens": ["Son\u00b7dern", "frisch", "zu", "Fel\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Zu der Kaufmannschaft und auch", "tokens": ["Zu", "der", "Kauf\u00b7mann\u00b7schaft", "und", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu dem Handwerk ich nicht taug,", "tokens": ["Zu", "dem", "Hand\u00b7werk", "ich", "nicht", "taug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern mich ern\u00e4hre", "tokens": ["Son\u00b7dern", "mich", "er\u00b7n\u00e4h\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mit dem Degen und Pistol,", "tokens": ["Mit", "dem", "De\u00b7gen", "und", "Pis\u00b7tol", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Und von meinen Feinden hol", "tokens": ["Und", "von", "mei\u00b7nen", "Fein\u00b7den", "hol"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich, was ich begehre.", "tokens": ["Ich", ",", "was", "ich", "be\u00b7geh\u00b7re", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Ich h\u00f6r gern der Armen Bitt,", "tokens": ["Ich", "h\u00f6r", "gern", "der", "Ar\u00b7men", "Bitt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hab ich was, so theil ich mit;", "tokens": ["Hab", "ich", "was", ",", "so", "theil", "ich", "mit", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "$,", "ADV", "KOUS", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich spendir die Heller", "tokens": ["Ich", "spen\u00b7dir", "die", "Hel\u00b7ler"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "PPER", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Auf ein gut Pferd und Gewehr,", "tokens": ["Auf", "ein", "gut", "Pferd", "und", "Ge\u00b7wehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "NN", "KON", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Schenkt mir Gott noch Etwas mehr,", "tokens": ["Schenkt", "mir", "Gott", "noch", "Et\u00b7was", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schick ichs nach dem Keller.", "tokens": ["Schick", "ichs", "nach", "dem", "Kel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.7": {"line.1": {"text": "Auch lieb ich der Musik Klang,", "tokens": ["Auch", "lieb", "ich", "der", "Mu\u00b7sik", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Stimm gern ein in den Gesang", "tokens": ["Stimm", "gern", "ein", "in", "den", "Ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wackerer Gesellen;", "tokens": ["Wa\u00b7cke\u00b7rer", "Ge\u00b7sel\u00b7len", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ich verderb kein gut Gelag,", "tokens": ["Ich", "ver\u00b7derb", "kein", "gut", "Ge\u00b7lag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bei der Burst mich lustig mach,", "tokens": ["Bei", "der", "Burst", "mich", "lus\u00b7tig", "mach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Pfleg mich frisch zu stellen.", "tokens": ["Pfleg", "mich", "frisch", "zu", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Esse gern was Gutes auch,", "tokens": ["Es\u00b7se", "gern", "was", "Gu\u00b7tes", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PWS", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Immer hab ich den Gebrauch,", "tokens": ["Im\u00b7mer", "hab", "ich", "den", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein gut Kleid zu tragen.", "tokens": ["Ein", "gut", "Kleid", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ich bin fromm, so lang ich kann,", "tokens": ["Ich", "bin", "fromm", ",", "so", "lang", "ich", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "ADV", "ADJD", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo nicht, pfleg ich mich alsdann", "tokens": ["Wo", "nicht", ",", "pfleg", "ich", "mich", "als\u00b7dann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PTKNEG", "$,", "VVFIN", "PPER", "PRF", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Frisch herum zu schlagen.", "tokens": ["Frisch", "he\u00b7rum", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APZR", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Jedem la\u00df ich seine Ehr,", "tokens": ["Je\u00b7dem", "la\u00df", "ich", "sei\u00b7ne", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "VVIMP", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebe junge M\u00e4dchen sehr,", "tokens": ["Lie\u00b7be", "jun\u00b7ge", "M\u00e4d\u00b7chen", "sehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Thu mich auch beflei\u00dfen,", "tokens": ["Thu", "mich", "auch", "be\u00b7flei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Weil ich nicht bin sch\u00f6n und fein,", "tokens": ["Weil", "ich", "nicht", "bin", "sch\u00f6n", "und", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich doch m\u00f6cht freundlich seyn,", "tokens": ["Da\u00df", "ich", "doch", "m\u00f6cht", "freund\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dienste zu erweisen.", "tokens": ["Diens\u00b7te", "zu", "er\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Werbe auch um ihre Gunst,", "tokens": ["Wer\u00b7be", "auch", "um", "ih\u00b7re", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seh ich, da\u00df es ist umsonst,", "tokens": ["Seh", "ich", ",", "da\u00df", "es", "ist", "um\u00b7sonst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich darum nicht z\u00fcrne;", "tokens": ["Ich", "da\u00b7rum", "nicht", "z\u00fcr\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PAV", "PTKNEG", "VVFIN", "$."], "meter": "----+-", "measure": "unknown.measure.single"}, "line.4": {"text": "Ist die Jungfer stolz von Sinn,", "tokens": ["Ist", "die", "Jung\u00b7fer", "stolz", "von", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df ich sie, und mach mich hin,", "tokens": ["La\u00df", "ich", "sie", ",", "und", "mach", "mich", "hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "$,", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zu der Baurendirne.", "tokens": ["Zu", "der", "Bau\u00b7ren\u00b7dir\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Weil ich, wie daf\u00fcr ich halt,", "tokens": ["Weil", "ich", ",", "wie", "da\u00b7f\u00fcr", "ich", "halt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "PAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht zu jung bin, noch zu alt,", "tokens": ["Nicht", "zu", "jung", "bin", ",", "noch", "zu", "alt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "VAFIN", "$,", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Will ich mich umschauen,", "tokens": ["Will", "ich", "mich", "um\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df ich nicht allein mehr schlaf,", "tokens": ["Da\u00df", "ich", "nicht", "al\u00b7lein", "mehr", "schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sondern mir zum Weib verschaff", "tokens": ["Son\u00b7dern", "mir", "zum", "Weib", "ver\u00b7schaff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Eine sch\u00f6n Jungfraue.", "tokens": ["Ei\u00b7ne", "sch\u00f6n", "Jung\u00b7frau\u00b7e", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "So ein gut Kerl bin ich nun,", "tokens": ["So", "ein", "gut", "Kerl", "bin", "ich", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Bitt, wollt mir zu wissen thun,", "tokens": ["Bitt", ",", "wollt", "mir", "zu", "wis\u00b7sen", "thun", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VMFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich euch gefalle;", "tokens": ["Wie", "ich", "euch", "ge\u00b7fal\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sonst sollt ihr versichert seyn,", "tokens": ["Sonst", "sollt", "ihr", "ver\u00b7si\u00b7chert", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ich will lieben euch allein", "tokens": ["Ich", "will", "lie\u00b7ben", "euch", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fcr das andre alle.", "tokens": ["F\u00fcr", "das", "and\u00b7re", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PIS", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Wollt ihr nun, so ist es klar,", "tokens": ["Wollt", "ihr", "nun", ",", "so", "ist", "es", "klar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und wir werden bald ein Paar.", "tokens": ["Und", "wir", "wer\u00b7den", "bald", "ein", "Paar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Drauf spricht sie gar sachte:", "tokens": ["Drauf", "spricht", "sie", "gar", "sach\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Ihr m\u00f6gt mir nach allem Schein", "tokens": ["Ihr", "m\u00f6gt", "mir", "nach", "al\u00b7lem", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "PIS", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gar ein guter Kerle seyn;", "tokens": ["Gar", "ein", "gu\u00b7ter", "Ker\u00b7le", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schmunzelt drauf und lachte.", "tokens": ["Schmun\u00b7zelt", "drauf", "und", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Als die Antwort ich bekam,", "tokens": ["Als", "die", "Ant\u00b7wort", "ich", "be\u00b7kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich sie in die Arme nahm,", "tokens": ["Ich", "sie", "in", "die", "Ar\u00b7me", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "K\u00fc\u00dft sie eins und fragte:", "tokens": ["K\u00fc\u00dft", "sie", "eins", "und", "frag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Was der Abschied endlich w\u00e4r.", "tokens": ["Was", "der", "Ab\u00b7schied", "end\u00b7lich", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Komme morgen wieder her,", "tokens": ["Kom\u00b7me", "mor\u00b7gen", "wie\u00b7der", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie gar freundlich sagte.", "tokens": ["Sie", "gar", "freund\u00b7lich", "sag\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Ich schw\u00f6r so wahr, als ich bin,", "tokens": ["Ich", "schw\u00f6r", "so", "wahr", ",", "als", "ich", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "PPER", "VAFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ein gut Kerl und geb euch hin", "tokens": ["Ein", "gut", "Kerl", "und", "geb", "euch", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "KON", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine beiden H\u00e4nde;", "tokens": ["Mei\u00b7ne", "bei\u00b7den", "H\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df wie ein gut Kerle ich", "tokens": ["Da\u00df", "wie", "ein", "gut", "Ker\u00b7le", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART", "ADJD", "NN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Euch will ganz best\u00e4ndiglich", "tokens": ["Euch", "will", "ganz", "be\u00b7st\u00e4n\u00b7dig\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Lieben bis ans Ende.", "tokens": ["Lie\u00b7ben", "bis", "ans", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "KON", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}