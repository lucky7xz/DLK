{"textgrid.poem.60002": {"metadata": {"author": {"name": "Herwegh, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Gro\u00df", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbseid umschlungen, Milliarden!\u00ab", "tokens": ["\u00bb", "seid", "um\u00b7schlun\u00b7gen", ",", "Mil\u00b7li\u00b7ar\u00b7den", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "VVPP", "$,", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6r ich mit Begeisterung", "tokens": ["H\u00f6r", "ich", "mit", "Be\u00b7geis\u00b7te\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Singen unsre Einheits-Barden:", "tokens": ["Sin\u00b7gen", "uns\u00b7re", "Ein\u00b7heits\u00b7Bar\u00b7den", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welche Federn! welcher Schwung!", "tokens": ["Wel\u00b7che", "Fe\u00b7dern", "!", "wel\u00b7cher", "Schwung", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAT", "NN", "$.", "PWAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sah man jemals solche Beute?", "tokens": ["Sah", "man", "je\u00b7mals", "sol\u00b7che", "Beu\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir verstehen unser Fach,", "tokens": ["Wir", "ver\u00b7ste\u00b7hen", "un\u00b7ser", "Fach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ja, ihr Professorenleute,", "tokens": ["Ja", ",", "ihr", "Pro\u00b7fes\u00b7so\u00b7ren\u00b7leu\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wir sind gro\u00df, br\u00fcllt Auerbach.", "tokens": ["Wir", "sind", "gro\u00df", ",", "br\u00fcllt", "Au\u00b7er\u00b7bach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Gottesfurcht und fromme Sitte,", "tokens": ["Got\u00b7tes\u00b7furcht", "und", "from\u00b7me", "Sit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blut und Eisen wirkten gut,", "tokens": ["Blut", "und", "Ei\u00b7sen", "wirk\u00b7ten", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vor unserm Reich der Mitte", "tokens": ["Und", "vor", "un\u00b7serm", "Reich", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zieht Europa stolz den Hut.", "tokens": ["Zieht", "Eu\u00b7ro\u00b7pa", "stolz", "den", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Geibel wird ein Epos schreiben;", "tokens": ["Gei\u00b7bel", "wird", "ein", "E\u00b7pos", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen blinderen Homer", "tokens": ["Ei\u00b7nen", "blin\u00b7de\u00b7ren", "Ho\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NE"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "W\u00fc\u00dft ich nirgends aufzutreiben:", "tokens": ["W\u00fc\u00dft", "ich", "nir\u00b7gends", "auf\u00b7zu\u00b7trei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wir sind gro\u00df \u2013 es freut mich sehr.", "tokens": ["Wir", "sind", "gro\u00df", "\u2013", "es", "freut", "mich", "sehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$(", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Elsa\u00df unser \u2013 Dank, ihr Streiter!", "tokens": ["El\u00b7sa\u00df", "un\u00b7ser", "\u2013", "Dank", ",", "ihr", "Strei\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "$(", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lothringen in deutscher Hand!", "tokens": ["Loth\u00b7rin\u00b7gen", "in", "deut\u00b7scher", "Hand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Immer l\u00e4nger, immer breiter", "tokens": ["Im\u00b7mer", "l\u00e4n\u00b7ger", ",", "im\u00b7mer", "brei\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Machen wir das Vaterland.", "tokens": ["Ma\u00b7chen", "wir", "das", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Eine Million Soldaten", "tokens": ["Ei\u00b7ne", "Mil\u00b7li\u00b7on", "Sol\u00b7da\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stehen da, wenn C\u00e4sar spricht,", "tokens": ["Ste\u00b7hen", "da", ",", "wenn", "C\u00e4\u00b7sar", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "KOUS", "NE", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Stramm gedrillt zu Heldentaten:", "tokens": ["Stramm", "ge\u00b7drillt", "zu", "Hel\u00b7den\u00b7ta\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wir sind gro\u00df \u2013 ich leugn es nicht.", "tokens": ["Wir", "sind", "gro\u00df", "\u2013", "ich", "leugn", "es", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "T\u00f6richt zwar ins Herz geschlossen", "tokens": ["T\u00f6\u00b7richt", "zwar", "ins", "Herz", "ge\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPRART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hatt ich einst ein Ideal,", "tokens": ["Hatt", "ich", "einst", "ein", "I\u00b7deal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Das zerfetzt nun und zerschossen", "tokens": ["Das", "zer\u00b7fetzt", "nun", "und", "zer\u00b7schos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liegt im preu\u00dfischen Spital.", "tokens": ["Liegt", "im", "preu\u00b7\u00dfi\u00b7schen", "Spi\u00b7tal", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch was k\u00fcmmern uns die Wunden,", "tokens": ["Doch", "was", "k\u00fcm\u00b7mern", "uns", "die", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die der Ruhm der ", "tokens": ["Die", "der", "Ruhm", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Mag sie, wie sie kann, gesunden:", "tokens": ["Mag", "sie", ",", "wie", "sie", "kann", ",", "ge\u00b7sun\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wir sind gro\u00df \u2013 das ist genug.", "tokens": ["Wir", "sind", "gro\u00df", "\u2013", "das", "ist", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$(", "PDS", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}