{"textgrid.poem.67863": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "11. Ans Rennthier", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kulnasaz, Rennthierchen, lieb Rennthierchen, la\u00df uns flink seyn,", "tokens": ["Kul\u00b7na\u00b7saz", ",", "Renn\u00b7thier\u00b7chen", ",", "lieb", "Renn\u00b7thier\u00b7chen", ",", "la\u00df", "uns", "flink", "seyn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADJD", "NN", "$,", "VVIMP", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "La\u00df uns fliegen, bald an Stell' und Ort seyn!", "tokens": ["La\u00df", "uns", "flie\u00b7gen", ",", "bald", "an", "Stell'", "und", "Ort", "seyn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "ADV", "APPR", "NN", "KON", "NN", "VAINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "S\u00fcmpfe sind noch weit daher,", "tokens": ["S\u00fcmp\u00b7fe", "sind", "noch", "weit", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADJD", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und haben fast kein Lied mehr.", "tokens": ["Und", "ha\u00b7ben", "fast", "kein", "Lied", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Sieh da, dich mag ich leiden, Kaiga-See,", "tokens": ["Sieh", "da", ",", "dich", "mag", "ich", "lei\u00b7den", ",", "Kai\u00b7ga\u00b7See", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Leb wohl, du guter Kailva-See,", "tokens": ["Leb", "wohl", ",", "du", "gu\u00b7ter", "Kail\u00b7va\u00b7See", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel schl\u00e4gt mir's schon das Herze", "tokens": ["Viel", "schl\u00e4gt", "mir's", "schon", "das", "Her\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf' m lieben Kaiga-See.", "tokens": ["Auf'", "m", "lie\u00b7ben", "Kai\u00b7ga\u00b7See", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Auf, Rennthierchen, liebes, auf,", "tokens": ["Auf", ",", "Renn\u00b7thier\u00b7chen", ",", "lie\u00b7bes", ",", "auf", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "$,", "NN", "$,", "ADJA", "$,", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fliege, fliege deinen Lauf!", "tokens": ["Flie\u00b7ge", ",", "flie\u00b7ge", "dei\u00b7nen", "Lauf", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir bald an Stell' und Ort seyn,", "tokens": ["Da\u00df", "wir", "bald", "an", "Stell'", "und", "Ort", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "KON", "NN", "VAINF", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "Bald uns unsrer Arbeit freun.", "tokens": ["Bald", "uns", "uns\u00b7rer", "Ar\u00b7beit", "freun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Bald ich meine Liebe seh \u2013", "tokens": ["Bald", "ich", "mei\u00b7ne", "Lie\u00b7be", "seh", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf, Rennthierchen, blick und sieh!", "tokens": ["Auf", ",", "Renn\u00b7thier\u00b7chen", ",", "blick", "und", "sieh", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "NN", "$,", "ADJD", "KON", "VVIMP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kulnasazlein\u00ab, siehst du sie", "tokens": ["Kul\u00b7na\u00b7saz\u00b7lein", "\u00ab", ",", "siehst", "du", "sie"], "token_info": ["word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "$(", "$,", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht schon baden?", "tokens": ["Nicht", "schon", "ba\u00b7den", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}