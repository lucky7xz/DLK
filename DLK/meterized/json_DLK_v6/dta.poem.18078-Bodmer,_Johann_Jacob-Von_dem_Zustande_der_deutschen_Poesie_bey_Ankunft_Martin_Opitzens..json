{"dta.poem.18078": {"metadata": {"author": {"name": "Bodmer, Johann Jacob", "birth": "N.A.", "death": "N.A."}, "title": "Von dem Zustande der deutschen  \n Poesie bey Ankunft Martin Opitzens.", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-200905198432", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wjr kommen nicht hieher, uns selbsten viel zu r\u00fchmen,", "tokens": ["Wjr", "kom\u00b7men", "nicht", "hie\u00b7her", ",", "uns", "selbs\u00b7ten", "viel", "zu", "r\u00fch\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "PAV", "$,", "PPER", "VVFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Oder durch fremde Sprach die Wahrheit zu verbl\u00fcmen,", "tokens": ["O\u00b7der", "durch", "frem\u00b7de", "Sprach", "die", "Wahr\u00b7heit", "zu", "ver\u00b7bl\u00fc\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als ob wir k\u00e4men jetzt aus einem End der Welt,", "tokens": ["Als", "ob", "wir", "k\u00e4\u00b7men", "jetzt", "aus", "ei\u00b7nem", "End", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Oder wieder-belebt vom Elisischen Feld.", "tokens": ["O\u00b7der", "wie\u00b7der\u00b7be\u00b7lebt", "vom", "E\u00b7li\u00b7si\u00b7schen", "Feld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Nein. Teufel sind wir nicht, noch Riesen, noch Halb-G\u00f6tter,", "tokens": ["Nein", ".", "Teu\u00b7fel", "sind", "wir", "nicht", ",", "noch", "Rie\u00b7sen", ",", "noch", "Halb\u00b7G\u00f6t\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "VAFIN", "PPER", "PTKNEG", "$,", "ADV", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Noch Helden, noch Wildleut, noch unsers Lands Versp\u00f6tter,", "tokens": ["Noch", "Hel\u00b7den", ",", "noch", "Wild\u00b7leut", ",", "noch", "un\u00b7sers", "Lands", "Ver\u00b7sp\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "NN", "$,", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das teutsche Reich bekannt ist unser Vaterland,", "tokens": ["Das", "teut\u00b7sche", "Reich", "be\u00b7kannt", "ist", "un\u00b7ser", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Teutsch sind wir von Geburt, von Stamme, Hertz und Hand.", "tokens": ["Teutsch", "sind", "wir", "von", "Ge\u00b7burt", ",", "von", "Stam\u00b7me", ",", "Hertz", "und", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Was dient es, fremden Prei\u00df und Nahmen zu entlehnen,", "tokens": ["Was", "dient", "es", ",", "frem\u00b7den", "Prei\u00df", "und", "Nah\u00b7men", "zu", "ent\u00b7leh\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Teutschland bedarff sich nicht mit Ausl\u00e4ndern besch\u00f6nen,", "tokens": ["Teutschland", "be\u00b7darff", "sich", "nicht", "mit", "Aus\u00b7l\u00e4n\u00b7dern", "be\u00b7sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "PTKNEG", "APPR", "NN", "VVINF", "$,"], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Wie dann die Welt wohl wei\u00df, da\u00df es zu aller Zeit", "tokens": ["Wie", "dann", "die", "Welt", "wohl", "wei\u00df", ",", "da\u00df", "es", "zu", "al\u00b7ler", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Treffliche Leut genug hatte zum Fried und Streit.", "tokens": ["Treff\u00b7li\u00b7che", "Leut", "ge\u00b7nug", "hat\u00b7te", "zum", "Fried", "und", "Streit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VAFIN", "APPRART", "NN", "KON", "NN", "$."], "meter": "+--+-+---+-+", "measure": "iambic.penta.invert"}, "line.13": {"text": "Darum, ob wir wohl jung, nicht sonders viel erfahren,", "tokens": ["Da\u00b7rum", ",", "ob", "wir", "wohl", "jung", ",", "nicht", "son\u00b7ders", "viel", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,", "PTKNEG", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Begehren wir doch nicht unsere F\u00e4ust zu spahren,", "tokens": ["Be\u00b7geh\u00b7ren", "wir", "doch", "nicht", "un\u00b7se\u00b7re", "F\u00e4ust", "zu", "spah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PTKNEG", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Sondern erscheinen nur in unsrer teutschen Tracht,", "tokens": ["Son\u00b7dern", "er\u00b7schei\u00b7nen", "nur", "in", "uns\u00b7rer", "teut\u00b7schen", "Tracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.16": {"text": "Mit teutsch-redlichem Muth, um unser erste Macht", "tokens": ["Mit", "teut\u00b7schred\u00b7li\u00b7chem", "Muth", ",", "um", "un\u00b7ser", "ers\u00b7te", "Macht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUI", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "An diesen Rittern hier (die so hoch triumphieren)", "tokens": ["An", "die\u00b7sen", "Rit\u00b7tern", "hier", "(", "die", "so", "hoch", "tri\u00b7um\u00b7phie\u00b7ren", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "$(", "ART", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Jhrer Begierd gem\u00e4\u00df, gewaffnet zu probieren,", "tokens": ["Ih\u00b7rer", "Be\u00b7gierd", "ge\u00b7m\u00e4\u00df", ",", "ge\u00b7waff\u00b7net", "zu", "pro\u00b7bie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$,", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.19": {"text": "Verhoffend zweifelsfrey, da\u00df diese erste Prob,", "tokens": ["Ver\u00b7hof\u00b7fend", "zwei\u00b7fels\u00b7frey", ",", "da\u00df", "die\u00b7se", "ers\u00b7te", "Prob", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "CARD", "$,", "KOUS", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Vollendend ihren Ruhm, anfangen soll das Lob,", "tokens": ["Voll\u00b7en\u00b7dend", "ih\u00b7ren", "Ruhm", ",", "an\u00b7fan\u00b7gen", "soll", "das", "Lob", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$,", "VVINF", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So man von nun an wird durch die Streich unsrer Wehren", "tokens": ["So", "man", "von", "nun", "an", "wird", "durch", "die", "Streich", "uns\u00b7rer", "Weh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "APPR", "ADV", "APZR", "VAFIN", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "-+--+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Unter dem Firmament t\u00e4glich erschallen h\u00f6ren.", "tokens": ["Un\u00b7ter", "dem", "Fir\u00b7ma\u00b7ment", "t\u00e4g\u00b7lich", "er\u00b7schal\u00b7len", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVINF", "VVINF", "$."], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}}}}}