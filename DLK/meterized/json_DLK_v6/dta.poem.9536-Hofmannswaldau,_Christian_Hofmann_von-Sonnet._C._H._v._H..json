{"dta.poem.9536": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Sonnet.  \n C. H. v. H.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Dich Lesbia und mich trug nechst ein geiler wagen/", "tokens": ["Dich", "Les\u00b7bia", "und", "mich", "trug", "nechst", "ein", "gei\u00b7ler", "wa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "KON", "PPER", "VVFIN", "ADV", "ART", "ADJA", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Gleich als die Cynthia begont den lauff der nacht/", "tokens": ["Gleich", "als", "die", "Cyn\u00b7thia", "be\u00b7gont", "den", "lauff", "der", "nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Flora hat ihn selbst zu ihrem fest erdacht/", "tokens": ["Die", "Flo\u00b7ra", "hat", "ihn", "selbst", "zu", "ih\u00b7rem", "fest", "er\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der verbuhlte gott das holtz herbey getragen.", "tokens": ["Und", "der", "ver\u00b7buhl\u00b7te", "gott", "das", "holtz", "her\u00b7bey", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Die farben/ so mit flei\u00df allhier begraben lagen/", "tokens": ["Die", "far\u00b7ben", "/", "so", "mit", "flei\u00df", "all\u00b7hier", "be\u00b7gra\u00b7ben", "la\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "APPR", "NN", "ADV", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sagten: Adons blut hat uns hieher gebracht;", "tokens": ["Die", "sag\u00b7ten", ":", "A\u00b7dons", "blut", "hat", "uns", "hie\u00b7her", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "NE", "NN", "VAFIN", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Venus hatte selbst die esse hei\u00df gemacht/", "tokens": ["Die", "Ve\u00b7nus", "hat\u00b7te", "selbst", "die", "es\u00b7se", "hei\u00df", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als ihn mit gutem stahl ihr krummer mann beschlagen.", "tokens": ["Als", "ihn", "mit", "gu\u00b7tem", "stahl", "ihr", "krum\u00b7mer", "mann", "be\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Und hat ihn dazumahl ein schwartzes tuch umh\u00fcllet/", "tokens": ["Und", "hat", "ihn", "da\u00b7zu\u00b7mahl", "ein", "schwart\u00b7zes", "tuch", "um\u00b7h\u00fcl\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schwartz st\u00f6ret keinen schertz und st\u00f6rt die liebe nicht/", "tokens": ["Schwartz", "st\u00f6\u00b7ret", "kei\u00b7nen", "schertz", "und", "st\u00f6rt", "die", "lie\u00b7be", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "KON", "VVFIN", "ART", "VVFIN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man schaut wie mancher stern aus schwartzen wolcken bricht/", "tokens": ["Man", "schaut", "wie", "man\u00b7cher", "stern", "aus", "schwart\u00b7zen", "wol\u00b7cken", "bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOKOM", "PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Und itzt ein wahrer reim aus schwartzem munde quillet.", "tokens": ["Und", "itzt", "ein", "wah\u00b7rer", "reim", "aus", "schwart\u00b7zem", "mun\u00b7de", "quil\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man soll kein wildes pferd nicht ferner mehr bem\u00fchen/", "tokens": ["Man", "soll", "kein", "wil\u00b7des", "pferd", "nicht", "fer\u00b7ner", "mehr", "be\u00b7m\u00fc\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PIAT", "ADJA", "NN", "PTKNEG", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den geilen wagen soll die geile taube ziehen.", "tokens": ["Den", "gei\u00b7len", "wa\u00b7gen", "soll", "die", "gei\u00b7le", "tau\u00b7be", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}