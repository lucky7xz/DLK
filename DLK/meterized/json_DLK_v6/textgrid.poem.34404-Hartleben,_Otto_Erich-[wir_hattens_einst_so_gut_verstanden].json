{"textgrid.poem.34404": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "[wir hattens einst so gut verstanden]", "genre": "verse", "period": "N.A.", "pub_year": 1885, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir hattens einst so gut verstanden,", "tokens": ["Wir", "hat\u00b7tens", "einst", "so", "gut", "ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zu k\u00fcssen uns zu rechter Stund,", "tokens": ["zu", "k\u00fcs\u00b7sen", "uns", "zu", "rech\u00b7ter", "Stund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "eh wir es selber ganz empfanden,", "tokens": ["eh", "wir", "es", "sel\u00b7ber", "ganz", "emp\u00b7fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "gefunden hatte Mund den Mund.", "tokens": ["ge\u00b7fun\u00b7den", "hat\u00b7te", "Mund", "den", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein einiger Gedanke schwebte,", "tokens": ["Ein", "ei\u00b7ni\u00b7ger", "Ge\u00b7dan\u00b7ke", "schweb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "war weder mir noch dir bewusst,", "tokens": ["war", "we\u00b7der", "mir", "noch", "dir", "be\u00b7wusst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "PPER", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und pl\u00f6tzlich Lipp an Lippe bebte", "tokens": ["und", "pl\u00f6tz\u00b7lich", "Lipp", "an", "Lip\u00b7pe", "beb\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "NE", "APPR", "NE", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und pl\u00f6tzlich bebte Brust an Brust.", "tokens": ["und", "pl\u00f6tz\u00b7lich", "beb\u00b7te", "Brust", "an", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dann haben wirs vergessen m\u00fcssen,", "tokens": ["Dann", "ha\u00b7ben", "wirs", "ver\u00b7ges\u00b7sen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "verleugnet ward die Kinderzeit,", "tokens": ["ver\u00b7leug\u00b7net", "ward", "die", "Kin\u00b7der\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wir trugen, statt uns froh zu k\u00fcssen,", "tokens": ["wir", "tru\u00b7gen", ",", "statt", "uns", "froh", "zu", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ehrbar und dumm das Heuchlerkleid.", "tokens": ["ehr\u00b7bar", "und", "dumm", "das", "Heuc\u00b7hler\u00b7kleid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "ART", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.4": {"line.1": {"text": "Doch als ich heut nach langen Tagen,", "tokens": ["Doch", "als", "ich", "heut", "nach", "lan\u00b7gen", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "dich still geliebte wiedersah \u2013", "tokens": ["dich", "still", "ge\u00b7lieb\u00b7te", "wie\u00b7der\u00b7sah", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wir hattens gar zu schwer getragen \u2013", "tokens": ["wir", "hat\u00b7tens", "gar", "zu", "schwer", "ge\u00b7tra\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKA", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "war Kuss und Kindheit wieder da!", "tokens": ["war", "Kuss", "und", "Kind\u00b7heit", "wie\u00b7der", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}