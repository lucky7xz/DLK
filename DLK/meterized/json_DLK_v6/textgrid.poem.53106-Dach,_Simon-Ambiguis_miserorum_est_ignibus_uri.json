{"textgrid.poem.53106": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Ambiguis miserorum est ignibus uri", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man sagt mir zwar, ich soll dich hassen", "tokens": ["Man", "sagt", "mir", "zwar", ",", "ich", "soll", "dich", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "$,", "PPER", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd nicht mehr lieben wie ich pflag;", "tokens": ["Vnd", "nicht", "mehr", "lie\u00b7ben", "wie", "ich", "pflag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVINF", "KOKOM", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So kan ich doch nicht von dir lassen,", "tokens": ["So", "kan", "ich", "doch", "nicht", "von", "dir", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich fliehe dich auch wie ich mag.", "tokens": ["Ich", "flie\u00b7he", "dich", "auch", "wie", "ich", "mag."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOKOM", "PPER", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Wie offt hab' ich mir vorgenommen,", "tokens": ["Wie", "offt", "hab'", "ich", "mir", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du soltest mir in meinen Sinn,", "tokens": ["Du", "sol\u00b7test", "mir", "in", "mei\u00b7nen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O Galathe, nun nicht mehr kommen,", "tokens": ["O", "Ga\u00b7la\u00b7the", ",", "nun", "nicht", "mehr", "kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADV", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nein! Nein, ich lieb' als nie vorhin.", "tokens": ["Nein", "!", "Nein", ",", "ich", "lieb'", "als", "nie", "vor\u00b7hin", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PTKANT", "$,", "PPER", "VVFIN", "KOKOM", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wir seyn ja nicht zugleich geboren,", "tokens": ["Wir", "seyn", "ja", "nicht", "zu\u00b7gleich", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es gleichen vnsre Sternen nicht;", "tokens": ["Es", "glei\u00b7chen", "vns\u00b7re", "Ster\u00b7nen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir hatte Venus sich verlohren,", "tokens": ["Mir", "hat\u00b7te", "Ve\u00b7nus", "sich", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dir aber schien' jhr helles Liecht.", "tokens": ["Dir", "a\u00b7ber", "schien'", "jhr", "hel\u00b7les", "Liecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Werd' ich durch List denn hintergangen,", "tokens": ["Werd'", "ich", "durch", "List", "denn", "hin\u00b7ter\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NE", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd hat man mir was beygebracht,", "tokens": ["Vnd", "hat", "man", "mir", "was", "bey\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich so stets an dir mu\u00df hangen", "tokens": ["Da\u00df", "ich", "so", "stets", "an", "dir", "mu\u00df", "han\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPER", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd ruhen weder Tag noch Nacht?", "tokens": ["Vnd", "ru\u00b7hen", "we\u00b7der", "Tag", "noch", "Nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Seh' ich dich nicht, so f\u00fchl' ich Schmertzen;", "tokens": ["Seh'", "ich", "dich", "nicht", ",", "so", "f\u00fchl'", "ich", "Schmert\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Genie\u00df' ich deiner Gegenwart,", "tokens": ["Ge\u00b7ni\u00b7e\u00df'", "ich", "dei\u00b7ner", "Ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "So ist mir doch nicht wol im Hertzen,", "tokens": ["So", "ist", "mir", "doch", "nicht", "wol", "im", "Hert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich stehe bey dir wie erstarrt.", "tokens": ["Ich", "ste\u00b7he", "bey", "dir", "wie", "er\u00b7starrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die Rede wil mir gantz nicht fliessen,", "tokens": ["Die", "Re\u00b7de", "wil", "mir", "gantz", "nicht", "flies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich zittre wie ein E\u00dfpen-Laub;", "tokens": ["Ich", "zitt\u00b7re", "wie", "ein", "E\u00df\u00b7pen\u00b7Laub", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Augen Quell mu\u00df sich ergiessen,", "tokens": ["Der", "Au\u00b7gen", "Quell", "mu\u00df", "sich", "er\u00b7gies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd bin wie Sinn-lo\u00df, Stumm vnd Taub.", "tokens": ["Vnd", "bin", "wie", "Sinn\u00b7lo\u00df", ",", "Stumm", "vnd", "Taub", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "KOKOM", "NN", "$,", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich gl\u00e4ube, das au\u00df dieser Ketten", "tokens": ["Ich", "gl\u00e4u\u00b7be", ",", "das", "au\u00df", "die\u00b7ser", "Ket\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd au\u00df dem harten Liebes-Streit", "tokens": ["Vnd", "au\u00df", "dem", "har\u00b7ten", "Lie\u00b7bes\u00b7Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich Perseus selbst nicht k\u00f6nn' erretten,", "tokens": ["Mich", "Per\u00b7seus", "selbst", "nicht", "k\u00f6nn'", "er\u00b7ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "ADV", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der doch Andromeden befreyt.", "tokens": ["Der", "doch", "And\u00b7ro\u00b7me\u00b7den", "be\u00b7freyt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Darumb sol Cloto meinem Leben,", "tokens": ["Da\u00b7rumb", "sol", "Clo\u00b7to", "mei\u00b7nem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "NE", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "(weil sonst mir nicht zu helffen steht,)", "tokens": ["(", "weil", "sonst", "mir", "nicht", "zu", "helf\u00b7fen", "steht", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "ADV", "PPER", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die l\u00e4ngst-gew\u00fcnschte Endschafft geben:", "tokens": ["Die", "l\u00e4ngs\u00b7tge\u00b7w\u00fcnschte", "End\u00b7schafft", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ob so ein Mensch der Lieb' entgeht?", "tokens": ["Ob", "so", "ein", "Mensch", "der", "Lieb'", "ent\u00b7geht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}