{"dta.poem.20093": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Das Bristol-Trauerspiel  \n oder  \n  Charles Bawdin\u2019s Tod .  \n (Nach Thomas Chatterton.)", "genre": "Lyrik", "period": "N.A.", "pub_year": "1851", "urn": "urn:nbn:de:kobv:b4-200905191321", "language": ["de:0.99"], "booktitle": "Fontane, Theodor: Gedichte. Berlin, 1851."}, "poem": {"stanza.1": {"line.1": {"text": "Aufd\u00e4mmert der Tag, der Hahn kr\u00e4ht hell,", "tokens": ["Auf\u00b7d\u00e4m\u00b7mert", "der", "Tag", ",", "der", "Hahn", "kr\u00e4ht", "hell", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bla\u00df schimmert des Mondes Horn,", "tokens": ["Bla\u00df", "schim\u00b7mert", "des", "Mon\u00b7des", "Horn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und im Morgenrothe der Tropfen Thau", "tokens": ["Und", "im", "Mor\u00b7gen\u00b7ro\u00b7the", "der", "Trop\u00b7fen", "Thau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "NN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Glitzert am Hagedorn.", "tokens": ["Glit\u00b7zert", "am", "Ha\u00b7ge\u00b7dorn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "K\u00f6nig Edward aber nicht Hahnenschrei", "tokens": ["K\u00f6\u00b7nig", "Ed\u00b7ward", "a\u00b7ber", "nicht", "Hah\u00b7nen\u00b7schrei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADV", "PTKNEG", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Rief ihn vom Schlummer wach;", "tokens": ["Rief", "ihn", "vom", "Schlum\u00b7mer", "wach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Drei Raben weckten ihn mit Gekreisch", "tokens": ["Drei", "Ra\u00b7ben", "weck\u00b7ten", "ihn", "mit", "Ge\u00b7kreisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oben am Wetterdach.", "tokens": ["O\u00b7ben", "am", "Wet\u00b7ter\u00b7dach", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "Und der K\u00f6nig fuhr auf: \u201ebeim ewigen Gott,", "tokens": ["Und", "der", "K\u00f6\u00b7nig", "fuhr", "auf", ":", "\u201e", "beim", "e\u00b7wi\u00b7gen", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$.", "$(", "APPRART", "ADJA", "NN", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ich versteh\u2019 euer Mahnen und Schrein;", "tokens": ["Ich", "ver\u00b7steh'", "eu\u00b7er", "Mah\u00b7nen", "und", "Schrein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Charles Bawdin, der soll sterben heut", "tokens": ["Char\u00b7les", "Baw\u00b7din", ",", "der", "soll", "ster\u00b7ben", "heut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PRELS", "ADJD", "VVFIN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und eure Speise sein!\u201c", "tokens": ["Und", "eu\u00b7re", "Spei\u00b7se", "sein", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der K\u00f6nig rief\u2019s; eine Kanne Wein", "tokens": ["Der", "K\u00f6\u00b7nig", "rie\u00b7f's", ";", "ei\u00b7ne", "Kan\u00b7ne", "Wein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$.", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Leert\u2019 er bis auf den Grund;", "tokens": ["Leert'", "er", "bis", "auf", "den", "Grund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ritter Canning stand zu Seiten ihm, \u2014", "tokens": ["Rit\u00b7ter", "Can\u00b7ning", "stand", "zu", "Sei\u00b7ten", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "VVFIN", "APPR", "NN", "PPER", "$,", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Dem war das Herze wund.", "tokens": ["Dem", "war", "das", "Her\u00b7ze", "wund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PDS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und Canning sprach: \u201emein K\u00f6nig und Herr", "tokens": ["Und", "Can\u00b7ning", "sprach", ":", "\u201e", "mein", "K\u00f6\u00b7nig", "und", "Herr"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "$.", "$(", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Vergie\u00dfe nicht Bawdin\u2019s Blut,", "tokens": ["Ver\u00b7gie\u00b7\u00dfe", "nicht", "Ba\u00b7wdin's", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "NE", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Was immer er dir B\u00f6ses that,", "tokens": ["Was", "im\u00b7mer", "er", "dir", "B\u00f6\u00b7ses", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm galt es brav und gut.", "tokens": ["Ihm", "galt", "es", "brav", "und", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u201edem Lankasterk\u00f6nig hat er gedient", "tokens": ["\u201e", "dem", "Lan\u00b7kas\u00b7ter\u00b7k\u00f6\u00b7nig", "hat", "er", "ge\u00b7dient"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VAFIN", "PPER", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Offen und sonder Scheu,", "tokens": ["Of\u00b7fen", "und", "son\u00b7der", "Scheu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "O Herr, an Deinem Feinde auch", "tokens": ["O", "Herr", ",", "an", "Dei\u00b7nem", "Fein\u00b7de", "auch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ehre Muth und Treu.\u201c", "tokens": ["Eh\u00b7re", "Muth", "und", "Treu", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Er sprach\u2019s. Noch schwieg der Ritter kaum,", "tokens": ["Er", "sprach'", "s.", "Noch", "schwieg", "der", "Rit\u00b7ter", "kaum", ","], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVIMP", "ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da z\u00fcrnet der K\u00f6nig und schnaubt:", "tokens": ["Da", "z\u00fcr\u00b7net", "der", "K\u00f6\u00b7nig", "und", "schnaubt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "\u201eeh Sternenschein auf die Erde f\u00e4llt,", "tokens": ["\u201e", "eh", "Ster\u00b7nen\u00b7schein", "auf", "die", "Er\u00b7de", "f\u00e4llt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "F\u00e4llt heut Charles Bawdin\u2019s Haupt.", "tokens": ["F\u00e4llt", "heut", "Char\u00b7les", "Ba\u00b7wdin's", "Haupt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NE", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u201eer war ein Verr\u00e4ther, er hat seine Hand", "tokens": ["\u201e", "er", "war", "ein", "Ver\u00b7r\u00e4\u00b7ther", ",", "er", "hat", "sei\u00b7ne", "Hand"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "In\u2019s Blut der Yorks getaucht,", "tokens": ["In's", "Blut", "der", "Y\u00b7orks", "ge\u00b7taucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Nicht eher hab\u2019 ich Rast noch Ruh", "tokens": ["Nicht", "e\u00b7her", "hab'", "ich", "Rast", "noch", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "VAFIN", "PPER", "NN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis seines gen Himmel raucht!\u201c", "tokens": ["Bis", "sei\u00b7nes", "gen", "Him\u00b7mel", "raucht", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Drauf Canning ernst: \u201enur Gnade Herr", "tokens": ["Drauf", "Can\u00b7ning", "ernst", ":", "\u201e", "nur", "Gna\u00b7de", "Herr"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PAV", "NN", "ADJD", "$.", "$(", "ADV", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Machet des Siegs Dich werth;", "tokens": ["Ma\u00b7chet", "des", "Siegs", "Dich", "werth", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Den Oelzweig und die Palme nimm", "tokens": ["Den", "O\u00b7el\u00b7zweig", "und", "die", "Pal\u00b7me", "nimm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nicht aber das Racheschwert.", "tokens": ["Nicht", "a\u00b7ber", "das", "Ra\u00b7ch\u00b7e\u00b7schwert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.10": {"line.1": {"text": "\u201egedenk, wir Menschen allzumal", "tokens": ["\u201e", "ge\u00b7denk", ",", "wir", "Men\u00b7schen", "all\u00b7zu\u00b7mal"], "token_info": ["punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "PPER", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind nur an S\u00fcnde gro\u00df,", "tokens": ["Sind", "nur", "an", "S\u00fcn\u00b7de", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Einziger auf Sankt Petri Stuhl", "tokens": ["Ein", "Ein\u00b7zi\u00b7ger", "auf", "Sankt", "Pe\u00b7tri", "Stuhl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "VVFIN", "NE", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist schuld- und fleckenlos.", "tokens": ["Ist", "schuld", "und", "fle\u00b7cken\u00b7los", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "TRUNC", "KON", "ADJD", "$."], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.11": {"line.1": {"text": "\u201evergieb! das festiget Dir auf\u2019s Haupt", "tokens": ["\u201e", "ver\u00b7gieb", "!", "das", "fes\u00b7ti\u00b7get", "Dir", "auf's", "Haupt"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVIMP", "$.", "PDS", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die kaum gewonnene Kron\u2019,", "tokens": ["Die", "kaum", "ge\u00b7won\u00b7ne\u00b7ne", "Kron'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und tr\u00e4gt Dein Scepter fort und fort", "tokens": ["Und", "tr\u00e4gt", "Dein", "Scep\u00b7ter", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Enkel und Enkelsohn;", "tokens": ["Auf", "En\u00b7kel", "und", "En\u00b7kel\u00b7sohn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "\u201edoch willst in Ha\u00df, mit blutigem Thau", "tokens": ["\u201e", "doch", "willst", "in", "Ha\u00df", ",", "mit", "blu\u00b7ti\u00b7gem", "Thau"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "VMFIN", "APPR", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Bespritzen Du Dein Kleid,", "tokens": ["Be\u00b7sprit\u00b7zen", "Du", "Dein", "Kleid", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So rei\u00dfen finstre M\u00e4chte Dir", "tokens": ["So", "rei\u00b7\u00dfen", "finst\u00b7re", "M\u00e4ch\u00b7te", "Dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Haupte das Goldgeschmeid.\u201c", "tokens": ["Vom", "Haup\u00b7te", "das", "Gold\u00b7ge\u00b7schmeid", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Der K\u00f6nig h\u00f6rt\u2019s. \u201eFort, Canning, fort!", "tokens": ["Der", "K\u00f6\u00b7nig", "h\u00f6rt'", "s.", "\u201e", "Fort", ",", "Can\u00b7ning", ",", "fort", "!"], "token_info": ["word", "word", "word", "abbreviation", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$(", "NN", "$,", "NE", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So lange Charles Bawdin lebt", "tokens": ["So", "lan\u00b7ge", "Char\u00b7les", "Baw\u00b7din", "lebt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "NE", "NE", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Will d\u00fcrsten ich, und ob am Gaum", "tokens": ["Will", "d\u00fcrs\u00b7ten", "ich", ",", "und", "ob", "am", "Gaum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "VMFIN", "PPER", "$,", "KON", "KOUS", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir auch die Zunge klebt.", "tokens": ["Mir", "auch", "die", "Zun\u00b7ge", "klebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Die Sonne, die da dr\u00fcben steigt", "tokens": ["Die", "Son\u00b7ne", ",", "die", "da", "dr\u00fc\u00b7ben", "steigt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Soll seine letzte sein!\u201c", "tokens": ["Soll", "sei\u00b7ne", "letz\u00b7te", "sein", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der K\u00f6nig schwieg, in Cannings Bart", "tokens": ["Der", "K\u00f6\u00b7nig", "schwieg", ",", "in", "Can\u00b7nings", "Bart"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Rann eine Thr\u00e4n\u2019 hinein.", "tokens": ["Rann", "ei\u00b7ne", "Thr\u00e4n'", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Und durch die Gassen, tr\u00fcben Sinn\u2019s,", "tokens": ["Und", "durch", "die", "Gas\u00b7sen", ",", "tr\u00fc\u00b7ben", "Sinn's", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Alsbald der Ritter schlich;", "tokens": ["Als\u00b7bald", "der", "Rit\u00b7ter", "schlich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In Bawdin\u2019s Kerker trat er ein,", "tokens": ["In", "Ba\u00b7wdin's", "Ker\u00b7ker", "trat", "er", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und weinte bitterlich.", "tokens": ["Und", "wein\u00b7te", "bit\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Der sah des Alten Herzeleid;", "tokens": ["Der", "sah", "des", "Al\u00b7ten", "Her\u00b7ze\u00b7leid", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er trat an ihn heran:", "tokens": ["Er", "trat", "an", "ihn", "he\u00b7ran", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201ezu sterben, Freund, ist Menschenloos,", "tokens": ["\u201e", "zu", "ster\u00b7ben", ",", "Freund", ",", "ist", "Men\u00b7schen\u00b7loos", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VVINF", "$,", "NN", "$,", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was thut es \u201ewie\u201c und \u201ewann\u201c!", "tokens": ["Was", "thut", "es", "\u201e", "wie", "\u201c", "und", "\u201e", "wann", "\u201c", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$(", "PWAV", "$(", "KON", "$(", "PWAV", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "\u201emir war das Schicksal dieses Tags", "tokens": ["\u201e", "mir", "war", "das", "Schick\u00b7sal", "die\u00b7ses", "Tags"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Anbeginn bestimmt;", "tokens": ["Von", "An\u00b7be\u00b7ginn", "be\u00b7stimmt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dem\u00fcthig tr\u00e4gt ein Christenherz", "tokens": ["De\u00b7m\u00fct\u00b7hig", "tr\u00e4gt", "ein", "Chris\u00b7ten\u00b7herz"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was Gott ihm schickt und nimmt.", "tokens": ["Was", "Gott", "ihm", "schickt", "und", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "\u201emir ist der Tod Erl\u00f6sung nur", "tokens": ["\u201e", "mir", "ist", "der", "Tod", "Er\u00b7l\u00f6\u00b7sung", "nur"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Allem, was ich litt; \u2014", "tokens": ["Von", "Al\u00b7lem", ",", "was", "ich", "litt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was hast Du, da\u00df in\u2019s Auge Dir", "tokens": ["Was", "hast", "Du", ",", "da\u00df", "in's", "Au\u00b7ge", "Dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "$,", "KOUS", "APPRART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Mannesthr\u00e4ne tritt?!\u201c", "tokens": ["Die", "Man\u00b7nest\u00b7hr\u00e4\u00b7ne", "tritt", "?!", "\u201c"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Sprach Canning: \u201ewohl um Deinen Tod", "tokens": ["Sprach", "Can\u00b7ning", ":", "\u201e", "wohl", "um", "Dei\u00b7nen", "Tod"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$.", "$(", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hab ich der Thr\u00e4nen viel,", "tokens": ["Hab", "ich", "der", "Thr\u00e4\u00b7nen", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch denk ich an Dein Weib und Kind", "tokens": ["Doch", "denk", "ich", "an", "Dein", "Weib", "und", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Find ich nicht Maa\u00df nicht Ziel.\u201c", "tokens": ["Find", "ich", "nicht", "Maa\u00df", "nicht", "Ziel", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "NN", "PTKNEG", "NN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.20": {"line.1": {"text": "\u201edann trockne Dir die Thr\u00e4nen schnell\u201c, \u2014", "tokens": ["\u201e", "dann", "trock\u00b7ne", "Dir", "die", "Thr\u00e4\u00b7nen", "schnell", "\u201c", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ART", "NN", "ADJD", "$(", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Klang Bawdin\u2019s Stimme da \u2014", "tokens": ["Klang", "Ba\u00b7wdin's", "Stim\u00b7me", "da"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NN", "ADV", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u201eder Wittwen und der Waisen Gott", "tokens": ["\u201e", "der", "Witt\u00b7wen", "und", "der", "Wai\u00b7sen", "Gott"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist auch den meinen nah.", "tokens": ["Ist", "auch", "den", "mei\u00b7nen", "nah", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "\u201emich mag er meucheln der Tyrann,", "tokens": ["\u201e", "mich", "mag", "er", "meu\u00b7cheln", "der", "Ty\u00b7rann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der frech sich K\u00f6nig nennt;", "tokens": ["Der", "frech", "sich", "K\u00f6\u00b7nig", "nennt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch wei\u00df ich, da\u00df ihn Gottes Hand", "tokens": ["Doch", "wei\u00df", "ich", ",", "da\u00df", "ihn", "Got\u00b7tes", "Hand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von meinen Kindern trennt.", "tokens": ["Von", "mei\u00b7nen", "Kin\u00b7dern", "trennt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "\u201eund, Canning, ohne Bangen traun", "tokens": ["\u201e", "und", ",", "Can\u00b7ning", ",", "oh\u00b7ne", "Ban\u00b7gen", "traun"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "$,", "NE", "$,", "KOUI", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Thu\u2019 ich den letzten Gang;", "tokens": ["Thu'", "ich", "den", "letz\u00b7ten", "Gang", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hab ja dem Tod in\u2019s Aug\u2019 gesehn", "tokens": ["Hab", "ja", "dem", "Tod", "in's", "Aug'", "ge\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein halbes Leben lang.", "tokens": ["Ein", "hal\u00b7bes", "Le\u00b7ben", "lang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "\u201ewie oft, wenn guten Schwertes Hieb", "tokens": ["\u201e", "wie", "oft", ",", "wenn", "gu\u00b7ten", "Schwer\u00b7tes", "Hieb"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "ADV", "$,", "KOUS", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hell durch die L\u00fcfte pfiff,", "tokens": ["Hell", "durch", "die", "L\u00fcf\u00b7te", "pfiff", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und blindlings in die Schlacht hinein", "tokens": ["Und", "blind\u00b7lings", "in", "die", "Schlacht", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Tod nach Beute griff, \u2014", "tokens": ["Der", "Tod", "nach", "Beu\u00b7te", "griff", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "\u201ewie oft dann sah er wild mich an!", "tokens": ["\u201e", "wie", "oft", "dann", "sah", "er", "wild", "mich", "an", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich starrt ihm in\u2019s Gesicht;", "tokens": ["Ich", "starrt", "ihm", "in's", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er hob die Hand zum Speereswurf, \u2014", "tokens": ["Er", "hob", "die", "Hand", "zum", "Spee\u00b7res\u00b7wurf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Galt mir\u2019s? ich wu\u00dft es nicht.", "tokens": ["Galt", "mir's", "?", "ich", "wu\u00dft", "es", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "\u201eund nun, wegwerfen sollt\u2019 ich selbst", "tokens": ["\u201e", "und", "nun", ",", "weg\u00b7wer\u00b7fen", "sollt'", "ich", "selbst"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KON", "ADV", "$,", "VVINF", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Mannes beste Zier?", "tokens": ["Des", "Man\u00b7nes", "bes\u00b7te", "Zier", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Im Leben Muth, im Tode Muth", "tokens": ["Im", "Le\u00b7ben", "Muth", ",", "im", "To\u00b7de", "Muth"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "NN", "$,", "APPRART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das, Canning, schuld ich mir.", "tokens": ["Das", ",", "Can\u00b7ning", ",", "schuld", "ich", "mir", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "NE", "$,", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "\u201eund schuld es meinem Vater auch; \u2014", "tokens": ["\u201e", "und", "schuld", "es", "mei\u00b7nem", "Va\u00b7ter", "auch", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ADJD", "PPER", "PPOSAT", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der war ein Ritter gut:", "tokens": ["Der", "war", "ein", "Rit\u00b7ter", "gut", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rein war sein altes Wappenschild,", "tokens": ["Rein", "war", "sein", "al\u00b7tes", "Wap\u00b7pen\u00b7schild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und rein sein altes Blut.", "tokens": ["Und", "rein", "sein", "al\u00b7tes", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "\u201egesetz und Recht, die hielt er fest", "tokens": ["\u201e", "ge\u00b7setz", "und", "Recht", ",", "die", "hielt", "er", "fest"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "KON", "NN", "$,", "PRELS", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Wirrsal der Parthein;", "tokens": ["Im", "Wirr\u00b7sal", "der", "Part\u00b7hein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Die schwere Kunst war seine Kunst:", "tokens": ["Die", "schwe\u00b7re", "Kunst", "war", "sei\u00b7ne", "Kunst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gerecht und mild zu sein.", "tokens": ["Ge\u00b7recht", "und", "mild", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "\u201eso war sein Haus: ein offnes Thor,", "tokens": ["\u201e", "so", "war", "sein", "Haus", ":", "ein", "off\u00b7nes", "Thor", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPOSAT", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und offner Tisch dazu;", "tokens": ["Und", "off\u00b7ner", "Tisch", "da\u00b7zu", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dem Bettler bot er Speis\u2019 und Trank,", "tokens": ["Dem", "Bett\u00b7ler", "bot", "er", "Speis'", "und", "Trank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Pilger Rast und Ruh.", "tokens": ["Dem", "Pil\u00b7ger", "Rast", "und", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "\u201ean seines Namens blanker Ehr\u2019", "tokens": ["\u201e", "an", "sei\u00b7nes", "Na\u00b7mens", "blan\u00b7ker", "Ehr'"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Schande nie geklebt,", "tokens": ["Hat", "Schan\u00b7de", "nie", "ge\u00b7klebt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und seiner fleckenlosen Treu", "tokens": ["Und", "sei\u00b7ner", "fle\u00b7cken\u00b7lo\u00b7sen", "Treu"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der hab ich nachgestrebt.", "tokens": ["Der", "hab", "ich", "nach\u00b7ge\u00b7strebt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "\u201emir lebt ein Weib, ich hab ihr Bett", "tokens": ["\u201e", "mir", "lebt", "ein", "Weib", ",", "ich", "hab", "ihr", "Bett"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Treubr\u00fcchig nie entehrt, \u2014", "tokens": ["Treu\u00b7br\u00fc\u00b7chig", "nie", "ent\u00b7ehrt", ","], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADJD", "ADV", "VVPP", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nie auch von Heinrich\u2019s heil\u2019gem Recht", "tokens": ["Nie", "auch", "von", "Hein\u00b7rich's", "heil'\u00b7gem", "Recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich treulos abgekehrt.", "tokens": ["Mich", "treu\u00b7los", "ab\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "\u201edrum geh in Ruh ich diesen Gang,", "tokens": ["\u201e", "drum", "geh", "in", "Ruh", "ich", "die\u00b7sen", "Gang", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VVFIN", "APPR", "NN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und, Canning, sterbe gern;", "tokens": ["Und", ",", "Can\u00b7ning", ",", "ster\u00b7be", "gern", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "NE", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mein Auge wird den Tod nicht sehn", "tokens": ["Mein", "Au\u00b7ge", "wird", "den", "Tod", "nicht", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des K\u00f6nigs meines Herrn.\u201c", "tokens": ["Des", "K\u00f6\u00b7nigs", "mei\u00b7nes", "Herrn", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Charles Bawdin schwieg; \u2014 da klang\u2019s herauf", "tokens": ["Char\u00b7les", "Baw\u00b7din", "schwieg", ";", "da", "klang's", "her\u00b7auf"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PTKVZ"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wie Rossesstampfen schon,", "tokens": ["Wie", "Ros\u00b7sess\u00b7tamp\u00b7fen", "schon", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die rost\u2019gen Angeln drehten sich", "tokens": ["Die", "rost'\u00b7gen", "An\u00b7geln", "dreh\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gaben schrillen Ton.", "tokens": ["Und", "ga\u00b7ben", "schril\u00b7len", "Ton", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Hell in des Kerkers offne Th\u00fcr", "tokens": ["Hell", "in", "des", "Ker\u00b7kers", "off\u00b7ne", "Th\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Drang jungen Tages Schein,", "tokens": ["Drang", "jun\u00b7gen", "Ta\u00b7ges", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und mit dem Licht des Morgens trat", "tokens": ["Und", "mit", "dem", "Licht", "des", "Mor\u00b7gens", "trat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein weinend Weib herein.", "tokens": ["Ein", "wei\u00b7nend", "Weib", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Charles Bawdin\u2019s Weib. Der Ritter sprach:", "tokens": ["Char\u00b7les", "Ba\u00b7wdin's", "Weib", ".", "Der", "Rit\u00b7ter", "sprach", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$.", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201ela\u00df sterben mich in Ruh,", "tokens": ["\u201e", "la\u00df", "ster\u00b7ben", "mich", "in", "Ruh", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wende nicht die Seele mein", "tokens": ["Und", "wen\u00b7de", "nicht", "die", "See\u00b7le", "mein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Irdschen wieder zu.", "tokens": ["Dem", "Ird\u00b7schen", "wie\u00b7der", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "\u201ela\u00df ab! Die Thr\u00e4n\u2019 in Deinem Aug\u2019", "tokens": ["\u201e", "la\u00df", "ab", "!", "Die", "Thr\u00e4n'", "in", "Dei\u00b7nem", "Aug'"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVIMP", "PTKVZ", "$.", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht mir das Herze weich,", "tokens": ["Macht", "mir", "das", "Her\u00b7ze", "weich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PDS", "VVFIN", "ADJD", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und w\u00e4scht dem frischen Muth in mir", "tokens": ["Und", "w\u00e4scht", "dem", "fri\u00b7schen", "Muth", "in", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Wange wieder bleich.\u201c", "tokens": ["Die", "Wan\u00b7ge", "wie\u00b7der", "bleich", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Er sprach\u2019s und schwieg. Das blasse Weib", "tokens": ["Er", "sprach's", "und", "schwieg", ".", "Das", "blas\u00b7se", "Weib"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sah starr ihm in\u2019s Gesicht,", "tokens": ["Sah", "starr", "ihm", "in's", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Ohr vernahm die Worte wohl", "tokens": ["Ihr", "Ohr", "ver\u00b7nahm", "die", "Wor\u00b7te", "wohl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00f6rte doch sie nicht.", "tokens": ["Und", "h\u00f6r\u00b7te", "doch", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Dann rief sie, da\u00df ihr Schmerzensschrei", "tokens": ["Dann", "rief", "sie", ",", "da\u00df", "ihr", "Schmer\u00b7zens\u00b7schrei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm in die Seele schnitt:", "tokens": ["Ihm", "in", "die", "See\u00b7le", "schnitt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201edas Beil, das Deinen Nacken trifft,", "tokens": ["\u201e", "das", "Beil", ",", "das", "Dei\u00b7nen", "Na\u00b7cken", "trifft", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O tr\u00e4f es doch mich mit!\u201c", "tokens": ["O", "tr\u00e4f", "es", "doch", "mich", "mit", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Hin sank sie; Bawdin k\u00fcsste leis", "tokens": ["Hin", "sank", "sie", ";", "Baw\u00b7din", "k\u00fcss\u00b7te", "leis"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "$.", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Stirne sie und Wang;", "tokens": ["Auf", "Stir\u00b7ne", "sie", "und", "Wang", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann sprach er: \u201eSchlie\u00dfer, nimm mich hin", "tokens": ["Dann", "sprach", "er", ":", "\u201e", "Schlie\u00b7\u00dfer", ",", "nimm", "mich", "hin"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "NN", "$,", "VVIMP", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf meinem letzten Gang!\u201c", "tokens": ["Auf", "mei\u00b7nem", "letz\u00b7ten", "Gang", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Er trat hinaus; da stand der Karrn", "tokens": ["Er", "trat", "hin\u00b7aus", ";", "da", "stand", "der", "Karrn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der sonst nur Sch\u00e4cher trug,", "tokens": ["Der", "sonst", "nur", "Sch\u00e4\u00b7cher", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und alsobald zum Richtplatz hin", "tokens": ["Und", "al\u00b7so\u00b7bald", "zum", "Richt\u00b7platz", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bewegte sich der Zug.", "tokens": ["Be\u00b7weg\u00b7te", "sich", "der", "Zug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Der Zug war so: der Richter vorn", "tokens": ["Der", "Zug", "war", "so", ":", "der", "Rich\u00b7ter", "vorn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In seines Amts Geschmeid,", "tokens": ["In", "sei\u00b7nes", "Amts", "Ge\u00b7schmeid", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hell glitzerte das Quastengold", "tokens": ["Hell", "glit\u00b7zer\u00b7te", "das", "Quas\u00b7ten\u00b7gold"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An seinem Scharlachkleid.", "tokens": ["An", "sei\u00b7nem", "Schar\u00b7lach\u00b7kleid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Zw\u00f6lf Augustiner kamen dann", "tokens": ["Zw\u00f6lf", "Au\u00b7gus\u00b7ti\u00b7ner", "ka\u00b7men", "dann"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "In h\u00e4renem Gewand,", "tokens": ["In", "h\u00e4\u00b7re\u00b7nem", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Rosenkranz und Gei\u00dfelstrick", "tokens": ["Mit", "Ro\u00b7sen\u00b7kranz", "und", "Gei\u00b7\u00dfel\u00b7strick"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In recht- und linker Hand.", "tokens": ["In", "recht", "und", "lin\u00b7ker", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Bu\u00dfpsalme sangen finster sie", "tokens": ["Bu\u00df\u00b7psal\u00b7me", "san\u00b7gen", "fins\u00b7ter", "sie"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJD", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In m\u00e4chtgen Melodien,", "tokens": ["In", "m\u00e4cht\u00b7gen", "Me\u00b7lo\u00b7dien", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und nieder schrillte Gl\u00f6cklein Klang", "tokens": ["Und", "nie\u00b7der", "schrill\u00b7te", "Gl\u00f6c\u00b7klein", "Klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PTKVZ", "VVFIN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Thurme Sankt Marien.", "tokens": ["Vom", "Thur\u00b7me", "Sankt", "Ma\u00b7ri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Den M\u00f6nchen folgte, festen Schritts", "tokens": ["Den", "M\u00f6n\u00b7chen", "folg\u00b7te", ",", "fes\u00b7ten", "Schritts"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Bogensch\u00fctzen-Hauf:", "tokens": ["Ein", "Bo\u00b7gen\u00b7sch\u00fct\u00b7zen\u00b7Hauf", ":"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Sennen waren all gespannt,", "tokens": ["Die", "Sen\u00b7nen", "wa\u00b7ren", "all", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Pfeile lagen auf.", "tokens": ["Die", "Pfei\u00b7le", "la\u00b7gen", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Wohl mocht ein Rest lankastrisch Volk", "tokens": ["Wohl", "mocht", "ein", "Rest", "lan\u00b7kast\u00b7risch", "Volk"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Ritter noch befrein,", "tokens": ["Den", "Rit\u00b7ter", "noch", "be\u00b7fr\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es durfte Bawdin\u2019s letzter Gang", "tokens": ["Es", "durf\u00b7te", "Ba\u00b7wdin's", "letz\u00b7ter", "Gang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der seiner Feinde sein.", "tokens": ["Der", "sei\u00b7ner", "Fein\u00b7de", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Dann kam er selbst: zwei Rappen vorn", "tokens": ["Dann", "kam", "er", "selbst", ":", "zwei", "Rap\u00b7pen", "vorn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "CARD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In wei\u00dfer Decken Putz,", "tokens": ["In", "wei\u00b7\u00dfer", "De\u00b7cken", "Putz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf ihren K\u00f6pfen wiegte sich", "tokens": ["Auf", "ih\u00b7ren", "K\u00f6p\u00b7fen", "wieg\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein schwarzer Federstutz.", "tokens": ["Ein", "schwar\u00b7zer", "Fe\u00b7der\u00b7stutz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Und wieder dann kam festen Schritts", "tokens": ["Und", "wie\u00b7der", "dann", "kam", "fes\u00b7ten", "Schritts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Bogensch\u00fctzen-Hauf:", "tokens": ["Ein", "Bo\u00b7gen\u00b7sch\u00fct\u00b7zen\u00b7Hauf", ":"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Sennen waren all gespannt,", "tokens": ["Die", "Sen\u00b7nen", "wa\u00b7ren", "all", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Pfeile lagen auf.", "tokens": ["Die", "Pfei\u00b7le", "la\u00b7gen", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Zw\u00f6lf Augustiner wieder dann", "tokens": ["Zw\u00f6lf", "Au\u00b7gus\u00b7ti\u00b7ner", "wie\u00b7der", "dann"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Psalmesmelodien, \u2014", "tokens": ["Mit", "Psal\u00b7mes\u00b7me\u00b7lo\u00b7di\u00b7en", ","], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und immer noch scholl Gl\u00f6cklein Klang", "tokens": ["Und", "im\u00b7mer", "noch", "scholl", "Gl\u00f6c\u00b7klein", "Klang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADJD", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Thurme Sankt Marien.", "tokens": ["Vom", "Thur\u00b7me", "Sankt", "Ma\u00b7ri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Den Schlu\u00df, den machte stra\u00dfenbreit", "tokens": ["Den", "Schlu\u00df", ",", "den", "mach\u00b7te", "stra\u00b7\u00dfen\u00b7breit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Volkes dicht Gedr\u00e4ng:", "tokens": ["Des", "Vol\u00b7kes", "dicht", "Ge\u00b7dr\u00e4ng", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von Dach und Fenster folgte man", "tokens": ["Von", "Dach", "und", "Fens\u00b7ter", "folg\u00b7te", "man"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem traurigen Gepr\u00e4ng.", "tokens": ["Dem", "trau\u00b7ri\u00b7gen", "Ge\u00b7pr\u00e4ng", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "Und jetzt an Christi Kreuz vorbei", "tokens": ["Und", "jetzt", "an", "Chris\u00b7ti", "Kreuz", "vor\u00b7bei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NE", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bewegte sich der Zug,", "tokens": ["Be\u00b7weg\u00b7te", "sich", "der", "Zug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hernieder schaute still das Lamm,", "tokens": ["Her\u00b7nie\u00b7der", "schau\u00b7te", "still", "das", "Lamm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das unsre S\u00fcnden trug.", "tokens": ["Das", "uns\u00b7re", "S\u00fcn\u00b7den", "trug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "Und Bawdin betete und sprach:", "tokens": ["Und", "Baw\u00b7din", "be\u00b7te\u00b7te", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eerbarm, o Herr, Dich mein,", "tokens": ["\u201e", "er\u00b7barm", ",", "o", "Herr", ",", "Dich", "mein", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "FM", "NN", "$,", "PPER", "PPOSAT", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wasch auch meine Seele heut", "tokens": ["Und", "wasch", "auch", "mei\u00b7ne", "See\u00b7le", "heut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADV", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von ihren Flecken rein!\u201c", "tokens": ["Von", "ih\u00b7ren", "Fle\u00b7cken", "rein", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "Er sprach\u2019s. Der K\u00f6nig aber stund", "tokens": ["Er", "sprach'", "s.", "Der", "K\u00f6\u00b7nig", "a\u00b7ber", "stund"], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVIMP", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Schlosses Fenster schon,", "tokens": ["An", "Schlos\u00b7ses", "Fens\u00b7ter", "schon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In seinem Antlitz paarte sich", "tokens": ["In", "sei\u00b7nem", "Ant\u00b7litz", "paar\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Rache und der Hohn.", "tokens": ["Die", "Ra\u00b7che", "und", "der", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "Charles Bawdin sah\u2019s; in seinem Karrn", "tokens": ["Char\u00b7les", "Baw\u00b7din", "sah's", ";", "in", "sei\u00b7nem", "Karrn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "NE", "$.", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Hob er sich stolz empor,", "tokens": ["Hob", "er", "sich", "stolz", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und donnerte mit fester Stimm", "tokens": ["Und", "don\u00b7ner\u00b7te", "mit", "fes\u00b7ter", "Stimm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An K\u00f6nig Edwards Ohr:", "tokens": ["An", "K\u00f6\u00b7nig", "Ed\u00b7wards", "Ohr", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.53": {"line.1": {"text": "\u201everr\u00e4ther, der Du bleibst und bist,", "tokens": ["\u201e", "ver\u00b7r\u00e4\u00b7ther", ",", "der", "Du", "bleibst", "und", "bist", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PRELS", "PPER", "VVFIN", "KON", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schau nur in Hohn mir zu,", "tokens": ["Schau", "nur", "in", "Hohn", "mir", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "PPER", "PTKVZ", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wie klein mich Deine Rache macht", "tokens": ["Wie", "klein", "mich", "Dei\u00b7ne", "Ra\u00b7che", "macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PPER", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bin gr\u00f6\u00dfer doch als Du.", "tokens": ["Bin", "gr\u00f6\u00b7\u00dfer", "doch", "als", "Du", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.54": {"line.1": {"text": "\u201edurch Mord und jede faule That", "tokens": ["\u201e", "durch", "Mord", "und", "je\u00b7de", "fau\u00b7le", "That"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "NN", "KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tr\u00e4gst Du die Krone Dein,", "tokens": ["Tr\u00e4gst", "Du", "die", "Kro\u00b7ne", "Dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch klebtest Du mit Blut sie fest", "tokens": ["Doch", "kleb\u00b7test", "Du", "mit", "Blut", "sie", "fest"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird doch nie Deine sein.", "tokens": ["Wird", "doch", "nie", "Dei\u00b7ne", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}