{"textgrid.poem.53774": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Stimme aus den Kalkgruben", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Unser Leib ist l\u00e4ngst zerfallen.", "tokens": ["Un\u00b7ser", "Leib", "ist", "l\u00e4ngst", "zer\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ehemalige H\u00e4nde krallen", "tokens": ["E\u00b7hem\u00b7a\u00b7li\u00b7ge", "H\u00e4n\u00b7de", "kral\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "in den Kopf des Nebenmanns", "tokens": ["in", "den", "Kopf", "des", "Ne\u00b7ben\u00b7manns"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "nach dem Tanz.", "tokens": ["nach", "dem", "Tanz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Hoch am Licht, da sind zum Beten", "tokens": ["Hoch", "am", "Licht", ",", "da", "sind", "zum", "Be\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "APPRART", "NN", "$,", "ADV", "VAFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "tausend Kreuze angetreten.", "tokens": ["tau\u00b7send", "Kreu\u00b7ze", "an\u00b7ge\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ein Gezischel l\u00e4uft umher:", "tokens": ["Ein", "Ge\u00b7zi\u00b7schel", "l\u00e4uft", "um\u00b7her", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.8": {"text": "\u00bbder \u2013?\u00ab", "tokens": ["\u00bb", "der", "\u2013", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct"], "pos": ["$(", "ART", "$(", "$.", "$("], "meter": "-", "measure": "single.down"}}, "stanza.2": {"line.1": {"text": "Daf\u00fcr faulen ausgewaschen", "tokens": ["Da\u00b7f\u00fcr", "fau\u00b7len", "aus\u00b7ge\u00b7wa\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["PAV", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6pfe und Patronentaschen?", "tokens": ["K\u00f6p\u00b7fe", "und", "Pat\u00b7ro\u00b7nen\u00b7ta\u00b7schen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00e4nde an die Hosennaht", "tokens": ["H\u00e4n\u00b7de", "an", "die", "Ho\u00b7sen\u00b7naht"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "steht ein Staat.", "tokens": ["steht", "ein", "Staat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Die Genossen, Demokraten,", "tokens": ["Die", "Ge\u00b7nos\u00b7sen", ",", "De\u00b7mo\u00b7kra\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "keiner wagt sich an Soldaten.", "tokens": ["kei\u00b7ner", "wagt", "sich", "an", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "\u00bbsiegreich f\u00fchrte er das Heer!\u00ab", "tokens": ["\u00bb", "sieg\u00b7reich", "f\u00fchr\u00b7te", "er", "das", "Heer", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Der \u2013?", "tokens": ["Der", "\u2013", "?"], "token_info": ["word", "punct", "punct"], "pos": ["ART", "$(", "$."], "meter": "-", "measure": "single.down"}}, "stanza.3": {"line.1": {"text": "Freikorps gie\u00dft sich auf die Lampe", "tokens": ["Frei\u00b7korps", "gie\u00dft", "sich", "auf", "die", "Lam\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "einen Stahlhelm voller Mampe.", "tokens": ["ei\u00b7nen", "Stahl\u00b7helm", "vol\u00b7ler", "Mam\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kaufmann steht dabei und kl\u00e4fft:", "tokens": ["Kauf\u00b7mann", "steht", "da\u00b7bei", "und", "kl\u00e4fft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbdas Gesch\u00e4ft . . . !\u00ab", "tokens": ["\u00bb", "das", "Ge\u00b7sch\u00e4ft", ".", ".", ".", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "ART", "NN", "$.", "$.", "$.", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Marsch \u2013 marsch! \u00c4rmel aufgekrempelt!", "tokens": ["Marsch", "\u2013", "marsch", "!", "\u00c4r\u00b7mel", "auf\u00b7ge\u00b7krem\u00b7pelt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJD", "$.", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vor der Welt sind wir gestempelt.", "tokens": ["Vor", "der", "Welt", "sind", "wir", "ge\u00b7stem\u00b7pelt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Der Extrakt von uns ist wer \u2013?", "tokens": ["Der", "Ex\u00b7trakt", "von", "uns", "ist", "wer", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "PWS", "$(", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Der.", "tokens": ["Der", "."], "token_info": ["word", "punct"], "pos": ["ART", "$."], "meter": "-", "measure": "single.down"}}}}}