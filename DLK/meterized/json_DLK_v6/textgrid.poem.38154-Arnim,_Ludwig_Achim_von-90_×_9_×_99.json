{"textgrid.poem.38154": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "90 \u00d7 9 \u00d7 99", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es waren einmal die Schneider,", "tokens": ["Es", "wa\u00b7ren", "ein\u00b7mal", "die", "Schnei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die hatten guten Muth,", "tokens": ["Die", "hat\u00b7ten", "gu\u00b7ten", "Muth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da tranken ihrer neunzig,", "tokens": ["Da", "tran\u00b7ken", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Aus einem Fingerhut.", "tokens": ["Aus", "ei\u00b7nem", "Fin\u00b7ger\u00b7hut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und als die Schneider versammelt waren,", "tokens": ["Und", "als", "die", "Schnei\u00b7der", "ver\u00b7sam\u00b7melt", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NE", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da hielten sie einen Rath,", "tokens": ["Da", "hiel\u00b7ten", "sie", "ei\u00b7nen", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da sassen ihrer neunzig,", "tokens": ["Da", "sas\u00b7sen", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig,", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Auf einem Kartenblat.", "tokens": ["Auf", "ei\u00b7nem", "Kar\u00b7ten\u00b7blat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und als die Schneider nach Hause kamen,", "tokens": ["Und", "als", "die", "Schnei\u00b7der", "nach", "Hau\u00b7se", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NE", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da k\u00f6nnen sie nicht hinein,", "tokens": ["Da", "k\u00f6n\u00b7nen", "sie", "nicht", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da schlupften ihrer neunzig,", "tokens": ["Da", "schlupf\u00b7ten", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Zum Schl\u00fcsselloch hinein.", "tokens": ["Zum", "Schl\u00fcs\u00b7sel\u00b7loch", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und als die Schneider recht lustig waren,", "tokens": ["Und", "als", "die", "Schnei\u00b7der", "recht", "lus\u00b7tig", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NE", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da hielten sie einen Tanz,", "tokens": ["Da", "hiel\u00b7ten", "sie", "ei\u00b7nen", "Tanz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da tanzten ihrer neunzig,", "tokens": ["Da", "tanz\u00b7ten", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Auf einem Geisenschwanz.", "tokens": ["Auf", "ei\u00b7nem", "Gei\u00b7sen\u00b7schwanz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und als sie auf der Herberg waren,", "tokens": ["Und", "als", "sie", "auf", "der", "Her\u00b7berg", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da hielten sie einen Schmau\u00df,", "tokens": ["Da", "hiel\u00b7ten", "sie", "ei\u00b7nen", "Schmau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da fra\u00dfen ihrer neunzig,", "tokens": ["Da", "fra\u00b7\u00dfen", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig,", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "An einer gebacknen Maus.", "tokens": ["An", "ei\u00b7ner", "ge\u00b7back\u00b7nen", "Maus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Und als ein Schnee gefallen war,", "tokens": ["Und", "als", "ein", "Schnee", "ge\u00b7fal\u00b7len", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da hielten sie Schlittenfahrt,", "tokens": ["Da", "hiel\u00b7ten", "sie", "Schlit\u00b7ten\u00b7fahrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da fuhren ihrer neunzig,", "tokens": ["Da", "fuh\u00b7ren", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Auf einem Geisenbarth.", "tokens": ["Auf", "ei\u00b7nem", "Gei\u00b7sen\u00b7barth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und als die Schneider nach Hause wollen,", "tokens": ["Und", "als", "die", "Schnei\u00b7der", "nach", "Hau\u00b7se", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NE", "APPR", "NN", "VMFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da haben sie keinen Bock,", "tokens": ["Da", "ha\u00b7ben", "sie", "kei\u00b7nen", "Bock", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da reiten ihrer neunzig,", "tokens": ["Da", "rei\u00b7ten", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Auf einem Haselstock.", "tokens": ["Auf", "ei\u00b7nem", "Ha\u00b7sel\u00b7stock", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und als die Schneider nach Hause kamen,", "tokens": ["Und", "als", "die", "Schnei\u00b7der", "nach", "Hau\u00b7se", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NE", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da sa\u00dfen sie beim Wein,", "tokens": ["Da", "sa\u00b7\u00dfen", "sie", "beim", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da tranken ihrer neunzig,", "tokens": ["Da", "tran\u00b7ken", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "An einem Sch\u00f6pplein Wein.", "tokens": ["An", "ei\u00b7nem", "Sch\u00f6p\u00b7plein", "Wein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und als sie all besoffen warn,", "tokens": ["Und", "als", "sie", "all", "be\u00b7sof\u00b7fen", "warn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sah man sie nicht mehr,", "tokens": ["Da", "sah", "man", "sie", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da krochen ihrer neunzig,", "tokens": ["Da", "kro\u00b7chen", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "In eine Lichtputzscheer.", "tokens": ["In", "ei\u00b7ne", "Licht\u00b7putz\u00b7scheer", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und als sie ausgeschlafen hatten,", "tokens": ["Und", "als", "sie", "aus\u00b7ge\u00b7schla\u00b7fen", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da k\u00f6nnen sie nicht heraus,", "tokens": ["Da", "k\u00f6n\u00b7nen", "sie", "nicht", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da wirft sie alle neunzig,", "tokens": ["Da", "wirft", "sie", "al\u00b7le", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Der Wirth zum Fenster hinaus.", "tokens": ["Der", "Wirth", "zum", "Fens\u00b7ter", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "Und als sie vor das Fenster kamen,", "tokens": ["Und", "als", "sie", "vor", "das", "Fens\u00b7ter", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da fallen sie um und um,", "tokens": ["Da", "fal\u00b7len", "sie", "um", "und", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da kommen ihrer neunzig,", "tokens": ["Da", "kom\u00b7men", "ih\u00b7rer", "neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "CARD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun mal neun und neunzig", "tokens": ["Neun", "mal", "neun", "und", "neun\u00b7zig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "In einem Kandel um.", "tokens": ["In", "ei\u00b7nem", "Kan\u00b7del", "um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}