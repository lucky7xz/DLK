{"textgrid.poem.54067": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Die M\u00e4uler auf!", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Heilgebr\u00fcll und v\u00f6lksche Heilung,", "tokens": ["Heil\u00b7ge\u00b7br\u00fcll", "und", "v\u00f6lk\u00b7sche", "Hei\u00b7lung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "schnittig, zackig, forsch und p\u00e4ng!", "tokens": ["schnit\u00b7tig", ",", "za\u00b7ckig", ",", "forsch", "und", "p\u00e4ng", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Staffelf\u00fchrer, Sturmabteilung,", "tokens": ["Staf\u00b7fel\u00b7f\u00fch\u00b7rer", ",", "Sturm\u00b7ab\u00b7tei\u00b7lung", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Blechkapellen, schn\u00e4dder\u00e4d\u00e4ng!", "tokens": ["Blech\u00b7ka\u00b7pel\u00b7len", ",", "schn\u00e4d\u00b7de\u00b7r\u00e4\u00b7d\u00e4ng", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Judenfresser, Stra\u00dfenmeute . . .", "tokens": ["Ju\u00b7den\u00b7fres\u00b7ser", ",", "Stra\u00b7\u00dfen\u00b7meu\u00b7te", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["NE", "$,", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kleine Leute. Kleine Leute.", "tokens": ["Klei\u00b7ne", "Leu\u00b7te", ".", "Klei\u00b7ne", "Leu\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Arme Luder br\u00fclln sich heiser,", "tokens": ["Ar\u00b7me", "Lu\u00b7der", "br\u00fclln", "sich", "hei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PRF", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "tausend H\u00e4ndefuchteln wild.", "tokens": ["tau\u00b7send", "H\u00e4n\u00b7de\u00b7fuch\u00b7teln", "wild", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hitler als der selige Kaiser,", "tokens": ["Hit\u00b7ler", "als", "der", "se\u00b7li\u00b7ge", "Kai\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "wie ein schlechtes Abziehbild.", "tokens": ["wie", "ein", "schlech\u00b7tes", "Ab\u00b7zieh\u00b7bild", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jedes dicken Schlagworts Beute:", "tokens": ["Je\u00b7des", "di\u00b7cken", "Schlag\u00b7worts", "Beu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kleine Leute! Kleine Leute!", "tokens": ["Klei\u00b7ne", "Leu\u00b7te", "!", "Klei\u00b7ne", "Leu\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Tun sich mit dem teutschen Land dick,", "tokens": ["Tun", "sich", "mit", "dem", "teut\u00b7schen", "Land", "dick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "APPR", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "grunzen wie das liebe Vieh.", "tokens": ["grun\u00b7zen", "wie", "das", "lie\u00b7be", "Vieh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Allerbilligste Romantik \u2013", "tokens": ["Al\u00b7ler\u00b7bil\u00b7ligs\u00b7te", "Ro\u00b7man\u00b7tik", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "hinten zahlt die Industrie.", "tokens": ["hin\u00b7ten", "zahlt", "die", "In\u00b7dust\u00b7rie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hinten zahlt die Landwirtschaft.", "tokens": ["Hin\u00b7ten", "zahlt", "die", "Land\u00b7wirt\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Toben sie auch fieberhaft:", "tokens": ["To\u00b7ben", "sie", "auch", "fie\u00b7ber\u00b7haft", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Sind doch schlechte deutsche Barden,", "tokens": ["Sind", "doch", "schlech\u00b7te", "deut\u00b7sche", "Bar\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "bunte Unternehmergarden!", "tokens": ["bun\u00b7te", "Un\u00b7ter\u00b7neh\u00b7mer\u00b7gar\u00b7den", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Bleiben gestern, morgen, heute", "tokens": ["Blei\u00b7ben", "ge\u00b7stern", ",", "mor\u00b7gen", ",", "heu\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "VVINF", "$,", "ADV", "$,", "ADV"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "kleine Leute! kleine Leute!", "tokens": ["klei\u00b7ne", "Leu\u00b7te", "!", "klei\u00b7ne", "Leu\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}