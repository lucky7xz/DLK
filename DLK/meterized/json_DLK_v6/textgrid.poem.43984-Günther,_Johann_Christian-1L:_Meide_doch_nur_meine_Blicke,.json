{"textgrid.poem.43984": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Meide doch nur meine Blicke,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Meide doch nur meine Blicke,", "tokens": ["Mei\u00b7de", "doch", "nur", "mei\u00b7ne", "Bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du vor mich gefehrlichs Kind,", "tokens": ["Du", "vor", "mich", "ge\u00b7fehr\u00b7lichs", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil sie nur Versuchungsstricke", "tokens": ["Weil", "sie", "nur", "Ver\u00b7su\u00b7chungs\u00b7stri\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Nachreu Neze sind.", "tokens": ["Und", "der", "Nach\u00b7reu", "Ne\u00b7ze", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Phillis herrscht in meinem Herzen", "tokens": ["Phil\u00b7lis", "herrscht", "in", "mei\u00b7nem", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und begehrt dies Reich allein,", "tokens": ["Und", "be\u00b7gehrt", "dies", "Reich", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Darum darf kein fremdes Scherzen", "tokens": ["Da\u00b7rum", "darf", "kein", "frem\u00b7des", "Scher\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und kein neuer Trieb hinein.", "tokens": ["Und", "kein", "neu\u00b7er", "Trieb", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich gesteh ohn alle S\u00fcnde:", "tokens": ["Ich", "ge\u00b7steh", "ohn", "al\u00b7le", "S\u00fcn\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dein Gesicht ist liebenswerth,", "tokens": ["Dein", "Ge\u00b7sicht", "ist", "lie\u00b7bens\u00b7werth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ich viel darinnen finde,", "tokens": ["Weil", "ich", "viel", "da\u00b7rin\u00b7nen", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was die klugen Geister n\u00e4hrt.", "tokens": ["Was", "die", "klu\u00b7gen", "Geis\u00b7ter", "n\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4ren mir der Phillis K\u00fc\u00dfe", "tokens": ["W\u00e4\u00b7ren", "mir", "der", "Phil\u00b7lis", "K\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch im Finstern nicht bekand,", "tokens": ["Auch", "im", "Fins\u00b7tern", "nicht", "be\u00b7kand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "H\u00e4tt ich deinem sanften Bi\u00dfe", "tokens": ["H\u00e4tt", "ich", "dei\u00b7nem", "sanf\u00b7ten", "Bi\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Gleich die Freyheit zugewand.", "tokens": ["Gleich", "die", "Frey\u00b7heit", "zu\u00b7ge\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Himmel, schr\u00e4nckstu auch die Liebe", "tokens": ["Him\u00b7mel", ",", "schr\u00e4ncks\u00b7tu", "auch", "die", "Lie\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch der Menschen Sazung ein?", "tokens": ["Durch", "der", "Men\u00b7schen", "Sa\u00b7zung", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "D\u00fcrften denn die zarten Triebe", "tokens": ["D\u00fcrf\u00b7ten", "denn", "die", "zar\u00b7ten", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht in viel zertheilet seyn?", "tokens": ["Nicht", "in", "viel", "zer\u00b7thei\u00b7let", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sehen mu\u00df man, auch begehren", "tokens": ["Se\u00b7hen", "mu\u00df", "man", ",", "auch", "be\u00b7geh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "VMFIN", "PIS", "$,", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und gleichwohl zur\u00fccke stehn;", "tokens": ["Und", "gleich\u00b7wohl", "zu\u00b7r\u00fc\u00b7cke", "stehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Pflegstu doch mit Hund und B\u00e4ren", "tokens": ["Pflegs\u00b7tu", "doch", "mit", "Hund", "und", "B\u00e4\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Viel gelinder umzugehn.", "tokens": ["Viel", "ge\u00b7lin\u00b7der", "um\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVIZU", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}