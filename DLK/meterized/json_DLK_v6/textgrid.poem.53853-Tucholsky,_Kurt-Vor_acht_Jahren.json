{"textgrid.poem.53853": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Vor acht Jahren", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja, damals \u2013!", "tokens": ["Ja", ",", "da\u00b7mals", "\u2013", "!"], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$(", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Da hat zum ersten Mal", "tokens": ["Da", "hat", "zum", "ers\u00b7ten", "Mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "in Preu\u00dfen die Erde gezittert.", "tokens": ["in", "Preu\u00b7\u00dfen", "die", "Er\u00b7de", "ge\u00b7zit\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Da f\u00fchlte der letzte Korporal:", "tokens": ["Da", "f\u00fchl\u00b7te", "der", "letz\u00b7te", "Kor\u00b7po\u00b7ral", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Dicke Luft! es gewittert!", "tokens": ["Di\u00b7cke", "Luft", "!", "es", "ge\u00b7wit\u00b7tert", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "PPER", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Sie rissen den Kesseln die Feuer heraus.", "tokens": ["Sie", "ris\u00b7sen", "den", "Kes\u00b7seln", "die", "Feu\u00b7er", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Gewehre herunter! Und alle nach Haus.", "tokens": ["Ge\u00b7weh\u00b7re", "her\u00b7un\u00b7ter", "!", "Und", "al\u00b7le", "nach", "Haus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "KON", "PIS", "APPR", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Ja, damals . . .", "tokens": ["Ja", ",", "da\u00b7mals", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$.", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Wo waren sie damals doch:", "tokens": ["Wo", "wa\u00b7ren", "sie", "da\u00b7mals", "doch", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "die Kaisers mit Ordensketten?", "tokens": ["die", "Kai\u00b7sers", "mit", "Or\u00b7dens\u00b7ket\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie sa\u00dfen zitternd im Mauseloch,", "tokens": ["Sie", "sa\u00b7\u00dfen", "zit\u00b7ternd", "im", "Mau\u00b7se\u00b7loch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "auf Autos und Damentoiletten.", "tokens": ["auf", "Au\u00b7tos", "und", "Da\u00b7men\u00b7to\u00b7i\u00b7let\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Kronprinz, Offiziere \u2013 mucksm\u00e4uschenstumm.", "tokens": ["Kron\u00b7prinz", ",", "Of\u00b7fi\u00b7zie\u00b7re", "\u2013", "mucks\u00b7m\u00e4u\u00b7schen\u00b7stumm", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "FM.la", "$(", "ADJD", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Keiner stand grade. Alle fielen um.", "tokens": ["Kei\u00b7ner", "stand", "gra\u00b7de", ".", "Al\u00b7le", "fie\u00b7len", "um", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$.", "PIS", "VVFIN", "PTKVZ", "$."], "meter": "+----+-+-+", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Ja, damals . . .", "tokens": ["Ja", ",", "da\u00b7mals", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$.", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Heut ist das so lange her . . . !", "tokens": ["Heut", "ist", "das", "so", "lan\u00b7ge", "her", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["ADV", "VAFIN", "PDS", "ADV", "ADV", "PTKVZ", "$.", "$.", "$.", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie sind alle wieder oben.", "tokens": ["Sie", "sind", "al\u00b7le", "wie\u00b7der", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Justizverbrecher. Schimmernde Wehr.", "tokens": ["Jus\u00b7tiz\u00b7ver\u00b7bre\u00b7cher", ".", "Schim\u00b7mern\u00b7de", "Wehr", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Alles wieder erschoben.", "tokens": ["Al\u00b7les", "wie\u00b7der", "er\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Halts Maul, Deutscher! Verdien! Verdien", "tokens": ["Halts", "Maul", ",", "Deut\u00b7scher", "!", "Ver\u00b7di\u00b7en", "!", "Ver\u00b7di\u00b7en"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NE", "NN", "$,", "NN", "$.", "NN", "$.", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "das Fressen f\u00fcr zwanzig Monarchien.", "tokens": ["das", "Fres\u00b7sen", "f\u00fcr", "zwan\u00b7zig", "Mon\u00b7ar\u00b7chi\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Ja, damals \u2013!", "tokens": ["Ja", ",", "da\u00b7mals", "\u2013", "!"], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$(", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Wie haben sie das getauft?", "tokens": ["Wie", "ha\u00b7ben", "sie", "das", "ge\u00b7tauft", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PDS", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Revolution? Das war keine.", "tokens": ["Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "?", "Das", "war", "kei\u00b7ne", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PDS", "VAFIN", "PIAT", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sie haben dich verraten und verkauft.", "tokens": ["Sie", "ha\u00b7ben", "dich", "ver\u00b7ra\u00b7ten", "und", "ver\u00b7kauft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Du denk immer das eine:", "tokens": ["Du", "denk", "im\u00b7mer", "das", "ei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ART", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "1918? Gesegnete Zahl.", "tokens": ["?", "Ge\u00b7se\u00b7gne\u00b7te", "Zahl", "."], "token_info": ["punct", "word", "word", "punct"], "pos": ["$.", "NN", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "N\u00e4chstes Mal besser.", "tokens": ["N\u00e4chs\u00b7tes", "Mal", "bes\u00b7ser", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Nochmal. Nochmal.", "tokens": ["Noch\u00b7mal", ".", "Noch\u00b7mal", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADV", "$.", "ADV", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}