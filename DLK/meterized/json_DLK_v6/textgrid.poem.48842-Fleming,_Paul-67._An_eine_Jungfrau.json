{"textgrid.poem.48842": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "67. An eine Jungfrau", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn dieses mein Sonnet sich des nicht d\u00fcrfte scheuen,", "tokens": ["Wenn", "die\u00b7ses", "mein", "Son\u00b7net", "sich", "des", "nicht", "d\u00fcrf\u00b7te", "scheu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PPOSAT", "NN", "PRF", "ART", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "da\u00df seine Nichtigkeit dir machte nicht Verdru\u00df,", "tokens": ["da\u00df", "sei\u00b7ne", "Nich\u00b7tig\u00b7keit", "dir", "mach\u00b7te", "nicht", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "o du der Neunen Zier, die um Olympens Flu\u00df", "tokens": ["o", "du", "der", "Neu\u00b7nen", "Zier", ",", "die", "um", "O\u00b7lym\u00b7pens", "Flu\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["FM", "PPER", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "in kluger Einfalt gehn, du vierte von den dreien,", "tokens": ["in", "klu\u00b7ger", "Ein\u00b7falt", "gehn", ",", "du", "vier\u00b7te", "von", "den", "drei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,", "PPER", "ADJA", "APPR", "ART", "CARD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "die F\u00f6bi Mumen sind, so wolt' ich ihm verzeihen,", "tokens": ["die", "F\u00f6\u00b7bi", "Mu\u00b7men", "sind", ",", "so", "wolt'", "ich", "ihm", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da\u00df es sich untersteht zu machen auf den Fu\u00df", "tokens": ["da\u00df", "es", "sich", "un\u00b7ter\u00b7steht", "zu", "ma\u00b7chen", "auf", "den", "Fu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "PTKZU", "VVINF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und dir zu bringen an den meinen Ehrengru\u00df,", "tokens": ["und", "dir", "zu", "brin\u00b7gen", "an", "den", "mei\u00b7nen", "Eh\u00b7ren\u00b7gru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "APPR", "ART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der unsrer Freundschaft dich aufs Neue will erfreuen.", "tokens": ["der", "uns\u00b7rer", "Freund\u00b7schaft", "dich", "aufs", "Neu\u00b7e", "will", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPRART", "ADJA", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Doch du wirst sehen nicht, wie schlecht mein Bote k\u00f6mmt,", "tokens": ["Doch", "du", "wirst", "se\u00b7hen", "nicht", ",", "wie", "schlecht", "mein", "Bo\u00b7te", "k\u00f6mmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PTKNEG", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der einig seinen Wert von deinem Preise nimmt?", "tokens": ["der", "ei\u00b7nig", "sei\u00b7nen", "Wert", "von", "dei\u00b7nem", "Prei\u00b7se", "nimmt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gib ihm denselben Wink, mit welchem s\u00fc\u00dfen Blicke", "tokens": ["Gib", "ihm", "den\u00b7sel\u00b7ben", "Wink", ",", "mit", "wel\u00b7chem", "s\u00fc\u00b7\u00dfen", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PDAT", "NN", "$,", "APPR", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "du neulich von mir gingst. H\u00f6r', Edle, was er spricht,", "tokens": ["du", "neu\u00b7lich", "von", "mir", "gingst", ".", "H\u00f6r'", ",", "Ed\u00b7le", ",", "was", "er", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPER", "VVFIN", "$.", "NE", "$,", "ADJA", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und la\u00df ihn nur bei dir. Der Antwort darf es nicht.", "tokens": ["und", "la\u00df", "ihn", "nur", "bei", "dir", ".", "Der", "Ant\u00b7wort", "darf", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "APPR", "PPER", "$.", "ART", "NN", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df ist mir Antwort satt, wenn er nicht k\u00f6mpt zur\u00fccke.", "tokens": ["Di\u00df", "ist", "mir", "Ant\u00b7wort", "satt", ",", "wenn", "er", "nicht", "k\u00f6mpt", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "ADJD", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}