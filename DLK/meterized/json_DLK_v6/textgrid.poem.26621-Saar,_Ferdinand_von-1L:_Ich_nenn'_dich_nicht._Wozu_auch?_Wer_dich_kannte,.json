{"textgrid.poem.26621": {"metadata": {"author": {"name": "Saar, Ferdinand von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich nenn' dich nicht. Wozu auch? Wer dich kannte,", "genre": "verse", "period": "N.A.", "pub_year": 1869, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich nenn' dich nicht. Wozu auch? Wer dich kannte,", "tokens": ["Ich", "nenn'", "dich", "nicht", ".", "Wo\u00b7zu", "auch", "?", "Wer", "dich", "kann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "PWAV", "ADV", "$.", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der wei\u00df, wem diese Trauerrhythmen gelten \u2013", "tokens": ["Der", "wei\u00df", ",", "wem", "die\u00b7se", "Trau\u00b7er\u00b7rhyth\u00b7men", "gel\u00b7ten", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PWS", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wer dich nicht gekannt, wem blo\u00df dein Name", "tokens": ["Und", "wer", "dich", "nicht", "ge\u00b7kannt", ",", "wem", "blo\u00df", "dein", "Na\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "PTKNEG", "VVPP", "$,", "PWS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Entgegenklang im wirren L\u00e4rm des Tages,", "tokens": ["Ent\u00b7ge\u00b7gen\u00b7klang", "im", "wir\u00b7ren", "L\u00e4rm", "des", "Ta\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dem sei genug das ernste Dichterwort:", "tokens": ["Dem", "sei", "ge\u00b7nug", "das", "erns\u00b7te", "Dich\u00b7ter\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df du ein edler, selt'ner Mensch gewesen.", "tokens": ["Da\u00df", "du", "ein", "ed\u00b7ler", ",", "selt'\u00b7ner", "Mensch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "$,", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Noch in des Lebens Aufgang standest du,", "tokens": ["Noch", "in", "des", "Le\u00b7bens", "Auf\u00b7gang", "stan\u00b7dest", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Jugend ros'ger Hauch umwehte dich,", "tokens": ["Der", "Ju\u00b7gend", "ros'\u00b7ger", "Hauch", "um\u00b7weh\u00b7te", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und was das Dasein bieten kann an Glanz,", "tokens": ["Und", "was", "das", "Da\u00b7sein", "bie\u00b7ten", "kann", "an", "Glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVINF", "VMFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "An Freuden und Gen\u00fcssen \u2013 lag verhei\u00dfend,", "tokens": ["An", "Freu\u00b7den", "und", "Ge\u00b7n\u00fcs\u00b7sen", "\u2013", "lag", "ver\u00b7hei\u00b7\u00dfend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Verlockend und erreichbar vor dir da.", "tokens": ["Ver\u00b7lo\u00b7ckend", "und", "er\u00b7reich\u00b7bar", "vor", "dir", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Du aber nipptest kaum am Rand des Bechers,", "tokens": ["Du", "a\u00b7ber", "nipp\u00b7test", "kaum", "am", "Rand", "des", "Be\u00b7chers", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Der dir entgegen sch\u00e4umte, w\u00e4hrend du,", "tokens": ["Der", "dir", "ent\u00b7ge\u00b7gen", "sch\u00e4um\u00b7te", ",", "w\u00e4h\u00b7rend", "du", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKVZ", "VVFIN", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Selbstlos, die reine Seele rein bewahrend,", "tokens": ["Selbst\u00b7los", ",", "die", "rei\u00b7ne", "See\u00b7le", "rein", "be\u00b7wah\u00b7rend", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und fr\u00fch schon ernsten Pflichten zugewendet,", "tokens": ["Und", "fr\u00fch", "schon", "erns\u00b7ten", "Pflich\u00b7ten", "zu\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Nur still bedacht warst, And're zu begl\u00fccken.", "tokens": ["Nur", "still", "be\u00b7dacht", "warst", ",", "An\u00b7d'\u00b7re", "zu", "be\u00b7gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "$,", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Nicht blo\u00df die N\u00e4chsten! Nicht die Theu'ren blo\u00df,", "tokens": ["Nicht", "blo\u00df", "die", "N\u00e4chs\u00b7ten", "!", "Nicht", "die", "Theu'\u00b7ren", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$.", "PTKNEG", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Die dir im tiefsten Sein verkn\u00fcpft gewesen", "tokens": ["Die", "dir", "im", "tiefs\u00b7ten", "Sein", "ver\u00b7kn\u00fcpft", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPRART", "ADJA", "NN", "VVPP", "VAPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Durch Bande der Natur; nicht blo\u00df die Freunde,", "tokens": ["Durch", "Ban\u00b7de", "der", "Na\u00b7tur", ";", "nicht", "blo\u00df", "die", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$.", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die du mit zartem, treuem Sinn erkoren:", "tokens": ["Die", "du", "mit", "zar\u00b7tem", ",", "treu\u00b7em", "Sinn", "er\u00b7ko\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "$,", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Nein, ", "tokens": ["Nein", ","], "token_info": ["word", "punct"], "pos": ["PTKANT", "$,"], "meter": "+", "measure": "single.up"}, "line.16": {"text": "Im harten Kampf des Lebens um dich her.", "tokens": ["Im", "har\u00b7ten", "Kampf", "des", "Le\u00b7bens", "um", "dich", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Denn wie dein Geist, tief innig im Verst\u00e4ndni\u00df,", "tokens": ["Denn", "wie", "dein", "Geist", ",", "tief", "in\u00b7nig", "im", "Ver\u00b7st\u00e4nd\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "NN", "$,", "ADJD", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Jedwedes Leid erma\u00df \u2013 und jedes Ziel,", "tokens": ["Jed\u00b7we\u00b7des", "Leid", "er\u00b7ma\u00df", "\u2013", "und", "je\u00b7des", "Ziel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$(", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Nach dem die Menschheit, sich vollendend, ringt:", "tokens": ["Nach", "dem", "die", "Menschheit", ",", "sich", "voll\u00b7en\u00b7dend", ",", "ringt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "$,", "PRF", "VVPP", "$,", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.20": {"text": "So war dein Herz, tief innig im Empfinden,", "tokens": ["So", "war", "dein", "Herz", ",", "tief", "in\u00b7nig", "im", "Emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "ADJD", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Auch jener G\u00fcte, jener Liebe voll,", "tokens": ["Auch", "je\u00b7ner", "G\u00fc\u00b7te", ",", "je\u00b7ner", "Lie\u00b7be", "voll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "$,", "PDAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Die Thr\u00e4nen trocknet und den Dank erl\u00e4\u00dft.", "tokens": ["Die", "Thr\u00e4\u00b7nen", "trock\u00b7net", "und", "den", "Dank", "er\u00b7l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "D'rum als du still und sanft gebettet lagst", "tokens": ["D'\u00b7rum", "als", "du", "still", "und", "sanft", "ge\u00b7bet\u00b7tet", "lagst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "KOUS", "PPER", "ADJD", "KON", "ADJD", "VVPP", "VVFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Zum ew'gen Schlaf, von Kerzen leis' umflackert,", "tokens": ["Zum", "ew'\u00b7gen", "Schlaf", ",", "von", "Ker\u00b7zen", "leis'", "um\u00b7fla\u00b7ckert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und hei\u00dfe Thr\u00e4nen flossen um dich her:", "tokens": ["Und", "hei\u00b7\u00dfe", "Thr\u00e4\u00b7nen", "flos\u00b7sen", "um", "dich", "her", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da f\u00fchlte Jeder, der zum letzten Mal", "tokens": ["Da", "f\u00fchl\u00b7te", "Je\u00b7der", ",", "der", "zum", "letz\u00b7ten", "Mal"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PRELS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Stumm in dein bleiches, sch\u00f6nes Antlitz sah,", "tokens": ["Stumm", "in", "dein", "blei\u00b7ches", ",", "sch\u00f6\u00b7nes", "Ant\u00b7litz", "sah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was diese rauhe Welt an dir verlor \u2013", "tokens": ["Was", "die\u00b7se", "rau\u00b7he", "Welt", "an", "dir", "ver\u00b7lor", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und nicht zu fassen war es, da\u00df der Tod", "tokens": ["Und", "nicht", "zu", "fas\u00b7sen", "war", "es", ",", "da\u00df", "der", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "PPER", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Gedankenlos und grausam solch ein Leben", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7los", "und", "grau\u00b7sam", "solch", "ein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ADJD", "PIAT", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Vernichten konnte, eh' es sich erf\u00fcllt ...", "tokens": ["Ver\u00b7nich\u00b7ten", "konn\u00b7te", ",", "eh'", "es", "sich", "er\u00b7f\u00fcllt", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "KOUS", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich nenn' dich nicht. Wozu auch? Wer dich kannte", "tokens": ["Ich", "nenn'", "dich", "nicht", ".", "Wo\u00b7zu", "auch", "?", "Wer", "dich", "kann\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "PWAV", "ADV", "$.", "PWS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der wei\u00df, wem diese Trauerrhythmen gelten \u2013", "tokens": ["Der", "wei\u00df", ",", "wem", "die\u00b7se", "Trau\u00b7er\u00b7rhyth\u00b7men", "gel\u00b7ten", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PWS", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wer dich nicht gekannt, wem blo\u00df dein Name", "tokens": ["Und", "wer", "dich", "nicht", "ge\u00b7kannt", ",", "wem", "blo\u00df", "dein", "Na\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "PTKNEG", "VVPP", "$,", "PWS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Entgegenklang im wirren L\u00e4rm des Tages,", "tokens": ["Ent\u00b7ge\u00b7gen\u00b7klang", "im", "wir\u00b7ren", "L\u00e4rm", "des", "Ta\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dem sei genug das ernste Dichterwort:", "tokens": ["Dem", "sei", "ge\u00b7nug", "das", "erns\u00b7te", "Dich\u00b7ter\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df du ein edler, selt'ner Mensch gewesen.", "tokens": ["Da\u00df", "du", "ein", "ed\u00b7ler", ",", "selt'\u00b7ner", "Mensch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "$,", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}