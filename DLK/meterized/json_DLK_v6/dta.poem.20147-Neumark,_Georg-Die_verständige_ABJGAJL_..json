{"dta.poem.20147": {"metadata": {"author": {"name": "Neumark, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Die verst\u00e4ndige  \n  ABJGAJL .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1666", "urn": "urn:nbn:de:kobv:b4-20424-1", "language": ["de:0.99"], "booktitle": "Neumark, Georg: Poetisch-Historischer Lustgarten. Frankfurt (Main), 1666."}, "poem": {"stanza.1": {"line.1": {"text": "Wolan! so kommt denn her/ die jhr die\nWeiber schmehet/", "tokens": ["Wo\u00b7lan", "!", "so", "kommt", "denn", "her", "/", "die", "jhr", "die", "Wei\u00b7ber", "schme\u00b7het", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVFIN", "ADV", "PTKVZ", "$(", "PRELS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ihr das liebe Volk/ verachtet/", "tokens": ["Die", "ihr", "das", "lie\u00b7be", "Volk", "/", "ver\u00b7ach\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df dem nicht sey also/ was ihr bi\u00dfweilen", "tokens": ["Da\u00df", "dem", "nicht", "sey", "al\u00b7so", "/", "was", "ihr", "bi\u00df\u00b7wei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "PTKNEG", "VAFIN", "ADV", "$(", "PWS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was manche frome Frau im Hertzen schmertz-", "tokens": ["Was", "man\u00b7che", "fro\u00b7me", "Frau", "im", "Hert\u00b7zen", "schmertz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIAT", "ADJA", "NN", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Jhr sprecht/ das Weibervolk sey eine Drangsals-", "tokens": ["Ihr", "sprecht", "/", "das", "Wei\u00b7ber\u00b7volk", "sey", "ei\u00b7ne", "Drang\u00b7sals"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "VAFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es sey auf dieser Welt den M\u00e4nnern eine Helle", "tokens": ["Es", "sey", "auf", "die\u00b7ser", "Welt", "den", "M\u00e4n\u00b7nern", "ei\u00b7ne", "Hel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PDAT", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Jhr sagt es sey ein Weib ein rechter Marter-", "tokens": ["Ihr", "sagt", "es", "sey", "ein", "Weib", "ein", "rech\u00b7ter", "Mar\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sie trill\u2019 Euch so und so/ sie sey ein Ungl\u00fckks-", "tokens": ["Sie", "trill'", "Euch", "so", "und", "so", "/", "sie", "sey", "ein", "Un\u00b7gl\u00fc\u00b7kks"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "ADV", "$(", "PPER", "VAFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df aber dem nicht so/ was ihr so schimpflich", "tokens": ["Da\u00df", "a\u00b7ber", "dem", "nicht", "so", "/", "was", "ihr", "so", "schimpf\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "PTKNEG", "ADV", "$(", "PWS", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "So sollt in kurtzem ihr de\u00dfwegen seyn erbl\u00f6det/", "tokens": ["So", "sollt", "in", "kurt\u00b7zem", "ihr", "de\u00df\u00b7we\u00b7gen", "seyn", "er\u00b7bl\u00f6\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "ADJA", "PPER", "PAV", "VAINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Jhr sollt vor Augen sehn was manches Weibs-", "tokens": ["Ihr", "sollt", "vor", "Au\u00b7gen", "sehn", "was", "man\u00b7ches", "Weibs"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF", "PWS", "PIS", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Was sie vor Wei\u00dfheit hegt vor ihrem n\u00e4rr-", "tokens": ["Was", "sie", "vor", "Wei\u00df\u00b7heit", "hegt", "vor", "ih\u00b7rem", "n\u00e4rr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Wie oftmals hat ein Weib/ durch klugverschlag-", "tokens": ["Wie", "oft\u00b7mals", "hat", "ein", "Weib", "/", "durch", "klug\u00b7ver\u00b7schlag"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "ART", "NN", "$(", "APPR", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Das Ungl\u00fckk/ so der Mann mit th\u00f6richtem Be-", "tokens": ["Das", "Un\u00b7gl\u00fckk", "/", "so", "der", "Mann", "mit", "th\u00f6\u00b7rich\u00b7tem", "Be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ADV", "ART", "NN", "APPR", "ADJA", "TRUNC"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Zu wege hat gebracht/ hinwieder abgewandt", "tokens": ["Zu", "we\u00b7ge", "hat", "ge\u00b7bracht", "/", "hin\u00b7wie\u00b7der", "ab\u00b7ge\u00b7wandt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "$(", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wie solches in der Welt genugsam ist bekandt.", "tokens": ["Wie", "sol\u00b7ches", "in", "der", "Welt", "ge\u00b7nug\u00b7sam", "ist", "be\u00b7kandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "ART", "NN", "ADJD", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ein einig Beyspiel nur wil ich vor Augen stellen/", "tokens": ["Ein", "ei\u00b7nig", "Bey\u00b7spiel", "nur", "wil", "ich", "vor", "Au\u00b7gen", "stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ADV", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$("], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.18": {"text": "Da mag denn iedermann ein freyes Urthel f\u00e4llen/", "tokens": ["Da", "mag", "denn", "ie\u00b7der\u00b7mann", "ein", "frey\u00b7es", "Ur\u00b7thel", "f\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ob nicht ein Weib oft d\u00e4mpft manch Unheil", "tokens": ["Ob", "nicht", "ein", "Weib", "oft", "d\u00e4mpft", "manch", "Un\u00b7heil"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Seht hier Abigail stellt sich zum Beyspiel dar.", "tokens": ["Seht", "hier", "A\u00b7bi\u00b7gail", "stellt", "sich", "zum", "Bey\u00b7spiel", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "VVFIN", "PRF", "APPRART", "NN", "PTKVZ", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.21": {"text": "Damals als David sloh' in  Parans W\u00fcste-\nneyen", "tokens": ["Da\u00b7mals", "als", "Da\u00b7vid", "sloh'", "in", "Pa\u00b7rans", "W\u00fcs\u00b7te", "ne\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NE", "VVFIN", "APPR", "NE", "TRUNC", "NN"], "meter": "-----+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Vor Sauls gefasstem Grimm\u2019 und tollen Rase-", "tokens": ["Vor", "Sauls", "ge\u00b7fass\u00b7tem", "Grimm'", "und", "tol\u00b7len", "Ra\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN", "KON", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Als er gleich einem Reh\u2019 in dikken W\u00e4ldern", "tokens": ["Als", "er", "gleich", "ei\u00b7nem", "Reh'", "in", "dik\u00b7ken", "W\u00e4l\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Und mehr in w\u00fcster Heid\u2019/ als feste\u0303 St\u00e4dten lebt/", "tokens": ["Und", "mehr", "in", "w\u00fcs\u00b7ter", "Heid'", "/", "als", "fest\u1ebd", "St\u00e4d\u00b7ten", "lebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$(", "KOUS", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "War Nabals Reichthum gro\u00df/ insonderheit an", "tokens": ["War", "Na\u00b7bals", "Reicht\u00b7hum", "gro\u00df", "/", "in\u00b7son\u00b7der\u00b7heit", "an"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "ADJD", "$(", "ADV", "APPR"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.26": {"text": "Sein Schafvieh kunte kaum von ihm gez\u00e4hlet", "tokens": ["Sein", "Schaf\u00b7vieh", "kun\u00b7te", "kaum", "von", "ihm", "ge\u00b7z\u00e4h\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Zu ", "tokens": ["Zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.28": {"text": "Das weiche Wollenvolk gieng \u00fcber Berg\u2019 und", "tokens": ["Das", "wei\u00b7che", "Wol\u00b7len\u00b7volk", "gieng", "\u00fc\u00b7ber", "Ber\u00b7g'", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "KON"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Indem man nun mit Lust die L\u00e4m\u0303er sahe weiden/", "tokens": ["In\u00b7dem", "man", "nun", "mit", "Lust", "die", "L\u00e4m\u0303er", "sa\u00b7he", "wei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "NN", "ART", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "Sa\u00df Koridon im Gras\u2019 und sang in vollen Freu-", "tokens": ["Sa\u00df", "Ko\u00b7ri\u00b7don", "im", "Gras'", "und", "sang", "in", "vol\u00b7len", "Freu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "APPRART", "NN", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Von seiner Amarill/ dort unter einem Baum", "tokens": ["Von", "sei\u00b7ner", "A\u00b7ma\u00b7rill", "/", "dort", "un\u00b7ter", "ei\u00b7nem", "Baum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Lag Damon gantz verliebt in einem s\u00fcssen", "tokens": ["Lag", "Da\u00b7mon", "gantz", "ver\u00b7liebt", "in", "ei\u00b7nem", "s\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "ADV", "VVPP", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": " zu eben dieser Zeit rief Nabal alle H\u00fcrten/", "tokens": ["zu", "e\u00b7ben", "die\u00b7ser", "Zeit", "rief", "Na\u00b7bal", "al\u00b7le", "H\u00fcr\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PDAT", "NN", "VVFIN", "NE", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Nach Haus\u2019/ und liesse sie nach Sch\u00e4ferahrt be-", "tokens": ["Nach", "Haus'", "/", "und", "lies\u00b7se", "sie", "nach", "Sch\u00e4\u00b7fe\u00b7rahrt", "be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "KON", "VVFIN", "PPER", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Da war an Speis\u2019 und Trank kein Mangel", "tokens": ["Da", "war", "an", "Speis'", "und", "Trank", "kein", "Man\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NN", "KON", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Man sahe iederman mit sattem Magen gehn.", "tokens": ["Man", "sa\u00b7he", "ie\u00b7der\u00b7man", "mit", "sat\u00b7tem", "Ma\u00b7gen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Inde\u00df stellt Nabal sich der ungeschikkte Lauer/", "tokens": ["In\u00b7de\u00df", "stellt", "Na\u00b7bal", "sich", "der", "un\u00b7ge\u00b7schikk\u00b7te", "Lau\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NE", "PRF", "ART", "ADJA", "NN", "$("], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.38": {"text": "Gleich einem gro\u00dfen Herrn/ und war doch nur ein", "tokens": ["Gleich", "ei\u00b7nem", "gro\u00b7\u00dfen", "Herrn", "/", "und", "war", "doch", "nur", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "$(", "KON", "VAFIN", "ADV", "ADV", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.39": {"text": "Und grober T\u00f6lpelskopf: Als nun das Mahl", "tokens": ["Und", "gro\u00b7ber", "T\u00f6l\u00b7pels\u00b7kopf", ":", "Als", "nun", "das", "Mahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$.", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Fieng sich mit vollem Ernst das Schafescheren", "tokens": ["Fi\u00b7eng", "sich", "mit", "vol\u00b7lem", "Ernst", "das", "Scha\u00b7fe\u00b7sche\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.41": {"text": "Da gieng es hurtig her/ der Geitzhal\u00df war zuge-", "tokens": ["Da", "gieng", "es", "hur\u00b7tig", "her", "/", "der", "Geitz\u00b7hal\u00df", "war", "zu\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$(", "ART", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Und sahe fleissig zu/ Er lief auf allen Wegen", "tokens": ["Und", "sa\u00b7he", "fleis\u00b7sig", "zu", "/", "Er", "lief", "auf", "al\u00b7len", "We\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PTKZU", "$(", "PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Bald hier bald dorten hin/ und nahm genau in", "tokens": ["Bald", "hier", "bald", "dor\u00b7ten", "hin", "/", "und", "nahm", "ge\u00b7nau", "in"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "ADJD", "APPR"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "Da\u00df nicht ein Wollenfleisch w\u00fcrd\u2019 auf die Sei-", "tokens": ["Da\u00df", "nicht", "ein", "Wol\u00b7len\u00b7fleisch", "w\u00fcrd'", "auf", "die", "Sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "VAFIN", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Sonst war er reich genug/ was nur die Schafe", "tokens": ["Sonst", "war", "er", "reich", "ge\u00b7nug", "/", "was", "nur", "die", "Scha\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADV", "$(", "PWS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.46": {"text": "Das war ihm/ sein Gesind\u2019/ alleine satt zu laben/", "tokens": ["Das", "war", "ihm", "/", "sein", "Ge\u00b7sind'", "/", "al\u00b7lei\u00b7ne", "satt", "zu", "la\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$(", "PPOSAT", "NN", "$(", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Es war bey ihm vollauf/ das Haus war alle", "tokens": ["Es", "war", "bey", "ihm", "vol\u00b7lauf", "/", "das", "Haus", "war", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "$(", "ART", "NN", "VAFIN", "PIS"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.48": {"text": "Nur Nabal war ein Narr/ und immer voll und", "tokens": ["Nur", "Na\u00b7bal", "war", "ein", "Narr", "/", "und", "im\u00b7mer", "voll", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VAFIN", "ART", "NN", "$(", "KON", "ADV", "ADJD", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.49": {"text": "Ob schon bey diesem Mann\u2019 auf allen seinen we-", "tokens": ["Ob", "schon", "bey", "die\u00b7sem", "Mann'", "auf", "al\u00b7len", "sei\u00b7nen", "we"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PDAT", "NN", "APPR", "PIAT", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Sich h\u00e4uffig sp\u00fcren lie\u00df des Himmels reicher", "tokens": ["Sich", "h\u00e4uf\u00b7fig", "sp\u00fc\u00b7ren", "lie\u00df", "des", "Him\u00b7mels", "rei\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "VVINF", "VVFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "So wars ihm doch nicht satt/ schart\u2019 immer", "tokens": ["So", "wars", "ihm", "doch", "nicht", "satt", "/", "schart'", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$(", "VVFIN", "ADV"], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.52": {"text": "Und hatte vor dem Geitz fast weder Rast noch", "tokens": ["Und", "hat\u00b7te", "vor", "dem", "Geitz", "fast", "we\u00b7der", "Rast", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "ADV", "KON", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.53": {"text": "Und ob sein kluges Weib/ war noch so sch\u00f6n von", "tokens": ["Und", "ob", "sein", "klu\u00b7ges", "Weib", "/", "war", "noch", "so", "sch\u00f6n", "von"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "$(", "VAFIN", "ADV", "ADV", "ADJD", "APPR"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.54": {"text": "Ein Beyspiel aller Zucht/ ein Spiegel aller Tu-", "tokens": ["Ein", "Bey\u00b7spiel", "al\u00b7ler", "Zucht", "/", "ein", "Spie\u00b7gel", "al\u00b7ler", "Tu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIAT", "NN", "$(", "ART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "So f\u00fchlte dieser Mops doch keine rechte Lust/", "tokens": ["So", "f\u00fchl\u00b7te", "die\u00b7ser", "Mops", "doch", "kei\u00b7ne", "rech\u00b7te", "Lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "ADV", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "An solcher \u00e4dlen Blum\u2019 und keuschen Marmor-", "tokens": ["An", "sol\u00b7cher", "\u00e4d\u00b7len", "Blum'", "und", "keu\u00b7schen", "Mar\u00b7mor"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "KON", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.57": {"text": "Zu eben dieser Zeit war David sehr geplaget/", "tokens": ["Zu", "e\u00b7ben", "die\u00b7ser", "Zeit", "war", "Da\u00b7vid", "sehr", "ge\u00b7pla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PDAT", "NN", "VAFIN", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und von dem stoltzen Saul verfolget und ver-", "tokens": ["Und", "von", "dem", "stolt\u00b7zen", "Saul", "ver\u00b7fol\u00b7get", "und", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "KON", "TRUNC"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.59": {"text": "Sein treu-verbliebnes Volk/ ein stahl beherzter", "tokens": ["Sein", "treu\u00b7ver\u00b7blieb\u00b7nes", "Volk", "/", "ein", "stahl", "be\u00b7herz\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.60": {"text": "Hielt sich mit ihm allhier in dieser Gegend auf.", "tokens": ["Hielt", "sich", "mit", "ihm", "all\u00b7hier", "in", "die\u00b7ser", "Ge\u00b7gend", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "ADV", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.61": {"text": "Allein es war nichts da zu brechen noch zu beissen/", "tokens": ["Al\u00b7lein", "es", "war", "nichts", "da", "zu", "bre\u00b7chen", "noch", "zu", "beis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PIS", "ADV", "PTKZU", "VVINF", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Und wuste David kaum sich au\u00df der Noht zu reis-", "tokens": ["Und", "wus\u00b7te", "Da\u00b7vid", "kaum", "sich", "au\u00df", "der", "Noht", "zu", "reis"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NE", "ADV", "PRF", "APPR", "ART", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Die Magen waren zwar erf\u00fcllt mit Hungers-", "tokens": ["Die", "Ma\u00b7gen", "wa\u00b7ren", "zwar", "er\u00b7f\u00fcllt", "mit", "Hun\u00b7ger\u00b7s"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Die Hertzen aber frisch zu streiten bi\u00df in Tod.", "tokens": ["Die", "Hert\u00b7zen", "a\u00b7ber", "frisch", "zu", "strei\u00b7ten", "bi\u00df", "in", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Dr\u00fcm wurde man bald Rahts/ den Mangel ab-", "tokens": ["Dr\u00fcm", "wur\u00b7de", "man", "bald", "Rahts", "/", "den", "Man\u00b7gel", "ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "NN", "$(", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.66": {"text": "Man kam auf diesen Schlu\u00df/ zu Nabal abzusen-", "tokens": ["Man", "kam", "auf", "die\u00b7sen", "Schlu\u00df", "/", "zu", "Na\u00b7bal", "ab\u00b7zu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "PDAT", "NN", "$(", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.67": {"text": "Als einem reichen Mann/ da\u00df Er zu grossem", "tokens": ["Als", "ei\u00b7nem", "rei\u00b7chen", "Mann", "/", "da\u00df", "Er", "zu", "gros\u00b7sem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "$(", "KOUS", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Doch etwas schikken m\u00f6cht\u2019 an Labsal/ Speis\u2019", "tokens": ["Doch", "et\u00b7was", "schik\u00b7ken", "m\u00f6cht'", "an", "Lab\u00b7sal", "/", "Speis'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "VVINF", "VMFIN", "APPR", "NN", "$(", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.69": {"text": "Zehn M\u00e4nner giengen hin/ versehn mit ihren", "tokens": ["Zehn", "M\u00e4n\u00b7ner", "gien\u00b7gen", "hin", "/", "ver\u00b7sehn", "mit", "ih\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PTKVZ", "$(", "VVFIN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.70": {"text": "Nach Nabals Sch\u00e4ferey/ dem Vnheil Raht zu", "tokens": ["Nach", "Na\u00b7bals", "Sch\u00e4\u00b7fe\u00b7rey", "/", "dem", "Vn\u00b7heil", "Raht", "zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "$(", "ART", "NN", "NN", "PTKZU"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.71": {"text": "Als Sie nun angelangt in sein erf\u00fclltes Hau\u00df/", "tokens": ["Als", "Sie", "nun", "an\u00b7ge\u00b7langt", "in", "sein", "er\u00b7f\u00fcll\u00b7tes", "Hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Brach Einer unter ihn\u2019n/ in diese Wort her-", "tokens": ["Brach", "Ei\u00b7ner", "un\u00b7ter", "ihn'n", "/", "in", "die\u00b7se", "Wort", "her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "PPER", "$(", "APPR", "PDAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.73": {"text": "Gott gebe dir viel Gl\u00fckk/ und ein vergn\u00fcgtes Le-", "tokens": ["Gott", "ge\u00b7be", "dir", "viel", "Gl\u00fckk", "/", "und", "ein", "ver\u00b7gn\u00fcg\u00b7tes", "Le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PIAT", "NN", "$(", "KON", "ART", "ADJA", "TRUNC"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.74": {"text": "Zu allem was du thust woll Er dir Segen geben/", "tokens": ["Zu", "al\u00b7lem", "was", "du", "thust", "woll", "Er", "dir", "Se\u00b7gen", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PWS", "PPER", "VVFIN", "VMFIN", "PPER", "PPER", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Du wolbegabter Mann/ dich gr\u00fcsset Davids", "tokens": ["Du", "wol\u00b7be\u00b7gab\u00b7ter", "Mann", "/", "dich", "gr\u00fcs\u00b7set", "Da\u00b7vids"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$(", "PPER", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.76": {"text": "Vnd w\u00fcnschet da\u00df du m\u00f6gst noch wachsen", "tokens": ["Vnd", "w\u00fcn\u00b7schet", "da\u00df", "du", "m\u00f6gst", "noch", "wach\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOUS", "PPER", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.77": {"text": "In was vor Hertzeleid/ der from\u0303e David kommen/", "tokens": ["In", "was", "vor", "Hert\u00b7ze\u00b7leid", "/", "der", "from\u0303e", "Da\u00b7vid", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "$(", "ART", "ADJA", "NE", "VVINF", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.78": {"text": "Das hast du zweifels frey/ schon allbereits ver-", "tokens": ["Das", "hast", "du", "zwei\u00b7fels", "frey", "/", "schon", "all\u00b7be\u00b7reits", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$(", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.79": {"text": "Nun schau/ wir leben hier in gro\u00dfer Angst und", "tokens": ["Nun", "schau", "/", "wir", "le\u00b7ben", "hier", "in", "gro\u00b7\u00dfer", "Angst", "und"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKVZ", "$(", "PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.80": {"text": "In \u00f6der W\u00fcsteney gebricht uns liebes Brodt.", "tokens": ["In", "\u00f6\u00b7der", "W\u00fcs\u00b7te\u00b7ney", "ge\u00b7bricht", "uns", "lie\u00b7bes", "Brodt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Nun h\u00f6ren wir da\u00df du die gantze Schaar der", "tokens": ["Nun", "h\u00f6\u00b7ren", "wir", "da\u00df", "du", "die", "gant\u00b7ze", "Schaar", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PPER", "ART", "ADJA", "NN", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.82": {"text": "Die dir zu Dienste stehn/ wilst diesen Tag bewir-", "tokens": ["Die", "dir", "zu", "Diens\u00b7te", "stehn", "/", "wilst", "die\u00b7sen", "Tag", "be\u00b7wir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "VVINF", "$(", "VMFIN", "PDAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Und da\u00df du werther Herr/ Gott gebe lange", "tokens": ["Und", "da\u00df", "du", "wert\u00b7her", "Herr", "/", "Gott", "ge\u00b7be", "lan\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJA", "NN", "$(", "NN", "VVFIN", "ADV"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.84": {"text": "Du und dein gantzes Hau\u00df in voller Freude seit.", "tokens": ["Du", "und", "dein", "gant\u00b7zes", "Hau\u00df", "in", "vol\u00b7ler", "Freu\u00b7de", "seit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Du weisst auch/ das dein Volk/ die Sch\u00e4fer/ die-", "tokens": ["Du", "weisst", "auch", "/", "das", "dein", "Volk", "/", "die", "Sch\u00e4\u00b7fer", "/", "die"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "$(", "ART", "PPOSAT", "NN", "$(", "ART", "NN", "$(", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.86": {"text": "Gantz sicher neben Uns die H\u00fcrden aufgeschla-", "tokens": ["Gantz", "si\u00b7cher", "ne\u00b7ben", "Uns", "die", "H\u00fcr\u00b7den", "auf\u00b7ge\u00b7schla"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "PPER", "ART", "NN", "TRUNC"], "meter": "+----+-+-+-+", "measure": "dactylic.init"}, "line.87": {"text": "Die Schafe trieben Sie vor unsrem Heer vor-", "tokens": ["Die", "Scha\u00b7fe", "trie\u00b7ben", "Sie", "vor", "uns\u00b7rem", "Heer", "vor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.88": {"text": "Auch wieder\u00fcm \u2019zur\u00fck/ und das/ glaub uns/", "tokens": ["Auch", "wie\u00b7de\u00b7r\u00fcm", "'zu\u00b7r\u00fck", "/", "und", "das", "/", "glaub", "uns", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$(", "KON", "ART", "$(", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.89": {"text": "Von so viel tausenden ist dir nicht ", "tokens": ["Von", "so", "viel", "tau\u00b7sen\u00b7den", "ist", "dir", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIAT", "ADJA", "VAFIN", "PPER", "PTKNEG"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.90": {"text": "Es hat dein Volk von uns kein b\u00f6ses Wort be-", "tokens": ["Es", "hat", "dein", "Volk", "von", "uns", "kein", "b\u00f6\u00b7ses", "Wort", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "PPER", "PIAT", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.91": {"text": "Glaub Nabal/ frage nach/ es ist kein einger", "tokens": ["Glaub", "Na\u00b7bal", "/", "fra\u00b7ge", "nach", "/", "es", "ist", "kein", "ein\u00b7ger"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$(", "VVFIN", "APPR", "$(", "PPER", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.92": {"text": "Der uns mit Fug und Recht bey dir verklagen", "tokens": ["Der", "uns", "mit", "Fug", "und", "Recht", "bey", "dir", "ver\u00b7kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.93": {"text": "Wann denn so gro\u00dfe Schaar wird heute mit dir", "tokens": ["Wann", "denn", "so", "gro\u00b7\u00dfe", "Schaar", "wird", "heu\u00b7te", "mit", "dir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "ADJA", "NN", "VAFIN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.94": {"text": "So bitten wir/ du wollst auch unser nicht verges-", "tokens": ["So", "bit\u00b7ten", "wir", "/", "du", "wollst", "auch", "un\u00b7ser", "nicht", "ver\u00b7ge\u00b7s"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PPER", "VMFIN", "ADV", "PPOSAT", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.95": {"text": "Betrachte doch die Noht/ schikk unserm schwa-", "tokens": ["Be\u00b7trach\u00b7te", "doch", "die", "Noht", "/", "schikk", "un\u00b7serm", "schwa"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "$(", "VVFIN", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.96": {"text": "Was seinen Hunger stillt/ gieb David doch die", "tokens": ["Was", "sei\u00b7nen", "Hun\u00b7ger", "stillt", "/", "gieb", "Da\u00b7vid", "doch", "die"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$(", "VVIMP", "NE", "ADV", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.97": {"text": "Und la\u00df im Elend\u2019 ihn nicht solchen Kummer lei-", "tokens": ["Und", "la\u00df", "im", "E\u00b7lend'", "ihn", "nicht", "sol\u00b7chen", "Kum\u00b7mer", "lei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "APPRART", "NN", "PPER", "PTKNEG", "PIAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Er wird schon/ traue nur/ sich dankbarlich be-", "tokens": ["Er", "wird", "schon", "/", "trau\u00b7e", "nur", "/", "sich", "dank\u00b7bar\u00b7lich", "be"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "$(", "VVFIN", "ADV", "$(", "PRF", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.99": {"text": "Und die Barmhertzigkeit/ die man an ihm/ itzt", "tokens": ["Und", "die", "Barm\u00b7hert\u00b7zig\u00b7keit", "/", "die", "man", "an", "ihm", "/", "itzt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "NN", "$(", "PRELS", "PIS", "APPR", "PPER", "$(", "ADV"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.100": {"text": "Erkennen dermaleinst/ mit Gnaderf\u00fclltem", "tokens": ["Er\u00b7ken\u00b7nen", "der\u00b7ma\u00b7leinst", "/", "mit", "Gna\u00b7der\u00b7f\u00fcll\u00b7tem"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "ADV", "$(", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.101": {"text": "Wenn ihn der h\u00f6chste Gott wird auf den Thron", "tokens": ["Wenn", "ihn", "der", "h\u00f6chs\u00b7te", "Gott", "wird", "auf", "den", "Thron"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.102": {"text": "Wenn ihn Jsrael wird als seinen K\u00f6nig sehen/", "tokens": ["Wenn", "ihn", "Js\u00b7rael", "wird", "als", "sei\u00b7nen", "K\u00f6\u00b7nig", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VAFIN", "KOKOM", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.103": {"text": "Welchs denn geschehen kan vielleicht in kurtzer", "tokens": ["Welchs", "denn", "ge\u00b7sche\u00b7hen", "kan", "viel\u00b7leicht", "in", "kurt\u00b7zer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVINF", "VMFIN", "ADV", "APPR", "ADJA"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.104": {"text": " du weist/ Er ist darzu gesalbt und einge-\nweiht.", "tokens": ["du", "weist", "/", "Er", "ist", "dar\u00b7zu", "ge\u00b7salbt", "und", "ein\u00b7ge", "weiht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VAFIN", "PAV", "VVPP", "KON", "TRUNC", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Er mu\u00df anitzo zwar/ von Saul ohn alle Schulden", "tokens": ["Er", "mu\u00df", "a\u00b7nit\u00b7zo", "zwar", "/", "von", "Saul", "ohn", "al\u00b7le", "Schul\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "$(", "APPR", "NE", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Verfolgung/ Schimpf und Spott in seinem Her-", "tokens": ["Ver\u00b7fol\u00b7gung", "/", "Schimpf", "und", "Spott", "in", "sei\u00b7nem", "Her"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "KON", "NN", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.107": {"text": "Das ihn sehr schmertzlich kr\u00e4nkt: doch weil es", "tokens": ["Das", "ihn", "sehr", "schmertz\u00b7lich", "kr\u00e4nkt", ":", "doch", "weil", "es"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "PPER", "ADV", "ADJD", "VVFIN", "$.", "ADV", "KOUS", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.108": {"text": "So tr\u00e4get Er Geduld/ und h\u00e4lt ihm willig", "tokens": ["So", "tr\u00e4\u00b7get", "Er", "Ge\u00b7duld", "/", "und", "h\u00e4lt", "ihm", "wil\u00b7lig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$(", "KON", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.109": {"text": "Wir wollen fernerweit vor deine Heerde wa-", "tokens": ["Wir", "wol\u00b7len", "fer\u00b7ner\u00b7weit", "vor", "dei\u00b7ne", "Heer\u00b7de", "wa"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Und zu beliebtem Dienst\u2019 uns treu verpflichtet ma-", "tokens": ["Und", "zu", "be\u00b7lieb\u00b7tem", "Dienst'", "uns", "treu", "ver\u00b7pflich\u00b7tet", "ma"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "PPER", "ADJD", "VVPP", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Ein tugendsam Gem\u00fcht/ dem Wolthat ist ge-", "tokens": ["Ein", "tu\u00b7gend\u00b7sam", "Ge\u00b7m\u00fcht", "/", "dem", "Wolt\u00b7hat", "ist", "ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVPP", "$(", "ART", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.112": {"text": "L\u00e4st billich H\u00fclf und Raht dem Nechsten wie-", "tokens": ["L\u00e4st", "bil\u00b7lich", "H\u00fclf", "und", "Raht", "dem", "Nechs\u00b7ten", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "NN", "KON", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.113": {"text": "Als Davids treuer Knecht die Rede kaum ge-", "tokens": ["Als", "Da\u00b7vids", "treu\u00b7er", "Knecht", "die", "Re\u00b7de", "kaum", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ADJA", "NN", "ART", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.114": {"text": "Fuhr Nabal Trunkenbold/ der gantz mit Wein", "tokens": ["Fuhr", "Na\u00b7bal", "Trun\u00b7ken\u00b7bold", "/", "der", "gantz", "mit", "Wein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "NE", "$(", "ART", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.115": {"text": "Und ziemlich schon bezecht/ ihn solcher ma\u00dfen", "tokens": ["Und", "ziem\u00b7lich", "schon", "be\u00b7zecht", "/", "ihn", "sol\u00b7cher", "ma\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVPP", "$(", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.116": {"text": "Was bringest du/ du Kerl/ vor Reden auf die", "tokens": ["Was", "brin\u00b7gest", "du", "/", "du", "Kerl", "/", "vor", "Re\u00b7den", "auf", "die"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$(", "PPER", "NN", "$(", "APPR", "NN", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.117": {"text": "Was David? Was wilst du viel Bettelworte", "tokens": ["Was", "Da\u00b7vid", "?", "Was", "wilst", "du", "viel", "Bet\u00b7tel\u00b7wor\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "NE", "$.", "PWS", "VMFIN", "PPER", "PIAT", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.118": {"text": "Man kennet David wol und seine lose Sachen/", "tokens": ["Man", "ken\u00b7net", "Da\u00b7vid", "wol", "und", "sei\u00b7ne", "lo\u00b7se", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NE", "ADV", "KON", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Er stift nur Aufruhr an/ er ist ein K\u00f6nigs-", "tokens": ["Er", "stift", "nur", "Auf\u00b7ruhr", "an", "/", "er", "ist", "ein", "K\u00f6\u00b7nigs"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN", "PTKVZ", "$(", "PPER", "VAFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.120": {"text": "Ich frage nichts nach ihm er sey Feind oder", "tokens": ["Ich", "fra\u00b7ge", "nichts", "nach", "ihm", "er", "sey", "Feind", "o\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPER", "PPER", "VAFIN", "NN", "KON"], "meter": "-+-+-+-++--", "measure": "unknown.measure.penta"}, "line.121": {"text": "Was sagst du armer Tropf/ wil David sein ein", "tokens": ["Was", "sagst", "du", "ar\u00b7mer", "Tropf", "/", "wil", "Da\u00b7vid", "sein", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADJA", "NN", "$(", "VMFIN", "NE", "PPOSAT", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.122": {"text": "O weit gefehlt/ mein Kerl/ darzu ist er zu wenig.", "tokens": ["O", "weit", "ge\u00b7fehlt", "/", "mein", "Kerl", "/", "dar\u00b7zu", "ist", "er", "zu", "we\u00b7nig", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVPP", "$(", "PPOSAT", "NN", "$(", "PAV", "VAFIN", "PPER", "PTKA", "PIS", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.123": {"text": "Hofft ein verlauffner H\u00fcrt\u2019 und schlechter", "tokens": ["Hofft", "ein", "ver\u00b7lauff\u00b7ner", "H\u00fcrt'", "und", "schlech\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.124": {"text": "Ein Landverr\u00e4hter auch/ auf einen K\u00f6nigs-", "tokens": ["Ein", "Land\u00b7ver\u00b7r\u00e4h\u00b7ter", "auch", "/", "auf", "ei\u00b7nen", "K\u00f6\u00b7nigs"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$(", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.125": {"text": "O aufgeblasner Sinn? vielleichte wird er pran-", "tokens": ["O", "auf\u00b7ge\u00b7blas\u00b7ner", "Sinn", "?", "viel\u00b7leich\u00b7te", "wird", "er", "pran"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "PIS", "VAFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Wenn er/ der Bettler wird an einem Baume", "tokens": ["Wenn", "er", "/", "der", "Bett\u00b7ler", "wird", "an", "ei\u00b7nem", "Bau\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$(", "ART", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.127": {"text": "Und solches ist mit recht der K\u00f6nigshasser", "tokens": ["Und", "sol\u00b7ches", "ist", "mit", "recht", "der", "K\u00f6\u00b7nigs\u00b7has\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "APPR", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.128": {"text": "Saul bleibet wohl vor ihm/ der grosse G\u00f6tter-", "tokens": ["Saul", "blei\u00b7bet", "wohl", "vor", "ihm", "/", "der", "gros\u00b7se", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "PPER", "$(", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.129": {"text": "Eur Herr ist wie ich h\u00f6r\u2019/ ein Schaum von losen", "tokens": ["Eur", "Herr", "ist", "wie", "ich", "h\u00f6r'", "/", "ein", "Schaum", "von", "lo\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "PPER", "VVFIN", "$(", "ART", "NN", "APPR", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.130": {"text": "Jhr f\u00fchrt nichts redliches auf euren Diebeshel-", "tokens": ["Ihr", "f\u00fchrt", "nichts", "red\u00b7li\u00b7ches", "auf", "eu\u00b7ren", "Die\u00b7bes\u00b7hel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "ADJA", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Jhr plakkt das arme Volk/ ihr raubet wo ihr", "tokens": ["Ihr", "plakkt", "das", "ar\u00b7me", "Volk", "/", "ihr", "rau\u00b7bet", "wo", "ihr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "PPER", "VVFIN", "PWAV", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.132": {"text": "Jhr seit zu anders nichts/ als B\u00fcberey ge-", "tokens": ["Ihr", "seit", "zu", "an\u00b7ders", "nichts", "/", "als", "B\u00fc\u00b7be\u00b7rey", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ADV", "PIS", "$(", "KOUS", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.133": {"text": "Soll ich euch speisen? Nein. Die k\u00f6nnens nicht", "tokens": ["Soll", "ich", "euch", "spei\u00b7sen", "?", "Nein", ".", "Die", "k\u00f6n\u00b7nens", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$.", "PTKANT", "$.", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.134": {"text": "So itzt in voller M\u00fch die rauche Schafe sche-", "tokens": ["So", "itzt", "in", "vol\u00b7ler", "M\u00fch", "die", "rau\u00b7che", "Scha\u00b7fe", "sche"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Nein/ pakket euch nur hin/ Bin ich gleich etwas", "tokens": ["Nein", "/", "pak\u00b7ket", "euch", "nur", "hin", "/", "Bin", "ich", "gleich", "et\u00b7was"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "VVFIN", "PPER", "ADV", "PTKVZ", "$(", "VAFIN", "PPER", "ADV", "PIS"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.136": {"text": "Und habe Vorraht gnug/ so ist es nicht vor", "tokens": ["Und", "ha\u00b7be", "Vor\u00b7raht", "gnug", "/", "so", "ist", "es", "nicht", "vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "NN", "ADV", "$(", "ADV", "VAFIN", "PPER", "PTKNEG", "PTKVZ"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.137": {"text": "Wer mir nicht Arbeit thut/ soll auch mein Brodt", "tokens": ["Wer", "mir", "nicht", "Ar\u00b7beit", "thut", "/", "soll", "auch", "mein", "Brodt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKNEG", "NN", "VVFIN", "$(", "VMFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.138": {"text": "Geht/ da sucht eure Kost wo ihr bisher gefressen/", "tokens": ["Geht", "/", "da", "sucht", "eu\u00b7re", "Kost", "wo", "ihr", "bis\u00b7her", "ge\u00b7fres\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "ADV", "VVFIN", "PPOSAT", "NN", "PWAV", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Geht stehlet anderswo/ und bettelt wo ihr", "tokens": ["Geht", "steh\u00b7let", "an\u00b7ders\u00b7wo", "/", "und", "bet\u00b7telt", "wo", "ihr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "VVFIN", "ADV", "$(", "KON", "VVFIN", "PWAV", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.140": {"text": "Vor David hab\u2019 ich nichts. Auch geb\u2019 ich kei-", "tokens": ["Vor", "Da\u00b7vid", "hab'", "ich", "nichts", ".", "Auch", "geb'", "ich", "kei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PIS", "$.", "ADV", "VVFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.141": {"text": "Der mir nicht wirklich dient. Da\u00df mir kein Schaf", "tokens": ["Der", "mir", "nicht", "wirk\u00b7lich", "dient", ".", "Da\u00df", "mir", "kein", "Schaf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PTKNEG", "ADJD", "VVFIN", "$.", "KOUS", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.142": {"text": "Und da\u00df ihr/ wie ihr r\u00fchmt/ mir nichtes abge-", "tokens": ["Und", "da\u00df", "ihr", "/", "wie", "ihr", "r\u00fchmt", "/", "mir", "nich\u00b7tes", "ab\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "$(", "PWAV", "PPER", "VVFIN", "$(", "PPER", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.143": {"text": "Da habt ihr recht gethan/ und mu\u00df ohn das", "tokens": ["Da", "habt", "ihr", "recht", "ge\u00b7than", "/", "und", "mu\u00df", "ohn", "das"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$(", "KON", "VMFIN", "APPR", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.144": {"text": "Da\u00df jhr Euch de\u00df enthalt/ ist nur ein blo\u00dfer", "tokens": ["Da\u00df", "jhr", "Euch", "de\u00df", "ent\u00b7halt", "/", "ist", "nur", "ein", "blo\u00b7\u00dfer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "$(", "VAFIN", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.145": {"text": "Vieleicht habt ihr es nicht zu werke k\u00f6nnen stel-", "tokens": ["Vie\u00b7leicht", "habt", "ihr", "es", "nicht", "zu", "wer\u00b7ke", "k\u00f6n\u00b7nen", "stel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "PTKNEG", "PTKZU", "VAINF", "VMFIN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Mein Sch\u00e4fervolk ist viel und stark/ so euch Ge-", "tokens": ["Mein", "Sch\u00e4\u00b7fer\u00b7volk", "ist", "viel", "und", "stark", "/", "so", "euch", "Ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "KON", "ADJD", "$(", "ADV", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.147": {"text": "Den Kopf wol bieten kan. Versucht es nur ge-", "tokens": ["Den", "Kopf", "wol", "bie\u00b7ten", "kan", ".", "Ver\u00b7sucht", "es", "nur", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVINF", "VMFIN", "$.", "VVFIN", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.148": {"text": "Wir wollen sehen/ wer dem andern abgewinnt.", "tokens": ["Wir", "wol\u00b7len", "se\u00b7hen", "/", "wer", "dem", "an\u00b7dern", "ab\u00b7ge\u00b7winnt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$(", "PWS", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Dr\u00fcm pakket euch nur weg von ", "tokens": ["Dr\u00fcm", "pak\u00b7ket", "euch", "nur", "weg", "von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.150": {"text": "Hier wohnt ein friedsam Volk/ geht eurem Feind\u2019", "tokens": ["Hier", "wohnt", "ein", "fried\u00b7sam", "Volk", "/", "geht", "eu\u00b7rem", "Feind'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN", "$(", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.151": {"text": "Recht! da\u00df ihr euren Leib vor euren K\u00f6nig", "tokens": ["Recht", "!", "da\u00df", "ihr", "eu\u00b7ren", "Leib", "vor", "eu\u00b7ren", "K\u00f6\u00b7nig"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "KOUS", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.152": {"text": "Geht/ es ist lang genug/ da\u00df ihr die Bauren", "tokens": ["Geht", "/", "es", "ist", "lang", "ge\u00b7nug", "/", "da\u00df", "ihr", "die", "Bau\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "PPER", "VAFIN", "ADJD", "ADV", "$(", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.153": {"text": "Wir fragen nichts nach euch/ bey solchen Frie-", "tokens": ["Wir", "fra\u00b7gen", "nichts", "nach", "euch", "/", "bey", "sol\u00b7chen", "Frie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPER", "$(", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.154": {"text": "Wir f\u00fcrchten uns auch nicht vor solchen Bettel-", "tokens": ["Wir", "f\u00fcrch\u00b7ten", "uns", "auch", "nicht", "vor", "sol\u00b7chen", "Bet\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.155": {"text": "Wie ihr und David seyd/ geht vor ein\u2019 andre", "tokens": ["Wie", "ihr", "und", "Da\u00b7vid", "seyd", "/", "geht", "vor", "ein'", "and\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "KON", "NE", "VAFIN", "$(", "VVFIN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.156": {"text": "Von mir bekommt ihr nichts. Geht/ pakket", "tokens": ["Von", "mir", "be\u00b7kommt", "ihr", "nichts", ".", "Geht", "/", "pak\u00b7ket"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "PIS", "$.", "VVFIN", "$(", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.157": {"text": "Furcht/ Scham/ Grimm/ Eyfer/ Zorn befiel die", "tokens": ["Furcht", "/", "Scham", "/", "Grimm", "/", "Ey\u00b7fer", "/", "Zorn", "be\u00b7fiel", "die"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NE", "$(", "NN", "$(", "NN", "VVFIN", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.158": {"text": "Sie kehrten \u00fcm/ und sich von diesem R\u00e4kel wand-", "tokens": ["Sie", "kehr\u00b7ten", "\u00fcm", "/", "und", "sich", "von", "die\u00b7sem", "R\u00e4\u00b7kel", "wan\u00b7d"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "$(", "KON", "PRF", "APPR", "PDAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Sie eylten nach dem Heer/ und sagtens David", "tokens": ["Sie", "eyl\u00b7ten", "nach", "dem", "Heer", "/", "und", "sag\u00b7tens", "Da\u00b7vid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "KON", "NE", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.160": {"text": "Was ihnen dieser R\u00f6lps vor Schimpf hatt\u2019 an-", "tokens": ["Was", "ih\u00b7nen", "die\u00b7ser", "R\u00f6lps", "vor", "Schimpf", "hatt'", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PDAT", "NN", "APPR", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.161": {"text": "Der fromme F\u00fcrst erschrakk von dieser neuen", "tokens": ["Der", "from\u00b7me", "F\u00fcrst", "er\u00b7schrakk", "von", "die\u00b7ser", "neu\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PDAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.162": {"text": "Er nam sein Schwert zur Hand/ und kehret sich", "tokens": ["Er", "nam", "sein", "Schwert", "zur", "Hand", "/", "und", "keh\u00b7ret", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$(", "KON", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.163": {"text": "Das neben ihn best\u00fcrtzt/ daher auch nach und", "tokens": ["Das", "ne\u00b7ben", "ihn", "be\u00b7st\u00fcrtzt", "/", "da\u00b7her", "auch", "nach", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "PPER", "VVPP", "$(", "PAV", "ADV", "APPR", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.164": {"text": "Von Grimm und Rach\u2019 erhitzt/ also erbittert", "tokens": ["Von", "Grimm", "und", "Rach'", "er\u00b7hitzt", "/", "al\u00b7so", "er\u00b7bit\u00b7tert"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "KON", "NN", "VVFIN", "$(", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.165": {"text": "Was! soll der schlimme Hund/ so sch\u00e4ndlich mich", "tokens": ["Was", "!", "soll", "der", "schlim\u00b7me", "Hund", "/", "so", "sch\u00e4nd\u00b7lich", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "$.", "VMFIN", "ART", "ADJA", "NN", "$(", "ADV", "ADJD", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.166": {"text": "Wolan seyd nur getrost/ ihr meine treue Rot-", "tokens": ["Wo\u00b7lan", "seyd", "nur", "ge\u00b7trost", "/", "ihr", "mei\u00b7ne", "treu\u00b7e", "Rot"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "VVPP", "$(", "PPER", "PPOSAT", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Ergreiffet das Gewehr/ und last uns eylends", "tokens": ["Er\u00b7greif\u00b7fet", "das", "Ge\u00b7wehr", "/", "und", "last", "uns", "ey\u00b7lends"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$(", "KON", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.168": {"text": "Er soll/ was David kan/ bald/ doch mit Un-", "tokens": ["Er", "soll", "/", "was", "Da\u00b7vid", "kan", "/", "bald", "/", "doch", "mit", "Un"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$(", "PWS", "NE", "VMFIN", "$(", "ADV", "$(", "ADV", "APPR", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.169": {"text": "Sein ungeschliffnes Maul soll ihm genugsam", "tokens": ["Sein", "un\u00b7ge\u00b7schliff\u00b7nes", "Maul", "soll", "ihm", "ge\u00b7nug\u00b7sam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.170": {"text": "Sein gantzes Hau\u00df sol heut\u2019 in frischem Blute ba-", "tokens": ["Sein", "gant\u00b7zes", "Hau\u00df", "sol", "heut'", "in", "fri\u00b7schem", "Blu\u00b7te", "ba"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADV", "APPR", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Der grobe Geitzhals soll sein eigner Henker", "tokens": ["Der", "gro\u00b7be", "Geitz\u00b7hals", "soll", "sein", "eig\u00b7ner", "Hen\u00b7ker"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.172": {"text": "Schont keines Mannes nicht/ schlagt/ stecht", "tokens": ["Schont", "kei\u00b7nes", "Man\u00b7nes", "nicht", "/", "schlagt", "/", "stecht"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "PIAT", "NN", "PTKNEG", "$(", "VVFIN", "$(", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.173": {"text": "Der T\u00f6lpel hat sein Land gantz unversehrt bestel-", "tokens": ["Der", "T\u00f6l\u00b7pel", "hat", "sein", "Land", "gantz", "un\u00b7ver\u00b7sehrt", "bes\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Wir haben ihm zu Nutz nicht einen Baum gef\u00e4l-", "tokens": ["Wir", "ha\u00b7ben", "ihm", "zu", "Nutz", "nicht", "ei\u00b7nen", "Baum", "ge\u00b7f\u00e4l"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "PTKNEG", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Wir haben gegen Jhn so h\u00f6flich uns be-", "tokens": ["Wir", "ha\u00b7ben", "ge\u00b7gen", "Jhn", "so", "h\u00f6f\u00b7lich", "uns", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "ADJD", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.176": {"text": "Und in der gr\u00f6sten Noht auch nicht ein Lamm", "tokens": ["Und", "in", "der", "gr\u00f6s\u00b7ten", "Noht", "auch", "nicht", "ein", "Lamm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADV", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.177": {"text": "Wir liessen seine Schaf auf diesen fetten Hei-", "tokens": ["Wir", "lies\u00b7sen", "sei\u00b7ne", "Schaf", "auf", "die\u00b7sen", "fet\u00b7ten", "Hei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PDAT", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Mit/ bey/ und neben uns gantz ungehindert wei-", "tokens": ["Mit", "/", "bey", "/", "und", "ne\u00b7ben", "uns", "gantz", "un\u00b7ge\u00b7hin\u00b7dert", "wei"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "$(", "APPR", "$(", "KON", "APPR", "PPER", "ADV", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Wir haben gegen Jhn uns nicht erzeigt wie", "tokens": ["Wir", "ha\u00b7ben", "ge\u00b7gen", "Jhn", "uns", "nicht", "er\u00b7zeigt", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "PRF", "PTKNEG", "VVPP", "KOKOM"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.180": {"text": "Er hat an mir gehabt recht einen guten Freund.", "tokens": ["Er", "hat", "an", "mir", "ge\u00b7habt", "recht", "ei\u00b7nen", "gu\u00b7ten", "Freund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VAPP", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Nu aber soll Er sehn was sein verteufelt Geitzen/", "tokens": ["Nu", "a\u00b7ber", "soll", "Er", "sehn", "was", "sein", "ver\u00b7teu\u00b7felt", "Geit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVFIN", "PIS", "VAINF", "VVFIN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Und gro\u00dfer Unverstand vor Unheil auf-kan-ret-", "tokens": ["Und", "gro\u00b7\u00dfer", "Un\u00b7ver\u00b7stand", "vor", "Un\u00b7heil", "auf\u00b7kan\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.183": {"text": "Ich wil ihm weisen/ was ein kleiner Hauffe", "tokens": ["Ich", "wil", "ihm", "wei\u00b7sen", "/", "was", "ein", "klei\u00b7ner", "Hauf\u00b7fe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$(", "PWS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.184": {"text": "Er soll mit Jammer sehn/ da\u00df David sey ein", "tokens": ["Er", "soll", "mit", "Jam\u00b7mer", "sehn", "/", "da\u00df", "Da\u00b7vid", "sey", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF", "$(", "KOUS", "NE", "VAFIN", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.185": {"text": "Soll Nabal vnd sein Hau\u00df so herrlich sich heut la-", "tokens": ["Soll", "Na\u00b7bal", "vnd", "sein", "Hau\u00df", "so", "herr\u00b7lich", "sich", "heut", "la"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "NE", "KON", "PPOSAT", "NN", "ADV", "ADJD", "PRF", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Und wird nicht einmal Dank vor unsre Dienste ha-", "tokens": ["Und", "wird", "nicht", "ein\u00b7mal", "Dank", "vor", "uns\u00b7re", "Diens\u00b7te", "ha"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "NN", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Geniest mein armes Volk nicht einen Trunck", "tokens": ["Ge\u00b7niest", "mein", "ar\u00b7mes", "Volk", "nicht", "ei\u00b7nen", "Trunck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.188": {"text": "Giebt man vor Wolthat Spott/ vor Freund-", "tokens": ["Giebt", "man", "vor", "Wolt\u00b7hat", "Spott", "/", "vor", "Freun\u00b7d"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "NN", "NN", "$(", "APPR", "TRUNC"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.189": {"text": "Nein/ warlich! diesen Trotz kan ich durchaus", "tokens": ["Nein", "/", "war\u00b7lich", "!", "die\u00b7sen", "Trotz", "kan", "ich", "durc\u00b7haus"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "ADV", "$.", "PDAT", "NN", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.190": {"text": "Er mu\u00df ein K\u00f6nigsheer noch besser lernen meiden.", "tokens": ["Er", "mu\u00df", "ein", "K\u00f6\u00b7nigs\u00b7heer", "noch", "bes\u00b7ser", "ler\u00b7nen", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Wer einem Kriegesmann/ was billich ist/ ver-", "tokens": ["Wer", "ei\u00b7nem", "Krie\u00b7ges\u00b7mann", "/", "was", "bil\u00b7lich", "ist", "/", "ver"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PWS", "ART", "NN", "$(", "PWS", "ADJD", "VAFIN", "$(", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.192": {"text": "Der hat gemeiniglich das Leben hingewagt.", "tokens": ["Der", "hat", "ge\u00b7mei\u00b7nig\u00b7lich", "das", "Le\u00b7ben", "hin\u00b7ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "Ich wil den Narrenkopf und sein gantz Haus ver-", "tokens": ["Ich", "wil", "den", "Nar\u00b7ren\u00b7kopf", "und", "sein", "gantz", "Haus", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "KON", "PPOSAT", "ADV", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.194": {"text": "Es soll heut alles das/ was m\u00e4nnlich heisset/ ster-", "tokens": ["Es", "soll", "heut", "al\u00b7les", "das", "/", "was", "m\u00e4nn\u00b7lich", "heis\u00b7set", "/", "ster"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "ART", "$(", "PWS", "ADJD", "VVFIN", "$(", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Wolan so folget mir/ und macht euch wol be-", "tokens": ["Wo\u00b7lan", "so", "fol\u00b7get", "mir", "/", "und", "macht", "euch", "wol", "be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$(", "KON", "VVFIN", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.196": {"text": "Heut ist euch gro\u00dfes Gut/ und Beute satt be-", "tokens": ["Heut", "ist", "euch", "gro\u00b7\u00dfes", "Gut", "/", "und", "Beu\u00b7te", "satt", "be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "$(", "KON", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.197": {"text": "Das Wort war kaum gesagt/ man sah die Armen", "tokens": ["Das", "Wort", "war", "kaum", "ge\u00b7sagt", "/", "man", "sah", "die", "Ar\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$(", "PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.198": {"text": "Man sah das tapfre Volk nach Schwert und Bo-", "tokens": ["Man", "sah", "das", "tapf\u00b7re", "Volk", "nach", "Schwert", "und", "Bo"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "APPR", "NE", "KON", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.199": {"text": "Sie waren all ergrimmt/ die Sebel scharf ge-", "tokens": ["Sie", "wa\u00b7ren", "all", "er\u00b7grimmt", "/", "die", "Se\u00b7bel", "scharf", "ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "VVPP", "$(", "ART", "NN", "VVFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.200": {"text": "Der Muht war auf das Dorf/ und Nabals Gut", "tokens": ["Der", "Muht", "war", "auf", "das", "Dorf", "/", "und", "Na\u00b7bals", "Gut"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$(", "KON", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.201": {"text": "Ein Knecht von Nabals Volk/ der alles die\u00df ver-", "tokens": ["Ein", "Knecht", "von", "Na\u00b7bals", "Volk", "/", "der", "al\u00b7les", "die\u00df", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "NN", "$(", "ART", "PIS", "PDS", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.202": {"text": "Macht ihm bald einen Schlu\u00df was darauf w\u00fcrde", "tokens": ["Macht", "ihm", "bald", "ei\u00b7nen", "Schlu\u00df", "was", "da\u00b7rauf", "w\u00fcr\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "PWS", "PAV", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.203": {"text": "Er sahe schon vorher das Ungl\u00fckk und Gefahr/", "tokens": ["Er", "sa\u00b7he", "schon", "vor\u00b7her", "das", "Un\u00b7gl\u00fckk", "und", "Ge\u00b7fahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Er hatte Vorschmakk gnug was David wil-", "tokens": ["Er", "hat\u00b7te", "Vor\u00b7schmakk", "gnug", "was", "Da\u00b7vid", "wil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "ADV", "PWS", "NE", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.205": {"text": "Er lief geschwinde hin/ als sie noch alle sassen/", "tokens": ["Er", "lief", "ge\u00b7schwin\u00b7de", "hin", "/", "als", "sie", "noch", "al\u00b7le", "sas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "PTKVZ", "$(", "KOUS", "PPER", "ADV", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Und mit vergn\u00fcgter Lust die fette Mahlzeit assen/", "tokens": ["Und", "mit", "ver\u00b7gn\u00fcg\u00b7ter", "Lust", "die", "fet\u00b7te", "Mahl\u00b7zeit", "as\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "Sprach zu Abigail: Ach Frau! auf diese Freud\u2019/", "tokens": ["Sprach", "zu", "A\u00b7bi\u00b7gail", ":", "Ach", "Frau", "!", "auf", "die\u00b7se", "Freud'", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$.", "ITJ", "NN", "$.", "APPR", "PDAT", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.208": {"text": "Folgt leider Angst und Noht und blutigs Her-", "tokens": ["Folgt", "lei\u00b7der", "Angst", "und", "Noht", "und", "blu\u00b7tigs", "Her"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "NN", "KON", "NN", "KON", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.209": {"text": "Ein schrekkliches Gew\u00f6lk schwebt \u00fcber unserm", "tokens": ["Ein", "schrek\u00b7kli\u00b7ches", "Ge\u00b7w\u00f6lk", "schwebt", "\u00fc\u00b7ber", "un\u00b7serm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.210": {"text": "Der Untergang ist da. Ich sag\u2019 es dir mit Grause/", "tokens": ["Der", "Un\u00b7ter\u00b7gang", "ist", "da", ".", "Ich", "sag'", "es", "dir", "mit", "Grau\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "PPER", "VVFIN", "PPER", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Wo du nicht schaffest Raht/ so ists mit uns ge-", "tokens": ["Wo", "du", "nicht", "schaf\u00b7fest", "Raht", "/", "so", "ists", "mit", "uns", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "VVFIN", "NN", "$(", "ADV", "VAFIN", "APPR", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.212": {"text": "Das Mordschwert ist im Zug und nahet sich", "tokens": ["Das", "Mord\u00b7schwert", "ist", "im", "Zug", "und", "na\u00b7het", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "KON", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.213": {"text": "Abigail wei\u00df nicht was sie begin\u0303t vor Schrekken/", "tokens": ["A\u00b7bi\u00b7gail", "wei\u00df", "nicht", "was", "sie", "be\u00b7gi\u00f1t", "vor", "Schrek\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "PWS", "PPER", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.214": {"text": "Sprach zitternd zu dem Knecht/ Er soll es bald", "tokens": ["Sprach", "zit\u00b7ternd", "zu", "dem", "Knecht", "/", "Er", "soll", "es", "bald"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVPP", "APPR", "ART", "NN", "$(", "PPER", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.215": {"text": "Was die\u00df/ so er gesagt/ vor eine Rede sey?", "tokens": ["Was", "die\u00df", "/", "so", "er", "ge\u00b7sagt", "/", "vor", "ei\u00b7ne", "Re\u00b7de", "sey", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "$(", "ADV", "PPER", "VVPP", "$(", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "Drauf bringt er alsobald/ ihr diese Nachricht", "tokens": ["Drauf", "bringt", "er", "al\u00b7so\u00b7bald", "/", "ihr", "die\u00b7se", "Nach\u00b7richt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$(", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.217": {"text": "H\u00f6r hochgeehrte Frau/ vor etwa sieben Stunden/", "tokens": ["H\u00f6r", "hoch\u00b7geehr\u00b7te", "Frau", "/", "vor", "et\u00b7wa", "sie\u00b7ben", "Stun\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$(", "APPR", "ADV", "CARD", "NN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.218": {"text": "Da haben sich allhier zehn M\u00e4nner eingefunden/", "tokens": ["Da", "ha\u00b7ben", "sich", "all\u00b7hier", "zehn", "M\u00e4n\u00b7ner", "ein\u00b7ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "ADV", "CARD", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.219": {"text": "Und Nabal angeredt mit gro\u00dfer H\u00f6flichkeit/", "tokens": ["Und", "Na\u00b7bal", "an\u00b7ge\u00b7redt", "mit", "gro\u00b7\u00dfer", "H\u00f6f\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVPP", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Sie klagten Davids Noth/ und ihre theure Zeit.", "tokens": ["Sie", "klag\u00b7ten", "Da\u00b7vids", "Noth", "/", "und", "ih\u00b7re", "theu\u00b7re", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "$(", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.221": {"text": "Sie baten ihn \u00fcm H\u00fclf \u00fcm wenig Trank und", "tokens": ["Sie", "ba\u00b7ten", "ihn", "\u00fcm", "H\u00fclf", "\u00fcm", "we\u00b7nig", "Trank", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "ADV", "PIAT", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.222": {"text": "Er aber fuhr sie an auf ungeheure Weise/", "tokens": ["Er", "a\u00b7ber", "fuhr", "sie", "an", "auf", "un\u00b7ge\u00b7heu\u00b7re", "Wei\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "APPR", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Er schalt und schimpfte sie/ ich hab\u2019 es selbst ge-", "tokens": ["Er", "schalt", "und", "schimpf\u00b7te", "sie", "/", "ich", "hab'", "es", "selbst", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "$(", "PPER", "VAFIN", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.224": {"text": "Er hie\u00df sie Schelm und Dieb/ und musten also", "tokens": ["Er", "hie\u00df", "sie", "Schelm", "und", "Dieb", "/", "und", "mus\u00b7ten", "al\u00b7so"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$(", "KON", "VMFIN", "ADV"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.225": {"text": "Jtzt bin ich gleich bericht da\u00df David auf-wird-", "tokens": ["Jtzt", "bin", "ich", "gleich", "be\u00b7richt", "da\u00df", "Da\u00b7vid", "auf\u00b7wird"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVFIN", "KOUS", "NE", "TRUNC"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.226": {"text": "Mit seinem gantzen Heer\u2019/ \u00fcm diesen Spott zu", "tokens": ["Mit", "sei\u00b7nem", "gant\u00b7zen", "Heer'", "/", "\u00fcm", "die\u00b7sen", "Spott", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "ADV", "PDAT", "NN", "PTKZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.227": {"text": "Wir sollen/ wie mir nun vertrauet/ ingemein", "tokens": ["Wir", "sol\u00b7len", "/", "wie", "mir", "nun", "ver\u00b7trau\u00b7et", "/", "in\u00b7ge\u00b7mein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "$(", "PWAV", "PPER", "ADV", "VVFIN", "$(", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Ohn all\u2019 Erbarmen heut\u2019 des bittern Todes seyn.", "tokens": ["Ohn", "all'", "Er\u00b7bar\u00b7men", "heut'", "des", "bit\u00b7tern", "To\u00b7des", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Nu hat des Davids Volk uns niemals ein Ge-", "tokens": ["Nu", "hat", "des", "Da\u00b7vids", "Volk", "uns", "nie\u00b7mals", "ein", "Ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NE", "NN", "PPER", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.230": {"text": "Noch Schaden beygebracht/ es stehn die Wollen-", "tokens": ["Noch", "Scha\u00b7den", "bey\u00b7ge\u00b7bracht", "/", "es", "stehn", "die", "Wol\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "VVPP", "$(", "PPER", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.231": {"text": "Ja noch in voller Zahl/ un\u0303 sind durch sie besch\u00fctzt", "tokens": ["Ja", "noch", "in", "vol\u00b7ler", "Zahl", "/", "u\u00f1", "sind", "durch", "sie", "be\u00b7sch\u00fctzt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "APPR", "ADJA", "NN", "$(", "KON", "VAFIN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Es hat uns dieses Heer/ glaub mir/ sehr viel ge-", "tokens": ["Es", "hat", "uns", "die\u00b7ses", "Heer", "/", "glaub", "mir", "/", "sehr", "viel", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "PDAT", "NN", "$(", "VVFIN", "PPER", "$(", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.233": {"text": "Sie waren \u00fcm das Vieh/ wie aufgef\u00fchrte Mau-", "tokens": ["Sie", "wa\u00b7ren", "\u00fcm", "das", "Vieh", "/", "wie", "auf\u00b7ge\u00b7f\u00fchr\u00b7te", "Mau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "ART", "NN", "$(", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Vor ihrer Wachsamkeit kunt\u2019 auch kein Wolf", "tokens": ["Vor", "ih\u00b7rer", "Wach\u00b7sam\u00b7keit", "kunt'", "auch", "kein", "Wolf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "ADV", "PIAT", "NE"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.235": {"text": "Sie haben neben uns/ auch in der Mitternacht/", "tokens": ["Sie", "ha\u00b7ben", "ne\u00b7ben", "uns", "/", "auch", "in", "der", "Mit\u00b7ter\u00b7nacht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "$(", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Mit steter Hurtigkeit/ vor sich und uns gewacht.", "tokens": ["Mit", "ste\u00b7ter", "Hur\u00b7tig\u00b7keit", "/", "vor", "sich", "und", "uns", "ge\u00b7wacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "APPR", "PRF", "KON", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Schau so hat David uns und unser Vieh ver-", "tokens": ["Schau", "so", "hat", "Da\u00b7vid", "uns", "und", "un\u00b7ser", "Vieh", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VAFIN", "NE", "PPER", "KON", "PPOSAT", "NN", "TRUNC"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.238": {"text": "Und wird vom Nabal nun so schimpflich abge-", "tokens": ["Und", "wird", "vom", "Na\u00b7bal", "nun", "so", "schimpf\u00b7lich", "ab\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPRART", "NE", "ADV", "ADV", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.239": {"text": "Dr\u00fcm wird solch\u2019 Ungl\u00fckkslast nun \u00fcber uns", "tokens": ["Dr\u00fcm", "wird", "solch'", "Un\u00b7gl\u00fckks\u00b7last", "nun", "\u00fc\u00b7ber", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PIAT", "NN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.240": {"text": "Und hat es unser Herr durch Bo\u00dfheit selbst ge-", "tokens": ["Und", "hat", "es", "un\u00b7ser", "Herr", "durch", "Bo\u00df\u00b7heit", "selbst", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.241": {"text": "Ich hett es/ als ichs h\u00f6hrt\u2019/ ihm hertzlich gern ge-", "tokens": ["Ich", "hett", "es", "/", "als", "ichs", "h\u00f6hrt'", "/", "ihm", "hertz\u00b7lich", "gern", "ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "$(", "KOUS", "PIS", "VVFIN", "$(", "PPER", "ADJD", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.242": {"text": "So weist du/ wie Er ist/ wie Er so giftig f\u00e4hret/", "tokens": ["So", "weist", "du", "/", "wie", "Er", "ist", "/", "wie", "Er", "so", "gif\u00b7tig", "f\u00e4h\u00b7ret", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWAV", "PPER", "VAFIN", "$(", "PWAV", "PPER", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Redt ihm ein Mensche zu der es sehr g\u00fctlich", "tokens": ["Redt", "ihm", "ein", "Men\u00b7sche", "zu", "der", "es", "sehr", "g\u00fct\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "APPR", "PRELS", "PPER", "ADV", "ADJD"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.244": {"text": "So f\u00e4hrt Er ihm zu Hals\u2019 und wird ihm spinne", "tokens": ["So", "f\u00e4hrt", "Er", "ihm", "zu", "Hals'", "und", "wird", "ihm", "spin\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "KON", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.245": {"text": "Hett\u2019 ich ein Wort gesagt/ Er hette mich geschla-", "tokens": ["Hett'", "ich", "ein", "Wort", "ge\u00b7sagt", "/", "Er", "het\u00b7te", "mich", "ge\u00b7schla"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVPP", "$(", "PPER", "VAFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.246": {"text": "Ich hette m\u00fcssen St\u00f6\u00df\u2019 und Feindschaft davon", "tokens": ["Ich", "het\u00b7te", "m\u00fcs\u00b7sen", "St\u00f6\u00df'", "und", "Feind\u00b7schaft", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VMFIN", "NE", "KON", "NN", "PAV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.247": {"text": "Er ist/ wie dir bekandt/ ein sehr geschwinder", "tokens": ["Er", "ist", "/", "wie", "dir", "be\u00b7kandt", "/", "ein", "sehr", "ge\u00b7schwin\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$(", "PWAV", "PPER", "ADJD", "$(", "ART", "ADV", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.248": {"text": "Der keinen Widerspruch noch Rahtschlag lei-", "tokens": ["Der", "kei\u00b7nen", "Wi\u00b7der\u00b7spruch", "noch", "Raht\u00b7schlag", "lei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "ADV", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.249": {"text": "Es mu\u00df ihm alles gehn/ wie er nur selber denket/", "tokens": ["Es", "mu\u00df", "ihm", "al\u00b7les", "gehn", "/", "wie", "er", "nur", "sel\u00b7ber", "den\u00b7ket", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "VVINF", "$(", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.250": {"text": "Ob manches ihn hernach schon hertzlich reut und", "tokens": ["Ob", "man\u00b7ches", "ihn", "her\u00b7nach", "schon", "hertz\u00b7lich", "reut", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.251": {"text": "Er hat in seinem Kopf\u2019 ein feuriges Gehirn/", "tokens": ["Er", "hat", "in", "sei\u00b7nem", "Kopf'", "ein", "feu\u00b7ri\u00b7ges", "Ge\u00b7hirn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Und folget niemand nicht/ als seiner eignen", "tokens": ["Und", "fol\u00b7get", "nie\u00b7mand", "nicht", "/", "als", "sei\u00b7ner", "eig\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "PTKNEG", "$(", "KOUS", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.253": {"text": "Da sieht man nun die Frucht! Gott wolle sich der", "tokens": ["Da", "sieht", "man", "nun", "die", "Frucht", "!", "Gott", "wol\u00b7le", "sich", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "$.", "NN", "VMFIN", "PRF", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.254": {"text": "Die wir an dieser Sach\u2019 unschuldig sind/ erbar-", "tokens": ["Die", "wir", "an", "die\u00b7ser", "Sach'", "un\u00b7schul\u00b7dig", "sind", "/", "er\u00b7ba\u00b7r"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "PPER", "APPR", "PDAT", "NN", "ADJD", "VAFIN", "$(", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.255": {"text": "Wir habens nicht verschuldt/ besondern Er mit", "tokens": ["Wir", "ha\u00b7bens", "nicht", "ver\u00b7schuldt", "/", "be\u00b7son\u00b7dern", "Er", "mit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVPP", "$(", "VVFIN", "PPER", "APPR"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.256": {"text": "Doch! s\u00fcndiget der Herr/ so leidet auch der", "tokens": ["Doch", "!", "s\u00fcn\u00b7di\u00b7get", "der", "Herr", "/", "so", "lei\u00b7det", "auch", "der"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$.", "VVFIN", "ART", "NN", "$(", "ADV", "VVFIN", "ADV", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.257": {"text": "Nu wei\u00df ich/ wehrte Frau/ da\u00df du von hohen", "tokens": ["Nu", "wei\u00df", "ich", "/", "wehr\u00b7te", "Frau", "/", "da\u00df", "du", "von", "ho\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "VVFIN", "NN", "$(", "KOUS", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.258": {"text": "Und da\u00df du/ wem du wilst/ das Hertze kanst ge-", "tokens": ["Und", "da\u00df", "du", "/", "wem", "du", "wilst", "/", "das", "Hert\u00b7ze", "kanst", "ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "$(", "PWS", "PPER", "VMFIN", "$(", "PDS", "VVFIN", "VMFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.259": {"text": "Dein tugendsamer Geist/ dein trefflicher Ver-", "tokens": ["Dein", "tu\u00b7gend\u00b7sa\u00b7mer", "Geist", "/", "dein", "treff\u00b7li\u00b7cher", "Ver"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "PPOSAT", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.260": {"text": "Dein klug-verschlagnes Hertz/ ist ja genug be-", "tokens": ["Dein", "klug\u00b7ver\u00b7schlagnes", "Hertz", "/", "ist", "ja", "ge\u00b7nug", "be"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "VAFIN", "ADV", "ADV", "TRUNC"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.261": {"text": "Wolan! trit vor den Ri\u00df/ rett\u2019 uns durch Gottes", "tokens": ["Wo\u00b7lan", "!", "trit", "vor", "den", "Ri\u00df", "/", "rett'", "uns", "durch", "Got\u00b7tes"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$.", "VVFIN", "APPR", "ART", "NN", "$(", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.262": {"text": "Geh dem erbostem Volk/ mit sanftem Muht\u2019 ent-", "tokens": ["Geh", "dem", "er\u00b7bos\u00b7tem", "Volk", "/", "mit", "sanf\u00b7tem", "Muht'", "ent"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN", "$(", "APPR", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.263": {"text": "Lesch mit dem Z\u00e4hrenbach des Davids grimme", "tokens": ["Lesch", "mit", "dem", "Z\u00e4h\u00b7ren\u00b7bach", "des", "Da\u00b7vids", "grim\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NE", "VVFIN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.264": {"text": "Und wehre mit Vernunft der gro\u00dfen Ungl\u00fckks-", "tokens": ["Und", "weh\u00b7re", "mit", "Ver\u00b7nunft", "der", "gro\u00b7\u00dfen", "Un\u00b7gl\u00fc\u00b7kks"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "Nim Speis\u2019 und Trank mit dir/ wir wollen helfen", "tokens": ["Nim", "Speis'", "und", "Trank", "mit", "dir", "/", "wir", "wol\u00b7len", "hel\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "KON", "NN", "APPR", "PPER", "$(", "PPER", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.266": {"text": "Ich wei\u00df wenn David h\u00f6hrt das j\u00e4mmerliche", "tokens": ["Ich", "wei\u00df", "wenn", "Da\u00b7vid", "h\u00f6hrt", "das", "j\u00e4m\u00b7mer\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOUS", "NE", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.267": {"text": "Und da\u00df in diesen Spott kein Mensch gewilligt", "tokens": ["Und", "da\u00df", "in", "die\u00b7sen", "Spott", "kein", "Mensch", "ge\u00b7wil\u00b7ligt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "PDAT", "NN", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.268": {"text": "Als Nabal nur vor sich/ ", "tokens": ["Als", "Na\u00b7bal", "nur", "vor", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "APPR", "PRF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.269": {"text": "Man wei\u00df ja \u00fcberal des Davids gut Gem\u00fchte/", "tokens": ["Man", "wei\u00df", "ja", "\u00fc\u00b7be\u00b7ral", "des", "Da\u00b7vids", "gut", "Ge\u00b7m\u00fch\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "ART", "NE", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.270": {"text": "Und da\u00df setn tapfres Hertz vermischt mit sanfter", "tokens": ["Und", "da\u00df", "setn", "tapf\u00b7res", "Hertz", "ver\u00b7mischt", "mit", "sanf\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.271": {"text": "Versuch es/ mach nur fort/ und eyle mit der", "tokens": ["Ver\u00b7such", "es", "/", "mach", "nur", "fort", "/", "und", "ey\u00b7le", "mit", "der"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$(", "VVFIN", "ADV", "PTKVZ", "$(", "KON", "NN", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.272": {"text": "Eh\u2019 uns das Ungl\u00fckk trifft. Bey Zeiten ist noch", "tokens": ["Eh'", "uns", "das", "Un\u00b7gl\u00fckk", "trifft", ".", "Bey", "Zei\u00b7ten", "ist", "noch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$.", "APPR", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.273": {"text": "Abigail voll Angst begunt insich zu gehen/", "tokens": ["A\u00b7bi\u00b7gail", "voll", "Angst", "be\u00b7gunt", "in\u00b7sich", "zu", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "NN", "VVFIN", "ADV", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.274": {"text": "Dacht/ Huy! Des Knechtes Red\u2019 ist gantz nicht", "tokens": ["Dacht", "/", "Huy", "!", "Des", "Knech\u00b7tes", "Red'", "ist", "gantz", "nicht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "NE", "$.", "ART", "ADJA", "NN", "VAFIN", "ADV", "PTKNEG"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.275": {"text": "Der Vorschlag ist sehr gut/ ob schon der Mensch", "tokens": ["Der", "Vor\u00b7schlag", "ist", "sehr", "gut", "/", "ob", "schon", "der", "Mensch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$(", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.276": {"text": "Durch kleines Werkgezeug geschehn oft gro\u00dfe", "tokens": ["Durch", "klei\u00b7nes", "Werk\u00b7ge\u00b7zeug", "ge\u00b7schehn", "oft", "gro\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP", "ADV", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.277": {"text": "Sie trit bald auf die Seit\u2019 und f\u00e4ngt an zubeden-", "tokens": ["Sie", "trit", "bald", "auf", "die", "Seit'", "und", "f\u00e4ngt", "an", "zu\u00b7be\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "KON", "VVFIN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.278": {"text": "Was Sie dem K\u00f6nige zu Ehren wolte schenken/", "tokens": ["Was", "Sie", "dem", "K\u00f6\u00b7ni\u00b7ge", "zu", "Eh\u00b7ren", "wol\u00b7te", "schen\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Das hochbetr\u00fcbte Weib steht aller Sorgen", "tokens": ["Das", "hoch\u00b7be\u00b7tr\u00fcb\u00b7te", "Weib", "steht", "al\u00b7ler", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.280": {"text": "Wei\u00df nicht/ wie sie den Zorn des Davids stillen", "tokens": ["Wei\u00df", "nicht", "/", "wie", "sie", "den", "Zorn", "des", "Da\u00b7vids", "stil\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$(", "PWAV", "PPER", "ART", "NN", "ART", "NE", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.281": {"text": "Darf ihren trunknen Mann auch nicht einmal", "tokens": ["Darf", "ih\u00b7ren", "trunk\u00b7nen", "Mann", "auch", "nicht", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.282": {"text": "Die Zeit geht eylends weg/ Sie f\u00e4ngt es an zu wa-", "tokens": ["Die", "Zeit", "geht", "ey\u00b7lends", "weg", "/", "Sie", "f\u00e4ngt", "es", "an", "zu", "wa"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$(", "PPER", "VVFIN", "PPER", "APPR", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.283": {"text": "Und thuts allein vor sich: Sie nimmt Brodt/", "tokens": ["Und", "thuts", "al\u00b7lein", "vor", "sich", ":", "Sie", "nimmt", "Brodt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PRF", "$.", "PPER", "VVFIN", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.284": {"text": "Und was zum Labsal dient/ Sie pakket h\u00e4uffig", "tokens": ["Und", "was", "zum", "Lab\u00b7sal", "dient", "/", "Sie", "pak\u00b7ket", "h\u00e4uf\u00b7fig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "APPRART", "NN", "VVFIN", "$(", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.285": {"text": "Sie heist mit dem Geschenk voran die Esel trei-", "tokens": ["Sie", "heist", "mit", "dem", "Ge\u00b7schenk", "vo\u00b7ran", "die", "E\u00b7sel", "trei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "Sie aber h\u00e4lt vor gut etwas zu r\u00fckk zu bleiben/", "tokens": ["Sie", "a\u00b7ber", "h\u00e4lt", "vor", "gut", "et\u00b7was", "zu", "r\u00fckk", "zu", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ADJD", "PIS", "PTKZU", "VVINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Sie zieht sich reinlich an/ und folget allge-", "tokens": ["Sie", "zieht", "sich", "rein\u00b7lich", "an", "/", "und", "fol\u00b7get", "all\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "$(", "KON", "VVFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.288": {"text": "Auf einem muntren Thier/ den frommen Knech-", "tokens": ["Auf", "ei\u00b7nem", "mun\u00b7tren", "Thier", "/", "den", "from\u00b7men", "Knech"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.289": {"text": "Sie denkt/ ich wil voran die reiche Gaben senden/", "tokens": ["Sie", "denkt", "/", "ich", "wil", "vo\u00b7ran", "die", "rei\u00b7che", "Ga\u00b7ben", "sen\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.290": {"text": "Und also Davids Grimm auf solche weise wenden/", "tokens": ["Und", "al\u00b7so", "Da\u00b7vids", "Grimm", "auf", "sol\u00b7che", "wei\u00b7se", "wen\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "NE", "APPR", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.291": {"text": " sie ist/ wie es fast scheint/ von Jacob des be-\nlehrt/", "tokens": ["sie", "ist", "/", "wie", "es", "fast", "scheint", "/", "von", "Ja\u00b7cob", "des", "be", "lehrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "PWAV", "PPER", "ADV", "VVFIN", "$(", "APPR", "NE", "ART", "TRUNC", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.292": {"text": "Der eben auf den Schlag des Esaus Zorn ge-", "tokens": ["Der", "e\u00b7ben", "auf", "den", "Schlag", "des", "E\u00b7saus", "Zorn", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "ART", "NN", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.293": {"text": "So reiset Sie nun fort mit M\u00e4gden und mit", "tokens": ["So", "rei\u00b7set", "Sie", "nun", "fort", "mit", "M\u00e4g\u00b7den", "und", "mit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "APPR", "NN", "KON", "APPR"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.294": {"text": "Und wil durch H\u00f6flichkeit mit Davids Eyfer fech-", "tokens": ["Und", "wil", "durch", "H\u00f6f\u00b7lich\u00b7keit", "mit", "Da\u00b7vids", "Ey\u00b7fer", "fech"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "NN", "APPR", "NE", "NE", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.295": {"text": "Sie hoffet auf den Sieg/ ob schon Sie jung und", "tokens": ["Sie", "hof\u00b7fet", "auf", "den", "Sieg", "/", "ob", "schon", "Sie", "jung", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "KOUS", "ADV", "PPER", "ADJD", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.296": {"text": "Sie sinnt auf gute Wort und sch\u00f6ne Redens-", "tokens": ["Sie", "sinnt", "auf", "gu\u00b7te", "Wort", "und", "sch\u00f6\u00b7ne", "Re\u00b7den\u00b7s"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "KON", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "In dem Sie nun voll Furcht/ auf die\u00df und jenes", "tokens": ["In", "dem", "Sie", "nun", "voll", "Furcht", "/", "auf", "die\u00df", "und", "je\u00b7nes"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADJD", "NN", "$(", "APPR", "PDS", "KON", "PDS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.298": {"text": "Und sich zu einer Kr\u00fcmm\u2019 auf da\u00df Gebirge lenket/", "tokens": ["Und", "sich", "zu", "ei\u00b7ner", "Kr\u00fcmm'", "auf", "da\u00df", "Ge\u00b7bir\u00b7ge", "len\u00b7ket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "APPR", "KOUS", "NN", "VVFIN", "$("], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.299": {"text": "Erblikkt Sie Davids Heer/ und ihrer Waffen", "tokens": ["Er\u00b7blikkt", "Sie", "Da\u00b7vids", "Heer", "/", "und", "ih\u00b7rer", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NE", "NN", "$(", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.300": {"text": "Sie merkt an ihnen wol des Muhtes grimme", "tokens": ["Sie", "merkt", "an", "ih\u00b7nen", "wol", "des", "Muh\u00b7tes", "grim\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.301": {"text": "Sie springt von ihrem Thier\u2019 und geht dem Volk\u2019", "tokens": ["Sie", "springt", "von", "ih\u00b7rem", "Thier'", "und", "geht", "dem", "Vol\u00b7k'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.302": {"text": "Den David gr\u00fcsset Sie/ Sie w\u00fcnscht ihm Heyl", "tokens": ["Den", "Da\u00b7vid", "gr\u00fcs\u00b7set", "Sie", "/", "Sie", "w\u00fcnscht", "ihm", "Heyl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "PPER", "$(", "PPER", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.303": {"text": "Als Er nun samt dem Heer noch n\u00e4her k\u00f6mpt", "tokens": ["Als", "Er", "nun", "samt", "dem", "Heer", "noch", "n\u00e4\u00b7her", "k\u00f6mpt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.304": {"text": "F\u00e4llt Sie vor ihm zu Fu\u00df/ und f\u00e4ngt zu rede\u0303 an:", "tokens": ["F\u00e4llt", "Sie", "vor", "ihm", "zu", "Fu\u00df", "/", "und", "f\u00e4ngt", "zu", "re\u00b7d\u1ebd", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "APPR", "NN", "$(", "KON", "VVFIN", "APPR", "NE", "PTKVZ", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.305": {"text": "Genade gro\u00dfer F\u00fcrst! La\u00df deinen Zorn doch falle\u0303/", "tokens": ["Ge\u00b7na\u00b7de", "gro\u00b7\u00dfer", "F\u00fcrst", "!", "La\u00df", "dei\u00b7nen", "Zorn", "doch", "fall\u1ebd", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$.", "VVIMP", "PPOSAT", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "H\u00f6r meine Klagred\u2019 an/ und mein so schlechtes", "tokens": ["H\u00f6r", "mei\u00b7ne", "Kla\u00b7gred'", "an", "/", "und", "mein", "so", "schlech\u00b7tes"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PPOSAT", "NN", "PTKVZ", "$(", "KON", "PPOSAT", "ADV", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.307": {"text": "Wirf einen Gnadenblikk/ auf mich dein\u2019 arme", "tokens": ["Wirf", "ei\u00b7nen", "Gna\u00b7den\u00b7blikk", "/", "auf", "mich", "dein'", "ar\u00b7me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "$(", "APPR", "PPER", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.308": {"text": "Und auf mein Elend Volk das Angst und", "tokens": ["Und", "auf", "mein", "E\u00b7lend", "Volk", "das", "Angst", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "NN", "ART", "NN", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.309": {"text": "Ich h\u00f6r\u2019 und wei\u00df es wol da\u00df Schimpf/ Spott/", "tokens": ["Ich", "h\u00f6r'", "und", "wei\u00df", "es", "wol", "da\u00df", "Schimpf", "/", "Spott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "KOUS", "NN", "$(", "NN", "$("], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.310": {"text": "Den Deinen zugef\u00fcgt/ und deinem hohen Stan-", "tokens": ["Den", "Dei\u00b7nen", "zu\u00b7ge\u00b7f\u00fcgt", "/", "und", "dei\u00b7nem", "ho\u00b7hen", "Stan"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$(", "KON", "PPOSAT", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.311": {"text": "Ja ich bekenn es dir/ und kr\u00e4nkt mich in der", "tokens": ["Ja", "ich", "be\u00b7kenn", "es", "dir", "/", "und", "kr\u00e4nkt", "mich", "in", "der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "VVFIN", "PPER", "PPER", "$(", "KON", "VVFIN", "PRF", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.312": {"text": "Ich aber bin nicht schuld/ auch hab\u2019 ichs nicht", "tokens": ["Ich", "a\u00b7ber", "bin", "nicht", "schuld", "/", "auch", "hab'", "ichs", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "PTKNEG", "ADJD", "$(", "ADV", "VAFIN", "PIS", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.313": {"text": "Gleich hab\u2019 ich dazumal/ als dieser Fehl geschehe\u0303/", "tokens": ["Gleich", "hab'", "ich", "da\u00b7zu\u00b7mal", "/", "als", "die\u00b7ser", "Fehl", "ge\u00b7scheh\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$(", "KOUS", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Auf jener Sch\u00e4ferey nach meinem Vieh gesehen:", "tokens": ["Auf", "je\u00b7ner", "Sch\u00e4\u00b7fe\u00b7rey", "nach", "mei\u00b7nem", "Vieh", "ge\u00b7se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.315": {"text": "Mir hat ein trewer Knecht die\u00df ungeschikkte", "tokens": ["Mir", "hat", "ein", "tre\u00b7wer", "Knecht", "die\u00df", "un\u00b7ge\u00b7schikk\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PDS", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.316": {"text": "Mit Schrekken angezeigt/ da ich nach Hause", "tokens": ["Mit", "Schrek\u00b7ken", "an\u00b7ge\u00b7zeigt", "/", "da", "ich", "nach", "Hau\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$(", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.317": {"text": "Ich trag ein gro\u00dfes Leid so mich tag-t\u00e4glich pla-", "tokens": ["Ich", "trag", "ein", "gro\u00b7\u00dfes", "Leid", "so", "mich", "tag\u00b7t\u00e4g\u00b7lich", "pla"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV", "PPER", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.318": {"text": "Mein Hau\u00dfkreutz ist so gro\u00df/ da\u00df es mich st\u00fcndlich", "tokens": ["Mein", "Hau\u00df\u00b7kreutz", "ist", "so", "gro\u00df", "/", "da\u00df", "es", "mich", "st\u00fcnd\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$(", "KOUS", "PPER", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.319": {"text": "Mein Ehmann ist ein R\u00f6lps/ ein grober Sauer-", "tokens": ["Mein", "Eh\u00b7mann", "ist", "ein", "R\u00f6lps", "/", "ein", "gro\u00b7ber", "Sau\u00b7e\u00b7r"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$(", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.320": {"text": "Ein unbedachtsam Holtz/ und gro\u00dfer Narren-", "tokens": ["Ein", "un\u00b7be\u00b7dacht\u00b7sam", "Holtz", "/", "und", "gro\u00b7\u00dfer", "Nar\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "$(", "KON", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.321": {"text": "Sein Name bringt es mit/ Er wei\u00df von keinem", "tokens": ["Sein", "Na\u00b7me", "bringt", "es", "mit", "/", "Er", "wei\u00df", "von", "kei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "$(", "PPER", "VVFIN", "APPR", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.322": {"text": "Es f\u00fchlt sein\u2019 Eselsstirn gar keine Weisheits", "tokens": ["Es", "f\u00fchlt", "sein'", "E\u00b7selss\u00b7tirn", "gar", "kei\u00b7ne", "Weis\u00b7heits"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.323": {"text": "Es wei\u00df sein T\u00f6lpelskopf von keiner Klugheit", "tokens": ["Es", "wei\u00df", "sein", "T\u00f6l\u00b7pels\u00b7kopf", "von", "kei\u00b7ner", "Klug\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.324": {"text": "Ist blo\u00df und nur allein auf Geitzen abgericht.", "tokens": ["Ist", "blo\u00df", "und", "nur", "al\u00b7lein", "auf", "Geit\u00b7zen", "ab\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KON", "ADV", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.325": {"text": "Erst hab ich seinen Sinn nicht allerdings erwo-", "tokens": ["Erst", "hab", "ich", "sei\u00b7nen", "Sinn", "nicht", "al\u00b7ler\u00b7dings", "er\u00b7wo"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.326": {"text": "Ich bin in meiner ", "tokens": ["Ich", "bin", "in", "mei\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.327": {"text": "An Reich thum f\u00e4hlt ihm nichts/ auch nichts", "tokens": ["An", "Reich", "thum", "f\u00e4hlt", "ihm", "nichts", "/", "auch", "nichts"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "NN", "VVFIN", "PPER", "PIS", "$(", "ADV", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.328": {"text": "Das Gut ist gro\u00df; Doch hat die Thorheit O-", "tokens": ["Das", "Gut", "ist", "gro\u00df", ";", "Doch", "hat", "die", "Thor\u00b7heit", "O"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "KON", "VAFIN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.329": {"text": "Er achtet meiner nicht/ h\u00e4lt mehr von Katz- und", "tokens": ["Er", "ach\u00b7tet", "mei\u00b7ner", "nicht", "/", "h\u00e4lt", "mehr", "von", "Katz", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "PTKNEG", "$(", "VVFIN", "ADV", "APPR", "TRUNC", "KON"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.330": {"text": "Als auf ein keusches Weib/ Ich bin an Jhn ge-", "tokens": ["Als", "auf", "ein", "keu\u00b7sches", "Weib", "/", "Ich", "bin", "an", "Jhn", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$(", "PPER", "VAFIN", "APPR", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.331": {"text": "Und mu\u00df zu frieden seyn/ Er lieget wie ein", "tokens": ["Und", "mu\u00df", "zu", "frie\u00b7den", "seyn", "/", "Er", "lie\u00b7get", "wie", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "NN", "VAINF", "$(", "PPER", "VVFIN", "KOKOM", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.332": {"text": "Denkt nicht an seine Pflicht/ und beut mir Hohn", "tokens": ["Denkt", "nicht", "an", "sei\u00b7ne", "Pflicht", "/", "und", "beut", "mir", "Hohn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.333": {"text": "Des Morgens schl\u00e4ft Er lang/ da mu\u00df ich auf jhn", "tokens": ["Des", "Mor\u00b7gens", "schl\u00e4ft", "Er", "lang", "/", "da", "mu\u00df", "ich", "auf", "jhn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "PPER", "ADJD", "$(", "ADV", "VMFIN", "PPER", "APPR", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.334": {"text": "Steht Er denn aus dem Bett so f\u00e4ngt Er an zu", "tokens": ["Steht", "Er", "denn", "aus", "dem", "Bett", "so", "f\u00e4ngt", "Er", "an", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "ADV", "VVFIN", "PPER", "APPR", "APPR"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.335": {"text": "Und ist ihm nichtes recht/ drauf s\u00e4uft Er Bier", "tokens": ["Und", "ist", "ihm", "nich\u00b7tes", "recht", "/", "drauf", "s\u00e4uft", "Er", "Bier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PIS", "ADJD", "$(", "PAV", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.336": {"text": "Frist seinen Wanst dikk voll/ und lebet wie ein", "tokens": ["Frist", "sei\u00b7nen", "Wanst", "dikk", "voll", "/", "und", "le\u00b7bet", "wie", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "NE", "ADJD", "$(", "KON", "VVFIN", "KOKOM", "ART"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.337": {"text": "Redt ihn denn jemaud an/ und wil was an Jhn", "tokens": ["Redt", "ihn", "denn", "je\u00b7maud", "an", "/", "und", "wil", "was", "an", "Jhn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PIS", "PTKVZ", "$(", "KON", "VMFIN", "PIS", "APPR", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.338": {"text": "So schnautzt Er wie ein Beer/ und h\u00f6rt von kei-", "tokens": ["So", "schnautzt", "Er", "wie", "ein", "Beer", "/", "und", "h\u00f6rt", "von", "kei"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$(", "KON", "VVFIN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.339": {"text": "Die Er oft h\u00f6ren solt\u2019/ Er steht und h\u00f6ret zwar/", "tokens": ["Die", "Er", "oft", "h\u00f6\u00b7ren", "solt'", "/", "Er", "steht", "und", "h\u00f6\u00b7ret", "zwar", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VMFIN", "$(", "PPER", "VVFIN", "KON", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.340": {"text": "Begreiffet aber nichts/ worvon die Rede war.", "tokens": ["Be\u00b7greif\u00b7fet", "a\u00b7ber", "nichts", "/", "wor\u00b7von", "die", "Re\u00b7de", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "$(", "PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.341": {"text": "Sagt dieser etwas Guts/ und meinet es zum be-", "tokens": ["Sagt", "die\u00b7ser", "et\u00b7was", "Guts", "/", "und", "mei\u00b7net", "es", "zum", "be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "PIAT", "NN", "$(", "KON", "VVFIN", "PPER", "APPRART", "TRUNC"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.342": {"text": "So giebt Er Antwort drauf/ dort aus dem feuch-", "tokens": ["So", "giebt", "Er", "Ant\u00b7wort", "drauf", "/", "dort", "aus", "dem", "feuch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$(", "ADV", "APPR", "ART", "TRUNC"], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.343": {"text": "Und solt\u2019 aus Osten seyn/ wenn Er ein wenig", "tokens": ["Und", "solt'", "aus", "Os\u00b7ten", "seyn", "/", "wenn", "Er", "ein", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "NN", "VAINF", "$(", "KOUS", "PPER", "ART", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.344": {"text": "Da\u00df man ihm etwas sagt/ das seinen Nutzen", "tokens": ["Da\u00df", "man", "ihm", "et\u00b7was", "sagt", "/", "das", "sei\u00b7nen", "Nut\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "ADV", "VVFIN", "$(", "ART", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.345": {"text": " so billt Er/ wie der Hund der auf dem Grum-\nmet lieget/", "tokens": ["so", "billt", "Er", "/", "wie", "der", "Hund", "der", "auf", "dem", "Grum", "met", "lie\u00b7get", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOKOM", "ART", "NN", "ART", "APPR", "ART", "TRUNC", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.346": {"text": "Den jenes Schaf/ welchs doch mit Weni em", "tokens": ["Den", "je\u00b7nes", "Schaf", "/", "welchs", "doch", "mit", "We\u00b7ni", "em"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PDAT", "NN", "$(", "PWS", "ADV", "APPR", "NE", "XY"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.347": {"text": "Um etwas Futter bat; Und so ists auch bewandt/", "tokens": ["Um", "et\u00b7was", "Fut\u00b7ter", "bat", ";", "Und", "so", "ists", "auch", "be\u00b7wandt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "VVFIN", "$.", "KON", "ADV", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.348": {"text": "Mit dene\u0303 die du hast/ O Printz/ zu ihm gesandt.", "tokens": ["Mit", "den\u1ebd", "die", "du", "hast", "/", "O", "Printz", "/", "zu", "ihm", "ge\u00b7sandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "PPER", "VAFIN", "$(", "NE", "NN", "$(", "APPR", "PPER", "VVPP", "$."], "meter": "----+-+-+-+", "measure": "unknown.measure.tetra"}, "line.349": {"text": "Dar\u00fcm la\u00df deinen Zorn/ O \u00e4dler F\u00fcrst/ sich stillen/", "tokens": ["Da\u00b7r\u00fcm", "la\u00df", "dei\u00b7nen", "Zorn", "/", "O", "\u00e4d\u00b7ler", "F\u00fcrst", "/", "sich", "stil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "$(", "NE", "ADJA", "NN", "$(", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.350": {"text": "Wo nicht \u00fcm meines Manns/ doch nur \u00fcm un-", "tokens": ["Wo", "nicht", "\u00fcm", "mei\u00b7nes", "Manns", "/", "doch", "nur", "\u00fcm", "un"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PTKNEG", "ADV", "PPOSAT", "NN", "$(", "ADV", "ADV", "APPRART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.351": {"text": "Wir k\u00f6nnen nichts darzu und haben keine", "tokens": ["Wir", "k\u00f6n\u00b7nen", "nichts", "dar\u00b7zu", "und", "ha\u00b7ben", "kei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIS", "PAV", "KON", "VAFIN", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.352": {"text": "Trag Nabals albre Red\u2019 und Thorheit mit Ge-", "tokens": ["Trag", "Na\u00b7bals", "alb\u00b7re", "Red'", "und", "Thor\u00b7heit", "mit", "Ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "NE", "NN", "KON", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.353": {"text": "Und schone deiner Magd/ wir sind nur schwache", "tokens": ["Und", "scho\u00b7ne", "dei\u00b7ner", "Magd", "/", "wir", "sind", "nur", "schwa\u00b7che"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$(", "PPER", "VAFIN", "ADV", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.354": {"text": "Du findest zwar bey uns ein ziemliches/ an beute/", "tokens": ["Du", "fin\u00b7dest", "zwar", "bey", "uns", "ein", "ziem\u00b7li\u00b7ches", "/", "an", "beu\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "ART", "ADJA", "$(", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.355": {"text": "Es ist ja ohne das/ mein Vorraht und mein Gut", "tokens": ["Es", "ist", "ja", "oh\u00b7ne", "das", "/", "mein", "Vor\u00b7raht", "und", "mein", "Gut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "$(", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.356": {"text": "Dein eigen/ schone nur das unverschuldte Blut.", "tokens": ["Dein", "ei\u00b7gen", "/", "scho\u00b7ne", "nur", "das", "un\u00b7ver\u00b7schuld\u00b7te", "Blut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.357": {"text": "Es sucht kein starker Leu ein L\u00e4mchen zubesie-", "tokens": ["Es", "sucht", "kein", "star\u00b7ker", "Leu", "ein", "L\u00e4m\u00b7chen", "zu\u00b7be\u00b7sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.358": {"text": "Kein Adler wird erz\u00fcrnt von einer matten Flie-", "tokens": ["Kein", "Ad\u00b7ler", "wird", "er\u00b7z\u00fcrnt", "von", "ei\u00b7ner", "mat\u00b7ten", "Flie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.359": {"text": "Ein tapfrer Kriegesmann und unerschrokkner", "tokens": ["Ein", "tapf\u00b7rer", "Krie\u00b7ges\u00b7mann", "und", "un\u00b7er\u00b7schrok\u00b7kner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.360": {"text": "Sucht seinen gro\u00dfen Feind in offenbarem Feld\u2019.", "tokens": ["Sucht", "sei\u00b7nen", "gro\u00b7\u00dfen", "Feind", "in", "of\u00b7fen\u00b7ba\u00b7rem", "Feld'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.361": {"text": "Zu einer Narrenred\u2019 und Thorheit stilleschwei-", "tokens": ["Zu", "ei\u00b7ner", "Nar\u00b7ren\u00b7red'", "und", "Thor\u00b7heit", "stil\u00b7le\u00b7schwei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.362": {"text": "Steht weisen M\u00e4nnern zu/ und solches ist ihr ei-", "tokens": ["Steht", "wei\u00b7sen", "M\u00e4n\u00b7nern", "zu", "/", "und", "sol\u00b7ches", "ist", "ihr", "ei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJA", "NN", "PTKZU", "$(", "KON", "PIS", "VAFIN", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.363": {"text": "Dr\u00fcm wirf ein gn\u00e4digs Aug\u2019 auf unsern Maon", "tokens": ["Dr\u00fcm", "wirf", "ein", "gn\u00e4\u00b7digs", "Aug'", "auf", "un\u00b7sern", "Maon"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.364": {"text": "Und \u00fcbe nicht an uns solch einen grimmen", "tokens": ["Und", "\u00fc\u00b7be", "nicht", "an", "uns", "solch", "ei\u00b7nen", "grim\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "APPR", "PPER", "PIAT", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.365": {"text": "Du bist ja schon gesalbt und wirst in kurtzen Tagen/", "tokens": ["Du", "bist", "ja", "schon", "ge\u00b7salbt", "und", "wirst", "in", "kurt\u00b7zen", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "KON", "VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.366": {"text": "Die Kron in Jsrael auf deinem Haupte tragen.", "tokens": ["Die", "Kron", "in", "Js\u00b7rael", "auf", "dei\u00b7nem", "Haup\u00b7te", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.367": {"text": "La\u00df dein so heiligs Amt? und deines Zepters", "tokens": ["La\u00df", "dein", "so", "hei\u00b7ligs", "Amt", "?", "und", "dei\u00b7nes", "Zep\u00b7ters"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "ADV", "ADJA", "NN", "$.", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.368": {"text": "Mit meiner Knechten Blut nicht angeschmitzet", "tokens": ["Mit", "mei\u00b7ner", "Knech\u00b7ten", "Blut", "nicht", "an\u00b7ge\u00b7schmit\u00b7zet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "PTKNEG", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.369": {"text": "Lesch den erhitzten Sinn/ das wird ein friedsam", "tokens": ["Lesch", "den", "er\u00b7hitz\u00b7ten", "Sinn", "/", "das", "wird", "ein", "fried\u00b7sam"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "$(", "PDS", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.370": {"text": "Und deinem hohen Geist\u2019 ein gro\u00df Vergn\u00fcgen ge-", "tokens": ["Und", "dei\u00b7nem", "ho\u00b7hen", "Geist'", "ein", "gro\u00df", "Ver\u00b7gn\u00fc\u00b7gen", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ART", "ADJD", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.371": {"text": "Bewahre/ tapfrer Printz/ vom Todschlag dei-", "tokens": ["Be\u00b7wah\u00b7re", "/", "tapf\u00b7rer", "Printz", "/", "vom", "Tod\u00b7schlag", "dei"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$(", "ADJA", "NN", "$(", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.372": {"text": "Bedenk wol vnd erweg den Koniglichen Stand.", "tokens": ["Be\u00b7denk", "wol", "vnd", "er\u00b7weg", "den", "Ko\u00b7nig\u00b7li\u00b7chen", "Stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.373": {"text": "Der dich in kurtzer Zeit/ ich wei\u00df es schon/ wird", "tokens": ["Der", "dich", "in", "kurt\u00b7zer", "Zeit", "/", "ich", "wei\u00df", "es", "schon", "/", "wird"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$(", "VAFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.374": {"text": "Wenn du des H", "tokens": ["Wenn", "du", "des", "H"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "XY"], "meter": "-+-+", "measure": "iambic.di"}, "line.375": {"text": "Das ist ein herrlich Lob/ und heber Himmel", "tokens": ["Das", "ist", "ein", "herr\u00b7lich", "Lob", "/", "und", "he\u00b7ber", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "NN", "$(", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.376": {"text": "Jm Fall ein\u2019 Obrikeit nichts m\u00f6rdlichs hat ge-", "tokens": ["Jm", "Fall", "ein'", "Ob\u00b7ri\u00b7keit", "nichts", "m\u00f6rd\u00b7lichs", "hat", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "PIS", "PIS", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.377": {"text": "Des K\u00f6nigliche Schwert soll nur die Laster", "tokens": ["Des", "K\u00f6\u00b7nig\u00b7li\u00b7che", "Schwert", "soll", "nur", "die", "Las\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.378": {"text": "Und nicht mit mattem Volk\u2019 und armen Leuten", "tokens": ["Und", "nicht", "mit", "mat\u00b7tem", "Vol\u00b7k'", "und", "ar\u00b7men", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.379": {"text": "Barmhertzigkeit und Glimpf begl\u00e4ntzt die F\u00fcr-", "tokens": ["Barm\u00b7hert\u00b7zig\u00b7keit", "und", "Glimpf", "be\u00b7gl\u00e4ntzt", "die", "F\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.380": {"text": "Die Tugend ziehrt allein den Majest\u00e4tschen", "tokens": ["Die", "Tu\u00b7gend", "ziehrt", "al\u00b7lein", "den", "Ma\u00b7jes\u00b7t\u00e4t\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.381": {"text": "Es ist ein gro\u00dfes Werk wer sonder Schuld regieret", "tokens": ["Es", "ist", "ein", "gro\u00b7\u00dfes", "Werk", "wer", "son\u00b7der", "Schuld", "re\u00b7gie\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PWS", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.382": {"text": "Und hier an Gottes stat/ das Regiment verf\u00fchret.", "tokens": ["Und", "hier", "an", "Got\u00b7tes", "stat", "/", "das", "Re\u00b7gi\u00b7ment", "ver\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "$(", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.383": {"text": "Wer nicht/ wie ein Tyrann/ unschuldig Blut", "tokens": ["Wer", "nicht", "/", "wie", "ein", "Ty\u00b7rann", "/", "un\u00b7schul\u00b7dig", "Blut"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PTKNEG", "$(", "KOKOM", "ART", "NN", "$(", "ADJD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.384": {"text": "Und folgt nicht wo sein Trotz und Bo\u00dfheit ihn", "tokens": ["Und", "folgt", "nicht", "wo", "sein", "Trotz", "und", "Bo\u00df\u00b7heit", "ihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "PWAV", "PPOSAT", "NN", "KON", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.385": {"text": "Die\u00df weist du alles wol dr\u00fcm wollest du verschone\u0303/", "tokens": ["Die\u00df", "weist", "du", "al\u00b7les", "wol", "dr\u00fcm", "wol\u00b7lest", "du", "ver\u00b7schon\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIS", "ADV", "PAV", "VMFIN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.386": {"text": "Und Nabals Missethat so schrekklich nicht beloh-", "tokens": ["Und", "Na\u00b7bals", "Mis\u00b7se\u00b7that", "so", "schrek\u00b7klich", "nicht", "be\u00b7loh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "NN", "ADV", "ADJD", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.387": {"text": "Hat einer grob gefehlt/ so straf nicht allesamt.", "tokens": ["Hat", "ei\u00b7ner", "grob", "ge\u00b7fehlt", "/", "so", "straf", "nicht", "al\u00b7le\u00b7samt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJD", "VVPP", "$(", "ADV", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.388": {"text": "Zur Zeit sanftm\u00fchtig seyn ist eines F\u00fcrsten", "tokens": ["Zur", "Zeit", "sanft\u00b7m\u00fch\u00b7tig", "seyn", "ist", "ei\u00b7nes", "F\u00fcrs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "VAINF", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.389": {"text": " du hast den Goliath durch Gottes Kraft be-\nzwungen/", "tokens": ["du", "hast", "den", "Go\u00b7li\u00b7ath", "durch", "Got\u00b7tes", "Kraft", "be", "zwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "NN", "TRUNC", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.390": {"text": "Dar\u00fcm wir dir unl\u00e4ngst ein Siegeslied gesun-", "tokens": ["Da\u00b7r\u00fcm", "wir", "dir", "un\u00b7l\u00e4ngst", "ein", "Sie\u00b7ges\u00b7lied", "ge\u00b7sun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "PPER", "ADV", "ART", "NN", "TRUNC"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.391": {"text": "Wolan! so sey denn auch dein eigner Obermann.", "tokens": ["Wo\u00b7lan", "!", "so", "sey", "denn", "auch", "dein", "eig\u00b7ner", "O\u00b7ber\u00b7mann", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VAFIN", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.392": {"text": "Der ist der st\u00e4rkste Held der sich selbst zwingen", "tokens": ["Der", "ist", "der", "st\u00e4rks\u00b7te", "Held", "der", "sich", "selbst", "zwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "ART", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.393": {"text": "Schau hier/ O theurer F\u00fcrst/ die wolgememten", "tokens": ["Schau", "hier", "/", "O", "theu\u00b7rer", "F\u00fcrst", "/", "die", "wol\u00b7ge\u00b7mem\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADV", "$(", "NE", "ADJA", "NN", "$(", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.394": {"text": "So deine Knecht\u2019 und Magd\u2019 anher getrieben ha-", "tokens": ["So", "dei\u00b7ne", "Knecht'", "und", "Magd'", "an\u00b7her", "ge\u00b7trie\u00b7ben", "ha"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "KON", "NN", "ADV", "VVPP", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.395": {"text": "Es ist zwar sehr gering/ doch mein\u2019 ichs hertz-", "tokens": ["Es", "ist", "zwar", "sehr", "ge\u00b7ring", "/", "doch", "mein'", "ichs", "hertz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$(", "ADV", "VVFIN", "PIS", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.396": {"text": "Ich bitte nim es an/ mit Gnad\u2019-erf\u00fclltem", "tokens": ["Ich", "bit\u00b7te", "nim", "es", "an", "/", "mit", "Gna\u00b7d'\u00b7er\u00b7f\u00fcll\u00b7tem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "PTKVZ", "$(", "APPR", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.397": {"text": "Nim mit Genad\u2019 und Gunst/ so wird Gott deine", "tokens": ["Nim", "mit", "Ge\u00b7nad'", "und", "Gunst", "/", "so", "wird", "Gott", "dei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "APPR", "NN", "KON", "NN", "$(", "ADV", "VAFIN", "NN", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.398": {"text": "Dein hohes K\u00f6nigreich fest und best\u00e4ndig machen/", "tokens": ["Dein", "ho\u00b7hes", "K\u00f6\u00b7nig\u00b7reich", "fest", "und", "be\u00b7st\u00e4n\u00b7dig", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.399": {"text": "Ich wei\u00df da\u00df dich/ mein Herr/ kein loser Vor-", "tokens": ["Ich", "wei\u00df", "da\u00df", "dich", "/", "mein", "Herr", "/", "kein", "lo\u00b7ser", "Vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "$(", "PPOSAT", "NN", "$(", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.400": {"text": "Es ist des H", "tokens": ["Es", "ist", "des", "H"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "XY"], "meter": "-+-+", "measure": "iambic.di"}, "line.401": {"text": "La\u00df ander leichtes Volk Mord/ Raub/ und Fre-", "tokens": ["La\u00df", "an\u00b7der", "leich\u00b7tes", "Volk", "Mord", "/", "Raub", "/", "und", "Fre"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVIMP", "ADJD", "ADJA", "NN", "NN", "$(", "NN", "$(", "KON", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.402": {"text": "Mit feindlicher Gewalt das gantze Land betr\u00fc-", "tokens": ["Mit", "feind\u00b7li\u00b7cher", "Ge\u00b7walt", "das", "gant\u00b7ze", "Land", "be\u00b7tr\u00fc"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.403": {"text": "Du und dein gantzes Heer/ seyd ja von solchem", "tokens": ["Du", "und", "dein", "gant\u00b7zes", "Heer", "/", "seyd", "ja", "von", "sol\u00b7chem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "KON", "PPOSAT", "ADJA", "NN", "$(", "VAFIN", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.404": {"text": "Da\u00df ihr die Hand nicht legt an andrer Leute", "tokens": ["Da\u00df", "ihr", "die", "Hand", "nicht", "legt", "an", "an\u00b7drer", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.405": {"text": "Ob du schon wirst gehasst/ und must Verfolgung", "tokens": ["Ob", "du", "schon", "wirst", "ge\u00b7hasst", "/", "und", "must", "Ver\u00b7fol\u00b7gung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$(", "KON", "VMFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.406": {"text": "Ob mit vergiftem Sinn\u2019 auch viele dich beneiden/", "tokens": ["Ob", "mit", "ver\u00b7gif\u00b7tem", "Sinn'", "auch", "vie\u00b7le", "dich", "be\u00b7nei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "ADV", "PIS", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.407": {"text": "So acht es alles nicht/ Gott hat schon seine", "tokens": ["So", "acht", "es", "al\u00b7les", "nicht", "/", "Gott", "hat", "schon", "sei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "PPER", "PIS", "PTKNEG", "$(", "NN", "VAFIN", "ADV", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.408": {"text": "Auf dich und auf dein Heer/ mit starken Schutz", "tokens": ["Auf", "dich", "und", "auf", "dein", "Heer", "/", "mit", "star\u00b7ken", "Schutz"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "KON", "APPR", "PPOSAT", "NN", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.409": {"text": "Die aber dir zum Leid\u2019 auf Ungl\u00fckksr\u00e4nke den-", "tokens": ["Die", "a\u00b7ber", "dir", "zum", "Leid'", "auf", "Un\u00b7gl\u00fckks\u00b7r\u00e4n\u00b7ke", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PPER", "APPRART", "NN", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.410": {"text": "Und suchen hie und da dich und dein Hau\u00df zu kr\u00e4n-", "tokens": ["Und", "su\u00b7chen", "hie", "und", "da", "dich", "und", "dein", "Hau\u00df", "zu", "kr\u00e4n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "KON", "KOUS", "PPER", "KON", "PPOSAT", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.411": {"text": "Die sollen voller Angst vor dir gar nicht bestehn/", "tokens": ["Die", "sol\u00b7len", "vol\u00b7ler", "Angst", "vor", "dir", "gar", "nicht", "be\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "APPR", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.412": {"text": "Mit Schrekken sollen sie zu Grund und Boden", "tokens": ["Mit", "Schrek\u00b7ken", "sol\u00b7len", "sie", "zu", "Grund", "und", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VMFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.413": {"text": "Ein b\u00f6ser Raht trifft oft den/ der ihn selbst erson-", "tokens": ["Ein", "b\u00f6\u00b7ser", "Raht", "trifft", "oft", "den", "/", "der", "ihn", "selbst", "er\u00b7son"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "$(", "PRELS", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.414": {"text": "Und hat gemeiniglich ein schlechtes Ziel gewon-", "tokens": ["Und", "hat", "ge\u00b7mei\u00b7nig\u00b7lich", "ein", "schlech\u00b7tes", "Ziel", "ge\u00b7won"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ART", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.415": {"text": "Wer Anderen zu\u0303 Fall ein Loch un\u0303 Grube macht/", "tokens": ["Wer", "An\u00b7de\u00b7ren", "z\u0169", "Fall", "ein", "Loch", "u\u00f1", "Gru\u00b7be", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "ADJA", "NN", "ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.416": {"text": "F\u00e4lt oftmals selber drein/ ob schon Ers nicht", "tokens": ["F\u00e4lt", "oft\u00b7mals", "sel\u00b7ber", "drein", "/", "ob", "schon", "Ers", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "PTKVZ", "$(", "KOUS", "ADV", "NN", "PTKNEG"], "meter": "-+-+-+-++-", "measure": "unknown.measure.penta"}, "line.417": {"text": "es haben zwar die Feind im Sinne/ dich zu schla-\ngen/", "tokens": ["es", "ha\u00b7ben", "zwar", "die", "Feind", "im", "Sin\u00b7ne", "/", "dich", "zu", "schla", "gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "$(", "PPER", "APPR", "TRUNC", "APPR", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.418": {"text": "Dich und dein treues Volk aus Jsrael zu jagen/", "tokens": ["Dich", "und", "dein", "treu\u00b7es", "Volk", "aus", "Js\u00b7rael", "zu", "ja\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "ADJA", "NN", "APPR", "NE", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.419": {"text": "Du aber wirst mit Lust erfahren mit der Zeit/", "tokens": ["Du", "a\u00b7ber", "wirst", "mit", "Lust", "er\u00b7fah\u00b7ren", "mit", "der", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "APPR", "NN", "VVINF", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.420": {"text": "Wie GOtt sie st\u00fcrtzen wird in ihrer Sicherheit.", "tokens": ["Wie", "Gott", "sie", "st\u00fcrt\u00b7zen", "wird", "in", "ih\u00b7rer", "Si\u00b7cher\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "VVINF", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.421": {"text": "Wenn nun des Feindes Macht wird endlich seyn", "tokens": ["Wenn", "nun", "des", "Fein\u00b7des", "Macht", "wird", "end\u00b7lich", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "VAFIN", "ADV", "VAINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.422": {"text": "So wird Gott alles thun was Er dir hat verspro-", "tokens": ["So", "wird", "Gott", "al\u00b7les", "thun", "was", "Er", "dir", "hat", "ver\u00b7spro"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "PIS", "VVINF", "PWS", "PPER", "PPER", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.423": {"text": "Dann wird dein K\u00f6nigreich auf festem Fu\u00dfe", "tokens": ["Dann", "wird", "dein", "K\u00f6\u00b7nig\u00b7reich", "auf", "fes\u00b7tem", "Fu\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.424": {"text": "Und deines Namens Lob bi\u00df an die Sternen", "tokens": ["Und", "dei\u00b7nes", "Na\u00b7mens", "Lob", "bi\u00df", "an", "die", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.425": {"text": "Denn wird dein ruhig Hertz an lauter Freude", "tokens": ["Denn", "wird", "dein", "ru\u00b7hig", "Hertz", "an", "lau\u00b7ter", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJD", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.426": {"text": "Da\u00df diese grimme That nicht wirklich vorgegan-", "tokens": ["Da\u00df", "die\u00b7se", "grim\u00b7me", "That", "nicht", "wirk\u00b7lich", "vor\u00b7ge\u00b7gan"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "PTKNEG", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.427": {"text": "Es wird dir seyn ein Trost/ und grosse Seelen-", "tokens": ["Es", "wird", "dir", "seyn", "ein", "Trost", "/", "und", "gros\u00b7se", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "ART", "NN", "$(", "KON", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.428": {"text": "Da\u00df du in diesem Zorn kein Blut vergossen", "tokens": ["Da\u00df", "du", "in", "die\u00b7sem", "Zorn", "kein", "Blut", "ver\u00b7gos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.429": {"text": "Ich wei\u00df du wirst hernach de\u00dfwegen Gott noch", "tokens": ["Ich", "wei\u00df", "du", "wirst", "her\u00b7nach", "de\u00df\u00b7we\u00b7gen", "Gott", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "ADV", "PAV", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.430": {"text": "Und mit erfreutem Geist Jhm Ehr\u2019 und Danck", "tokens": ["Und", "mit", "er\u00b7freu\u00b7tem", "Geist", "Jhm", "Ehr'", "und", "Danck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.431": {"text": "Denk dran da\u00df dirs gesagt dein arm\u2019 Abigail.", "tokens": ["Denk", "dran", "da\u00df", "dirs", "ge\u00b7sagt", "dein", "arm'", "A\u00b7bi\u00b7gail", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PAV", "KOUS", "PIS", "VVPP", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.432": {"text": "Hiermit schlo\u00df sie die Red\u2019 und schwiege seuf-", "tokens": ["Hier\u00b7mit", "schlo\u00df", "sie", "die", "Red'", "und", "schwie\u00b7ge", "seuf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "KON", "ADJA", "TRUNC"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.433": {"text": "Was solte David thun? Er lie\u00df die G\u00fcte wal-", "tokens": ["Was", "sol\u00b7te", "Da\u00b7vid", "thun", "?", "Er", "lie\u00df", "die", "G\u00fc\u00b7te", "wa\u00b7l"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "NE", "VVINF", "$.", "PPER", "VVFIN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.434": {"text": "Der Mordsinn legte sich/ es sieng an zu erkalten", "tokens": ["Der", "Mord\u00b7sinn", "leg\u00b7te", "sich", "/", "es", "sieng", "an", "zu", "er\u00b7kal\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "$(", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.435": {"text": "Der zorn erhitzte Muht/ der Eyfer war gethan/", "tokens": ["Der", "zorn", "er\u00b7hitz\u00b7te", "Muht", "/", "der", "Ey\u00b7fer", "war", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.436": {"text": "Die Sanftmnht brach hervor/ vnd fieng zu sie-", "tokens": ["Die", "Sanftmnht", "brach", "her\u00b7vor", "/", "vnd", "fi\u00b7eng", "zu", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "KON", "VVFIN", "APPR", "TRUNC"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.437": {"text": "Er warf ein Aug\u2019 auf Sie/ stieg bald von seinem", "tokens": ["Er", "warf", "ein", "Aug'", "auf", "Sie", "/", "stieg", "bald", "von", "sei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "$(", "VVFIN", "ADV", "APPR", "PPOSAT"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.438": {"text": "Er grief Sie bey der Hand/ und hub sie von der", "tokens": ["Er", "grief", "Sie", "bey", "der", "Hand", "/", "und", "hub", "sie", "von", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KON", "VVFIN", "PPER", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.439": {"text": "Auf der Sie kniehend lag/ versprach ihr Fried\u2019", "tokens": ["Auf", "der", "Sie", "knie\u00b7hend", "lag", "/", "ver\u00b7sprach", "ihr", "Fried'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$(", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.440": {"text": "Die noch in Furchten war/ vnd redt ihr also zu:", "tokens": ["Die", "noch", "in", "Furch\u00b7ten", "war", "/", "vnd", "redt", "ihr", "al\u00b7so", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VAFIN", "$(", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.441": {"text": "Wolan Abigail! Das Unglukk ist gewendet/", "tokens": ["Wo\u00b7lan", "A\u00b7bi\u00b7gail", "!", "Das", "Un\u00b7glukk", "ist", "ge\u00b7wen\u00b7det", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$.", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.442": {"text": "Gott sey Lob/ Ehr\u2019 und Prei\u00df da\u00df Er dich herge-", "tokens": ["Gott", "sey", "Lob", "/", "Ehr'", "und", "Prei\u00df", "da\u00df", "Er", "dich", "her\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "NN", "$(", "NN", "KON", "NN", "KOUS", "PPER", "PRF", "TRUNC"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.443": {"text": "Das Blutbad ist gehemmt/ das vor der Th\u00fcr", "tokens": ["Das", "Blut\u00b7bad", "ist", "ge\u00b7hemmt", "/", "das", "vor", "der", "Th\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "PDS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.444": {"text": "Dem H\u00f6chsten sey gedankt der ewig ewig lebt.", "tokens": ["Dem", "H\u00f6chs\u00b7ten", "sey", "ge\u00b7dankt", "der", "e\u00b7wig", "e\u00b7wig", "lebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ART", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.445": {"text": "Gesegnet sey das Wort/ dz du hast aus gesprochen/", "tokens": ["Ge\u00b7seg\u00b7net", "sey", "das", "Wort", "/", "dz", "du", "hast", "aus", "ge\u00b7spro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$(", "KOUS", "PPER", "VAFIN", "APPR", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.446": {"text": "Das meinen Vorsatz hat zu rechter Zeit gebroche\u0303/", "tokens": ["Das", "mei\u00b7nen", "Vor\u00b7satz", "hat", "zu", "rech\u00b7ter", "Zeit", "ge\u00b7bro\u00b7ch\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.447": {"text": "Gesegnet seyst du selbst/ da\u00df du hast abgewandt/", "tokens": ["Ge\u00b7seg\u00b7net", "seyst", "du", "selbst", "/", "da\u00df", "du", "hast", "ab\u00b7ge\u00b7wandt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.448": {"text": "Das nicht mit Menschenblut bespr\u00fctzet meine", "tokens": ["Das", "nicht", "mit", "Men\u00b7schen\u00b7blut", "be\u00b7spr\u00fct\u00b7zet", "mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PTKNEG", "APPR", "NN", "VVFIN", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.449": {"text": "Glaub sicherlich/ wenn du nicht werst darzwi-", "tokens": ["Glaub", "si\u00b7cher\u00b7lich", "/", "wenn", "du", "nicht", "werst", "dar\u00b7zwi"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "$(", "KOUS", "PPER", "PTKNEG", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.450": {"text": "Dem Nabal hett\u2019 ich selbst das Leben abgenom-", "tokens": ["Dem", "Na\u00b7bal", "hett'", "ich", "selbst", "das", "Le\u00b7ben", "ab\u00b7ge\u00b7nom"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VAFIN", "PPER", "ADV", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.451": {"text": "Ich hette deinen Mann/ den groben Nimmer", "tokens": ["Ich", "het\u00b7te", "dei\u00b7nen", "Mann", "/", "den", "gro\u00b7ben", "Nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.452": {"text": "Der mich und dieses Heer/ so hoch beschimpfet", "tokens": ["Der", "mich", "und", "die\u00b7ses", "Heer", "/", "so", "hoch", "be\u00b7schimp\u00b7fet"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "KON", "PDAT", "NN", "$(", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.453": {"text": "Mit diesem scharfen Schwert\u2019 ohn alles Leid er-", "tokens": ["Mit", "die\u00b7sem", "schar\u00b7fen", "Schwert'", "ohn", "al\u00b7les", "Leid", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "APPR", "PIAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.454": {"text": "Es hette diesen Hohn mein Volk mit Grimm ge-", "tokens": ["Es", "het\u00b7te", "die\u00b7sen", "Hohn", "mein", "Volk", "mit", "Grimm", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "PPOSAT", "NN", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.455": {"text": "Es hett\u2019 ihr gro\u00dfer Zorn und W\u00fcten nicht ge-", "tokens": ["Es", "hett'", "ihr", "gro\u00b7\u00dfer", "Zorn", "und", "W\u00fc\u00b7ten", "nicht", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "KON", "NN", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.456": {"text": "Bi\u00df Maon \u00fcberschwemmt mit seinem eignen", "tokens": ["Bi\u00df", "Maon", "\u00fc\u00b7bersc\u00b7hwemmt", "mit", "sei\u00b7nem", "eig\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.457": {"text": "Schau aber/ nunmehr soll sich alles Ungl\u00fckk stil-", "tokens": ["Schau", "a\u00b7ber", "/", "nun\u00b7mehr", "soll", "sich", "al\u00b7les", "Un\u00b7gl\u00fckk", "stil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "$(", "ADV", "VMFIN", "PRF", "PIAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.458": {"text": "Und zwar/ Ahigail/ \u00fcm deiner Wei\u00dfheit willen/", "tokens": ["Und", "zwar", "/", "A\u00b7hi\u00b7gail", "/", "\u00fcm", "dei\u00b7ner", "Wei\u00df\u00b7heit", "wil\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "NN", "$(", "APPRART", "PPOSAT", "NN", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.459": {"text": "Dein freundlichs Angesicht so nichts als Tu-", "tokens": ["Dein", "freund\u00b7lichs", "An\u00b7ge\u00b7sicht", "so", "nichts", "als", "Tu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "PIS", "KOKOM", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.460": {"text": "Hat alle Grausamkeit und Eyfer hingelegt.", "tokens": ["Hat", "al\u00b7le", "Grau\u00b7sam\u00b7keit", "und", "Ey\u00b7fer", "hin\u00b7ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.461": {"text": "Es soll mein gantzes Heer zur\u00fckk sich wieder wen-", "tokens": ["Es", "soll", "mein", "gant\u00b7zes", "Heer", "zu\u00b7r\u00fckk", "sich", "wie\u00b7der", "wen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.462": {"text": "Und dein Geschenk empfahn von deinen milden", "tokens": ["Und", "dein", "Ge\u00b7schenk", "em\u00b7pfahn", "von", "dei\u00b7nen", "mil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.463": {"text": "Hab du vor solches dank. Durch h\u00f6flichen Ver-", "tokens": ["Hab", "du", "vor", "sol\u00b7ches", "dank", ".", "Durch", "h\u00f6f\u00b7li\u00b7chen", "Ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "PIAT", "NN", "$.", "APPR", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.464": {"text": "Hast du von deiner Stadt das Wetter abge-", "tokens": ["Hast", "du", "von", "dei\u00b7ner", "Stadt", "das", "Wet\u00b7ter", "ab\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.465": {"text": "Kehr wiederum zur\u00fckk/ und leb in gutem Frieden/", "tokens": ["Kehr", "wie\u00b7de\u00b7rum", "zu\u00b7r\u00fckk", "/", "und", "leb", "in", "gu\u00b7tem", "Frie\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.466": {"text": "Der Krieg ist nunmehr aus/ die Sach\u2019 ist wol ent-", "tokens": ["Der", "Krieg", "ist", "nun\u00b7mehr", "aus", "/", "die", "Sach'", "ist", "wol", "ent"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "$(", "ART", "NN", "VAFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.467": {"text": "Gesegnet must du seyn! Geh hin/ warn deinen", "tokens": ["Ge\u00b7seg\u00b7net", "must", "du", "seyn", "!", "Geh", "hin", "/", "warn", "dei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "VAINF", "$.", "NE", "PTKVZ", "$(", "VAFIN", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.468": {"text": "Sprich da\u00df solch einen Spott kein K\u00f6nig lei-", "tokens": ["Sprich", "da\u00df", "solch", "ei\u00b7nen", "Spott", "kein", "K\u00f6\u00b7nig", "lei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "KOUS", "PIAT", "ART", "NN", "PIAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.469": {"text": "Er soll ein andermal die Zunge besser zwingen/", "tokens": ["Er", "soll", "ein", "an\u00b7der\u00b7mal", "die", "Zun\u00b7ge", "bes\u00b7ser", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADV", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.470": {"text": "Und nicht ein solch Gesp\u00f6tt\u2019 aus seinem Rachen", "tokens": ["Und", "nicht", "ein", "solch", "Ge\u00b7sp\u00f6tt'", "aus", "sei\u00b7nem", "Ra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ART", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.471": {"text": "Beschimpfung thut sehr weh/ und kr\u00e4nkt das", "tokens": ["Be\u00b7schimp\u00b7fung", "thut", "sehr", "weh", "/", "und", "kr\u00e4nkt", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.472": {"text": "Ein frommer Biedermann sch\u00fctzt billich ja", "tokens": ["Ein", "from\u00b7mer", "Bie\u00b7der\u00b7mann", "sch\u00fctzt", "bil\u00b7lich", "ja"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.473": {"text": "Sag da\u00df wir Redlichkeit und Tugend hertzlich", "tokens": ["Sag", "da\u00df", "wir", "Red\u00b7lich\u00b7keit", "und", "Tu\u00b7gend", "hertz\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "PPER", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.474": {"text": "Und da\u00df wir nicht gemein mit Schelmen oder", "tokens": ["Und", "da\u00df", "wir", "nicht", "ge\u00b7mein", "mit", "Schel\u00b7men", "o\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "ADJD", "APPR", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.475": {"text": "Auch nicht durch R\u00e4uberey verschaffen unser", "tokens": ["Auch", "nicht", "durch", "R\u00e4u\u00b7be\u00b7rey", "ver\u00b7schaf\u00b7fen", "un\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "APPR", "NN", "VVFIN", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.476": {"text": "Wie Er uns angeschnautzt Wir leiden freilich", "tokens": ["Wie", "Er", "uns", "an\u00b7ge\u00b7schnautzt", "Wir", "lei\u00b7den", "frei\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.477": {"text": "Und m\u00fcssen Andere/ die mittleidender Sitten/", "tokens": ["Und", "m\u00fcs\u00b7sen", "An\u00b7de\u00b7re", "/", "die", "mitt\u00b7lei\u00b7den\u00b7der", "Sit\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.478": {"text": "Und reich von G\u00fctern sind/ \u00fcm Lebensmittel bit-", "tokens": ["Und", "reich", "von", "G\u00fc\u00b7tern", "sind", "/", "\u00fcm", "Le\u00b7bens\u00b7mit\u00b7tel", "bit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "NN", "VAFIN", "$(", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.479": {"text": "Denn Paran giebt uns nichts/ da wir anitzo", "tokens": ["Denn", "Pa\u00b7ran", "giebt", "uns", "nichts", "/", "da", "wir", "a\u00b7nit\u00b7zo"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PPER", "PIS", "$(", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.480": {"text": "Als B\u00e4ume/ Stauden/ Gras und harte Felsen-", "tokens": ["Als", "B\u00e4u\u00b7me", "/", "Stau\u00b7den", "/", "Gras", "und", "har\u00b7te", "Fel\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "$(", "NN", "$(", "NN", "KON", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.481": {"text": "Man sucht uns hie und da/ wir m\u00fcssen leider lei-", "tokens": ["Man", "sucht", "uns", "hie", "und", "da", "/", "wir", "m\u00fcs\u00b7sen", "lei\u00b7der", "lei"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "KON", "ADV", "$(", "PPER", "VMFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.482": {"text": "Da wir doch nichts verschuldt/ wir m\u00fcssen Sa-", "tokens": ["Da", "wir", "doch", "nichts", "ver\u00b7schuldt", "/", "wir", "m\u00fcs\u00b7sen", "Sa"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVPP", "$(", "PPER", "VMFIN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.483": {"text": "Und unser Hau\u00df und Hof: Doch schadt es al-", "tokens": ["Und", "un\u00b7ser", "Hau\u00df", "und", "Hof", ":", "Doch", "schadt", "es", "al"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "$.", "KON", "VVFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.484": {"text": "Dann ist Sauls Hochmuht aus/ wenn Gottes", "tokens": ["Dann", "ist", "Sauls", "Hoch\u00b7muht", "aus", "/", "wenn", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "NN", "PTKVZ", "$(", "KOUS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.485": {"text": "So bald geschehen wird. Alsdenn wil ich dran", "tokens": ["So", "bald", "ge\u00b7sche\u00b7hen", "wird", ".", "Als\u00b7denn", "wil", "ich", "dran"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVPP", "VAFIN", "$.", "ADV", "VMFIN", "PPER", "PAV"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.486": {"text": "So wol an die/ die mich so hertz und schmertzlich", "tokens": ["So", "wol", "an", "die", "/", "die", "mich", "so", "hertz", "und", "schmertz\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "$(", "PRELS", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.487": {"text": "Als die mir Guts gethan. Wolan so geh denn", "tokens": ["Als", "die", "mir", "Guts", "ge\u00b7than", ".", "Wo\u00b7lan", "so", "geh", "denn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "PPER", "NN", "VVPP", "$.", "ADV", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.488": {"text": "Ich bleibe dir verpflicht weil ich im Leben bin.", "tokens": ["Ich", "blei\u00b7be", "dir", "ver\u00b7pflicht", "weil", "ich", "im", "Le\u00b7ben", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "KOUS", "PPER", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.489": {"text": "Abigail war froh/ Sie neigte sich gantz nieder/", "tokens": ["A\u00b7bi\u00b7gail", "war", "froh", "/", "Sie", "neig\u00b7te", "sich", "gantz", "nie\u00b7der", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "$(", "PPER", "VVFIN", "PRF", "ADV", "PTKVZ", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.490": {"text": "Sie r\u00fchmte Davids Sinn/ und dankt\u2019 ihm hertz-", "tokens": ["Sie", "r\u00fchm\u00b7te", "Da\u00b7vids", "Sinn", "/", "und", "dankt'", "ihm", "hertz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "NN", "$(", "KON", "VVFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.491": {"text": "Vor die Barmhertzigkeit/ so Er an ihr gethan/", "tokens": ["Vor", "die", "Barm\u00b7hert\u00b7zig\u00b7keit", "/", "so", "Er", "an", "ihr", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$(", "ADV", "PPER", "APPR", "PPER", "VVPP", "$("], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.492": {"text": "Damit schied Sie von Jhm/ und macht sich", "tokens": ["Da\u00b7mit", "schied", "Sie", "von", "Jhm", "/", "und", "macht", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "PPER", "$(", "KON", "VVFIN", "PRF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.493": {"text": "Seht was die Tugend wirkt! seht was doch weise", "tokens": ["Seht", "was", "die", "Tu\u00b7gend", "wirkt", "!", "seht", "was", "doch", "wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PWS", "ART", "NN", "VVFIN", "$.", "VVFIN", "PWS", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.494": {"text": "Mit Dehmuht untermischt/ thun und verrichten", "tokens": ["Mit", "Deh\u00b7muht", "un\u00b7ter\u00b7mischt", "/", "thun", "und", "ver\u00b7rich\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$(", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.495": {"text": "Seht was Verstand und Witz/ seht was ein", "tokens": ["Seht", "was", "Ver\u00b7stand", "und", "Witz", "/", "seht", "was", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIS", "NN", "KON", "NN", "$(", "VVFIN", "PWS", "ART"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.496": {"text": "Seht was ein redlichs Hertz vor gro\u00dfe Thaten", "tokens": ["Seht", "was", "ein", "red\u00b7lichs", "Hertz", "vor", "gro\u00b7\u00dfe", "Tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PWS", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.497": {"text": "Hier siegt ein zahrtes Weib/ mit nichts als guten", "tokens": ["Hier", "siegt", "ein", "zahr\u00b7tes", "Weib", "/", "mit", "nichts", "als", "gu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$(", "APPR", "PIS", "KOKOM", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.498": {"text": "Sie treibt ein feindlichs Heer von Maons schwa-", "tokens": ["Sie", "treibt", "ein", "feind\u00b7lichs", "Heer", "von", "Maons", "schwa"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.499": {"text": "Jhr Bogen/ Pfeil und Schwert ist fromme", "tokens": ["Ihr", "Bo\u00b7gen", "/", "Pfeil", "und", "Schwert", "ist", "from\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "NN", "KON", "NN", "VAFIN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.500": {"text": "Sie legt mit H\u00f6flichkeit ein blutigs Ungl\u00fckk", "tokens": ["Sie", "legt", "mit", "H\u00f6f\u00b7lich\u00b7keit", "ein", "blu\u00b7tigs", "Un\u00b7gl\u00fckk"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.501": {"text": "Es war das Kriegesvolk zum theil nicht wol zu", "tokens": ["Es", "war", "das", "Krie\u00b7ges\u00b7volk", "zum", "theil", "nicht", "wol", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "PTKNEG", "ADV", "PTKZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.502": {"text": "Da\u00df dieses keusche Weib so friedlich abgeschieden/", "tokens": ["Da\u00df", "die\u00b7ses", "keu\u00b7sche", "Weib", "so", "fried\u00b7lich", "ab\u00b7ge\u00b7schie\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.503": {"text": "Sie waren sehr erpicht/ mit eyferigem Muht\u2019/", "tokens": ["Sie", "wa\u00b7ren", "sehr", "er\u00b7picht", "/", "mit", "ey\u00b7fe\u00b7ri\u00b7gem", "Muht'", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.504": {"text": "Wie ein Soldate pflegt/ auf Nabals reiches", "tokens": ["Wie", "ein", "Sol\u00b7da\u00b7te", "pflegt", "/", "auf", "Na\u00b7bals", "rei\u00b7ches"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$(", "APPR", "NE", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.505": {"text": "Sie waren alle Sinns den Hunger erst zu stillen/", "tokens": ["Sie", "wa\u00b7ren", "al\u00b7le", "Sinns", "den", "Hun\u00b7ger", "erst", "zu", "stil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.506": {"text": "Hernach mit Geld\u2019 und Gut die Beutel auszu-", "tokens": ["Her\u00b7nach", "mit", "Geld'", "und", "Gut", "die", "Beu\u00b7tel", "aus\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "ADJD", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.507": {"text": "Vermeinten/ wie denn auch der Schimpf es", "tokens": ["Ver\u00b7mein\u00b7ten", "/", "wie", "denn", "auch", "der", "Schimpf", "es"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "KOKOM", "ADV", "ADV", "ART", "NN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.508": {"text": "Des Nabals gantzes Hau\u00df zu tilgen mit dem", "tokens": ["Des", "Na\u00b7bals", "gant\u00b7zes", "Hau\u00df", "zu", "til\u00b7gen", "mit", "dem"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.509": {"text": "Sie aber musten fort und bald zu r\u00fckke lenden/", "tokens": ["Sie", "a\u00b7ber", "mus\u00b7ten", "fort", "und", "bald", "zu", "r\u00fck\u00b7ke", "len\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKVZ", "KON", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.510": {"text": "Und sich von diesem Ohrt\u2019/ auf Parans H\u00fcgel", "tokens": ["Und", "sich", "von", "die\u00b7sem", "Ohrt'", "/", "auf", "Pa\u00b7rans", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "PDAT", "NN", "$(", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.511": {"text": "Als Sie nun angelangt auf einen sch\u00f6nen", "tokens": ["Als", "Sie", "nun", "an\u00b7ge\u00b7langt", "auf", "ei\u00b7nen", "sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.512": {"text": "Theilt David unter Sie den \u00fcberschikkten", "tokens": ["Theilt", "Da\u00b7vid", "un\u00b7ter", "Sie", "den", "\u00fc\u00b7bersc\u00b7hikk\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.513": {"text": "Von Ladsall/ Speis\u2019 und Trank: Das Volk er-", "tokens": ["Von", "Lad\u00b7sall", "/", "Speis'", "und", "Trank", ":", "Das", "Volk", "er"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$(", "NN", "KON", "NN", "$.", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.514": {"text": "Nachdem es lang gefast/ es lie\u00df sich alles nie-", "tokens": ["Nach\u00b7dem", "es", "lang", "ge\u00b7fast", "/", "es", "lie\u00df", "sich", "al\u00b7les", "nie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "$(", "PPER", "VVFIN", "PRF", "PIS", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.515": {"text": "In das betleete Gras/ verga\u00dfen alles Leid/", "tokens": ["In", "das", "be\u00b7tlee\u00b7te", "Gras", "/", "ver\u00b7ga\u00b7\u00dfen", "al\u00b7les", "Leid", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.516": {"text": "Und hatten allesamt recht gut\u2019 Ergetzlichkeit.", "tokens": ["Und", "hat\u00b7ten", "al\u00b7le\u00b7samt", "recht", "gut'", "Er\u00b7getz\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.517": {"text": "Indem Abigail nunmehr nach Hause kommen/", "tokens": ["In\u00b7dem", "A\u00b7bi\u00b7gail", "nun\u00b7mehr", "nach", "Hau\u00b7se", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.518": {"text": "Findt Sie das gantze Hau\u00df von Wollust einge-", "tokens": ["Findt", "Sie", "das", "gant\u00b7ze", "Hau\u00df", "von", "Wol\u00b7lust", "ein\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.519": {"text": "Es war ein gro\u00df Gejauchtz\u2019/ ein Jeder schrieh", "tokens": ["Es", "war", "ein", "gro\u00df", "Ge\u00b7jauchtz'", "/", "ein", "Je\u00b7der", "schrieh"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$(", "ART", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.520": {"text": "Insonderheit ihr Mann war auch mit rasend", "tokens": ["In\u00b7son\u00b7der\u00b7heit", "ihr", "Mann", "war", "auch", "mit", "ra\u00b7send"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.521": {"text": "Er hatte sich mit Wein auch dergestalt begossen/", "tokens": ["Er", "hat\u00b7te", "sich", "mit", "Wein", "auch", "der\u00b7ge\u00b7stalt", "be\u00b7gos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.522": {"text": "Da\u00df ihm die starken Tr\u00fcnk\u2019 au\u00df seinem Halse flos-", "tokens": ["Da\u00df", "ihm", "die", "star\u00b7ken", "Tr\u00fcnk'", "au\u00df", "sei\u00b7nem", "Hal\u00b7se", "flos"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.523": {"text": "Weil ihm der Leib zu eng/ Er sa\u00df dort wie ein", "tokens": ["Weil", "ihm", "der", "Leib", "zu", "eng", "/", "Er", "sa\u00df", "dort", "wie", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NE", "$(", "PPER", "VVFIN", "ADV", "KOKOM", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.524": {"text": "Regt weder Arm noch Bein/ und klotzte wie", "tokens": ["Regt", "we\u00b7der", "Arm", "noch", "Bein", "/", "und", "klotz\u00b7te", "wie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "KON", "NN", "ADV", "NN", "$(", "KON", "VVFIN", "KOKOM"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.525": {"text": "Schlief halb und halb im Rausch/ Er sieng oft an", "tokens": ["Schlief", "halb", "und", "halb", "im", "Rausch", "/", "Er", "sieng", "oft", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "KON", "ADJD", "APPRART", "NN", "$(", "PPER", "VVFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.526": {"text": "Nu/ saufft doch frisch her\u00fcm/ lasts gehen nach der", "tokens": ["Nu", "/", "saufft", "doch", "frisch", "he\u00b7r\u00fcm", "/", "lasts", "ge\u00b7hen", "nach", "der"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "VVFIN", "ADV", "ADJD", "PTKVZ", "$(", "ADV", "VVFIN", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.527": {"text": "Gieb eine Humpe her! Es gilt dir Nachbar", "tokens": ["Gieb", "ei\u00b7ne", "Hum\u00b7pe", "her", "!", "Es", "gilt", "dir", "Nach\u00b7bar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.528": {"text": "Auf Sauls Gesundheit! Sauf! trink au\u00df und", "tokens": ["Auf", "Sauls", "Ge\u00b7sund\u00b7heit", "!", "Sauf", "!", "trink", "au\u00df", "und"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "$.", "NN", "$.", "VVFIN", "PTKVZ", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.529": {"text": "So fand\u2019 Abigail/ wiewol mit gro\u00dfen Schmertzen/", "tokens": ["So", "fand'", "A\u00b7bi\u00b7gail", "/", "wie\u00b7wol", "mit", "gro\u00b7\u00dfen", "Schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$(", "KOUS", "APPR", "ADJA", "NN", "$("], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.530": {"text": "Jhr freundlichs Ehgemahl/ es that ihr Weh im", "tokens": ["Ihr", "freund\u00b7lichs", "Eh\u00b7ge\u00b7mahl", "/", "es", "that", "ihr", "Weh", "im"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "APPRART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.531": {"text": "Da\u00df ihr versoffner Mann so unbesonnen war/", "tokens": ["Da\u00df", "ihr", "ver\u00b7soff\u00b7ner", "Mann", "so", "un\u00b7be\u00b7son\u00b7nen", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.532": {"text": "Nicht wissend/ was vor Angst und schrekkliche", "tokens": ["Nicht", "wis\u00b7send", "/", "was", "vor", "Angst", "und", "schrek\u00b7kli\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "$(", "PWS", "APPR", "NN", "KON", "ADJA"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.533": {"text": "Sie von ihm abgewandt. Sie sah die G\u00e4ste sitzen/", "tokens": ["Sie", "von", "ihm", "ab\u00b7ge\u00b7wandt", ".", "Sie", "sah", "die", "G\u00e4s\u00b7te", "sit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.534": {"text": "Und theils von gro\u00dfem Fro\u00df und vielem Sauffen", "tokens": ["Und", "theils", "von", "gro\u00b7\u00dfem", "Fro\u00df", "und", "vie\u00b7lem", "Sauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "KON", "PIS", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.535": {"text": "Hier lag ein voller Knecht/ dort eine volle Magd/", "tokens": ["Hier", "lag", "ein", "vol\u00b7ler", "Knecht", "/", "dort", "ei\u00b7ne", "vol\u00b7le", "Magd", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$(", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.536": {"text": "Und hatte mit dem Soff/ ich wei\u00df nicht was/", "tokens": ["Und", "hat\u00b7te", "mit", "dem", "Soff", "/", "ich", "wei\u00df", "nicht", "was", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "PWS", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.537": {"text": "Sie lie\u00df es also gehn bi\u00df Nabal eingeschlafen/", "tokens": ["Sie", "lie\u00df", "es", "al\u00b7so", "gehn", "bi\u00df", "Na\u00b7bal", "ein\u00b7ge\u00b7schla\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVINF", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.538": {"text": "Drauf jagt sie alles weg/ die H\u00fcrten zu den Scha-", "tokens": ["Drauf", "jagt", "sie", "al\u00b7les", "weg", "/", "die", "H\u00fcr\u00b7ten", "zu", "den", "Scha"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PIS", "PTKVZ", "$(", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.539": {"text": "Und schaffet Ruh\u2019 im Haus: Es war schon", "tokens": ["Und", "schaf\u00b7fet", "Ruh'", "im", "Haus", ":", "Es", "war", "schon"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "APPRART", "NN", "$.", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.540": {"text": "Als Sie hatt\u2019 ihren Mann ins warme Bette", "tokens": ["Als", "Sie", "hatt'", "ih\u00b7ren", "Mann", "ins", "war\u00b7me", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VAFIN", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.541": {"text": "Da nun die Nacht vor bey und man den Morgen", "tokens": ["Da", "nun", "die", "Nacht", "vor", "bey", "und", "man", "den", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "APPR", "APPR", "KON", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.542": {"text": "Als Nabal seine Speis\u2019/ und starken Rausch ver-", "tokens": ["Als", "Na\u00b7bal", "sei\u00b7ne", "Speis'", "/", "und", "star\u00b7ken", "Rausch", "ver"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "PPOSAT", "NN", "$(", "KON", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.543": {"text": "Und wieder n\u00fcchtern war/ gieng sein verst\u00e4ndig", "tokens": ["Und", "wie\u00b7der", "n\u00fcch\u00b7tern", "war", "/", "gieng", "sein", "ver\u00b7st\u00e4n\u00b7dig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "$(", "VVFIN", "PPOSAT", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.544": {"text": "Zu ihm/ und stellt\u2019 ihm vor sein gestrigs Zeit-", "tokens": ["Zu", "ihm", "/", "und", "stellt'", "ihm", "vor", "sein", "ge\u00b7strigs", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$(", "KON", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "TRUNC"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.545": {"text": "Sie sprach ihm heftig zu/ Sie fieng ihn an zu-", "tokens": ["Sie", "sprach", "ihm", "hef\u00b7tig", "zu", "/", "Sie", "fi\u00b7eng", "ihn", "an", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKZU", "$(", "PPER", "VVFIN", "PPER", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.546": {"text": "Mit einer scharfen Red\u2019/ und alles zu erz\u00e4hlen/", "tokens": ["Mit", "ei\u00b7ner", "schar\u00b7fen", "Red'", "/", "und", "al\u00b7les", "zu", "er\u00b7z\u00e4h\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "KON", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.547": {"text": "Was gestern war geschehn/ erwehnte die Ge-", "tokens": ["Was", "ge\u00b7stern", "war", "ge\u00b7schehn", "/", "er\u00b7wehn\u00b7te", "die", "Ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADV", "VAFIN", "VVPP", "$(", "VVFIN", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.548": {"text": "Und was vor Hertzeleid auf Sie gerichtet war.", "tokens": ["Und", "was", "vor", "Hert\u00b7ze\u00b7leid", "auf", "Sie", "ge\u00b7rich\u00b7tet", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.549": {"text": "Sagt unter andern so: Du wirst ja noch wol wis-", "tokens": ["Sagt", "un\u00b7ter", "an\u00b7dern", "so", ":", "Du", "wirst", "ja", "noch", "wol", "wis"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PIS", "ADV", "$.", "PPER", "VAFIN", "ADV", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.550": {"text": "Da\u00df Davids Volk sich stets der Redlichkeit be-", "tokens": ["Da\u00df", "Da\u00b7vids", "Volk", "sich", "stets", "der", "Red\u00b7lich\u00b7keit", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "NN", "PRF", "ADV", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.551": {"text": "Da\u00df Sie uns nichts gethan/ man sagt von", "tokens": ["Da\u00df", "Sie", "uns", "nichts", "ge\u00b7than", "/", "man", "sagt", "von"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "PIS", "VVPP", "$(", "PIS", "VVFIN", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.552": {"text": "Da\u00df ihr Gem\u00fcht\u2019 auf Raub und Stehlen ab-", "tokens": ["Da\u00df", "ihr", "Ge\u00b7m\u00fcht'", "auf", "Raub", "und", "Steh\u00b7len", "ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.553": {"text": "Auch ist dir wol bewust/ da\u00df David au\u00dferkohren/", "tokens": ["Auch", "ist", "dir", "wol", "be\u00b7wust", "/", "da\u00df", "Da\u00b7vid", "au\u00b7\u00dfer\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$(", "KOUS", "NE", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.554": {"text": "Und durch des H\u00f6chsten Gunst zum K\u00f6nige ge-", "tokens": ["Und", "durch", "des", "H\u00f6chs\u00b7ten", "Gunst", "zum", "K\u00f6\u00b7ni\u00b7ge", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.555": {"text": "Es hat ja Samuel zu solcher W\u00fcrdigkeit/", "tokens": ["Es", "hat", "ja", "Sa\u00b7muel", "zu", "sol\u00b7cher", "W\u00fcr\u00b7dig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NE", "APPR", "PIAT", "NN", "$("], "meter": "+---+-+-+-+", "measure": "dactylic.init"}, "line.556": {"text": "Jhn/ wie schon gnug bekandt/ gesalbt und ein-", "tokens": ["Jhn", "/", "wie", "schon", "gnug", "be\u00b7kandt", "/", "ge\u00b7salbt", "und", "ein"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$(", "KOKOM", "ADV", "ADV", "ADJD", "$(", "VVPP", "KON", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.557": {"text": "Er wird/ wenn Er sein Kreutz/ und Elend\u2019 ausge-", "tokens": ["Er", "wird", "/", "wenn", "Er", "sein", "Kreutz", "/", "und", "E\u00b7lend'", "aus\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$(", "KOUS", "PPER", "PPOSAT", "NN", "$(", "KON", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.558": {"text": "Wenn Gottes Wunderhand ihn von den Tr\u00fcb-", "tokens": ["Wenn", "Got\u00b7tes", "Wun\u00b7der\u00b7hand", "ihn", "von", "den", "Tr\u00fcb"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "NN", "PPER", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.559": {"text": "Erl\u00f6sen wird/ wenn sich verliebret seine Pein/", "tokens": ["Er\u00b7l\u00f6\u00b7sen", "wird", "/", "wenn", "sich", "ver\u00b7lieb\u00b7ret", "sei\u00b7ne", "Pein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$(", "KOUS", "PRF", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.560": {"text": "Ein Richter Jsraels/ und unser K\u00f6nig seyn.", "tokens": ["Ein", "Rich\u00b7ter", "Js\u00b7raels", "/", "und", "un\u00b7ser", "K\u00f6\u00b7nig", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$(", "KON", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.561": {"text": "Und du hast seine Knecht\u2019 als solche zu dir kahmen/", "tokens": ["Und", "du", "hast", "sei\u00b7ne", "Knecht'", "als", "sol\u00b7che", "zu", "dir", "kah\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPOSAT", "NN", "KOKOM", "PIAT", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.562": {"text": "Da sie in ihrer Noht/ zu uns die Zuflucht nah-", "tokens": ["Da", "sie", "in", "ih\u00b7rer", "Noht", "/", "zu", "uns", "die", "Zu\u00b7flucht", "nah"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "$(", "APPR", "PPER", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.563": {"text": "So schimpflich angesehn/ und sch\u00e4ndlich aus-", "tokens": ["So", "schimpf\u00b7lich", "an\u00b7ge\u00b7sehn", "/", "und", "sch\u00e4nd\u00b7lich", "aus"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "$(", "KON", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.564": {"text": "Als were David selbst ein schn\u00f6der B\u00f6sewicht.", "tokens": ["Als", "we\u00b7re", "Da\u00b7vid", "selbst", "ein", "schn\u00f6\u00b7der", "B\u00f6\u00b7se\u00b7wicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NE", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.565": {"text": "Welchs ihn und sein gantz Heer/ wie man auch", "tokens": ["Welchs", "ihn", "und", "sein", "gantz", "Heer", "/", "wie", "man", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "KON", "PPOSAT", "ADV", "NN", "$(", "PWAV", "PIS", "ADV"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.566": {"text": "Jm Hertzen weh gethan/ und Zweifelsfrey noch", "tokens": ["Jm", "Hert\u00b7zen", "weh", "ge\u00b7than", "/", "und", "Zwei\u00b7fels\u00b7frey", "noch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$(", "KON", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.567": {"text": "Sie haben unsrem Vieh nichts Wiedriges ge-", "tokens": ["Sie", "ha\u00b7ben", "uns\u00b7rem", "Vieh", "nichts", "Wied\u00b7ri\u00b7ges", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "PIS", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.568": {"text": "Und du fuhrst sie voll Grimm so ehrenr\u00fchrig", "tokens": ["Und", "du", "fuhrst", "sie", "voll", "Grimm", "so", "eh\u00b7ren\u00b7r\u00fch\u00b7rig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "NE", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.569": {"text": "Pfuy! gro\u00dfer Unverstand", "tokens": ["Pfuy", "!", "gro\u00b7\u00dfer", "Un\u00b7ver\u00b7stand"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$.", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.570": {"text": "Mein! schau ist das nicht ein vern\u00fcnftiges Begin-", "tokens": ["Mein", "!", "schau", "ist", "das", "nicht", "ein", "ver\u00b7n\u00fcnf\u00b7ti\u00b7ges", "Be\u00b7gin"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "$.", "ADJD", "VAFIN", "PDS", "PTKNEG", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.571": {"text": "Wenn man den jenigen/ ders hertzlich gut ge-", "tokens": ["Wenn", "man", "den", "je\u00b7ni\u00b7gen", "/", "ders", "hertz\u00b7lich", "gut", "ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "PIAT", "$(", "ADV", "ADJD", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.572": {"text": "Verh\u00f6hnet schimpft und schmeht/ als einen", "tokens": ["Ver\u00b7h\u00f6h\u00b7net", "schimpft", "und", "schmeht", "/", "als", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "VVFIN", "KON", "VVFIN", "$(", "KOUS", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.573": {"text": "Was hett\u2019 es dir geschadt/ da unsre Leute sa\u00dfen/", "tokens": ["Was", "hett'", "es", "dir", "ge\u00b7schadt", "/", "da", "uns\u00b7re", "Leu\u00b7te", "sa\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PPER", "VVPP", "$(", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.574": {"text": "Und nach vollbrachter Schur/ die fette Mahlzeit", "tokens": ["Und", "nach", "voll\u00b7brach\u00b7ter", "Schur", "/", "die", "fet\u00b7te", "Mahl\u00b7zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.575": {"text": "Auch unser Vorraht gro\u00df/ dem H\u00f6chsten sey", "tokens": ["Auch", "un\u00b7ser", "Vor\u00b7raht", "gro\u00df", "/", "dem", "H\u00f6chs\u00b7ten", "sey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "ADJD", "$(", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.576": {"text": "Von dessen milder Hand wir alles ja erlangt/", "tokens": ["Von", "des\u00b7sen", "mil\u00b7der", "Hand", "wir", "al\u00b7les", "ja", "er\u00b7langt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "PPER", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.577": {"text": "Wenn du des Davids Heer/ mit Speis\u2019 und", "tokens": ["Wenn", "du", "des", "Da\u00b7vids", "Heer", "/", "mit", "Speis'", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NE", "NN", "$(", "APPR", "NN", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.578": {"text": "Und sie mit G\u00fctigkoit au\u00df ihrer Noht gesetzet.", "tokens": ["Und", "sie", "mit", "G\u00fc\u00b7tig\u00b7koit", "au\u00df", "ih\u00b7rer", "Noht", "ge\u00b7set\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.579": {"text": "Es ist ja h\u00e4uffig da/ die Kammern sind ja voll/", "tokens": ["Es", "ist", "ja", "h\u00e4uf\u00b7fig", "da", "/", "die", "Kam\u00b7mern", "sind", "ja", "voll", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADV", "$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.580": {"text": "Es mangelt uns ja nichts/ und das wei\u00df David", "tokens": ["Es", "man\u00b7gelt", "uns", "ja", "nichts", "/", "und", "das", "wei\u00df", "Da\u00b7vid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PIS", "$(", "KON", "PDS", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.581": {"text": "Das ist ein sch\u00f6nes Werk zu rechter Zeit was", "tokens": ["Das", "ist", "ein", "sch\u00f6\u00b7nes", "Werk", "zu", "rech\u00b7ter", "Zeit", "was"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PWS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.582": {"text": "Und bey so grossem Gut auch Andrer Noth beden-", "tokens": ["Und", "bey", "so", "gros\u00b7sem", "Gut", "auch", "A\u00b7ndrer", "Noth", "be\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "ADJA", "NN", "ADV", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.583": {"text": "Dem w\u00e4chset mehr noch zu/ dem fehlt der Se-", "tokens": ["Dem", "w\u00e4ch\u00b7set", "mehr", "noch", "zu", "/", "dem", "fehlt", "der", "Se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "PTKZU", "$(", "ART", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.584": {"text": "Der sein gesegnet Brodt dem Hungerigen", "tokens": ["Der", "sein", "ge\u00b7seg\u00b7net", "Brodt", "dem", "Hun\u00b7ge\u00b7ri\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "VVPP", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.585": {"text": "Wer kein Mitleiden hat mit nohtd\u00fcrftigen Ar-", "tokens": ["Wer", "kein", "Mit\u00b7lei\u00b7den", "hat", "mit", "noht\u00b7d\u00fcrf\u00b7ti\u00b7gen", "Ar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIAT", "NN", "VAFIN", "APPR", "ADJA", "TRUNC"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.586": {"text": "De\u00df wird der reiche GOtt sich wieder nicht er-", "tokens": ["De\u00df", "wird", "der", "rei\u00b7che", "Gott", "sich", "wie\u00b7der", "nicht", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "PRF", "ADV", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.587": {"text": "Wer zu bequemer Zeit die Hand er\u00f6ffnen kan/", "tokens": ["Wer", "zu", "be\u00b7que\u00b7mer", "Zeit", "die", "Hand", "er\u00b7\u00f6ff\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKA", "ADJD", "NN", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.588": {"text": "Und hilft dem Nechsten aus/ der ist ein frommer", "tokens": ["Und", "hilft", "dem", "Nechs\u00b7ten", "aus", "/", "der", "ist", "ein", "from\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$(", "ART", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.589": {"text": "Du weist es selber wol/ es werden deine Sitten/", "tokens": ["Du", "weist", "es", "sel\u00b7ber", "wol", "/", "es", "wer\u00b7den", "dei\u00b7ne", "Sit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$(", "PPER", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.590": {"text": "Von keinem anders nicht/ als mit Verdru\u00df ge-", "tokens": ["Von", "kei\u00b7nem", "an\u00b7ders", "nicht", "/", "als", "mit", "Ver\u00b7dru\u00df", "ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "ADV", "PTKNEG", "$(", "KOKOM", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.591": {"text": "Du bist so grob und plump/ erzeigst dich wie ein", "tokens": ["Du", "bist", "so", "grob", "und", "plump", "/", "er\u00b7zeigst", "dich", "wie", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$(", "VVFIN", "PPER", "KOKOM", "ART"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.592": {"text": "Wann du das Maul aufthust/ so gukkt ein", "tokens": ["Wann", "du", "das", "Maul", "auf\u00b7thust", "/", "so", "gukkt", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$(", "ADV", "VVFIN", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.593": {"text": "Du weist es wol/ wie ich so oft vor dich getreten/", "tokens": ["Du", "weist", "es", "wol", "/", "wie", "ich", "so", "oft", "vor", "dich", "ge\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$(", "PWAV", "PPER", "ADV", "ADV", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.594": {"text": "Und dich mit Weinen hab\u2019 als einen Herrn ge-", "tokens": ["Und", "dich", "mit", "Wei\u00b7nen", "hab'", "als", "ei\u00b7nen", "Herrn", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "NN", "VAFIN", "KOKOM", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.595": {"text": "Da\u00df du doch \u00e4ndern wollst den ungeschliffnen", "tokens": ["Da\u00df", "du", "doch", "\u00e4n\u00b7dern", "wollst", "den", "un\u00b7ge\u00b7schliff\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.596": {"text": "Du aber thust es nicht/ du folgest immerhin/", "tokens": ["Du", "a\u00b7ber", "thust", "es", "nicht", "/", "du", "fol\u00b7gest", "im\u00b7mer\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "PTKNEG", "$(", "PPER", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.597": {"text": "Wo dich dein Nabals Hertz nach seinem Willen", "tokens": ["Wo", "dich", "dein", "Na\u00b7bals", "Hertz", "nach", "sei\u00b7nem", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.598": {"text": "Es ist kein guter Raht der deine Thorheit r\u00fchret/", "tokens": ["Es", "ist", "kein", "gu\u00b7ter", "Raht", "der", "dei\u00b7ne", "Thor\u00b7heit", "r\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.599": {"text": "Du meinst zwar dein Gehirn/ sey klug und weise", "tokens": ["Du", "meinst", "zwar", "dein", "Ge\u00b7hirn", "/", "sey", "klug", "und", "wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "PPOSAT", "NN", "$(", "VAFIN", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.600": {"text": "Da doch dein Centnerkopf kein Quentlein Klug-", "tokens": ["Da", "doch", "dein", "Cent\u00b7ner\u00b7kopf", "kein", "Quent\u00b7lein", "Klug"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "PIAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.601": {"text": "Verzeih mir lieber Mann/ ich mu\u00df die Warheit", "tokens": ["Ver\u00b7zeih", "mir", "lie\u00b7ber", "Mann", "/", "ich", "mu\u00df", "die", "War\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "NN", "$(", "PPER", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.602": {"text": "Ich mu\u00df dirs dermaleinst in dein Gewissen jagen/", "tokens": ["Ich", "mu\u00df", "dirs", "der\u00b7ma\u00b7leinst", "in", "dein", "Ge\u00b7wis\u00b7sen", "ja\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.603": {"text": "Da\u00df du daran gedenkst. Ich bitte nochmals", "tokens": ["Da\u00df", "du", "da\u00b7ran", "ge\u00b7denkst", ".", "Ich", "bit\u00b7te", "noch\u00b7mals"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PAV", "VVPP", "$.", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.604": {"text": "Ach \u00e4ndr\u2019 ach \u00e4ndre dich und thu es doch nicht", "tokens": ["Ach", "\u00e4ndr'", "ach", "\u00e4nd\u00b7re", "dich", "und", "thu", "es", "doch", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ITJ", "ITJ", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "ADV", "PTKNEG"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.605": {"text": "Ein gut gemeintes Wort/ die H\u00f6flichkeit im", "tokens": ["Ein", "gut", "ge\u00b7mein\u00b7tes", "Wort", "/", "die", "H\u00f6f\u00b7lich\u00b7keit", "im"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN", "$(", "ART", "NN", "APPRART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.606": {"text": "Kan manches Ungemach und Ungl\u00fckk unter-", "tokens": ["Kan", "man\u00b7ches", "Un\u00b7ge\u00b7mach", "und", "Un\u00b7gl\u00fckk", "un\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIAT", "NN", "KON", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.607": {"text": "Wer aber nichts als Trotz und Schmehwort", "tokens": ["Wer", "a\u00b7ber", "nichts", "als", "Trotz", "und", "Schmeh\u00b7wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PIS", "KOKOM", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.608": {"text": "Legt oft der Sanftmuht selbst Zorn/ Schwert", "tokens": ["Legt", "oft", "der", "Sanft\u00b7muht", "selbst", "Zorn", "/", "Schwert"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "NN", "$(", "NN"], "meter": "-+-+--++", "measure": "iambic.tetra.relaxed"}, "line.609": {"text": "Ich hab\u2019 es in der That/ bi\u00dfher in so viel Jahren/", "tokens": ["Ich", "hab'", "es", "in", "der", "That", "/", "bi\u00df\u00b7her", "in", "so", "viel", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "$(", "ADV", "APPR", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.610": {"text": "Und/ da\u00df es wahr sey/ selbst noch gestrigs Tags", "tokens": ["Und", "/", "da\u00df", "es", "wahr", "sey", "/", "selbst", "noch", "ge\u00b7strigs", "Tags"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$(", "KOUS", "PPER", "ADJD", "VAFIN", "$(", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.611": {"text": "Ich hab\u2019 ein Beyspiel de\u00df gesehn auf einen", "tokens": ["Ich", "hab'", "ein", "Bey\u00b7spiel", "de\u00df", "ge\u00b7sehn", "auf", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "VVPP", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.612": {"text": "Was ein verbostes Maul/ und H\u00f6flichkeit ver-", "tokens": ["Was", "ein", "ver\u00b7bos\u00b7tes", "Maul", "/", "und", "H\u00f6f\u00b7lich\u00b7keit", "ver"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "$(", "KON", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.613": {"text": "Mein Hertz erzittert noch/ kaum mag ich mehr", "tokens": ["Mein", "Hertz", "er\u00b7zit\u00b7tert", "noch", "/", "kaum", "mag", "ich", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$(", "ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.614": {"text": "Wie David kam/ \u00fcm dich und unser Haus zu", "tokens": ["Wie", "Da\u00b7vid", "kam", "/", "\u00fcm", "dich", "und", "un\u00b7ser", "Haus", "zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "VVFIN", "$(", "VVIMP", "PPER", "KON", "PPOSAT", "NN", "PTKZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.615": {"text": "Sein Volk war gantz erf\u00fcllt mit Eyfer/ Zorn", "tokens": ["Sein", "Volk", "war", "gantz", "er\u00b7f\u00fcllt", "mit", "Ey\u00b7fer", "/", "Zorn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVPP", "APPR", "NN", "$(", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.616": {"text": "Mich deucht ich sehe noch der blo\u00dfen Sebel", "tokens": ["Mich", "deucht", "ich", "se\u00b7he", "noch", "der", "blo\u00b7\u00dfen", "Se\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.617": {"text": "Als die beschimpfte Knecht\u2019 ins L\u00e4ger wieder kom-", "tokens": ["Als", "die", "be\u00b7schimpf\u00b7te", "Knecht'", "ins", "L\u00e4\u00b7ger", "wie\u00b7der", "kom"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.618": {"text": "Und David diesen Spott von ihnen gnug vernom-", "tokens": ["Und", "Da\u00b7vid", "die\u00b7sen", "Spott", "von", "ih\u00b7nen", "gnug", "ver\u00b7nom"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "PDAT", "NN", "APPR", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.619": {"text": "Da war das gantze Heer zur grimmen Rach", "tokens": ["Da", "war", "das", "gant\u00b7ze", "Heer", "zur", "grim\u00b7men", "Rach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.620": {"text": "Es nahm ein jederman sein Mordschwert in die", "tokens": ["Es", "nahm", "ein", "je\u00b7der\u00b7man", "sein", "Mord\u00b7schwert", "in", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "PIS", "PPOSAT", "NN", "APPR", "ART"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.621": {"text": "Das Urtheil war gef\u00e4llt/ der Stab war schon ge-", "tokens": ["Das", "Ur\u00b7theil", "war", "ge\u00b7f\u00e4llt", "/", "der", "Stab", "war", "schon", "ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "ART", "NN", "VAFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.622": {"text": "Der zugef\u00fcgte Schimpf solt\u2019 eifrigst seyn ge-", "tokens": ["Der", "zu\u00b7ge\u00b7f\u00fcg\u00b7te", "Schimpf", "solt'", "eif\u00b7rigst", "seyn", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADJD", "VAINF", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.623": {"text": "Gantz Maon solte sich in seinem Blute sehn/", "tokens": ["Gantz", "Maon", "sol\u00b7te", "sich", "in", "sei\u00b7nem", "Blu\u00b7te", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.624": {"text": "Das Schwert solt\u2019 erst in dich/ hernach in Alle", "tokens": ["Das", "Schwert", "solt'", "erst", "in", "dich", "/", "her\u00b7nach", "in", "Al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "APPR", "PPER", "$(", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.625": {"text": "Die\u00df hat dein Maul/ welchs gantz mit Bo\u00dfheit ist", "tokens": ["Die\u00df", "hat", "dein", "Maul", "/", "welchs", "gantz", "mit", "Bo\u00df\u00b7heit", "ist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$(", "PWS", "ADV", "APPR", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.626": {"text": "(ich kenn\u2019 es alzuwol) ach leider! angestiftet:", "tokens": ["(", "ich", "kenn'", "es", "al\u00b7zu\u00b7wol", ")", "ach", "lei\u00b7der", "!", "an\u00b7ge\u00b7stif\u00b7tet", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "$(", "ITJ", "ADV", "$.", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.627": {"text": "Da\u00df David und sein Heer auf Wuten war be-", "tokens": ["Da\u00df", "Da\u00b7vid", "und", "sein", "Heer", "auf", "Wu\u00b7ten", "war", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "KON", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.628": {"text": "Das hat dein\u2019 Unvernunft und grosser Trotz ge-", "tokens": ["Das", "hat", "dein'", "Un\u00b7ver\u00b7nunft", "und", "gros\u00b7ser", "Trotz", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "KON", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.629": {"text": "Gott aber/ der uns noch so g\u00fctig und gewogen/", "tokens": ["Gott", "a\u00b7ber", "/", "der", "uns", "noch", "so", "g\u00fc\u00b7tig", "und", "ge\u00b7wo\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$(", "PRELS", "PPER", "ADV", "ADV", "ADJD", "KON", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.630": {"text": "Hat das schuldlose Blut aus dieser Angst gezogen/", "tokens": ["Hat", "das", "schuld\u00b7lo\u00b7se", "Blut", "aus", "die\u00b7ser", "Angst", "ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.631": {"text": "Sein mildes Vaterhertz war noch so wol ge-", "tokens": ["Sein", "mil\u00b7des", "Va\u00b7ter\u00b7hertz", "war", "noch", "so", "wol", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.632": {"text": "Da\u00df es durch mich/ glaub nur/ des Davids", "tokens": ["Da\u00df", "es", "durch", "mich", "/", "glaub", "nur", "/", "des", "Da\u00b7vids"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPER", "$(", "VVFIN", "ADV", "$(", "ART", "NE"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.633": {"text": "Denn da mirs war gesagt/ und du in vollem", "tokens": ["Denn", "da", "mirs", "war", "ge\u00b7sagt", "/", "und", "du", "in", "vol\u00b7lem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "NE", "VAFIN", "VVPP", "$(", "KON", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.634": {"text": "Da du schon halb-berauscht bey deinem H\u00fcrten-", "tokens": ["Da", "du", "schon", "halb\u00b7be\u00b7rauscht", "bey", "dei\u00b7nem", "H\u00fcr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.635": {"text": "Macht\u2019 ich mich eilends auf/ nahm Speis\u2019 und", "tokens": ["Macht'", "ich", "mich", "ei\u00b7lends", "auf", "/", "nahm", "Speis'", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "$(", "VVFIN", "NN", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.636": {"text": "Und zog/ dir unbewust/ durch unsre Hinder-", "tokens": ["Und", "zog", "/", "dir", "un\u00b7be\u00b7wust", "/", "durch", "uns\u00b7re", "Hin\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$(", "PPER", "ADJD", "$(", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.637": {"text": "Mit dem Gesinde fort/ des Davids Heer\u2019 ent-", "tokens": ["Mit", "dem", "Ge\u00b7sin\u00b7de", "fort", "/", "des", "Da\u00b7vids", "Heer'", "ent"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$(", "ART", "NE", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.638": {"text": "Ich rief den H\u00f6chsten an/ der gab Genad\u2019 und", "tokens": ["Ich", "rief", "den", "H\u00f6chs\u00b7ten", "an", "/", "der", "gab", "Ge\u00b7nad'", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$(", "ART", "VVFIN", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.639": {"text": "Da\u00df ich war angenehm/ Gott lob/ bey jeder-", "tokens": ["Da\u00df", "ich", "war", "an\u00b7ge\u00b7nehm", "/", "Gott", "lob", "/", "bey", "je\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "$(", "NN", "NN", "$(", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.640": {"text": "Da\u00df mein dem\u00fctig Wort des Davids Hertz", "tokens": ["Da\u00df", "mein", "de\u00b7m\u00fc\u00b7tig", "Wort", "des", "Da\u00b7vids", "Hertz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJD", "NN", "ART", "NE", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.641": {"text": "Ich weint\u2019/ ich fleht\u2019/ ich bat\u2019/ ich fiel vor Jhme", "tokens": ["Ich", "weint'", "/", "ich", "fleht'", "/", "ich", "bat'", "/", "ich", "fiel", "vor", "Jh\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.642": {"text": "Ich gab ihm das Geschenk/ damit vers\u00f6hnt\u2019 ich", "tokens": ["Ich", "gab", "ihm", "das", "Ge\u00b7schenk", "/", "da\u00b7mit", "ver\u00b7s\u00f6hnt'", "ich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$(", "PAV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.643": {"text": "Was du mit deinem Trotz in das Gewehr ge-", "tokens": ["Was", "du", "mit", "dei\u00b7nem", "Trotz", "in", "das", "Ge\u00b7wehr", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.644": {"text": "Es ist nun wieder Fried\u2019/ und alles gut ge-", "tokens": ["Es", "ist", "nun", "wie\u00b7der", "Fried'", "/", "und", "al\u00b7les", "gut", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "NE", "$(", "KON", "PIS", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.645": {"text": "Wolan! so la\u00df uns nun den H\u00f6chsten dankbar", "tokens": ["Wo\u00b7lan", "!", "so", "la\u00df", "uns", "nun", "den", "H\u00f6chs\u00b7ten", "dank\u00b7bar"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "VVIMP", "PPER", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.646": {"text": "Da\u00df Er sein Vaterhertz hat wollen uns erweisen/", "tokens": ["Da\u00df", "Er", "sein", "Va\u00b7ter\u00b7hertz", "hat", "wol\u00b7len", "uns", "er\u00b7wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.647": {"text": "Und sonderlich dank du/ da\u00df seine Wunder-", "tokens": ["Und", "son\u00b7der\u00b7lich", "dank", "du", "/", "da\u00df", "sei\u00b7ne", "Wun\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PPER", "$(", "KOUS", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.648": {"text": "Solch schrekklich Ungel\u00fckk hat von dir abge-", "tokens": ["Solch", "schrek\u00b7klich", "Un\u00b7ge\u00b7l\u00fckk", "hat", "von", "dir", "ab\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADJD", "NN", "VAFIN", "APPR", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.649": {"text": "Dir hette Davids Zorn/ und sein ergrimmte", "tokens": ["Dir", "het\u00b7te", "Da\u00b7vids", "Zorn", "/", "und", "sein", "er\u00b7grimm\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NE", "NN", "$(", "KON", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.650": {"text": "Gezeiget/ wie du solst bewehrte Leute spotten/", "tokens": ["Ge\u00b7zei\u00b7get", "/", "wie", "du", "solst", "be\u00b7wehr\u00b7te", "Leu\u00b7te", "spot\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "PWAV", "PPER", "VMFIN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.651": {"text": "Man hette dich gelehrt was K\u00f6nigschimpfen", "tokens": ["Man", "het\u00b7te", "dich", "ge\u00b7lehrt", "was", "K\u00f6\u00b7nig\u00b7schimp\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "VVPP", "PWS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.652": {"text": "Dr\u00fcm dank dem lieben GOtt: Das Wetter ist", "tokens": ["Dr\u00fcm", "dank", "dem", "lie\u00b7ben", "Gott", ":", "Das", "Wet\u00b7ter", "ist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$.", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.653": {"text": "Mit Schaden wird man klug. Ach zwinge die", "tokens": ["Mit", "Scha\u00b7den", "wird", "man", "klug", ".", "Ach", "zwin\u00b7ge", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "PIS", "ADJD", "$.", "ITJ", "VVFIN", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.654": {"text": "Und \u00e4ndre deinen Sinn/ ach lerne kl\u00fcger werden/", "tokens": ["Und", "\u00e4nd\u00b7re", "dei\u00b7nen", "Sinn", "/", "ach", "ler\u00b7ne", "kl\u00fc\u00b7ger", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$(", "ADV", "VVFIN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.655": {"text": "Da\u00df du nicht wieder\u00fcm k\u00f6mmst in solch Unge-", "tokens": ["Da\u00df", "du", "nicht", "wie\u00b7de\u00b7r\u00fcm", "k\u00f6mmst", "in", "solch", "Un\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.656": {"text": "Ich rahte noch einmal/ la\u00df von der Thorheit", "tokens": ["Ich", "rah\u00b7te", "noch", "ein\u00b7mal", "/", "la\u00df", "von", "der", "Thor\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$(", "VVIMP", "APPR", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.657": {"text": "Als Nabal gantz beteubt die\u00df alles eingenommen/", "tokens": ["Als", "Na\u00b7bal", "gantz", "be\u00b7teubt", "die\u00df", "al\u00b7les", "ein\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "VVFIN", "PDS", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.658": {"text": "Was vor ein Ungel\u00fckk\u2019 hett auf ihn sollen kom-", "tokens": ["Was", "vor", "ein", "Un\u00b7ge\u00b7l\u00fc\u00b7kk'", "hett", "auf", "ihn", "sol\u00b7len", "kom"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "VAFIN", "APPR", "PPER", "VMFIN", "TRUNC"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.659": {"text": "Erschrakk er heftig sehr/ Er fiel in Ohnmacht", "tokens": ["Er\u00b7schrakk", "er", "hef\u00b7tig", "sehr", "/", "Er", "fiel", "in", "Ohn\u00b7macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PPER", "ADJD", "ADV", "$(", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.660": {"text": "Verlohr in solcher Angst Gedanken/ Muht und", "tokens": ["Ver\u00b7lohr", "in", "sol\u00b7cher", "Angst", "Ge\u00b7dan\u00b7ken", "/", "Muht", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "PIAT", "NN", "NN", "$(", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.661": {"text": "Als ihm die Schwachheit nun war wieder\u00fcm", "tokens": ["Als", "ihm", "die", "Schwach\u00b7heit", "nun", "war", "wie\u00b7de\u00b7r\u00fcm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VAFIN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.662": {"text": "Hat Er/ den Fall nicht gro\u00df zu f\u00fcrchten/ ange-", "tokens": ["Hat", "Er", "/", "den", "Fall", "nicht", "gro\u00df", "zu", "f\u00fcrch\u00b7ten", "/", "an\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "$(", "ART", "NN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$(", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.663": {"text": "Wie schrekklich er auch war: Er schlug es aus", "tokens": ["Wie", "schrek\u00b7klich", "er", "auch", "war", ":", "Er", "schlug", "es", "aus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "VAFIN", "$.", "PPER", "VVFIN", "PPER", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.664": {"text": "Meynt da\u00df Abigail es nur so gro\u00df gemacht.", "tokens": ["Meynt", "da\u00df", "A\u00b7bi\u00b7gail", "es", "nur", "so", "gro\u00df", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "NE", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.665": {"text": "Er zweifelt ob es auch sey alles so geschehen/", "tokens": ["Er", "zwei\u00b7felt", "ob", "es", "auch", "sey", "al\u00b7les", "so", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "ADV", "VAFIN", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.666": {"text": "Wie sie ihm vorgesagt/ Er wil es nicht gestehen/", "tokens": ["Wie", "sie", "ihm", "vor\u00b7ge\u00b7sagt", "/", "Er", "wil", "es", "nicht", "ge\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVPP", "$(", "PPER", "VMFIN", "PPER", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.667": {"text": "Verneinet da\u00df er hab\u2019 ein solchen Fehl gethan/", "tokens": ["Ver\u00b7nei\u00b7net", "da\u00df", "er", "hab'", "ein", "sol\u00b7chen", "Fehl", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "PPER", "VAFIN", "ART", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.668": {"text": "Er schl\u00e4gt es in den Wind/ und denket kaum", "tokens": ["Er", "schl\u00e4gt", "es", "in", "den", "Wind", "/", "und", "den\u00b7ket", "kaum"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.669": {"text": "Er beist da\u00df Sie so viel an Vorraht weggewen-", "tokens": ["Er", "beist", "da\u00df", "Sie", "so", "viel", "an", "Vor\u00b7raht", "weg\u00b7ge\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "ADV", "ADV", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.670": {"text": "Und dankt ihr nicht/ da\u00df Sie das Ungl\u00fckk abge-", "tokens": ["Und", "dankt", "ihr", "nicht", "/", "da\u00df", "Sie", "das", "Un\u00b7gl\u00fckk", "ab\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$(", "KOUS", "PPER", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.671": {"text": "Und was das \u00e4rgste war/ Er ist so blind ge-", "tokens": ["Und", "was", "das", "\u00e4rgs\u00b7te", "war", "/", "Er", "ist", "so", "blind", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ART", "ADJA", "VAFIN", "$(", "PPER", "VAFIN", "ADV", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.672": {"text": "Er schl\u00e4gt des H\u00f6chsten Gnad\u2019 und Beystand", "tokens": ["Er", "schl\u00e4gt", "des", "H\u00f6chs\u00b7ten", "Gnad'", "und", "Beys\u00b7tand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.673": {"text": "Dr\u00fcm wirft ihn Gottes Hand ins Siechbett wie-", "tokens": ["Dr\u00fcm", "wirft", "ihn", "Got\u00b7tes", "Hand", "ins", "Siech\u00b7bett", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "NN", "NN", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.674": {"text": "Weil keine Bessrung da: Es werden alle Glieder", "tokens": ["Weil", "kei\u00b7ne", "Bess\u00b7rung", "da", ":", "Es", "wer\u00b7den", "al\u00b7le", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.675": {"text": "An ihme matt und schwach/ hat weder Rast", "tokens": ["An", "ih\u00b7me", "matt", "und", "schwach", "/", "hat", "we\u00b7der", "Rast"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "ADJD", "KON", "ADJD", "$(", "VAFIN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.676": {"text": "Die Lebenskrafft nimmt ab; Die Krankheit", "tokens": ["Die", "Le\u00b7bens\u00b7krafft", "nimmt", "ab", ";", "Die", "Krank\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.677": {"text": "Als nun der Sonnen Liecht war neunmal aufge-", "tokens": ["Als", "nun", "der", "Son\u00b7nen", "Liecht", "war", "neun\u00b7mal", "auf\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "VAFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.678": {"text": "Und kaum/ zum zehndenmal zu scheinen/ ange-", "tokens": ["Und", "kaum", "/", "zum", "zehn\u00b7den\u00b7mal", "zu", "schei\u00b7nen", "/", "an\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "$(", "APPRART", "ADV", "PTKZU", "VVINF", "$(", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.679": {"text": "Kam Nabals End\u2019 herbey/ da schied\u2019 er ab/ und", "tokens": ["Kam", "Na\u00b7bals", "End'", "her\u00b7bey", "/", "da", "schied'", "er", "ab", "/", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["NE", "NE", "NN", "PTKVZ", "$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$(", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.680": {"text": "Da er vor gro\u00dfes Gut/ ein enges Grab erwarb.", "tokens": ["Da", "er", "vor", "gro\u00b7\u00dfes", "Gut", "/", "ein", "en\u00b7ges", "Grab", "er\u00b7warb", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.681": {"text": "Seht hier ein Beyspiel an: Den stets die Gold-", "tokens": ["Seht", "hier", "ein", "Bey\u00b7spiel", "an", ":", "Den", "stets", "die", "Gold"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$.", "ART", "ADV", "ART", "TRUNC"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.682": {"text": "Der alles Gut und Geld zusammen scharrt und", "tokens": ["Der", "al\u00b7les", "Gut", "und", "Geld", "zu\u00b7sam\u00b7men", "scharrt", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADJD", "KON", "NN", "ADV", "VVFIN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.683": {"text": "Der bringt itzt nichts als ein schlecht Todten-", "tokens": ["Der", "bringt", "itzt", "nichts", "als", "ein", "schlecht", "Tod\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PIS", "KOKOM", "ART", "ADJD", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.684": {"text": "Ein ewigs Schandger\u00fccht\u2019 ist seiner Thorheit", "tokens": ["Ein", "e\u00b7wigs", "Schand\u00b7ge\u00b7r\u00fccht'", "ist", "sei\u00b7ner", "Thor\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.685": {"text": "Es wird bald laut und kund/ da\u00df Nabal war ge-", "tokens": ["Es", "wird", "bald", "laut", "und", "kund", "/", "da\u00df", "Na\u00b7bal", "war", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "PTKVZ", "$(", "KOUS", "NE", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.686": {"text": "Und da\u00df Abigail die Freyheit hatt\u2019 erworben/", "tokens": ["Und", "da\u00df", "A\u00b7bi\u00b7gail", "die", "Frey\u00b7heit", "hatt'", "er\u00b7wor\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.687": {"text": "Die Fama blie\u00df es aus und macht\u2019 es offenbar/", "tokens": ["Die", "Fa\u00b7ma", "blie\u00df", "es", "aus", "und", "macht'", "es", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.688": {"text": "Dem Kenas erst/ als er auf seiner Nachtwach", "tokens": ["Dem", "Ke\u00b7nas", "erst", "/", "als", "er", "auf", "sei\u00b7ner", "Nacht\u00b7wach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$(", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.689": {"text": "Er war ein tapfrer Mann/ und hatte Davids", "tokens": ["Er", "war", "ein", "tapf\u00b7rer", "Mann", "/", "und", "hat\u00b7te", "Da\u00b7vids"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "KON", "VAFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.690": {"text": "Verfolgung/ Kreutz und Leid getreulich helfen", "tokens": ["Ver\u00b7fol\u00b7gung", "/", "Kreutz", "und", "Leid", "ge\u00b7treu\u00b7lich", "hel\u00b7fen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "KON", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.691": {"text": "Die Reihe war an ihm und muste Schildwach", "tokens": ["Die", "Rei\u00b7he", "war", "an", "ihm", "und", "mus\u00b7te", "Schild\u00b7wach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "KON", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.692": {"text": "Da\u00df nicht der schlauhe Feind Sie m\u00f6chte hin-", "tokens": ["Da\u00df", "nicht", "der", "schlau\u00b7he", "Feind", "Sie", "m\u00f6ch\u00b7te", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "PPER", "VMFIN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.693": {"text": "Er wandelt\u2019 an dem Berg\u2019/ Er gteng da auf und", "tokens": ["Er", "wan\u00b7delt'", "an", "dem", "Ber\u00b7g'", "/", "Er", "gteng", "da", "auf", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "PPER", "VVFIN", "ADV", "PTKVZ", "KON"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.694": {"text": "Er sah sich munter \u00fcm/ und schauet\u2019 hin und wie-", "tokens": ["Er", "sah", "sich", "mun\u00b7ter", "\u00fcm", "/", "und", "schau\u00b7et'", "hin", "und", "wie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "$(", "KON", "VVFIN", "PTKVZ", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.695": {"text": "Und da\u00df der sanfte Schlaff ihn ja nicht \u00fcber-", "tokens": ["Und", "da\u00df", "der", "sanf\u00b7te", "Schlaff", "ihn", "ja", "nicht", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "PPER", "ADV", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.696": {"text": "F\u00e4ngt er ein Lied ehen an/ und singt mit srohem", "tokens": ["F\u00e4ngt", "er", "ein", "Lied", "e\u00b7hen", "an", "/", "und", "singt", "mit", "sro\u00b7hem"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "APPR", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}}}}