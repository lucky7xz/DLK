{"dta.poem.23854": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Gedancken \u00fcber etliche Ma\u00dfqven in einer  \n Wirthschafft 1682.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Mein lieber Bruder z\u00fcrne nicht/", "tokens": ["Mein", "lie\u00b7ber", "Bru\u00b7der", "z\u00fcr\u00b7ne", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wann mir Zeit und Lust gebricht/", "tokens": ["Da\u00df", "wann", "mir", "Zeit", "und", "Lust", "ge\u00b7bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich nicht an Schreiben dencke:", "tokens": ["Ich", "nicht", "an", "Schrei\u00b7ben", "den\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du weist da\u00df ich dein Diener bin/", "tokens": ["Du", "weist", "da\u00df", "ich", "dein", "Die\u00b7ner", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und unterdessen meinen Sinn", "tokens": ["Und", "un\u00b7ter\u00b7des\u00b7sen", "mei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf dich nach Dessau lencke.", "tokens": ["Auf", "dich", "nach", "Des\u00b7sau", "len\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.2": {"line.1": {"text": "Seit dem du weggereiset bist", "tokens": ["Seit", "dem", "du", "weg\u00b7ge\u00b7rei\u00b7set", "bist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spricht man alhier ohne arge List", "tokens": ["Spricht", "man", "al\u00b7hier", "oh\u00b7ne", "ar\u00b7ge", "List"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Von vielen neuen Dingen", "tokens": ["Von", "vie\u00b7len", "neu\u00b7en", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Davon ich nach der Meister Art/", "tokens": ["Da\u00b7von", "ich", "nach", "der", "Meis\u00b7ter", "Art", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und zwar in Knittel-Verschen zart/", "tokens": ["Und", "zwar", "in", "Knit\u00b7tel\u00b7Ver\u00b7schen", "zart", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir etwas vor wil singen.", "tokens": ["Dir", "et\u00b7was", "vor", "wil", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Merckt Christen was der Teuffel thut/", "tokens": ["Merckt", "Chris\u00b7ten", "was", "der", "Teuf\u00b7fel", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PWS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den - - - das gute Blut", "tokens": ["Den", "das", "gu\u00b7te", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$(", "$(", "$(", "ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Hat - - - todt gestochen;", "tokens": ["Hat", "todt", "ge\u00b7sto\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "$(", "$(", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "So gehts wann uns der Wein erhitzt/", "tokens": ["So", "gehts", "wann", "uns", "der", "Wein", "er\u00b7hitzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PWAV", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch meint man der Gefangen sitzt", "tokens": ["Doch", "meint", "man", "der", "Ge\u00b7fan\u00b7gen", "sitzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kan werden lo\u00df gesprochen.", "tokens": ["Kan", "wer\u00b7den", "lo\u00df", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der - von - - Lobesan", "tokens": ["Der", "von", "Lo\u00b7be\u00b7san"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "$(", "APPR", "$(", "$(", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Kam hier vergangenen Sontag an/", "tokens": ["Kam", "hier", "ver\u00b7gan\u00b7ge\u00b7nen", "Son\u00b7tag", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJA", "NN", "PTKVZ", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Da er die Post gefahren", "tokens": ["Da", "er", "die", "Post", "ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von Dantzig an bis nach Bernau/", "tokens": ["Von", "Dant\u00b7zig", "an", "bis", "nach", "Bern\u00b7au", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "KON", "APPR", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und will sich/ lieber Leser schau/", "tokens": ["Und", "will", "sich", "/", "lie\u00b7ber", "Le\u00b7ser", "schau", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "$(", "ADV", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit einer Witwe paaren.", "tokens": ["Mit", "ei\u00b7ner", "Wit\u00b7we", "paa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "So offt er den Magnet ansieht/", "tokens": ["So", "offt", "er", "den", "Mag\u00b7net", "an\u00b7sieht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Der ihn so kr\u00e4fftig an sich zieht/", "tokens": ["Der", "ihn", "so", "kr\u00e4ff\u00b7tig", "an", "sich", "zieht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Macht er verliebte Minen/", "tokens": ["Macht", "er", "ver\u00b7lieb\u00b7te", "Mi\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Und singt in dulci Jubilo;", "tokens": ["Und", "singt", "in", "dul\u00b7ci", "Ju\u00b7bi\u00b7lo", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sonst h\u00e4lt er sich incognito", "tokens": ["Sonst", "h\u00e4lt", "er", "sich", "in\u00b7co\u00b7gni\u00b7to"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und l\u00e4\u00dft sich nicht bedienen.", "tokens": ["Und", "l\u00e4\u00dft", "sich", "nicht", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "- - - welcher manche Nacht", "tokens": ["wel\u00b7cher", "man\u00b7che", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["$(", "$(", "$(", "PRELS", "PIAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Mit der Bassette zugebracht", "tokens": ["Mit", "der", "Bas\u00b7set\u00b7te", "zu\u00b7ge\u00b7bracht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Und ward von der Trabanten Schaar", "tokens": ["Und", "ward", "von", "der", "Tra\u00b7ban\u00b7ten", "Schaar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Sachsen/ glaube mir f\u00fcrwahr/", "tokens": ["Nach", "Sach\u00b7sen", "/", "glau\u00b7be", "mir", "f\u00fcr\u00b7wahr", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$(", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Begleitet auf der Strassen.", "tokens": ["Be\u00b7glei\u00b7tet", "auf", "der", "Stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Des - - - seinem Secret-", "tokens": ["Des", "sei\u00b7nem", "Se\u00b7cret"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "$(", "$(", "$(", "PPOSAT", "TRUNC"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Ario es nicht besser geht", "tokens": ["A\u00b7rio", "es", "nicht", "bes\u00b7ser", "geht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "PTKNEG", "ADJD", "VVFIN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "In Z\u00fcchten und in Ehren/", "tokens": ["In", "Z\u00fcch\u00b7ten", "und", "in", "Eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So bald der Chur-F\u00fcrst sprach ein Wort", "tokens": ["So", "bald", "der", "Chur\u00b7F\u00fcrst", "sprach", "ein", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zog er in wenig Stunden fort", "tokens": ["Zog", "er", "in", "we\u00b7nig", "Stun\u00b7den", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Warum/ die Zeit wirds lehren.", "tokens": ["Wa\u00b7rum", "/", "die", "Zeit", "wirds", "leh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Der Cammer-Juncker - - zu letzt", "tokens": ["Der", "Cam\u00b7mer\u00b7Jun\u00b7cker", "zu", "letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "$(", "APPR", "ADV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Starb/ und ward zierlich beygesetzt/", "tokens": ["Starb", "/", "und", "ward", "zier\u00b7lich", "bey\u00b7ge\u00b7setzt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KON", "VAFIN", "ADJD", "VVPP", "$("], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dazu viel Volck gebeten", "tokens": ["Da\u00b7zu", "viel", "Volck", "ge\u00b7be\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Tod von diesem armen Hahn", "tokens": ["Der", "Tod", "von", "die\u00b7sem", "ar\u00b7men", "Hahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hat mancher Henne leid gethan", "tokens": ["Hat", "man\u00b7cher", "Hen\u00b7ne", "leid", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die er noch solte treten.", "tokens": ["Die", "er", "noch", "sol\u00b7te", "tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Eins mu\u00df ich melden zum Beschlu\u00df", "tokens": ["Eins", "mu\u00df", "ich", "mel\u00b7den", "zum", "Be\u00b7schlu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du findest einen sch\u00f6nen Gru\u00df", "tokens": ["Du", "fin\u00b7dest", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Gru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Alhier von meiner Frauen/", "tokens": ["Al\u00b7hier", "von", "mei\u00b7ner", "Frau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Fr\u00e4ulein - - - in Geb\u00fchr", "tokens": ["Die", "Fr\u00e4u\u00b7lein", "in", "Ge\u00b7b\u00fchr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "$(", "$(", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Verlanget ebenfals dich hier", "tokens": ["Ver\u00b7lan\u00b7get", "e\u00b7ben\u00b7fals", "dich", "hier"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bald wieder anzuschauen.", "tokens": ["Bald", "wie\u00b7der", "an\u00b7zu\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Datum Berlin den 12ten Tag", "tokens": ["Da\u00b7tum", "Ber\u00b7lin", "den", "12\u00b7ten", "Tag"], "token_info": ["word", "word", "word", "number_compound", "word"], "pos": ["PAV", "NE", "ART", "ADJA", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Des Monats da man Erndten mag/", "tokens": ["Des", "Mo\u00b7nats", "da", "man", "Ernd\u00b7ten", "mag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Jahre da man schreibet", "tokens": ["Im", "Jah\u00b7re", "da", "man", "schrei\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Tausent Sechshundert Achtzig Acht.", "tokens": ["Tau\u00b7sent", "Sechs\u00b7hun\u00b7dert", "Acht\u00b7zig", "Acht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "CARD", "CARD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Adjeu der sey zum Schelm gemacht", "tokens": ["Ad\u00b7jeu", "der", "sey", "zum", "Schelm", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "VAFIN", "APPRART", "NN", "VVPP"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Der nicht getreu verbleibet.", "tokens": ["Der", "nicht", "ge\u00b7treu", "ver\u00b7blei\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}