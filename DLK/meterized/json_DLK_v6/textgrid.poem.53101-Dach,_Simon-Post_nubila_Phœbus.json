{"textgrid.poem.53101": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Post nubila Ph\u0153bus", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sol mein Geist geb\u00fccket gehen", "tokens": ["Sol", "mein", "Geist", "ge\u00b7b\u00fc\u00b7cket", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "VVPP", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd ohn alle Hoffnung stehen,", "tokens": ["Vnd", "ohn", "al\u00b7le", "Hoff\u00b7nung", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ein Vngl\u00fcck an mich setzt?", "tokens": ["Wenn", "ein", "Vn\u00b7gl\u00fcck", "an", "mich", "setzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sol ich zagen in den N\u00f6then,", "tokens": ["Sol", "ich", "za\u00b7gen", "in", "den", "N\u00f6\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ein Vnfall mich zu t\u00f6dten", "tokens": ["Wenn", "ein", "Vn\u00b7fall", "mich", "zu", "t\u00f6d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grimmig seine Z\u00e4hne wetzt?", "tokens": ["Grim\u00b7mig", "sei\u00b7ne", "Z\u00e4h\u00b7ne", "wetzt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Nein, ich wil zu keiner seiten", "tokens": ["Nein", ",", "ich", "wil", "zu", "kei\u00b7ner", "sei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "APPR", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Au\u00df der Wei\u00dfheit Wege schreiten,", "tokens": ["Au\u00df", "der", "Wei\u00df\u00b7heit", "We\u00b7ge", "schrei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern fleissig mein Geh\u00f6r", "tokens": ["Son\u00b7dern", "fleis\u00b7sig", "mein", "Ge\u00b7h\u00f6r"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihrer g\u00fcldnen Rede leihen,", "tokens": ["Ih\u00b7rer", "g\u00fcld\u00b7nen", "Re\u00b7de", "lei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie wird meinen Geist befreyen", "tokens": ["Sie", "wird", "mei\u00b7nen", "Geist", "be\u00b7fre\u00b7yen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVINF"], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Durch die Edle Zucht vnd Lehr.", "tokens": ["Durch", "die", "Ed\u00b7le", "Zucht", "vnd", "Lehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ob ich noch so sehr mich fresse", "tokens": ["Ob", "ich", "noch", "so", "sehr", "mich", "fres\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd mein Leiden stets ermesse,", "tokens": ["Vnd", "mein", "Lei\u00b7den", "stets", "er\u00b7mes\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6rt es durch die\u00df Mittel auff?", "tokens": ["H\u00f6rt", "es", "durch", "die\u00df", "Mit\u00b7tel", "auff", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PDS", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja! so wenig ich der Winde", "tokens": ["Ja", "!", "so", "we\u00b7nig", "ich", "der", "Win\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADV", "PIS", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Brausen durch mein Schelten binde,", "tokens": ["Brau\u00b7sen", "durch", "mein", "Schel\u00b7ten", "bin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd der Str\u00f6me schnellen Lauff.", "tokens": ["Vnd", "der", "Str\u00f6\u00b7me", "schnel\u00b7len", "Lauff", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie wir sehn die Wolcken fliehen", "tokens": ["Wie", "wir", "sehn", "die", "Wol\u00b7cken", "flie\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd sie vber vns hinziehen,", "tokens": ["Vnd", "sie", "vber", "vns", "hin\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wehren aber jhnen nicht:", "tokens": ["Weh\u00b7ren", "a\u00b7ber", "jh\u00b7nen", "nicht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Also kan des Menschen Gr\u00e4men", "tokens": ["Al\u00b7so", "kan", "des", "Men\u00b7schen", "Gr\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nichts von seinem Leiden nehmen,", "tokens": ["Nichts", "von", "sei\u00b7nem", "Lei\u00b7den", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn es gifftig auff jhn sticht.", "tokens": ["Wenn", "es", "giff\u00b7tig", "auff", "jhn", "sticht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Welcher nur in b\u00f6sen F\u00e4llen", "tokens": ["Wel\u00b7cher", "nur", "in", "b\u00f6\u00b7sen", "F\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAT", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich so kl\u00fcglich wei\u00df zu stellen,", "tokens": ["Sich", "so", "kl\u00fcg\u00b7lich", "wei\u00df", "zu", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als gieng' jhm sein Leid nicht an,", "tokens": ["Als", "gieng'", "jhm", "sein", "Leid", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVIMP", "PPER", "PPOSAT", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Schawet wie mit frembdem Hertzen", "tokens": ["Scha\u00b7wet", "wie", "mit", "fremb\u00b7dem", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auff das w\u00fcten seiner Schmertzen,", "tokens": ["Auff", "das", "w\u00fc\u00b7ten", "sei\u00b7ner", "Schmert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist am allerbesten dran.", "tokens": ["Ist", "am", "al\u00b7ler\u00b7bes\u00b7ten", "dran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "ADJA", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Edle Hengste von Gebl\u00fcte", "tokens": ["Ed\u00b7le", "Hengs\u00b7te", "von", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Traben fort, es bell' vnd w\u00fcte", "tokens": ["Tra\u00b7ben", "fort", ",", "es", "bell'", "vnd", "w\u00fc\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "PPER", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie der Hund auch jmmer wil;", "tokens": ["Wie", "der", "Hund", "auch", "jm\u00b7mer", "wil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wer sich an das Gl\u00fcck wil kehren,", "tokens": ["Wer", "sich", "an", "das", "Gl\u00fcck", "wil", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn es k\u00f6mpt jhn zu gef\u00e4hren,", "tokens": ["Wenn", "es", "k\u00f6mpt", "jhn", "zu", "ge\u00b7f\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kennet nicht der Wei\u00dfheit Ziel.", "tokens": ["Ken\u00b7net", "nicht", "der", "Wei\u00df\u00b7heit", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wer zu sehr die Nase schn\u00e4utzet", "tokens": ["Wer", "zu", "sehr", "die", "Na\u00b7se", "schn\u00e4ut\u00b7zet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKA", "ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd die Hunde t\u00f6richt reitzet,", "tokens": ["Vnd", "die", "Hun\u00b7de", "t\u00f6\u00b7richt", "reit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gehet blutig offt davon:", "tokens": ["Ge\u00b7het", "blu\u00b7tig", "offt", "da\u00b7von", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die der Noht durch stetes weinen", "tokens": ["Die", "der", "Noht", "durch", "ste\u00b7tes", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPR", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bald sich abzuhelffen meinen,", "tokens": ["Bald", "sich", "ab\u00b7zu\u00b7hel\u00b7ffen", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVIZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Haben duppelt Leid zu lohn.", "tokens": ["Ha\u00b7ben", "dup\u00b7pelt", "Leid", "zu", "lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Endlich wird das Vngl\u00fcck brechen", "tokens": ["End\u00b7lich", "wird", "das", "Vn\u00b7gl\u00fcck", "bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd jhm selbst die Kr\u00e4ffte schwechen,", "tokens": ["Vnd", "jhm", "selbst", "die", "Kr\u00e4ff\u00b7te", "schwe\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch die nimmer-stille-Zeit,", "tokens": ["Durch", "die", "nim\u00b7mer\u00b7stil\u00b7le\u00b7Zeit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Welche, wie sie allen Dingen", "tokens": ["Wel\u00b7che", ",", "wie", "sie", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAT", "$,", "PWAV", "PPER", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sol vnd mu\u00df die Endschafft bringen,", "tokens": ["Sol", "vnd", "mu\u00df", "die", "End\u00b7schafft", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Also auch der Trawrigkeit.", "tokens": ["Al\u00b7so", "auch", "der", "Traw\u00b7rig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Da denn offt das tieffste Leiden", "tokens": ["Da", "denn", "offt", "das", "tieffs\u00b7te", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Wird ersetzt mit tausend Frewden,", "tokens": ["Wird", "er\u00b7setzt", "mit", "tau\u00b7send", "Frew\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welches vns denn s\u00e4nffter thut,", "tokens": ["Wel\u00b7ches", "vns", "denn", "s\u00e4nff\u00b7ter", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als wenn wir nur stets in L\u00fcsten", "tokens": ["Als", "wenn", "wir", "nur", "stets", "in", "L\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Nichts von Noht zu sagen w\u00fcsten,", "tokens": ["Nichts", "von", "Noht", "zu", "sa\u00b7gen", "w\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Frisch am Leibe, reich am Gut.", "tokens": ["Frisch", "am", "Lei\u00b7be", ",", "reich", "am", "Gut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$,", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Nach des Winters kalten Winden", "tokens": ["Nach", "des", "Win\u00b7ters", "kal\u00b7ten", "Win\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df die Vorjahrs-Lufft sich finden", "tokens": ["Mu\u00df", "die", "Vor\u00b7jahr\u00b7sLufft", "sich", "fin\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd die gr\u00fcne Sommer-Zier:", "tokens": ["Vnd", "die", "gr\u00fc\u00b7ne", "Som\u00b7mer\u00b7Zier", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach den harten Donnerschl\u00e4gen,", "tokens": ["Nach", "den", "har\u00b7ten", "Don\u00b7ner\u00b7schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nach den Wolcken vnd dem Regen", "tokens": ["Nach", "den", "Wol\u00b7cken", "vnd", "dem", "Re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "K\u00f6mpt die g\u00fcldne Sonn' herf\u00fcr.", "tokens": ["K\u00f6mpt", "die", "g\u00fcld\u00b7ne", "Sonn'", "her\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Letzlich pflegen wir zu lachen", "tokens": ["Letz\u00b7lich", "pfle\u00b7gen", "wir", "zu", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der vorhin betr\u00fcbten Sachen,", "tokens": ["Der", "vor\u00b7hin", "be\u00b7tr\u00fcb\u00b7ten", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd erzwingen diesen Schluss:", "tokens": ["Vnd", "er\u00b7zwin\u00b7gen", "die\u00b7sen", "Schluss", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wer der Wei\u00dfheit nachzukommen", "tokens": ["Wer", "der", "Wei\u00df\u00b7heit", "nach\u00b7zu\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "VVIZU"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sich bem\u00fcht, hat diesen frommen,", "tokens": ["Sich", "be\u00b7m\u00fcht", ",", "hat", "die\u00b7sen", "from\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "VAFIN", "PDAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df jhm alles dienen mu\u00df.", "tokens": ["Da\u00df", "jhm", "al\u00b7les", "die\u00b7nen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}