{"textgrid.poem.59534": {"metadata": {"author": {"name": "Arndt, Ernst Moritz", "birth": "N.A.", "death": "N.A."}, "title": "9.", "genre": "verse", "period": "N.A.", "pub_year": 1814, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir wandeln hier in Finsternissen", "tokens": ["Wir", "wan\u00b7deln", "hier", "in", "Fins\u00b7ter\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und schaun vergebens nach dem Licht;", "tokens": ["Und", "schaun", "ver\u00b7ge\u00b7bens", "nach", "dem", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht tr\u00f6sten mag uns, was wir wissen", "tokens": ["Nicht", "tr\u00f6s\u00b7ten", "mag", "uns", ",", "was", "wir", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "VMFIN", "PPER", "$,", "PRELS", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und was wir k\u00f6nnen, helfen nicht:", "tokens": ["Und", "was", "wir", "k\u00f6n\u00b7nen", ",", "hel\u00b7fen", "nicht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VMFIN", "$,", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wickelt ewig auf und ab", "tokens": ["So", "wi\u00b7ckelt", "e\u00b7wig", "auf", "und", "ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich Labyrinth aus Labyrinthen,", "tokens": ["Sich", "La\u00b7by\u00b7rinth", "aus", "La\u00b7by\u00b7rin\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und heute sehen wir verschwinden,", "tokens": ["Und", "heu\u00b7te", "se\u00b7hen", "wir", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was gestern s\u00fc\u00dfe T\u00e4uschung gab.", "tokens": ["Was", "ge\u00b7stern", "s\u00fc\u00b7\u00dfe", "T\u00e4u\u00b7schung", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch liebt der Stolze seine Irre,", "tokens": ["Doch", "liebt", "der", "Stol\u00b7ze", "sei\u00b7ne", "Ir\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Eitle seinen L\u00fcgenschein", "tokens": ["Der", "Eit\u00b7le", "sei\u00b7nen", "L\u00fc\u00b7gen\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wirret in das Truggewirre", "tokens": ["Und", "wir\u00b7ret", "in", "das", "Trug\u00b7ge\u00b7wir\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich jede Stunde fester ein,", "tokens": ["Sich", "je\u00b7de", "Stun\u00b7de", "fes\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verschm\u00e4ht die Wahrheit f\u00fcr Gedicht,", "tokens": ["Ver\u00b7schm\u00e4ht", "die", "Wahr\u00b7heit", "f\u00fcr", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verschm\u00e4ht die Flamme f\u00fcr den Schimmer,", "tokens": ["Ver\u00b7schm\u00e4ht", "die", "Flam\u00b7me", "f\u00fcr", "den", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und hascht und sucht und findet immer,", "tokens": ["Und", "hascht", "und", "sucht", "und", "fin\u00b7det", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Doch ach! sich selber find't er nicht.", "tokens": ["Doch", "ach", "!", "sich", "sel\u00b7ber", "find't", "er", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PRF", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "O du, durch den die Sonnen brennen", "tokens": ["O", "du", ",", "durch", "den", "die", "Son\u00b7nen", "bren\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "APPR", "ART", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und leuchtend durch die Himmel gehn,", "tokens": ["Und", "leuch\u00b7tend", "durch", "die", "Him\u00b7mel", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gott, lehre du mich selbst erkennen", "tokens": ["Gott", ",", "leh\u00b7re", "du", "mich", "selbst", "er\u00b7ken\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und meiner K\u00fcnste Lug verstehn,", "tokens": ["Und", "mei\u00b7ner", "K\u00fcns\u00b7te", "Lug", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O hebe dein dem\u00fctig Kind", "tokens": ["O", "he\u00b7be", "dein", "de\u00b7m\u00fc\u00b7tig", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "ADJD", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Empor mit deinen Liebesarmen", "tokens": ["Em\u00b7por", "mit", "dei\u00b7nen", "Lie\u00b7be\u00b7sar\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und la\u00df sein Herz in dir erwarmen,", "tokens": ["Und", "la\u00df", "sein", "Herz", "in", "dir", "er\u00b7war\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vor dem die Engel Stammler sind.", "tokens": ["Vor", "dem", "die", "En\u00b7gel", "Stamm\u00b7ler", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Aus deines Lichtes reichem Meere", "tokens": ["Aus", "dei\u00b7nes", "Lich\u00b7tes", "rei\u00b7chem", "Mee\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Flo\u00df einst ein einziger Tropfen aus", "tokens": ["Flo\u00df", "einst", "ein", "ein\u00b7zi\u00b7ger", "Trop\u00b7fen", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "APPR"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und z\u00fcndete die Sternenheere", "tokens": ["Und", "z\u00fcn\u00b7de\u00b7te", "die", "Ster\u00b7nen\u00b7hee\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Lampen all im Himmelshaus \u2013", "tokens": ["Und", "Lam\u00b7pen", "all", "im", "Him\u00b7mels\u00b7haus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PIAT", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O einen Funken nur f\u00fcr mich!", "tokens": ["O", "ei\u00b7nen", "Fun\u00b7ken", "nur", "f\u00fcr", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur einen Schimmer von dem Glanze!", "tokens": ["Nur", "ei\u00b7nen", "Schim\u00b7mer", "von", "dem", "Glan\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und droben in dem Sternentanze", "tokens": ["Und", "dro\u00b7ben", "in", "dem", "Ster\u00b7nen\u00b7tan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit allen Seligen preis' ich dich.", "tokens": ["Mit", "al\u00b7len", "Se\u00b7li\u00b7gen", "preis'", "ich", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}