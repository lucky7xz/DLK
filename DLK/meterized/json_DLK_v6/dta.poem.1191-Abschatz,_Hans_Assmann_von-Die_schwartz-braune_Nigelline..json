{"dta.poem.1191": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Die schwartz-braune Nigelline.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.85", "tl:0.14"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Hylas mag nach seinem Sinn ", "tokens": ["Hy\u00b7las", "mag", "nach", "sei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Andre Farben k\u00f6stlich sch\u00e4tzen/", "tokens": ["And\u00b7re", "Far\u00b7ben", "k\u00f6st\u00b7lich", "sch\u00e4t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich mit wei\u00df und roth erg\u00f6tzen;", "tokens": ["Sich", "mit", "wei\u00df", "und", "roth", "er\u00b7g\u00f6t\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "VVFIN", "KON", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwartz ist meine Sch\u00e4fferin.", "tokens": ["Schwartz", "ist", "mei\u00b7ne", "Sch\u00e4f\u00b7fe\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Schwartz vergn\u00fcget meine Seele/", "tokens": ["Schwartz", "ver\u00b7gn\u00fc\u00b7get", "mei\u00b7ne", "See\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwartz soll meine Farbe seyn/", "tokens": ["Schwartz", "soll", "mei\u00b7ne", "Far\u00b7be", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPOSAT", "NN", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bi\u00df des schwartzen Grabes H\u00f6le", "tokens": ["Bi\u00df", "des", "schwart\u00b7zen", "Gra\u00b7bes", "H\u00f6\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schleust den todten C\u00f6rper ein.", "tokens": ["Schleust", "den", "tod\u00b7ten", "C\u00f6r\u00b7per", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Zwar der hellen Augen Licht/", "tokens": ["Zwar", "der", "hel\u00b7len", "Au\u00b7gen", "Licht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Welche Pallas blau gewiesen/", "tokens": ["Wel\u00b7che", "Pal\u00b7las", "blau", "ge\u00b7wie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird von Paris hoch gepriesen/", "tokens": ["Wird", "von", "Pa\u00b7ris", "hoch", "ge\u00b7prie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NE", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber hebt den Apffel nicht:", "tokens": ["A\u00b7ber", "hebt", "den", "Apf\u00b7fel", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Zytheren s\u00fcsses Blicken/", "tokens": ["Der", "Zy\u00b7the\u00b7ren", "s\u00fcs\u00b7ses", "Bli\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die aus ihrer Augen Nacht", "tokens": ["Die", "aus", "ih\u00b7rer", "Au\u00b7gen", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kunte Sonnen-Strahlen schicken/", "tokens": ["Kun\u00b7te", "Son\u00b7nen\u00b7Strah\u00b7len", "schi\u00b7cken", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat den Prei\u00df darvon gebracht.", "tokens": ["Hat", "den", "Prei\u00df", "dar\u00b7von", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PAV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "G\u00f6ldner Locken stoltze Pracht", "tokens": ["G\u00f6ld\u00b7ner", "Lo\u00b7cken", "stolt\u00b7ze", "Pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mag den leichten Nero fangen:", "tokens": ["Mag", "den", "leich\u00b7ten", "Ne\u00b7ro", "fan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bleibt das kl\u00fcgste Wild nicht hangen/", "tokens": ["Bleibt", "das", "kl\u00fcgs\u00b7te", "Wild", "nicht", "han\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo die Schlinge schwartz gemacht?", "tokens": ["Wo", "die", "Schlin\u00b7ge", "schwartz", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Braunes Haar kan auch verdienen/", "tokens": ["Brau\u00b7nes", "Haar", "kan", "auch", "ver\u00b7die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gleich dem gelben/ Zahl und Lied:", "tokens": ["Gleich", "dem", "gel\u00b7ben", "/", "Zahl", "und", "Lied", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zeuge/ wer an Nigellinen", "tokens": ["Zeu\u00b7ge", "/", "wer", "an", "Ni\u00b7gel\u00b7li\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "PWS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein recht w\u00fcrdig Beyspiel sieht.", "tokens": ["Ein", "recht", "w\u00fcr\u00b7dig", "Bey\u00b7spiel", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "R\u00fchmt der rothen Schmincke Zier/", "tokens": ["R\u00fchmt", "der", "ro\u00b7then", "Schmin\u00b7cke", "Zier", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Last die wei\u00dfe Cloris prangen", "tokens": ["Last", "die", "wei\u00b7\u00dfe", "Clo\u00b7ris", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NE", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem Schnee der glatten Wangen;", "tokens": ["Mit", "dem", "Schnee", "der", "glat\u00b7ten", "Wan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwartz allein beliebet mir.", "tokens": ["Schwartz", "al\u00b7lein", "be\u00b7lie\u00b7bet", "mir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Roth mu\u00df von der Sonne bleichen/", "tokens": ["Roth", "mu\u00df", "von", "der", "Son\u00b7ne", "blei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df nimmt ihre Brandmahl an;", "tokens": ["Wei\u00df", "nimmt", "ih\u00b7re", "Brand\u00b7mahl", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ists nicht schwartz/ der Treue Zeichen/", "tokens": ["Ists", "nicht", "schwartz", "/", "der", "Treu\u00b7e", "Zei\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADJD", "$(", "ART", "NN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das sich nimmer \u00e4ndern kan.", "tokens": ["Das", "sich", "nim\u00b7mer", "\u00e4n\u00b7dern", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Schw\u00e4rzt der blaue Himmel nicht/", "tokens": ["Schw\u00e4rzt", "der", "blau\u00b7e", "Him\u00b7mel", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKNEG", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu der Thetis lassen tragen/", "tokens": ["Zu", "der", "The\u00b7tis", "las\u00b7sen", "tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein gebr\u00e4untes Angesicht.", "tokens": ["Sein", "ge\u00b7br\u00e4un\u00b7tes", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Liebt man nicht den duncklen Schaten", "tokens": ["Liebt", "man", "nicht", "den", "dunck\u00b7len", "Scha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PTKNEG", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der schwartzen N\u00e4chte Rast/", "tokens": ["Und", "der", "schwart\u00b7zen", "N\u00e4ch\u00b7te", "Rast", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn die hei\u00dfen Glieder braten", "tokens": ["Wenn", "die", "hei\u00b7\u00dfen", "Glie\u00b7der", "bra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr des Tages Uberlast?", "tokens": ["F\u00fcr", "des", "Ta\u00b7ges", "U\u00b7ber\u00b7last", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Wird nach schwartzer Kirschen Frucht", "tokens": ["Wird", "nach", "schwart\u00b7zer", "Kir\u00b7schen", "Frucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht der h\u00f6chste Baum bestiegen/", "tokens": ["Nicht", "der", "h\u00f6chs\u00b7te", "Baum", "be\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Andre/ die man siehet liegen/", "tokens": ["And\u00b7re", "/", "die", "man", "sie\u00b7het", "lie\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$(", "PRELS", "PIS", "VVFIN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kaum mit fauler Hand gesucht?", "tokens": ["Kaum", "mit", "fau\u00b7ler", "Hand", "ge\u00b7sucht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Mu\u00df der Blumen Prei\u00df nicht steigen/", "tokens": ["Mu\u00df", "der", "Blu\u00b7men", "Prei\u00df", "nicht", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df nicht Ros\u2019 und Tulipan/", "tokens": ["Mu\u00df", "nicht", "Ros'", "und", "Tu\u00b7li\u00b7pan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn sie sich zur Schw\u00e4rtze neigen/", "tokens": ["Wenn", "sie", "sich", "zur", "Schw\u00e4rt\u00b7ze", "nei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00f6her seyn gesehen an.", "tokens": ["H\u00f6\u00b7her", "seyn", "ge\u00b7se\u00b7hen", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Hylas mag nach seinem Sinn", "tokens": ["Hy\u00b7las", "mag", "nach", "sei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Andrer Farben Zier erheben:", "tokens": ["A\u00b7ndrer", "Far\u00b7ben", "Zier", "er\u00b7he\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Will sich mir zu eigen geben", "tokens": ["Will", "sich", "mir", "zu", "ei\u00b7gen", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "PPER", "PTKA", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine schwartze Sch\u00e4fferin/", "tokens": ["Mei\u00b7ne", "schwart\u00b7ze", "Sch\u00e4f\u00b7fe\u00b7rin", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "So sag ich von Grund der Seele:", "tokens": ["So", "sag", "ich", "von", "Grund", "der", "See\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Schwartz soll meine Farbe seyn/", "tokens": ["Schwartz", "soll", "mei\u00b7ne", "Far\u00b7be", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPOSAT", "NN", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bi\u00df des schwartzen Grabes H\u00f6le", "tokens": ["Bi\u00df", "des", "schwart\u00b7zen", "Gra\u00b7bes", "H\u00f6\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schleust den todten C\u00f6rper ein.", "tokens": ["Schleust", "den", "tod\u00b7ten", "C\u00f6r\u00b7per", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}