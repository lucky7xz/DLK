{"dta.poem.13490": {"metadata": {"author": {"name": "Eichendorff, Joseph von", "birth": "N.A.", "death": "N.A."}, "title": "Ix .  \n  Jahrmarkt .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905191113", "language": ["de:0.71", "af:0.28"], "booktitle": "Eichendorff, Joseph von: Gedichte. Berlin, 1837."}, "poem": {"stanza.1": {"line.1": {"text": "Sind's die H\u00e4user, sind's die Gassen?", "tokens": ["Sin\u00b7d's", "die", "H\u00e4u\u00b7ser", ",", "sin\u00b7d's", "die", "Gas\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ach, ich wei\u00df nicht, wo ich bin!", "tokens": ["Ach", ",", "ich", "wei\u00df", "nicht", ",", "wo", "ich", "bin", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hab' ein Liebchen hier gelassen,", "tokens": ["Hab'", "ein", "Lieb\u00b7chen", "hier", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und manch Jahr ging seitdem hin.", "tokens": ["Und", "manch", "Jahr", "ging", "seit\u00b7dem", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Aus den Fenstern sch\u00f6ne Frauen", "tokens": ["Aus", "den", "Fens\u00b7tern", "sch\u00f6\u00b7ne", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehn mir freundlich in's Gesicht,", "tokens": ["Sehn", "mir", "freund\u00b7lich", "in's", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keine kann so frischlich schauen,", "tokens": ["Kei\u00b7ne", "kann", "so", "frischlich", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Als mein liebes Liebchen sicht.", "tokens": ["Als", "mein", "lie\u00b7bes", "Lieb\u00b7chen", "sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "An dem Hause poch' ich bange \u2014", "tokens": ["An", "dem", "Hau\u00b7se", "poch'", "ich", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch die Fenster stehen leer,", "tokens": ["Doch", "die", "Fens\u00b7ter", "ste\u00b7hen", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ausgezogen ist sie lange,", "tokens": ["Aus\u00b7ge\u00b7zo\u00b7gen", "ist", "sie", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es kennt mich keiner mehr.", "tokens": ["Und", "es", "kennt", "mich", "kei\u00b7ner", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PIS", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und ringsum ein Rufen, Handeln,", "tokens": ["Und", "ring\u00b7sum", "ein", "Ru\u00b7fen", ",", "Han\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Schmucke Waaren, bunter Schein,", "tokens": ["Schmu\u00b7cke", "Waa\u00b7ren", ",", "bun\u00b7ter", "Schein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Herr'n und Damen gehn und wandeln", "tokens": ["Herr'n", "und", "Da\u00b7men", "gehn", "und", "wan\u00b7deln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVINF", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zwischendurch in bunten Reih'n.", "tokens": ["Zwi\u00b7schen\u00b7durch", "in", "bun\u00b7ten", "Reih'", "n."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "APPR", "ADJA", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Zierlich B\u00fccken, freundlich Blicken,", "tokens": ["Zier\u00b7lich", "B\u00fc\u00b7cken", ",", "freund\u00b7lich", "Bli\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Manches fl\u00fccht'ge Liebeswort,", "tokens": ["Man\u00b7ches", "fl\u00fccht'\u00b7ge", "Lie\u00b7bes\u00b7wort", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00e4ndedr\u00fccken, heimlich Nicken \u2014", "tokens": ["H\u00e4n\u00b7de\u00b7dr\u00fc\u00b7cken", ",", "heim\u00b7lich", "Ni\u00b7cken"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimmt sie all' der Strom mit fort.", "tokens": ["Nimmt", "sie", "all'", "der", "Strom", "mit", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ART", "NN", "APPR", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und mein Liebchen sah ich eben", "tokens": ["Und", "mein", "Lieb\u00b7chen", "sah", "ich", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Traurig in dem lust'gen Schwarm,", "tokens": ["Trau\u00b7rig", "in", "dem", "lust'\u00b7gen", "Schwarm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein sch\u00f6ner Herr daneben", "tokens": ["Und", "ein", "sch\u00f6\u00b7ner", "Herr", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "PAV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchrt sie stolz und ernst am Arm.", "tokens": ["F\u00fchrt", "sie", "stolz", "und", "ernst", "am", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "KON", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch verbla\u00dft war Mund und Wange,", "tokens": ["Doch", "ver\u00b7bla\u00dft", "war", "Mund", "und", "Wan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gebrochen war ihr Blick,", "tokens": ["Und", "ge\u00b7bro\u00b7chen", "war", "ihr", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seltsam schaut' sie stumm und lange,", "tokens": ["Selt\u00b7sam", "schaut'", "sie", "stumm", "und", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADJD", "KON", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lange noch auf mich zur\u00fcck. \u2014", "tokens": ["Lan\u00b7ge", "noch", "auf", "mich", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "PTKVZ", "$.", "$("], "meter": "+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Und es endet Tag und Scherzen,", "tokens": ["Und", "es", "en\u00b7det", "Tag", "und", "Scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die Gassen pfeift der Wind \u2014", "tokens": ["Durch", "die", "Gas\u00b7sen", "pfeift", "der", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner wei\u00df, wie unsre Herzen", "tokens": ["Kei\u00b7ner", "wei\u00df", ",", "wie", "uns\u00b7re", "Her\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "PWAV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tief von Schmerz zerrissen sind.", "tokens": ["Tief", "von", "Schmerz", "zer\u00b7ris\u00b7sen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}