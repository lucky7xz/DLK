{"dta.poem.12285": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Abt Neithards und seiner M\u00fcnche Chor.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich will mich aber freuen gegen diesen Mayen,               ", "tokens": ["Ich", "will", "mich", "a\u00b7ber", "freu\u00b7en", "ge\u00b7gen", "die\u00b7sen", "Ma\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Der mir gar \u00fcppiglichen Muth soll verleihen,", "tokens": ["Der", "mir", "gar", "\u00fcp\u00b7pig\u00b7li\u00b7chen", "Muth", "soll", "ver\u00b7lei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Das sey eim Bauer und seinen Gesellen leide.", "tokens": ["Das", "sey", "eim", "Bau\u00b7er", "und", "sei\u00b7nen", "Ge\u00b7sel\u00b7len", "lei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Ich habe der Lieben gedient also lange,", "tokens": ["Ich", "ha\u00b7be", "der", "Lie\u00b7ben", "ge\u00b7dient", "al\u00b7so", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ADV", "ADV", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Oft und viel mit meinem neuen Gesange,", "tokens": ["Oft", "und", "viel", "mit", "mei\u00b7nem", "neu\u00b7en", "Ge\u00b7san\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Die gelben Bl\u00fcmelein bracht ich ihr von der Heyde.", "tokens": ["Die", "gel\u00b7ben", "Bl\u00fc\u00b7me\u00b7lein", "bracht", "ich", "ihr", "von", "der", "Hey\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-++-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Die trug sie gar h\u00fcbschlich zu dem Tanze,", "tokens": ["Die", "trug", "sie", "gar", "h\u00fcb\u00b7schlich", "zu", "dem", "Tan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Alle meine Hoffnung mu\u00dft mir werden ganze,", "tokens": ["Al\u00b7le", "mei\u00b7ne", "Hoff\u00b7nung", "mu\u00dft", "mir", "wer\u00b7den", "gan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "VMFIN", "PPER", "VAFIN", "ADJA", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Da ich sie sah die s\u00e4uberliche Magd.", "tokens": ["Da", "ich", "sie", "sah", "die", "s\u00e4u\u00b7ber\u00b7li\u00b7che", "Magd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich kam zu der Lieben schon gegessen,", "tokens": ["Ich", "kam", "zu", "der", "Lie\u00b7ben", "schon", "ge\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wohl vier und zwanzig Bauern, die hatten sich vermessen,", "tokens": ["Wohl", "vier", "und", "zwan\u00b7zig", "Bau\u00b7ern", ",", "die", "hat\u00b7ten", "sich", "ver\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "KON", "CARD", "NN", "$,", "PRELS", "VAFIN", "PRF", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Von ihne da ward sch\u00e4mlich ich verjagt.", "tokens": ["Von", "ih\u00b7ne", "da", "ward", "sch\u00e4m\u00b7lich", "ich", "ver\u00b7jagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VAFIN", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "In einer weiten Stube mit Gedr\u00e4nge,", "tokens": ["In", "ei\u00b7ner", "wei\u00b7ten", "Stu\u00b7be", "mit", "Ge\u00b7dr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die weite Stube ward mir viel zu enge,", "tokens": ["Die", "wei\u00b7te", "Stu\u00b7be", "ward", "mir", "viel", "zu", "en\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und meines Lebens h\u00e4tte ich n\u00e4chst versagt.", "tokens": ["Und", "mei\u00b7nes", "Le\u00b7bens", "h\u00e4t\u00b7te", "ich", "n\u00e4chst", "ver\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Aller meiner Noth konnt ich nicht bedenken,", "tokens": ["Al\u00b7ler", "mei\u00b7ner", "Noth", "konnt", "ich", "nicht", "be\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Um und um hin lief ich an den B\u00e4nken,", "tokens": ["Um", "und", "um", "hin", "lief", "ich", "an", "den", "B\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "KON", "APPR", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Bis da\u00df ich doch die recht Th\u00fcr erschreite.", "tokens": ["Bis", "da\u00df", "ich", "doch", "die", "recht", "Th\u00fcr", "er\u00b7schrei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Meines Unfalls Rath h\u00e4tt ich bald vergessen,", "tokens": ["Mei\u00b7nes", "Un\u00b7falls", "Rath", "h\u00e4tt", "ich", "bald", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Meine weiten Spr\u00fcng die waren ungemessen,", "tokens": ["Mei\u00b7ne", "wei\u00b7ten", "Spr\u00fcng", "die", "wa\u00b7ren", "un\u00b7ge\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ART", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Die ich vor den alten Gauchen hin schreite.", "tokens": ["Die", "ich", "vor", "den", "al\u00b7ten", "Gau\u00b7chen", "hin", "schrei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Dahin gen Wien, da eilt ich also balde,", "tokens": ["Da\u00b7hin", "gen", "Wi\u00b7en", ",", "da", "eilt", "ich", "al\u00b7so", "bal\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NE", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "H\u00e4tt ich einen Laden Tuchs mit Gewalte,", "tokens": ["H\u00e4tt", "ich", "ei\u00b7nen", "La\u00b7den", "Tuchs", "mit", "Ge\u00b7wal\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Bey hundert Ellen, darum zahlt ich gut.", "tokens": ["Bey", "hun\u00b7dert", "El\u00b7len", ",", "da\u00b7rum", "zahlt", "ich", "gut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "PAV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Und zehn Ellen mehr, darum wollt ichs nicht lassen,", "tokens": ["Und", "zehn", "El\u00b7len", "mehr", ",", "da\u00b7rum", "wollt", "ichs", "nicht", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "ADV", "$,", "PAV", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Darum so wollt ich \u00fcppiglichen stossen", "tokens": ["Da\u00b7rum", "so", "wollt", "ich", "\u00fcp\u00b7pig\u00b7li\u00b7chen", "stos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VMFIN", "PPER", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die vier und zwanzig Bauren hochgemuthe.", "tokens": ["Die", "vier", "und", "zwan\u00b7zig", "Bau\u00b7ren", "hoch\u00b7ge\u00b7mu\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "KON", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Und h\u00e4tt ich einen Schneider mit zweien Knechten,", "tokens": ["Und", "h\u00e4tt", "ich", "ei\u00b7nen", "Schnei\u00b7der", "mit", "zwei\u00b7en", "Knech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NE", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die mir schnitten die Kleider also gerechte,", "tokens": ["Die", "mir", "schnit\u00b7ten", "die", "Klei\u00b7der", "al\u00b7so", "ge\u00b7rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Vier und zwanzig Kutten mu\u00dften sie tragen.", "tokens": ["Vier", "und", "zwan\u00b7zig", "Kut\u00b7ten", "mu\u00df\u00b7ten", "sie", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "KON", "CARD", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Die eine kurz, die andere wohl gel\u00e4nget,", "tokens": ["Die", "ei\u00b7ne", "kurz", ",", "die", "an\u00b7de\u00b7re", "wohl", "ge\u00b7l\u00e4n\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als Gott ihnen ihr Gew\u00e4chs nun hat verh\u00e4nget,", "tokens": ["Als", "Gott", "ih\u00b7nen", "ihr", "Ge\u00b7w\u00e4chs", "nun", "hat", "ver\u00b7h\u00e4n\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PPOSAT", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Und oben weit gefalten um den Kragen,", "tokens": ["Und", "o\u00b7ben", "weit", "ge\u00b7fal\u00b7ten", "um", "den", "Kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Die f\u00fcnf und zwanzigst Kutten will ich selber tragen,", "tokens": ["Die", "f\u00fcnf", "und", "zwan\u00b7zigst", "Kut\u00b7ten", "will", "ich", "sel\u00b7ber", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "KON", "VVFIN", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df man f\u00fcr den Abt mich m\u00fcsse ansagen,", "tokens": ["Da\u00df", "man", "f\u00fcr", "den", "Abt", "mich", "m\u00fcs\u00b7se", "an\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wann ich in dem Land mit ihnen umfahre.", "tokens": ["Wann", "ich", "in", "dem", "Land", "mit", "ih\u00b7nen", "um\u00b7fah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Und h\u00e4tt ich einen Scherer also gute,", "tokens": ["Und", "h\u00e4tt", "ich", "ei\u00b7nen", "Sche\u00b7rer", "al\u00b7so", "gu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der mir die Bauern bescheret die Bauern hochgemuthe,", "tokens": ["Der", "mir", "die", "Bau\u00b7ern", "be\u00b7sche\u00b7ret", "die", "Bau\u00b7ern", "hoch\u00b7ge\u00b7mu\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich wollt ihnen scheeren die alten Bauern-Haare.", "tokens": ["Ich", "wollt", "ih\u00b7nen", "schee\u00b7ren", "die", "al\u00b7ten", "Bau\u00b7ern\u00b7Haa\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.14": {"line.1": {"text": "Noch so mu\u00df ich hahen viererley Dinge,", "tokens": ["Noch", "so", "mu\u00df", "ich", "ha\u00b7hen", "vie\u00b7rer\u00b7ley", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Oben eine Platte und darum einen Ringe,", "tokens": ["O\u00b7ben", "ei\u00b7ne", "Plat\u00b7te", "und", "da\u00b7rum", "ei\u00b7nen", "Rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "PAV", "ART", "NN", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Gleichwie ein M\u00f6nch auf Erden soll seyn.", "tokens": ["Gleich\u00b7wie", "ein", "M\u00f6nch", "auf", "Er\u00b7den", "soll", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.15": {"line.1": {"text": "Noch so hab ich der Abentheuer nicht gare,", "tokens": ["Noch", "so", "hab", "ich", "der", "A\u00b7bent\u00b7heu\u00b7er", "nicht", "ga\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+--++-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Er hie\u00df ihm bringen ein Osterwein so klare,", "tokens": ["Er", "hie\u00df", "ihm", "brin\u00b7gen", "ein", "Os\u00b7ter\u00b7wein", "so", "kla\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ART", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und ein Schlaftrinken go\u00df er ihnen darein.", "tokens": ["Und", "ein", "Schlaf\u00b7trin\u00b7ken", "go\u00df", "er", "ih\u00b7nen", "da\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PPER", "PAV", "$."], "meter": "--++-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.16": {"line.1": {"text": "Also war das Abentheuer bereitet,", "tokens": ["Al\u00b7so", "war", "das", "A\u00b7bent\u00b7heu\u00b7er", "be\u00b7rei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und auf einem Karren schnelle geleitet,", "tokens": ["Und", "auf", "ei\u00b7nem", "Kar\u00b7ren", "schnel\u00b7le", "ge\u00b7lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wohl zu dem gr\u00fcnen Anger hin.", "tokens": ["Wohl", "zu", "dem", "gr\u00fc\u00b7nen", "An\u00b7ger", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Zum gr\u00fcnen Anger unter der sch\u00f6nen Linden,", "tokens": ["Zum", "gr\u00fc\u00b7nen", "An\u00b7ger", "un\u00b7ter", "der", "sch\u00f6\u00b7nen", "Lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da lie\u00dfen sich die Bauren allsammt finden,", "tokens": ["Da", "lie\u00b7\u00dfen", "sich", "die", "Bau\u00b7ren", "all\u00b7sammt", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihrer vier und zwanzig, das war ihr Ungewinn.", "tokens": ["Ih\u00b7rer", "vier", "und", "zwan\u00b7zig", ",", "das", "war", "ihr", "Un\u00b7ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "CARD", "KON", "CARD", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Der erste der sprach, wollt ihr den Neithard sehen,", "tokens": ["Der", "ers\u00b7te", "der", "sprach", ",", "wollt", "ihr", "den", "Neit\u00b7hard", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "VVFIN", "$,", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der ander sprach, ja m\u00fcst ihm Leid geschehen,", "tokens": ["Der", "an\u00b7der", "sprach", ",", "ja", "m\u00fcst", "ihm", "Leid", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$,", "ADV", "VMFIN", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und meld sein nicht, es mu\u00df an sein Leben gahn.", "tokens": ["Und", "meld", "sein", "nicht", ",", "es", "mu\u00df", "an", "sein", "Le\u00b7ben", "gahn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "PTKNEG", "$,", "PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+----+-+-+", "measure": "dactylic.init"}}, "stanza.19": {"line.1": {"text": "Er zog die Gugel von der Platten gare,", "tokens": ["Er", "zog", "die", "Gu\u00b7gel", "von", "der", "Plat\u00b7ten", "ga\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der dritt sprach, es ist ein M\u00f6nch f\u00fcrwahre,", "tokens": ["Der", "dritt", "sprach", ",", "es", "ist", "ein", "M\u00f6nch", "f\u00fcr\u00b7wah\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und ist in unserm Land ein fremder Mann.", "tokens": ["Und", "ist", "in", "un\u00b7serm", "Land", "ein", "frem\u00b7der", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Er zuckt die Gugel gar nieder auf den R\u00fccken,", "tokens": ["Er", "zuckt", "die", "Gu\u00b7gel", "gar", "nie\u00b7der", "auf", "den", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er trat zu den Bauren gar voll T\u00fccken,", "tokens": ["Er", "trat", "zu", "den", "Bau\u00b7ren", "gar", "voll", "T\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "ADJD", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie bald trat Engelmayer zu ihm dar.", "tokens": ["Wie", "bald", "trat", "En\u00b7gel\u00b7may\u00b7er", "zu", "ihm", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "NE", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Er sprach: \u201eGr\u00fc\u00df euch Gott Kinder, wollt ihr trinken?", "tokens": ["Er", "sprach", ":", "\u201e", "Gr\u00fc\u00df", "euch", "Gott", "Kin\u00b7der", ",", "wollt", "ihr", "trin\u00b7ken", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VVIMP", "PPER", "NN", "NN", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201eguten Osterwein will ich euch schenken.\u201c", "tokens": ["\u201e", "gu\u00b7ten", "Os\u00b7ter\u00b7wein", "will", "ich", "euch", "schen\u00b7ken", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Da bot er ihnen das Schlaftr\u00e4nklein dar.", "tokens": ["Da", "bot", "er", "ih\u00b7nen", "das", "Schlaf\u00b7tr\u00e4nk\u00b7lein", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "Sie trunken alle den Oesterwein gar vaste,", "tokens": ["Sie", "trun\u00b7ken", "al\u00b7le", "den", "O\u00b7es\u00b7ter\u00b7wein", "gar", "vas\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ART", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Je l\u00e4nger, je mehr, so mehret sich ihr Laster,", "tokens": ["Je", "l\u00e4n\u00b7ger", ",", "je", "mehr", ",", "so", "meh\u00b7ret", "sich", "ihr", "Las\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADV", "$,", "ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$,"], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Sie lagen alle vor tod an einer Schaar.", "tokens": ["Sie", "la\u00b7gen", "al\u00b7le", "vor", "tod", "an", "ei\u00b7ner", "Schaar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.23": {"line.1": {"text": "Die Messer und die Schwerdt begunnt er ihnen rauffen,", "tokens": ["Die", "Mes\u00b7ser", "und", "die", "Schwerdt", "be\u00b7gunnt", "er", "ih\u00b7nen", "rauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die dicken Stecken mit den gro\u00dfen Knauffen,", "tokens": ["Die", "di\u00b7cken", "Ste\u00b7cken", "mit", "den", "gro\u00b7\u00dfen", "Knauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "G\u00fcrtel und Taschen nahm er von ihnen gar.", "tokens": ["G\u00fcr\u00b7tel", "und", "Ta\u00b7schen", "nahm", "er", "von", "ih\u00b7nen", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}}, "stanza.24": {"line.1": {"text": "Also wurden ihrer vier und zwanzig beschoren,", "tokens": ["Al\u00b7so", "wur\u00b7den", "ih\u00b7rer", "vier", "und", "zwan\u00b7zig", "be\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "CARD", "KON", "CARD", "VVINF", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Rock und Mantel h\u00e4ttens all verlohren,", "tokens": ["Rock", "und", "Man\u00b7tel", "h\u00e4t\u00b7tens", "all", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PIAT", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Vier und zwanzig Kutten stie\u00df er ihnen an.", "tokens": ["Vier", "und", "zwan\u00b7zig", "Kut\u00b7ten", "stie\u00df", "er", "ih\u00b7nen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "KON", "CARD", "NN", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.25": {"line.1": {"text": "Sie lagen bis an den vierten Tag ohne Sinnen,", "tokens": ["Sie", "la\u00b7gen", "bis", "an", "den", "vier\u00b7ten", "Tag", "oh\u00b7ne", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+----+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Allererst da wurden sie's wohl innen,", "tokens": ["Al\u00b7le\u00b7rerst", "da", "wur\u00b7den", "sie's", "wohl", "in\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und h\u00f6rt, wie einer sprach der alten Knaben.", "tokens": ["Und", "h\u00f6rt", ",", "wie", "ei\u00b7ner", "sprach", "der", "al\u00b7ten", "Kna\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Der greift da mit der Hand wohl auf das Haare:", "tokens": ["Der", "greift", "da", "mit", "der", "Hand", "wohl", "auf", "das", "Haa\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201enun freut euch alle, ich bin ein M\u00f6nch f\u00fcrwahre,", "tokens": ["\u201e", "nun", "freut", "euch", "al\u00b7le", ",", "ich", "bin", "ein", "M\u00f6nch", "f\u00fcr\u00b7wah\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PIS", "$,", "PPER", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u201eund will uns Morgen eine Fr\u00fchme\u00df haben.\u201c", "tokens": ["\u201e", "und", "will", "uns", "Mor\u00b7gen", "ei\u00b7ne", "Fr\u00fch\u00b7me\u00df", "ha\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VMFIN", "PPER", "NN", "ART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Der andere sprach: \u201eSo sing uns das Amte,", "tokens": ["Der", "an\u00b7de\u00b7re", "sprach", ":", "\u201e", "So", "sing", "uns", "das", "Am\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201edas helfen wir dir Bruder allesammte,", "tokens": ["\u201e", "das", "hel\u00b7fen", "wir", "dir", "Bru\u00b7der", "al\u00b7le\u00b7samm\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u201eals wir vor und nach dem Pfluge gethan haben.\u201c", "tokens": ["\u201e", "als", "wir", "vor", "und", "nach", "dem", "Pflu\u00b7ge", "ge\u00b7than", "ha\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PTKVZ", "KON", "APPR", "ART", "NN", "VVPP", "VAINF", "$.", "$("], "meter": "+-+-+-+-+++-", "measure": "unknown.measure.septa"}}, "stanza.28": {"line.1": {"text": "Der Neithard kam wohl zu den Bauren getreten:", "tokens": ["Der", "Neit\u00b7hard", "kam", "wohl", "zu", "den", "Bau\u00b7ren", "ge\u00b7tre\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201eihr liebe Kind wer hat euch her gebeten,", "tokens": ["\u201e", "ihr", "lie\u00b7be", "Kind", "wer", "hat", "euch", "her", "ge\u00b7be\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u201eda\u00df ihr so liegt in Gottes Ordnung hie.\u201c", "tokens": ["\u201e", "da\u00df", "ihr", "so", "liegt", "in", "Got\u00b7tes", "Ord\u00b7nung", "hie", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "VVFIN", "APPR", "NN", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "\u201enun lieber Herr, das hat uns Gott erschaffen,", "tokens": ["\u201e", "nun", "lie\u00b7ber", "Herr", ",", "das", "hat", "uns", "Gott", "er\u00b7schaf\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "NN", "$,", "PDS", "VAFIN", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201ewir sind all worden hie zu Pfaffen,", "tokens": ["\u201e", "wir", "sind", "all", "wor\u00b7den", "hie", "zu", "Pfaf\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PIAT", "VAPP", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eund sind dazu gar wenig doch gelehrt.\u201c", "tokens": ["\u201e", "und", "sind", "da\u00b7zu", "gar", "we\u00b7nig", "doch", "ge\u00b7lehrt", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VAFIN", "PAV", "ADV", "PIS", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "\u201eihr lieben Kind, zum Lernen seyd ihr junge,", "tokens": ["\u201e", "ihr", "lie\u00b7ben", "Kind", ",", "zum", "Ler\u00b7nen", "seyd", "ihr", "jun\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "$,", "APPRART", "NN", "VAFIN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201ein meinem Mund trag ich eine gelehrte Zunge,", "tokens": ["\u201e", "in", "mei\u00b7nem", "Mund", "trag", "ich", "ei\u00b7ne", "ge\u00b7lehr\u00b7te", "Zun\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u201eund gute Lehre geb ich euch nun hie.\u201c", "tokens": ["\u201e", "und", "gu\u00b7te", "Leh\u00b7re", "geb", "ich", "euch", "nun", "hie", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ADJA", "NN", "VVFIN", "PPER", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Mit guten Worten bracht er's auf die Stra\u00dfe,", "tokens": ["Mit", "gu\u00b7ten", "Wor\u00b7ten", "bracht", "er's", "auf", "die", "Stra\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dahin gen Wien, so sie Gott immer hasse,", "tokens": ["Da\u00b7hin", "gen", "Wi\u00b7en", ",", "so", "sie", "Gott", "im\u00b7mer", "has\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NE", "$,", "ADV", "PPER", "NN", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wohl auf die Br\u00fccke vor des Herzogs Thor.", "tokens": ["Wohl", "auf", "die", "Br\u00fc\u00b7cke", "vor", "des", "Her\u00b7zogs", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Er stellt sie vor das Thor wohl auf die Br\u00fccken,", "tokens": ["Er", "stellt", "sie", "vor", "das", "Thor", "wohl", "auf", "die", "Br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er kehrt ihnen die Gel\u00e4nder wohl an den R\u00fccken:", "tokens": ["Er", "kehrt", "ih\u00b7nen", "die", "Ge\u00b7l\u00e4n\u00b7der", "wohl", "an", "den", "R\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+----+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u201enun lieben Br\u00fcder wartet mein hiervor.", "tokens": ["\u201e", "nun", "lie\u00b7ben", "Br\u00fc\u00b7der", "war\u00b7tet", "mein", "hier\u00b7vor", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "VVFIN", "PPOSAT", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "\u201eso will ich gehen zu Herzog Otten grade,", "tokens": ["\u201e", "so", "will", "ich", "ge\u00b7hen", "zu", "Her\u00b7zog", "Ot\u00b7ten", "gra\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVFIN", "APPR", "NE", "NE", "ADV", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201eda\u00df er uns bald mit einer Zell berathe,", "tokens": ["\u201e", "da\u00df", "er", "uns", "bald", "mit", "ei\u00b7ner", "Zell", "be\u00b7ra\u00b7the", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u201edarin wollen wir singen grob und klar.", "tokens": ["\u201e", "da\u00b7rin", "wol\u00b7len", "wir", "sin\u00b7gen", "grob", "und", "klar", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VMFIN", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.34": {"line.1": {"text": "\u201elieber Herzog Otto, ich bin ein Priester worden,", "tokens": ["\u201e", "lie\u00b7ber", "Her\u00b7zog", "Ot\u00b7to", ",", "ich", "bin", "ein", "Pries\u00b7ter", "wor\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "NE", "NE", "$,", "PPER", "VAFIN", "ART", "NN", "VAPP", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "\u201eund habe mir gestiftet selbst einen neuen Orden,", "tokens": ["\u201e", "und", "ha\u00b7be", "mir", "ge\u00b7stif\u00b7tet", "selbst", "ei\u00b7nen", "neu\u00b7en", "Or\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "VVPP", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u201edrau\u00dfen stehn meine Br\u00fcder all in einer Schaar.", "tokens": ["\u201e", "drau\u00b7\u00dfen", "stehn", "mei\u00b7ne", "Br\u00fc\u00b7der", "all", "in", "ei\u00b7ner", "Schaar", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPOSAT", "NN", "PIAT", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}}}}