{"dta.poem.9832": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Das frohlockende Berlin/  \n Als Se. Churf\u00fcrstl. Durchl. zu Brandenb.  \n Friederich der Dritte/  \n Nach eroberten Keyserswerth und Bonn/ auch ein-  \n genommener Clevischen huldigung wieder  \n zur\u00fcck kamen.  \n C. E.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Komm dann/ Durchlauchtigster/ und stille das verlangen/", "tokens": ["Komm", "dann", "/", "Durch\u00b7lauch\u00b7tigs\u00b7ter", "/", "und", "stil\u00b7le", "das", "ver\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "NN", "$(", "KON", "VVFIN", "PDS", "VVFIN", "$("], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Wormit in unterth\u00e4nigkeit", "tokens": ["Wor\u00b7mit", "in", "un\u00b7ter\u00b7th\u00e4\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dein armes volck so lange zeit", "tokens": ["Dein", "ar\u00b7mes", "volck", "so", "lan\u00b7ge", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gew\u00fcnschet hat dich zu empfangen!", "tokens": ["Ge\u00b7w\u00fcn\u00b7schet", "hat", "dich", "zu", "emp\u00b7fan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Komm/ zieh in gnaden bey uns ein!", "tokens": ["Komm", "/", "zieh", "in", "gna\u00b7den", "bey", "uns", "ein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "APPR", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir brennen tausend freuden-kertzen:", "tokens": ["Dir", "bren\u00b7nen", "tau\u00b7send", "freu\u00b7den\u00b7kert\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nimm diesen andachts-vollen schein", "tokens": ["Nimm", "die\u00b7sen", "an\u00b7dachts\u00b7vol\u00b7len", "schein"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zum ew\u2019gen opffer an von unsren treuen hertzen.", "tokens": ["Zum", "ew'\u00b7gen", "opf\u00b7fer", "an", "von", "un\u00b7sren", "treu\u00b7en", "hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "La\u00df immer hin die sonn von unsren gr\u00e4ntzen eilen;", "tokens": ["La\u00df", "im\u00b7mer", "hin", "die", "sonn", "von", "un\u00b7sren", "gr\u00e4nt\u00b7zen", "ei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gehstu doch/ landes-sonn/ uns auff.", "tokens": ["Gehs\u00b7tu", "doch", "/", "lan\u00b7des\u00b7sonn", "/", "uns", "auff", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$(", "NE", "$(", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was k\u00fcmmert uns der sonnen lauff/", "tokens": ["Was", "k\u00fcm\u00b7mert", "uns", "der", "son\u00b7nen", "lauff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wann du nur bey uns wilt verweilen?", "tokens": ["Wann", "du", "nur", "bey", "uns", "wilt", "ver\u00b7wei\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein gnaden-volles angesicht", "tokens": ["Dein", "gna\u00b7den\u00b7vol\u00b7les", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bestrahlt uns aus weit be\u00dfren zimmern/", "tokens": ["Be\u00b7strahlt", "uns", "aus", "weit", "be\u00df\u00b7ren", "zim\u00b7mern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und l\u00e4\u00dft sein hocherlauchtes licht", "tokens": ["Und", "l\u00e4\u00dft", "sein", "ho\u00b7cher\u00b7lauch\u00b7tes", "licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit ungemeiner glut auff unsre demuth schimmern.", "tokens": ["Mit", "un\u00b7ge\u00b7mei\u00b7ner", "glut", "auff", "uns\u00b7re", "de\u00b7muth", "schim\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Welch zusatz aber will nicht unser gl\u00fcck umbkr\u00e4ntzen/", "tokens": ["Welch", "zu\u00b7satz", "a\u00b7ber", "will", "nicht", "un\u00b7ser", "gl\u00fcck", "umb\u00b7kr\u00e4nt\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VMFIN", "PTKNEG", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da itzt/ bekr\u00f6nter sieges-held/", "tokens": ["Da", "itzt", "/", "be\u00b7kr\u00f6n\u00b7ter", "sie\u00b7ges\u00b7held", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die lorbern der ber\u00fchmten welt", "tokens": ["Die", "lor\u00b7bern", "der", "be\u00b7r\u00fchm\u00b7ten", "welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Umb deinen theuren scheitel gl\u00e4ntzen?", "tokens": ["Umb", "dei\u00b7nen", "theu\u00b7ren", "schei\u00b7tel", "gl\u00e4nt\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie reichlich k\u00f6mmstu nicht bepalmt?", "tokens": ["Wie", "reich\u00b7lich", "k\u00f6mms\u00b7tu", "nicht", "be\u00b7palmt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wer wird deinen zug nicht loben/", "tokens": ["Und", "wer", "wird", "dei\u00b7nen", "zug", "nicht", "lo\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der stahl und felsen auch zermalmt/", "tokens": ["Der", "stahl", "und", "fel\u00b7sen", "auch", "zer\u00b7malmt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und so den feinde lehrt die allerschwerste proben?", "tokens": ["Und", "so", "den", "fein\u00b7de", "lehrt", "die", "al\u00b7ler\u00b7schwers\u00b7te", "pro\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Dein adler kan nicht nur im offnen felde siegen;", "tokens": ["Dein", "ad\u00b7ler", "kan", "nicht", "nur", "im", "off\u00b7nen", "fel\u00b7de", "sie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "ADV", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er greifft auch w\u00e4ll\u2019 und mauren an.", "tokens": ["Er", "greifft", "auch", "w\u00e4ll'", "und", "mau\u00b7ren", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVFIN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Welch wunder hat er nicht gethan", "tokens": ["Welch", "wun\u00b7der", "hat", "er", "nicht", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "PTKNEG", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In den nur vorgespielten kriegen?", "tokens": ["In", "den", "nur", "vor\u00b7ge\u00b7spiel\u00b7ten", "krie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der hahn/ so keck er sonsten ist/", "tokens": ["Der", "hahn", "/", "so", "keck", "er", "sons\u00b7ten", "ist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADJD", "PPER", "ADV", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "L\u00e4st sich in enge winckel schliessen/", "tokens": ["L\u00e4st", "sich", "in", "en\u00b7ge", "win\u00b7ckel", "schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Wann du mit flammen ausger\u00fcst", "tokens": ["Wann", "du", "mit", "flam\u00b7men", "aus\u00b7ge\u00b7r\u00fcst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den strahl bewehrter faust auff seinen kopff l\u00e4st schiessen.", "tokens": ["Den", "strahl", "be\u00b7wehr\u00b7ter", "faust", "auff", "sei\u00b7nen", "kopff", "l\u00e4st", "schies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Bonn scheut dein scharff gefecht/ und K\u00e4yserswerth ingleichen/", "tokens": ["Bonn", "scheut", "dein", "scharff", "ge\u00b7fecht", "/", "und", "K\u00e4y\u00b7sers\u00b7werth", "in\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "ADJD", "VVPP", "$(", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denckt an dein donnrendes gesch\u00fctz/", "tokens": ["Denckt", "an", "dein", "donn\u00b7ren\u00b7des", "ge\u00b7sch\u00fctz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie f\u00fcrchten deiner schwerdter blitz/", "tokens": ["Sie", "f\u00fcrch\u00b7ten", "dei\u00b7ner", "schwerd\u00b7ter", "blitz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nebst den gef\u00fchrten doppelstreichen;", "tokens": ["Nebst", "den", "ge\u00b7f\u00fchr\u00b7ten", "dop\u00b7pel\u00b7strei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie kennen deines adlers macht/", "tokens": ["Sie", "ken\u00b7nen", "dei\u00b7nes", "ad\u00b7lers", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und seine kriegerische klauen/", "tokens": ["Und", "sei\u00b7ne", "krie\u00b7ge\u00b7ri\u00b7sche", "klau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und sind zu solcher furcht gebracht/", "tokens": ["Und", "sind", "zu", "sol\u00b7cher", "furcht", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df ihnen nach der zeit wird sattsam vor dir grauen.", "tokens": ["Da\u00df", "ih\u00b7nen", "nach", "der", "zeit", "wird", "satt\u00b7sam", "vor", "dir", "grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VAFIN", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Umb wie viel r\u00f6ther wird nicht nun dein adler scheinen/", "tokens": ["Umb", "wie", "viel", "r\u00f6\u00b7ther", "wird", "nicht", "nun", "dein", "ad\u00b7ler", "schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "KOKOM", "ADV", "ADJD", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nun er durchs hahnen blut benetzt?", "tokens": ["Nun", "er", "durchs", "hah\u00b7nen", "blut", "be\u00b7netzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist und bleibet unverletzt/", "tokens": ["Er", "ist", "und", "blei\u00b7bet", "un\u00b7ver\u00b7letzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil GOtt und tugend ihn umbz\u00e4unen.", "tokens": ["Weil", "Gott", "und", "tu\u00b7gend", "ihn", "umb\u00b7z\u00e4u\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und kan er gar der sonnen licht", "tokens": ["Und", "kan", "er", "gar", "der", "son\u00b7nen", "licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch strengen schwung entgegen gehen;", "tokens": ["Durch", "stren\u00b7gen", "schwung", "ent\u00b7ge\u00b7gen", "ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wie? solt er denn auff erden nicht", "tokens": ["Wie", "?", "solt", "er", "denn", "auff", "er\u00b7den", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VMFIN", "PPER", "ADV", "APPR", "NN", "PTKNEG"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Auch unter rauch und dampff der stoltzen feinde stehen?", "tokens": ["Auch", "un\u00b7ter", "rauch", "und", "dampff", "der", "stolt\u00b7zen", "fein\u00b7de", "ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJD", "KON", "PAV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Dein Cleve will also zum ersten dich umfassen.", "tokens": ["Dein", "Cle\u00b7ve", "will", "al\u00b7so", "zum", "ers\u00b7ten", "dich", "um\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VMFIN", "ADV", "APPRART", "ADJA", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du warst der nordstern in der h\u00f6h/", "tokens": ["Du", "warst", "der", "nords\u00b7tern", "in", "der", "h\u00f6h", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wornach es auff ergrimmter see", "tokens": ["Wor\u00b7nach", "es", "auff", "er\u00b7grimm\u00b7ter", "see"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein sehnlichs auge schiessen lassen.", "tokens": ["Sein", "sehn\u00b7lichs", "au\u00b7ge", "schies\u00b7sen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da nun der blutge feind bek\u00e4mpfft/", "tokens": ["Da", "nun", "der", "blut\u00b7ge", "feind", "be\u00b7k\u00e4mpfft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der es zum raube wolt erjagen/", "tokens": ["Der", "es", "zum", "rau\u00b7be", "wolt", "er\u00b7ja\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und durch dein truncknes schwerdt ged\u00e4mpfft/", "tokens": ["Und", "durch", "dein", "trunck\u00b7nes", "schwerdt", "ge\u00b7d\u00e4mpfft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sieht man es billich dir den crantz entgegen tragen.", "tokens": ["Sieht", "man", "es", "bil\u00b7lich", "dir", "den", "crantz", "ent\u00b7ge\u00b7gen", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "PPER", "ART", "NN", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So sehr es aber sucht dich l\u00e4nger zu verweilen/", "tokens": ["So", "sehr", "es", "a\u00b7ber", "sucht", "dich", "l\u00e4n\u00b7ger", "zu", "ver\u00b7wei\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So schaffet doch dein steiffer schlu\u00df/", "tokens": ["So", "schaf\u00b7fet", "doch", "dein", "steif\u00b7fer", "schlu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df es mit heisser wehmuth mu\u00df", "tokens": ["Da\u00df", "es", "mit", "heis\u00b7ser", "weh\u00b7muth", "mu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dich sehn von seinen gr\u00e4ntzen eilen.", "tokens": ["Dich", "sehn", "von", "sei\u00b7nen", "gr\u00e4nt\u00b7zen", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du w\u00fcnschest auch dein \u00fcbrigs land", "tokens": ["Du", "w\u00fcn\u00b7schest", "auch", "dein", "\u00fcb\u00b7rigs", "land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In hohen augenschein zu fassen/", "tokens": ["In", "ho\u00b7hen", "au\u00b7gen\u00b7schein", "zu", "fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und bey so h\u00f6chst begl\u00fccktem stand", "tokens": ["Und", "bey", "so", "h\u00f6chst", "be\u00b7gl\u00fcck\u00b7tem", "stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "ADV", "ADJA", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wiltu dich endlich hier voll gnaden niederlassen.", "tokens": ["Wil\u00b7tu", "dich", "end\u00b7lich", "hier", "voll", "gna\u00b7den", "nie\u00b7der\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "ADJD", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "So komm nun/ theurer held/ und la\u00df dich bey uns finden/", "tokens": ["So", "komm", "nun", "/", "theu\u00b7rer", "held", "/", "und", "la\u00df", "dich", "bey", "uns", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$(", "ADJD", "VVFIN", "$(", "KON", "VVIMP", "PPER", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Komm und erfreue diese stadt/", "tokens": ["Komm", "und", "er\u00b7freu\u00b7e", "die\u00b7se", "stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die l\u00e4ngst den altar fertig hat", "tokens": ["Die", "l\u00e4ngst", "den", "al\u00b7tar", "fer\u00b7tig", "hat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dir brand und opffer anzuz\u00fcnden:", "tokens": ["Dir", "brand", "und", "opf\u00b7fer", "an\u00b7zu\u00b7z\u00fcn\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die palmen sind dir schon gestreut/", "tokens": ["Die", "pal\u00b7men", "sind", "dir", "schon", "ge\u00b7streut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nim hier noch an die letzten zweige/", "tokens": ["Nim", "hier", "noch", "an", "die", "letz\u00b7ten", "zwei\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "APPR", "ART", "ADJA", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die zwar von schwacher faust berelt;", "tokens": ["Die", "zwar", "von", "schwa\u00b7cher", "faust", "be\u00b7relt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch unsrer tieffsten pflicht sind ein bew\u00e4hrter zeuge.", "tokens": ["Doch", "uns\u00b7rer", "tieffs\u00b7ten", "pflicht", "sind", "ein", "be\u00b7w\u00e4hr\u00b7ter", "zeu\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wir hoffen fest zu GOtt/ die lorbeern werden bl\u00fchen/", "tokens": ["Wir", "hof\u00b7fen", "fest", "zu", "Gott", "/", "die", "lor\u00b7beern", "wer\u00b7den", "bl\u00fc\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "$(", "ART", "NN", "VAINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Womit dein hohes haupt umkr\u00e4ntzt/", "tokens": ["Wo\u00b7mit", "dein", "ho\u00b7hes", "haupt", "um\u00b7kr\u00e4ntzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der sieg/ so aus den bl\u00e4ttern gl\u00e4ntzt/", "tokens": ["Der", "sieg", "/", "so", "aus", "den", "bl\u00e4t\u00b7tern", "gl\u00e4ntzt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird keinen unfall nach sich ziehen.", "tokens": ["Wird", "kei\u00b7nen", "un\u00b7fall", "nach", "sich", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Denn dieser schlu\u00df bleibt fest gesetzt:", "tokens": ["Denn", "die\u00b7ser", "schlu\u00df", "bleibt", "fest", "ge\u00b7setzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der GOtt/ der sonst die adler sch\u00fctzet/", "tokens": ["Der", "Gott", "/", "der", "sonst", "die", "ad\u00b7ler", "sch\u00fct\u00b7zet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "H\u00e4lt auch die lorbeern unverletzt/", "tokens": ["H\u00e4lt", "auch", "die", "lor\u00b7beern", "un\u00b7ver\u00b7letzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenns noch so ungeheur umb ihre gipffel blitzet.", "tokens": ["Wenns", "noch", "so", "un\u00b7ge\u00b7heur", "umb", "ih\u00b7re", "gipf\u00b7fel", "blit\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}