{"textgrid.poem.44038": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Liebster Heiland, dencke doch,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Liebster Heiland, dencke doch,", "tokens": ["Liebs\u00b7ter", "Hei\u00b7land", ",", "den\u00b7cke", "doch", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Satan kommt mit neuen Stricken.", "tokens": ["Sa\u00b7tan", "kommt", "mit", "neu\u00b7en", "Stri\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Erstlich suchte mich sein Joch", "tokens": ["Erst\u00b7lich", "such\u00b7te", "mich", "sein", "Joch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die Wollust zu ber\u00fccken,", "tokens": ["Durch", "die", "Wol\u00b7lust", "zu", "be\u00b7r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da die List nichts richten kan,", "tokens": ["Da", "die", "List", "nichts", "rich\u00b7ten", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sezt er mit Verzweiflung an.", "tokens": ["Sezt", "er", "mit", "Ver\u00b7zwei\u00b7flung", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Mein Gewi\u00dfen weckt er auf,", "tokens": ["Mein", "Ge\u00b7wi\u00b7\u00dfen", "weckt", "er", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4st sich alle S\u00fcnd erzehlen,", "tokens": ["L\u00e4st", "sich", "al\u00b7le", "S\u00fcnd", "er\u00b7zeh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Will mich durch den Lebenslauf", "tokens": ["Will", "mich", "durch", "den", "Le\u00b7bens\u00b7lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der begangnen Thorheit qu\u00e4len", "tokens": ["Der", "be\u00b7gang\u00b7nen", "Thor\u00b7heit", "qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und verst\u00e4rckt mit H\u00f6ll und Tod", "tokens": ["Und", "ver\u00b7st\u00e4rckt", "mit", "H\u00f6ll", "und", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Gefahr der lezten Noth.", "tokens": ["Die", "Ge\u00b7fahr", "der", "lez\u00b7ten", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wein und schrey dich stumm und blind!", "tokens": ["Wein", "und", "schrey", "dich", "stumm", "und", "blind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Also schwazt der Seelengeyer.", "tokens": ["Al\u00b7so", "schwazt", "der", "See\u00b7len\u00b7ge\u00b7yer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00bbvor ein solch verruchtes Kind", "tokens": ["\u00bb", "vor", "ein", "solch", "ver\u00b7ruch\u00b7tes", "Kind"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00e4lt dein Gott seyn Blut zu theuer,", "tokens": ["H\u00e4lt", "dein", "Gott", "seyn", "Blut", "zu", "theu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPOSAT", "NN", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bu\u00dfe, Be\u00dfrung und Gebeth", "tokens": ["Bu\u00b7\u00dfe", ",", "Be\u00df\u00b7rung", "und", "Ge\u00b7beth"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind jezt Ohnmacht und zu sp\u00e4t.", "tokens": ["Sind", "jezt", "Ohn\u00b7macht", "und", "zu", "sp\u00e4t", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "KON", "PTKA", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Doch, mein Heiland, dencke nicht,", "tokens": ["Doch", ",", "mein", "Hei\u00b7land", ",", "den\u00b7cke", "nicht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er unsre Liebe scheide;", "tokens": ["Da\u00df", "er", "uns\u00b7re", "Lie\u00b7be", "schei\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Meines Glaubens Zuversicht", "tokens": ["Mei\u00b7nes", "Glau\u00b7bens", "Zu\u00b7ver\u00b7sicht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trozt in deinem Unschuldskleide", "tokens": ["Trozt", "in", "dei\u00b7nem", "Un\u00b7schulds\u00b7klei\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Satan, H\u00f6lle, Tod und Welt,", "tokens": ["Sa\u00b7tan", ",", "H\u00f6l\u00b7le", ",", "Tod", "und", "Welt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn auch alles bricht und f\u00e4llt.", "tokens": ["Wenn", "auch", "al\u00b7les", "bricht", "und", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "W\u00e4r auch meine Schuld so gro\u00df", "tokens": ["W\u00e4r", "auch", "mei\u00b7ne", "Schuld", "so", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als des ganzen Volcks zusammen,", "tokens": ["Als", "des", "gan\u00b7zen", "Volcks", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00fcndigt ich auf Gnade los,", "tokens": ["S\u00fcn\u00b7digt", "ich", "auf", "Gna\u00b7de", "los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00fclf ich dich in Tod verdammen,", "tokens": ["H\u00fclf", "ich", "dich", "in", "Tod", "ver\u00b7dam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja begieng ich noch zur Zeit", "tokens": ["Ja", "be\u00b7gieng", "ich", "noch", "zur", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Laster M\u00f6gligkeit,", "tokens": ["Al\u00b7ler", "Las\u00b7ter", "M\u00f6g\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Dennoch suchten Ernst und Reu", "tokens": ["Den\u00b7noch", "such\u00b7ten", "Ernst", "und", "Reu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "KON", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich, du Vorspruch aller Armen,", "tokens": ["Dich", ",", "du", "Vor\u00b7spruch", "al\u00b7ler", "Ar\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und verspr\u00e4chen sich dabey", "tokens": ["Und", "ver\u00b7spr\u00e4\u00b7chen", "sich", "da\u00b7bey"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein gewaltiges Erbarmen.", "tokens": ["Ein", "ge\u00b7wal\u00b7ti\u00b7ges", "Er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dein Verdienst gilt ewiglich,", "tokens": ["Dein", "Ver\u00b7dienst", "gilt", "e\u00b7wig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und in dieses h\u00fcll ich mich.", "tokens": ["Und", "in", "die\u00b7ses", "h\u00fcll", "ich", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "PPER", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Klopft die lezte Botschaft an,", "tokens": ["Klopft", "die", "lez\u00b7te", "Bot\u00b7schaft", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Geh ich freudig von der Erden;", "tokens": ["Geh", "ich", "freu\u00b7dig", "von", "der", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn dein Wort nicht l\u00fcgen kan,", "tokens": ["Wenn", "dein", "Wort", "nicht", "l\u00fc\u00b7gen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mu\u00df mir Heil und Himmel werden.", "tokens": ["Mu\u00df", "mir", "Heil", "und", "Him\u00b7mel", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "KON", "NN", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "K\u00e4men auch nur zween hinein,", "tokens": ["K\u00e4\u00b7men", "auch", "nur", "zween", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Will ich doch der andre seyn.", "tokens": ["Will", "ich", "doch", "der", "and\u00b7re", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "ADJA", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}