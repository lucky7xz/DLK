{"textgrid.poem.48584": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "16. Auf Herrn Heinrich Arninks und Jungfrau Elsgen van Schoten Hochzeit in Revel", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Venus sah' den Br\u00e4utgam sitzen", "tokens": ["Ve\u00b7nus", "sah'", "den", "Br\u00e4ut\u00b7gam", "sit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NE", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf den Spitzen", "tokens": ["auf", "den", "Spit\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "des geh\u00f6rnten Helikons,", "tokens": ["des", "ge\u00b7h\u00f6rn\u00b7ten", "He\u00b7li\u00b7kons", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da man sich vermeint zu sichern", "tokens": ["da", "man", "sich", "ver\u00b7meint", "zu", "si\u00b7chern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "VVPP", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "in den B\u00fcchern", "tokens": ["in", "den", "B\u00fc\u00b7chern"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "f\u00fcr den Listen ihres Sohns.", "tokens": ["f\u00fcr", "den", "Lis\u00b7ten", "ih\u00b7res", "Sohns", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Komm, Kind, sprach sie, la\u00df die St\u00e4rke", "tokens": ["Komm", ",", "Kind", ",", "sprach", "sie", ",", "la\u00df", "die", "St\u00e4r\u00b7ke"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "VVFIN", "PPER", "$,", "VVIMP", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "unsrer Werke", "tokens": ["uns\u00b7rer", "Wer\u00b7ke"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Allen heute werden klar!", "tokens": ["Al\u00b7len", "heu\u00b7te", "wer\u00b7den", "klar", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Pindus ists, der mich nicht ehret;", "tokens": ["Pin\u00b7dus", "ists", ",", "der", "mich", "nicht", "eh\u00b7ret", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "dich versehret", "tokens": ["dich", "ver\u00b7seh\u00b7ret"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "der Gelehrten blasse Schaar.", "tokens": ["der", "Ge\u00b7lehr\u00b7ten", "blas\u00b7se", "Schaar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Eilends nam das Kind zusammen", "tokens": ["Ei\u00b7lends", "nam", "das", "Kind", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Pfeil' und Flammen,", "tokens": ["Pfeil'", "und", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "eilends sa\u00df er auf zu ihr;", "tokens": ["ei\u00b7lends", "sa\u00df", "er", "auf", "zu", "ihr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "APPR", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "eilends fuhr er durch die Wiesen", "tokens": ["ei\u00b7lends", "fuhr", "er", "durch", "die", "Wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "der Odrysen,", "tokens": ["der", "Od\u00b7ry\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "edles Thessalis, zu dir.", "tokens": ["ed\u00b7les", "Thes\u00b7sa\u00b7lis", ",", "zu", "dir", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NE", "$,", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Alle funden sich am Reien", "tokens": ["Al\u00b7le", "fun\u00b7den", "sich", "am", "Rei\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "voller Schreien,", "tokens": ["vol\u00b7ler", "Schrei\u00b7en", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "voller Jauchzen, wie man lacht;", "tokens": ["vol\u00b7ler", "Jauch\u00b7zen", ",", "wie", "man", "lacht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle sahen sie sich spritzen", "tokens": ["Al\u00b7le", "sa\u00b7hen", "sie", "sich", "sprit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "aus der Pf\u00fctzen,", "tokens": ["aus", "der", "Pf\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "die das Fl\u00fcgelpferd gemacht.", "tokens": ["die", "das", "Fl\u00fc\u00b7gel\u00b7pferd", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Eh' sich Iemand das versahe,", "tokens": ["Eh'", "sich", "Ie\u00b7mand", "das", "ver\u00b7sa\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "NE", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "traten nahe", "tokens": ["tra\u00b7ten", "na\u00b7he"], "token_info": ["word", "word"], "pos": ["VVFIN", "PTKVZ"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Venus und ihr Zypripor.", "tokens": ["Ve\u00b7nus", "und", "ihr", "Zyp\u00b7ri\u00b7por", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PPOSAT", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "D\u00fcrft ihr, sprachen sie, mehr G\u00e4ste", "tokens": ["D\u00fcrft", "ihr", ",", "spra\u00b7chen", "sie", ",", "mehr", "G\u00e4s\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "zu dem Feste?", "tokens": ["zu", "dem", "Fes\u00b7te", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "--+-", "measure": "anapaest.init"}, "line.6": {"text": "Nein! sprach Klio. Das darvor!", "tokens": ["Nein", "!", "sprach", "Klio", ".", "Das", "dar\u00b7vor", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVFIN", "NE", "$.", "ART", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Amor bot ihr bald die Spitze", "tokens": ["A\u00b7mor", "bot", "ihr", "bald", "die", "Spit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mit dem Flitze,", "tokens": ["mit", "dem", "Flit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "den er gleich auch schnellte los.", "tokens": ["den", "er", "gleich", "auch", "schnell\u00b7te", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Drauf f\u00e4llt unser Br\u00e4utgam eben", "tokens": ["Drauf", "f\u00e4llt", "un\u00b7ser", "Br\u00e4ut\u00b7gam", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPOSAT", "NE", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "ohne Leben", "tokens": ["oh\u00b7ne", "Le\u00b7ben"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "in der Kr\u00e4uter gr\u00fcnen Scho\u00df.", "tokens": ["in", "der", "Kr\u00e4u\u00b7ter", "gr\u00fc\u00b7nen", "Scho\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Da kam Zynthius, der sch\u00f6ne,", "tokens": ["Da", "kam", "Zynt\u00b7hi\u00b7us", ",", "der", "sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,", "ART", "ADJA", "$,"], "meter": "-+----+-", "measure": "dactylic.init"}, "line.2": {"text": "mit Get\u00f6ne", "tokens": ["mit", "Ge\u00b7t\u00f6\u00b7ne"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "durch den dicken Dannenwald.", "tokens": ["durch", "den", "di\u00b7cken", "Dan\u00b7nen\u00b7wald", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle die gesamten Feinde", "tokens": ["Al\u00b7le", "die", "ge\u00b7sam\u00b7ten", "Fein\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wurden Freunde,", "tokens": ["wur\u00b7den", "Freun\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "und der Tote lebte bald.", "tokens": ["und", "der", "To\u00b7te", "leb\u00b7te", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Mir ists leide, sprach Zythere,", "tokens": ["Mir", "ists", "lei\u00b7de", ",", "sprach", "Zy\u00b7the\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "$,", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df ich h\u00f6re,", "tokens": ["da\u00df", "ich", "h\u00f6\u00b7re", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "da\u00df der Fremde ward verletzt.", "tokens": ["da\u00df", "der", "Frem\u00b7de", "ward", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er ist w\u00fcrdig meiner Gnade.", "tokens": ["Er", "ist", "w\u00fcr\u00b7dig", "mei\u00b7ner", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieser Schade", "tokens": ["Die\u00b7ser", "Scha\u00b7de"], "token_info": ["word", "word"], "pos": ["PDAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "soll ihm reichlich sein ersetzt.", "tokens": ["soll", "ihm", "reich\u00b7lich", "sein", "er\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VAINF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Bei den g\u00fcldnen Karitinnen", "tokens": ["Bei", "den", "g\u00fcld\u00b7nen", "Ka\u00b7ri\u00b7tin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ward sie innen", "tokens": ["ward", "sie", "in\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "einer menschlichen Gestalt.", "tokens": ["ei\u00b7ner", "menschli\u00b7chen", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Diese, sprach sie, soll ihn herzen", "tokens": ["Die\u00b7se", ",", "sprach", "sie", ",", "soll", "ihn", "her\u00b7zen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "$,", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "f\u00fcr die Schmerzen,", "tokens": ["f\u00fcr", "die", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "f\u00fcr die schimpfliche Gewalt.", "tokens": ["f\u00fcr", "die", "schimpf\u00b7li\u00b7che", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Erato lief mit Melposen", "tokens": ["E\u00b7ra\u00b7to", "lief", "mit", "Mel\u00b7po\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und brach Rosen", "tokens": ["und", "brach", "Ro\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "f\u00fcr das neuverm\u00e4hlte Paar,", "tokens": ["f\u00fcr", "das", "neu\u00b7ver\u00b7m\u00e4hl\u00b7te", "Paar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und die Andern schrien aus Freuden:", "tokens": ["und", "die", "An\u00b7dern", "schri\u00b7en", "aus", "Freu\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "APPR", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wol sei Beiden!,", "tokens": ["Wol", "sei", "Bei\u00b7den", "!", ","], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$.", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "da\u00df die Luft voll T\u00f6nens war.", "tokens": ["da\u00df", "die", "Luft", "voll", "T\u00f6\u00b7nens", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Seid erfreut, ihr Hochzeit-G\u00e4ste,", "tokens": ["Seid", "er\u00b7freut", ",", "ihr", "Hoch\u00b7zeit\u00b7G\u00e4s\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf das Beste!", "tokens": ["auf", "das", "Bes\u00b7te", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Paphos und Olymp sind eins.", "tokens": ["Pa\u00b7phos", "und", "O\u00b7lymp", "sind", "eins", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAFIN", "PIS", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Unser Br\u00e4utgam hat die Beute.", "tokens": ["Un\u00b7ser", "Br\u00e4ut\u00b7gam", "hat", "die", "Beu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schont auf heute", "tokens": ["Schont", "auf", "heu\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "APPR", "ADV"], "meter": "-+--", "measure": "dactylic.init"}, "line.6": {"text": "keiner Kost und keines Weins!", "tokens": ["kei\u00b7ner", "Kost", "und", "kei\u00b7nes", "Weins", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Die gestirnten L\u00fcfte scherzen.", "tokens": ["Die", "ge\u00b7stirn\u00b7ten", "L\u00fcf\u00b7te", "scher\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tausent Kerzen,", "tokens": ["Tau\u00b7sent", "Ker\u00b7zen", ","], "token_info": ["word", "word", "punct"], "pos": ["CARD", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "tausent lichter Fackeln stehn.", "tokens": ["tau\u00b7sent", "lich\u00b7ter", "Fa\u00b7ckeln", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Di\u00df sind Hymens g\u00fcldne Boten.", "tokens": ["Di\u00df", "sind", "Hy\u00b7mens", "g\u00fcld\u00b7ne", "Bo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die von Schoten", "tokens": ["Die", "von", "Scho\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "soll nun stracks zu Bette gehn!", "tokens": ["soll", "nun", "stracks", "zu", "Bet\u00b7te", "gehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Sch\u00f6ne Braut, seid ohne Sorgen", "tokens": ["Sch\u00f6\u00b7ne", "Braut", ",", "seid", "oh\u00b7ne", "Sor\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "f\u00fcr dem Morgen,", "tokens": ["f\u00fcr", "dem", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "der euch euren Namen nimmt!", "tokens": ["der", "euch", "eu\u00b7ren", "Na\u00b7men", "nimmt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Um was ihr euch halb betr\u00fcbet", "tokens": ["Um", "was", "ihr", "euch", "halb", "be\u00b7tr\u00fc\u00b7bet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PWS", "PPER", "PRF", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und doch liebet,", "tokens": ["und", "doch", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "ist uns Allen so bestimmt.", "tokens": ["ist", "uns", "Al\u00b7len", "so", "be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Tr\u00f6stet nun, d\u00f6rft ihr euch trauen,", "tokens": ["Tr\u00f6s\u00b7tet", "nun", ",", "d\u00f6rft", "ihr", "euch", "trau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "VVFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "ihr Jungfrauen,", "tokens": ["ihr", "Jung\u00b7frau\u00b7en", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "k\u00fc\u00dft die Braut zum Letzten nun!", "tokens": ["k\u00fc\u00dft", "die", "Braut", "zum", "Letz\u00b7ten", "nun", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Andre, was ihr lasset,", "tokens": ["Und", "das", "And\u00b7re", ",", "was", "ihr", "las\u00b7set", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "sie nicht hasset,", "tokens": ["sie", "nicht", "has\u00b7set", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "das soll ihr der Liebste tun.", "tokens": ["das", "soll", "ihr", "der", "Liebs\u00b7te", "tun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}