{"dta.poem.10115": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Bluhmen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Hierauf begeb' ich mich in meinem Sinn", "tokens": ["Hier\u00b7auf", "be\u00b7geb'", "ich", "mich", "in", "mei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nach einem Bluhmen-reichen Garten,", "tokens": ["Nach", "ei\u00b7nem", "Bluh\u00b7men\u00b7rei\u00b7chen", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und bl\u00fchendem Gefild\u2019, im dencken, hin.", "tokens": ["Und", "bl\u00fc\u00b7hen\u00b7dem", "Ge\u00b7fild'", ",", "im", "den\u00b7cken", ",", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "APPRART", "VVINF", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "O welch ein Schmeltz! wie viele Arten", "tokens": ["O", "welch", "ein", "Sch\u00b7meltz", "!", "wie", "vie\u00b7le", "Ar\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PIAT", "ART", "NN", "$.", "PWAV", "PIAT", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von sch\u00f6nen Farben! welche Menge!", "tokens": ["Von", "sch\u00f6\u00b7nen", "Far\u00b7ben", "!", "wel\u00b7che", "Men\u00b7ge", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "PWAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und auch zugleich, o welche Symmetrie!", "tokens": ["Und", "auch", "zu\u00b7gleich", ",", "o", "wel\u00b7che", "Sym\u00b7me\u00b7trie", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "FM", "PWAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wie stimmt die\u00df gl\u00e4ntzende Gepr\u00e4nge,", "tokens": ["Wie", "stimmt", "die\u00df", "gl\u00e4nt\u00b7zen\u00b7de", "Ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PDS", "ADJA", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "In einer s\u00fcssen Harmonie,", "tokens": ["In", "ei\u00b7ner", "s\u00fcs\u00b7sen", "Har\u00b7mo\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und, in dem bunten Wunder-Schein,", "tokens": ["Und", ",", "in", "dem", "bun\u00b7ten", "Wun\u00b7der\u00b7Schein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die holde Mischung doch so lieblich \u00fcberein!", "tokens": ["Die", "hol\u00b7de", "Misc\u00b7hung", "doch", "so", "lieb\u00b7lich", "\u00fc\u00b7be\u00b7re\u00b7in", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Welch eine Schilderey! wer hat die Pracht", "tokens": ["Welch", "ei\u00b7ne", "Schil\u00b7de\u00b7rey", "!", "wer", "hat", "die", "Pracht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "$.", "PWS", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "So unbegreifflich sch\u00f6n gemacht?", "tokens": ["So", "un\u00b7be\u00b7greif\u00b7flich", "sch\u00f6n", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit welchem Uberflu\u00df sind hier die Zierlichkeiten", "tokens": ["Mit", "wel\u00b7chem", "U\u00b7ber\u00b7flu\u00df", "sind", "hier", "die", "Zier\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verschwendet! ach woher? aus welcher Sch\u00f6nheits-Quelle", "tokens": ["Ver\u00b7schwen\u00b7det", "!", "ach", "wo\u00b7her", "?", "aus", "wel\u00b7cher", "Sch\u00f6n\u00b7heits\u00b7Quel\u00b7le"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "$.", "XY", "PWAV", "$.", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sind solche reitzende Beschaffenheiten,", "tokens": ["Sind", "sol\u00b7che", "reit\u00b7zen\u00b7de", "Be\u00b7schaf\u00b7fen\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Die wir aus einer ieden Stelle", "tokens": ["Die", "wir", "aus", "ei\u00b7ner", "ie\u00b7den", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "In solcher F\u00fclle sehn, entsprungen, herzuleiten?", "tokens": ["In", "sol\u00b7cher", "F\u00fcl\u00b7le", "sehn", ",", "ent\u00b7sprun\u00b7gen", ",", "her\u00b7zu\u00b7lei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$,", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Was ist doch an ihm selbst der Ursprung solches Lichts,", "tokens": ["Was", "ist", "doch", "an", "ihm", "selbst", "der", "Ur\u00b7sprung", "sol\u00b7ches", "Lichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "APPR", "PPER", "ADV", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Freud, Ergetzlichkeit, und Nahrung des Gesichts?", "tokens": ["Der", "Freud", ",", "Er\u00b7getz\u00b7lich\u00b7keit", ",", "und", "Nah\u00b7rung", "des", "Ge\u00b7sichts", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wir wollen von dem Glantz und Schmuck, der allgemein,", "tokens": ["Wir", "wol\u00b7len", "von", "dem", "Glantz", "und", "Schmuck", ",", "der", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "KON", "NN", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Nun etwas weiter gehen,", "tokens": ["Nun", "et\u00b7was", "wei\u00b7ter", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Und nur, von einigen insonderheit,", "tokens": ["Und", "nur", ",", "von", "ei\u00b7ni\u00b7gen", "in\u00b7son\u00b7der\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Die Zierde, Pracht, und Bildung sehen.", "tokens": ["Die", "Zier\u00b7de", ",", "Pracht", ",", "und", "Bil\u00b7dung", "se\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Lasst uns diejenigen, ohn auf die Wahl zu achten,", "tokens": ["Lasst", "uns", "die\u00b7je\u00b7ni\u00b7gen", ",", "ohn", "auf", "die", "Wahl", "zu", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "$,", "KOUI", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So ungefehr zuerst uns aufst\u00f6sst, erst betrachten!", "tokens": ["So", "un\u00b7ge\u00b7fehr", "zu\u00b7erst", "uns", "auf\u00b7st\u00f6sst", ",", "erst", "be\u00b7trach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PPER", "VVFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie bricht nur eben auf, und hat noch allen Glantz", "tokens": ["Sie", "bricht", "nur", "e\u00b7ben", "auf", ",", "und", "hat", "noch", "al\u00b7len", "Glantz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "KON", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der frischen Lieblichkeit.", "tokens": ["Der", "fri\u00b7schen", "Lieb\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Trifft man bey Menschen wol so helle Farben an?", "tokens": ["Trifft", "man", "bey", "Men\u00b7schen", "wol", "so", "hel\u00b7le", "Far\u00b7ben", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NN", "ADV", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und die, zu gleicher Zeit,", "tokens": ["Und", "die", ",", "zu", "glei\u00b7cher", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "So sanft, so angenehm? Ist eine Kunst zu finden,", "tokens": ["So", "sanft", ",", "so", "an\u00b7ge\u00b7nehm", "?", "Ist", "ei\u00b7ne", "Kunst", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$.", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wodurch in einem Zeug man F\u00e4den mancher Art", "tokens": ["Wo\u00b7durch", "in", "ei\u00b7nem", "Zeug", "man", "F\u00e4\u00b7den", "man\u00b7cher", "Art"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "PIS", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So gar erstaunlich d\u00fcnn\u2019 und zart", "tokens": ["So", "gar", "er\u00b7staun\u00b7lich", "d\u00fcnn'", "und", "zart"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zusammen weben und verbinden,", "tokens": ["Zu\u00b7sam\u00b7men", "we\u00b7ben", "und", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "So \u00fcberk\u00fcnstlich f\u00fcgen kann.", "tokens": ["So", "\u00fc\u00b7ber\u00b7k\u00fcnst\u00b7lich", "f\u00fc\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Man bringe hier,", "tokens": ["Man", "brin\u00b7ge", "hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Bey dieser bunten Bl\u00e4tter Zier,", "tokens": ["Bey", "die\u00b7ser", "bun\u00b7ten", "Bl\u00e4t\u00b7ter", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Selbst Salomonis Kleid,", "tokens": ["Selbst", "Sa\u00b7lo\u00b7mo\u00b7nis", "Kleid", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Den Purpur seiner Herrlichkeit:", "tokens": ["Den", "Pur\u00b7pur", "sei\u00b7ner", "Herr\u00b7lich\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wie grob, wie ungleich, rauch! ja recht wie haarne Decken,", "tokens": ["Wie", "grob", ",", "wie", "un\u00b7gleich", ",", "rauch", "!", "ja", "recht", "wie", "haar\u00b7ne", "De\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,", "ADJD", "$.", "ADV", "ADJD", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wie schlecht gef\u00e4rbt, wie voller Flecken", "tokens": ["Wie", "schlecht", "ge\u00b7f\u00e4rbt", ",", "wie", "vol\u00b7ler", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVPP", "$,", "PWAV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Ist dieses, bey der Bluhmen Pracht,", "tokens": ["Ist", "die\u00b7ses", ",", "bey", "der", "Bluh\u00b7men", "Pracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Gewebt, gef\u00e4rbet und gemacht!", "tokens": ["Ge\u00b7webt", ",", "ge\u00b7f\u00e4r\u00b7bet", "und", "ge\u00b7macht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wenn aber auch die Bluhme nicht so sch\u00f6n", "tokens": ["Wenn", "a\u00b7ber", "auch", "die", "Bluh\u00b7me", "nicht", "so", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "PTKNEG", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In allen ihren Theilen w\u00e4re;", "tokens": ["In", "al\u00b7len", "ih\u00b7ren", "Thei\u00b7len", "w\u00e4\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kann man was zierlichers, als wie ihr Gantzes, sehn", "tokens": ["Kann", "man", "was", "zier\u00b7li\u00b7chers", ",", "als", "wie", "ihr", "Gant\u00b7zes", ",", "sehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "PIS", "PWS", "ADV", "$,", "KOUS", "KOKOM", "PPOSAT", "NN", "$,", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In ihrer Symmetrie? seht den Zusammenhang,", "tokens": ["In", "ih\u00b7rer", "Sym\u00b7me\u00b7trie", "?", "seht", "den", "Zu\u00b7sam\u00b7men\u00b7hang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wie Regel-recht der Bl\u00e4tter Nang!", "tokens": ["Wie", "Re\u00b7gel\u00b7recht", "der", "Bl\u00e4t\u00b7ter", "Nang", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie richtig, ordentlich ist im Zusammenhalt", "tokens": ["Wie", "rich\u00b7tig", ",", "or\u00b7dent\u00b7lich", "ist", "im", "Zu\u00b7sam\u00b7men\u00b7halt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "ADJD", "VAFIN", "APPRART", "NN"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Der gantzen Bluhmen Form und zierliche Gestalt:", "tokens": ["Der", "gant\u00b7zen", "Bluh\u00b7men", "Form", "und", "zier\u00b7li\u00b7che", "Ge\u00b7stalt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Man sollte, wenn man recht, mit achtsamen Gem\u00fcth", "tokens": ["Man", "soll\u00b7te", ",", "wenn", "man", "recht", ",", "mit", "acht\u00b7sa\u00b7men", "Ge\u00b7m\u00fcth"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VMFIN", "$,", "KOUS", "PIS", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Des Sch\u00f6pfers Weisheit, Macht, ja fast Gef\u00e4lligkeit,", "tokens": ["Des", "Sch\u00f6p\u00b7fers", "Weis\u00b7heit", ",", "Macht", ",", "ja", "fast", "Ge\u00b7f\u00e4l\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "NN", "$,", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von einer Bluhme sieht,", "tokens": ["Von", "ei\u00b7ner", "Bluh\u00b7me", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Fast glauben, da\u00df derselbe Schein", "tokens": ["Fast", "glau\u00b7ben", ",", "da\u00df", "der\u00b7sel\u00b7be", "Schein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVINF", "$,", "KOUS", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Best\u00e4ndig werd\u2019 und m\u00fcsse prangen.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "werd'", "und", "m\u00fcs\u00b7se", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "KON", "VMFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Allein,", "tokens": ["Al\u00b7lein", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "So ist sie allbereit,", "tokens": ["So", "ist", "sie", "all\u00b7be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Vom Morgen bis zur Nacht, verwelckt, und schon vergangen.", "tokens": ["Vom", "Mor\u00b7gen", "bis", "zur", "Nacht", ",", "ver\u00b7welckt", ",", "und", "schon", "ver\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN", "$,", "VVPP", "$,", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was sollen wir denn nicht gedencken", "tokens": ["Was", "sol\u00b7len", "wir", "denn", "nicht", "ge\u00b7den\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "PTKNEG", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Vom unerme\u00dflichen und tieffen Ocean", "tokens": ["Vom", "un\u00b7er\u00b7me\u00df\u00b7li\u00b7chen", "und", "tief\u00b7fen", "O\u00b7cean"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Der Vollenkommenheit, aus welchem auf ein Kraut", "tokens": ["Der", "Vol\u00b7len\u00b7kom\u00b7men\u00b7heit", ",", "aus", "wel\u00b7chem", "auf", "ein", "Kraut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sich solche Zier und Pracht, in solcher F\u00fclle sencken,", "tokens": ["Sich", "sol\u00b7che", "Zier", "und", "Pracht", ",", "in", "sol\u00b7cher", "F\u00fcl\u00b7le", "sen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "KON", "NN", "$,", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die man doch so verg\u00e4nglich schaut.", "tokens": ["Die", "man", "doch", "so", "ver\u00b7g\u00e4ng\u00b7lich", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wie wird ein solcher GOTT nicht Geister schm\u00fccken", "tokens": ["Wie", "wird", "ein", "sol\u00b7cher", "GoTT", "nicht", "Geis\u00b7ter", "schm\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "PIAT", "NN", "PTKNEG", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und sie beseeligen! Er, der mit solchem Schein", "tokens": ["Und", "sie", "be\u00b7see\u00b7li\u00b7gen", "!", "Er", ",", "der", "mit", "sol\u00b7chem", "Schein"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVINF", "$.", "PPER", "$,", "PRELS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Thiere Futter schm\u00fcckt! kann man so blind denn seyn,", "tokens": ["Der", "Thie\u00b7re", "Fut\u00b7ter", "schm\u00fcckt", "!", "kann", "man", "so", "blind", "denn", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "VMFIN", "PIS", "ADV", "ADJD", "KON", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nach Sch\u00f6nheit, Jugend, Ehr, mit solchem Ernst zu rennen,", "tokens": ["Nach", "Sch\u00f6n\u00b7heit", ",", "Ju\u00b7gend", ",", "Ehr", ",", "mit", "sol\u00b7chem", "Ernst", "zu", "ren\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,", "APPR", "PIAT", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und selbe wahre G\u00fcter nennen?", "tokens": ["Und", "sel\u00b7be", "wah\u00b7re", "G\u00fc\u00b7ter", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da selbe doch, den Bluhmen gleich, verschwinden,", "tokens": ["Da", "sel\u00b7be", "doch", ",", "den", "Bluh\u00b7men", "gleich", ",", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "ART", "NN", "ADV", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und \u00f6ffters morgen schon nicht mehr zu finden.", "tokens": ["Und", "\u00f6ff\u00b7ters", "mor\u00b7gen", "schon", "nicht", "mehr", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}