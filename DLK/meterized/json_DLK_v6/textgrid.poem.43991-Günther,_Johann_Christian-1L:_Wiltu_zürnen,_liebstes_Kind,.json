{"textgrid.poem.43991": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wiltu z\u00fcrnen, liebstes Kind,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wiltu z\u00fcrnen, liebstes Kind,", "tokens": ["Wil\u00b7tu", "z\u00fcr\u00b7nen", ",", "liebs\u00b7tes", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach so z\u00fcrne mit dem Gl\u00fccke,", "tokens": ["Ach", "so", "z\u00fcr\u00b7ne", "mit", "dem", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "De\u00dfen Unrecht, Zorn und T\u00fccke", "tokens": ["De\u00b7\u00dfen", "Un\u00b7recht", ",", "Zorn", "und", "T\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsrer Trennung Ursach sind;", "tokens": ["Uns\u00b7rer", "Tren\u00b7nung", "Ur\u00b7sach", "sind", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Z\u00fcrne gar mit meinem Herzen,", "tokens": ["Z\u00fcr\u00b7ne", "gar", "mit", "mei\u00b7nem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das vorhin in St\u00fccken bricht,", "tokens": ["Das", "vor\u00b7hin", "in", "St\u00fc\u00b7cken", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Ich verbei\u00dfe gern die Schmerzen,", "tokens": ["Ich", "ver\u00b7bei\u00b7\u00dfe", "gern", "die", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Fluche nur der Liebe nicht!", "tokens": ["Flu\u00b7che", "nur", "der", "Lie\u00b7be", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Fluche nur der Liebe nicht!", "tokens": ["Flu\u00b7che", "nur", "der", "Lie\u00b7be", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was dein z\u00e4rtlich Fleisch erduldet,", "tokens": ["Was", "dein", "z\u00e4rt\u00b7lich", "Fleisch", "er\u00b7dul\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat sie warlich nicht verschuldet,", "tokens": ["Hat", "sie", "war\u00b7lich", "nicht", "ver\u00b7schul\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ob es gleich die Misgunst spricht.", "tokens": ["Ob", "es", "gleich", "die", "Mis\u00b7gunst", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mein Verh\u00e4ngn\u00fc\u00df, nicht dein K\u00fc\u00dfen,", "tokens": ["Mein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", ",", "nicht", "dein", "K\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat dich in den Gram gesezt,", "tokens": ["Hat", "dich", "in", "den", "Gram", "ge\u00b7sezt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Der mein redliches Gewi\u00dfen", "tokens": ["Der", "mein", "red\u00b7li\u00b7ches", "Ge\u00b7wi\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Zwar betr\u00fcbt, doch nicht verlezt.", "tokens": ["Zwar", "be\u00b7tr\u00fcbt", ",", "doch", "nicht", "ver\u00b7lezt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Da\u00df du mir als meine Braut", "tokens": ["Da\u00df", "du", "mir", "als", "mei\u00b7ne", "Braut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf ein keusches Widerstreben", "tokens": ["Auf", "ein", "keu\u00b7sches", "Wi\u00b7der\u00b7stre\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seele, Geist und Brust gegeben", "tokens": ["See\u00b7le", ",", "Geist", "und", "Brust", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mir, was du hast, vertraut,", "tokens": ["Und", "mir", ",", "was", "du", "hast", ",", "ver\u00b7traut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "$,", "PWS", "PPER", "VAFIN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist so wenig eine S\u00fcnde", "tokens": ["Ist", "so", "we\u00b7nig", "ei\u00b7ne", "S\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als mein Ku\u00df ein Judasku\u00df,", "tokens": ["Als", "mein", "Ku\u00df", "ein", "Ju\u00b7das\u00b7ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ob ich gleich von meinem Kinde", "tokens": ["Ob", "ich", "gleich", "von", "mei\u00b7nem", "Kin\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Unverhoft entrinnen mu\u00df.", "tokens": ["Un\u00b7ver\u00b7hoft", "ent\u00b7rin\u00b7nen", "mu\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Glaube, da\u00df ich mir dein Weh", "tokens": ["Glau\u00b7be", ",", "da\u00df", "ich", "mir", "dein", "Weh"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Thr\u00e4nen Meng und Sch\u00e4rfe", "tokens": ["Und", "der", "Thr\u00e4\u00b7nen", "Meng", "und", "Sch\u00e4r\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NE", "KON", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "In mir selbst mit Angst entwerfe,", "tokens": ["In", "mir", "selbst", "mit", "Angst", "ent\u00b7wer\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn ich jezt zur\u00fccke geh", "tokens": ["Wenn", "ich", "jezt", "zu\u00b7r\u00fc\u00b7cke", "geh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und den s\u00fc\u00dfen Bund bedencke,", "tokens": ["Und", "den", "s\u00fc\u00b7\u00dfen", "Bund", "be\u00b7den\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Den wir bey erfolgter Nacht", "tokens": ["Den", "wir", "bey", "er\u00b7folg\u00b7ter", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ohne Kuppler, List und R\u00e4ncke", "tokens": ["Oh\u00b7ne", "Kupp\u00b7ler", ",", "List", "und", "R\u00e4n\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Mit Entz\u00fcckung fest gemacht.", "tokens": ["Mit", "Ent\u00b7z\u00fc\u00b7ckung", "fest", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was vor keusche Z\u00e4rtligkeit", "tokens": ["Was", "vor", "keu\u00b7sche", "Z\u00e4rt\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sog ich aus dem lieben Munde,", "tokens": ["Sog", "ich", "aus", "dem", "lie\u00b7ben", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem es etwan diese Stunde,", "tokens": ["Dem", "es", "et\u00b7wan", "die\u00b7se", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "PDAT", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Aber mir zur Angst, gereut!", "tokens": ["A\u00b7ber", "mir", "zur", "Angst", ",", "ge\u00b7reut", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "$,", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was vor hiziges Entz\u00fccken", "tokens": ["Was", "vor", "hi\u00b7zi\u00b7ges", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gab nicht dort die Jahrmarcktslust,", "tokens": ["Gab", "nicht", "dort", "die", "Jahr\u00b7marckts\u00b7lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Wo du mich mit na\u00dfen Blicken", "tokens": ["Wo", "du", "mich", "mit", "na\u00b7\u00dfen", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Um das Thor verla\u00dfen must!", "tokens": ["Um", "das", "Thor", "ver\u00b7la\u00b7\u00dfen", "must", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Himmel, ach, gedenck ich dran,", "tokens": ["Him\u00b7mel", ",", "ach", ",", "ge\u00b7denck", "ich", "dran", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$,", "VVIMP", "PPER", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ich damahls vor Gel\u00fcbde,", "tokens": ["Was", "ich", "da\u00b7mahls", "vor", "Ge\u00b7l\u00fcb\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als uns Neid und Spott betr\u00fcbte,", "tokens": ["Als", "uns", "Neid", "und", "Spott", "be\u00b7tr\u00fcb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wie viel ich sonst gethan,", "tokens": ["Und", "wie", "viel", "ich", "sonst", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du erh\u00f6rtest auch die Liebe", "tokens": ["Du", "er\u00b7h\u00f6r\u00b7test", "auch", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und bedrohtest die Gefahr,", "tokens": ["Und", "be\u00b7droh\u00b7test", "die", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Die bey unserm hei\u00dfen Triebe", "tokens": ["Die", "bey", "un\u00b7serm", "hei\u00b7\u00dfen", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Anfangs zu besorgen war.", "tokens": ["An\u00b7fangs", "zu", "be\u00b7sor\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Nunmehr hatt ich schon die Ruh;", "tokens": ["Nun\u00b7mehr", "hatt", "ich", "schon", "die", "Ruh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hofnung, Sehnsucht und Verlangen,", "tokens": ["Hof\u00b7nung", ",", "Sehn\u00b7sucht", "und", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dich nun v\u00f6llig zu empfangen,", "tokens": ["Dich", "nun", "v\u00f6l\u00b7lig", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eilten nach dem Hafen zu.", "tokens": ["Eil\u00b7ten", "nach", "dem", "Ha\u00b7fen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Phillis flocht bereits die Myrthen,", "tokens": ["Phil\u00b7lis", "flocht", "be\u00b7reits", "die", "Myr\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aber, ach, du Donnerwort,", "tokens": ["A\u00b7ber", ",", "ach", ",", "du", "Don\u00b7ner\u00b7wort", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "ITJ", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Eh sie noch mein Haupt umg\u00fcrthen,", "tokens": ["Eh", "sie", "noch", "mein", "Haupt", "um\u00b7g\u00fcr\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Mu\u00df ich sonder Abschied fort.", "tokens": ["Mu\u00df", "ich", "son\u00b7der", "Ab\u00b7schied", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "O wie manche, manche Nacht", "tokens": ["O", "wie", "man\u00b7che", ",", "man\u00b7che", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "PWAV", "PIS", "$,", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird mir noch auf harten K\u00fc\u00dfen", "tokens": ["Wird", "mir", "noch", "auf", "har\u00b7ten", "K\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Diese Glieder w\u00e4lzen m\u00fc\u00dfen,", "tokens": ["Die\u00b7se", "Glie\u00b7der", "w\u00e4l\u00b7zen", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVINF", "VMINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die du einmahl hoch geacht,", "tokens": ["Die", "du", "ein\u00b7mahl", "hoch", "ge\u00b7acht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die du sonst so sch\u00f6n gepriesen", "tokens": ["Die", "du", "sonst", "so", "sch\u00f6n", "ge\u00b7prie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADV", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und so z\u00e4rtlich angedr\u00fcckt,", "tokens": ["Und", "so", "z\u00e4rt\u00b7lich", "an\u00b7ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df es noch die Abendwiesen", "tokens": ["Da\u00df", "es", "noch", "die", "Ab\u00b7end\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und den jungen Hayn erquickt!", "tokens": ["Und", "den", "jun\u00b7gen", "Hayn", "er\u00b7quickt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sprich ver\u00e4chtlich, fluche, schilt,", "tokens": ["Sprich", "ver\u00b7\u00e4cht\u00b7lich", ",", "flu\u00b7che", ",", "schilt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVIMP", "ADJD", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Rei\u00df, verbrenne meine Lieder,", "tokens": ["Rei\u00df", ",", "ver\u00b7bren\u00b7ne", "mei\u00b7ne", "Lie\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Rufe deinem Menling wieder,", "tokens": ["Ru\u00b7fe", "dei\u00b7nem", "Men\u00b7ling", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der vielleicht noch immer gilt!", "tokens": ["Der", "viel\u00b7leicht", "noch", "im\u00b7mer", "gilt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Las dir nichts von mir mehr taugen,", "tokens": ["Las", "dir", "nichts", "von", "mir", "mehr", "tau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PIS", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ja, verfolge mich mit List \u2013", "tokens": ["Ja", ",", "ver\u00b7fol\u00b7ge", "mich", "mit", "List", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PRF", "APPR", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Phillis bleibt in meinen Augen,", "tokens": ["Phil\u00b7lis", "bleibt", "in", "mei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Was sie stets gewesen ist.", "tokens": ["Was", "sie", "stets", "ge\u00b7we\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Was du stets gewesen bist,", "tokens": ["Was", "du", "stets", "ge\u00b7we\u00b7sen", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine Braut und mein Vergn\u00fcgen,", "tokens": ["Mei\u00b7ne", "Braut", "und", "mein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das mir durch ein grausam F\u00fcgen", "tokens": ["Das", "mir", "durch", "ein", "grau\u00b7sam", "F\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "APPR", "ART", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jezt zur Marter worden ist,", "tokens": ["Jezt", "zur", "Mar\u00b7ter", "wor\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": ". . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.6": {"text": ". . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.7": {"text": ". . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.8": {"text": ". . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.11": {"line.1": {"text": "Himmel, der du mich erkennst,", "tokens": ["Him\u00b7mel", ",", "der", "du", "mich", "er\u00b7kennst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der du alles siehst und richtest,", "tokens": ["Der", "du", "al\u00b7les", "siehst", "und", "rich\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der du alles weist und schlichtest,", "tokens": ["Der", "du", "al\u00b7les", "weist", "und", "schlich\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der du bindest und zertrennst,", "tokens": ["Der", "du", "bin\u00b7dest", "und", "zer\u00b7trennst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Werd ich nicht von deinem Schlu\u00dfe", "tokens": ["Werd", "ich", "nicht", "von", "dei\u00b7nem", "Schlu\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit Gewalt davon gejagt,", "tokens": ["Mit", "Ge\u00b7walt", "da\u00b7von", "ge\u00b7jagt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O so werde meinem Fu\u00dfe", "tokens": ["O", "so", "wer\u00b7de", "mei\u00b7nem", "Fu\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ewig seine Ruh versagt.", "tokens": ["E\u00b7wig", "sei\u00b7ne", "Ruh", "ver\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ja, ich sage, macht der Tod", "tokens": ["Ja", ",", "ich", "sa\u00b7ge", ",", "macht", "der", "Tod"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "$,", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner Brust mehr Furcht und Plage,", "tokens": ["Mei\u00b7ner", "Brust", "mehr", "Furcht", "und", "Pla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als ich ihrentwegen trage,", "tokens": ["Als", "ich", "ih\u00b7rent\u00b7we\u00b7gen", "tra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ihr manches Wetter droht,", "tokens": ["Da", "ihr", "man\u00b7ches", "Wet\u00b7ter", "droht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "O so werde mein Gebl\u00fcte", "tokens": ["O", "so", "wer\u00b7de", "mein", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nach und nach durch Gram verzehrt;", "tokens": ["Nach", "und", "nach", "durch", "Gram", "ver\u00b7zehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "APPR", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Doch ich weis schon, mein Gem\u00fcthe", "tokens": ["Doch", "ich", "weis", "schon", ",", "mein", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "PTKVZ", "ADV", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist wohl etwas Be\u00dfers werth.", "tokens": ["Ist", "wohl", "et\u00b7was", "Be\u00b7\u00dfers", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "O wie manch galantes Kind", "tokens": ["O", "wie", "manch", "ga\u00b7lan\u00b7tes", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird mit mir noch Mitleid haben,", "tokens": ["Wird", "mit", "mir", "noch", "Mit\u00b7leid", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn wir beide l\u00e4ngst begraben", "tokens": ["Wenn", "wir", "bei\u00b7de", "l\u00e4ngst", "be\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mehr Staub als Knochen sind!", "tokens": ["Und", "mehr", "Staub", "als", "Kno\u00b7chen", "sind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KOUS", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "O wie manche wird das Leiden,", "tokens": ["O", "wie", "man\u00b7che", "wird", "das", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "PIS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So du meinetwegen fliehst,", "tokens": ["So", "du", "mei\u00b7net\u00b7we\u00b7gen", "fliehst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Als ein r\u00fchmlich Creuz beneiden,", "tokens": ["Als", "ein", "r\u00fchm\u00b7lich", "Creuz", "be\u00b7nei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Dem du dich aus Groll entziehst!", "tokens": ["Dem", "du", "dich", "aus", "Groll", "ent\u00b7ziehst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Schr\u00f6ckt dich nun mein Elend ab", "tokens": ["Schr\u00f6ckt", "dich", "nun", "mein", "E\u00b7lend", "ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und versagstu mir auf Erden", "tokens": ["Und", "ver\u00b7sags\u00b7tu", "mir", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle Hofnung, dein zu werden,", "tokens": ["Al\u00b7le", "Hof\u00b7nung", ",", "dein", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PPOSAT", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So erwarthe nur mein Grab.", "tokens": ["So", "er\u00b7wart\u00b7he", "nur", "mein", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nachmahls solstu sehn und h\u00f6ren,", "tokens": ["Nach\u00b7mahls", "sols\u00b7tu", "sehn", "und", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Doch vor dich bereits zu sp\u00e4t,", "tokens": ["Doch", "vor", "dich", "be\u00b7reits", "zu", "sp\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df auch die mein Lob verehren,", "tokens": ["Da\u00df", "auch", "die", "mein", "Lob", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Die mich jezt aus Neid geschm\u00e4ht.", "tokens": ["Die", "mich", "jezt", "aus", "Neid", "ge\u00b7schm\u00e4ht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}