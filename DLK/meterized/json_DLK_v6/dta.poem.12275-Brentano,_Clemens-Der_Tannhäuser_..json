{"dta.poem.12275": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Der Tannh\u00e4user .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nun will ich aber heben an,               ", "tokens": ["Nun", "will", "ich", "a\u00b7ber", "he\u00b7ben", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Tannh\u00e4user wollen wir singen,", "tokens": ["Vom", "Tann\u00b7h\u00e4u\u00b7ser", "wol\u00b7len", "wir", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und was er wunders hat gethan,", "tokens": ["Und", "was", "er", "wun\u00b7ders", "hat", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "NE", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Frau Venussinnen.", "tokens": ["Mit", "Frau", "Ve\u00b7nus\u00b7sin\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Der Tannh\u00e4user war ein Ritter gut,", "tokens": ["Der", "Tann\u00b7h\u00e4u\u00b7ser", "war", "ein", "Rit\u00b7ter", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Er wollt gro\u00df Wunder schauen,", "tokens": ["Er", "wollt", "gro\u00df", "Wun\u00b7der", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da zog er in Frau Venus Berg,", "tokens": ["Da", "zog", "er", "in", "Frau", "Ve\u00b7nus", "Berg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "NE", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Zu andern sch\u00f6nen Frauen.", "tokens": ["Zu", "an\u00b7dern", "sch\u00f6\u00b7nen", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u201eherr Tannh\u00e4user, Ihr seyd mir lieb,", "tokens": ["\u201e", "herr", "Tann\u00b7h\u00e4u\u00b7ser", ",", "Ihr", "seyd", "mir", "lieb", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "\u201edaran sollt Ihr gedenken,", "tokens": ["\u201e", "da\u00b7ran", "sollt", "Ihr", "ge\u00b7den\u00b7ken", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eihr habt mir einen Eid geschworen,", "tokens": ["\u201e", "ihr", "habt", "mir", "ei\u00b7nen", "Eid", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eihr wollt nicht von mir wanken.\u201c", "tokens": ["\u201e", "ihr", "wollt", "nicht", "von", "mir", "wan\u00b7ken", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "PTKNEG", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u201efrau Venus, ich hab' es nicht gethan,", "tokens": ["\u201e", "frau", "Ve\u00b7nus", ",", "ich", "hab'", "es", "nicht", "ge\u00b7than", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201eich will dem widersprechen,", "tokens": ["\u201e", "ich", "will", "dem", "wi\u00b7der\u00b7spre\u00b7chen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201edenn niemand spricht das mehr, als Ihr,", "tokens": ["\u201e", "denn", "nie\u00b7mand", "spricht", "das", "mehr", ",", "als", "Ihr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "PIS", "VVFIN", "ART", "ADV", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201egott helf mir zu den Rechten.\u201c", "tokens": ["\u201e", "gott", "helf", "mir", "zu", "den", "Rech\u00b7ten", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u201eherr Tannh\u00e4user, wie saget ihr mir!", "tokens": ["\u201e", "herr", "Tann\u00b7h\u00e4u\u00b7ser", ",", "wie", "sa\u00b7get", "ihr", "mir", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "PPER", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "\u201eihr sollet bey uns bleiben,", "tokens": ["\u201e", "ihr", "sol\u00b7let", "bey", "uns", "blei\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich geb Euch meiner Gespielen ein,", "tokens": ["\u201e", "ich", "geb", "Euch", "mei\u00b7ner", "Ge\u00b7spie\u00b7len", "ein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201ezu einem eh'lichen Weibe.", "tokens": ["\u201e", "zu", "ei\u00b7nem", "eh'\u00b7li\u00b7chen", "Wei\u00b7be", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "\u201enehme ich dann ein ander Weib,", "tokens": ["\u201e", "neh\u00b7me", "ich", "dann", "ein", "an\u00b7der", "Weib", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "\u201eals ich hab in meinem Sinne,", "tokens": ["\u201e", "als", "ich", "hab", "in", "mei\u00b7nem", "Sin\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201eso mu\u00df ich in der H\u00f6llen-Gluth,", "tokens": ["\u201e", "so", "mu\u00df", "ich", "in", "der", "H\u00f6l\u00b7len\u00b7Gluth", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eda ewiglich verbrennen.\u201c", "tokens": ["\u201e", "da", "e\u00b7wig\u00b7lich", "ver\u00b7bren\u00b7nen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u201edu sagst mir viel von der H\u00f6llengluth,", "tokens": ["\u201e", "du", "sagst", "mir", "viel", "von", "der", "H\u00f6l\u00b7len\u00b7gluth", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201edu hast es doch nicht befunden,", "tokens": ["\u201e", "du", "hast", "es", "doch", "nicht", "be\u00b7fun\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201egedenk an meinen rothen Mund,", "tokens": ["\u201e", "ge\u00b7denk", "an", "mei\u00b7nen", "ro\u00b7then", "Mund", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eder lacht zu allen Stunden.\u201c", "tokens": ["\u201e", "der", "lacht", "zu", "al\u00b7len", "Stun\u00b7den", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "VVFIN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "\u201ewas hilft mich Euer rother Mund,", "tokens": ["\u201e", "was", "hilft", "mich", "Eu\u00b7er", "ro\u00b7ther", "Mund", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eer ist mir gar unmehre,", "tokens": ["\u201e", "er", "ist", "mir", "gar", "un\u00b7meh\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201enun gib mir Urlaub Frau Venus zart,", "tokens": ["\u201e", "nun", "gib", "mir", "Ur\u00b7laub", "Frau", "Ve\u00b7nus", "zart", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVIMP", "PPER", "NN", "NN", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201edurch aller Frauen Ehre.\u201c", "tokens": ["\u201e", "durch", "al\u00b7ler", "Frau\u00b7en", "Eh\u00b7re", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "\u201eherr Tannh\u00e4user, wollt Ihr Urlaub han,", "tokens": ["\u201e", "herr", "Tann\u00b7h\u00e4u\u00b7ser", ",", "wollt", "Ihr", "Ur\u00b7laub", "han", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "VMFIN", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201eich will Euch keinen geben,", "tokens": ["\u201e", "ich", "will", "Euch", "kei\u00b7nen", "ge\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "PIAT", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201enun bleibet edler Tannh\u00e4user zart,", "tokens": ["\u201e", "nun", "blei\u00b7bet", "ed\u00b7ler", "Tann\u00b7h\u00e4u\u00b7ser", "zart", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "\u201eund frischet Euer Leben.\u201c", "tokens": ["\u201e", "und", "fri\u00b7schet", "Eu\u00b7er", "Le\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u201emein Leben ist schon worden krank,", "tokens": ["\u201e", "mein", "Le\u00b7ben", "ist", "schon", "wor\u00b7den", "krank", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ADV", "VAPP", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eich kann nicht l\u00e4nger bleiben,", "tokens": ["\u201e", "ich", "kann", "nicht", "l\u00e4n\u00b7ger", "blei\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201egebt mir Urlaub Fraue zart,", "tokens": ["\u201e", "gebt", "mir", "Ur\u00b7laub", "Frau\u00b7e", "zart", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "NN", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201evon Eurem stolzen Leibe.\u201c", "tokens": ["\u201e", "von", "Eu\u00b7rem", "stol\u00b7zen", "Lei\u00b7be", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u201eherr Tannh\u00e4user nicht sprecht also,", "tokens": ["\u201e", "herr", "Tann\u00b7h\u00e4u\u00b7ser", "nicht", "sprecht", "al\u00b7so", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "PTKNEG", "VVFIN", "ADV", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "\u201eihr seyd nicht wohl bey Sinnen,", "tokens": ["\u201e", "ihr", "seyd", "nicht", "wohl", "bey", "Sin\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKNEG", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201enun la\u00dft uns in die Kammer gehn,", "tokens": ["\u201e", "nun", "la\u00dft", "uns", "in", "die", "Kam\u00b7mer", "gehn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund spielen der heimlichen Minnen.\u201c", "tokens": ["\u201e", "und", "spie\u00b7len", "der", "heim\u00b7li\u00b7chen", "Min\u00b7nen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.12": {"line.1": {"text": "\u201eeure Minne ist mir worden leid,", "tokens": ["\u201e", "eu\u00b7re", "Min\u00b7ne", "ist", "mir", "wor\u00b7den", "leid", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "PPER", "VAPP", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201eich hab in meinem Sinne,", "tokens": ["\u201e", "ich", "hab", "in", "mei\u00b7nem", "Sin\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eo Venus, edle Jungfrau zart,", "tokens": ["\u201e", "o", "Ve\u00b7nus", ",", "ed\u00b7le", "Jung\u00b7frau", "zart", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eihr seyd ein Teufelinne.\u201c", "tokens": ["\u201e", "ihr", "seyd", "ein", "Teu\u00b7fe\u00b7lin\u00b7ne", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u201etannh\u00e4user ach, wie sprecht Ihr so,", "tokens": ["\u201e", "tann\u00b7h\u00e4u\u00b7ser", "ach", ",", "wie", "sprecht", "Ihr", "so", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "XY", "XY", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ebestehet Ihr mich zu schelten?", "tokens": ["\u201e", "be\u00b7ste\u00b7het", "Ihr", "mich", "zu", "schel\u00b7ten", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201esollt ihr noch l\u00e4nger bei uns seyn,", "tokens": ["\u201e", "sollt", "ihr", "noch", "l\u00e4n\u00b7ger", "bei", "uns", "seyn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "ADV", "ADJD", "APPR", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edes Worts m\u00fc\u00dft Ihr entgelten.", "tokens": ["\u201e", "des", "Worts", "m\u00fc\u00dft", "Ihr", "ent\u00b7gel\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u201etannh\u00e4user wollt Ihr Urlaub han,", "tokens": ["\u201e", "tann\u00b7h\u00e4u\u00b7ser", "wollt", "Ihr", "Ur\u00b7laub", "han", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VMFIN", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201enehmt Urlaub von den Greisen,", "tokens": ["\u201e", "nehmt", "Ur\u00b7laub", "von", "den", "Grei\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "\u201eund wo Ihr in dem Land umbfahrn,", "tokens": ["\u201e", "und", "wo", "Ihr", "in", "dem", "Land", "umb\u00b7fahrn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWAV", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201emein Lob das sollt Ihr preisen.\u201c", "tokens": ["\u201e", "mein", "Lob", "das", "sollt", "Ihr", "prei\u00b7sen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "PDS", "VMFIN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Der Tannh\u00e4user zog wieder aus dem Berg,", "tokens": ["Der", "Tann\u00b7h\u00e4u\u00b7ser", "zog", "wie\u00b7der", "aus", "dem", "Berg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "In Jammer und in Reuen:", "tokens": ["In", "Jam\u00b7mer", "und", "in", "Reu\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich will gen Rom in die fromme Stadt,", "tokens": ["\u201e", "ich", "will", "gen", "Rom", "in", "die", "from\u00b7me", "Stadt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "APPR", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201eall auf den Pabst vertrauen.", "tokens": ["\u201e", "all", "auf", "den", "Pabst", "ver\u00b7trau\u00b7en", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.16": {"line.1": {"text": "\u201enun fahr ich fr\u00f6hlich auf die Bahn,", "tokens": ["\u201e", "nun", "fahr", "ich", "fr\u00f6h\u00b7lich", "auf", "die", "Bahn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201egott mu\u00df es immer walten,", "tokens": ["\u201e", "gott", "mu\u00df", "es", "im\u00b7mer", "wal\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201ezu einem Pabst, der hei\u00dft Urban,", "tokens": ["\u201e", "zu", "ei\u00b7nem", "Pabst", ",", "der", "hei\u00dft", "Ur\u00b7ban", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "$,", "PRELS", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eob er mich wolle behalten.", "tokens": ["\u201e", "ob", "er", "mich", "wol\u00b7le", "be\u00b7hal\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.17": {"line.1": {"text": "\u201eherr Pabst Ihr geistlicher Vater mein,", "tokens": ["\u201e", "herr", "Pabst", "Ihr", "geist\u00b7li\u00b7cher", "Va\u00b7ter", "mein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "PPOSAT", "$,"], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "\u201eich klag Euch meine S\u00fcnde,", "tokens": ["\u201e", "ich", "klag", "Euch", "mei\u00b7ne", "S\u00fcn\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201edie ich mein Tag begangen hab,", "tokens": ["\u201e", "die", "ich", "mein", "Tag", "be\u00b7gan\u00b7gen", "hab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PPER", "PPOSAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eals ich Euch will verk\u00fcnden.", "tokens": ["\u201e", "als", "ich", "Euch", "will", "ver\u00b7k\u00fcn\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "\u201eich bin gewesen ein ganzes Jahr,", "tokens": ["\u201e", "ich", "bin", "ge\u00b7we\u00b7sen", "ein", "gan\u00b7zes", "Jahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VAPP", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u201ebey Venus einer Frauen,", "tokens": ["\u201e", "bey", "Ve\u00b7nus", "ei\u00b7ner", "Frau\u00b7en", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201enun will ich Beicht und Bu\u00df empfahn,", "tokens": ["\u201e", "nun", "will", "ich", "Beicht", "und", "Bu\u00df", "em\u00b7pfahn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eob ich m\u00f6cht Gott anschauen.\u201c", "tokens": ["\u201e", "ob", "ich", "m\u00f6cht", "Gott", "an\u00b7schau\u00b7en", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "VMFIN", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Der Pabst hat einen Stecken wei\u00df,", "tokens": ["Der", "Pabst", "hat", "ei\u00b7nen", "Ste\u00b7cken", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der war vom d\u00fcrren Zweige:", "tokens": ["Der", "war", "vom", "d\u00fcr\u00b7ren", "Zwei\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201ewann dieser Stecken Bl\u00e4tter tr\u00e4gt,", "tokens": ["\u201e", "wann", "die\u00b7ser", "Ste\u00b7cken", "Bl\u00e4t\u00b7ter", "tr\u00e4gt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PDAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201esind dir deine S\u00fcnden verziehen.\u201c", "tokens": ["\u201e", "sind", "dir", "dei\u00b7ne", "S\u00fcn\u00b7den", "ver\u00b7zie\u00b7hen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$.", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "\u201esollt ich leben nicht mehr denn ein Jahr,", "tokens": ["\u201e", "sollt", "ich", "le\u00b7ben", "nicht", "mehr", "denn", "ein", "Jahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201eein Jahr auf dieser Erden,", "tokens": ["\u201e", "ein", "Jahr", "auf", "die\u00b7ser", "Er\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eso wollt ich Reu und Bu\u00df empfahn,", "tokens": ["\u201e", "so", "wollt", "ich", "Reu", "und", "Bu\u00df", "em\u00b7pfahn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "NE", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund Gottes Gnad erwerben.\u201c", "tokens": ["\u201e", "und", "Got\u00b7tes", "Gnad", "er\u00b7wer\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "NN", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Da zog er wieder aus der Stadt,", "tokens": ["Da", "zog", "er", "wie\u00b7der", "aus", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Jammer und in Leiden:", "tokens": ["In", "Jam\u00b7mer", "und", "in", "Lei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201emaria Mutter, reine Magd,", "tokens": ["\u201e", "ma\u00b7ria", "Mut\u00b7ter", ",", "rei\u00b7ne", "Magd", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201emu\u00df ich mich von dir scheiden,", "tokens": ["\u201e", "mu\u00df", "ich", "mich", "von", "dir", "schei\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "\u201eso zieh ich wieder in den Berg,", "tokens": ["\u201e", "so", "zieh", "ich", "wie\u00b7der", "in", "den", "Berg", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eewiglich und ohn Ende,", "tokens": ["\u201e", "e\u00b7wig\u00b7lich", "und", "ohn", "En\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "KON", "APPR", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u201ezu Venus meiner Frauen zart,", "tokens": ["\u201e", "zu", "Ve\u00b7nus", "mei\u00b7ner", "Frau\u00b7en", "zart", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201ewohin mich Gott will senden.\u201c", "tokens": ["\u201e", "wo\u00b7hin", "mich", "Gott", "will", "sen\u00b7den", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+--+--", "measure": "iambic.di.relaxed"}}, "stanza.23": {"line.1": {"text": "\u201eseyd willkommen Tannh\u00e4user gut,", "tokens": ["\u201e", "seyd", "will\u00b7kom\u00b7men", "Tann\u00b7h\u00e4u\u00b7ser", "gut", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADJD", "NN", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201eich hab Euch lang entbehret,", "tokens": ["\u201e", "ich", "hab", "Euch", "lang", "ent\u00b7beh\u00b7ret", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201ewillkommen seyd mein liebster Herr,", "tokens": ["\u201e", "will\u00b7kom\u00b7men", "seyd", "mein", "liebs\u00b7ter", "Herr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edu Held, mir treu bekehret.\u201c", "tokens": ["\u201e", "du", "Held", ",", "mir", "treu", "be\u00b7keh\u00b7ret", ".", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "NN", "$,", "PPER", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Darnach wohl auf den dritten Tag,", "tokens": ["Dar\u00b7nach", "wohl", "auf", "den", "drit\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Stecken hub an zu gr\u00fcnen,", "tokens": ["Der", "Ste\u00b7cken", "hub", "an", "zu", "gr\u00fc\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da sandt man Boten in alle Land,", "tokens": ["Da", "sandt", "man", "Bo\u00b7ten", "in", "al\u00b7le", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wohin der Tannh\u00e4user kommen.", "tokens": ["Wo\u00b7hin", "der", "Tann\u00b7h\u00e4u\u00b7ser", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.25": {"line.1": {"text": "Da war er wieder in den Berg,", "tokens": ["Da", "war", "er", "wie\u00b7der", "in", "den", "Berg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Darinnen sollt er nun bleiben,", "tokens": ["Da\u00b7rin\u00b7nen", "sollt", "er", "nun", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So lang bis an den j\u00fcngsten Tag,", "tokens": ["So", "lang", "bis", "an", "den", "j\u00fcng\u00b7sten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo ihn Gott will hinweisen.", "tokens": ["Wo", "ihn", "Gott", "will", "hin\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VMFIN", "VVINF", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.26": {"line.1": {"text": "Das soll nimmer kein Priester thun,", "tokens": ["Das", "soll", "nim\u00b7mer", "kein", "Pries\u00b7ter", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Dem Menschen Mistrost geben,", "tokens": ["Dem", "Men\u00b7schen", "Mist\u00b7rost", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Will er denn Bu\u00df und Reu empfahn,", "tokens": ["Will", "er", "denn", "Bu\u00df", "und", "Reu", "em\u00b7pfahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "KON", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die S\u00fcnde sey ihm vergeben.", "tokens": ["Die", "S\u00fcn\u00b7de", "sey", "ihm", "ver\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}