{"textgrid.poem.48362": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Charles Bawdins Tod und Begr\u00e4bnis", "genre": "verse", "period": "N.A.", "pub_year": 1850, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf d\u00e4mmert der Tag, der Hahn kr\u00e4ht hell,", "tokens": ["Auf", "d\u00e4m\u00b7mert", "der", "Tag", ",", "der", "Hahn", "kr\u00e4ht", "hell", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bla\u00df schimmert des Mondes Horn,", "tokens": ["Bla\u00df", "schim\u00b7mert", "des", "Mon\u00b7des", "Horn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und im Morgenrote der Tropfen Tau", "tokens": ["Und", "im", "Mor\u00b7gen\u00b7ro\u00b7te", "der", "Trop\u00b7fen", "Tau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "NN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Glitzert am Hagedorn.", "tokens": ["Glit\u00b7zert", "am", "Ha\u00b7ge\u00b7dorn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "K\u00f6nig Edward aber, nicht Hahnenschrei", "tokens": ["K\u00f6\u00b7nig", "Ed\u00b7ward", "a\u00b7ber", ",", "nicht", "Hah\u00b7nen\u00b7schrei"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "ADV", "$,", "PTKNEG", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Rief ihn vom Schlummer wach;", "tokens": ["Rief", "ihn", "vom", "Schlum\u00b7mer", "wach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Drei Raben weckten ihn mit Gekreisch", "tokens": ["Drei", "Ra\u00b7ben", "weck\u00b7ten", "ihn", "mit", "Ge\u00b7kreisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oben am Wetterdach.", "tokens": ["O\u00b7ben", "am", "Wet\u00b7ter\u00b7dach", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "Und der K\u00f6nig fuhr auf: \u00bbBeim ew'gen Gott,", "tokens": ["Und", "der", "K\u00f6\u00b7nig", "fuhr", "auf", ":", "\u00bb", "Beim", "ew'\u00b7gen", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$.", "$(", "APPRART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ich versteh' euer Mahnen und Schrei'n;", "tokens": ["Ich", "ver\u00b7steh'", "eu\u00b7er", "Mah\u00b7nen", "und", "Schrei'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und eure Speise sein.", "tokens": ["Und", "eu\u00b7re", "Spei\u00b7se", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Verr\u00e4ter war er. Er hat seine Hand", "tokens": ["Ver\u00b7r\u00e4\u00b7ter", "war", "er", ".", "Er", "hat", "sei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "$.", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In das Blut des Yorks getaucht,", "tokens": ["In", "das", "Blut", "des", "Y\u00b7orks", "ge\u00b7taucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Nicht eher hab' ich Rast und Ruh,", "tokens": ["Nicht", "e\u00b7her", "hab'", "ich", "Rast", "und", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis seines gen Himmel raucht.\u00ab", "tokens": ["Bis", "sei\u00b7nes", "gen", "Him\u00b7mel", "raucht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Da sprach Ritter Canning: \u00bbMein K\u00f6nig und Herr,", "tokens": ["Da", "sprach", "Rit\u00b7ter", "Can\u00b7ning", ":", "\u00bb", "Mein", "K\u00f6\u00b7nig", "und", "Herr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "$.", "$(", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vergie\u00dfe nicht Bawdins Blut,", "tokens": ["Ver\u00b7gie\u00b7\u00dfe", "nicht", "Baw\u00b7dins", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "NE", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Was immer er dir B\u00f6ses tat,", "tokens": ["Was", "im\u00b7mer", "er", "dir", "B\u00f6\u00b7ses", "tat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm galt es brav und gut.", "tokens": ["Ihm", "galt", "es", "brav", "und", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Dem Lankasterk\u00f6nig hat er gedient", "tokens": ["Dem", "Lan\u00b7kas\u00b7ter\u00b7k\u00f6\u00b7nig", "hat", "er", "ge\u00b7dient"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Offen und sonder Scheu,", "tokens": ["Of\u00b7fen", "und", "son\u00b7der", "Scheu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "K\u00f6nig Edward, an deinen Feinden auch", "tokens": ["K\u00f6\u00b7nig", "Ed\u00b7ward", ",", "an", "dei\u00b7nen", "Fein\u00b7den", "auch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "APPR", "PPOSAT", "NN", "ADV"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ehre Mut und Treu.", "tokens": ["Eh\u00b7re", "Mut", "und", "Treu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "La\u00df Gnade walten, nur Gnad' allein", "tokens": ["La\u00df", "Gna\u00b7de", "wal\u00b7ten", ",", "nur", "Gnad'", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "NN", "VVINF", "$,", "ADV", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Machet des Siegs dich wert,", "tokens": ["Ma\u00b7chet", "des", "Siegs", "dich", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Den Oelzweig und die Palme nimm,", "tokens": ["Den", "O\u00b7el\u00b7zweig", "und", "die", "Pal\u00b7me", "nimm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nicht aber das Racheschwert.", "tokens": ["Nicht", "a\u00b7ber", "das", "Ra\u00b7ch\u00b7e\u00b7schwert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.8": {"line.1": {"text": "Gedenke, wir Menschen allzumal", "tokens": ["Ge\u00b7den\u00b7ke", ",", "wir", "Men\u00b7schen", "all\u00b7zu\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "NN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sind nur an S\u00fcnde gro\u00df,", "tokens": ["Sind", "nur", "an", "S\u00fcn\u00b7de", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein einziger auf Sankt Petri Stuhl", "tokens": ["Ein", "ein\u00b7zi\u00b7ger", "auf", "Sankt", "Pe\u00b7tri", "Stuhl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "VVFIN", "NE", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ist schuld- und fleckenlos.", "tokens": ["Ist", "schuld", "und", "fle\u00b7cken\u00b7los", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "TRUNC", "KON", "ADJD", "$."], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.9": {"line.1": {"text": "Vergib! ", "tokens": ["Ver\u00b7gib", "!"], "token_info": ["word", "punct"], "pos": ["VVIMP", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Die kaum gewonnene Kron' ...\u00ab", "tokens": ["Die", "kaum", "ge\u00b7won\u00b7ne\u00b7ne", "Kron'", "...", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$(", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Umsonst, die rostigen Angeln drehn", "tokens": ["Um\u00b7sonst", ",", "die", "ros\u00b7ti\u00b7gen", "An\u00b7geln", "drehn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sich schrill im Tower schon.", "tokens": ["Sich", "schrill", "im", "To\u00b7wer", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und bei Tagesfr\u00fch', in des Kerkers Tor", "tokens": ["Und", "bei", "Ta\u00b7ges\u00b7fr\u00fch'", ",", "in", "des", "Ker\u00b7kers", "Tor"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "$,", "APPR", "ART", "NN", "NN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Sheriff die Botschaft trug,", "tokens": ["Der", "She\u00b7riff", "die", "Bot\u00b7schaft", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und ein St\u00fcndlein, und zum Richtplatz hin", "tokens": ["Und", "ein", "St\u00fcnd\u00b7lein", ",", "und", "zum", "Richt\u00b7platz", "hin"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "KON", "APPRART", "NN", "PTKVZ"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Bewegte sich der Zug.", "tokens": ["Be\u00b7weg\u00b7te", "sich", "der", "Zug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Der Zug war so: der Richter vorn", "tokens": ["Der", "Zug", "war", "so", ":", "der", "Rich\u00b7ter", "vorn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In seines Amts Geschmeid',", "tokens": ["In", "sei\u00b7nes", "Amts", "Ge\u00b7schmeid'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hell glitzerte das Quastengold", "tokens": ["Hell", "glit\u00b7zer\u00b7te", "das", "Quas\u00b7ten\u00b7gold"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An seinem Scharlachkleid.", "tokens": ["An", "sei\u00b7nem", "Schar\u00b7lach\u00b7kleid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Zw\u00f6lf Augustiner kamen dann", "tokens": ["Zw\u00f6lf", "Au\u00b7gus\u00b7ti\u00b7ner", "ka\u00b7men", "dann"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "In h\u00e4renem Gewand,", "tokens": ["In", "h\u00e4\u00b7re\u00b7nem", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Rosenkranz und Gei\u00dfelstrick", "tokens": ["Mit", "Ro\u00b7sen\u00b7kranz", "und", "Gei\u00b7\u00dfel\u00b7strick"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In recht- und linker Hand.", "tokens": ["In", "recht", "und", "lin\u00b7ker", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Bu\u00dfpsalmen sangen finster sie,", "tokens": ["Bu\u00df\u00b7psal\u00b7men", "san\u00b7gen", "fins\u00b7ter", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und finster die Wolken ziehn,", "tokens": ["Und", "fins\u00b7ter", "die", "Wol\u00b7ken", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und dazwischen schrillte Gl\u00f6ckleinklang", "tokens": ["Und", "da\u00b7zwi\u00b7schen", "schrill\u00b7te", "Gl\u00f6c\u00b7klein\u00b7klang"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Vom Turme Sankt Marien.", "tokens": ["Vom", "Tur\u00b7me", "Sankt", "Ma\u00b7ri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Den M\u00f6nchen folgte, festen Schritts,", "tokens": ["Den", "M\u00f6n\u00b7chen", "folg\u00b7te", ",", "fes\u00b7ten", "Schritts", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Bogensch\u00fctzenhauf,", "tokens": ["Ein", "Bo\u00b7gen\u00b7sch\u00fct\u00b7zen\u00b7hauf", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Sennen waren all gespannt,", "tokens": ["Die", "Sen\u00b7nen", "wa\u00b7ren", "all", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Pfeile lagen auf.", "tokens": ["Die", "Pfei\u00b7le", "la\u00b7gen", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wohl mochte versteckt lankastrisch Volk", "tokens": ["Wohl", "moch\u00b7te", "ver\u00b7steckt", "lan\u00b7kast\u00b7risch", "Volk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "VVFIN", "ADJD", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den Ritter noch befrein,", "tokens": ["Den", "Rit\u00b7ter", "noch", "be\u00b7fr\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es mochte Charles Bawdins letzter Gang", "tokens": ["Es", "moch\u00b7te", "Char\u00b7les", "Baw\u00b7dins", "letz\u00b7ter", "Gang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der seiner Feinde sein.", "tokens": ["Der", "sei\u00b7ner", "Fein\u00b7de", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Dann kam er selbst: zwei Rappen vorn", "tokens": ["Dann", "kam", "er", "selbst", ":", "zwei", "Rap\u00b7pen", "vorn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "CARD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In schwarzer Decken Putz,", "tokens": ["In", "schwar\u00b7zer", "De\u00b7cken", "Putz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf ihren K\u00f6pfen bewegte sich", "tokens": ["Auf", "ih\u00b7ren", "K\u00f6p\u00b7fen", "be\u00b7weg\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Strau\u00dfenfederstutz.", "tokens": ["Ein", "Strau\u00b7\u00dfen\u00b7fe\u00b7der\u00b7stutz", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Und wieder dann kam festen Schritts", "tokens": ["Und", "wie\u00b7der", "dann", "kam", "fes\u00b7ten", "Schritts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Bogensch\u00fctzenhauf,", "tokens": ["Ein", "Bo\u00b7gen\u00b7sch\u00fct\u00b7zen\u00b7hauf", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Sennen waren all gespannt,", "tokens": ["Die", "Sen\u00b7nen", "wa\u00b7ren", "all", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Pfeile lagen auf.", "tokens": ["Die", "Pfei\u00b7le", "la\u00b7gen", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Zw\u00f6lf Augustiner wieder dann", "tokens": ["Zw\u00f6lf", "Au\u00b7gus\u00b7ti\u00b7ner", "wie\u00b7der", "dann"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Psalmenmelodien \u2013", "tokens": ["Mit", "Psal\u00b7men\u00b7me\u00b7lo\u00b7di\u00b7en", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und immer noch scholl Gl\u00f6ckleinklang", "tokens": ["Und", "im\u00b7mer", "noch", "scholl", "Gl\u00f6c\u00b7klein\u00b7klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Turme Sankt Marien.", "tokens": ["Vom", "Tur\u00b7me", "Sankt", "Ma\u00b7ri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Und nun zum Schlusse, stra\u00dfenbreit", "tokens": ["Und", "nun", "zum", "Schlus\u00b7se", ",", "stra\u00b7\u00dfen\u00b7breit"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Volkes dicht Gedr\u00e4ng,", "tokens": ["Des", "Vol\u00b7kes", "dicht", "Ge\u00b7dr\u00e4ng", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von allen D\u00e4chern folgte man", "tokens": ["Von", "al\u00b7len", "D\u00e4\u00b7chern", "folg\u00b7te", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem traurigen Gepr\u00e4ng.", "tokens": ["Dem", "trau\u00b7ri\u00b7gen", "Ge\u00b7pr\u00e4ng", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Zuletzt an Christi Kreuz vorbei", "tokens": ["Zu\u00b7letzt", "an", "Chris\u00b7ti", "Kreuz", "vor\u00b7bei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NE", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bewegte sich der Zug,", "tokens": ["Be\u00b7weg\u00b7te", "sich", "der", "Zug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hernieder schaute still das Lamm,", "tokens": ["Her\u00b7nie\u00b7der", "schau\u00b7te", "still", "das", "Lamm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das unsre S\u00fcnden trug.", "tokens": ["Das", "uns\u00b7re", "S\u00fcn\u00b7den", "trug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Charles Bawdin aber betete leis:", "tokens": ["Char\u00b7les", "Baw\u00b7din", "a\u00b7ber", "be\u00b7te\u00b7te", "leis", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "\u00bbheiland, erbarm dich mein", "tokens": ["\u00bb", "hei\u00b7land", ",", "er\u00b7barm", "dich", "mein"], "token_info": ["punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "ADJD", "PPER", "PPOSAT"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und wasch auch meine Seele heut", "tokens": ["Und", "wasch", "auch", "mei\u00b7ne", "See\u00b7le", "heut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADV", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von aller S\u00fcnde rein.\u00ab", "tokens": ["Von", "al\u00b7ler", "S\u00fcn\u00b7de", "rein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und die Thems' entlang und das Schlo\u00df vorbei,", "tokens": ["Und", "die", "Thems'", "ent\u00b7lang", "und", "das", "Schlo\u00df", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und nun waren sie zur Stell':", "tokens": ["Und", "nun", "wa\u00b7ren", "sie", "zur", "Stell'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Verhangen schwarz war das Schafott,", "tokens": ["Ver\u00b7han\u00b7gen", "schwarz", "war", "das", "Scha\u00b7fott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Das Beil, es blitzte hell.", "tokens": ["Das", "Beil", ",", "es", "blitz\u00b7te", "hell", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Rings Stille. Da sprach Charles Bawdin laut:", "tokens": ["Rings", "Stil\u00b7le", ".", "Da", "sprach", "Char\u00b7les", "Baw\u00b7din", "laut", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ADV", "VVFIN", "NE", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbblutacker bleibt dies Land,", "tokens": ["\u00bb", "blu\u00b7ta\u00b7cker", "bleibt", "dies", "Land", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PDS", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Solange Schwert und Zepter bleibt", "tokens": ["So\u00b7lan\u00b7ge", "Schwert", "und", "Zep\u00b7ter", "bleibt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In dieses Edwards Hand.", "tokens": ["In", "die\u00b7ses", "Ed\u00b7wards", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Vergehn vor Gram wird manches Weib", "tokens": ["Ver\u00b7gehn", "vor", "Gram", "wird", "man\u00b7ches", "Weib"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und manche junge Braut,", "tokens": ["Und", "man\u00b7che", "jun\u00b7ge", "Braut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Eh' dieses Land den ersten Strahl", "tokens": ["Eh'", "die\u00b7ses", "Land", "den", "ers\u00b7ten", "Strahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PDAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Friedens wieder schaut.\u00ab", "tokens": ["Des", "Frie\u00b7dens", "wie\u00b7der", "schaut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Und rasch an Priesters Seite dann", "tokens": ["Und", "rasch", "an", "Pries\u00b7ters", "Sei\u00b7te", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "NN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hin kniet' er aufs Schafott,", "tokens": ["Hin", "kniet'", "er", "aufs", "Scha\u00b7fott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und betend still die Seele sein", "tokens": ["Und", "be\u00b7tend", "still", "die", "See\u00b7le", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADJD", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Empfahl er seinem Gott.", "tokens": ["Emp\u00b7fahl", "er", "sei\u00b7nem", "Gott", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Hin flo\u00df sein Blut. Laut weinend stand", "tokens": ["Hin", "flo\u00df", "sein", "Blut", ".", "Laut", "wei\u00b7nend", "stand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$.", "APPR", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Volk im Kreis umher,", "tokens": ["Das", "Volk", "im", "Kreis", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wieviel auch roten Blutes flo\u00df,", "tokens": ["Wie\u00b7viel", "auch", "ro\u00b7ten", "Blu\u00b7tes", "flo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Tr\u00e4nen flossen mehr.", "tokens": ["Der", "Tr\u00e4\u00b7nen", "flos\u00b7sen", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Der Henker dann, mit scharfer Axt,", "tokens": ["Der", "Hen\u00b7ker", "dann", ",", "mit", "schar\u00b7fer", "Axt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vierteilte Bawdins Rumpf,", "tokens": ["Vier\u00b7teil\u00b7te", "Baw\u00b7dins", "Rumpf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und jeder Teil ward aufgesteckt", "tokens": ["Und", "je\u00b7der", "Teil", "ward", "auf\u00b7ge\u00b7steckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf einen Lanzenstumpf.", "tokens": ["Auf", "ei\u00b7nen", "Lan\u00b7zen\u00b7stumpf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Der eine t\u00e4t als Wetterfahn'", "tokens": ["Der", "ei\u00b7ne", "t\u00e4t", "als", "Wet\u00b7ter\u00b7fahn'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf dem Tower-Turm sich drehn,", "tokens": ["Auf", "dem", "Tow\u00b7er\u00b7Turm", "sich", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein zweiter war als Gitterschmuck", "tokens": ["Ein", "zwei\u00b7ter", "war", "als", "Git\u00b7ter\u00b7schmuck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor Edwards Schlo\u00df zu sehn.", "tokens": ["Vor", "Ed\u00b7wards", "Schlo\u00df", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Der dritt' und vierte, samt dem Haupt,", "tokens": ["Der", "dritt'", "und", "vier\u00b7te", ",", "samt", "dem", "Haupt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei fahlem Mittagsschein", "tokens": ["Bei", "fah\u00b7lem", "Mit\u00b7tags\u00b7schein"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von dreien Toren blickten die", "tokens": ["Von", "drei\u00b7en", "To\u00b7ren", "blick\u00b7ten", "die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "VVFIN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weit in das Land hinein.", "tokens": ["Weit", "in", "das", "Land", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Da wurden sie, bei Tag und Nacht,", "tokens": ["Da", "wur\u00b7den", "sie", ",", "bei", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Umkr\u00e4chzet und umkreist,", "tokens": ["Um\u00b7kr\u00e4ch\u00b7zet", "und", "um\u00b7kreist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Raben- und das Kr\u00e4henvolk", "tokens": ["Das", "Ra\u00b7ben", "und", "das", "Kr\u00e4\u00b7hen\u00b7volk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat alles aufgespeist.", "tokens": ["Hat", "al\u00b7les", "auf\u00b7ge\u00b7speist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Das war das End' von Bawdins Treu", "tokens": ["Das", "war", "das", "End'", "von", "Baw\u00b7dins", "Treu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und seiner Ehren Ziel ...", "tokens": ["Und", "sei\u00b7ner", "Eh\u00b7ren", "Ziel", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Gott schenk' dem K\u00f6nig, unsrem Herrn,", "tokens": ["Gott", "schenk'", "dem", "K\u00f6\u00b7nig", ",", "uns\u00b7rem", "Herrn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "So treuer Diener viel.", "tokens": ["So", "treu\u00b7er", "Die\u00b7ner", "viel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}