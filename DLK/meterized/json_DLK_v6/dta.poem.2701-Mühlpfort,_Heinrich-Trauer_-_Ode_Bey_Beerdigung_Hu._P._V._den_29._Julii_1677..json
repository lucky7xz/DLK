{"dta.poem.2701": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Trauer - Ode/  \n  Bey Beerdigung Hu. P. V. den  29.  \n Julii 1677.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mischt Tr\u00e4ncke der Unsterbligkeit/", "tokens": ["Mischt", "Tr\u00e4n\u00b7cke", "der", "U\u00b7nster\u00b7blig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ART", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Zieht Safft und Saltz au\u00df edlen Steinen;", "tokens": ["Zieht", "Safft", "und", "Saltz", "au\u00df", "ed\u00b7len", "Stei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sucht was der Theophrast bereit/", "tokens": ["Sucht", "was", "der", "Theo\u00b7ph\u00b7rast", "be\u00b7reit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Helmont kocht aus d\u00fcrren Beinen;", "tokens": ["Und", "Hel\u00b7mont", "kocht", "aus", "d\u00fcr\u00b7ren", "Bei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ja h\u00e4ttet ihr der Weisen Stein/", "tokens": ["Ja", "h\u00e4t\u00b7tet", "ihr", "der", "Wei\u00b7sen", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jhr Sterblichen/ den Schatz der Sch\u00e4tze:", "tokens": ["Ihr", "Sterb\u00b7li\u00b7chen", "/", "den", "Schatz", "der", "Sch\u00e4t\u00b7ze", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So k\u00f6nt ihr doch nicht ewig seyn/", "tokens": ["So", "k\u00f6nt", "ihr", "doch", "nicht", "e\u00b7wig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Euch f\u00e4llt des Todes Haupt-Gesetze.", "tokens": ["Euch", "f\u00e4llt", "des", "To\u00b7des", "Haup\u00b7tGe\u00b7set\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Jhr Klugen die ihr graue Haar/", "tokens": ["Ihr", "Klu\u00b7gen", "die", "ihr", "grau\u00b7e", "Haar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als einen grossen Wucher zehlet/", "tokens": ["Als", "ei\u00b7nen", "gros\u00b7sen", "Wu\u00b7cher", "zeh\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und bettelt umb viel lange Jahr/", "tokens": ["Und", "bet\u00b7telt", "umb", "viel", "lan\u00b7ge", "Jahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erkennt doch wie ihr weit gefehlet.", "tokens": ["Er\u00b7kennt", "doch", "wie", "ihr", "weit", "ge\u00b7feh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KOKOM", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer w\u00fcnscht ihm auf der Folter-Banck", "tokens": ["Wer", "w\u00fcnscht", "ihm", "auf", "der", "Fol\u00b7ter\u00b7Banck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In Schmertzen angespannt zuliegen?", "tokens": ["In", "Schmert\u00b7zen", "an\u00b7ge\u00b7spannt", "zu\u00b7lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und euch sol Elend/ Siech\u2019 und Kranck", "tokens": ["Und", "euch", "sol", "E\u00b7lend", "/", "Siech'", "und", "Kranck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "PIAT", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Des Lebens weiter Frist vergn\u00fcgen.", "tokens": ["Des", "Le\u00b7bens", "wei\u00b7ter", "Frist", "ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Gelehrte/ wenn ihr nun gefast", "tokens": ["Ge\u00b7lehr\u00b7te", "/", "wenn", "ihr", "nun", "ge\u00b7fast"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "KOUS", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was Himmel/ Erd und See umbschliessen/", "tokens": ["Was", "Him\u00b7mel", "/", "Erd", "und", "See", "umbsc\u00b7hlies\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$(", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So seyd ihr doch ein blosser Gast/", "tokens": ["So", "seyd", "ihr", "doch", "ein", "blos\u00b7ser", "Gast", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der mu\u00df/ was man ihm giebt/ geniessen.", "tokens": ["Der", "mu\u00df", "/", "was", "man", "ihm", "giebt", "/", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VMFIN", "$(", "PWS", "PIS", "PPER", "VVFIN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach Phantasey! ach toller Wahn!", "tokens": ["Ach", "Phan\u00b7ta\u00b7sey", "!", "ach", "tol\u00b7ler", "Wahn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "XY", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bey Hohen K\u00fcnsten di\u00df entbehren/", "tokens": ["Bey", "Ho\u00b7hen", "K\u00fcns\u00b7ten", "di\u00df", "ent\u00b7beh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was uns nach diesem Leben kan", "tokens": ["Was", "uns", "nach", "die\u00b7sem", "Le\u00b7ben", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "PDAT", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Wissenschafften Kern gewehren.", "tokens": ["Der", "Wis\u00b7sen\u00b7schaff\u00b7ten", "Kern", "ge\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Hier gilt auch nicht ein eisern Arm.", "tokens": ["Hier", "gilt", "auch", "nicht", "ein", "ei\u00b7sern", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch des Aleides Tapfferkeiten;", "tokens": ["Noch", "des", "A\u00b7lei\u00b7des", "Tapf\u00b7fer\u00b7kei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es sey das Blut so frisch und warm/", "tokens": ["Es", "sey", "das", "Blut", "so", "frisch", "und", "warm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Faust bereit und keck zum Streiten.", "tokens": ["Die", "Faust", "be\u00b7reit", "und", "keck", "zum", "Strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie viel hat nicht der Sand bedeckt/", "tokens": ["Wie", "viel", "hat", "nicht", "der", "Sand", "be\u00b7deckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PTKNEG", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die man der Zeiten Wunder nante/", "tokens": ["Die", "man", "der", "Zei\u00b7ten", "Wun\u00b7der", "nan\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die gantze L\u00e4nder offt erschreckt/", "tokens": ["Die", "gant\u00b7ze", "L\u00e4n\u00b7der", "offt", "er\u00b7schreckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und man sie vor den Mars erkante?", "tokens": ["Und", "man", "sie", "vor", "den", "Mars", "er\u00b7kan\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nichts was des Menschen Witz ersinnt/", "tokens": ["Nichts", "was", "des", "Men\u00b7schen", "Witz", "er\u00b7sinnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PWS", "ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie hoch er immer auch gestiegen/", "tokens": ["Wie", "hoch", "er", "im\u00b7mer", "auch", "ge\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was seiner H\u00e4nde Werck beginnt/", "tokens": ["Was", "sei\u00b7ner", "H\u00e4n\u00b7de", "Werck", "be\u00b7ginnt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan \u00fcber die Verwesung siegen.", "tokens": ["Kan", "\u00fc\u00b7ber", "die", "Ver\u00b7we\u00b7sung", "sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wir treten auf/ wir treten ab/", "tokens": ["Wir", "tre\u00b7ten", "auf", "/", "wir", "tre\u00b7ten", "ab", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "$(", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wenn wir uns genug gezeiget/", "tokens": ["Und", "wenn", "wir", "uns", "ge\u00b7nug", "ge\u00b7zei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So sieht man wie der Hirten-Stab", "tokens": ["So", "sieht", "man", "wie", "der", "Hir\u00b7ten\u00b7Stab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zugleich sich mit dem Scepter neiget.", "tokens": ["Zu\u00b7gleich", "sich", "mit", "dem", "Scep\u00b7ter", "nei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "So wird ihm auch kein Eigenthum", "tokens": ["So", "wird", "ihm", "auch", "kein", "Ei\u00b7gen\u00b7thum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Mensch durch sein Verm\u00f6gen bauen.", "tokens": ["Ein", "Mensch", "durch", "sein", "Ver\u00b7m\u00f6\u00b7gen", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Band/ Hoheit/ Ehre/ Pracht und Ruhm", "tokens": ["Band", "/", "Ho\u00b7heit", "/", "Eh\u00b7re", "/", "Pracht", "und", "Ruhm"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und was wir so erhitzt anschauen/", "tokens": ["Und", "was", "wir", "so", "er\u00b7hitzt", "an\u00b7schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das Blendwerck der sehr kurtzen Zeit", "tokens": ["Das", "Blend\u00b7werck", "der", "sehr", "kurt\u00b7zen", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kan uns die Augen so verbinden/", "tokens": ["Kan", "uns", "die", "Au\u00b7gen", "so", "ver\u00b7bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df wir den Weg der Ewigkeit", "tokens": ["Da\u00df", "wir", "den", "Weg", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Bey unserm Abschied schwerlich finden.", "tokens": ["Bey", "un\u00b7serm", "Ab\u00b7schied", "schwer\u00b7lich", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ein Spieler zieht die Kleider aus/", "tokens": ["Ein", "Spie\u00b7ler", "zieht", "die", "Klei\u00b7der", "aus", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sich die Schau-Lust hat geendet.", "tokens": ["Wenn", "sich", "die", "Schau\u00b7Lust", "hat", "ge\u00b7en\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So lassen wir auch Hof und Haus", "tokens": ["So", "las\u00b7sen", "wir", "auch", "Hof", "und", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und was uns das Gel\u00fcck gesendet.", "tokens": ["Und", "was", "uns", "das", "Ge\u00b7l\u00fcck", "ge\u00b7sen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "M\u00fcst\u2019 einer ohne Ma\u00dfque seyn/", "tokens": ["M\u00fcst'", "ei\u00b7ner", "oh\u00b7ne", "Ma\u00df\u00b7que", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "APPR", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie he\u00dflich wird er sich gebehrden/", "tokens": ["Wie", "he\u00df\u00b7lich", "wird", "er", "sich", "ge\u00b7behr\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Stat angenommner Tugend Schein/", "tokens": ["Stat", "an\u00b7ge\u00b7nomm\u00b7ner", "Tu\u00b7gend", "Schein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Laster gr\u00f6ster ", "tokens": ["Der", "Las\u00b7ter", "gr\u00f6s\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Was suchen wir denn auf der Welt?", "tokens": ["Was", "su\u00b7chen", "wir", "denn", "auf", "der", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wird mit schn\u00f6dem Danck uns lohnen/", "tokens": ["Sie", "wird", "mit", "schn\u00f6\u00b7dem", "Danck", "uns", "loh\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man wei\u00df/ da\u00df man vor kindisch h\u00e4lt", "tokens": ["Man", "wei\u00df", "/", "da\u00df", "man", "vor", "kin\u00b7disch", "h\u00e4lt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$(", "KOUS", "PIS", "APPR", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die spielen mit gemahlten Bohnen.", "tokens": ["Die", "spie\u00b7len", "mit", "ge\u00b7mahl\u00b7ten", "Boh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wir Kl\u00fcgsten sind ein albers Kind/", "tokens": ["Wir", "Kl\u00fcgs\u00b7ten", "sind", "ein", "al\u00b7bers", "Kind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das gar kein gutes kan erzielen/", "tokens": ["Das", "gar", "kein", "gu\u00b7tes", "kan", "er\u00b7zie\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PIAT", "ADJA", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn wir bey vielem Rauch und Wind/", "tokens": ["Wenn", "wir", "bey", "vie\u00b7lem", "Rauch", "und", "Wind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIS", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "De\u00df Himmels Kleinod offt verspielen.", "tokens": ["De\u00df", "Him\u00b7mels", "Klei\u00b7nod", "offt", "ver\u00b7spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Es sey das Grab so sch\u00f6n geziert/", "tokens": ["Es", "sey", "das", "Grab", "so", "sch\u00f6n", "ge\u00b7ziert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Leichen-Pracht so wol bestellet;", "tokens": ["Die", "Lei\u00b7chen\u00b7Pracht", "so", "wol", "be\u00b7stel\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Umbsonst da\u00df man Gew\u00f6lb auf f\u00fchrt", "tokens": ["Um\u00b7bsonst", "da\u00df", "man", "Ge\u00b7w\u00f6lb", "auf", "f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PIS", "NN", "APPR", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo nicht die Seele ", "tokens": ["Wo", "nicht", "die", "See\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PTKNEG", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Der Leib/ das schn\u00f6de S\u00fcnden-Nest", "tokens": ["Der", "Leib", "/", "das", "schn\u00f6\u00b7de", "S\u00fcn\u00b7den\u00b7Nest"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mag ja in seiner Grufft verschimmeln;", "tokens": ["Mag", "ja", "in", "sei\u00b7ner", "Grufft", "ver\u00b7schim\u00b7meln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn nur die Seel im ", "tokens": ["Wenn", "nur", "die", "Seel", "im"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Sich schwingt zu den gestirnten Himmeln.", "tokens": ["Sich", "schwingt", "zu", "den", "ge\u00b7stirn\u00b7ten", "Him\u00b7meln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Geehrtste Muhme die der Tod", "tokens": ["Ge\u00b7ehrts\u00b7te", "Muh\u00b7me", "die", "der", "Tod"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch so viel Leichen hat bewehret/", "tokens": ["Durch", "so", "viel", "Lei\u00b7chen", "hat", "be\u00b7weh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "VAFIN", "VVFIN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie wei\u00df ja wie uns Angst und Noth", "tokens": ["Sie", "wei\u00df", "ja", "wie", "uns", "Angst", "und", "Noth"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KOKOM", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Lebens beste Krafft verzehret.", "tokens": ["Des", "Le\u00b7bens", "bes\u00b7te", "Krafft", "ver\u00b7zeh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Erst Vater/ und denn Bruder sehn", "tokens": ["Erst", "Va\u00b7ter", "/", "und", "denn", "Bru\u00b7der", "sehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "$(", "KON", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gestrecket auff der Bahre liegen/", "tokens": ["Ge\u00b7stre\u00b7cket", "auff", "der", "Bah\u00b7re", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Verursacht nur ein kl\u00e4glich flehn", "tokens": ["Ver\u00b7ur\u00b7sacht", "nur", "ein", "kl\u00e4g\u00b7lich", "flehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "ADJD", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und ist so leicht nicht einzuwiegen.", "tokens": ["Und", "ist", "so", "leicht", "nicht", "ein\u00b7zu\u00b7wie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Nun aber ihr der Tod ins Hertz/", "tokens": ["Nun", "a\u00b7ber", "ihr", "der", "Tod", "ins", "Hertz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und an den Punct der Seele schneidet/", "tokens": ["Und", "an", "den", "Punct", "der", "See\u00b7le", "schnei\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So glaub ich da\u00df dergleichen Schmertz", "tokens": ["So", "glaub", "ich", "da\u00df", "derg\u00b7lei\u00b7chen", "Schmertz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PIS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gemeinen Trost und Rath nicht leidet.", "tokens": ["Ge\u00b7mei\u00b7nen", "Trost", "und", "Rath", "nicht", "lei\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie scheint geboren nur zu seyn/", "tokens": ["Sie", "scheint", "ge\u00b7bo\u00b7ren", "nur", "zu", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "ADV", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu leben unter lauter Leichen;", "tokens": ["Zu", "le\u00b7ben", "un\u00b7ter", "lau\u00b7ter", "Lei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man scharrt den Vetter noch nicht ein", "tokens": ["Man", "scharrt", "den", "Vet\u00b7ter", "noch", "nicht", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So mu\u00df ihr Ehschatz auch verbleichen.", "tokens": ["So", "mu\u00df", "ihr", "Eh\u00b7schatz", "auch", "ver\u00b7blei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch seiner Tugend W\u00fcrdigkeit/", "tokens": ["Doch", "sei\u00b7ner", "Tu\u00b7gend", "W\u00fcr\u00b7dig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wissenschafft und edle Gaben/", "tokens": ["Die", "Wis\u00b7sen\u00b7schafft", "und", "ed\u00b7le", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Stehn nicht in der Vergessenheit", "tokens": ["Stehn", "nicht", "in", "der", "Ver\u00b7ges\u00b7sen\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und werden wie der Leib begraben.", "tokens": ["Und", "wer\u00b7den", "wie", "der", "Leib", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie glaube da\u00df wer so gelebt", "tokens": ["Sie", "glau\u00b7be", "da\u00df", "wer", "so", "ge\u00b7lebt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOUS", "PWS", "ADV", "VVPP"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Der f\u00e4hrt mit Ehr und Ruhm von hinnen.", "tokens": ["Der", "f\u00e4hrt", "mit", "Ehr", "und", "Ruhm", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "KON", "NN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Er hat nach diesem Gut gestrebt", "tokens": ["Er", "hat", "nach", "die\u00b7sem", "Gut", "ge\u00b7strebt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PDAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das bleibt/ wenn anders mu\u00df zerrinnen.", "tokens": ["Das", "bleibt", "/", "wenn", "an\u00b7ders", "mu\u00df", "zer\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "KOUS", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}