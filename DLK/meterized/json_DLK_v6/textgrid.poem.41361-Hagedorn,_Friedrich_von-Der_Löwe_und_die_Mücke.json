{"textgrid.poem.41361": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der L\u00f6we und die M\u00fccke", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein kluger Heiliger, selbst Augustinus, spricht:", "tokens": ["Ein", "klu\u00b7ger", "Hei\u00b7li\u00b7ger", ",", "selbst", "Au\u00b7gus\u00b7ti\u00b7nus", ",", "spricht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "NE", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbdem Sonnenk\u00f6rper ist die Fliege vorzuziehen;", "tokens": ["\u00bb", "dem", "Son\u00b7nen\u00b7k\u00f6r\u00b7per", "ist", "die", "Flie\u00b7ge", "vor\u00b7zu\u00b7zie\u00b7hen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn ihr, nicht jenem, ward ein Lebensgeist verliehen.\u00ab", "tokens": ["Denn", "ihr", ",", "nicht", "je\u00b7nem", ",", "ward", "ein", "Le\u00b7bens\u00b7geist", "ver\u00b7lie\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "$,", "PTKNEG", "PDAT", "$,", "VAFIN", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vielleicht ist dieses wahr; ich aber glaub' es nicht.", "tokens": ["Viel\u00b7leicht", "ist", "die\u00b7ses", "wahr", ";", "ich", "a\u00b7ber", "glaub'", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDAT", "ADJD", "$.", "PPER", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch denk' ich keinen Ruhm den Fliegen abzusprechen;", "tokens": ["Doch", "denk'", "ich", "kei\u00b7nen", "Ruhm", "den", "Flie\u00b7gen", "ab\u00b7zu\u00b7spre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Fliegen wissen sich zu r\u00e4chen:", "tokens": ["Die", "Flie\u00b7gen", "wis\u00b7sen", "sich", "zu", "r\u00e4\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auch M\u00fccken fehlt es nicht an Keckheit, noch an Macht.", "tokens": ["Auch", "M\u00fc\u00b7cken", "fehlt", "es", "nicht", "an", "Keck\u00b7heit", ",", "noch", "an", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wer ist der Heldin zu vergleichen,", "tokens": ["Wer", "ist", "der", "Hel\u00b7din", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die jenes starke Thier aufs \u00e4u\u00dferste gebracht,", "tokens": ["Die", "je\u00b7nes", "star\u00b7ke", "Thier", "aufs", "\u00e4u\u00b7\u00dfers\u00b7te", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "ADJA", "NN", "APPRART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dem alle Thiere zitternd weichen?", "tokens": ["Dem", "al\u00b7le", "Thie\u00b7re", "zit\u00b7ternd", "wei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Thiere Regiment in Monomotapa", "tokens": ["Der", "Thie\u00b7re", "Re\u00b7gi\u00b7ment", "in", "Mo\u00b7no\u00b7mo\u00b7ta\u00b7pa"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "War durch Gewalt und Recht dem L\u00f6wen zugefallen,", "tokens": ["War", "durch", "Ge\u00b7walt", "und", "Recht", "dem", "L\u00f6\u00b7wen", "zu\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der sich, Monarchen gleich, von sch\u00fcchternen Vasallen", "tokens": ["Der", "sich", ",", "Mon\u00b7ar\u00b7chen", "gleich", ",", "von", "sch\u00fcch\u00b7ter\u00b7nen", "Va\u00b7sal\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PRF", "$,", "NN", "ADV", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Geschmeichelt und gef\u00fcrchtet sah.", "tokens": ["Ge\u00b7schmei\u00b7chelt", "und", "ge\u00b7f\u00fcrch\u00b7tet", "sah", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dort hei\u00dft ein schwarzer F\u00fcrst das Wunder seiner Zeit,", "tokens": ["Dort", "hei\u00dft", "ein", "schwar\u00b7zer", "F\u00fcrst", "das", "Wun\u00b7der", "sei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat nur sein Heldenmuth viel B\u00f6ses unterlassen;", "tokens": ["Hat", "nur", "sein", "Hel\u00b7den\u00b7muth", "viel", "B\u00f6\u00b7ses", "un\u00b7ter\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den L\u00f6wen nannten auch noch ungel\u00e4hmte Sassen", "tokens": ["Den", "L\u00f6\u00b7wen", "nann\u00b7ten", "auch", "noch", "un\u00b7ge\u00b7l\u00e4hm\u00b7te", "Sas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Muster seiner G\u00fctigkeit.", "tokens": ["Das", "Mus\u00b7ter", "sei\u00b7ner", "G\u00fc\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Das Lob n\u00e4hrt seinen Stolz, so wie sein Grimm die Noth.", "tokens": ["Das", "Lob", "n\u00e4hrt", "sei\u00b7nen", "Stolz", ",", "so", "wie", "sein", "Grimm", "die", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,", "ADV", "KOKOM", "PPOSAT", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit beiden durfte nur die k\u00fchne M\u00fccke scherzen,", "tokens": ["Mit", "bei\u00b7den", "durf\u00b7te", "nur", "die", "k\u00fch\u00b7ne", "M\u00fc\u00b7cke", "scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die ihm aus edlem Ha\u00df, mit freiheitvollem Herzen,", "tokens": ["Die", "ihm", "aus", "ed\u00b7lem", "Ha\u00df", ",", "mit", "frei\u00b7heit\u00b7vol\u00b7lem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des scharfen Stachels Spitze bot.", "tokens": ["Des", "schar\u00b7fen", "Sta\u00b7chels", "Spit\u00b7ze", "bot", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Angriff wird gewagt; sie selber bl\u00e4st zur Schlacht;", "tokens": ["Der", "An\u00b7griff", "wird", "ge\u00b7wagt", ";", "sie", "sel\u00b7ber", "bl\u00e4st", "zur", "Schlacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "PPER", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie s\u00e4umt nicht, an den Feind sich peinlich fest zu saugen,", "tokens": ["Sie", "s\u00e4umt", "nicht", ",", "an", "den", "Feind", "sich", "pein\u00b7lich", "fest", "zu", "sau\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "APPR", "ART", "NN", "PRF", "ADJD", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und hat den K\u00f6nig bald um Rachen, Maul und Augen", "tokens": ["Und", "hat", "den", "K\u00f6\u00b7nig", "bald", "um", "Ra\u00b7chen", ",", "Maul", "und", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit tausend Schmerzen wund gemacht.", "tokens": ["Mit", "tau\u00b7send", "Schmer\u00b7zen", "wund", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Er tobet, schnaubt und sch\u00e4umt; die Thiere bergen sich;", "tokens": ["Er", "to\u00b7bet", ",", "schnaubt", "und", "sch\u00e4umt", ";", "die", "Thie\u00b7re", "ber\u00b7gen", "sich", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$.", "ART", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Tapfersten entfliehn den majest\u00e4tschen Klauen.", "tokens": ["Die", "Tap\u00b7fers\u00b7ten", "ent\u00b7fliehn", "den", "ma\u00b7jes\u00b7t\u00e4t\u00b7schen", "Klau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er br\u00fcllt; der H\u00fcgel bebt; das allgemeine Grauen", "tokens": ["Er", "br\u00fcllt", ";", "der", "H\u00fc\u00b7gel", "bebt", ";", "das", "all\u00b7ge\u00b7mei\u00b7ne", "Grau\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vermehrt ein jeder M\u00fcckenstich.", "tokens": ["Ver\u00b7mehrt", "ein", "je\u00b7der", "M\u00fc\u00b7cken\u00b7stich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was will der St\u00e4rkre thun? Der Schw\u00e4chre gibt nicht nach;", "tokens": ["Was", "will", "der", "St\u00e4r\u00b7kre", "thun", "?", "Der", "Schw\u00e4ch\u00b7re", "gibt", "nicht", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "VVINF", "$.", "ART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der L\u00f6we sucht umsonst die M\u00fccke zu erreichen,", "tokens": ["Der", "L\u00f6\u00b7we", "sucht", "um\u00b7sonst", "die", "M\u00fc\u00b7cke", "zu", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wird, nach langem Streit, nach mi\u00dfgelungnen Streichen,", "tokens": ["Und", "wird", ",", "nach", "lan\u00b7gem", "Streit", ",", "nach", "mi\u00df\u00b7ge\u00b7lung\u00b7nen", "Strei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Erm\u00fcdet, und an Kr\u00e4ften schwach.", "tokens": ["Er\u00b7m\u00fc\u00b7det", ",", "und", "an", "Kr\u00e4f\u00b7ten", "schwach", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Sie putzt ihr Panzerhemd, die Schuppen um den Leib,", "tokens": ["Sie", "putzt", "ihr", "Pan\u00b7zer\u00b7hemd", ",", "die", "Schup\u00b7pen", "um", "den", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ihren Federbusch, l\u00e4\u00dft beide Fl\u00fcgel klingen,", "tokens": ["Und", "ih\u00b7ren", "Fe\u00b7der\u00b7busch", ",", "l\u00e4\u00dft", "bei\u00b7de", "Fl\u00fc\u00b7gel", "klin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "VVFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zieht alle Schwerter ein, die aus dem R\u00fcssel dringen,", "tokens": ["Zieht", "al\u00b7le", "Schwer\u00b7ter", "ein", ",", "die", "aus", "dem", "R\u00fcs\u00b7sel", "drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und h\u00e4lt sich f\u00fcr kein schlechtes Weib.", "tokens": ["Und", "h\u00e4lt", "sich", "f\u00fcr", "kein", "schlech\u00b7tes", "Weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Nun steigt sie in die Luft, mit Sieg und Ruhm geschm\u00fcckt;", "tokens": ["Nun", "steigt", "sie", "in", "die", "Luft", ",", "mit", "Sieg", "und", "Ruhm", "ge\u00b7schm\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nun wei\u00df sie schon die Kunst, die L\u00f6wen zu besiegen:", "tokens": ["Nun", "wei\u00df", "sie", "schon", "die", "Kunst", ",", "die", "L\u00f6\u00b7wen", "zu", "be\u00b7sie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bald aber sieht man sie in ein Gewebe fliegen,", "tokens": ["Bald", "a\u00b7ber", "sieht", "man", "sie", "in", "ein", "Ge\u00b7we\u00b7be", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Darin die Spinne sie erstickt.", "tokens": ["Da\u00b7rin", "die", "Spin\u00b7ne", "sie", "er\u00b7stickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Aus beider Sicherheit wird deutlich wahrgenommen,", "tokens": ["Aus", "bei\u00b7der", "Si\u00b7cher\u00b7heit", "wird", "deut\u00b7lich", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df oft der schw\u00e4chste Feind den k\u00fchnsten Helden schl\u00e4gt.", "tokens": ["Da\u00df", "oft", "der", "schw\u00e4chs\u00b7te", "Feind", "den", "k\u00fchns\u00b7ten", "Hel\u00b7den", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie mancher Waghals ist im Zufall umgekommen,", "tokens": ["Wie", "man\u00b7cher", "Wag\u00b7hals", "ist", "im", "Zu\u00b7fall", "um\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den weder Sturm noch Schlacht erlegt!", "tokens": ["Den", "we\u00b7der", "Sturm", "noch", "Schlacht", "er\u00b7legt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "NN", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}