{"textgrid.poem.37020": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "Aus meinem Merkbuche", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbcommunismus! Gleichheit! Kein Selbsteigenthum!", "tokens": ["\u00bb", "com\u00b7mu\u00b7nis\u00b7mus", "!", "Gleich\u00b7heit", "!", "Kein", "Selbs\u00b7tei\u00b7gen\u00b7thum", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM.la", "$.", "NN", "$.", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Der Staat ist die B\u00fcrger-Caserne!", "tokens": ["Der", "Staat", "ist", "die", "B\u00fcr\u00b7ger\u00b7Ca\u00b7ser\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Kein Gesetz! Keine Liebe! Kein Kranz f\u00fcr den Ruhm!", "tokens": ["Kein", "Ge\u00b7setz", "!", "Kei\u00b7ne", "Lie\u00b7be", "!", "Kein", "Kranz", "f\u00fcr", "den", "Ruhm", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "PIAT", "NN", "$.", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Alles Gro\u00dfe, hei, an die Laterne!\u00ab", "tokens": ["Al\u00b7les", "Gro\u00b7\u00dfe", ",", "hei", ",", "an", "die", "La\u00b7ter\u00b7ne", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "ADJA", "$,", "ITJ", "$,", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Mit solchem Gebr\u00fcll und dem Weibergekreisch", "tokens": ["Mit", "sol\u00b7chem", "Ge\u00b7br\u00fcll", "und", "dem", "Wei\u00b7ber\u00b7ge\u00b7kreisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "ART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Dazwischen: \u00bbWir emancipiren das Fleisch!\u00ab", "tokens": ["Da\u00b7zwi\u00b7schen", ":", "\u00bb", "Wir", "e\u00b7man\u00b7ci\u00b7pi\u00b7ren", "das", "Fleisch", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "$.", "$(", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Zog t\u00e4glich die roheste Klasse", "tokens": ["Zog", "t\u00e4g\u00b7lich", "die", "ro\u00b7hes\u00b7te", "Klas\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Der Dummdummer wild durch die Gasse.", "tokens": ["Der", "Dumm\u00b7dum\u00b7mer", "wild", "durch", "die", "Gas\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Am Anfang erregten die Tollen mir Graun", "tokens": ["Am", "An\u00b7fang", "er\u00b7reg\u00b7ten", "die", "Tol\u00b7len", "mir", "Graun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "PPER", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Mit ihren Schlachtbeilen und Messern;", "tokens": ["Mit", "ih\u00b7ren", "Schlacht\u00b7bei\u00b7len", "und", "Mes\u00b7sern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Doch der Umstand, da\u00df sie tagt\u00e4glich zu schau'n,", "tokens": ["Doch", "der", "Um\u00b7stand", ",", "da\u00df", "sie", "tag\u00b7t\u00e4g\u00b7lich", "zu", "schau'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "KOUS", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Belehrte mich bald eines Bessern.", "tokens": ["Be\u00b7lehr\u00b7te", "mich", "bald", "ei\u00b7nes", "Bes\u00b7sern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie waren besoldet und spielten so gra\u00df,", "tokens": ["Sie", "wa\u00b7ren", "be\u00b7sol\u00b7det", "und", "spiel\u00b7ten", "so", "gra\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Um das Streben, das edelste, heiligste, das", "tokens": ["Um", "das", "Stre\u00b7ben", ",", "das", "e\u00b7dels\u00b7te", ",", "hei\u00b7ligs\u00b7te", ",", "das"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUI", "ART", "NN", "$,", "ART", "ADJA", "$,", "ADJA", "$,", "PRELS"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "Nach Freiheit, durch solch Menetekeln", "tokens": ["Nach", "Frei\u00b7heit", ",", "durch", "solch", "Me\u00b7ne\u00b7te\u00b7keln"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem Volk allgemach zu verekeln.", "tokens": ["Dem", "Volk", "all\u00b7ge\u00b7mach", "zu", "ve\u00b7re\u00b7keln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Ein B\u00fcrschchen sprach dr\u00fcben im Heil-Institut", "tokens": ["Ein", "B\u00fcr\u00b7schchen", "sprach", "dr\u00fc\u00b7ben", "im", "Heil\u00b7In\u00b7sti\u00b7tut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "F\u00fcr sittlich-verwahrloste Greise", "tokens": ["F\u00fcr", "sitt\u00b7lich\u00b7ver\u00b7wahr\u00b7los\u00b7te", "Grei\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "F\u00fcr den geistigen Fortschritt sehr warm und sehr gut", "tokens": ["F\u00fcr", "den", "geis\u00b7ti\u00b7gen", "Fort\u00b7schritt", "sehr", "warm", "und", "sehr", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV", "ADJD", "KON", "ADV", "ADJD"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Und ... drehte dabei sich im Kreise! \u2013", "tokens": ["Und", "...", "dreh\u00b7te", "da\u00b7bei", "sich", "im", "Krei\u00b7se", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$(", "VVFIN", "PAV", "PRF", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Daneben im Wasserverehrer-Verein,", "tokens": ["Da\u00b7ne\u00b7ben", "im", "Was\u00b7ser\u00b7ver\u00b7eh\u00b7rer\u00b7Ver\u00b7ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Da schimpfte man wacker auf Schnaps und auf Wein", "tokens": ["Da", "schimpf\u00b7te", "man", "wa\u00b7cker", "auf", "Schnaps", "und", "auf", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Und zechte hernach in Spelunken", "tokens": ["Und", "zech\u00b7te", "her\u00b7nach", "in", "Spe\u00b7lun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bis da\u00df man sternhagelvoll trunken.", "tokens": ["Bis", "da\u00df", "man", "stern\u00b7ha\u00b7gel\u00b7voll", "trun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Es gibt hier 'n Collegium (Namens: Mies-Mies)", "tokens": ["Es", "gibt", "hier", "'n", "Col\u00b7le\u00b7gi\u00b7um", "(", "Na\u00b7mens", ":", "Mies\u00b7Mies", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$(", "NN", "$.", "NE", "$("], "meter": "-+----+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Alter Weiber mit pechschwarzen Hauben,", "tokens": ["Al\u00b7ter", "Wei\u00b7ber", "mit", "pech\u00b7schwar\u00b7zen", "Hau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Das allen Dummdummern vorschreibet pr\u00e4cis,", "tokens": ["Das", "al\u00b7len", "Dumm\u00b7dum\u00b7mern", "vor\u00b7schrei\u00b7bet", "pr\u00e4\u00b7cis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Was sie sollen empfinden und glauben.", "tokens": ["Was", "sie", "sol\u00b7len", "emp\u00b7fin\u00b7den", "und", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "VVINF", "KON", "VVINF", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Und wer anders empfindet und Anderes glaubt,", "tokens": ["Und", "wer", "an\u00b7ders", "emp\u00b7fin\u00b7det", "und", "An\u00b7de\u00b7res", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "KON", "PIS", "VVFIN", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.6": {"text": "Der wird in den Fu\u00df- und den Hals-Block geschraubt,", "tokens": ["Der", "wird", "in", "den", "Fu\u00df", "und", "den", "Hals\u00b7Block", "ge\u00b7schraubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ART", "TRUNC", "KON", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Und mu\u00df dies ungl\u00fcckliche Wesen", "tokens": ["Und", "mu\u00df", "dies", "un\u00b7gl\u00fcck\u00b7li\u00b7che", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PDS", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Des Sultans Gedichte dann lesen!", "tokens": ["Des", "Sul\u00b7tans", "Ge\u00b7dich\u00b7te", "dann", "le\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.5": {"line.1": {"text": "Niemals wag' ich einen Zweifel", "tokens": ["Nie\u00b7mals", "wag'", "ich", "ei\u00b7nen", "Zwei\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auszusprechen, kaum zu hegen,", "tokens": ["Aus\u00b7zu\u00b7spre\u00b7chen", ",", "kaum", "zu", "he\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn hier alle Eltern sagen,", "tokens": ["Wenn", "hier", "al\u00b7le", "El\u00b7tern", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber ohne Ausnahm' alle:", "tokens": ["A\u00b7ber", "oh\u00b7ne", "Aus\u00b7nahm'", "al\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ihr Kind \u00bbmerkw\u00fcrdig klug sei!", "tokens": ["Da\u00df", "ihr", "Kind", "\u00bb", "merk\u00b7w\u00fcr\u00b7dig", "klug", "sei", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$(", "ADJD", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und gewitzt wie gar kein and'res!\u00ab", "tokens": ["Und", "ge\u00b7witzt", "wie", "gar", "kein", "an\u00b7d'\u00b7res", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVPP", "KOKOM", "ADV", "PIAT", "PIS", "$.", "$("], "meter": "--+-+----", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Aber wie's bei diesem Segen", "tokens": ["A\u00b7ber", "wie's", "bei", "die\u00b7sem", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An geiststarker Jugend m\u00f6glich,", "tokens": ["An", "geist\u00b7star\u00b7ker", "Ju\u00b7gend", "m\u00f6g\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df man unter den Erwachs'nen", "tokens": ["Da\u00df", "man", "un\u00b7ter", "den", "Er\u00b7wachs'\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine solche ungeheure", "tokens": ["Ei\u00b7ne", "sol\u00b7che", "un\u00b7ge\u00b7heu\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["ART", "PIAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Anzahl gro\u00dfer Esel findet,", "tokens": ["An\u00b7zahl", "gro\u00b7\u00dfer", "E\u00b7sel", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das ist's, was ich nicht verstehe.", "tokens": ["Das", "ist's", ",", "was", "ich", "nicht", "ver\u00b7ste\u00b7he", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "PWS", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Das Gymnasium, in welchem die Pr\u00fcfung heut war,", "tokens": ["Das", "Gym\u00b7na\u00b7si\u00b7um", ",", "in", "wel\u00b7chem", "die", "Pr\u00fc\u00b7fung", "heut", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "ADV", "VAFIN", "$,"], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Tr\u00e4gt die Inschrift: \u00bbWissen macht W\u00fchler.\u00ab", "tokens": ["Tr\u00e4gt", "die", "In\u00b7schrift", ":", "\u00bb", "Wis\u00b7sen", "macht", "W\u00fch\u00b7ler", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "$(", "NN", "VVFIN", "NN", "$.", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Der Director, ein alter und braver Husar,", "tokens": ["Der", "Di\u00b7rec\u00b7tor", ",", "ein", "al\u00b7ter", "und", "bra\u00b7ver", "Hu\u00b7sar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Ward examinirt durch die Sch\u00fcler.", "tokens": ["Ward", "e\u00b7xa\u00b7min\u00b7irt", "durch", "die", "Sch\u00fc\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man ging scharf ihm zu Leibe, allein er ", "tokens": ["Man", "ging", "scharf", "ihm", "zu", "Lei\u00b7be", ",", "al\u00b7lein", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "VVFIN", "PPER", "APPR", "NN", "$,", "ADV", "PPER"], "meter": "-++--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Denn jedwede Antwort gab daf\u00fcr ein Pfand,", "tokens": ["Denn", "jed\u00b7we\u00b7de", "Ant\u00b7wort", "gab", "da\u00b7f\u00fcr", "ein", "Pfand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PAV", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Da\u00df vom Wissen in allen Gestalten", "tokens": ["Da\u00df", "vom", "Wis\u00b7sen", "in", "al\u00b7len", "Ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "APPR", "PIAT", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.8": {"text": "Er vollst\u00e4ndig rein sich erhalten.", "tokens": ["Er", "voll\u00b7st\u00e4n\u00b7dig", "rein", "sich", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "PRF", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.8": {"line.1": {"text": "Und wie Er, so bewiesen die Lehrer, die noch", "tokens": ["Und", "wie", "Er", ",", "so", "be\u00b7wie\u00b7sen", "die", "Leh\u00b7rer", ",", "die", "noch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "PPER", "$,", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vor's Examen der Sch\u00fcler heut mu\u00dften,", "tokens": ["Vor's", "E\u00b7xa\u00b7men", "der", "Sch\u00fc\u00b7ler", "heut", "mu\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADV", "VMFIN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da\u00df sie viel zwar vom Muftigefabel, jedoch", "tokens": ["Da\u00df", "sie", "viel", "zwar", "vom", "Muf\u00b7ti\u00b7ge\u00b7fa\u00b7bel", ",", "je\u00b7doch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPRART", "NN", "$,", "ADV"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Von Gott und der Welt Nichts wu\u00dften;", "tokens": ["Von", "Gott", "und", "der", "Welt", "Nichts", "wu\u00df\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ART", "NN", "PIS", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da\u00df sie also das Ziel, und zwar wunderbar leicht,", "tokens": ["Da\u00df", "sie", "al\u00b7so", "das", "Ziel", ",", "und", "zwar", "wun\u00b7der\u00b7bar", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "$,", "KON", "ADV", "ADJD", "ADJD", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.6": {"text": "Das h\u00f6chste der Philosophieen erreicht,", "tokens": ["Das", "h\u00f6chs\u00b7te", "der", "Phi\u00b7lo\u00b7so\u00b7phi\u00b7een", "er\u00b7reicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "VVPP", "$,"], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Und da\u00df f\u00fcr der Staatsschule Zweck hie", "tokens": ["Und", "da\u00df", "f\u00fcr", "der", "Staats\u00b7schu\u00b7le", "Zweck", "hie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ART", "NN", "NN", "ADV"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Durchaus und vollkommen am Fleck sie.", "tokens": ["Durc\u00b7haus", "und", "voll\u00b7kom\u00b7men", "am", "Fleck", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADJD", "APPRART", "NN", "PPER", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}