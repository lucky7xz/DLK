{"dta.poem.19386": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "119.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195090", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein B\u00fc\u00dfer, der im Wald bei strenger Bu\u00dfe b\u00fc\u00dfte,", "tokens": ["Ein", "B\u00fc\u00b7\u00dfer", ",", "der", "im", "Wald", "bei", "stren\u00b7ger", "Bu\u00b7\u00dfe", "b\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit s\u00fc\u00dfen Fr\u00fcchten nie den herben Gaumen s\u00fc\u00dfte,", "tokens": ["Mit", "s\u00fc\u00b7\u00dfen", "Fr\u00fcch\u00b7ten", "nie", "den", "her\u00b7ben", "Gau\u00b7men", "s\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der trocknen Lippe nie erlaubte k\u00fchles Na\u00df,", "tokens": ["Der", "trock\u00b7nen", "Lip\u00b7pe", "nie", "er\u00b7laub\u00b7te", "k\u00fch\u00b7les", "Na\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur laues Wasser trank, nur welke Wurzeln a\u00df;", "tokens": ["Nur", "lau\u00b7es", "Was\u00b7ser", "trank", ",", "nur", "wel\u00b7ke", "Wur\u00b7zeln", "a\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$,", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ward einst gefragt, warum er sich so gar kasteie,", "tokens": ["Ward", "einst", "ge\u00b7fragt", ",", "wa\u00b7rum", "er", "sich", "so", "gar", "kas\u00b7tei\u00b7e", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$,", "PWAV", "PPER", "PRF", "ADV", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ob zum Seelenheil die Pein nothwendig seie?", "tokens": ["Und", "ob", "zum", "See\u00b7len\u00b7heil", "die", "Pein", "noth\u00b7wen\u00b7dig", "sei\u00b7e", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "NN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Er sprach: Es ist allein f\u00fcr meine Seele nicht,", "tokens": ["Er", "sprach", ":", "Es", "ist", "al\u00b7lein", "f\u00fcr", "mei\u00b7ne", "See\u00b7le", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich halte so zugleich die Welt im Gleichgewicht.", "tokens": ["Ich", "hal\u00b7te", "so", "zu\u00b7gleich", "die", "Welt", "im", "Gleich\u00b7ge\u00b7wicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Soviele sind die nur nach s\u00fc\u00dfen Fr\u00fcchten rennen,", "tokens": ["So\u00b7vie\u00b7le", "sind", "die", "nur", "nach", "s\u00fc\u00b7\u00dfen", "Fr\u00fcch\u00b7ten", "ren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soviele die allein nach k\u00fchler Labe brennen,", "tokens": ["So\u00b7vie\u00b7le", "die", "al\u00b7lein", "nach", "k\u00fch\u00b7ler", "La\u00b7be", "bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Soviele die wie Gift das Herbe weichlich fliehn,", "tokens": ["So\u00b7vie\u00b7le", "die", "wie", "Gift", "das", "Her\u00b7be", "weich\u00b7lich", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "KOKOM", "NN", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df auch das Gegentheil einmal nothwendig schien.", "tokens": ["Da\u00df", "auch", "das", "Ge\u00b7gen\u00b7theil", "ein\u00b7mal", "noth\u00b7wen\u00b7dig", "schien", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "So \u00fcbernahm ich denn, was nicht durft' unterbleiben,", "tokens": ["So", "\u00fc\u00b7bern\u00b7ahm", "ich", "denn", ",", "was", "nicht", "durft'", "un\u00b7ter\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PRELS", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und \u00fcbertreibe hier, weil sie dort \u00fcbertreiben.", "tokens": ["Und", "\u00fc\u00b7bert\u00b7rei\u00b7be", "hier", ",", "weil", "sie", "dort", "\u00fc\u00b7bert\u00b7rei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}