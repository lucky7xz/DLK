{"dta.poem.5358": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Inseln.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn wir der Berge schroffe H\u00f6hen,", "tokens": ["Wenn", "wir", "der", "Ber\u00b7ge", "schrof\u00b7fe", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit einem aufmercksamen Blick,", "tokens": ["Mit", "ei\u00b7nem", "auf\u00b7merck\u00b7sa\u00b7men", "Blick", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bedachtsam an- und \u00fcbersehen,", "tokens": ["Be\u00b7dacht\u00b7sam", "an", "und", "\u00fc\u00b7ber\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "TRUNC", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und dencken etwann einst zur\u00fcck", "tokens": ["Und", "den\u00b7cken", "et\u00b7wann", "einst", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auf Inseln, die im Meere stehen;", "tokens": ["Auf", "In\u00b7seln", ",", "die", "im", "Mee\u00b7re", "ste\u00b7hen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So scheinen diese jenen gleich,", "tokens": ["So", "schei\u00b7nen", "die\u00b7se", "je\u00b7nen", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "PDS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nur mit dem Unterscheid allein,", "tokens": ["Nur", "mit", "dem", "Un\u00b7ter\u00b7scheid", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.10": {"text": "Bey den Gedancken f\u00e4llt mir ein:", "tokens": ["Bey", "den", "Ge\u00b7dan\u00b7cken", "f\u00e4llt", "mir", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Ob etwann eine tieffe Fluth", "tokens": ["Ob", "et\u00b7wann", "ei\u00b7ne", "tief\u00b7fe", "Fluth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Um unsere Gebirg\u2019 einst auch geruht,", "tokens": ["Um", "un\u00b7se\u00b7re", "Ge\u00b7bir\u00b7g'", "einst", "auch", "ge\u00b7ruht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "Und da\u00df, ob wir es gleich nicht lesen,", "tokens": ["Und", "da\u00df", ",", "ob", "wir", "es", "gleich", "nicht", "le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "KOUS", "PPER", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Sie Wasser-Inseln einst gewesen?", "tokens": ["Sie", "Was\u00b7ser\u00b7In\u00b7seln", "einst", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Wie uns, wenn wir auf Berge steigen,", "tokens": ["Wie", "uns", ",", "wenn", "wir", "auf", "Ber\u00b7ge", "stei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "KOUS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und sich dort Meer-Gew\u00e4chs\u2019, in tausend Arten, zeigen,", "tokens": ["Und", "sich", "dort", "Meer\u00b7Ge\u00b7w\u00e4chs'", ",", "in", "tau\u00b7send", "Ar\u00b7ten", ",", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PRF", "ADV", "NN", "$,", "APPR", "CARD", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Augen-Schein davon fast \u00fcberf\u00fchrt,", "tokens": ["Der", "Au\u00b7gen\u00b7Schein", "da\u00b7von", "fast", "\u00fc\u00b7berf\u00b7\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Auf eine Art, die uns mit Furcht und Anmuth r\u00fchrt.", "tokens": ["Auf", "ei\u00b7ne", "Art", ",", "die", "uns", "mit", "Furcht", "und", "An\u00b7muth", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sprich! w\u00fcrden nicht, wenn etwann jetzt das Meer", "tokens": ["Sprich", "!", "w\u00fcr\u00b7den", "nicht", ",", "wenn", "et\u00b7wann", "jetzt", "das", "Meer"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "$.", "VAFIN", "PTKNEG", "$,", "KOUS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Vom Wasser ausgeleeret w\u00e4r,", "tokens": ["Vom", "Was\u00b7ser", "aus\u00b7ge\u00b7lee\u00b7ret", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Die Inseln all\u2019 als grosser Berge H\u00f6h\u2019n", "tokens": ["Die", "In\u00b7seln", "all'", "als", "gros\u00b7ser", "Ber\u00b7ge", "H\u00f6h'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIAT", "KOKOM", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Ohn allen Zweifel anzusehn,", "tokens": ["Ohn", "al\u00b7len", "Zwei\u00b7fel", "an\u00b7zu\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Und zu betrachten seyn? Wie w\u00e4r\u2019 es, wenn vielleicht", "tokens": ["Und", "zu", "be\u00b7trach\u00b7ten", "seyn", "?", "Wie", "w\u00e4r'", "es", ",", "wenn", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKZU", "VVINF", "VAINF", "$.", "PWAV", "VAFIN", "PPER", "$,", "KOUS", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die Fluth dereinst noch mehr vertheilt w\u00e4r\u2019 und versiegen,", "tokens": ["Die", "Fluth", "de\u00b7reinst", "noch", "mehr", "ver\u00b7theilt", "w\u00e4r'", "und", "ver\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADV", "VVPP", "VAFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Meer-Berg\u2019 ebenfals, entbl\u00f6sset aufwerts stiegen,", "tokens": ["Die", "Meer\u00b7Ber\u00b7g'", "e\u00b7ben\u00b7fals", ",", "ent\u00b7bl\u00f6s\u00b7set", "auf\u00b7werts", "stie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.26": {"text": "Und so, wie unsre Berg\u2019 und Fl\u00e4chen unsrer Erden,", "tokens": ["Und", "so", ",", "wie", "uns\u00b7re", "Ber\u00b7g'", "und", "Fl\u00e4\u00b7chen", "uns\u00b7rer", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "PPOSAT", "NN", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Auch Inseln in der Luft einst k\u00f6nnten werden?", "tokens": ["Auch", "In\u00b7seln", "in", "der", "Luft", "einst", "k\u00f6nn\u00b7ten", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "ADV", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Mit den Gedancken schlief ich ein,", "tokens": ["Mit", "den", "Ge\u00b7dan\u00b7cken", "schlief", "ich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ein verwirrter Traum mit meinen Sinnen spielte;", "tokens": ["Als", "ein", "ver\u00b7wirr\u00b7ter", "Traum", "mit", "mei\u00b7nen", "Sin\u00b7nen", "spiel\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da ich mich bi\u00df zum Mond in Eil getragen f\u00fchlte.", "tokens": ["Da", "ich", "mich", "bi\u00df", "zum", "Mond", "in", "Eil", "ge\u00b7tra\u00b7gen", "f\u00fchl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "APPRART", "NN", "APPR", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich fand in dieser Welt, die unsre stets begleitet,", "tokens": ["Ich", "fand", "in", "die\u00b7ser", "Welt", ",", "die", "uns\u00b7re", "stets", "be\u00b7glei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "$,", "PRELS", "PPOSAT", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df selbe gr\u00f6ss\u2019ren theils aus Wasser zubereitet.", "tokens": ["Da\u00df", "sel\u00b7be", "gr\u00f6ss'\u00b7ren", "theils", "aus", "Was\u00b7ser", "zu\u00b7be\u00b7rei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADJA", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein kleiner Philosoph, der viertzig mahl so klein,", "tokens": ["Ein", "klei\u00b7ner", "Phi\u00b7lo\u00b7soph", ",", "der", "viert\u00b7zig", "mahl", "so", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "CARD", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als wie wir hier auf Erden seyn,", "tokens": ["Als", "wie", "wir", "hier", "auf", "Er\u00b7den", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "PPER", "ADV", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erzehlte mir zu Anfang vielerley,", "tokens": ["Er\u00b7zehl\u00b7te", "mir", "zu", "An\u00b7fang", "vie\u00b7ler\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PIAT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und unter andern auch: da\u00df ihre Welt", "tokens": ["Und", "un\u00b7ter", "an\u00b7dern", "auch", ":", "da\u00df", "ih\u00b7re", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "PIS", "ADV", "$.", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Aus unsrer Welt entstanden sey.", "tokens": ["Aus", "uns\u00b7rer", "Welt", "ent\u00b7stan\u00b7den", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die Erde w\u00e4r\u2019 zuerst mit Wasser gantz bedeckt,", "tokens": ["Die", "Er\u00b7de", "w\u00e4r'", "zu\u00b7erst", "mit", "Was\u00b7ser", "gantz", "be\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So da\u00df sichs h\u00f6her noch als alle Berg\u2019 erstreckt;", "tokens": ["So", "da\u00df", "sichs", "h\u00f6\u00b7her", "noch", "als", "al\u00b7le", "Ber\u00b7g'", "er\u00b7streckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "ADJD", "ADV", "KOKOM", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.13": {"text": "Durch ihres Sch\u00f6pfers blosses Wollen,", "tokens": ["Durch", "ih\u00b7res", "Sch\u00f6p\u00b7fers", "blos\u00b7ses", "Wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Da\u00df unsre Welt bewohnet werden sollen,", "tokens": ["Da\u00df", "uns\u00b7re", "Welt", "be\u00b7woh\u00b7net", "wer\u00b7den", "sol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVPP", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "H\u00e4tt er, der aller Fluten Last", "tokens": ["H\u00e4tt", "er", ",", "der", "al\u00b7ler", "Flu\u00b7ten", "Last"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PIAT", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "In einen Schlauch zusammen fa\u00dft,", "tokens": ["In", "ei\u00b7nen", "Schlauch", "zu\u00b7sam\u00b7men", "fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die Wasser guten theils von ihr genommen,", "tokens": ["Die", "Was\u00b7ser", "gu\u00b7ten", "theils", "von", "ihr", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Und sie (woraus der Mond entsprungen und gekommen)", "tokens": ["Und", "sie", "(", "wo\u00b7raus", "der", "Mond", "ent\u00b7sprun\u00b7gen", "und", "ge\u00b7kom\u00b7men", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "PWAV", "ART", "NN", "VVPP", "KON", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So wol zu ihrem Nutz, als auch zum Dienst der Welt,", "tokens": ["So", "wol", "zu", "ih\u00b7rem", "Nutz", ",", "als", "auch", "zum", "Dienst", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "$,", "KOUS", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "In Wirbel unsrer Erd\u2019 in solchen Stand gestellt,", "tokens": ["In", "Wir\u00b7bel", "uns\u00b7rer", "Erd'", "in", "sol\u00b7chen", "Stand", "ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Da\u00df wir uns beid\u2019 anjetzt, vom Sonnen-Strahl beschienen,", "tokens": ["Da\u00df", "wir", "uns", "beid'", "an\u00b7jetzt", ",", "vom", "Son\u00b7nen\u00b7Strahl", "be\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PIS", "VVFIN", "$,", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Durch einen Gegen-Schein einander dienen.", "tokens": ["Durch", "ei\u00b7nen", "Ge\u00b7gen\u00b7Schein", "ein\u00b7an\u00b7der", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Auf gleiche Weise w\u00e4r\u2019 es auch Saturn ergangen;", "tokens": ["Auf", "glei\u00b7che", "Wei\u00b7se", "w\u00e4r'", "es", "auch", "Sa\u00b7turn", "er\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPER", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Nicht minder Jupiter, die (wie wir einen nur)", "tokens": ["Nicht", "min\u00b7der", "Ju\u00b7pi\u00b7ter", ",", "die", "(", "wie", "wir", "ei\u00b7nen", "nur", ")"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "NN", "$,", "PRELS", "$(", "PWAV", "PPER", "ART", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Neun Monden zu Trabanten drauf empfangen.", "tokens": ["Neun", "Mon\u00b7den", "zu", "Tra\u00b7ban\u00b7ten", "drauf", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Ja, er vermeinte gar, wofern ihn nicht die Spur", "tokens": ["Ja", ",", "er", "ver\u00b7mein\u00b7te", "gar", ",", "wo\u00b7fern", "ihn", "nicht", "die", "Spur"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Gewisser Zeichen sollte triegen;", "tokens": ["Ge\u00b7wis\u00b7ser", "Zei\u00b7chen", "soll\u00b7te", "trie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Wir k\u00f6nnten noch wol einen kriegen:", "tokens": ["Wir", "k\u00f6nn\u00b7ten", "noch", "wol", "ei\u00b7nen", "krie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Da, aus dem gar zu tieffen Meer,", "tokens": ["Da", ",", "aus", "dem", "gar", "zu", "tief\u00b7fen", "Meer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wodurch wir denn nicht nur noch einen neuen Schein", "tokens": ["Wo\u00b7durch", "wir", "denn", "nicht", "nur", "noch", "ei\u00b7nen", "neu\u00b7en", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "PTKNEG", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Nachts am Himmel w\u00fcrden sehen,", "tokens": ["Des", "Nachts", "am", "Him\u00b7mel", "w\u00fcr\u00b7den", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es w\u00fcrden so viel mehr Gebirg\u2019 entdecket stehen,", "tokens": ["Es", "w\u00fcr\u00b7den", "so", "viel", "mehr", "Ge\u00b7bir\u00b7g'", "ent\u00b7de\u00b7cket", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIAT", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.4": {"text": "Die jetzt, in Inseln, noch im Meer verdecket seyn,", "tokens": ["Die", "jetzt", ",", "in", "In\u00b7seln", ",", "noch", "im", "Meer", "ver\u00b7de\u00b7cket", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "APPR", "NN", "$,", "ADV", "APPRART", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die alle von den B\u00fcrgern unsrer Erden", "tokens": ["Die", "al\u00b7le", "von", "den", "B\u00fcr\u00b7gern", "uns\u00b7rer", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So denn bewohnet k\u00f6nnten werden.", "tokens": ["So", "denn", "be\u00b7woh\u00b7net", "k\u00f6nn\u00b7ten", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Leser glaubet leicht, wie ich darauf erwacht,", "tokens": ["Mein", "Le\u00b7ser", "glau\u00b7bet", "leicht", ",", "wie", "ich", "da\u00b7rauf", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "$,", "PWAV", "PPER", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df ich um diesen Traum recht inniglich gelacht,", "tokens": ["Da\u00df", "ich", "um", "die\u00b7sen", "Traum", "recht", "in\u00b7nig\u00b7lich", "ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch hab ich ihm auch wol zuweilen nachgedacht.", "tokens": ["Doch", "hab", "ich", "ihm", "auch", "wol", "zu\u00b7wei\u00b7len", "nach\u00b7ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}