{"textgrid.poem.42147": {"metadata": {"author": {"name": "Wedekind, Frank", "birth": "N.A.", "death": "N.A."}, "title": "Weltweisheit", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir waren Philister und merkten es, wie", "tokens": ["Wir", "wa\u00b7ren", "Phi\u00b7lis\u00b7ter", "und", "merk\u00b7ten", "es", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "NN", "KON", "VVFIN", "PPER", "$,", "PWAV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Kr\u00e4fte des Geistes erschlafften;", "tokens": ["Die", "Kr\u00e4f\u00b7te", "des", "Geis\u00b7tes", "er\u00b7schlaff\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Da warfen wir uns auf die Philosophie,", "tokens": ["Da", "war\u00b7fen", "wir", "uns", "auf", "die", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die tiefste der Wissenschaften.", "tokens": ["Die", "tiefs\u00b7te", "der", "Wis\u00b7sen\u00b7schaf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Da haben wir gr\u00fcndlich uns eingepr\u00e4gt", "tokens": ["Da", "ha\u00b7ben", "wir", "gr\u00fcnd\u00b7lich", "uns", "ein\u00b7ge\u00b7pr\u00e4gt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "PPER", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die Spr\u00fcche der gro\u00dfen Gelehrten;", "tokens": ["Die", "Spr\u00fc\u00b7che", "der", "gro\u00b7\u00dfen", "Ge\u00b7lehr\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und was man im Fleisch und im Blute tr\u00e4gt,", "tokens": ["Und", "was", "man", "im", "Fleisch", "und", "im", "Blu\u00b7te", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "APPRART", "NN", "KON", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Das wei\u00df man dann auch zu verwerten.", "tokens": ["Das", "wei\u00df", "man", "dann", "auch", "zu", "ver\u00b7wer\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ersch\u00f6pfe die Stunden, genie\u00dfe die Zeit,", "tokens": ["Er\u00b7sch\u00f6p\u00b7fe", "die", "Stun\u00b7den", ",", "ge\u00b7nie\u00b7\u00dfe", "die", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "La\u00df Katzen und Hunde verzagen.", "tokens": ["La\u00df", "Kat\u00b7zen", "und", "Hun\u00b7de", "ver\u00b7za\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Die Reue, den Fluch und die Niedrigkeit,", "tokens": ["Die", "Reu\u00b7e", ",", "den", "Fluch", "und", "die", "Nied\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wir lernten es stoisch ertragen.", "tokens": ["Wir", "lern\u00b7ten", "es", "sto\u00b7isch", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Als Stoiker lebten wir \u00fcber Tag,", "tokens": ["Als", "Stoi\u00b7ker", "leb\u00b7ten", "wir", "\u00fc\u00b7ber", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kein Staubgeborner stand h\u00f6her;", "tokens": ["Kein", "Staub\u00b7ge\u00b7bor\u00b7ner", "stand", "h\u00f6\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch wenn die Nacht auf den Bergen lag,", "tokens": ["Doch", "wenn", "die", "Nacht", "auf", "den", "Ber\u00b7gen", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dann wurden wir Epikur\u00e4er.", "tokens": ["Dann", "wur\u00b7den", "wir", "E\u00b7pi\u00b7ku\u00b7r\u00e4\u00b7er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "So flossen die Jahre der Jugend dahin,", "tokens": ["So", "flos\u00b7sen", "die", "Jah\u00b7re", "der", "Ju\u00b7gend", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PAV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Sch\u00f6pfung ein bl\u00fchender Garten,", "tokens": ["Die", "Sch\u00f6p\u00b7fung", "ein", "bl\u00fc\u00b7hen\u00b7der", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Mit duftigen Blumen und M\u00e4dchen darin", "tokens": ["Mit", "duf\u00b7ti\u00b7gen", "Blu\u00b7men", "und", "M\u00e4d\u00b7chen", "da\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "PAV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Von allen exotischen Arten.", "tokens": ["Von", "al\u00b7len", "e\u00b7xot\u00b7isc\u00b7hen", "Ar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und wenn uns dann schlie\u00dflich die Kraft gebricht,", "tokens": ["Und", "wenn", "uns", "dann", "schlie\u00df\u00b7lich", "die", "Kraft", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Zu fr\u00f6nen unsern Gel\u00fcsten,", "tokens": ["Zu", "fr\u00f6\u00b7nen", "un\u00b7sern", "Ge\u00b7l\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dann beugen das Haupt wir noch lange nicht,", "tokens": ["Dann", "beu\u00b7gen", "das", "Haupt", "wir", "noch", "lan\u00b7ge", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "ADV", "PTKNEG", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Dann werden wir Pessimisten.", "tokens": ["Dann", "wer\u00b7den", "wir", "Pes\u00b7si\u00b7mis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Dann spotten wir \u00fcber die eitle Welt,", "tokens": ["Dann", "spot\u00b7ten", "wir", "\u00fc\u00b7ber", "die", "eit\u00b7le", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und der Menschheit kleinliches Trachten,", "tokens": ["Und", "der", "Menschheit", "klein\u00b7li\u00b7ches", "Trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Dann lernen wir, was uns zu sauer f\u00e4llt,", "tokens": ["Dann", "ler\u00b7nen", "wir", ",", "was", "uns", "zu", "sau\u00b7er", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PRELS", "PPER", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Aus tiefster Seele verachten.", "tokens": ["Aus", "tiefs\u00b7ter", "See\u00b7le", "ver\u00b7ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Dann hebe die Schwingen, Phantasie,", "tokens": ["Dann", "he\u00b7be", "die", "Schwin\u00b7gen", ",", "Phan\u00b7ta\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu jenen himmlischen H\u00f6hen,", "tokens": ["Zu", "je\u00b7nen", "himm\u00b7li\u00b7schen", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zu jenen Gegenden, die noch nie", "tokens": ["Zu", "je\u00b7nen", "Ge\u00b7gen\u00b7den", ",", "die", "noch", "nie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein sterbliches Auge gesehen.", "tokens": ["Ein", "sterb\u00b7li\u00b7ches", "Au\u00b7ge", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.9": {"line.1": {"text": "Dort, wo ein rosiges Morgenrot", "tokens": ["Dort", ",", "wo", "ein", "ro\u00b7si\u00b7ges", "Mor\u00b7gen\u00b7rot"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den fernen \u00c4ther entz\u00fcndet,", "tokens": ["Den", "fer\u00b7nen", "\u00c4\u00b7ther", "ent\u00b7z\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hat sich Frau Eva nach ihrem Tod", "tokens": ["Hat", "sich", "Frau", "E\u00b7va", "nach", "ih\u00b7rem", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "NN", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ein neues Eden gegr\u00fcndet.", "tokens": ["Ein", "neu\u00b7es", "E\u00b7den", "ge\u00b7gr\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Es scharrte mein Musengaul vor der T\u00fcr,", "tokens": ["Es", "scharr\u00b7te", "mein", "Mu\u00b7sen\u00b7gaul", "vor", "der", "T\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da bin ich aufgestiegen,", "tokens": ["Da", "bin", "ich", "auf\u00b7ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da flog ich, Liebchen, zu dir, zu dir,", "tokens": ["Da", "flog", "ich", ",", "Lieb\u00b7chen", ",", "zu", "dir", ",", "zu", "dir", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "NN", "$,", "APPR", "PPER", "$,", "APPR", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In deinen Armen zu liegen.", "tokens": ["In", "dei\u00b7nen", "Ar\u00b7men", "zu", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Und als ich mich sonnte in deinem Blick,", "tokens": ["Und", "als", "ich", "mich", "sonn\u00b7te", "in", "dei\u00b7nem", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "War Angst und Not verschwunden.", "tokens": ["War", "Angst", "und", "Not", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da hab ich das irdische Liebesgl\u00fcck", "tokens": ["Da", "hab", "ich", "das", "ir\u00b7di\u00b7sche", "Lie\u00b7bes\u00b7gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Weit s\u00fc\u00dfer als je gefunden.", "tokens": ["Weit", "s\u00fc\u00b7\u00dfer", "als", "je", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KOKOM", "ADV", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Das Eis zerschmolz, das Herz ward weit", "tokens": ["Das", "Eis", "zer\u00b7schmolz", ",", "das", "Herz", "ward", "weit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und jubelte Fr\u00fchlingslieder.", "tokens": ["Und", "ju\u00b7bel\u00b7te", "Fr\u00fch\u00b7lings\u00b7lie\u00b7der", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und mit der jungen Begehrlichkeit", "tokens": ["Und", "mit", "der", "jun\u00b7gen", "Be\u00b7gehr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Kam die junge Gesundheit wieder.", "tokens": ["Kam", "die", "jun\u00b7ge", "Ge\u00b7sund\u00b7heit", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "ADV", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Laut jauchzt ich auf aus voller Brust:", "tokens": ["Laut", "jauchzt", "ich", "auf", "aus", "vol\u00b7ler", "Brust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O la\u00df mich bei dir bleiben,", "tokens": ["O", "la\u00df", "mich", "bei", "dir", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In deiner unverg\u00e4nglichen Lust", "tokens": ["In", "dei\u00b7ner", "un\u00b7ver\u00b7g\u00e4ng\u00b7li\u00b7chen", "Lust"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Auf ewig mich zu bet\u00e4uben!", "tokens": ["Auf", "e\u00b7wig", "mich", "zu", "be\u00b7t\u00e4u\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Da kracht der Himmel, die Erde bebt,", "tokens": ["Da", "kracht", "der", "Him\u00b7mel", ",", "die", "Er\u00b7de", "bebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es donnert die Atmosph\u00e4re,", "tokens": ["Es", "don\u00b7nert", "die", "At\u00b7mo\u00b7sph\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und meine s\u00fcndige Seele verschwebt", "tokens": ["Und", "mei\u00b7ne", "s\u00fcn\u00b7di\u00b7ge", "See\u00b7le", "ver\u00b7schwebt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In duftige, luftige Leere.", "tokens": ["In", "duf\u00b7ti\u00b7ge", ",", "luf\u00b7ti\u00b7ge", "Lee\u00b7re", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}