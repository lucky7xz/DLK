{"textgrid.poem.58687": {"metadata": {"author": {"name": "Tersteegen, Gerhard", "birth": "N.A.", "death": "N.A."}, "title": "119.", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Viele werden gereinigt, gel\u00e4utert und bew\u00e4hrt werden. Daniel 12, 10", "tokens": ["Vie\u00b7le", "wer\u00b7den", "ge\u00b7rei\u00b7nigt", ",", "ge\u00b7l\u00e4u\u00b7tert", "und", "be\u00b7w\u00e4hrt", "wer\u00b7den", ".", "Da\u00b7ni\u00b7el", "12", ",", "10"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "number", "punct", "number"], "pos": ["PIS", "VAFIN", "VVPP", "$,", "VVPP", "KON", "VVPP", "VAINF", "$.", "NE", "CARD", "$,", "CARD"], "meter": "+-+--+--+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.2": {"line.1": {"text": "Der Weizen kann noch leicht von Spreu gereinigt werden,", "tokens": ["Der", "Wei\u00b7zen", "kann", "noch", "leicht", "von", "Spreu", "ge\u00b7rei\u00b7nigt", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADJD", "APPR", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das tut's nicht, ob du schon von toten Werken rein,", "tokens": ["Das", "tut's", "nicht", ",", "ob", "du", "schon", "von", "to\u00b7ten", "Wer\u00b7ken", "rein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es sitzet durch und durch in dir der Schmutz der Erden,", "tokens": ["Es", "sit\u00b7zet", "durch", "und", "durch", "in", "dir", "der", "Schmutz", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "KON", "APPR", "APPR", "PPER", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Lauge bei\u00dft noch scharf, eh' du schneewei\u00df wirst sein.", "tokens": ["Die", "Lau\u00b7ge", "bei\u00dft", "noch", "scharf", ",", "eh'", "du", "schnee\u00b7wei\u00df", "wirst", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "VAINF", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Doch ist's ", "tokens": ["Doch", "ist's"], "token_info": ["word", "word"], "pos": ["KON", "NE"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Die tiefste Seelennot die schlimmsten Schlacken zeigt;", "tokens": ["Die", "tiefs\u00b7te", "See\u00b7len\u00b7not", "die", "schlimms\u00b7ten", "Schla\u00b7cken", "zeigt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mein Schmelzer, fahr nur fort, mach mich in Proben treuer", "tokens": ["Mein", "Schmel\u00b7zer", ",", "fahr", "nur", "fort", ",", "mach", "mich", "in", "Pro\u00b7ben", "treu\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ADV", "PTKVZ", "$,", "VVFIN", "PPER", "APPR", "NN", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und mit mir viele noch! Wohl dem, der's Ziel erreicht!", "tokens": ["Und", "mit", "mir", "vie\u00b7le", "noch", "!", "Wohl", "dem", ",", "der's", "Ziel", "er\u00b7reicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PIS", "ADV", "$.", "ADV", "ART", "$,", "PRELAT", "NN", "VVPP", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}}}}}