{"dta.poem.8617": {"metadata": {"author": {"name": "Lenau, Nikolaus", "birth": "N.A.", "death": "N.A."}, "title": "In der W\u00fcste .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1832", "urn": "urn:nbn:de:kobv:b4-200905193572", "language": ["de:0.99"], "booktitle": "Lenau, Nikolaus: Gedichte. Stuttgart, 1832."}, "poem": {"stanza.1": {"line.1": {"text": "Ist's nicht eitel und vergebens,", "tokens": ["Ist's", "nicht", "ei\u00b7tel", "und", "ver\u00b7ge\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADJD", "KON", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lieben Freunde, saget an!", "tokens": ["Lie\u00b7ben", "Freun\u00b7de", ",", "sa\u00b7get", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch den W\u00fcstensand des Lebens", "tokens": ["Durch", "den", "W\u00fcs\u00b7ten\u00b7sand", "des", "Le\u00b7bens"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich zu w\u00fchlen eine Bahn?", "tokens": ["Sich", "zu", "w\u00fch\u00b7len", "ei\u00b7ne", "Bahn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Streut auch unser Fu\u00df im Staube", "tokens": ["Streut", "auch", "un\u00b7ser", "Fu\u00df", "im", "Stau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spuren aus von seinem Lauf,", "tokens": ["Spu\u00b7ren", "aus", "von", "sei\u00b7nem", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleich, wie Geier nach dem Raube,", "tokens": ["Gleich", ",", "wie", "Gei\u00b7er", "nach", "dem", "Rau\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kommt ein Sturm und fri\u00dft sie auf.", "tokens": ["Kommt", "ein", "Sturm", "und", "fri\u00dft", "sie", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Einsam und in Karavanen", "tokens": ["Ein\u00b7sam", "und", "in", "Ka\u00b7ra\u00b7va\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Treibt es nach dem Land der Ruh',", "tokens": ["Treibt", "es", "nach", "dem", "Land", "der", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es flattern tausend Fahnen", "tokens": ["Und", "es", "flat\u00b7tern", "tau\u00b7send", "Fah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVINF", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hier und dort der Ferne zu.", "tokens": ["Hier", "und", "dort", "der", "Fer\u00b7ne", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wir auch wandern vielverb\u00fcndet", "tokens": ["Wir", "auch", "wan\u00b7dern", "viel\u00b7ver\u00b7b\u00fcn\u00b7det"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach der R\u00e4thselferne aus;", "tokens": ["Nach", "der", "R\u00e4th\u00b7sel\u00b7fer\u00b7ne", "aus", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch der Strahl der W\u00fcste z\u00fcndet", "tokens": ["Doch", "der", "Strahl", "der", "W\u00fcs\u00b7te", "z\u00fcn\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sehnsucht nach dem k\u00fchlen Haus;", "tokens": ["Sehn\u00b7sucht", "nach", "dem", "k\u00fch\u00b7len", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Z\u00fcndet hei\u00dfer stets das Sehnen", "tokens": ["Z\u00fcn\u00b7det", "hei\u00b7\u00dfer", "stets", "das", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJA", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In die Gruft aus diesem Land,", "tokens": ["In", "die", "Gruft", "aus", "die\u00b7sem", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo, nie satt, nach unsern Thr\u00e4nen", "tokens": ["Wo", ",", "nie", "satt", ",", "nach", "un\u00b7sern", "Thr\u00e4\u00b7nen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "$,", "ADV", "ADJD", "$,", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lechzt empor der d\u00fcrre Sand.", "tokens": ["Lechzt", "em\u00b7por", "der", "d\u00fcr\u00b7re", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}