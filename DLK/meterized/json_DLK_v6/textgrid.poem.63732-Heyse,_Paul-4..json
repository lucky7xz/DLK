{"textgrid.poem.63732": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "4.", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ratet, von wem ich komme, Don Pavolo! \u2013 Von der Gevattrin?", "tokens": ["Ra\u00b7tet", ",", "von", "wem", "ich", "kom\u00b7me", ",", "Don", "Pa\u00b7vo\u00b7lo", "!", "\u2013", "Von", "der", "Ge\u00b7vat\u00b7trin", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "PWS", "PPER", "VVFIN", "$,", "NE", "NE", "$.", "$(", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-+--+-", "measure": "iambic.septa.invert"}, "line.2": {"text": "Falsch! \u2013 Von der Schneiderin? \u2013 Falsch! \u2013 Dann von der Messe gewi\u00df!", "tokens": ["Falsch", "!", "\u2013", "Von", "der", "Schnei\u00b7de\u00b7rin", "?", "\u2013", "Falsch", "!", "\u2013", "Dann", "von", "der", "Mes\u00b7se", "ge\u00b7wi\u00df", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "$(", "APPR", "ART", "NN", "$.", "$(", "ADJD", "$.", "$(", "ADV", "APPR", "ART", "NN", "ADV", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nein, Ihr wollt's nicht raten! \u2013 Bei San Francesco, Luisa,", "tokens": ["Nein", ",", "Ihr", "wollt's", "nicht", "ra\u00b7ten", "!", "\u2013", "Bei", "San", "Fran\u00b7ce\u00b7sco", ",", "Lu\u00b7i\u00b7sa", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$.", "$(", "APPR", "NE", "NE", "$,", "NE", "$,"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Gern; wer aber err\u00e4t M\u00e4dchengedanken und -tun? \u2013", "tokens": ["Gern", ";", "wer", "a\u00b7ber", "er\u00b7r\u00e4t", "M\u00e4d\u00b7chen\u00b7ge\u00b7dan\u00b7ken", "und", "?", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "PWS", "ADV", "ADJD", "NN", "KON", "NE", "$.", "$("], "meter": "+-+---+--+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Bei Mariuccia war ich. \u2013 Bei der! \u2013 Nun tut mir der Herr doch,", "tokens": ["Bei", "Ma\u00b7riuc\u00b7cia", "war", "ich", ".", "\u2013", "Bei", "der", "!", "\u2013", "Nun", "tut", "mir", "der", "Herr", "doch", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "$.", "$(", "APPR", "ART", "$.", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "--+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Gar, als w\u00e4re das nichts. \u2013 Wenig, Luisa, f\u00fcr mich. \u2013", "tokens": ["Gar", ",", "als", "w\u00e4\u00b7re", "das", "nichts", ".", "\u2013", "We\u00b7nig", ",", "Lu\u00b7i\u00b7sa", ",", "f\u00fcr", "mich", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "KOKOM", "VAFIN", "ART", "PIS", "$.", "$(", "ADV", "$,", "NE", "$,", "APPR", "PPER", "$.", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.7": {"text": "Habt nur Geduld; gleich kommt es an Euch. Ich macht' ein Gesch\u00e4ft mir", "tokens": ["Habt", "nur", "Ge\u00b7duld", ";", "gleich", "kommt", "es", "an", "Euch", ".", "Ich", "macht'", "ein", "Ge\u00b7sch\u00e4ft", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "$.", "ADV", "VVFIN", "PPER", "APPR", "PPER", "$.", "PPER", "VVFIN", "ART", "NN", "PPER"], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.8": {"text": "Heut am Morgen und tat Seidengespinst in den Korb,", "tokens": ["Heut", "am", "Mor\u00b7gen", "und", "tat", "Sei\u00b7den\u00b7ge\u00b7spinst", "in", "den", "Korb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Da\u00df sie ein Band mir webe; sie hat im Haus die Ger\u00e4te.", "tokens": ["Da\u00df", "sie", "ein", "Band", "mir", "we\u00b7be", ";", "sie", "hat", "im", "Haus", "die", "Ge\u00b7r\u00e4\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Und ich fand sie, allein Mutter und Schwester mit ihr,", "tokens": ["Und", "ich", "fand", "sie", ",", "al\u00b7lein", "Mut\u00b7ter", "und", "Schwes\u00b7ter", "mit", "ihr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "ADV", "NN", "KON", "NN", "APPR", "PPER", "$,"], "meter": "--+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Richtet' es aus und hoffte von Euch ein W\u00f6rtchen zu plaudern,", "tokens": ["Rich\u00b7tet'", "es", "aus", "und", "hoff\u00b7te", "von", "Euch", "ein", "W\u00f6rt\u00b7chen", "zu", "plau\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "APPR", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Aber die anderen zwei horchten; ich h\u00fctete mich.", "tokens": ["A\u00b7ber", "die", "an\u00b7de\u00b7ren", "zwei", "horch\u00b7ten", ";", "ich", "h\u00fc\u00b7te\u00b7te", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "CARD", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "+--+---+--+--+", "measure": "dactylic.di.plus"}, "line.13": {"text": "Und so war ein St\u00fcndchen vertan. Da ging ich, und mit mir", "tokens": ["Und", "so", "war", "ein", "St\u00fcnd\u00b7chen", "ver\u00b7tan", ".", "Da", "ging", "ich", ",", "und", "mit", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "VVPP", "$.", "ADV", "VVFIN", "PPER", "$,", "KON", "APPR", "PPER"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.14": {"text": "Ging Mariuccia. Wie gern h\u00e4tte sie nun mich befragt!", "tokens": ["Ging", "Ma\u00b7riuc\u00b7cia", ".", "Wie", "gern", "h\u00e4t\u00b7te", "sie", "nun", "mich", "be\u00b7fragt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$.", "PWAV", "ADV", "VAFIN", "PPER", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.15": {"text": "Also stehen wir unter der T\u00fcr. Ich sage: Commare,", "tokens": ["Al\u00b7so", "ste\u00b7hen", "wir", "un\u00b7ter", "der", "T\u00fcr", ".", "Ich", "sa\u00b7ge", ":", "Com\u00b7ma\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "$.", "NN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.16": {"text": "Sag' ich, besuchst du mich nie? \u2013 Aber sie sch\u00fcttelt den Kopf.", "tokens": ["Sag'", "ich", ",", "be\u00b7suchst", "du", "mich", "nie", "?", "\u2013", "A\u00b7ber", "sie", "sch\u00fct\u00b7telt", "den", "Kopf", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "VVFIN", "PPER", "PRF", "ADV", "$.", "$(", "KON", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}, "line.17": {"text": "Nein, denn ich darf nicht, sagt sie; du wei\u00dft, nicht liebt es die Mutter,", "tokens": ["Nein", ",", "denn", "ich", "darf", "nicht", ",", "sagt", "sie", ";", "du", "wei\u00dft", ",", "nicht", "liebt", "es", "die", "Mut\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "PPER", "VMFIN", "PTKNEG", "$,", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "$,", "PTKNEG", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "---+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Weil ihr ein Wirtshaus habt. \u2013 N\u00e4rrchen, es stehet ja leer;", "tokens": ["Weil", "ihr", "ein", "Wirts\u00b7haus", "habt", ".", "\u2013", "N\u00e4rr\u00b7chen", ",", "es", "ste\u00b7het", "ja", "leer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$.", "$(", "NN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Noch ist keiner gekommen zum Seebad. \u2013 Aber es wohnt doch", "tokens": ["Noch", "ist", "kei\u00b7ner", "ge\u00b7kom\u00b7men", "zum", "See\u00b7bad", ".", "\u2013", "A\u00b7ber", "es", "wohnt", "doch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "VVPP", "APPRART", "NN", "$.", "$(", "KON", "PPER", "VVFIN", "ADV"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.20": {"text": "Einer bei euch. \u2013 Nun der, sag' ich, \u2013 wie findest du den? \u2013", "tokens": ["Ei\u00b7ner", "bei", "euch", ".", "\u2013", "Nun", "der", ",", "sag'", "ich", ",", "\u2013", "wie", "fin\u00b7dest", "du", "den", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "APPR", "PPER", "$.", "$(", "ADV", "ART", "$,", "VVFIN", "PPER", "$,", "$(", "PWAV", "VVFIN", "PPER", "ART", "$.", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.21": {"text": "Ei, nicht \u00fcbel. \u2013 Verstelle dich nur, Spitzb\u00fcbin! du hast ihn", "tokens": ["Ei", ",", "nicht", "\u00fc\u00b7bel", ".", "\u2013", "Ver\u00b7stel\u00b7le", "dich", "nur", ",", "Spitz\u00b7b\u00fc\u00b7bin", "!", "du", "hast", "ihn"], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PTKNEG", "ADJD", "$.", "$(", "NN", "PPER", "ADV", "$,", "NE", "$.", "PPER", "VAFIN", "PPER"], "meter": "+-+--+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.22": {"text": "Gern, und du wei\u00dft, er dich! sag' ich. Da lacht sie und schweigt.", "tokens": ["Gern", ",", "und", "du", "wei\u00dft", ",", "er", "dich", "!", "sag'", "ich", ".", "Da", "lacht", "sie", "und", "schweigt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KON", "PPER", "VVFIN", "$,", "PPER", "PRF", "$.", "VVFIN", "PPER", "$.", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Aber auf einmal fa\u00dft sie mich um und k\u00fc\u00dft mich, ich denke", "tokens": ["A\u00b7ber", "auf", "ein\u00b7mal", "fa\u00dft", "sie", "mich", "um", "und", "k\u00fc\u00dft", "mich", ",", "ich", "den\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ADV", "VVFIN", "PPER", "PRF", "APPR", "KON", "VVFIN", "PPER", "$,", "PPER", "VVFIN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.24": {"text": "Gleich, sie erstickt mich, und dann l\u00e4uft sie wie Wetter davon.", "tokens": ["Gleich", ",", "sie", "er\u00b7stickt", "mich", ",", "und", "dann", "l\u00e4uft", "sie", "wie", "Wet\u00b7ter", "da\u00b7von", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPER", "$,", "KON", "ADV", "VVFIN", "PPER", "KOKOM", "NN", "PTKVZ", "$."], "meter": "+--+---+--+--+", "measure": "dactylic.di.plus"}, "line.25": {"text": "Und ich ruf' es ihr nach: ", "tokens": ["Und", "ich", "ruf'", "es", "ihr", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.26": {"text": "Aber du wei\u00dft wohl, ", "tokens": ["A\u00b7ber", "du", "wei\u00dft", "wohl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.27": {"text": "Tu's Luisa! und weg, ins Zimmer hinein. Die Arme!", "tokens": ["Tu's", "Lu\u00b7i\u00b7sa", "!", "und", "weg", ",", "ins", "Zim\u00b7mer", "hin\u00b7ein", ".", "Die", "Ar\u00b7me", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "KON", "PTKVZ", "$,", "APPRART", "NN", "PTKVZ", "$.", "ART", "NN", "$."], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.28": {"text": "Denk' ich, sie h\u00e4tt' es allein freilich am liebsten bestellt.", "tokens": ["Denk'", "ich", ",", "sie", "h\u00e4tt'", "es", "al\u00b7lein", "frei\u00b7lich", "am", "liebs\u00b7ten", "be\u00b7stellt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Aber so stehet es jetzt, Herr, und da hab' ich den Ku\u00df.", "tokens": ["A\u00b7ber", "so", "ste\u00b7het", "es", "jetzt", ",", "Herr", ",", "und", "da", "hab'", "ich", "den", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$,", "NN", "$,", "KON", "ADV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.30": {"text": "Seht, Don Pavolo, dies tut die Luisa f\u00fcr Euch:", "tokens": ["Seht", ",", "Don", "Pa\u00b7vo\u00b7lo", ",", "dies", "tut", "die", "Lu\u00b7i\u00b7sa", "f\u00fcr", "Euch", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "NE", "$,", "PDS", "VVFIN", "ART", "NE", "APPR", "PPER", "$."], "meter": "-+--+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Anderen t\u00e4t' sie's nimmer; doch Ihr, Ihr wisset, was Scherz ist,", "tokens": ["An\u00b7de\u00b7ren", "t\u00e4t'", "sie's", "nim\u00b7mer", ";", "doch", "Ihr", ",", "Ihr", "wis\u00b7set", ",", "was", "Scherz", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "VVFIN", "PPER", "ADV", "$.", "KON", "PPER", "$,", "PPER", "VVFIN", "$,", "PWS", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.32": {"text": "Und dies alles, es sind Possen. Nun aber im Ernst:", "tokens": ["Und", "dies", "al\u00b7les", ",", "es", "sind", "Pos\u00b7sen", ".", "Nun", "a\u00b7ber", "im", "Ernst", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PIS", "$,", "PPER", "VAFIN", "NN", "$.", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "--+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.33": {"text": "Geb' ich den Ku\u00df nicht wieder f\u00fcr Euch? Und h\u00e4ttet Ihr keinen", "tokens": ["Geb'", "ich", "den", "Ku\u00df", "nicht", "wie\u00b7der", "f\u00fcr", "Euch", "?", "Und", "h\u00e4t\u00b7tet", "Ihr", "kei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "PTKNEG", "ADV", "APPR", "PPER", "$.", "KON", "VAFIN", "PPER", "PIAT"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.34": {"text": "Mir zu bestellen? Es w\u00e4r' jetzo in einem getan. \u2013", "tokens": ["Mir", "zu", "be\u00b7stel\u00b7len", "?", "Es", "w\u00e4r'", "jet\u00b7zo", "in", "ei\u00b7nem", "ge\u00b7tan", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ADV", "APPR", "ART", "VVPP", "$.", "$("], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.35": {"text": "Liebe Luisa, ich tat ein Gel\u00fcbd, nie K\u00fcsse zu geben;", "tokens": ["Lie\u00b7be", "Lu\u00b7i\u00b7sa", ",", "ich", "tat", "ein", "Ge\u00b7l\u00fcbd", ",", "nie", "K\u00fcs\u00b7se", "zu", "ge\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "ADV", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.36": {"text": "K\u00fcsse zu ", "tokens": ["K\u00fcs\u00b7se", "zu"], "token_info": ["word", "word"], "pos": ["NN", "PTKZU"], "meter": "+-+", "measure": "trochaic.di"}}}}}