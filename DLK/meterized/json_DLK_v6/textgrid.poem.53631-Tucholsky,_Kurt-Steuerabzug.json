{"textgrid.poem.53631": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Steuerabzug", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Dame, die im kleinen H\u00e4uschen", "tokens": ["Die", "Da\u00b7me", ",", "die", "im", "klei\u00b7nen", "H\u00e4usc\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "dort residiert am L\u00fctzowplatz,", "tokens": ["dort", "re\u00b7si\u00b7diert", "am", "L\u00fct\u00b7zow\u00b7platz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "den M\u00e4nnern dient, den kleinen M\u00e4uschen", "tokens": ["den", "M\u00e4n\u00b7nern", "dient", ",", "den", "klei\u00b7nen", "M\u00e4u\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "(in Klasse I und II), die hats", "tokens": ["(", "in", "Klas\u00b7se", "I", "und", "I\u00b7i", ")", ",", "die", "hats"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "APPR", "NN", "CARD", "KON", "CARD", "$(", "$,", "PRELS", "VAFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "von nun an schwer in ihrem Leben:", "tokens": ["von", "nun", "an", "schwer", "in", "ih\u00b7rem", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie mu\u00df dem Staat an Steuern geben", "tokens": ["Sie", "mu\u00df", "dem", "Staat", "an", "Steu\u00b7ern", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "von ihrem Geld am Monatsend", "tokens": ["von", "ih\u00b7rem", "Geld", "am", "Mo\u00b7nat\u00b7send"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "10% \u2013! 10% \u2013!", "tokens": ["%", "\u2013", "!", "10", "%", "\u2013", "!"], "token_info": ["punct", "punct", "punct", "number", "punct", "punct", "punct"], "pos": ["$(", "$(", "$.", "CARD", "$(", "$(", "$."]}}, "stanza.2": {"line.1": {"text": "Die Jungfrau liegt in ihrem Bettchen.", "tokens": ["Die", "Jung\u00b7frau", "liegt", "in", "ih\u00b7rem", "Bett\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht weit davon der Kavalier.", "tokens": ["Nicht", "weit", "da\u00b7von", "der", "Ka\u00b7va\u00b7lier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie ist ein emsig-braves M\u00e4ttchen", "tokens": ["Sie", "ist", "ein", "em\u00b7sig\u00b7bra\u00b7ves", "M\u00e4tt\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "(sie denkt: Wie du mir, so ich dir . . . )", "tokens": ["(", "sie", "denkt", ":", "Wie", "du", "mir", ",", "so", "ich", "dir", ".", ".", ".", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$.", "PWAV", "PPER", "PPER", "$,", "ADV", "PPER", "PPER", "$.", "$.", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er blecht. Sie seufzt. Sie mu\u00df es lassen.", "tokens": ["Er", "blecht", ".", "Sie", "seufzt", ".", "Sie", "mu\u00df", "es", "las\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Auch sie zahlt in die Steuerkassen", "tokens": ["Auch", "sie", "zahlt", "in", "die", "Steu\u00b7er\u00b7kas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "von dem, was man das Strumpfgeld nennt,", "tokens": ["von", "dem", ",", "was", "man", "das", "Strumpf\u00b7geld", "nennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "10% \u2013! 10% \u2013!", "tokens": ["%", "\u2013", "!", "10", "%", "\u2013", "!"], "token_info": ["punct", "punct", "punct", "number", "punct", "punct", "punct"], "pos": ["$(", "$(", "$.", "CARD", "$(", "$(", "$."]}}, "stanza.3": {"line.1": {"text": "Herr Weismann setzt in seine Presse", "tokens": ["Herr", "Weis\u00b7mann", "setzt", "in", "sei\u00b7ne", "Pres\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "den b\u00f6sen Bolschewistenspuk.", "tokens": ["den", "b\u00f6\u00b7sen", "Bol\u00b7sche\u00b7wis\u00b7tens\u00b7puk", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aufrei\u00dft der Redakteur die Fresse.", "tokens": ["Auf\u00b7rei\u00dft", "der", "Re\u00b7dak\u00b7teur", "die", "Fres\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Herrn Weismann ists noch nicht genug.", "tokens": ["Herrn", "Weis\u00b7mann", "ists", "noch", "nicht", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00dft euch nur nicht die Ruhe rauben!", "tokens": ["La\u00dft", "euch", "nur", "nicht", "die", "Ru\u00b7he", "rau\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist das auch wahr? Mu\u00df man das glauben,", "tokens": ["Ist", "das", "auch", "wahr", "?", "Mu\u00df", "man", "das", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "PTKVZ", "$.", "VMFIN", "PIS", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "was uns erz\u00e4hlt ein Spitzelgent?", "tokens": ["was", "uns", "er\u00b7z\u00e4hlt", "ein", "Spit\u00b7zel\u00b7gent", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "10% \u2013! 10% \u2013!", "tokens": ["%", "\u2013", "!", "10", "%", "\u2013", "!"], "token_info": ["punct", "punct", "punct", "number", "punct", "punct", "punct"], "pos": ["$(", "$(", "$.", "CARD", "$(", "$(", "$."]}}, "stanza.4": {"line.1": {"text": "Der Fiskus l\u00fcpft die Steuerlarve.", "tokens": ["Der", "Fis\u00b7kus", "l\u00fcpft", "die", "Steu\u00b7er\u00b7lar\u00b7ve", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dem Dichter zieht man auch was ab?", "tokens": ["Dem", "Dich\u00b7ter", "zieht", "man", "auch", "was", "ab", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich fall vor Schreck in meine Harfe.", "tokens": ["Ich", "fall", "vor", "Schreck", "in", "mei\u00b7ne", "Har\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist der Stein zu meinem Grab!", "tokens": ["Das", "ist", "der", "Stein", "zu", "mei\u00b7nem", "Grab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Sorgen nagen t\u00e4glich schlimmer.", "tokens": ["Die", "Sor\u00b7gen", "na\u00b7gen", "t\u00e4g\u00b7lich", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Verdient denn unsereiner immer", "tokens": ["Ver\u00b7di\u00b7ent", "denn", "un\u00b7ser\u00b7ei\u00b7ner", "im\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "PPOSAT", "ADV"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "als Obermusenpr\u00e4sident", "tokens": ["als", "O\u00b7ber\u00b7mu\u00b7sen\u00b7pr\u00e4\u00b7si\u00b7dent"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "10% \u2013? 10%?", "tokens": ["%", "\u2013", "?", "10", "%", "?"], "token_info": ["punct", "punct", "punct", "number", "punct", "punct"], "pos": ["$(", "$(", "$.", "CARD", "$(", "$."]}}}}}