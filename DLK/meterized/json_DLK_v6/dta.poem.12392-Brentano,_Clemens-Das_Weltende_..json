{"dta.poem.12392": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Das Weltende .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ob ich gleich kein Schatz nicht hab,               ", "tokens": ["Ob", "ich", "gleich", "kein", "Schatz", "nicht", "hab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "PTKNEG", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Will ich schon ein finden,", "tokens": ["Will", "ich", "schon", "ein", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Geh ichs G\u00e4\u00dflein auf und ab,", "tokens": ["Geh", "ichs", "G\u00e4\u00df\u00b7lein", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zur gro\u00dfen Linden.", "tokens": ["Bis", "zur", "gro\u00b7\u00dfen", "Lin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Als ich zu der Linden kam,", "tokens": ["Als", "ich", "zu", "der", "Lin\u00b7den", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NE", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sa\u00df mein Schatz daneben:", "tokens": ["Sa\u00df", "mein", "Schatz", "da\u00b7ne\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PAV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u201egr\u00fc\u00df dich Gott, herzlieber Schatz!", "tokens": ["\u201e", "gr\u00fc\u00df", "dich", "Gott", ",", "herz\u00b7lie\u00b7ber", "Schatz", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201ewo bist du gewesen?\u201c", "tokens": ["\u201e", "wo", "bist", "du", "ge\u00b7we\u00b7sen", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPER", "VAPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "\u201eschatz, wo ich gewesen bin,", "tokens": ["\u201e", "schatz", ",", "wo", "ich", "ge\u00b7we\u00b7sen", "bin", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PWAV", "PPER", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201edarf ich dir wohl sagen,", "tokens": ["\u201e", "darf", "ich", "dir", "wohl", "sa\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u201ewar in fremde Lande hin,", "tokens": ["\u201e", "war", "in", "frem\u00b7de", "Lan\u00b7de", "hin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201ehab gar viel erfahren.", "tokens": ["\u201e", "hab", "gar", "viel", "er\u00b7fah\u00b7ren", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "\u201esah am Ende von der Welt,", "tokens": ["\u201e", "sah", "am", "En\u00b7de", "von", "der", "Welt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ewie die Bretter pa\u00dften,", "tokens": ["\u201e", "wie", "die", "Bret\u00b7ter", "pa\u00df\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u201enoch die alten Monden hell", "tokens": ["\u201e", "noch", "die", "al\u00b7ten", "Mon\u00b7den", "hell"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "ADJA", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201eall in einem Kasten.", "tokens": ["\u201e", "all", "in", "ei\u00b7nem", "Kas\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "\u201esahn wie schlechte Fischtuch aus,", "tokens": ["\u201e", "sahn", "wie", "schlech\u00b7te", "Fischtuch", "aus", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "KOKOM", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u201esonne kam gegangen,", "tokens": ["\u201e", "son\u00b7ne", "kam", "ge\u00b7gan\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u201etipte nur ein wenig drauf,", "tokens": ["\u201e", "tip\u00b7te", "nur", "ein", "we\u00b7nig", "drauf", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201ebrannt mich wie mit Zangen.", "tokens": ["\u201e", "brannt", "mich", "wie", "mit", "Zan\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "KOKOM", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "\u201eh\u00e4tt ich einen Schritt gethan,", "tokens": ["\u201e", "h\u00e4tt", "ich", "ei\u00b7nen", "Schritt", "ge\u00b7than", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eh\u00e4tt ich nichts mehr funden,", "tokens": ["\u201e", "h\u00e4tt", "ich", "nichts", "mehr", "fun\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u201esage nun mein Liebchen an", "tokens": ["\u201e", "sa\u00b7ge", "nun", "mein", "Lieb\u00b7chen", "an"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "ADV", "PPOSAT", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201ewie du dich befunden.\u201c", "tokens": ["\u201e", "wie", "du", "dich", "be\u00b7fun\u00b7den", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "PRF", "VVPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "\u201eich befand mich in dem Thal,", "tokens": ["\u201e", "ich", "be\u00b7fand", "mich", "in", "dem", "Thal", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201esa\u00dfen da zwey Hasen,", "tokens": ["\u201e", "sa\u00b7\u00dfen", "da", "zwey", "Ha\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u201efra\u00dfen ab das gr\u00fcne Gras", "tokens": ["\u201e", "fra\u00b7\u00dfen", "ab", "das", "gr\u00fc\u00b7ne", "Gras"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201ebis zum d\u00fcrren Rasen.", "tokens": ["\u201e", "bis", "zum", "d\u00fcr\u00b7ren", "Ra\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "\u201ein der kalten Wintersnacht,", "tokens": ["\u201e", "in", "der", "kal\u00b7ten", "Win\u00b7ter\u00b7snacht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201elie\u00dfest du mich sitzen,", "tokens": ["\u201e", "lie\u00b7\u00dfest", "du", "mich", "sit\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u201eey mein schwarzbraun Aeugelein,", "tokens": ["\u201e", "ey", "mein", "schwarz\u00b7braun", "A\u00b7e\u00b7u\u00b7ge\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "\u201emust du Wasser schwitzen.", "tokens": ["\u201e", "must", "du", "Was\u00b7ser", "schwit\u00b7zen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "\u201edarum reis' in Sommernacht,", "tokens": ["\u201e", "da\u00b7rum", "reis'", "in", "Som\u00b7mer\u00b7nacht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201enur zu aller Welt Ende,", "tokens": ["\u201e", "nur", "zu", "al\u00b7ler", "Welt", "En\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "\u201ewer sich gar zu lustig macht,", "tokens": ["\u201e", "wer", "sich", "gar", "zu", "lus\u00b7tig", "macht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PRF", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201enimmt ein schlechtes Ende.\u201c", "tokens": ["\u201e", "nimmt", "ein", "schlech\u00b7tes", "En\u00b7de", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}