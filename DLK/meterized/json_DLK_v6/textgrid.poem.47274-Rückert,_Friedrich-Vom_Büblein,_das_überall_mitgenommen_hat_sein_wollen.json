{"textgrid.poem.47274": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Vom B\u00fcblein, das \u00fcberall mitgenommen hat sein wollen", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Denk' an! das B\u00fcblein ist einmal", "tokens": ["Denk'", "an", "!", "das", "B\u00fcb\u00b7lein", "ist", "ein\u00b7mal"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spazieren gangen im Wiesenthal;", "tokens": ["Spa\u00b7zie\u00b7ren", "gan\u00b7gen", "im", "Wie\u00b7sent\u00b7hal", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da wurd's m\u00fcd' gar sehr", "tokens": ["Da", "wurd's", "m\u00fcd'", "gar", "sehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADJD", "ADV", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Und sagt': \u00bbIch kann nicht mehr;", "tokens": ["Und", "sagt'", ":", "\u00bb", "Ich", "kann", "nicht", "mehr", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VMFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn nur was k\u00e4me", "tokens": ["Wenn", "nur", "was", "k\u00e4\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PWS", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und mich mitn\u00e4hme!\u00ab", "tokens": ["Und", "mich", "mit\u00b7n\u00e4h\u00b7me", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Da ist das B\u00e4chlein geflossen kommen", "tokens": ["Da", "ist", "das", "B\u00e4ch\u00b7lein", "ge\u00b7flos\u00b7sen", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und hat's B\u00fcblein mitgenommen;", "tokens": ["Und", "hat's", "B\u00fcb\u00b7lein", "mit\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Das B\u00fcblein hat sich aufs B\u00e4chlein gesetzt", "tokens": ["Das", "B\u00fcb\u00b7lein", "hat", "sich", "aufs", "B\u00e4ch\u00b7lein", "ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PRF", "APPRART", "NN", "VVPP"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und hat gesagt: \u00bbSo gef\u00e4llt mir's jetzt.\u00ab", "tokens": ["Und", "hat", "ge\u00b7sagt", ":", "\u00bb", "So", "ge\u00b7f\u00e4llt", "mir's", "jetzt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$.", "$(", "ADV", "VVFIN", "NE", "ADV", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Aber was meinst du? das B\u00e4chlein war kalt,", "tokens": ["A\u00b7ber", "was", "meinst", "du", "?", "das", "B\u00e4ch\u00b7lein", "war", "kalt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$.", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Das hat das B\u00fcblein gesp\u00fcrt gar bald;", "tokens": ["Das", "hat", "das", "B\u00fcb\u00b7lein", "ge\u00b7sp\u00fcrt", "gar", "bald", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVPP", "ADV", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es hat's gefroren gar sehr,", "tokens": ["Es", "hat's", "ge\u00b7fro\u00b7ren", "gar", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ADV", "ADV", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Es sagt': \u00bbIch kann nicht mehr;", "tokens": ["Es", "sagt'", ":", "\u00bb", "Ich", "kann", "nicht", "mehr", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VMFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn nur was k\u00e4me", "tokens": ["Wenn", "nur", "was", "k\u00e4\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PWS", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und mich mitn\u00e4hme!\u00ab", "tokens": ["Und", "mich", "mit\u00b7n\u00e4h\u00b7me", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Da ist das Schifflein geschwommen kommen", "tokens": ["Da", "ist", "das", "Schif\u00b7flein", "ge\u00b7schwom\u00b7men", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und hat's B\u00fcblein mitgenommen;", "tokens": ["Und", "hat's", "B\u00fcb\u00b7lein", "mit\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Das B\u00fcblein hat sich aufs Schifflein gesetzt", "tokens": ["Das", "B\u00fcb\u00b7lein", "hat", "sich", "aufs", "Schif\u00b7flein", "ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PRF", "APPRART", "NN", "VVPP"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und hat gesagt: \u00bbDa gef\u00e4llt mir's jetzt.\u00ab", "tokens": ["Und", "hat", "ge\u00b7sagt", ":", "\u00bb", "Da", "ge\u00b7f\u00e4llt", "mir's", "jetzt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$.", "$(", "ADV", "VVFIN", "NE", "ADV", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Aber siehst du? das Schifflein war schmal,", "tokens": ["A\u00b7ber", "siehst", "du", "?", "das", "Schif\u00b7flein", "war", "schmal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Das B\u00fcblein denkt: \u00bbDa fall' ich einmal\u00ab;", "tokens": ["Das", "B\u00fcb\u00b7lein", "denkt", ":", "\u00bb", "Da", "fall'", "ich", "ein\u00b7mal", "\u00ab", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "$(", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Da f\u00fcrcht' es sich gar sehr", "tokens": ["Da", "f\u00fcrcht'", "es", "sich", "gar", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und sagt': \u00bbIch mag nicht mehr;", "tokens": ["Und", "sagt'", ":", "\u00bb", "Ich", "mag", "nicht", "mehr", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VMFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn nur was k\u00e4me", "tokens": ["Wenn", "nur", "was", "k\u00e4\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PWS", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und mich mitn\u00e4hme!\u00ab", "tokens": ["Und", "mich", "mit\u00b7n\u00e4h\u00b7me", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Da ist die Schnecke gekrochen gekommen", "tokens": ["Da", "ist", "die", "Schne\u00b7cke", "ge\u00b7kro\u00b7chen", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "VVPP"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und hat's B\u00fcblein mitgenommen;", "tokens": ["Und", "hat's", "B\u00fcb\u00b7lein", "mit\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Das B\u00fcblein hat sich ins Schneckenh\u00e4uslein gesetzt", "tokens": ["Das", "B\u00fcb\u00b7lein", "hat", "sich", "ins", "Schne\u00b7cken\u00b7h\u00e4us\u00b7lein", "ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PRF", "APPRART", "NN", "VVPP"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Und hat gesagt: \u00bbDa gef\u00e4llt mir's jetzt.\u00ab", "tokens": ["Und", "hat", "ge\u00b7sagt", ":", "\u00bb", "Da", "ge\u00b7f\u00e4llt", "mir's", "jetzt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$.", "$(", "ADV", "VVFIN", "NE", "ADV", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Aber denk'! die Schnecke war kein Gaul,", "tokens": ["A\u00b7ber", "denk'", "!", "die", "Schne\u00b7cke", "war", "kein", "Gaul", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sie war im Kriechen gar zu faul;", "tokens": ["Sie", "war", "im", "Krie\u00b7chen", "gar", "zu", "faul", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem B\u00fcblein ging's langsam zu sehr;", "tokens": ["Dem", "B\u00fcb\u00b7lein", "ging's", "lang\u00b7sam", "zu", "sehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Es sagt': \u00bbIch mag nicht mehr;", "tokens": ["Es", "sagt'", ":", "\u00bb", "Ich", "mag", "nicht", "mehr", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VMFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn nur was k\u00e4me", "tokens": ["Wenn", "nur", "was", "k\u00e4\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PWS", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und mich mitn\u00e4hme!\u00ab", "tokens": ["Und", "mich", "mit\u00b7n\u00e4h\u00b7me", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Da ist der Reuter geritten gekommen,", "tokens": ["Da", "ist", "der", "Reu\u00b7ter", "ge\u00b7rit\u00b7ten", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NE", "VVPP", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Der hat's B\u00fcblein mitgenommen;", "tokens": ["Der", "hat's", "B\u00fcb\u00b7lein", "mit\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Das B\u00fcblein hat sich hinten aufs Pferd gesetzt", "tokens": ["Das", "B\u00fcb\u00b7lein", "hat", "sich", "hin\u00b7ten", "aufs", "Pferd", "ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "APPRART", "NN", "VVPP"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Und hat gesagt: \u00bbSo gef\u00e4llt mir's jetzt.\u00ab", "tokens": ["Und", "hat", "ge\u00b7sagt", ":", "\u00bb", "So", "ge\u00b7f\u00e4llt", "mir's", "jetzt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$.", "$(", "ADV", "VVFIN", "NE", "ADV", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Aber gib acht! das ging wie der Wind,", "tokens": ["A\u00b7ber", "gib", "acht", "!", "das", "ging", "wie", "der", "Wind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "CARD", "$.", "PDS", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Es ging dem B\u00fcblein gar zu geschwind;", "tokens": ["Es", "ging", "dem", "B\u00fcb\u00b7lein", "gar", "zu", "ge\u00b7schwind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Es hopst drauf hin und her", "tokens": ["Es", "hopst", "drauf", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und schreit: \u00bbIch kann nicht mehr;", "tokens": ["Und", "schreit", ":", "\u00bb", "Ich", "kann", "nicht", "mehr", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VMFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn nur was k\u00e4me", "tokens": ["Wenn", "nur", "was", "k\u00e4\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PWS", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und mich mitn\u00e4hme!\u00ab", "tokens": ["Und", "mich", "mit\u00b7n\u00e4h\u00b7me", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Da ist ein Baum ihm ins Haar gekommen", "tokens": ["Da", "ist", "ein", "Baum", "ihm", "ins", "Haar", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "APPRART", "NN", "VVPP"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und hat das B\u00fcblein mitgenomnen;", "tokens": ["Und", "hat", "das", "B\u00fcb\u00b7lein", "mit\u00b7ge\u00b7nom\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Er hat's geh\u00e4ngt an einen Ast gar hoch,", "tokens": ["Er", "hat's", "ge\u00b7h\u00e4ngt", "an", "ei\u00b7nen", "Ast", "gar", "hoch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Dort h\u00e4ngt das B\u00fcblein und zappelt noch.", "tokens": ["Dort", "h\u00e4ngt", "das", "B\u00fcb\u00b7lein", "und", "zap\u00b7pelt", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}