{"textgrid.poem.66550": {"metadata": {"author": {"name": "Roquette, Otto", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich wei\u00df noch wohl die liebe Zeit,", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich wei\u00df noch wohl die liebe Zeit,", "tokens": ["Ich", "wei\u00df", "noch", "wohl", "die", "lie\u00b7be", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da mich zuerst dein Anblick r\u00fchrte", "tokens": ["Da", "mich", "zu\u00b7erst", "dein", "An\u00b7blick", "r\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und, alle Freuden im Geleit,", "tokens": ["Und", ",", "al\u00b7le", "Freu\u00b7den", "im", "Ge\u00b7leit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Gl\u00fcck auf meinen Pfad dich f\u00fchrte!", "tokens": ["Das", "Gl\u00fcck", "auf", "mei\u00b7nen", "Pfad", "dich", "f\u00fchr\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich wei\u00df die Zeit auch, da ich bang", "tokens": ["Ich", "wei\u00df", "die", "Zeit", "auch", ",", "da", "ich", "bang"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein \u00fcberfluthend Herz bezwungen,", "tokens": ["Mein", "\u00fc\u00b7berf\u00b7lut\u00b7hend", "Herz", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVPP", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vom Aufgang bis zum Niedergang", "tokens": ["Vom", "Auf\u00b7gang", "bis", "zum", "Nie\u00b7der\u00b7gang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Tage Qualen durchgerungen.", "tokens": ["Der", "Ta\u00b7ge", "Qua\u00b7len", "durch\u00b7ge\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Vergang'nes fordr' ich nicht zur\u00fcck,", "tokens": ["Ver\u00b7gang'\u00b7nes", "fordr'", "ich", "nicht", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch halt ich f\u00fcr das l\u00e4ngst entf\u00fchrte", "tokens": ["Doch", "halt", "ich", "f\u00fcr", "das", "l\u00e4ngst", "ent\u00b7f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Fest die Erinn'rung an das Gl\u00fcck,", "tokens": ["Fest", "die", "Er\u00b7inn'\u00b7rung", "an", "das", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Da mich zuerst dein Anblick r\u00fchrte!", "tokens": ["Da", "mich", "zu\u00b7erst", "dein", "An\u00b7blick", "r\u00fchr\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}