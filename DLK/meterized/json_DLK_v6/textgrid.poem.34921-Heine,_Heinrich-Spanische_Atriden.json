{"textgrid.poem.34921": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Spanische Atriden", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Am Hubertustag des Jahres", "tokens": ["Am", "Hu\u00b7ber\u00b7tus\u00b7tag", "des", "Jah\u00b7res"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dreizehnhundertdreiundachtzig", "tokens": ["Drei\u00b7zehn\u00b7hun\u00b7dert\u00b7drei\u00b7un\u00b7dacht\u00b7zig"], "token_info": ["word"], "pos": ["CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gab der K\u00f6nig uns ein Gastmahl", "tokens": ["Gab", "der", "K\u00f6\u00b7nig", "uns", "ein", "Gast\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu Segovia im Schlosse.", "tokens": ["Zu", "Se\u00b7go\u00b7via", "im", "Schlos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Hofgastm\u00e4hler sind dieselben", "tokens": ["Hof\u00b7ga\u00b7stm\u00e4h\u00b7ler", "sind", "die\u00b7sel\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["NN", "VAFIN", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00dcberall, es g\u00e4hnt dieselbe", "tokens": ["\u00dc\u00b7be\u00b7rall", ",", "es", "g\u00e4hnt", "die\u00b7sel\u00b7be"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Souver\u00e4ne Langeweile", "tokens": ["Sou\u00b7ve\u00b7r\u00e4\u00b7ne", "Lan\u00b7ge\u00b7wei\u00b7le"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An der Tafel aller F\u00fcrsten.", "tokens": ["An", "der", "Ta\u00b7fel", "al\u00b7ler", "F\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Prunkgeschirr von Gold und Silber,", "tokens": ["Prunk\u00b7ge\u00b7schirr", "von", "Gold", "und", "Sil\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leckerbissen aller Zonen,", "tokens": ["Le\u00b7cker\u00b7bis\u00b7sen", "al\u00b7ler", "Zo\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und derselbe Bleigeschmack,", "tokens": ["Und", "der\u00b7sel\u00b7be", "Blei\u00b7ge\u00b7schmack", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Mahnend an Lokustes K\u00fcche.", "tokens": ["Mah\u00b7nend", "an", "Lo\u00b7kus\u00b7tes", "K\u00fc\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Auch derselbe seidne P\u00f6bel,", "tokens": ["Auch", "der\u00b7sel\u00b7be", "seid\u00b7ne", "P\u00f6\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Buntgeputzt und vornehm nickend,", "tokens": ["Bunt\u00b7ge\u00b7putzt", "und", "vor\u00b7nehm", "ni\u00b7ckend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Beet von Tulipanen;", "tokens": ["Wie", "ein", "Beet", "von", "Tu\u00b7li\u00b7pa\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur die Saucen sind verschieden.", "tokens": ["Nur", "die", "Sau\u00b7cen", "sind", "ver\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und das ist ein Wispern, Sumsen,", "tokens": ["Und", "das", "ist", "ein", "Wis\u00b7pern", ",", "Sum\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ART", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das wie Mohn den Sinn einschl\u00e4fert,", "tokens": ["Das", "wie", "Mohn", "den", "Sinn", "ein\u00b7schl\u00e4\u00b7fert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KOKOM", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bis Trompetenst\u00f6\u00dfe wecken", "tokens": ["Bis", "Trom\u00b7pe\u00b7ten\u00b7st\u00f6\u00b7\u00dfe", "we\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus der kauenden Bet\u00e4ubnis.", "tokens": ["Aus", "der", "kau\u00b7en\u00b7den", "Be\u00b7t\u00e4ub\u00b7nis", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Neben mir, zum Gl\u00fccke, sa\u00df", "tokens": ["Ne\u00b7ben", "mir", ",", "zum", "Gl\u00fc\u00b7cke", ",", "sa\u00df"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "PPER", "$,", "APPRART", "NN", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Don Diego Albuquerque,", "tokens": ["Don", "Die\u00b7go", "Al\u00b7bu\u00b7quer\u00b7que", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem die Rede unterhaltsam", "tokens": ["Dem", "die", "Re\u00b7de", "un\u00b7ter\u00b7halt\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von den klugen Lippen flo\u00df.", "tokens": ["Von", "den", "klu\u00b7gen", "Lip\u00b7pen", "flo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ganz vorz\u00fcglich gut erz\u00e4hlte", "tokens": ["Ganz", "vor\u00b7z\u00fcg\u00b7lich", "gut", "er\u00b7z\u00e4hl\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er die blut'gen Hofgeschichten", "tokens": ["Er", "die", "blut'\u00b7gen", "Hof\u00b7ge\u00b7schich\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus den Tagen des Don Pedro,", "tokens": ["Aus", "den", "Ta\u00b7gen", "des", "Don", "Ped\u00b7ro", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Den man \u00bbK\u00f6nig Grausam\u00ab nannte.", "tokens": ["Den", "man", "\u00bb", "K\u00f6\u00b7nig", "Grau\u00b7sam", "\u00ab", "nann\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIS", "$(", "NN", "NE", "$(", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Als ich frug, warum Don Pedro", "tokens": ["Als", "ich", "frug", ",", "wa\u00b7rum", "Don", "Ped\u00b7ro"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "NE", "NE"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Seinen Bruder Don Fredrego", "tokens": ["Sei\u00b7nen", "Bru\u00b7der", "Don", "Fred\u00b7re\u00b7go"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NE", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Insgeheim enthaupten lie\u00df,", "tokens": ["Ins\u00b7ge\u00b7heim", "ent\u00b7haup\u00b7ten", "lie\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sprach mein Tischgenosse seufzend:", "tokens": ["Sprach", "mein", "Tischge\u00b7nos\u00b7se", "seuf\u00b7zend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "\u00bbse\u00f1or! glaubt nicht, was sie klimpern", "tokens": ["\u00bb", "se\u00f1or", "!", "glaubt", "nicht", ",", "was", "sie", "klim\u00b7pern"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PTKVZ", "$.", "VVFIN", "PTKNEG", "$,", "PRELS", "PPER", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf den schlottrigen Gitarren,", "tokens": ["Auf", "den", "schlott\u00b7ri\u00b7gen", "Gi\u00b7tar\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "B\u00e4nkels\u00e4nger, Maultiertreiber,", "tokens": ["B\u00e4n\u00b7kel\u00b7s\u00e4n\u00b7ger", ",", "Maul\u00b7tier\u00b7trei\u00b7ber", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In Posaden, Kneipen, Schenken.", "tokens": ["In", "Po\u00b7sa\u00b7den", ",", "Knei\u00b7pen", ",", "Schen\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Glaubet nimmer, was sie faseln", "tokens": ["Glau\u00b7bet", "nim\u00b7mer", ",", "was", "sie", "fa\u00b7seln"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "PRELS", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der Liebe Don Fredregos", "tokens": ["Von", "der", "Lie\u00b7be", "Don", "Fred\u00b7re\u00b7gos"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und Don Pedros sch\u00f6ner Gattin,", "tokens": ["Und", "Don", "Ped\u00b7ros", "sch\u00f6\u00b7ner", "Gat\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "ADJA", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Do\u00f1a Blanka von Bourbon.", "tokens": ["Do\u00f1a", "Blan\u00b7ka", "von", "Bour\u00b7bon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Nicht der Eifersucht des Gatten,", "tokens": ["Nicht", "der", "Ei\u00b7fer\u00b7sucht", "des", "Gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur der Mi\u00dfgunst eines Neidharts", "tokens": ["Nur", "der", "Mi\u00df\u00b7gunst", "ei\u00b7nes", "Neid\u00b7harts"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fiel als Opfer Don Fredrego,", "tokens": ["Fiel", "als", "Op\u00b7fer", "Don", "Fred\u00b7re\u00b7go", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "NN", "NE", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Calatravas Ordensmeister.", "tokens": ["Ca\u00b7la\u00b7tra\u00b7vas", "Or\u00b7dens\u00b7meis\u00b7ter", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Das Verbrechen, das Don Pedro", "tokens": ["Das", "Ver\u00b7bre\u00b7chen", ",", "das", "Don", "Ped\u00b7ro"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Nicht verzieh, das war sein Ruhm,", "tokens": ["Nicht", "ver\u00b7zieh", ",", "das", "war", "sein", "Ruhm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener Ruhm, den Do\u00f1a Fama", "tokens": ["Je\u00b7ner", "Ruhm", ",", "den", "Do\u00f1a", "Fa\u00b7ma"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "NN", "$,", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit Entz\u00fccken ausposaunte.", "tokens": ["Mit", "Ent\u00b7z\u00fc\u00b7cken", "aus\u00b7po\u00b7saun\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Auch verzieh ihm nicht Don Pedro", "tokens": ["Auch", "ver\u00b7zieh", "ihm", "nicht", "Don", "Ped\u00b7ro"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "NE", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Seiner Seele Hochgef\u00fchle", "tokens": ["Sei\u00b7ner", "See\u00b7le", "Hoch\u00b7ge\u00b7f\u00fch\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Wohlgestalt des Leibes,", "tokens": ["Und", "die", "Wohl\u00b7ge\u00b7stalt", "des", "Lei\u00b7bes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die ein Abbild solcher Seele.", "tokens": ["Die", "ein", "Ab\u00b7bild", "sol\u00b7cher", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Bl\u00fchend blieb mir im Ged\u00e4chtnis", "tokens": ["Bl\u00fc\u00b7hend", "blieb", "mir", "im", "Ge\u00b7d\u00e4cht\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese schlanke Heldenblume;", "tokens": ["Die\u00b7se", "schlan\u00b7ke", "Hel\u00b7den\u00b7blu\u00b7me", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nie verge\u00df ich dieses sch\u00f6ne", "tokens": ["Nie", "ver\u00b7ge\u00df", "ich", "die\u00b7ses", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00e4umerische J\u00fcnglingsantlitz.", "tokens": ["Tr\u00e4u\u00b7me\u00b7ri\u00b7sche", "J\u00fcng\u00b7lings\u00b7ant\u00b7litz", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Das war eben jene Sorte,", "tokens": ["Das", "war", "e\u00b7ben", "je\u00b7ne", "Sor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die geliebt wird von den Feen,", "tokens": ["Die", "ge\u00b7liebt", "wird", "von", "den", "Feen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein m\u00e4rchenhaft Geheimnis", "tokens": ["Und", "ein", "m\u00e4r\u00b7chen\u00b7haft", "Ge\u00b7heim\u00b7nis"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sprach aus allen diesen Z\u00fcgen.", "tokens": ["Sprach", "aus", "al\u00b7len", "die\u00b7sen", "Z\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Blaue Augen, deren Schmelz", "tokens": ["Blau\u00b7e", "Au\u00b7gen", ",", "de\u00b7ren", "Schmelz"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Blendend wie ein Edelstein \u2013", "tokens": ["Blen\u00b7dend", "wie", "ein", "E\u00b7del\u00b7stein", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOKOM", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber auch der stieren H\u00e4rte", "tokens": ["A\u00b7ber", "auch", "der", "stie\u00b7ren", "H\u00e4r\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eines Edelsteins teilhaftig.", "tokens": ["Ei\u00b7nes", "E\u00b7del\u00b7steins", "teil\u00b7haf\u00b7tig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Seine Haare waren schwarz,", "tokens": ["Sei\u00b7ne", "Haa\u00b7re", "wa\u00b7ren", "schwarz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bl\u00e4ulichschwarz, von seltnem Glanze,", "tokens": ["Bl\u00e4u\u00b7lich\u00b7schwarz", ",", "von", "selt\u00b7nem", "Glan\u00b7ze", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und in \u00fcppig sch\u00f6nen Locken", "tokens": ["Und", "in", "\u00fcp\u00b7pig", "sch\u00f6\u00b7nen", "Lo\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf die Schulter niederfallend.", "tokens": ["Auf", "die", "Schul\u00b7ter", "nie\u00b7der\u00b7fal\u00b7lend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "In der sch\u00f6nen Stadt Coimbra,", "tokens": ["In", "der", "sch\u00f6\u00b7nen", "Stadt", "Coim\u00b7bra", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die er abgewann den Mohren,", "tokens": ["Die", "er", "ab\u00b7ge\u00b7wann", "den", "Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sah ich ihn zum letzten Male", "tokens": ["Sah", "ich", "ihn", "zum", "letz\u00b7ten", "Ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebend \u2013 ungl\u00fccksel'ger Prinz!", "tokens": ["Le\u00b7bend", "\u2013", "un\u00b7gl\u00fcck\u00b7sel'\u00b7ger", "Prinz", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$(", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Eben kam er vom Alkanzor,", "tokens": ["E\u00b7ben", "kam", "er", "vom", "Al\u00b7kan\u00b7zor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Durch die engen Stra\u00dfen reitend;", "tokens": ["Durch", "die", "en\u00b7gen", "Stra\u00b7\u00dfen", "rei\u00b7tend", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Manche junge Mohrin lauschte", "tokens": ["Man\u00b7che", "jun\u00b7ge", "Moh\u00b7rin", "lauschte"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hinterm Gitter ihres Fensters.", "tokens": ["Hin\u00b7term", "Git\u00b7ter", "ih\u00b7res", "Fens\u00b7ters", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Seines Hauptes Helmbusch wehte", "tokens": ["Sei\u00b7nes", "Haup\u00b7tes", "Helm\u00b7busch", "weh\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frei galant, jedoch des Mantels", "tokens": ["Frei", "ga\u00b7lant", ",", "je\u00b7doch", "des", "Man\u00b7tels"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADJD", "$,", "ADV", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Strenges Calatrava-Kreuz", "tokens": ["Stren\u00b7ges", "Ca\u00b7la\u00b7tra\u00b7va\u00b7Kreuz"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Scheuchte jeden Buhlgedanken.", "tokens": ["Scheuch\u00b7te", "je\u00b7den", "Buhl\u00b7ge\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Ihm zur Seite, freudewedelnd,", "tokens": ["Ihm", "zur", "Sei\u00b7te", ",", "freu\u00b7de\u00b7we\u00b7delnd", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprang sein Liebling, Allan hie\u00df er,", "tokens": ["Sprang", "sein", "Lieb\u00b7ling", ",", "Al\u00b7lan", "hie\u00df", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Bestie solzer Rasse,", "tokens": ["Ei\u00b7ne", "Be\u00b7stie", "sol\u00b7zer", "Ras\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Deren Heimat die Sierra.", "tokens": ["De\u00b7ren", "Hei\u00b7mat", "die", "Sier\u00b7ra", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.22": {"line.1": {"text": "Trotz der ungeheuern Gr\u00f6\u00dfe", "tokens": ["Trotz", "der", "un\u00b7ge\u00b7heu\u00b7ern", "Gr\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War er wie ein Reh gelenkig,", "tokens": ["War", "er", "wie", "ein", "Reh", "ge\u00b7len\u00b7kig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "ART", "NN", "ADJD", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Nobel war des Kopfes Bildung,", "tokens": ["No\u00b7bel", "war", "des", "Kop\u00b7fes", "Bil\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ob sie gleich dem Fuchse \u00e4hnlich.", "tokens": ["Ob", "sie", "gleich", "dem", "Fuch\u00b7se", "\u00e4hn\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Schneewei\u00df und so weich wie Seide", "tokens": ["Schnee\u00b7wei\u00df", "und", "so", "weich", "wie", "Sei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ADV", "ADJD", "KOKOM", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Flockten lang herab die Haare;", "tokens": ["Flock\u00b7ten", "lang", "her\u00b7ab", "die", "Haa\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit Rubinen inkrustieret", "tokens": ["Mit", "Ru\u00b7bi\u00b7nen", "in\u00b7krus\u00b7tie\u00b7ret"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "War das breite goldne Halshand.", "tokens": ["War", "das", "brei\u00b7te", "gold\u00b7ne", "Hals\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Dieses Halshand, sagt man, barg", "tokens": ["Die\u00b7ses", "Hals\u00b7hand", ",", "sagt", "man", ",", "barg"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PDAT", "NN", "$,", "VVFIN", "PIS", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen Talisman der Treue;", "tokens": ["Ei\u00b7nen", "Ta\u00b7lis\u00b7man", "der", "Treu\u00b7e", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Niemals wich er von der Seite", "tokens": ["Nie\u00b7mals", "wich", "er", "von", "der", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seines Herrn, der treue Hund.", "tokens": ["Sei\u00b7nes", "Herrn", ",", "der", "treu\u00b7e", "Hund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "O der schauerlichen Treue!", "tokens": ["O", "der", "schau\u00b7er\u00b7li\u00b7chen", "Treu\u00b7e", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir erbebet das Gem\u00fcte,", "tokens": ["Mir", "er\u00b7be\u00b7bet", "das", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Denk ich dran, wie sie sich hier", "tokens": ["Denk", "ich", "dran", ",", "wie", "sie", "sich", "hier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PAV", "$,", "PWAV", "PPER", "PRF", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Offenbart vor unsern Augen.", "tokens": ["Of\u00b7fen\u00b7bart", "vor", "un\u00b7sern", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "O des schreckenvollen Tages!", "tokens": ["O", "des", "schre\u00b7cken\u00b7vol\u00b7len", "Ta\u00b7ges", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hier in diesem Saale war es,", "tokens": ["Hier", "in", "die\u00b7sem", "Saa\u00b7le", "war", "es", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie heute sa\u00df ich hier", "tokens": ["Und", "wie", "heu\u00b7te", "sa\u00df", "ich", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "VVFIN", "PPER", "ADV"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "An der k\u00f6niglichen Tafel.", "tokens": ["An", "der", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Ta\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "An dem obern Tafelende,", "tokens": ["An", "dem", "o\u00b7bern", "Ta\u00b7fe\u00b7len\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Dort, wo heute Don Henrico", "tokens": ["Dort", ",", "wo", "heu\u00b7te", "Don", "Hen\u00b7ri\u00b7co"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "ADV", "NE", "NE"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Fr\u00f6hlich bechert mit der Blume", "tokens": ["Fr\u00f6h\u00b7lich", "be\u00b7chert", "mit", "der", "Blu\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Kastilian'scher Ritterschaft \u2013", "tokens": ["Ka\u00b7sti\u00b7lian'\u00b7scher", "Rit\u00b7ter\u00b7schaft", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Jenes Tags sa\u00df dort Don Pedro", "tokens": ["Je\u00b7nes", "Tags", "sa\u00df", "dort", "Don", "Ped\u00b7ro"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VVFIN", "ADV", "NE", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Finster stumm, und neben ihm,", "tokens": ["Fins\u00b7ter", "stumm", ",", "und", "ne\u00b7ben", "ihm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "KON", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Strahlend stolz wie eine G\u00f6ttin,", "tokens": ["Strah\u00b7lend", "stolz", "wie", "ei\u00b7ne", "G\u00f6t\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sa\u00df Maria de Padilla.", "tokens": ["Sa\u00df", "Ma\u00b7ria", "de", "Pa\u00b7dil\u00b7la", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Hier am untern End' der Tafel,", "tokens": ["Hier", "am", "un\u00b7tern", "End'", "der", "Ta\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo wir heut die Dame sehen,", "tokens": ["Wo", "wir", "heut", "die", "Da\u00b7me", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deren gro\u00dfe Linnenkrause", "tokens": ["De\u00b7ren", "gro\u00b7\u00dfe", "Lin\u00b7nen\u00b7krau\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie ein wei\u00dfer Teller aussieht \u2013", "tokens": ["Wie", "ein", "wei\u00b7\u00dfer", "Tel\u00b7ler", "aus\u00b7sieht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.30": {"line.1": {"text": "W\u00e4hrend ihr vergilbt Gesichtchen", "tokens": ["W\u00e4h\u00b7rend", "ihr", "ver\u00b7gilbt", "Ge\u00b7sicht\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit dem s\u00e4uerlichen L\u00e4cheln", "tokens": ["Mit", "dem", "s\u00e4u\u00b7er\u00b7li\u00b7chen", "L\u00e4\u00b7cheln"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Zitrone gleichet, welche", "tokens": ["Der", "Zit\u00b7ro\u00b7ne", "glei\u00b7chet", ",", "wel\u00b7che"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Auf besagtem Teller ruht:", "tokens": ["Auf", "be\u00b7sag\u00b7tem", "Tel\u00b7ler", "ruht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Hier am untern End' der Tafel", "tokens": ["Hier", "am", "un\u00b7tern", "End'", "der", "Ta\u00b7fel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War ein leerer Platz geblieben;", "tokens": ["War", "ein", "lee\u00b7rer", "Platz", "ge\u00b7blie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eines Gasts von hohem Range", "tokens": ["Ei\u00b7nes", "Gasts", "von", "ho\u00b7hem", "Ran\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schien der goldne Stuhl zu harren.", "tokens": ["Schien", "der", "gold\u00b7ne", "Stuhl", "zu", "har\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Don Fredrego war der Gast,", "tokens": ["Don", "Fred\u00b7re\u00b7go", "war", "der", "Gast", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Dem der goldne Stuhl bestimmt war \u2013", "tokens": ["Dem", "der", "gold\u00b7ne", "Stuhl", "be\u00b7stimmt", "war", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "VVPP", "VAFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch er kam nicht \u2013 ach, wir wissen", "tokens": ["Doch", "er", "kam", "nicht", "\u2013", "ach", ",", "wir", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$(", "XY", "$,", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jetzt den Grund der Z\u00f6gerung.", "tokens": ["Jetzt", "den", "Grund", "der", "Z\u00f6\u00b7ge\u00b7rung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Ach, zur selben Stunde wurde", "tokens": ["Ach", ",", "zur", "sel\u00b7ben", "Stun\u00b7de", "wur\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "APPRART", "ADJA", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie vollbracht, die dunkle Untat,", "tokens": ["Sie", "voll\u00b7bracht", ",", "die", "dunk\u00b7le", "Un\u00b7tat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der arglos junge Held", "tokens": ["Und", "der", "arg\u00b7los", "jun\u00b7ge", "Held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJD", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Wurde von Don Pedros Schergen", "tokens": ["Wur\u00b7de", "von", "Don", "Ped\u00b7ros", "Scher\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "NE", "NE", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.34": {"line.1": {"text": "Hinterlistig \u00fcberfallen", "tokens": ["Hin\u00b7ter\u00b7lis\u00b7tig", "\u00fc\u00b7berf\u00b7al\u00b7len"], "token_info": ["word", "word"], "pos": ["ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gebunden fortgeschleppt", "tokens": ["Und", "ge\u00b7bun\u00b7den", "fort\u00b7ge\u00b7schleppt"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In ein \u00f6des Schlo\u00dfgew\u00f6lbe,", "tokens": ["In", "ein", "\u00f6\u00b7des", "Schlo\u00df\u00b7ge\u00b7w\u00f6l\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur von Fackelschein beleuchtet.", "tokens": ["Nur", "von", "Fa\u00b7ckel\u00b7schein", "be\u00b7leuch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Dorten standen Henkersknechte,", "tokens": ["Dor\u00b7ten", "stan\u00b7den", "Hen\u00b7kers\u00b7knech\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dorten stand der rote Meister,", "tokens": ["Dor\u00b7ten", "stand", "der", "ro\u00b7te", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der, gest\u00fctzt auf seinem Richtbeil,", "tokens": ["Der", ",", "ge\u00b7st\u00fctzt", "auf", "sei\u00b7nem", "Richt\u00b7beil", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit schwerm\u00fct'ger Miene sprach:", "tokens": ["Mit", "schwer\u00b7m\u00fct'\u00b7ger", "Mie\u00b7ne", "sprach", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.36": {"line.1": {"text": "\u203ajetzt, Gro\u00dfmeister von San Jago,", "tokens": ["\u203a", "jetzt", ",", "Gro\u00df\u00b7meis\u00b7ter", "von", "San", "Ja\u00b7go", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "NN", "APPR", "NE", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "M\u00fc\u00dft Ihr Euch zum Tod bereiten,", "tokens": ["M\u00fc\u00dft", "Ihr", "Euch", "zum", "Tod", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Viertelstunde sei", "tokens": ["Ei\u00b7ne", "Vier\u00b7tel\u00b7stun\u00b7de", "sei"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Euch bewilligt zum Gebete.\u2039", "tokens": ["Euch", "be\u00b7wil\u00b7ligt", "zum", "Ge\u00b7be\u00b7te", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Don Fredrego kniete nieder,", "tokens": ["Don", "Fred\u00b7re\u00b7go", "knie\u00b7te", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Betete mit frommer Ruhe,", "tokens": ["Be\u00b7te\u00b7te", "mit", "from\u00b7mer", "Ru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "Sprach sodann: \u203aIch hab vollendet\u2039,", "tokens": ["Sprach", "so\u00b7dann", ":", "\u203a", "Ich", "hab", "voll\u00b7en\u00b7det", "\u2039", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "$.", "$(", "PPER", "VAFIN", "VVPP", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und empfing den Todesstreich.", "tokens": ["Und", "emp\u00b7fing", "den", "To\u00b7des\u00b7streich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "In demselben Augenblicke,", "tokens": ["In", "dem\u00b7sel\u00b7ben", "Au\u00b7gen\u00b7bli\u00b7cke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als der Kopf zu Boden rollte,", "tokens": ["Als", "der", "Kopf", "zu", "Bo\u00b7den", "roll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sprang drauf zu der treue Allan,", "tokens": ["Sprang", "drauf", "zu", "der", "treu\u00b7e", "Al\u00b7lan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Welcher unbemerkt gefolgt war.", "tokens": ["Wel\u00b7cher", "un\u00b7be\u00b7merkt", "ge\u00b7folgt", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Er erfa\u00dfte, mit den Z\u00e4hnen,", "tokens": ["Er", "er\u00b7fa\u00df\u00b7te", ",", "mit", "den", "Z\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bei dem Lockenhaar das Haupt,", "tokens": ["Bei", "dem", "Lo\u00b7cken\u00b7haar", "das", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit dieser teuern Beute", "tokens": ["Und", "mit", "die\u00b7ser", "teu\u00b7ern", "Beu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Scho\u00df er zauberschnell von dannen.", "tokens": ["Scho\u00df", "er", "zau\u00b7ber\u00b7schnell", "von", "dan\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Jammer und Geschrei erscholl", "tokens": ["Jam\u00b7mer", "und", "Ge\u00b7schrei", "er\u00b7scholl"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00dcberall auf seinem Wege,", "tokens": ["\u00dc\u00b7be\u00b7rall", "auf", "sei\u00b7nem", "We\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch die G\u00e4nge und Gem\u00e4cher,", "tokens": ["Durch", "die", "G\u00e4n\u00b7ge", "und", "Ge\u00b7m\u00e4\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Treppen auf und Treppen ab.", "tokens": ["Trep\u00b7pen", "auf", "und", "Trep\u00b7pen", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Seit dem Gastmahl des Belsazar", "tokens": ["Seit", "dem", "Gast\u00b7mahl", "des", "Bel\u00b7sa\u00b7zar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Gab es keine Tischgesellschaft,", "tokens": ["Gab", "es", "kei\u00b7ne", "Tischge\u00b7sell\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Welche so verst\u00f6ret aussah", "tokens": ["Wel\u00b7che", "so", "ver\u00b7st\u00f6\u00b7ret", "aus\u00b7sah"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wie die unsre in dem Saale,", "tokens": ["Wie", "die", "uns\u00b7re", "in", "dem", "Saa\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Als das Unget\u00fcm hereinsprang", "tokens": ["Als", "das", "Un\u00b7ge\u00b7t\u00fcm", "her\u00b7ein\u00b7sprang"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mit dem Haupte Don Fredregos,", "tokens": ["Mit", "dem", "Haup\u00b7te", "Don", "Fred\u00b7re\u00b7gos", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Das er mit den Z\u00e4hnen schleppte", "tokens": ["Das", "er", "mit", "den", "Z\u00e4h\u00b7nen", "schlepp\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An den tr\u00e4ufend blut'gen Haaren.", "tokens": ["An", "den", "tr\u00e4u\u00b7fend", "blut'\u00b7gen", "Haa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Auf den leer gebliebnen Stuhl,", "tokens": ["Auf", "den", "leer", "ge\u00b7blieb\u00b7nen", "Stuhl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Welcher seinem Herrn bestimmt war;", "tokens": ["Wel\u00b7cher", "sei\u00b7nem", "Herrn", "be\u00b7stimmt", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sprang der Hund und, wie ein Kl\u00e4ger,", "tokens": ["Sprang", "der", "Hund", "und", ",", "wie", "ein", "Kl\u00e4\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hielt er uns das Haupt entgegen.", "tokens": ["Hielt", "er", "uns", "das", "Haupt", "ent\u00b7ge\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Ach, es war das wohlbekannte", "tokens": ["Ach", ",", "es", "war", "das", "wohl\u00b7be\u00b7kann\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heldenantlitz, aber bl\u00e4sser,", "tokens": ["Hel\u00b7den\u00b7ant\u00b7litz", ",", "a\u00b7ber", "bl\u00e4s\u00b7ser", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber ernster, durch den Tod,", "tokens": ["A\u00b7ber", "erns\u00b7ter", ",", "durch", "den", "Tod", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und umringelt gar entsetzlich", "tokens": ["Und", "um\u00b7rin\u00b7gelt", "gar", "ent\u00b7setz\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD"], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.45": {"line.1": {"text": "Von der F\u00fclle schwarzer Locken,", "tokens": ["Von", "der", "F\u00fcl\u00b7le", "schwar\u00b7zer", "Lo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die sich b\u00e4umten wie der wilde", "tokens": ["Die", "sich", "b\u00e4um\u00b7ten", "wie", "der", "wil\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "VVFIN", "KOKOM", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlangenkopfputz der Meduse,", "tokens": ["Schlan\u00b7gen\u00b7kopf\u00b7putz", "der", "Me\u00b7du\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Auch wie dieser schreckversteinernd.", "tokens": ["Auch", "wie", "die\u00b7ser", "schreck\u00b7ver\u00b7stei\u00b7nernd", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PDS", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Ja, wir waren wie versteinert,", "tokens": ["Ja", ",", "wir", "wa\u00b7ren", "wie", "ver\u00b7stei\u00b7nert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "KOKOM", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sahn uns an mit starrer Miene,", "tokens": ["Sahn", "uns", "an", "mit", "star\u00b7rer", "Mie\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und gel\u00e4hmt war jede Zunge", "tokens": ["Und", "ge\u00b7l\u00e4hmt", "war", "je\u00b7de", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVPP", "VAFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von der Angst und Etikette.", "tokens": ["Von", "der", "Angst", "und", "E\u00b7ti\u00b7ket\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Nur Maria de Padilla", "tokens": ["Nur", "Ma\u00b7ria", "de", "Pa\u00b7dil\u00b7la"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NE", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Brach das allgemeine Schweigen;", "tokens": ["Brach", "das", "all\u00b7ge\u00b7mei\u00b7ne", "Schwei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00e4nderingend, laut aufschluchzend,", "tokens": ["H\u00e4n\u00b7de\u00b7rin\u00b7gend", ",", "laut", "auf\u00b7schluch\u00b7zend", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jammerte sie ahndungsvoll:", "tokens": ["Jam\u00b7mer\u00b7te", "sie", "ahn\u00b7dungs\u00b7voll", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "\u203ahei\u00dfen wird es jetzt, ich h\u00e4tte", "tokens": ["\u203a", "hei\u00b7\u00dfen", "wird", "es", "jetzt", ",", "ich", "h\u00e4t\u00b7te"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVINF", "VAFIN", "PPER", "ADV", "$,", "PPER", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Angestiftet solche Mordtat,", "tokens": ["An\u00b7ge\u00b7stif\u00b7tet", "sol\u00b7che", "Mord\u00b7tat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Groll trifft meine Kinder,", "tokens": ["Und", "der", "Groll", "trifft", "mei\u00b7ne", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine schuldlos armen Kinder!\u2039\u00ab", "tokens": ["Mei\u00b7ne", "schuld\u00b7los", "ar\u00b7men", "Kin\u00b7der", "!", "\u2039", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "ADJD", "ADJA", "NN", "$.", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Don Diego unterbrach hier", "tokens": ["Don", "Die\u00b7go", "un\u00b7ter\u00b7brach", "hier"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ADV"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Seine Rede, denn wir sahen,", "tokens": ["Sei\u00b7ne", "Re\u00b7de", ",", "denn", "wir", "sa\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df die Tafel aufgehoben", "tokens": ["Da\u00df", "die", "Ta\u00b7fel", "auf\u00b7ge\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Hof den Saal verlassen.", "tokens": ["Und", "der", "Hof", "den", "Saal", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "H\u00f6fisch fein von Sitten, gab", "tokens": ["H\u00f6\u00b7fisch", "fein", "von", "Sit\u00b7ten", ",", "gab"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "ADJD", "APPR", "NN", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir der Ritter das Geleite,", "tokens": ["Mir", "der", "Rit\u00b7ter", "das", "Ge\u00b7lei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wir wandelten selbander", "tokens": ["Und", "wir", "wan\u00b7del\u00b7ten", "sel\u00b7ban\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch das alte Gotenschlo\u00df.", "tokens": ["Durch", "das", "al\u00b7te", "Go\u00b7ten\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "In dem Kreuzgang, welcher leitet", "tokens": ["In", "dem", "Kreuz\u00b7gang", ",", "wel\u00b7cher", "lei\u00b7tet"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach des K\u00f6nigs Hundest\u00e4llen,", "tokens": ["Nach", "des", "K\u00f6\u00b7nigs", "Hun\u00b7des\u00b7t\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die durch Knurren und Gekl\u00e4ffe", "tokens": ["Die", "durch", "Knur\u00b7ren", "und", "Ge\u00b7kl\u00e4f\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schon von fernher sich verk\u00fcnd'gen,", "tokens": ["Schon", "von", "fern\u00b7her", "sich", "ver\u00b7k\u00fcn\u00b7d'\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "PRF", "VVPP", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}}, "stanza.52": {"line.1": {"text": "Dorten sah ich, in der Wand", "tokens": ["Dor\u00b7ten", "sah", "ich", ",", "in", "der", "Wand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eingemauert und nach au\u00dfen", "tokens": ["Ein\u00b7ge\u00b7mau\u00b7ert", "und", "nach", "au\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "APPR", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fest mit Eisenwerk vergattert,", "tokens": ["Fest", "mit", "Ei\u00b7sen\u00b7werk", "ver\u00b7gat\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Zelle wie ein K\u00e4fig.", "tokens": ["Ei\u00b7ne", "Zel\u00b7le", "wie", "ein", "K\u00e4\u00b7fig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Menschliche Gestalten zwo", "tokens": ["Menschli\u00b7che", "Ge\u00b7stal\u00b7ten", "zwo"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "CARD"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Sa\u00dfen drin, zwei junge Knaben;", "tokens": ["Sa\u00b7\u00dfen", "drin", ",", "zwei", "jun\u00b7ge", "Kna\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "CARD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Angefesselt bei den Beinen,", "tokens": ["An\u00b7ge\u00b7fes\u00b7selt", "bei", "den", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hockten sie auf fauler Streu.", "tokens": ["Hock\u00b7ten", "sie", "auf", "fau\u00b7ler", "Streu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Kaum zw\u00f6lfj\u00e4hrig schien der eine,", "tokens": ["Kaum", "zw\u00f6lf\u00b7j\u00e4h\u00b7rig", "schien", "der", "ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenig \u00e4lter war der andre;", "tokens": ["We\u00b7nig", "\u00e4l\u00b7ter", "war", "der", "and\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Gesichter sch\u00f6n und edel,", "tokens": ["Die", "Ge\u00b7sich\u00b7ter", "sch\u00f6n", "und", "e\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber fahl und welk von Siechtum.", "tokens": ["A\u00b7ber", "fahl", "und", "welk", "von", "Siech\u00b7tum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADJD", "APPR", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Waren ganz zerlumpt, fast nackend,", "tokens": ["Wa\u00b7ren", "ganz", "zer\u00b7lumpt", ",", "fast", "na\u00b7ckend", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die magern Leibchen trugen", "tokens": ["Und", "die", "ma\u00b7gern", "Leib\u00b7chen", "tru\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wunde Spuren der Mi\u00dfhandlung;", "tokens": ["Wun\u00b7de", "Spu\u00b7ren", "der", "Mi\u00df\u00b7hand\u00b7lung", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Beide sch\u00fcttelte das Fieber.", "tokens": ["Bei\u00b7de", "sch\u00fct\u00b7tel\u00b7te", "das", "Fie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Aus der Tiefe ihres Elends", "tokens": ["Aus", "der", "Tie\u00b7fe", "ih\u00b7res", "E\u00b7lends"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schauten sie zu mir empor,", "tokens": ["Schau\u00b7ten", "sie", "zu", "mir", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie mit wei\u00dfen Geisteraugen,", "tokens": ["Wie", "mit", "wei\u00b7\u00dfen", "Geis\u00b7ter\u00b7au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ich schier darob erschrocken.", "tokens": ["Da\u00df", "ich", "schier", "da\u00b7rob", "er\u00b7schro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PAV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "\u00bbwer sind diese Jammerbilder?\u00ab", "tokens": ["\u00bb", "wer", "sind", "die\u00b7se", "Jam\u00b7mer\u00b7bil\u00b7der", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VAFIN", "PDAT", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rief ich aus, indem ich hastig", "tokens": ["Rief", "ich", "aus", ",", "in\u00b7dem", "ich", "has\u00b7tig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Don Diegos Hand ergriff,", "tokens": ["Don", "Die\u00b7gos", "Hand", "er\u00b7griff", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "VVFIN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die gezittert, wie ich f\u00fchlte.", "tokens": ["Die", "ge\u00b7zit\u00b7tert", ",", "wie", "ich", "f\u00fchl\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Don Diego schien verlegen,", "tokens": ["Don", "Die\u00b7go", "schien", "ver\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Sah sich um, ob niemand lausche,", "tokens": ["Sah", "sich", "um", ",", "ob", "nie\u00b7mand", "lau\u00b7sche", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKVZ", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seufzte tief und sprach am Ende,", "tokens": ["Seufz\u00b7te", "tief", "und", "sprach", "am", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heitern Weltmannston erk\u00fcnstelnd:", "tokens": ["Hei\u00b7tern", "Welt\u00b7manns\u00b7ton", "er\u00b7k\u00fcns\u00b7telnd", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "\u00bbdieses sind zwei K\u00f6nigskinder,", "tokens": ["\u00bb", "die\u00b7ses", "sind", "zwei", "K\u00f6\u00b7nigs\u00b7kin\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fch verwaiset, K\u00f6nig Pedro", "tokens": ["Fr\u00fch", "ver\u00b7wai\u00b7set", ",", "K\u00f6\u00b7nig", "Ped\u00b7ro"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVFIN", "$,", "NN", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Hie\u00df der Vater, und die Mutter", "tokens": ["Hie\u00df", "der", "Va\u00b7ter", ",", "und", "die", "Mut\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "War Maria de Padilla.", "tokens": ["War", "Ma\u00b7ria", "de", "Pa\u00b7dil\u00b7la", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Nach der gro\u00dfen Schlacht bei Narvas,", "tokens": ["Nach", "der", "gro\u00b7\u00dfen", "Schlacht", "bei", "Nar\u00b7vas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Wo Henrico Transtamare", "tokens": ["Wo", "Hen\u00b7ri\u00b7co", "Trans\u00b7ta\u00b7ma\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NE", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Seinen Bruder, K\u00f6nig Pedro,", "tokens": ["Sei\u00b7nen", "Bru\u00b7der", ",", "K\u00f6\u00b7nig", "Ped\u00b7ro", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Von der gro\u00dfen Last der Krone", "tokens": ["Von", "der", "gro\u00b7\u00dfen", "Last", "der", "Kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Und zugleich von jener gr\u00f6\u00dfern", "tokens": ["Und", "zu\u00b7gleich", "von", "je\u00b7ner", "gr\u00f6\u00b7\u00dfern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PDAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Last, die Leben hei\u00dft, befreite:", "tokens": ["Last", ",", "die", "Le\u00b7ben", "hei\u00dft", ",", "be\u00b7frei\u00b7te", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da traf auch die Bruderskinder", "tokens": ["Da", "traf", "auch", "die", "Bru\u00b7ders\u00b7kin\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Don Henricos Siegergro\u00dfmut.", "tokens": ["Don", "Hen\u00b7ri\u00b7cos", "Sie\u00b7ger\u00b7gro\u00df\u00b7mut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.62": {"line.1": {"text": "Hat sich ihrer angenommen,", "tokens": ["Hat", "sich", "ih\u00b7rer", "an\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "PPOSAT", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie es einem Oheim ziemet,", "tokens": ["Wie", "es", "ei\u00b7nem", "O\u00b7heim", "zie\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und im eignen Schlosse gab er", "tokens": ["Und", "im", "eig\u00b7nen", "Schlos\u00b7se", "gab", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihnen freie Kost und Wohnung.", "tokens": ["Ih\u00b7nen", "frei\u00b7e", "Kost", "und", "Woh\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Enge freilich ist das St\u00fcbchen,", "tokens": ["En\u00b7ge", "frei\u00b7lich", "ist", "das", "St\u00fcb\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das er ihnen angewiesen,", "tokens": ["Das", "er", "ih\u00b7nen", "an\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch im Sommer ist es k\u00fchlig,", "tokens": ["Doch", "im", "Som\u00b7mer", "ist", "es", "k\u00fch\u00b7lig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nicht gar zu kalt im Winter.", "tokens": ["Und", "nicht", "gar", "zu", "kalt", "im", "Win\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PTKA", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Ihre Speis' ist Roggenbrot,", "tokens": ["Ih\u00b7re", "Speis'", "ist", "Rog\u00b7gen\u00b7brot", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das so schmackhaft ist, als h\u00e4tt es", "tokens": ["Das", "so", "schmack\u00b7haft", "ist", ",", "als", "h\u00e4tt", "es"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "ADV", "ADJD", "VAFIN", "$,", "KOKOM", "VAFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "G\u00f6ttin Ceres selbst gebacken", "tokens": ["G\u00f6t\u00b7tin", "Ce\u00b7res", "selbst", "ge\u00b7ba\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr ihr liebes Proserpinchen.", "tokens": ["F\u00fcr", "ihr", "lie\u00b7bes", "Pro\u00b7ser\u00b7pin\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Manchmal schickt er ihnen auch", "tokens": ["Manch\u00b7mal", "schickt", "er", "ih\u00b7nen", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Kumpe mit Garbanzos,", "tokens": ["Ei\u00b7ne", "Kum\u00b7pe", "mit", "Gar\u00b7ban\u00b7zos", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Jungen merken dann,", "tokens": ["Und", "die", "Jun\u00b7gen", "mer\u00b7ken", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df es Sonntag ist in Spanien.", "tokens": ["Da\u00df", "es", "Sonn\u00b7tag", "ist", "in", "Spa\u00b7ni\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.66": {"line.1": {"text": "Doch nicht immer ist es Sonntag,", "tokens": ["Doch", "nicht", "im\u00b7mer", "ist", "es", "Sonn\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und nicht immer gibt's Garbanzos,", "tokens": ["Und", "nicht", "im\u00b7mer", "gibt's", "Gar\u00b7ban\u00b7zos", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Oberkoppelmeister", "tokens": ["Und", "der", "O\u00b7ber\u00b7kop\u00b7pel\u00b7meis\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Regaliert sie mit der Peitsche.", "tokens": ["Re\u00b7ga\u00b7liert", "sie", "mit", "der", "Peit\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.67": {"line.1": {"text": "Denn der Oberkoppelmeister,", "tokens": ["Denn", "der", "O\u00b7ber\u00b7kop\u00b7pel\u00b7meis\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der die St\u00e4lle mit der Meute", "tokens": ["Der", "die", "St\u00e4l\u00b7le", "mit", "der", "Meu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sowie auch den Neffenk\u00e4fig", "tokens": ["So\u00b7wie", "auch", "den", "Nef\u00b7fen\u00b7k\u00e4\u00b7fig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Unter seiner Aufsicht hat,", "tokens": ["Un\u00b7ter", "sei\u00b7ner", "Auf\u00b7sicht", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Ist der ungl\u00fccksel'ge Gatte", "tokens": ["Ist", "der", "un\u00b7gl\u00fcck\u00b7sel'\u00b7ge", "Gat\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jener sauren Zitronella", "tokens": ["Je\u00b7ner", "sau\u00b7ren", "Zit\u00b7ro\u00b7nel\u00b7la"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mit der wei\u00dfen Tellerkrause,", "tokens": ["Mit", "der", "wei\u00b7\u00dfen", "Tel\u00b7ler\u00b7krau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die wir heut bei Tisch bewundert,", "tokens": ["Die", "wir", "heut", "bei", "Tisch", "be\u00b7wun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "Und sie keift so frech, da\u00df oft", "tokens": ["Und", "sie", "keift", "so", "frech", ",", "da\u00df", "oft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihr Gemahl zur Peitsche greift \u2013", "tokens": ["Ihr", "Ge\u00b7mahl", "zur", "Peit\u00b7sche", "greift", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und hierher eilt und die Hunde", "tokens": ["Und", "hier\u00b7her", "eilt", "und", "die", "Hun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "KON", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und die armen Knaben z\u00fcchtigt.", "tokens": ["Und", "die", "ar\u00b7men", "Kna\u00b7ben", "z\u00fcch\u00b7tigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Doch der K\u00f6nig hat mi\u00dfbilligt", "tokens": ["Doch", "der", "K\u00f6\u00b7nig", "hat", "mi\u00df\u00b7bil\u00b7ligt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Solch Verfahren und befahl,", "tokens": ["Solch", "Ver\u00b7fah\u00b7ren", "und", "be\u00b7fahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df man k\u00fcnftig seine Neffen", "tokens": ["Da\u00df", "man", "k\u00fcnf\u00b7tig", "sei\u00b7ne", "Nef\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht behandle wie die Hunde.", "tokens": ["Nicht", "be\u00b7hand\u00b7le", "wie", "die", "Hun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Keiner fremden Mietlingsfaust", "tokens": ["Kei\u00b7ner", "frem\u00b7den", "Miet\u00b7lings\u00b7faust"], "token_info": ["word", "word", "word"], "pos": ["PIS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird er ferner anvertrauen", "tokens": ["Wird", "er", "fer\u00b7ner", "an\u00b7ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre Zucht, die er hinf\u00fcro", "tokens": ["Ih\u00b7re", "Zucht", ",", "die", "er", "hin\u00b7f\u00fc\u00b7ro"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Eigenh\u00e4ndig leiten will.\u00ab", "tokens": ["Ei\u00b7gen\u00b7h\u00e4n\u00b7dig", "lei\u00b7ten", "will", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVINF", "VMFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "Don Diego stockte pl\u00f6tzlich,", "tokens": ["Don", "Die\u00b7go", "stock\u00b7te", "pl\u00f6tz\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ADJD", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Denn der Seneschall des Schlosses", "tokens": ["Denn", "der", "Se\u00b7ne\u00b7schall", "des", "Schlos\u00b7ses"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kam zu uns und frug uns", "tokens": ["Kam", "zu", "uns", "und", "frug", "uns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "PPER", "KON", "VVFIN", "PPER"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00f6flich: ob wir wohlgespeist? \u2013 \u2013", "tokens": ["H\u00f6f\u00b7lich", ":", "ob", "wir", "wohl\u00b7ge\u00b7speist", "?", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADJD", "$.", "KOUS", "PPER", "VAFIN", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}