{"textgrid.poem.57006": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Anto-Logie", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Anfang lebte, wie bekannt,", "tokens": ["Im", "An\u00b7fang", "leb\u00b7te", ",", "wie", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "als gr\u00f6\u00dfter S\u00e4uger der ", "tokens": ["als", "gr\u00f6\u00df\u00b7ter", "S\u00e4u\u00b7ger", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wobei gig eine Zahl ist, die", "tokens": ["Wo\u00b7bei", "gig", "ei\u00b7ne", "Zahl", "ist", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADJD", "ART", "NN", "VAFIN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "es nicht mehr gibt, \u2013 so gro\u00df war sie!", "tokens": ["es", "nicht", "mehr", "gibt", ",", "\u2013", "so", "gro\u00df", "war", "sie", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "VVFIN", "$,", "$(", "ADV", "ADJD", "VAFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch jene Gr\u00f6\u00dfe schwand wie Rauch.", "tokens": ["Doch", "je\u00b7ne", "Gr\u00f6\u00b7\u00dfe", "schwand", "wie", "Rauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zeit gab's genug \u2013 und Zahlen auch.", "tokens": ["Zeit", "gab's", "ge\u00b7nug", "\u2013", "und", "Zah\u00b7len", "auch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "$(", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Bis eines Tags, ein winzig Ding,", "tokens": ["Bis", "ei\u00b7nes", "Tags", ",", "ein", "win\u00b7zig", "Ding", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der ", "tokens": ["der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.5": {"line.1": {"text": "Wo blieb sein Reich? Wo blieb er selb? \u2013", "tokens": ["Wo", "blieb", "sein", "Reich", "?", "Wo", "blieb", "er", "selb", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "$.", "PWAV", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Bein wird im Museum gelb.", "tokens": ["Sein", "Bein", "wird", "im", "Mu\u00b7se\u00b7um", "gelb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART", "NN", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.6": {"line.1": {"text": "Zwar gab die g\u00fctige Natur", "tokens": ["Zwar", "gab", "die", "g\u00fc\u00b7ti\u00b7ge", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "den ", "tokens": ["den"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.7": {"line.1": {"text": "Doch ach, der Pulverpavian,", "tokens": ["Doch", "ach", ",", "der", "Pul\u00b7ver\u00b7pa\u00b7vi\u00b7an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der Mensch, voll Gier nach seinem Zahn,", "tokens": ["der", "Mensch", ",", "voll", "Gier", "nach", "sei\u00b7nem", "Zahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "erschie\u00dft ihn, statt ihm Zeit zu lassen,", "tokens": ["er\u00b7schie\u00dft", "ihn", ",", "statt", "ihm", "Zeit", "zu", "las\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUI", "PPER", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zum ", "tokens": ["zum"], "token_info": ["word"], "pos": ["APPRART"], "meter": "-", "measure": "single.down"}}, "stanza.9": {"line.1": {"text": "O, \u00bbKlub zum Schutz der wilden Tiere\u00ab,", "tokens": ["O", ",", "\u00bb", "Klub", "zum", "Schutz", "der", "wil\u00b7den", "Tie\u00b7re", "\u00ab", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "$(", "NE", "APPRART", "NN", "ART", "ADJA", "NN", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "hilf, da\u00df der Mensch nicht ruiniere", "tokens": ["hilf", ",", "da\u00df", "der", "Mensch", "nicht", "ru\u00b7i\u00b7nie\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "KOUS", "ART", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "die Sprossen dieser Riesenleiter,", "tokens": ["die", "Spros\u00b7sen", "die\u00b7ser", "Rie\u00b7sen\u00b7lei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die stets noch weiter f\u00fchrt und weiter!", "tokens": ["die", "stets", "noch", "wei\u00b7ter", "f\u00fchrt", "und", "wei\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "VVFIN", "KON", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wie dankbar wird der Ant dir sein,", "tokens": ["Wie", "dank\u00b7bar", "wird", "der", "Ant", "dir", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "l\u00e4\u00dft du ihn wachsen und gedeihn, \u2013", "tokens": ["l\u00e4\u00dft", "du", "ihn", "wach\u00b7sen", "und", "ge\u00b7deihn", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVINF", "KON", "VVINF", "$,", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "bis er dereinst im Nebel hinten", "tokens": ["bis", "er", "de\u00b7reinst", "im", "Ne\u00b7bel", "hin\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als ", "tokens": ["als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "-", "measure": "single.down"}}}}}