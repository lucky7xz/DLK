{"textgrid.poem.53613": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Namens\u00e4nderung", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich darf nun wieder Theo Tiger hei\u00dfen.", "tokens": ["Ich", "darf", "nun", "wie\u00b7der", "Theo", "Ti\u00b7ger", "hei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "NE", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Maske f\u00e4llt: kein n\u00fcrenberger Kind", "tokens": ["Die", "Mas\u00b7ke", "f\u00e4llt", ":", "kein", "n\u00fc\u00b7ren\u00b7ber\u00b7ger", "Kind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "bin ich \u2013 la\u00dft mich in Menschen bei\u00dfen,", "tokens": ["bin", "ich", "\u2013", "la\u00dft", "mich", "in", "Men\u00b7schen", "bei\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$(", "VVIMP", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die gut genug zu meiner F\u00fctterung sind.", "tokens": ["die", "gut", "ge\u00b7nug", "zu", "mei\u00b7ner", "F\u00fct\u00b7te\u00b7rung", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Die Politik hat ihre Fr\u00fchjahrsmoden.", "tokens": ["Die", "Po\u00b7li\u00b7tik", "hat", "ih\u00b7re", "Fr\u00fch\u00b7jahrs\u00b7mo\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zur Zeit tr\u00e4gt man sich demokratisch \u2013 nicht zu knapp.", "tokens": ["Zur", "Zeit", "tr\u00e4gt", "man", "sich", "de\u00b7mo\u00b7kra\u00b7tisch", "\u2013", "nicht", "zu", "knapp", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "PRF", "ADJD", "$(", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-++-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Man steht im Dress auf jenem H\u00e4ngeboden", "tokens": ["Man", "steht", "im", "Dress", "auf", "je\u00b7nem", "H\u00e4n\u00b7ge\u00b7bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der Wirklichkeit und wei\u00df nichts mehr von Kapp.", "tokens": ["der", "Wirk\u00b7lich\u00b7keit", "und", "wei\u00df", "nichts", "mehr", "von", "Kapp", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PIS", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Der Tiger knurrt. Er spuckt die Emballage", "tokens": ["Der", "Ti\u00b7ger", "knurrt", ".", "Er", "spuckt", "die", "Em\u00b7bal\u00b7la\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der Opfer g\u00e4hnend in sein Raubtierhaus.", "tokens": ["der", "Op\u00b7fer", "g\u00e4h\u00b7nend", "in", "sein", "Raub\u00b7tier\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er sieht den Knaben gern in die Visage", "tokens": ["Er", "sieht", "den", "Kna\u00b7ben", "gern", "in", "die", "Vi\u00b7sa\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und zieht sie alle splitternackend aus.", "tokens": ["und", "zieht", "sie", "al\u00b7le", "split\u00b7ter\u00b7na\u00b7ckend", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Nackt will ich sie. So kann ich sie verdauen.", "tokens": ["Nackt", "will", "ich", "sie", ".", "So", "kann", "ich", "sie", "ver\u00b7dau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "$.", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nackt will ich sie. Ich pfeif auf Uniform.", "tokens": ["Nackt", "will", "ich", "sie", ".", "Ich", "pfeif", "auf", "U\u00b7ni\u00b7form", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "$.", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nackt will ich Milit\u00e4rs und Kinofrauen \u2013", "tokens": ["Nackt", "will", "ich", "Mi\u00b7li\u00b7t\u00e4rs", "und", "Ki\u00b7no\u00b7frau\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ich wei\u00df: die T\u00fcnche l\u00fcgt enorm.", "tokens": ["ich", "wei\u00df", ":", "die", "T\u00fcn\u00b7che", "l\u00fcgt", "en\u00b7orm", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sieh den Professor an! Er gibt sich fachlich", "tokens": ["Sieh", "den", "Pro\u00b7fes\u00b7sor", "an", "!", "Er", "gibt", "sich", "fach\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und spricht von Ramses und vom Erbschaftsstreit", "tokens": ["und", "spricht", "von", "Ram\u00b7ses", "und", "vom", "Erb\u00b7schafts\u00b7streit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NE", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und t\u00e4glich infiltriert er, scheinbar sachlich,", "tokens": ["und", "t\u00e4g\u00b7lich", "in\u00b7filt\u00b7riert", "er", ",", "schein\u00b7bar", "sach\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "den jungen Herrn die alte Kaiserzeit.", "tokens": ["den", "jun\u00b7gen", "Herrn", "die", "al\u00b7te", "Kai\u00b7ser\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Sieh die Beamten! Sieh die Landratsbande!", "tokens": ["Sieh", "die", "Be\u00b7am\u00b7ten", "!", "Sieh", "die", "Land\u00b7rats\u00b7ban\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$.", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie tun nur so. Dreht sich einmal das Rad?", "tokens": ["Sie", "tun", "nur", "so", ".", "Dreht", "sich", "ein\u00b7mal", "das", "Rad", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nackt will ich sie. Dann lieg ich still im Sande", "tokens": ["Nackt", "will", "ich", "sie", ".", "Dann", "lieg", "ich", "still", "im", "San\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "$.", "ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und w\u00fcnsche tr\u00e4umend diesem deutschen Lande . . .", "tokens": ["und", "w\u00fcn\u00b7sche", "tr\u00e4u\u00b7mend", "die\u00b7sem", "deut\u00b7schen", "Lan\u00b7de", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PDAT", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Da knirscht die T\u00fcr.", "tokens": ["Da", "knirscht", "die", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ich werde niemals satt.", "tokens": ["Ich", "wer\u00b7de", "nie\u00b7mals", "satt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}