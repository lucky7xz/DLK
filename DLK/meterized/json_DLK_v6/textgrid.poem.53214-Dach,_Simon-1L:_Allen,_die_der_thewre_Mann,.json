{"textgrid.poem.53214": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Allen, die der thewre Mann,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Allen, die der thewre Mann,", "tokens": ["Al\u00b7len", ",", "die", "der", "thew\u00b7re", "Mann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Herr Wolder, hat ausgegeben,", "tokens": ["Herr", "Wol\u00b7der", ",", "hat", "aus\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sprach ich meine Seiten an.", "tokens": ["Sprach", "ich", "mei\u00b7ne", "Sei\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sollt' ich dich nicht auch erheben,", "tokens": ["Sollt'", "ich", "dich", "nicht", "auch", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Du der T\u00f6chter j\u00fcngste, Braut,", "tokens": ["Du", "der", "T\u00f6ch\u00b7ter", "j\u00fcngs\u00b7te", ",", "Braut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADJA", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nun Herr Sam sich dir vertrawt?", "tokens": ["Nun", "Herr", "Sam", "sich", "dir", "ver\u00b7trawt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "NE", "PRF", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Dieses m\u00f6cht ich nicht bey dir", "tokens": ["Die\u00b7ses", "m\u00f6cht", "ich", "nicht", "bey", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "M\u00fcglich zu entschuldign wissen.", "tokens": ["M\u00fcg\u00b7lich", "zu", "ent\u00b7schul\u00b7dign", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was? mein Geigenspiel hat Zier", "tokens": ["Was", "?", "mein", "Gei\u00b7gen\u00b7spiel", "hat", "Zier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "$.", "PPOSAT", "NN", "VAFIN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aller Lieb' ertheilen m\u00fcssen", "tokens": ["Al\u00b7ler", "Lieb'", "er\u00b7thei\u00b7len", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVINF", "VMINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Derer, die durch Preussen-Land", "tokens": ["De\u00b7rer", ",", "die", "durch", "Preus\u00b7sen\u00b7Land"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mir nur etwas sind verwandt.", "tokens": ["Mir", "nur", "et\u00b7was", "sind", "ver\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Weis nicht hierumb Heilgenbeil,", "tokens": ["Weis", "nicht", "hie\u00b7rumb", "Heil\u00b7gen\u00b7beil", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PAV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das mich offt geh\u00f6rt hat geigen?", "tokens": ["Das", "mich", "offt", "ge\u00b7h\u00f6rt", "hat", "gei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "VVPP", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wermd, von grosser Anmuth geil,", "tokens": ["Wermd", ",", "von", "gros\u00b7ser", "An\u00b7muth", "geil", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deckt noch jetzt mit gr\u00fcnen Zweigen,", "tokens": ["Deckt", "noch", "jetzt", "mit", "gr\u00fc\u00b7nen", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was f\u00fcr Lieb' ich damals sangk,", "tokens": ["Was", "f\u00fcr", "Lieb'", "ich", "da\u00b7mals", "sangk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df Geth\u00e4l und Berg erklangk.", "tokens": ["Da\u00df", "Ge\u00b7th\u00e4l", "und", "Berg", "er\u00b7klangk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auch Gedilgen wird gestehn", "tokens": ["Auch", "Ge\u00b7dil\u00b7gen", "wird", "ge\u00b7stehn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "VAFIN", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich nimmer still gewesen,", "tokens": ["Da\u00df", "ich", "nim\u00b7mer", "still", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo ich da nur pflag zu gehn,", "tokens": ["Wo", "ich", "da", "nur", "pflag", "zu", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab' ich etwas mir erlesen", "tokens": ["Hab'", "ich", "et\u00b7was", "mir", "er\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auffzusetzen, das vieleicht", "tokens": ["Auff\u00b7zu\u00b7set\u00b7zen", ",", "das", "vie\u00b7leicht"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "CARD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch wol auff die Nachwelt reicht.", "tokens": ["Auch", "wol", "auff", "die", "Nach\u00b7welt", "reicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ihr Gestr\u00e4uche, Fl\u00fcsse, Stein,", "tokens": ["Ihr", "Ge\u00b7str\u00e4u\u00b7che", ",", "Fl\u00fcs\u00b7se", ",", "Stein", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihr der See gebohrne Fichten,", "tokens": ["Ihr", "der", "See", "ge\u00b7bohr\u00b7ne", "Fich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Thal, Gebirg, ihr gebt mir ein,", "tokens": ["Thal", ",", "Ge\u00b7birg", ",", "ihr", "gebt", "mir", "ein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich w\u00fcrdigs k\u00f6ntte tichten,", "tokens": ["Was", "ich", "w\u00fcr\u00b7digs", "k\u00f6nt\u00b7te", "tich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Himmel, Wiesen, Feld und Wald", "tokens": ["Him\u00b7mel", ",", "Wie\u00b7sen", ",", "Feld", "und", "Wald"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind der Lieder Auffenthalt.", "tokens": ["Sind", "der", "Lie\u00b7der", "Auf\u00b7fent\u00b7halt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Welcher etwas singen wil,", "tokens": ["Wel\u00b7cher", "et\u00b7was", "sin\u00b7gen", "wil", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat darnach nicht weit zu lauffen,", "tokens": ["Hat", "dar\u00b7nach", "nicht", "weit", "zu", "lauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihm h\u00e4lt Lufft und Wolcken still,", "tokens": ["Ihm", "h\u00e4lt", "Lufft", "und", "Wol\u00b7cken", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Vnd giebt Wahren ihm zu kauffen,", "tokens": ["Vnd", "giebt", "Wah\u00b7ren", "ihm", "zu", "kauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die er durch gesinnten Flei\u00df", "tokens": ["Die", "er", "durch", "ge\u00b7sinn\u00b7ten", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Allzeit auszubringen weis.", "tokens": ["All\u00b7zeit", "aus\u00b7zu\u00b7brin\u00b7gen", "weis", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Diesen Vorkauff hat allein", "tokens": ["Die\u00b7sen", "Vor\u00b7kauff", "hat", "al\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Welcher f\u00fchrt den Ruhm der Seiten,", "tokens": ["Wel\u00b7cher", "f\u00fchrt", "den", "Ruhm", "der", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemand dringet mir sich ein,", "tokens": ["Nie\u00b7mand", "drin\u00b7get", "mir", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemand sucht mein Recht zu streiten,", "tokens": ["Nie\u00b7mand", "sucht", "mein", "Recht", "zu", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn ich auff gerechter Bahn", "tokens": ["Denn", "ich", "auff", "ge\u00b7rech\u00b7ter", "Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Keinem Vorfang hie gethan.", "tokens": ["Kei\u00b7nem", "Vor\u00b7fang", "hie", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Geh' ich offt gleich vor das Thor,", "tokens": ["Geh'", "ich", "offt", "gleich", "vor", "das", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Keiner wird mich handeln sehen,", "tokens": ["Kei\u00b7ner", "wird", "mich", "han\u00b7deln", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keinem trett' ich irgends vor,", "tokens": ["Kei\u00b7nem", "trett'", "ich", "ir\u00b7gends", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Keinem Bawren werd' ich flehen,", "tokens": ["Kei\u00b7nem", "Baw\u00b7ren", "werd'", "ich", "fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df sein Korn und was er hat", "tokens": ["Da\u00df", "sein", "Korn", "und", "was", "er", "hat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "PWS", "PPER", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mir nur nachfahr' in die Stadt.", "tokens": ["Mir", "nur", "nach\u00b7fahr'", "in", "die", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.9": {"line.1": {"text": "Vnd wenn ich mit meinem Sinn", "tokens": ["Vnd", "wenn", "ich", "mit", "mei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Erd und Lufft bin durch gefahren,", "tokens": ["Erd", "und", "Lufft", "bin", "durch", "ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "APPR", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd nun gnug versehen bin", "tokens": ["Vnd", "nun", "gnug", "ver\u00b7se\u00b7hen", "bin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVPP", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hie mit Anmuht, da mit Wahren,", "tokens": ["Hie", "mit", "An\u00b7muht", ",", "da", "mit", "Wah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "KOUS", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Klaget nichts, da\u00df meine Hand", "tokens": ["Kla\u00b7get", "nichts", ",", "da\u00df", "mei\u00b7ne", "Hand"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Einem Dinge was entwand.", "tokens": ["Ei\u00b7nem", "Din\u00b7ge", "was", "ent\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Keine Blum' hat sich beschwert", "tokens": ["Kei\u00b7ne", "Blum'", "hat", "sich", "be\u00b7schwert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "PRF", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd kein gr\u00fcnes Laub, da\u00df ihnen", "tokens": ["Vnd", "kein", "gr\u00fc\u00b7nes", "Laub", ",", "da\u00df", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN", "$,", "KOUS", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sey ihr s\u00fcsser Safft verzehrt", "tokens": ["Sey", "ihr", "s\u00fcs\u00b7ser", "Safft", "ver\u00b7zehrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Von dem Honig-Volck, den Bienen", "tokens": ["Von", "dem", "Ho\u00b7nig\u00b7Volck", ",", "den", "Bie\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tragen sie gleich spat und fr\u00fch", "tokens": ["Tra\u00b7gen", "sie", "gleich", "spat", "und", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "VVFIN", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gnugsam erndten Mensch und Vieh.", "tokens": ["Gnug\u00b7sam", "ernd\u00b7ten", "Mensch", "und", "Vieh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Mehr wo bleibet Waltterkeim,", "tokens": ["Mehr", "wo", "blei\u00b7bet", "Walt\u00b7ter\u00b7keim", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PWAV", "VVFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zintten, Ragnit, die imgleichen", "tokens": ["Zint\u00b7ten", ",", "Rag\u00b7nit", ",", "die", "im\u00b7glei\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NE", "$,", "PRELS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Satt empfunden meinen Reim?", "tokens": ["Satt", "emp\u00b7fun\u00b7den", "mei\u00b7nen", "Reim", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kurtz, bey Heyraht und bey Leichen", "tokens": ["Kurtz", ",", "bey", "Hey\u00b7raht", "und", "bey", "Lei\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "NN", "KON", "APPR", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Spricht man mich umb Lieder an", "tokens": ["Spricht", "man", "mich", "umb", "Lie\u00b7der", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gleich als einen Arbeitsmann.", "tokens": ["Gleich", "als", "ei\u00b7nen", "Ar\u00b7beits\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Vnd du solltest, Dorothe,", "tokens": ["Vnd", "du", "soll\u00b7test", ",", "Do\u00b7ro\u00b7the", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "$,", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Nicht von mir ein Denckmal schawen", "tokens": ["Nicht", "von", "mir", "ein", "Denck\u00b7mal", "scha\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "PPER", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner Anmuthreichen Eh'?", "tokens": ["Dei\u00b7ner", "An\u00b7muth\u00b7rei\u00b7chen", "Eh'", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00e4r auff meine Trew zu bawen,", "tokens": ["W\u00e4r", "auff", "mei\u00b7ne", "Trew", "zu", "ba\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Der ich Seiten, Hand und Sinn", "tokens": ["Der", "ich", "Sei\u00b7ten", ",", "Hand", "und", "Sinn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Deinem Hause schuldig bin?", "tokens": ["Dei\u00b7nem", "Hau\u00b7se", "schul\u00b7dig", "bin", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Geht zusammen, wehrtes Par,", "tokens": ["Geht", "zu\u00b7sam\u00b7men", ",", "wehr\u00b7tes", "Par", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Part euch in des H\u00f6chsten Nahmen.", "tokens": ["Part", "euch", "in", "des", "H\u00f6chs\u00b7ten", "Nah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wessen werd' ich hie gewar?", "tokens": ["Wes\u00b7sen", "werd'", "ich", "hie", "ge\u00b7war", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Braut, du nimmst dir einen Samen,", "tokens": ["Braut", ",", "du", "nimmst", "dir", "ei\u00b7nen", "Sa\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Darumb wirst du, wie ich mein',", "tokens": ["Da\u00b7rumb", "wirst", "du", ",", "wie", "ich", "mein'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Allzeit reich von Samen seyn.", "tokens": ["All\u00b7zeit", "reich", "von", "Sa\u00b7men", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Hat der Vatter nicht sein Hau\u00df", "tokens": ["Hat", "der", "Vat\u00b7ter", "nicht", "sein", "Hau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit gew\u00fcnschter Zucht besetzet,", "tokens": ["Mit", "ge\u00b7w\u00fcnschter", "Zucht", "be\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Breitet ihr euch gleichfals aus,", "tokens": ["Brei\u00b7tet", "ihr", "euch", "gleich\u00b7fals", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Traget Frucht, die euch ergetzet,", "tokens": ["Tra\u00b7get", "Frucht", ",", "die", "euch", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wachst, besamet Land und Welt,", "tokens": ["Wachst", ",", "be\u00b7sa\u00b7met", "Land", "und", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die die\u00df Mittel nur erh\u00e4lt.", "tokens": ["Die", "die\u00df", "Mit\u00b7tel", "nur", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Kein Gebrechen seh' ich hier,", "tokens": ["Kein", "Ge\u00b7bre\u00b7chen", "seh'", "ich", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er der Br\u00e4utigam, dein Leben,", "tokens": ["Er", "der", "Br\u00e4u\u00b7ti\u00b7gam", ",", "dein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ART", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fchret aller K\u00fcnste Zier,", "tokens": ["F\u00fch\u00b7ret", "al\u00b7ler", "K\u00fcns\u00b7te", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die ihm Ehr und Ansehn geben,", "tokens": ["Die", "ihm", "Ehr", "und", "An\u00b7sehn", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df die Ertz Schul ihm den Stand", "tokens": ["Da\u00df", "die", "Ertz", "Schul", "ihm", "den", "Stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN", "PPER", "ART", "NN"], "meter": "+-++--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Eines Lehrers zuerkant.", "tokens": ["Ei\u00b7nes", "Leh\u00b7rers", "zu\u00b7er\u00b7kant", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "R\u00fchm' ich seine Sitten viel?", "tokens": ["R\u00fchm'", "ich", "sei\u00b7ne", "Sit\u00b7ten", "viel", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seines Vatters Haus imgleichen?", "tokens": ["Sei\u00b7nes", "Vat\u00b7ters", "Haus", "im\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd da\u00df jetzt darinn Herr Thiel", "tokens": ["Vnd", "da\u00df", "jetzt", "da\u00b7rinn", "Herr", "Thiel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "PAV", "NN", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Mehr noch thut als Vatters Zeichen?", "tokens": ["Mehr", "noch", "thut", "als", "Vat\u00b7ters", "Zei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "KOUS", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lass' ich hier der Remsen Haus", "tokens": ["Lass'", "ich", "hier", "der", "Rem\u00b7sen", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd viel andere Sachen aus?", "tokens": ["Vnd", "viel", "an\u00b7de\u00b7re", "Sa\u00b7chen", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.17": {"line.1": {"text": "Auch von dir, geehrte Braut,", "tokens": ["Auch", "von", "dir", ",", "ge\u00b7ehr\u00b7te", "Braut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lass' ich anstehn viel zu singen,", "tokens": ["Lass'", "ich", "an\u00b7stehn", "viel", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn von allen wird geschawt", "tokens": ["Denn", "von", "al\u00b7len", "wird", "ge\u00b7schawt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIS", "VAFIN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich w\u00fcste beyzubringen.", "tokens": ["Was", "ich", "w\u00fcs\u00b7te", "bey\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Summa, hie ist Gl\u00fcck und Ehr,", "tokens": ["Sum\u00b7ma", ",", "hie", "ist", "Gl\u00fcck", "und", "Ehr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Eines feilet, Herr Wolder.", "tokens": ["Ei\u00b7nes", "fei\u00b7let", ",", "Herr", "Wol\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "NN", "NE", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.18": {"line.1": {"text": "Lebte der, so h\u00e4ttest du", "tokens": ["Leb\u00b7te", "der", ",", "so", "h\u00e4t\u00b7test", "du"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "$,", "ADV", "VAFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Allen Reichthum, alle Gaben,", "tokens": ["Al\u00b7len", "Reicht\u00b7hum", ",", "al\u00b7le", "Ga\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn er war der Seinen Rhu,", "tokens": ["Denn", "er", "war", "der", "Sei\u00b7nen", "Rhu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich ihm zu dancken haben,", "tokens": ["Die", "sich", "ihm", "zu", "dan\u00b7cken", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PPER", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als die er bem\u00fchet war", "tokens": ["Als", "die", "er", "be\u00b7m\u00fc\u00b7het", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "PPER", "VVFIN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zu erweitern immerdar.", "tokens": ["Zu", "er\u00b7wei\u00b7tern", "im\u00b7mer\u00b7dar", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Zwar der Kirchen Seul und Schutz,", "tokens": ["Zwar", "der", "Kir\u00b7chen", "Seul", "und", "Schutz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der er zugeb\u00fcsst sein Leben,", "tokens": ["Der", "er", "zu\u00b7ge\u00b7b\u00fcsst", "sein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber auch des Hauses Nutz,", "tokens": ["A\u00b7ber", "auch", "des", "Hau\u00b7ses", "Nutz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das von ihm kuntt' alles heben,", "tokens": ["Das", "von", "ihm", "kuntt'", "al\u00b7les", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Vorsorg, Auffsicht, Pfleg und Raht", "tokens": ["Vor\u00b7sorg", ",", "Auff\u00b7sicht", ",", "Pfleg", "und", "Raht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd warumb ein jedes baht.", "tokens": ["Vnd", "wa\u00b7rumb", "ein", "je\u00b7des", "baht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "PIAT", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.20": {"line.1": {"text": "Dieser Schatz entgehet dir.", "tokens": ["Die\u00b7ser", "Schatz", "ent\u00b7ge\u00b7het", "dir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gott wird seine Stell' ersetzen,", "tokens": ["Gott", "wird", "sei\u00b7ne", "Stell'", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird euch schencken Gn\u00fcg und Zier", "tokens": ["Wird", "euch", "schen\u00b7cken", "Gn\u00fcg", "und", "Zier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "NE", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd was Leute kan ergetzen,", "tokens": ["Vnd", "was", "Leu\u00b7te", "kan", "er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die in Lieb und Leid allein", "tokens": ["Die", "in", "Lieb", "und", "Leid", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Fest auff ihn gegr\u00fcndet seyn.", "tokens": ["Fest", "auff", "ihn", "ge\u00b7gr\u00fcn\u00b7det", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Du geborgest ietzt dein Schiff,", "tokens": ["Du", "ge\u00b7bor\u00b7gest", "ietzt", "dein", "Schiff", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4hrest sicher in dem Tieff", "tokens": ["F\u00e4h\u00b7rest", "si\u00b7cher", "in", "dem", "Tieff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Trotz den Winden, trotz den Wellen,", "tokens": ["Trotz", "den", "Win\u00b7den", ",", "trotz", "den", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dein Verh\u00e4ngnis lacht dich an", "tokens": ["Dein", "Ver\u00b7h\u00e4ng\u00b7nis", "lacht", "dich", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd das Gl\u00fcck sucht, wie es kan,", "tokens": ["Vnd", "das", "Gl\u00fcck", "sucht", ",", "wie", "es", "kan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "G\u00fclden dir sich darzustellen.", "tokens": ["G\u00fcl\u00b7den", "dir", "sich", "dar\u00b7zu\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Eine Fraw, dem Reben gleich,", "tokens": ["Ei\u00b7ne", "Fraw", ",", "dem", "Re\u00b7ben", "gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Von geehrter Freundschaft reich,", "tokens": ["Von", "ge\u00b7ehr\u00b7ter", "Freund\u00b7schaft", "reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die mit keuscher Zucht kan prangen,", "tokens": ["Die", "mit", "keu\u00b7scher", "Zucht", "kan", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VMFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd in ihrem Hertzen hat", "tokens": ["Vnd", "in", "ih\u00b7rem", "Hert\u00b7zen", "hat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00e4u\u00dflicheit, Verstand und Raht,", "tokens": ["H\u00e4u\u00df\u00b7li\u00b7cheit", ",", "Ver\u00b7stand", "und", "Raht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Solst du ehlich heut umbfangen.", "tokens": ["Solst", "du", "eh\u00b7lich", "heut", "umb\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Auff bedien die Wehrtste wol,", "tokens": ["Auff", "be\u00b7di\u00b7en", "die", "Wehrts\u00b7te", "wol", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Thu ihr was ein Ehmann sol,", "tokens": ["Thu", "ihr", "was", "ein", "Eh\u00b7mann", "sol", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ART", "NN", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df die Zeiten dich nicht hindern,", "tokens": ["La\u00df", "die", "Zei\u00b7ten", "dich", "nicht", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df dein' Apotheke seyn", "tokens": ["La\u00df", "dein'", "A\u00b7pot\u00b7he\u00b7ke", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "NN", "VAINF"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Reich von Kr\u00e4utern, S\u00e4fften, Stein,", "tokens": ["Reich", "von", "Kr\u00e4u\u00b7tern", ",", "S\u00e4ff\u00b7ten", ",", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd dein Hau\u00df von lieben Kindern.", "tokens": ["Vnd", "dein", "Hau\u00df", "von", "lie\u00b7ben", "Kin\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Dein Geberd und Angesicht", "tokens": ["Dein", "Ge\u00b7berd", "und", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leugnet deinen Vater nicht,", "tokens": ["Leug\u00b7net", "dei\u00b7nen", "Va\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "O den Mann von weisen Sinnen,", "tokens": ["O", "den", "Mann", "von", "wei\u00b7sen", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd den Wolstand unsrer Stad!", "tokens": ["Vnd", "den", "Wol\u00b7stand", "uns\u00b7rer", "Stad", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie geschwinde wust er Raht,", "tokens": ["Wie", "ge\u00b7schwin\u00b7de", "wust", "er", "Raht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wo es Noht war, zu gewinnen?", "tokens": ["Wo", "es", "Noht", "war", ",", "zu", "ge\u00b7win\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VAFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "La\u00df sein Bild, Gestalt und Schein", "tokens": ["La\u00df", "sein", "Bild", ",", "Ge\u00b7stalt", "und", "Schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Stets in Kindes Kindern seyn,", "tokens": ["Stets", "in", "Kin\u00b7des", "Kin\u00b7dern", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "NN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd f\u00fcr allen seine Gaben.", "tokens": ["Vnd", "f\u00fcr", "al\u00b7len", "sei\u00b7ne", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebt, ihr Liebsten, werdet alt,", "tokens": ["Lebt", ",", "ihr", "Liebs\u00b7ten", ",", "wer\u00b7det", "alt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wachst an Segen mannigfalt,", "tokens": ["Wachst", "an", "Se\u00b7gen", "man\u00b7nig\u00b7falt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bis der Himmel euch wil haben.", "tokens": ["Bis", "der", "Him\u00b7mel", "euch", "wil", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}