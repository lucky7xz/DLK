{"textgrid.poem.62704": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Ein Sendschreiben", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du denkest warlich falsch, wenn deine Seele meint,", "tokens": ["Du", "den\u00b7kest", "war\u00b7lich", "falsch", ",", "wenn", "dei\u00b7ne", "See\u00b7le", "meint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich z\u00f6rnte, weil dein Brief so sp\u00e4t zur\u00fcck gekommen,", "tokens": ["Ich", "z\u00f6rn\u00b7te", ",", "weil", "dein", "Brief", "so", "sp\u00e4t", "zu\u00b7r\u00fcck", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ADJD", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und eingelaufen ist. Ich habe nun vernommen,", "tokens": ["Und", "ein\u00b7ge\u00b7lau\u00b7fen", "ist", ".", "Ich", "ha\u00b7be", "nun", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Woran die Ursach liebt. Ich glaube deinem Wort,", "tokens": ["Wo\u00b7ran", "die", "Ur\u00b7sach", "liebt", ".", "Ich", "glau\u00b7be", "dei\u00b7nem", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Zeit ist warlich kurz, sie eilt und flieget fort.", "tokens": ["Die", "Zeit", "ist", "war\u00b7lich", "kurz", ",", "sie", "eilt", "und", "flie\u00b7get", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VVFIN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kaum eh wirs uns versehn, so sind die Tages Stunden", "tokens": ["Kaum", "eh", "wirs", "uns", "ver\u00b7sehn", ",", "so", "sind", "die", "Ta\u00b7ges", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PIS", "PPER", "VVINF", "$,", "ADV", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit aller unsrer M\u00fch und Arbeit schon verschwunden.", "tokens": ["Mit", "al\u00b7ler", "uns\u00b7rer", "M\u00fch", "und", "Ar\u00b7beit", "schon", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wohl dem, der seine Zeit recht einzutheilen wei\u00df!", "tokens": ["Wohl", "dem", ",", "der", "sei\u00b7ne", "Zeit", "recht", "ein\u00b7zu\u00b7thei\u00b7len", "wei\u00df", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "PPOSAT", "NN", "ADJD", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wohl dir, da\u00df du beym Buch und Pult mit M\u00fch und Schwei\u00df", "tokens": ["Wohl", "dir", ",", "da\u00df", "du", "beym", "Buch", "und", "Pult", "mit", "M\u00fch", "und", "Schwei\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "KOUS", "PPER", "APPRART", "NN", "KON", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Tage hinterlegst! Ich w\u00fcrde dirs verdenken,", "tokens": ["Die", "Ta\u00b7ge", "hin\u00b7ter\u00b7legst", "!", "Ich", "w\u00fcr\u00b7de", "dirs", "ver\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wenn du mir einen Brief in Reimen w\u00fcrdest schenken,", "tokens": ["Wenn", "du", "mir", "ei\u00b7nen", "Brief", "in", "Rei\u00b7men", "w\u00fcr\u00b7dest", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "APPR", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wodurch vielleicht ein Dienst der Themis unterblieb,", "tokens": ["Wo\u00b7durch", "viel\u00b7leicht", "ein", "Dienst", "der", "The\u00b7mis", "un\u00b7ter\u00b7blieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und dein Geist nicht das Amt der Weisheit eifrig trieb.", "tokens": ["Und", "dein", "Geist", "nicht", "das", "Amt", "der", "Weis\u00b7heit", "eif\u00b7rig", "trieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKNEG", "ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wie? h\u00e4ngt dein Saytenspiel best\u00e4ubet an der Wand?", "tokens": ["Wie", "?", "h\u00e4ngt", "dein", "Say\u00b7ten\u00b7spiel", "be\u00b7st\u00e4u\u00b7bet", "an", "der", "Wand", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "F\u00fchlt deine Brust hierdurch so starken Widerstand?", "tokens": ["F\u00fchlt", "dei\u00b7ne", "Brust", "hier\u00b7durch", "so", "star\u00b7ken", "Wi\u00b7der\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PAV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Soll deine liebe Frau so ganz verlassen heisen?", "tokens": ["Soll", "dei\u00b7ne", "lie\u00b7be", "Frau", "so", "ganz", "ver\u00b7las\u00b7sen", "hei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "O. \u2013 \u2013 kanst du dich ihr wohl so scharf entreisen?", "tokens": ["O.", "\u2013", "\u2013", "kanst", "du", "dich", "ihr", "wohl", "so", "scharf", "en\u00b7trei\u00b7sen", "?"], "token_info": ["abbreviation", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "$(", "VMFIN", "PPER", "PRF", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.18": {"text": "Verzeihe meinen Scherz, der meinem Kiel entf\u00e4hrt.", "tokens": ["Ver\u00b7zei\u00b7he", "mei\u00b7nen", "Scherz", ",", "der", "mei\u00b7nem", "Kiel", "ent\u00b7f\u00e4hrt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wie aber werde ich aus deinem Brief belehrt,", "tokens": ["Wie", "a\u00b7ber", "wer\u00b7de", "ich", "aus", "dei\u00b7nem", "Brief", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Da\u00df dein bedr\u00e4ngter Fu\u00df auf Dornen m\u00fcsse gehen,", "tokens": ["Da\u00df", "dein", "be\u00b7dr\u00e4ng\u00b7ter", "Fu\u00df", "auf", "Dor\u00b7nen", "m\u00fcs\u00b7se", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und du \u2013 \u2013 \u2013 nur Unruh m\u00fcssest sehen?", "tokens": ["Und", "du", "\u2013", "\u2013", "\u2013", "nur", "Un\u00b7ruh", "m\u00fcs\u00b7sest", "se\u00b7hen", "?"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "$(", "$(", "ADV", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Was schreibst du? Zwar die Noth und Last ist allgemein,", "tokens": ["Was", "schreibst", "du", "?", "Zwar", "die", "Noth", "und", "Last", "ist", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "ADV", "ART", "NN", "KON", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sie schliesset niemand aus. Man bilde sich nicht ein,", "tokens": ["Sie", "schlies\u00b7set", "nie\u00b7mand", "aus", ".", "Man", "bil\u00b7de", "sich", "nicht", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PTKVZ", "$.", "PIS", "VVFIN", "PRF", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da\u00df jemand auf der Welt von Kreutz und b\u00f6sen Tagen,", "tokens": ["Da\u00df", "je\u00b7mand", "auf", "der", "Welt", "von", "Kreutz", "und", "b\u00f6\u00b7sen", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Von Tr\u00fcbsal und von Angst nicht etwas k\u00f6nte sagen.", "tokens": ["Von", "Tr\u00fcb\u00b7sal", "und", "von", "Angst", "nicht", "et\u00b7was", "k\u00f6n\u00b7te", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "PTKNEG", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "So wenig als das Feld von Ungest\u00fcm befreyt,", "tokens": ["So", "we\u00b7nig", "als", "das", "Feld", "von", "Un\u00b7ge\u00b7st\u00fcm", "be\u00b7freyt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Und angefochten bleibt; so wenig kan die Zeit", "tokens": ["Und", "an\u00b7ge\u00b7foch\u00b7ten", "bleibt", ";", "so", "we\u00b7nig", "kan", "die", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "VVFIN", "$.", "ADV", "PIS", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Die unser Fu\u00df durchl\u00e4uft, von lauter Freude wissen,", "tokens": ["Die", "un\u00b7ser", "Fu\u00df", "durch\u00b7l\u00e4uft", ",", "von", "lau\u00b7ter", "Freu\u00b7de", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wir trinken unsern Trank und nehmen unsre Bissen", "tokens": ["Wir", "trin\u00b7ken", "un\u00b7sern", "Trank", "und", "neh\u00b7men", "uns\u00b7re", "Bis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Gar oft mit Thr\u00e4nen ein. Kein Mensch ist auf der Welt,", "tokens": ["Gar", "oft", "mit", "Thr\u00e4\u00b7nen", "ein", ".", "Kein", "Mensch", "ist", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "PTKVZ", "$.", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Dem nicht die Allmachts-Hand den Kreutz-Kelch zugestellt.", "tokens": ["Dem", "nicht", "die", "All\u00b7machts\u00b7Hand", "den", "Kreutz\u00b7Kelch", "zu\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Doch wer ihn herzhaft trinkt, und ist getrost in allen,", "tokens": ["Doch", "wer", "ihn", "herz\u00b7haft", "trinkt", ",", "und", "ist", "ge\u00b7trost", "in", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "VVFIN", "$,", "KON", "VAFIN", "ADJD", "APPR", "PIAT", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Den l\u00e4\u00dft die ewge Huld doch nie in Leiden fallen.", "tokens": ["Den", "l\u00e4\u00dft", "die", "ew\u00b7ge", "Huld", "doch", "nie", "in", "Lei\u00b7den", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Es ist ein k\u00f6stlich Ding, in seiner Jugend-Zeit", "tokens": ["Es", "ist", "ein", "k\u00f6st\u00b7lich", "Ding", ",", "in", "sei\u00b7ner", "Ju\u00b7gend\u00b7Zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Die Tr\u00fcbsal, so uns dr\u00fcckt, das bittre Herzeleid,", "tokens": ["Die", "Tr\u00fcb\u00b7sal", ",", "so", "uns", "dr\u00fcckt", ",", "das", "bitt\u00b7re", "Her\u00b7ze\u00b7leid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Recht standhaft auszustehn und mit Gedult zu tragen.", "tokens": ["Recht", "stand\u00b7haft", "aus\u00b7zu\u00b7stehn", "und", "mit", "Ge\u00b7dult", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "KON", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie aber h\u00f6r ich dich in deinem Schreiben klagen?", "tokens": ["Wie", "a\u00b7ber", "h\u00f6r", "ich", "dich", "in", "dei\u00b7nem", "Schrei\u00b7ben", "kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beweintest du mein Haus, gieng dir Sidonia", "tokens": ["Be\u00b7wein\u00b7test", "du", "mein", "Haus", ",", "gieng", "dir", "Si\u00b7do\u00b7nia"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "NE"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und wer ihr zugeh\u00f6rt, j\u00fcngst so empfindlich nah?", "tokens": ["Und", "wer", "ihr", "zu\u00b7ge\u00b7h\u00f6rt", ",", "j\u00fcngst", "so", "emp\u00b7find\u00b7lich", "nah", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "$,", "ADV", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat dir, ", "tokens": ["Hat", "dir", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Ist wahr? da\u00df du, wie ich, der H\u00e4nde Paar gerungen,", "tokens": ["Ist", "wahr", "?", "da\u00df", "du", ",", "wie", "ich", ",", "der", "H\u00e4n\u00b7de", "Paar", "ge\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$.", "KOUS", "PPER", "$,", "PWAV", "PPER", "$,", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und uns beklaget hast? du kanst zwar meinen Schmerz", "tokens": ["Und", "uns", "be\u00b7kla\u00b7get", "hast", "?", "du", "kanst", "zwar", "mei\u00b7nen", "Schmerz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVPP", "VAFIN", "$.", "PPER", "VMFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und hochbetr\u00fcbten Geist/ und abgemattes Herz", "tokens": ["Und", "hoch\u00b7be\u00b7tr\u00fcb\u00b7ten", "Geist", "/", "und", "ab\u00b7ge\u00b7mat\u00b7tes", "Herz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$(", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bey unsrer Feuers-Glut und Noth gar wohl erwegen.", "tokens": ["Bey", "uns\u00b7rer", "Feu\u00b7er\u00b7sGlut", "und", "Noth", "gar", "wohl", "er\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Jedoch, wie du schon wei\u00dft, hat uns des H\u00f6chsten Seegen", "tokens": ["Je\u00b7doch", ",", "wie", "du", "schon", "wei\u00dft", ",", "hat", "uns", "des", "H\u00f6chs\u00b7ten", "See\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und Allmacht wunderbar, da wir es kaum gedacht,", "tokens": ["Und", "All\u00b7macht", "wun\u00b7der\u00b7bar", ",", "da", "wir", "es", "kaum", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "$,", "KOUS", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Erhalten und besch\u00fctzt, und aus der Noth gebracht.", "tokens": ["Er\u00b7hal\u00b7ten", "und", "be\u00b7sch\u00fctzt", ",", "und", "aus", "der", "Noth", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "$,", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ach! einmahl hat uns schon das Feuer aufgerieben,", "tokens": ["Ach", "!", "ein\u00b7mahl", "hat", "uns", "schon", "das", "Feu\u00b7er", "auf\u00b7ge\u00b7rie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Jetzt aber, Gott sey Lob! sind wir verschont geblieben.", "tokens": ["Jetzt", "a\u00b7ber", ",", "Gott", "sey", "Lob", "!", "sind", "wir", "ver\u00b7schont", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "NN", "VAFIN", "NN", "$.", "VAFIN", "PPER", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wie du dein Vaterland j\u00fcngsthin beweinet hast;", "tokens": ["Wie", "du", "dein", "Va\u00b7ter\u00b7land", "j\u00fcng\u00b7sthin", "be\u00b7wei\u00b7net", "hast", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So hab ich gleichfals auch ein Klag-Lied abgefa\u00dft,", "tokens": ["So", "hab", "ich", "gleich\u00b7fals", "auch", "ein", "Klag\u00b7Lied", "ab\u00b7ge\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Um meine Vaterstadt auch thr\u00e4nend zu besingen.", "tokens": ["Um", "mei\u00b7ne", "Va\u00b7ter\u00b7stadt", "auch", "thr\u00e4\u00b7nend", "zu", "be\u00b7sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Mu\u00df dir und mir ein Lied zu unserm Schmerz gelingen?", "tokens": ["Mu\u00df", "dir", "und", "mir", "ein", "Lied", "zu", "un\u00b7serm", "Schmerz", "ge\u00b7lin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KON", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Dein Mitleid, ", "tokens": ["Dein", "Mit\u00b7leid", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.19": {"text": "Und danke dir davor, so rein ich immer kan.", "tokens": ["Und", "dan\u00b7ke", "dir", "da\u00b7vor", ",", "so", "rein", "ich", "im\u00b7mer", "kan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PAV", "$,", "ADV", "ADJD", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Dein sch\u00f6n und frommer Wunsch bringt gleichen Wunsch zur\u00fccke.", "tokens": ["Dein", "sch\u00f6n", "und", "from\u00b7mer", "Wunsch", "bringt", "glei\u00b7chen", "Wunsch", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "KON", "ADJA", "NN", "VVFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich w\u00fcnsche dir davor des Himmels Gnaden-Blicke;", "tokens": ["Ich", "w\u00fcn\u00b7sche", "dir", "da\u00b7vor", "des", "Him\u00b7mels", "Gna\u00b7den\u00b7Bli\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die Allmacht sch\u00fctze dich und segne Amt und Stand,", "tokens": ["Die", "All\u00b7macht", "sch\u00fct\u00b7ze", "dich", "und", "seg\u00b7ne", "Amt", "und", "Stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KON", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und bringe deinen Fu\u00df in ein gelobtes Land.", "tokens": ["Und", "brin\u00b7ge", "dei\u00b7nen", "Fu\u00df", "in", "ein", "ge\u00b7lob\u00b7tes", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Noch eins, ", "tokens": ["Noch", "eins", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "PIS", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Wenn er dich sprechen kan, er ist ganz ausser sich,", "tokens": ["Wenn", "er", "dich", "spre\u00b7chen", "kan", ",", "er", "ist", "ganz", "aus\u00b7ser", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,", "PPER", "VAFIN", "ADV", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn er an dich gedenkt, er glaubet festiglich,", "tokens": ["Wenn", "er", "an", "dich", "ge\u00b7denkt", ",", "er", "glau\u00b7bet", "fes\u00b7tig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Du seyst der liebste Freund, den er nur jemahls funden;", "tokens": ["Du", "seyst", "der", "liebs\u00b7te", "Freund", ",", "den", "er", "nur", "je\u00b7mahls", "fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Zuspruch und dein Gru\u00df labt ihn zu allen Stunden.", "tokens": ["Dein", "Zu\u00b7spruch", "und", "dein", "Gru\u00df", "labt", "ihn", "zu", "al\u00b7len", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hochwerther! soll ich dann in unserm Ger-Athen", "tokens": ["Hoch\u00b7wert\u00b7her", "!", "soll", "ich", "dann", "in", "un\u00b7serm", "Ger\u00b7A\u00b7then"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VMFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Dich nicht einmahl bey mir bewirthen oder sehn?", "tokens": ["Dich", "nicht", "ein\u00b7mahl", "bey", "mir", "be\u00b7wirt\u00b7hen", "o\u00b7der", "sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "APPR", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Soll B \u2013 \u2013 dieses Gl\u00fcck so oft und viel geniessen;", "tokens": ["Soll", "B", "\u2013", "\u2013", "die\u00b7ses", "Gl\u00fcck", "so", "oft", "und", "viel", "ge\u00b7nies\u00b7sen", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "XY", "$(", "$(", "PDAT", "NN", "ADV", "ADV", "KON", "ADV", "VVPP", "$."], "meter": "+---+-+-+-+-", "measure": "dactylic.init"}, "line.9": {"text": "So hoff ich, wirst du auch Sidonen einst begr\u00fcssen.", "tokens": ["So", "hoff", "ich", ",", "wirst", "du", "auch", "Si\u00b7do\u00b7nen", "einst", "be\u00b7gr\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}