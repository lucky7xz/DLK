{"textgrid.poem.26401": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: Achtzig Jahr sind ihre Beine,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Achtzig Jahr sind ihre Beine,", "tokens": ["Acht\u00b7zig", "Jahr", "sind", "ih\u00b7re", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wackeln im Laternenscheine.", "tokens": ["Wa\u00b7ckeln", "im", "La\u00b7ter\u00b7nen\u00b7schei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nachts, wo stinkend K\u00e4sten stehn,", "tokens": ["Nachts", ",", "wo", "stin\u00b7kend", "K\u00e4s\u00b7ten", "stehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADJD", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mu\u00df von T\u00fcr zu T\u00fcr sie gehn.", "tokens": ["Mu\u00df", "von", "T\u00fcr", "zu", "T\u00fcr", "sie", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Lumpen sammelt sie auf Gassen,", "tokens": ["Lum\u00b7pen", "sam\u00b7melt", "sie", "auf", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel ihre S\u00e4cke fassen,", "tokens": ["So", "viel", "ih\u00b7re", "S\u00e4\u00b7cke", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Schleicht geb\u00fcckt die ganze Nacht,", "tokens": ["Schleicht", "ge\u00b7b\u00fcckt", "die", "gan\u00b7ze", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil der Hunger Beine macht.", "tokens": ["Weil", "der", "Hun\u00b7ger", "Bei\u00b7ne", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Mit Aristokratenh\u00e4nden", "tokens": ["Mit", "A\u00b7ris\u00b7to\u00b7kra\u00b7ten\u00b7h\u00e4n\u00b7den"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tut sie jeden Lumpen wenden,", "tokens": ["Tut", "sie", "je\u00b7den", "Lum\u00b7pen", "wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Taxiert ihn auf Goldgehalt,", "tokens": ["Ta\u00b7xiert", "ihn", "auf", "Gold\u00b7ge\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Denn kein Lumpen wird zu alt.", "tokens": ["Denn", "kein", "Lum\u00b7pen", "wird", "zu", "alt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Unter Asche, Staubpapieren", "tokens": ["Un\u00b7ter", "A\u00b7sche", ",", "Staub\u00b7pa\u00b7pie\u00b7ren"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kann sich Manches hinverirren,", "tokens": ["Kann", "sich", "Man\u00b7ches", "hin\u00b7ve\u00b7rir\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was die Welt verachten tat,", "tokens": ["Was", "die", "Welt", "ver\u00b7ach\u00b7ten", "tat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und was trotzdem Taxe hat.", "tokens": ["Und", "was", "trotz\u00b7dem", "Ta\u00b7xe", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Anastasia, die Gro\u00dfmutter,", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", ",", "die", "Gro\u00df\u00b7mut\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+--+-++-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "M\u00fchsam sucht sie Lumpenfutter.", "tokens": ["M\u00fch\u00b7sam", "sucht", "sie", "Lum\u00b7pen\u00b7fut\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Freudvoll flucht der alte Mund", "tokens": ["Freud\u00b7voll", "flucht", "der", "al\u00b7te", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00dcber jeden Lumpenfund.", "tokens": ["\u00dc\u00b7ber", "je\u00b7den", "Lum\u00b7pen\u00b7fund", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Nimmt sie Lumpen in die H\u00e4nde,", "tokens": ["Nimmt", "sie", "Lum\u00b7pen", "in", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Singen sie ihr ganze B\u00e4nde.", "tokens": ["Sin\u00b7gen", "sie", "ihr", "gan\u00b7ze", "B\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lumpen sehn sich d\u00fcster an,", "tokens": ["Lum\u00b7pen", "sehn", "sich", "d\u00fcs\u00b7ter", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dunkle Zeiten h\u00e4ngen dran.", "tokens": ["Dunk\u00b7le", "Zei\u00b7ten", "h\u00e4n\u00b7gen", "dran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Zeiten, die sich nie vergessen,", "tokens": ["Zei\u00b7ten", ",", "die", "sich", "nie", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PRF", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind auf Lumpen wie versessen.", "tokens": ["Sind", "auf", "Lum\u00b7pen", "wie", "ver\u00b7ses\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KOKOM", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Anastasia wei\u00df das gut,", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", "wei\u00df", "das", "gut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PDS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mancher Lumpen klebt wie Blut.", "tokens": ["Man\u00b7cher", "Lum\u00b7pen", "klebt", "wie", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "KOKOM", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Manchen wirft man fort mit Schimpfen,", "tokens": ["Man\u00b7chen", "wirft", "man", "fort", "mit", "Schimp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "PTKVZ", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch der Blick mu\u00df sich einimpfen,", "tokens": ["Doch", "der", "Blick", "mu\u00df", "sich", "ein\u00b7imp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "PRF", "VVPP", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Als w\u00e4r' dir der Lump verwandt,", "tokens": ["Als", "w\u00e4r'", "dir", "der", "Lump", "ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kommt er stets dir in die Hand.", "tokens": ["Kommt", "er", "stets", "dir", "in", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Solcher Lump will dich nicht lassen,", "tokens": ["Sol\u00b7cher", "Lump", "will", "dich", "nicht", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Findst ihn in den fernsten Gassen,", "tokens": ["Findst", "ihn", "in", "den", "ferns\u00b7ten", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Findst ihn jeden zweiten Tag,", "tokens": ["Findst", "ihn", "je\u00b7den", "zwei\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Diesen Lumpen, der dich mag.", "tokens": ["Die\u00b7sen", "Lum\u00b7pen", ",", "der", "dich", "mag."], "token_info": ["word", "word", "punct", "word", "word", "abbreviation"], "pos": ["PDAT", "NN", "$,", "PRELS", "PRF", "NE"], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Heut' in dunkeln Morgenstunden", "tokens": ["Heut'", "in", "dun\u00b7keln", "Mor\u00b7gen\u00b7stun\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat sich wieder was gefunden.", "tokens": ["Hat", "sich", "wie\u00b7der", "was", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "PIS", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jemand sie beim Namen rief,", "tokens": ["Je\u00b7mand", "sie", "beim", "Na\u00b7men", "rief", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ihr's kalt im R\u00fccken lief.", "tokens": ["Da\u00df", "ih\u00b7r's", "kalt", "im", "R\u00fc\u00b7cken", "lief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Unterm Mond, blauangelaufen,", "tokens": ["Un\u00b7term", "Mond", ",", "blau\u00b7an\u00b7ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stand da Eine, konnt' kaum schnaufen,", "tokens": ["Stand", "da", "Ei\u00b7ne", ",", "konnt'", "kaum", "schnau\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "$,", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Alte, kahl am Hirn,", "tokens": ["Ei\u00b7ne", "Al\u00b7te", ",", "kahl", "am", "Hirn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Schatten um die Stirn.", "tokens": ["Ei\u00b7nen", "Schat\u00b7ten", "um", "die", "Stirn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Fuchtelt mit dem Lumpenhaken,", "tokens": ["Fuch\u00b7telt", "mit", "dem", "Lum\u00b7pen\u00b7ha\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lacht mit ausgedorrten Backen,", "tokens": ["Lacht", "mit", "aus\u00b7ge\u00b7dorr\u00b7ten", "Ba\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Rei\u00dft Gro\u00dfmutter fast entzwei,", "tokens": ["Rei\u00dft", "Gro\u00df\u00b7mut\u00b7ter", "fast", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kreischt laut, da\u00df sie Fatma sei.", "tokens": ["Kreischt", "laut", ",", "da\u00df", "sie", "Fat\u00b7ma", "sei", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "KOUS", "PPER", "NE", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Anastasia tut die alten", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", "tut", "die", "al\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dohlenaugen grinsend falten:", "tokens": ["Doh\u00b7len\u00b7au\u00b7gen", "grin\u00b7send", "fal\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Verdammt, als ob's gestern sei,", "tokens": ["Ver\u00b7dammt", ",", "als", "ob's", "ge\u00b7stern", "sei", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "NE", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kennt man Fatma am Geschrei.", "tokens": ["Kennt", "man", "Fat\u00b7ma", "am", "Ge\u00b7schrei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NE", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "F\u00fcnfzig Jahre sind's und dr\u00fcber,", "tokens": ["F\u00fcnf\u00b7zig", "Jah\u00b7re", "sin\u00b7d's", "und", "dr\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NE", "KON", "PAV", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Stehn sich wieder gegen\u00fcber:", "tokens": ["Stehn", "sich", "wie\u00b7der", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird nie ausgetanzt der Ball", "tokens": ["Wird", "nie", "aus\u00b7ge\u00b7tanzt", "der", "Ball"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Auf der Erde Bettelstall?", "tokens": ["Auf", "der", "Er\u00b7de", "Bet\u00b7tel\u00b7stall", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Sah sie oft schon nachts hier streichen,", "tokens": ["Sah", "sie", "oft", "schon", "nachts", "hier", "strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wollt' gern ihrem Rock ausweichen.", "tokens": ["Wollt'", "gern", "ih\u00b7rem", "Rock", "aus\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Manche Lumpenzeit nie stirbt,", "tokens": ["Man\u00b7che", "Lum\u00b7pen\u00b7zeit", "nie", "stirbt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleich wie manch' Lump nie verdirbt.", "tokens": ["Gleich", "wie", "man\u00b7ch'", "Lump", "nie", "ver\u00b7dirbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bbfatma ist nicht auszurotten\u00ab,", "tokens": ["\u00bb", "fat\u00b7ma", "ist", "nicht", "aus\u00b7zu\u00b7rot\u00b7ten", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "VAFIN", "PTKNEG", "VVIZU", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tat die Alte kichernd spotten.", "tokens": ["Tat", "die", "Al\u00b7te", "ki\u00b7chernd", "spot\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbnur die Zeit, die geht herum,", "tokens": ["\u00bb", "nur", "die", "Zeit", ",", "die", "geht", "he\u00b7rum", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "$,", "PRELS", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Flasche bringt sie um.\u00ab", "tokens": ["Und", "die", "Fla\u00b7sche", "bringt", "sie", "um", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Fatma zieht aus tiefster Tasche", "tokens": ["Fat\u00b7ma", "zieht", "aus", "tiefs\u00b7ter", "Ta\u00b7sche"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine abgen\u00fctzte Flasche,", "tokens": ["Ei\u00b7ne", "ab\u00b7ge\u00b7n\u00fctz\u00b7te", "Fla\u00b7sche", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ladet Anastasia ein:", "tokens": ["La\u00b7det", "A\u00b7nas\u00b7ta\u00b7sia", "ein", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbheute soll ein Festchen sein!", "tokens": ["\u00bb", "heu\u00b7te", "soll", "ein", "Fest\u00b7chen", "sein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "La\u00df die Lumpens\u00e4cke laufen!", "tokens": ["La\u00df", "die", "Lum\u00b7pen\u00b7s\u00e4\u00b7cke", "lau\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wollen alten K\u00fcmmel kaufen.", "tokens": ["Wol\u00b7len", "al\u00b7ten", "K\u00fcm\u00b7mel", "kau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lad' dich in mein Kellerloch,", "tokens": ["Lad'", "dich", "in", "mein", "Kel\u00b7ler\u00b7loch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00e4serinden hab' ich noch.", "tokens": ["K\u00e4\u00b7se\u00b7rin\u00b7den", "hab'", "ich", "noch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wollen uns mal bene tuen,", "tokens": ["Wol\u00b7len", "uns", "mal", "be\u00b7ne", "tu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ganz wie einst in Atlasschuhen,", "tokens": ["Ganz", "wie", "einst", "in", "At\u00b7las\u00b7schu\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn wir uns gut prall geschn\u00fcrt,", "tokens": ["Wenn", "wir", "uns", "gut", "prall", "ge\u00b7schn\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "NN", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Blank geschminkt, laut aufgef\u00fchrt.", "tokens": ["Blank", "ge\u00b7schminkt", ",", "laut", "auf\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Heute sind wir Klappersteine.", "tokens": ["Heu\u00b7te", "sind", "wir", "Klap\u00b7per\u00b7stei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einmal schwammen wir im Weine,", "tokens": ["Ein\u00b7mal", "schwam\u00b7men", "wir", "im", "Wei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Welt war Tag und Nacht", "tokens": ["Und", "die", "Welt", "war", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "KON", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Damals nur f\u00fcr uns gemacht.", "tokens": ["Da\u00b7mals", "nur", "f\u00fcr", "uns", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "\u00d6fters zahltest Du die Zechen,", "tokens": ["\u00d6f\u00b7ters", "zahl\u00b7test", "Du", "die", "Ze\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Daf\u00fcr will heut' ich mal blechen.", "tokens": ["Da\u00b7f\u00fcr", "will", "heut'", "ich", "mal", "ble\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ADV", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Manches schiebt sich lange auf,", "tokens": ["Man\u00b7ches", "schiebt", "sich", "lan\u00b7ge", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einmal aber kommt man drauf.\u00ab", "tokens": ["Ein\u00b7mal", "a\u00b7ber", "kommt", "man", "drauf", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Anastasia, ohne T\u00fccke,", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", ",", "oh\u00b7ne", "T\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fchlt der Freundschaft Scherbenst\u00fccke,", "tokens": ["F\u00fchlt", "der", "Freund\u00b7schaft", "Scher\u00b7ben\u00b7st\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mehr noch als der K\u00fcmmel lockt,", "tokens": ["Mehr", "noch", "als", "der", "K\u00fcm\u00b7mel", "lockt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das was rings um Fatma hockt.", "tokens": ["Das", "was", "rings", "um", "Fat\u00b7ma", "hockt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "ADV", "APPR", "NE", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.23": {"line.1": {"text": "Jene drallen Jugendzeiten,", "tokens": ["Je\u00b7ne", "dral\u00b7len", "Ju\u00b7gend\u00b7zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo sie um die Venus freiten,", "tokens": ["Wo", "sie", "um", "die", "Ve\u00b7nus", "frei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo sie wie der Mond zur Nacht", "tokens": ["Wo", "sie", "wie", "der", "Mond", "zur", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "KOKOM", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich geputzt und fein gemacht.", "tokens": ["Sich", "ge\u00b7putzt", "und", "fein", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "KON", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Die Kulisse ist verschoben!", "tokens": ["Die", "Ku\u00b7lis\u00b7se", "ist", "ver\u00b7scho\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach der Mond, der h\u00e4ngt noch oben,", "tokens": ["Ach", "der", "Mond", ",", "der", "h\u00e4ngt", "noch", "o\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ART", "NN", "$,", "PRELS", "VVFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieht sie mit dem Hintern an,", "tokens": ["Sieht", "sie", "mit", "dem", "Hin\u00b7tern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil er nur noch spotten kann.", "tokens": ["Weil", "er", "nur", "noch", "spot\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Und die beiden Alten wandern,", "tokens": ["Und", "die", "bei\u00b7den", "Al\u00b7ten", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine an dem Arm der andern,", "tokens": ["Ei\u00b7ne", "an", "dem", "Arm", "der", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kaufen Doppelk\u00fcmmel, rein,", "tokens": ["Kau\u00b7fen", "Dop\u00b7pel\u00b7k\u00fcm\u00b7mel", ",", "rein", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schlie\u00dfen sich bei Fatma ein.", "tokens": ["Schlie\u00b7\u00dfen", "sich", "bei", "Fat\u00b7ma", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "In der Fatma Kellerkammer", "tokens": ["In", "der", "Fat\u00b7ma", "Kel\u00b7ler\u00b7kam\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Finstert's w\u00fcst wie Altersjammer.", "tokens": ["Fins\u00b7tert's", "w\u00fcst", "wie", "Al\u00b7ters\u00b7jam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KOKOM", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr das Wiedersehensfest", "tokens": ["F\u00fcr", "das", "Wie\u00b7der\u00b7se\u00b7hens\u00b7fest"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Brennt man einen Unschlittrest.", "tokens": ["Brennt", "man", "ei\u00b7nen", "Un\u00b7schlitt\u00b7rest", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.27": {"line.1": {"text": "Fahl schaun beide Klapperk\u00f6pfe,", "tokens": ["Fahl", "schaun", "bei\u00b7de", "Klap\u00b7per\u00b7k\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind wie vielgeflickte T\u00f6pfe.", "tokens": ["Sind", "wie", "viel\u00b7ge\u00b7flick\u00b7te", "T\u00f6p\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine stiert die Andre an:", "tokens": ["Ei\u00b7ne", "stiert", "die", "And\u00b7re", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df man so sich \u00e4ndern kann!", "tokens": ["Da\u00df", "man", "so", "sich", "\u00e4n\u00b7dern", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PRF", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Sie, die flottesten Het\u00e4ren,", "tokens": ["Sie", ",", "die", "flot\u00b7tes\u00b7ten", "He\u00b7t\u00e4\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heute zwei Schindangerm\u00e4hren!", "tokens": ["Heu\u00b7te", "zwei", "Schin\u00b7dan\u00b7ger\u00b7m\u00e4h\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Strotzend war einmal ihr Ruhm, \u2013", "tokens": ["Strot\u00b7zend", "war", "ein\u00b7mal", "ihr", "Ruhm", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "PPOSAT", "NN", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur noch Lumpen gehen um.", "tokens": ["Nur", "noch", "Lum\u00b7pen", "ge\u00b7hen", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Einen Zeitungskn\u00e4ul sie finden", "tokens": ["Ei\u00b7nen", "Zei\u00b7tungs\u00b7kn\u00e4ul", "sie", "fin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und drin alte K\u00e4serinden,", "tokens": ["Und", "drin", "al\u00b7te", "K\u00e4\u00b7se\u00b7rin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Beide kauen ohne Zahn,", "tokens": ["Bei\u00b7de", "kau\u00b7en", "oh\u00b7ne", "Zahn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der K\u00fcmmel gibt Elan.", "tokens": ["Und", "der", "K\u00fcm\u00b7mel", "gibt", "E\u00b7lan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "K\u00fcmmel schmatzend tun sie schw\u00e4tzen,", "tokens": ["K\u00fcm\u00b7mel", "schmat\u00b7zend", "tun", "sie", "schw\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Schnaps und's Unschlitt setzen", "tokens": ["Und", "der", "Schnaps", "un\u00b7d's", "Un\u00b7schlitt", "set\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hitzige Gesichter hin,", "tokens": ["Hit\u00b7zi\u00b7ge", "Ge\u00b7sich\u00b7ter", "hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ein Wetter will aufziehn.", "tokens": ["Und", "ein", "Wet\u00b7ter", "will", "auf\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "--+-++-", "measure": "anapaest.init"}}, "stanza.31": {"line.1": {"text": "Fatma kreischt: \u00bbWar ich nicht immer", "tokens": ["Fat\u00b7ma", "kreischt", ":", "\u00bb", "War", "ich", "nicht", "im\u00b7mer"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$.", "$(", "VAFIN", "PPER", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein geschultes Frauenzimmer?", "tokens": ["Ein", "ge\u00b7schul\u00b7tes", "Frau\u00b7en\u00b7zim\u00b7mer", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wog mich auf f\u00fcr schweres Gold, \u2013", "tokens": ["Wog", "mich", "auf", "f\u00fcr", "schwe\u00b7res", "Gold", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "APPR", "APPR", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die Finger ist's gerollt!", "tokens": ["Durch", "die", "Fin\u00b7ger", "ist's", "ge\u00b7rollt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Meine sch\u00f6nen Schulterbogen", "tokens": ["Mei\u00b7ne", "sch\u00f6\u00b7nen", "Schul\u00b7ter\u00b7bo\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haben Opern \u00fcberwogen,", "tokens": ["Ha\u00b7ben", "O\u00b7pern", "\u00fc\u00b7ber\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ich in der Matinee", "tokens": ["Wenn", "ich", "in", "der", "Ma\u00b7ti\u00b7nee"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Halbnackt in der Log' mich seh'.", "tokens": ["Halb\u00b7nackt", "in", "der", "Lo\u00b7g'", "mich", "seh'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Keinen konnt' die Oper r\u00fchren,", "tokens": ["Kei\u00b7nen", "konnt'", "die", "O\u00b7per", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur mein Fleisch mu\u00dft' Jeder sp\u00fcren,", "tokens": ["Nur", "mein", "Fleisch", "mu\u00dft'", "Je\u00b7der", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Blick von jedem Gauch", "tokens": ["Und", "der", "Blick", "von", "je\u00b7dem", "Gauch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hing wie Zangen mir am Bauch.", "tokens": ["Hing", "wie", "Zan\u00b7gen", "mir", "am", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Wei\u00dft du, wenn's mir eingefallen,", "tokens": ["Wei\u00dft", "du", ",", "wenn's", "mir", "ein\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Konnt' ich gl\u00fchen wie Korallen.", "tokens": ["Konnt'", "ich", "gl\u00fc\u00b7hen", "wie", "Ko\u00b7ral\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "KOKOM", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hatte es mir mal beliebt,", "tokens": ["Hat\u00b7te", "es", "mir", "mal", "be\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fragte Keiner, was er gibt.", "tokens": ["Frag\u00b7te", "Kei\u00b7ner", ",", "was", "er", "gibt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Mancher lebte so geschwinder,", "tokens": ["Man\u00b7cher", "leb\u00b7te", "so", "ge\u00b7schwin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warf f\u00fcr mich fort Weib und Kinder;", "tokens": ["Warf", "f\u00fcr", "mich", "fort", "Weib", "und", "Kin\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "PTKVZ", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sah mich einer z\u00e4rtlich an, \u2013", "tokens": ["Sah", "mich", "ei\u00b7ner", "z\u00e4rt\u00b7lich", "an", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJD", "PTKVZ", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ruinierte ich den Mann.\u00ab", "tokens": ["Ru\u00b7i\u00b7nier\u00b7te", "ich", "den", "Mann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Anastasia mit Vergn\u00fcgen", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["NE", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spricht: \u00bbVerdammt tust Du doch l\u00fcgen!", "tokens": ["Spricht", ":", "\u00bb", "Ver\u00b7dammt", "tust", "Du", "doch", "l\u00fc\u00b7gen", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "VVPP", "VVFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch auch Dich belog die Welt,", "tokens": ["Doch", "auch", "Dich", "be\u00b7log", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil sie heut' nicht zu Dir h\u00e4lt.\u00ab", "tokens": ["Weil", "sie", "heut'", "nicht", "zu", "Dir", "h\u00e4lt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Fatmas Zung' geht wie 'ne Spule,", "tokens": ["Fat\u00b7mas", "Zung'", "geht", "wie", "'ne", "Spu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In ihr schwillt die alte Buhle,", "tokens": ["In", "ihr", "schwillt", "die", "al\u00b7te", "Buh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Prahlt vom Schlittennachmittag,", "tokens": ["Prahlt", "vom", "Schlit\u00b7ten\u00b7nach\u00b7mit\u00b7tag", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo der Schnee mal k\u00fcnstlich lag.", "tokens": ["Wo", "der", "Schnee", "mal", "k\u00fcnst\u00b7lich", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Einer hatte ihr zu F\u00fc\u00dfen", "tokens": ["Ei\u00b7ner", "hat\u00b7te", "ihr", "zu", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tausend F\u00e4sser Salz streun m\u00fcssen;", "tokens": ["Tau\u00b7send", "F\u00e4s\u00b7ser", "Salz", "streun", "m\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von dem Schlo\u00df am Waldesrand", "tokens": ["Von", "dem", "Schlo\u00df", "am", "Wal\u00b7des\u00b7rand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Meile in das Land ....", "tokens": ["Ei\u00b7ne", "Mei\u00b7le", "in", "das", "Land", "...."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Anastasia unterdessen", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", "un\u00b7ter\u00b7des\u00b7sen"], "token_info": ["word", "word"], "pos": ["NE", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat sich schweigend hei\u00dfgesessen,", "tokens": ["Hat", "sich", "schwei\u00b7gend", "hei\u00df\u00b7ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Etwas rei\u00dft sie wie die Gicht,", "tokens": ["Et\u00b7was", "rei\u00dft", "sie", "wie", "die", "Gicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wie Pfeffer brennt's Gesicht.", "tokens": ["Und", "wie", "Pfef\u00b7fer", "brennt's", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Schm\u00e4hlich ist's ihr eingefallen:", "tokens": ["Schm\u00e4h\u00b7lich", "ist's", "ihr", "ein\u00b7ge\u00b7fal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diesem Einen unter allen", "tokens": ["Die\u00b7sem", "Ei\u00b7nen", "un\u00b7ter", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ART", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "War es, dem sie sich verschwor \u2013", "tokens": ["War", "es", ",", "dem", "sie", "sich", "ver\u00b7schwor", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "PRELS", "PPER", "PRF", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fatma doch kam ihr zuvor!", "tokens": ["Fat\u00b7ma", "doch", "kam", "ihr", "zu\u00b7vor", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.41": {"line.1": {"text": "Fatma ist mit ihm verschwunden.", "tokens": ["Fat\u00b7ma", "ist", "mit", "ihm", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Schwieriger als Todesstunden", "tokens": ["Schwie\u00b7ri\u00b7ger", "als", "To\u00b7dess\u00b7tun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["NN", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "War ihr dieser Schicksalsschlag.", "tokens": ["War", "ihr", "die\u00b7ser", "Schick\u00b7sals\u00b7schlag", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Heute noch wurmt sie der Tag.", "tokens": ["Heu\u00b7te", "noch", "wurmt", "sie", "der", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.42": {"line.1": {"text": "Schnaps nach Schnaps mu\u00df sie schnell trinken,", "tokens": ["Schnaps", "nach", "Schnaps", "mu\u00df", "sie", "schnell", "trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil die alten Wunden stinken.", "tokens": ["Weil", "die", "al\u00b7ten", "Wun\u00b7den", "stin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00dcberall im Kellerloch", "tokens": ["\u00dc\u00b7be\u00b7rall", "im", "Kel\u00b7ler\u00b7loch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schleicht jetzt dieser Eine noch.", "tokens": ["Schleicht", "jetzt", "die\u00b7ser", "Ei\u00b7ne", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PDAT", "ART", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Damals dorrten ihr die Br\u00fcste.", "tokens": ["Da\u00b7mals", "dorr\u00b7ten", "ihr", "die", "Br\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keiner mit Verstand so k\u00fc\u00dfte,", "tokens": ["Kei\u00b7ner", "mit", "Ver\u00b7stand", "so", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner mehr so stark verstund", "tokens": ["Kei\u00b7ner", "mehr", "so", "stark", "ver\u00b7stund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "ADV", "ADV", "ADJD", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einzubrennen seinen Mund.", "tokens": ["Ein\u00b7zu\u00b7bren\u00b7nen", "sei\u00b7nen", "Mund", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Hitzig war er wie die Heiden!", "tokens": ["Hit\u00b7zig", "war", "er", "wie", "die", "Hei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie lie\u00df ihn mit Wollust leiden,", "tokens": ["Sie", "lie\u00df", "ihn", "mit", "Wol\u00b7lust", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wollt ihm darum wiederstehn,", "tokens": ["Wollt", "ihm", "da\u00b7rum", "wie\u00b7ders\u00b7tehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PAV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Um sein Herz seufzen zu sehn.", "tokens": ["Um", "sein", "Herz", "seuf\u00b7zen", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.45": {"line.1": {"text": "Und im Grund mu\u00dft' man sich sch\u00e4men,", "tokens": ["Und", "im", "Grund", "mu\u00dft'", "man", "sich", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VMFIN", "PIS", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tadellos war sein Benehmen.", "tokens": ["Ta\u00b7del\u00b7los", "war", "sein", "Be\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dralle Schweine waren wir,", "tokens": ["Dral\u00b7le", "Schwei\u00b7ne", "wa\u00b7ren", "wir", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und er immer Kavalier.", "tokens": ["Und", "er", "im\u00b7mer", "Ka\u00b7va\u00b7lier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Fatma, mit den Heuchelbr\u00fcsten,", "tokens": ["Fat\u00b7ma", ",", "mit", "den", "Heu\u00b7chel\u00b7br\u00fcs\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Konnt' mir diesen Mann verw\u00fcsten!", "tokens": ["Konnt'", "mir", "die\u00b7sen", "Mann", "ver\u00b7w\u00fcs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sah, wie ich f\u00fcr ihn geschw\u00e4rmt,", "tokens": ["Sah", ",", "wie", "ich", "f\u00fcr", "ihn", "ge\u00b7schw\u00e4rmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat ihn sich mit Kunst erw\u00e4rmt.", "tokens": ["Hat", "ihn", "sich", "mit", "Kunst", "er\u00b7w\u00e4rmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Heut' noch l\u00e4g' er mir zu F\u00fc\u00dfen \u2013", "tokens": ["Heut'", "noch", "l\u00e4g'", "er", "mir", "zu", "F\u00fc\u00b7\u00dfen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Scheusal Fatma, sollst mir's b\u00fc\u00dfen!", "tokens": ["Scheu\u00b7sal", "Fat\u00b7ma", ",", "sollst", "mir's", "b\u00fc\u00b7\u00dfen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mache sie zu kaltem Aas,", "tokens": ["Ma\u00b7che", "sie", "zu", "kal\u00b7tem", "Aas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil sie sich an mir verga\u00df.", "tokens": ["Weil", "sie", "sich", "an", "mir", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.48": {"line.1": {"text": "Und die Alte mu\u00df ausspucken:", "tokens": ["Und", "die", "Al\u00b7te", "mu\u00df", "aus\u00b7spu\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese Fatma will ich ducken!", "tokens": ["Die\u00b7se", "Fat\u00b7ma", "will", "ich", "du\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses soll mein Festlein sein,", "tokens": ["Die\u00b7ses", "soll", "mein", "Fest\u00b7lein", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Heute ist die Rache mein.", "tokens": ["Heu\u00b7te", "ist", "die", "Ra\u00b7che", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Anastasias Augen stechen,", "tokens": ["A\u00b7nas\u00b7ta\u00b7si\u00b7as", "Au\u00b7gen", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ihre H\u00e4nde wollen r\u00e4chen ....", "tokens": ["Ih\u00b7re", "H\u00e4n\u00b7de", "wol\u00b7len", "r\u00e4\u00b7chen", "...."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schnell fliegt's Schnapsglas an die Wand,", "tokens": ["Schnell", "fliegt's", "Schnaps\u00b7glas", "an", "die", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ob sich ein Gift drin fand.", "tokens": ["Als", "ob", "sich", "ein", "Gift", "drin", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PRF", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Und nach langen f\u00fcnfzig Jahren", "tokens": ["Und", "nach", "lan\u00b7gen", "f\u00fcnf\u00b7zig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tut ein Feuer in sie fahren.", "tokens": ["Tut", "ein", "Feu\u00b7er", "in", "sie", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner wu\u00dfte wie's geschah \u2013", "tokens": ["Kei\u00b7ner", "wu\u00df\u00b7te", "wie's", "ge\u00b7schah", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mundoffen schweigt Fatma da.", "tokens": ["Mun\u00b7dof\u00b7fen", "schweigt", "Fat\u00b7ma", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NE", "PTKVZ", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.51": {"line.1": {"text": "Aufrichtet sich stier die Alte,", "tokens": ["Auf\u00b7rich\u00b7tet", "sich", "stier", "die", "Al\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Blut brennt ihr in jeder Falte,", "tokens": ["Blut", "brennt", "ihr", "in", "je\u00b7der", "Fal\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zum Schlag holt aus der Blick \u2013", "tokens": ["Und", "zum", "Schlag", "holt", "aus", "der", "Blick", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fatma fr\u00f6stelt's im Genick.", "tokens": ["Fat\u00b7ma", "fr\u00f6s\u00b7telt's", "im", "Ge\u00b7nick", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPRART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.52": {"line.1": {"text": "Aus dem Kiefer, aus dem hohlen,", "tokens": ["Aus", "dem", "Kie\u00b7fer", ",", "aus", "dem", "hoh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4llt das kleine Wort \u00bb", "tokens": ["F\u00e4llt", "das", "klei\u00b7ne", "Wort", "\u00bb"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbja, gestohlen hast du ihn!\u00ab", "tokens": ["\u00bb", "ja", ",", "ge\u00b7stoh\u00b7len", "hast", "du", "ihn", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "VVPP", "VAFIN", "PPER", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Anastasia schleudert's hin.", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", "schleu\u00b7dert's", "hin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Ihre F\u00e4uste, ihre steifen,", "tokens": ["Ih\u00b7re", "F\u00e4us\u00b7te", ",", "ih\u00b7re", "stei\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach dem Lumpenhaken greifen.", "tokens": ["Nach", "dem", "Lum\u00b7pen\u00b7ha\u00b7ken", "grei\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ehe Fatma noch konnt' schrein,", "tokens": ["E\u00b7he", "Fat\u00b7ma", "noch", "konnt'", "schrein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "VMFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schlug das Eisen w\u00fctend ein.", "tokens": ["Schlug", "das", "Ei\u00b7sen", "w\u00fc\u00b7tend", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Dann h\u00f6rt man's nur einmal klatschen,", "tokens": ["Dann", "h\u00f6rt", "man's", "nur", "ein\u00b7mal", "klat\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als t\u00e4t eine T\u00fcr zupatschen.", "tokens": ["Als", "t\u00e4t", "ei\u00b7ne", "T\u00fcr", "zu\u00b7pat\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Fatma fiel zur Diele tot,", "tokens": ["Fat\u00b7ma", "fiel", "zur", "Die\u00b7le", "tot", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Bretter wurden rot.", "tokens": ["Und", "die", "Bret\u00b7ter", "wur\u00b7den", "rot", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Anastasia, nicht zufrieden,", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", ",", "nicht", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4\u00dft ringsum die Rach' aussieden.", "tokens": ["L\u00e4\u00dft", "ring\u00b7sum", "die", "Rach'", "aus\u00b7sie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "St\u00fchle, alles was sie fand,", "tokens": ["St\u00fch\u00b7le", ",", "al\u00b7les", "was", "sie", "fand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIS", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Links und rechts fliegt's an die Wand.", "tokens": ["Links", "und", "rechts", "fliegt's", "an", "die", "Wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Spr\u00fchendhei\u00df sind ihre Glieder;", "tokens": ["Spr\u00fc\u00b7hend\u00b7hei\u00df", "sind", "ih\u00b7re", "Glie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bei der Leiche hockt sie nieder,", "tokens": ["Bei", "der", "Lei\u00b7che", "hockt", "sie", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sie pufft sie dann und wann,", "tokens": ["Und", "sie", "pufft", "sie", "dann", "und", "wann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "KON", "PWAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Z\u00e4hlt ihr auf, was sie getan:", "tokens": ["Z\u00e4hlt", "ihr", "auf", ",", "was", "sie", "ge\u00b7tan", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "\u00bbglaubst du, Liebe l\u00e4\u00dft sich narren?", "tokens": ["\u00bb", "glaubst", "du", ",", "Lie\u00b7be", "l\u00e4\u00dft", "sich", "nar\u00b7ren", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "NN", "VVFIN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle sollten Gold dir karren!", "tokens": ["Al\u00b7le", "soll\u00b7ten", "Gold", "dir", "kar\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stahlst mir frech das Allerbest!", "tokens": ["Stahlst", "mir", "frech", "das", "Al\u00b7ler\u00b7best", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Finster ist mein Lebensrest.", "tokens": ["Fins\u00b7ter", "ist", "mein", "Le\u00b7bens\u00b7rest", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.58": {"line.1": {"text": "Tatst mir seine Lippen schmatzen,", "tokens": ["Tatst", "mir", "sei\u00b7ne", "Lip\u00b7pen", "schmat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schielend nur nach seinen Batzen!", "tokens": ["Schie\u00b7lend", "nur", "nach", "sei\u00b7nen", "Bat\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser Eine, er war mein, \u2013", "tokens": ["Die\u00b7ser", "Ei\u00b7ne", ",", "er", "war", "mein", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "$,", "PPER", "VAFIN", "PPOSAT", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Stecktest dir ihn auch noch ein!", "tokens": ["Steck\u00b7test", "dir", "ihn", "auch", "noch", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "Konnt' dir kein Gewissen klopfen?", "tokens": ["Konnt'", "dir", "kein", "Ge\u00b7wis\u00b7sen", "klop\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gabst ihm geile Liebestropfen.", "tokens": ["Gabst", "ihm", "gei\u00b7le", "Lie\u00b7be\u00b7strop\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hast an Liebe nie geglaubt,", "tokens": ["Hast", "an", "Lie\u00b7be", "nie", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur wie Elstern Gold geraubt.", "tokens": ["Nur", "wie", "Els\u00b7tern", "Gold", "ge\u00b7raubt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NE", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Denk' ich heut' noch meiner Qualen,", "tokens": ["Denk'", "ich", "heut'", "noch", "mei\u00b7ner", "Qua\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kann's dein Leben nicht bezahlen.", "tokens": ["Kann's", "dein", "Le\u00b7ben", "nicht", "be\u00b7zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Daf\u00fcr ist dein Tod zu klein,", "tokens": ["Da\u00b7f\u00fcr", "ist", "dein", "Tod", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "PTKA", "ADJD", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Solltest tausend Mal tot sein.", "tokens": ["Soll\u00b7test", "tau\u00b7send", "Mal", "tot", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Mein Herz ward zur Schinderkammer.", "tokens": ["Mein", "Herz", "ward", "zur", "Schin\u00b7der\u00b7kam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Widerlich lag drin mein Jammer.", "tokens": ["Wi\u00b7der\u00b7lich", "lag", "drin", "mein", "Jam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.3": {"text": "Lange hebt man so was auf,", "tokens": ["Lan\u00b7ge", "hebt", "man", "so", "was", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einmal aber st\u00f6\u00dft man drauf.", "tokens": ["Ein\u00b7mal", "a\u00b7ber", "st\u00f6\u00dft", "man", "drauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Lebt ein Mensch auch unter Lumpen,", "tokens": ["Lebt", "ein", "Mensch", "auch", "un\u00b7ter", "Lum\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keiner soll sein Ich verschlumpen.", "tokens": ["Kei\u00b7ner", "soll", "sein", "Ich", "ver\u00b7schlum\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPOSAT", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch beim kleinsten Lebensstrund", "tokens": ["Auch", "beim", "kleins\u00b7ten", "Le\u00b7bens\u00b7strund"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schmeckt die Rache stets gesund.\u00ab", "tokens": ["Schmeckt", "die", "Ra\u00b7che", "stets", "ge\u00b7sund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Anastasia mu\u00df sich schneutzen,", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", "mu\u00df", "sich", "schneut\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schatten an den W\u00e4nden kreuzen,", "tokens": ["Schat\u00b7ten", "an", "den", "W\u00e4n\u00b7den", "kreu\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Paffend geht das Unschlitt aus,", "tokens": ["Paf\u00b7fend", "geht", "das", "Un\u00b7schlitt", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ging Mordlust aus dem Haus.", "tokens": ["Als", "ging", "Mord\u00b7lust", "aus", "dem", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Eine Weil' tut's Licht noch fackeln,", "tokens": ["Ei\u00b7ne", "Weil'", "tut's", "Licht", "noch", "fa\u00b7ckeln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Kammer scheint zu wackeln;", "tokens": ["Und", "die", "Kam\u00b7mer", "scheint", "zu", "wa\u00b7ckeln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Anastasia starrt hinein,", "tokens": ["A\u00b7nas\u00b7ta\u00b7sia", "starrt", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nickt ersch\u00f6pft beim Leichnam ein.", "tokens": ["Nickt", "er\u00b7sch\u00f6pft", "beim", "Leich\u00b7nam", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Wei\u00df nicht mehr, nach wieviel Stunden", "tokens": ["Wei\u00df", "nicht", "mehr", ",", "nach", "wie\u00b7viel", "Stun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ADV", "$,", "APPR", "PIAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Hat sie endlich heim gefunden;", "tokens": ["Hat", "sie", "end\u00b7lich", "heim", "ge\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKVZ", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Reulos ging sie von dem Ort.", "tokens": ["Reu\u00b7los", "ging", "sie", "von", "dem", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unger\u00e4cht blieb dieser Mord.", "tokens": ["Un\u00b7ge\u00b7r\u00e4cht", "blieb", "die\u00b7ser", "Mord", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "W\u00e4r' es auch herausgekommen,", "tokens": ["W\u00e4r'", "es", "auch", "her\u00b7aus\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Feig' h\u00e4tt' sie sich nicht benommen.", "tokens": ["Feig'", "h\u00e4tt'", "sie", "sich", "nicht", "be\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PRF", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "T\u00f6ter macht nicht das Schaffott,", "tokens": ["T\u00f6\u00b7ter", "macht", "nicht", "das", "Schaf\u00b7fott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Ist man schon im Grunde tot.", "tokens": ["Ist", "man", "schon", "im", "Grun\u00b7de", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "APPRART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}