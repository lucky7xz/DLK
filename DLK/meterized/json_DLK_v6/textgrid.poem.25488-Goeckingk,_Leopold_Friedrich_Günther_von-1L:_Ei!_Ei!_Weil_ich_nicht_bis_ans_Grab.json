{"textgrid.poem.25488": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ei! Ei! Weil ich nicht bis ans Grab", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ei! Ei! Weil ich nicht bis ans Grab", "tokens": ["Ei", "!", "Ei", "!", "Weil", "ich", "nicht", "bis", "ans", "Grab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "NN", "$.", "KOUS", "PPER", "PTKNEG", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Harzgebirge bin geblieben,", "tokens": ["Im", "Harz\u00b7ge\u00b7bir\u00b7ge", "bin", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So brichst du \u00fcber mich den Stab,", "tokens": ["So", "brichst", "du", "\u00fc\u00b7ber", "mich", "den", "Stab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in dem Urtheil' steht geschrieben:", "tokens": ["Und", "in", "dem", "Urt\u00b7heil'", "steht", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vielleicht des Herzens edler Drang,", "tokens": ["Viel\u00b7leicht", "des", "Her\u00b7zens", "ed\u00b7ler", "Drang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Je mehr, je besser auszus\u00e4en? \u2013", "tokens": ["Je", "mehr", ",", "je", "bes\u00b7ser", "aus\u00b7zu\u00b7s\u00e4\u00b7en", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Nein! du gibst deutlich zu verstehen:", "tokens": ["Nein", "!", "du", "gibst", "deut\u00b7lich", "zu", "ver\u00b7ste\u00b7hen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbdie Sucht nach Titeln und nach Rang!\u00ab", "tokens": ["\u00bb", "die", "Sucht", "nach", "Ti\u00b7teln", "und", "nach", "Rang", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da haben wir's! Der einst, zum Schein',", "tokens": ["Da", "ha\u00b7ben", "wir's", "!", "Der", "einst", ",", "zum", "Schein'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$.", "ART", "ADV", "$,", "APPRART", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.10": {"text": "Laut gegen Kriecherei gesprochen,", "tokens": ["Laut", "ge\u00b7gen", "Krie\u00b7che\u00b7rei", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Hat selbst sich Titel nun erkrochen,", "tokens": ["Hat", "selbst", "sich", "Ti\u00b7tel", "nun", "er\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PRF", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Hat schimpflich sich durch Schmeichelein", "tokens": ["Hat", "schimpf\u00b7lich", "sich", "durch", "Schmei\u00b7che\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "PRF", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Zur Sylbe ", "tokens": ["Zur", "Syl\u00b7be"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Ja freilich! Wenn dem also w\u00e4re,", "tokens": ["Ja", "frei\u00b7lich", "!", "Wenn", "dem", "al\u00b7so", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$.", "KOUS", "ART", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "So w\u00e4r' es schlimm genug f\u00fcr ihn;", "tokens": ["So", "w\u00e4r'", "es", "schlimm", "ge\u00b7nug", "f\u00fcr", "ihn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Der Schatten selbst von wahrer Ehre,", "tokens": ["Der", "Schat\u00b7ten", "selbst", "von", "wah\u00b7rer", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Trotz seinem Ehrgeitz', m\u00fc\u00dft' ihn fliehn.", "tokens": ["Trotz", "sei\u00b7nem", "Ehr\u00b7geitz'", ",", "m\u00fc\u00dft'", "ihn", "fliehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Doch ist's an sich uns kein Verbrechen,", "tokens": ["Doch", "ist's", "an", "sich", "uns", "kein", "Ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "PRF", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Empor zu steigen: dann so la\u00dft,", "tokens": ["Em\u00b7por", "zu", "stei\u00b7gen", ":", "dann", "so", "la\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$.", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wenn Ihr ein Endurtheil verfa\u00dft,", "tokens": ["Wenn", "Ihr", "ein", "End\u00b7urt\u00b7heil", "ver\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Die Wahrheit auch ein W\u00f6rtchen sprechen.", "tokens": ["Die", "Wahr\u00b7heit", "auch", "ein", "W\u00f6rt\u00b7chen", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Der Muse Thr\u00e4nen w\u00fcrden zwar", "tokens": ["Der", "Mu\u00b7se", "Thr\u00e4\u00b7nen", "w\u00fcr\u00b7den", "zwar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Mit vollem Recht' die Leyer netzen,", "tokens": ["Mit", "vol\u00b7lem", "Recht'", "die", "Le\u00b7yer", "net\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Verg\u00e4\u00dfe bei Cujaz Gesetzen", "tokens": ["Ver\u00b7g\u00e4\u00b7\u00dfe", "bei", "Cu\u00b7jaz", "Ge\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.26": {"text": "Wer will ihn missen? Wer ersetzen?", "tokens": ["Wer", "will", "ihn", "mis\u00b7sen", "?", "Wer", "er\u00b7set\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "PWS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Doch ob ich tausend Reime mehr,", "tokens": ["Doch", "ob", "ich", "tau\u00b7send", "Rei\u00b7me", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "CARD", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Ob tausend minder hinterlasse:", "tokens": ["Ob", "tau\u00b7send", "min\u00b7der", "hin\u00b7ter\u00b7las\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Wen k\u00fcmmert das? Mich selbst nicht sehr,", "tokens": ["Wen", "k\u00fcm\u00b7mert", "das", "?", "Mich", "selbst", "nicht", "sehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDS", "$.", "PPER", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Am wenigsten die gro\u00dfe Masse", "tokens": ["Am", "we\u00b7nigs\u00b7ten", "die", "gro\u00b7\u00dfe", "Mas\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "PIS", "ART", "ADJA", "NN"], "meter": "-----+-+-", "measure": "unknown.measure.di"}, "line.31": {"text": "Der Nation.", "tokens": ["Der", "Na\u00b7tion", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.32": {"text": "\u00bbnun gut! Allein", "tokens": ["\u00bb", "nun", "gut", "!", "Al\u00b7lein"], "token_info": ["punct", "word", "word", "punct", "word"], "pos": ["$(", "ADV", "ADJD", "$.", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.33": {"text": "Es macht dem Philosophen Ehre", "tokens": ["Es", "macht", "dem", "Phi\u00b7lo\u00b7so\u00b7phen", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Mit seinem Gl\u00fcck' zufrieden seyn;", "tokens": ["Mit", "sei\u00b7nem", "Gl\u00fcck", "zu\u00b7frie\u00b7den", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Denn Rang und Titel sind Chim\u00e4re!\u00ab", "tokens": ["Denn", "Rang", "und", "Ti\u00b7tel", "sind", "Chi\u00b7m\u00e4\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Das hab' ich immer selbst geglaubt;", "tokens": ["Das", "hab'", "ich", "im\u00b7mer", "selbst", "ge\u00b7glaubt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Doch folgt daraus: Es sey erlaubt,", "tokens": ["Doch", "folgt", "da\u00b7raus", ":", "Es", "sey", "er\u00b7laubt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Blo\u00df nach Bequemlichkeit zu leben,", "tokens": ["Blo\u00df", "nach", "Be\u00b7quem\u00b7lich\u00b7keit", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Bevor um das gesenkte Haupt", "tokens": ["Be\u00b7vor", "um", "das", "ge\u00b7senk\u00b7te", "Haupt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Noch d\u00fcnne Silberlocken schweben?", "tokens": ["Noch", "d\u00fcn\u00b7ne", "Sil\u00b7berl\u00b7o\u00b7cken", "schwe\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Soll, wer aus Neigung oder Noth,", "tokens": ["Soll", ",", "wer", "aus", "Nei\u00b7gung", "o\u00b7der", "Noth", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Nach irgend einem Ziele strebte,", "tokens": ["Nach", "ir\u00b7gend", "ei\u00b7nem", "Zie\u00b7le", "streb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Der Auster gleich, nur da den Tod", "tokens": ["Der", "Aus\u00b7ter", "gleich", ",", "nur", "da", "den", "Tod"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Erwarten, wo er fest sich klebte?", "tokens": ["Er\u00b7war\u00b7ten", ",", "wo", "er", "fest", "sich", "kleb\u00b7te", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "VVFIN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Soll er vom erstern, nahen Ziel',", "tokens": ["Soll", "er", "vom", "ers\u00b7tern", ",", "na\u00b7hen", "Ziel'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Wenn edler Muth und Kraftgef\u00fchl", "tokens": ["Wenn", "ed\u00b7ler", "Muth", "und", "Kraft\u00b7ge\u00b7f\u00fchl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Ihm des entferntern Preis verhei\u00dfen,", "tokens": ["Ihm", "des", "ent\u00b7fern\u00b7tern", "Preis", "ver\u00b7hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Nicht wagen, k\u00fchn sich loszurei\u00dfen?", "tokens": ["Nicht", "wa\u00b7gen", ",", "k\u00fchn", "sich", "los\u00b7zu\u00b7rei\u00b7\u00dfen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,", "ADJD", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Erkriecht die\u00df ferne Ziel der Thor", "tokens": ["Er\u00b7kriecht", "die\u00df", "fer\u00b7ne", "Ziel", "der", "Thor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PDS", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Um Titel, Rang und Friedrichsdor:", "tokens": ["Um", "Ti\u00b7tel", ",", "Rang", "und", "Fried\u00b7richs\u00b7dor", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Gibt's darum keine be\u00dfre Preise?", "tokens": ["Gibt's", "da\u00b7rum", "kei\u00b7ne", "be\u00df\u00b7re", "Prei\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.52": {"text": "Nur Zeit und Kraft bezahlt der Staat,", "tokens": ["Nur", "Zeit", "und", "Kraft", "be\u00b7zahlt", "der", "Staat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.53": {"text": "Durch Selbstbewu\u00dftseyn guter That", "tokens": ["Durch", "Selbst\u00b7be\u00b7wu\u00df\u00b7tseyn", "gu\u00b7ter", "That"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "Bezahlt sich selbst die That der Weise.", "tokens": ["Be\u00b7zahlt", "sich", "selbst", "die", "That", "der", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.55": {"text": "Mich sch\u00e4men sollt' ich billig wohl,", "tokens": ["Mich", "sch\u00e4\u00b7men", "sollt'", "ich", "bil\u00b7lig", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VMFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "Nun in der Hauptstadt gar zu leben?", "tokens": ["Nun", "in", "der", "Haupt\u00b7stadt", "gar", "zu", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "Und strenger Moralisten Groll", "tokens": ["Und", "stren\u00b7ger", "Mo\u00b7ra\u00b7lis\u00b7ten", "Groll"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Darf, scheint es, mir es nie vergeben,", "tokens": ["Darf", ",", "scheint", "es", ",", "mir", "es", "nie", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "VVFIN", "PPER", "$,", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.59": {"text": "So hoch hinauf geklimmt zu seyn?", "tokens": ["So", "hoch", "hin\u00b7auf", "ge\u00b7klimmt", "zu", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Was aber kann ich f\u00fcr den Schein?", "tokens": ["Was", "a\u00b7ber", "kann", "ich", "f\u00fcr", "den", "Schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Nie hatte meine Phantasie", "tokens": ["Nie", "hat\u00b7te", "mei\u00b7ne", "Phan\u00b7ta\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Sich beides je zum Ziel' erkohren;", "tokens": ["Sich", "bei\u00b7des", "je", "zum", "Ziel'", "er\u00b7koh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIS", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.63": {"text": "Noch mehr: Um beides hab' ich nie", "tokens": ["Noch", "mehr", ":", "Um", "bei\u00b7des", "hab'", "ich", "nie"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "APPR", "PIS", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Ein Wort, selbst keinen Wunsch verloren.", "tokens": ["Ein", "Wort", ",", "selbst", "kei\u00b7nen", "Wunsch", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "Da\u00df ich dem ehrenhaften Winke", "tokens": ["Da\u00df", "ich", "dem", "eh\u00b7ren\u00b7haf\u00b7ten", "Win\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.66": {"text": "Des K\u00f6nigs folgt': Ist die\u00df ein Grund,", "tokens": ["Des", "K\u00f6\u00b7nigs", "folgt'", ":", "Ist", "die\u00df", "ein", "Grund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VAFIN", "PDS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Da\u00df ich in deiner Achtung sinke?", "tokens": ["Da\u00df", "ich", "in", "dei\u00b7ner", "Ach\u00b7tung", "sin\u00b7ke", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "Und dieses machst der Welt du kund?", "tokens": ["Und", "die\u00b7ses", "machst", "der", "Welt", "du", "kund", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Doch sicher wird es dich gereuen,", "tokens": ["Doch", "si\u00b7cher", "wird", "es", "dich", "ge\u00b7reu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.70": {"text": "Und Rang und Titel mir verzeihen,", "tokens": ["Und", "Rang", "und", "Ti\u00b7tel", "mir", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.71": {"text": "Kommst du nur selber nach ", "tokens": ["Kommst", "du", "nur", "sel\u00b7ber", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.72": {"text": "Und findest, da\u00df ich hier geblieben,", "tokens": ["Und", "fin\u00b7dest", ",", "da\u00df", "ich", "hier", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "Was ich zu seyn in ", "tokens": ["Was", "ich", "zu", "seyn", "in"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKZU", "VAINF", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.74": {"text": "Und da\u00df mich alle die noch lieben,", "tokens": ["Und", "da\u00df", "mich", "al\u00b7le", "die", "noch", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "ART", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.75": {"text": "Die irgend mich geliebt zuvor.", "tokens": ["Die", "ir\u00b7gend", "mich", "ge\u00b7liebt", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "VVPP", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.76": {"text": "Wer, vorw\u00e4rts von dem Gl\u00fcck' getrieben,", "tokens": ["Wer", ",", "vor\u00b7w\u00e4rts", "von", "dem", "Gl\u00fcck", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.77": {"text": "Die Weisheit unterwegs verlor,", "tokens": ["Die", "Weis\u00b7heit", "un\u00b7ter\u00b7wegs", "ver\u00b7lor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "H\u00e4tt' er wie Salomo zuvor", "tokens": ["H\u00e4tt'", "er", "wie", "Sa\u00b7lo\u00b7mo", "zu\u00b7vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KOKOM", "NE", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.79": {"text": "Auch gleich geredet und geschrieben,", "tokens": ["Auch", "gleich", "ge\u00b7re\u00b7det", "und", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.80": {"text": "Ward drum nicht weniger ein Thor.", "tokens": ["Ward", "drum", "nicht", "we\u00b7ni\u00b7ger", "ein", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "PTKNEG", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}