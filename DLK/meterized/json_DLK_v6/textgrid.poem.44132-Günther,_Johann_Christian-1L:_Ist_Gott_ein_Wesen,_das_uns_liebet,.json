{"textgrid.poem.44132": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ist Gott ein Wesen, das uns liebet,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist Gott ein Wesen, das uns liebet,", "tokens": ["Ist", "Gott", "ein", "We\u00b7sen", ",", "das", "uns", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So wie ich \u00fcberwiesen bin,", "tokens": ["So", "wie", "ich", "\u00fc\u00b7berw\u00b7ie\u00b7sen", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nicht aus Scherz und Eigensinn", "tokens": ["Und", "nicht", "aus", "Scherz", "und", "Ei\u00b7gen\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verfolgung, Trost und Warnung giebet,", "tokens": ["Ver\u00b7fol\u00b7gung", ",", "Trost", "und", "War\u00b7nung", "gie\u00b7bet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist, sag ich, Gott ein Menschenfreund,", "tokens": ["Ist", ",", "sag", "ich", ",", "Gott", "ein", "Men\u00b7schen\u00b7freund", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So wird er mir auch Licht gew\u00e4hren", "tokens": ["So", "wird", "er", "mir", "auch", "Licht", "ge\u00b7w\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und endlich auch den \u00e4rgsten Feind", "tokens": ["Und", "end\u00b7lich", "auch", "den", "\u00e4rgs\u00b7ten", "Feind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Auf dieses mein Gebeth bekehren.", "tokens": ["Auf", "die\u00b7ses", "mein", "Ge\u00b7beth", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Rachgier, so mich treibt, ist, da\u00df ich sehnlich fleh,", "tokens": ["Die", "Rach\u00b7gier", ",", "so", "mich", "treibt", ",", "ist", ",", "da\u00df", "ich", "sehn\u00b7lich", "fleh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df Welt und Neid einmahl mein ehrlich Herze seh.", "tokens": ["Da\u00df", "Welt", "und", "Neid", "ein\u00b7mahl", "mein", "ehr\u00b7lich", "Her\u00b7ze", "seh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "PPOSAT", "ADJD", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Frau, deren Geist und seltne Gaben", "tokens": ["Frau", ",", "de\u00b7ren", "Geist", "und", "selt\u00b7ne", "Ga\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELAT", "NN", "KON", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "An Neigung, Lust und hoher Kraft", "tokens": ["An", "Nei\u00b7gung", ",", "Lust", "und", "ho\u00b7her", "Kraft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu jeder klugen Wi\u00dfenschaft", "tokens": ["Zu", "je\u00b7der", "klu\u00b7gen", "Wi\u00b7\u00dfen\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar wenig ihres gleichen haben,", "tokens": ["Gar", "we\u00b7nig", "ih\u00b7res", "glei\u00b7chen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPOSAT", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Versichre dich der Danckbarkeit", "tokens": ["Ver\u00b7sich\u00b7re", "dich", "der", "Dan\u00b7ck\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Der elternlosen Pierinnen,", "tokens": ["Der", "el\u00b7tern\u00b7lo\u00b7sen", "Pie\u00b7rin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Dein Nachruhm soll von Zeit zu Zeit", "tokens": ["Dein", "Nach\u00b7ruhm", "soll", "von", "Zeit", "zu", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Durch ihre Lieder Glanz gewinnen.", "tokens": ["Durch", "ih\u00b7re", "Lie\u00b7der", "Glanz", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Misgunst lacht dazu, allein die Warheit spricht:", "tokens": ["Die", "Mis\u00b7gunst", "lacht", "da\u00b7zu", ",", "al\u00b7lein", "die", "War\u00b7heit", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$,", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dein gro\u00df Verdienst beseelt, was meiner Kunst gebricht.", "tokens": ["Dein", "gro\u00df", "Ver\u00b7dienst", "be\u00b7seelt", ",", "was", "mei\u00b7ner", "Kunst", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "VVPP", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Es spiegelt sich in deiner H\u00fclfe", "tokens": ["Es", "spie\u00b7gelt", "sich", "in", "dei\u00b7ner", "H\u00fcl\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Herz der Tochter Pharao;", "tokens": ["Das", "Herz", "der", "Toch\u00b7ter", "Pha\u00b7rao", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der Vorwiz fragt: Warum denn so?", "tokens": ["Der", "Vor\u00b7wiz", "fragt", ":", "Wa\u00b7rum", "denn", "so", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWAV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du bist ja wohl kein Kind im Schilfe.", "tokens": ["Du", "bist", "ja", "wohl", "kein", "Kind", "im", "Schil\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ja wohl, die Gr\u00f6\u00dfe der Gefahr", "tokens": ["Ja", "wohl", ",", "die", "Gr\u00f6\u00b7\u00dfe", "der", "Ge\u00b7fahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$,", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bedarf wie Moses g\u00fctger Armen;", "tokens": ["Be\u00b7darf", "wie", "Mo\u00b7ses", "g\u00fct\u00b7ger", "Ar\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich lag und liege ganz und gar,", "tokens": ["Ich", "lag", "und", "lie\u00b7ge", "ganz", "und", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du hast ein gn\u00e4diges Erbarmen;", "tokens": ["Du", "hast", "ein", "gn\u00e4\u00b7di\u00b7ges", "Er\u00b7bar\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ich weine, du erh\u00f6rst und ziehst mich starck und bald,", "tokens": ["Ich", "wei\u00b7ne", ",", "du", "er\u00b7h\u00f6rst", "und", "ziehst", "mich", "starck", "und", "bald", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "KON", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und mitten in der Flucht bekomm ich Aufenthalt.", "tokens": ["Und", "mit\u00b7ten", "in", "der", "Flucht", "be\u00b7komm", "ich", "Auf\u00b7ent\u00b7halt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So scharf ich mich in Thr\u00e4nen gr\u00e4me,", "tokens": ["So", "scharf", "ich", "mich", "in", "Thr\u00e4\u00b7nen", "gr\u00e4\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So \u00e4ngstlich ich verla\u00dfen bin,", "tokens": ["So", "\u00e4ngst\u00b7lich", "ich", "ver\u00b7la\u00b7\u00dfen", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wenig sch\u00e4zt ich den Gewinn,", "tokens": ["So", "we\u00b7nig", "sch\u00e4zt", "ich", "den", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wofern er jezt von dir nicht k\u00e4me;", "tokens": ["Wo\u00b7fern", "er", "jezt", "von", "dir", "nicht", "k\u00e4\u00b7me", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein Ansehn giebt allein den Werth,", "tokens": ["Dein", "An\u00b7sehn", "giebt", "al\u00b7lein", "den", "Werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wornach ich Huld und Gaben sch\u00e4ze.", "tokens": ["Wor\u00b7nach", "ich", "Huld", "und", "Ga\u00b7ben", "sch\u00e4\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich habe mich vorl\u00e4ngst erkl\u00e4rt,", "tokens": ["Ich", "ha\u00b7be", "mich", "vor\u00b7l\u00e4ngst", "er\u00b7kl\u00e4rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df nichts mein Herz in Unruh seze", "tokens": ["Da\u00df", "nichts", "mein", "Herz", "in", "Un\u00b7ruh", "se\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Als dieses, da\u00df ich nicht aus Armuth zeigen kan,", "tokens": ["Als", "die\u00b7ses", ",", "da\u00df", "ich", "nicht", "aus", "Ar\u00b7muth", "zei\u00b7gen", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "KOUS", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ich seh mehr die Person als Werck und Zuwurf an.", "tokens": ["Ich", "seh", "mehr", "die", "Per\u00b7son", "als", "Werck", "und", "Zu\u00b7wurf", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "KOUS", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich habe freilich Jugends\u00fcnden;", "tokens": ["Ich", "ha\u00b7be", "frei\u00b7lich", "Ju\u00b7gend\u00b7s\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist wohl bey viel Thoren klug?", "tokens": ["Wer", "ist", "wohl", "bey", "viel", "Tho\u00b7ren", "klug", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch bin ich auch gestraft genug;", "tokens": ["Doch", "bin", "ich", "auch", "ge\u00b7straft", "ge\u00b7nug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Be\u00dfrung kan Vergebung finden.", "tokens": ["Die", "Be\u00df\u00b7rung", "kan", "Ver\u00b7ge\u00b7bung", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Neider wiegeln alles auf,", "tokens": ["Die", "Nei\u00b7der", "wie\u00b7geln", "al\u00b7les", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Ungl\u00fcck will mit Tagen steigen,", "tokens": ["Das", "Un\u00b7gl\u00fcck", "will", "mit", "Ta\u00b7gen", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich las ihm, wie ich mu\u00df, den Lauf", "tokens": ["Ich", "las", "ihm", ",", "wie", "ich", "mu\u00df", ",", "den", "Lauf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und will nur bey Bekehrung schweigen.", "tokens": ["Und", "will", "nur", "bey", "Be\u00b7keh\u00b7rung", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Der C\u00f6rper ist geschw\u00e4cht, die Jugend schiest dahin;", "tokens": ["Der", "C\u00f6r\u00b7per", "ist", "ge\u00b7schw\u00e4cht", ",", "die", "Ju\u00b7gend", "schiest", "da\u00b7hin", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was schadet's, wenn ich nur im Alter ruhig bin?", "tokens": ["Was", "scha\u00b7det's", ",", "wenn", "ich", "nur", "im", "Al\u00b7ter", "ru\u00b7hig", "bin", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "ADV", "APPRART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Vorsicht, theure Mariane,", "tokens": ["Die", "Vor\u00b7sicht", ",", "theu\u00b7re", "Ma\u00b7ri\u00b7a\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Besch\u00fcze dein geseegnet Haus,", "tokens": ["Be\u00b7sch\u00fc\u00b7ze", "dein", "ge\u00b7seeg\u00b7net", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVPP", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie z\u00fcrne nach den Wellen aus", "tokens": ["Sie", "z\u00fcr\u00b7ne", "nach", "den", "Wel\u00b7len", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und f\u00fchr auch dich die gleichste Bahne.", "tokens": ["Und", "f\u00fchr", "auch", "dich", "die", "gleichs\u00b7te", "Bah\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein gro\u00df- und w\u00fcrdiger Gemahl,", "tokens": ["Dein", "gro\u00df", "und", "w\u00fcr\u00b7di\u00b7ger", "Ge\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den \u00c4mter, Stand und Klugheit k\u00fc\u00dfen,", "tokens": ["Den", "\u00c4m\u00b7ter", ",", "Stand", "und", "Klug\u00b7heit", "k\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wird in der weisen V\u00e4ter Zahl", "tokens": ["Wird", "in", "der", "wei\u00b7sen", "V\u00e4\u00b7ter", "Zahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sein Gl\u00fccke selbst zu mehren wi\u00dfen,", "tokens": ["Sein", "Gl\u00fc\u00b7cke", "selbst", "zu", "meh\u00b7ren", "wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Nachdem man \u00fcberall, so viel ich schon geh\u00f6rt,", "tokens": ["Nach\u00b7dem", "man", "\u00fc\u00b7be\u00b7rall", ",", "so", "viel", "ich", "schon", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "$,", "ADV", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Nahmen seines Ruhms mit Lob und Warheit ehrt.", "tokens": ["Den", "Nah\u00b7men", "sei\u00b7nes", "Ruhms", "mit", "Lob", "und", "War\u00b7heit", "ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}