{"textgrid.poem.49754": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Siegesallee", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn Sie mal nach Berlin reisen,", "tokens": ["Wenn", "Sie", "mal", "nach", "Ber\u00b7lin", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NE", "VVINF", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Hochverehrter, dann vers\u00e4umen Sie nicht zu gehen", "tokens": ["Hoch\u00b7ver\u00b7ehr\u00b7ter", ",", "dann", "ver\u00b7s\u00e4u\u00b7men", "Sie", "nicht", "zu", "ge\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "In die Siegesallee, bei der Bellevuestra\u00dfe;", "tokens": ["In", "die", "Sie\u00b7ge\u00b7sal\u00b7lee", ",", "bei", "der", "Bel\u00b7le\u00b7vue\u00b7stra\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Da k\u00f6nnen Sie etwas wirklich Gediegenes sehen.", "tokens": ["Da", "k\u00f6n\u00b7nen", "Sie", "et\u00b7was", "wirk\u00b7lich", "Ge\u00b7die\u00b7ge\u00b7nes", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADJD", "NN", "VVINF", "$."], "meter": "-+--+-+---+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Andere St\u00e4dte haben ja auch Denkm\u00e4ler,", "tokens": ["An\u00b7de\u00b7re", "St\u00e4d\u00b7te", "ha\u00b7ben", "ja", "auch", "Denk\u00b7m\u00e4\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Aber h\u00f6chstens ein bis anderthalb Dutzend,", "tokens": ["A\u00b7ber", "h\u00f6chs\u00b7tens", "ein", "bis", "an\u00b7der\u00b7thalb", "Dut\u00b7zend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wenn Sie jedoch diesen Haufen beisammen erblicken,", "tokens": ["Wenn", "Sie", "je\u00b7doch", "die\u00b7sen", "Hau\u00b7fen", "bei\u00b7sam\u00b7men", "er\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PDAT", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Mein Lieber, da werden Sie wirklich stutzend.", "tokens": ["Mein", "Lie\u00b7ber", ",", "da", "wer\u00b7den", "Sie", "wirk\u00b7lich", "stut\u00b7zend", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Ich glaube, es sind auf jeder Seite zwanzig.", "tokens": ["Ich", "glau\u00b7be", ",", "es", "sind", "auf", "je\u00b7der", "Sei\u00b7te", "zwan\u00b7zig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PIAT", "NN", "CARD", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Jeder hat einen S\u00e4bel oder einen Hirschf\u00e4nger,", "tokens": ["Je\u00b7der", "hat", "ei\u00b7nen", "S\u00e4\u00b7bel", "o\u00b7der", "ei\u00b7nen", "Hirschf\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und mit der andern Hand macht er eine sch\u00f6ne Bewegung,", "tokens": ["Und", "mit", "der", "an\u00b7dern", "Hand", "macht", "er", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Be\u00b7we\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wie ein Kunstreiter oder wie ein Operns\u00e4nger.", "tokens": ["Wie", "ein", "Kuns\u00b7trei\u00b7ter", "o\u00b7der", "wie", "ein", "O\u00b7pern\u00b7s\u00e4n\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "KON", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Jeder tut so, als wollte er eben sagen", "tokens": ["Je\u00b7der", "tut", "so", ",", "als", "woll\u00b7te", "er", "e\u00b7ben", "sa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "$,", "KOUS", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-++--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Sehr bedeutende, historische Worte.", "tokens": ["Sehr", "be\u00b7deu\u00b7ten\u00b7de", ",", "his\u00b7to\u00b7ri\u00b7sche", "Wor\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+--+---+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Die ganze Gruppe ist sch\u00f6n wei\u00df und proper verfertigt,", "tokens": ["Die", "gan\u00b7ze", "Grup\u00b7pe", "ist", "sch\u00f6n", "wei\u00df", "und", "pro\u00b7per", "ver\u00b7fer\u00b7tigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "VVFIN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wie von einem Konditor auf einer Hochzeitstorte.", "tokens": ["Wie", "von", "ei\u00b7nem", "Kon\u00b7di\u00b7tor", "auf", "ei\u00b7ner", "Hoch\u00b7zeits\u00b7tor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.5": {"line.1": {"text": "Am besten ist es, wenn Sie eine Droschke ben\u00fctzen", "tokens": ["Am", "bes\u00b7ten", "ist", "es", ",", "wenn", "Sie", "ei\u00b7ne", "Droschke", "be\u00b7n\u00fct\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKA", "ADJD", "VAFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und zuerst die eine Reihe hinunterfahren,", "tokens": ["Und", "zu\u00b7erst", "die", "ei\u00b7ne", "Rei\u00b7he", "hin\u00b7un\u00b7ter\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ART", "NN", "VVINF", "$,"], "meter": "--+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wenn Sie den Maskenball rechts werden gesehen haben,", "tokens": ["Wenn", "Sie", "den", "Mas\u00b7ken\u00b7ball", "rechts", "wer\u00b7den", "ge\u00b7se\u00b7hen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VAFIN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "K\u00f6nnen Sie sich vielleicht die linke Seite ersparen.", "tokens": ["K\u00f6n\u00b7nen", "Sie", "sich", "viel\u00b7leicht", "die", "lin\u00b7ke", "Sei\u00b7te", "er\u00b7spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}}, "stanza.6": {"line.1": {"text": "Wenn Sie aber dennoch den Anblick riskieren,", "tokens": ["Wenn", "Sie", "a\u00b7ber", "den\u00b7noch", "den", "An\u00b7blick", "ris\u00b7kie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "So d\u00fcrfen Sie nicht \u00fcberm\u00e4\u00dfig erschrecken,", "tokens": ["So", "d\u00fcr\u00b7fen", "Sie", "nicht", "\u00fc\u00b7berm\u00b7\u00e4\u00b7\u00dfig", "er\u00b7schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wenn unterwegs das Pferd mitsamt dem Inhaber", "tokens": ["Wenn", "un\u00b7ter\u00b7wegs", "das", "Pferd", "mit\u00b7samt", "dem", "In\u00b7ha\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sollte vielleicht an der Drehkrankheit verrecken.", "tokens": ["Soll\u00b7te", "viel\u00b7leicht", "an", "der", "Dreh\u00b7krank\u00b7heit", "ver\u00b7re\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}}}}