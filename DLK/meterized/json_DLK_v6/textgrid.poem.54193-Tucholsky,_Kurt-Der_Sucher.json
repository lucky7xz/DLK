{"textgrid.poem.54193": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der Sucher", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Such \u2013 such", "tokens": ["Such", "\u2013", "such"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "XY"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "suche immer nach dem Geld.", "tokens": ["su\u00b7che", "im\u00b7mer", "nach", "dem", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann kommt es an.", "tokens": ["Dann", "kommt", "es", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Such \u2013 such", "tokens": ["Such", "\u2013", "such"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "XY"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "such es auf der ganzen Welt!", "tokens": ["such", "es", "auf", "der", "gan\u00b7zen", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Denk immer dran!", "tokens": ["Denk", "im\u00b7mer", "dran", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Krieche ihm nach.", "tokens": ["Krie\u00b7che", "ihm", "nach", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Leck auf seine Spur!", "tokens": ["Leck", "auf", "sei\u00b7ne", "Spur", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Sei nicht schwach \u2013", "tokens": ["Sei", "nicht", "schwach", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "denk immer nur:", "tokens": ["denk", "im\u00b7mer", "nur", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Verdienen! Verdienen! Verdienen!", "tokens": ["Ver\u00b7die\u00b7nen", "!", "Ver\u00b7die\u00b7nen", "!", "Ver\u00b7die\u00b7nen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.12": {"text": "Verdienen! Verdienen! Verdienen!", "tokens": ["Ver\u00b7die\u00b7nen", "!", "Ver\u00b7die\u00b7nen", "!", "Ver\u00b7die\u00b7nen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Ernst ist die Spekulation.", "tokens": ["Ernst", "ist", "die", "Spe\u00b7ku\u00b7la\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Aber lieben \u2013 aber lieben \u2013", "tokens": ["A\u00b7ber", "lie\u00b7ben", "\u2013", "a\u00b7ber", "lie\u00b7ben", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "aber lieben mu\u00dft du es schon.", "tokens": ["a\u00b7ber", "lie\u00b7ben", "mu\u00dft", "du", "es", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "PPER", "PPER", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.2": {"line.1": {"text": "Such \u2013 such", "tokens": ["Such", "\u2013", "such"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "XY"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "suche immer den Erfolg.", "tokens": ["su\u00b7che", "im\u00b7mer", "den", "Er\u00b7folg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Dann kommt er an.", "tokens": ["Dann", "kommt", "er", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Pfeif \u2013 pfeif \u2013", "tokens": ["Pfeif", "\u2013", "pfeif", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "VVIMP", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "pfeife auf das ganze Volk!", "tokens": ["pfei\u00b7fe", "auf", "das", "gan\u00b7ze", "Volk", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Tritt auf den Vordermann!", "tokens": ["Tritt", "auf", "den", "Vor\u00b7der\u00b7mann", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Schmeichle der Macht!", "tokens": ["Schmeich\u00b7le", "der", "Macht", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Sag immer Ja.", "tokens": ["Sag", "im\u00b7mer", "Ja", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKANT", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Bei Tag und bei Nacht", "tokens": ["Bei", "Tag", "und", "bei", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Halleluja \u2013 Hurra!", "tokens": ["Hal\u00b7le\u00b7lu\u00b7ja", "\u2013", "Hur\u00b7ra", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "ITJ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "Nach oben! Nach oben! Nach oben!", "tokens": ["Nach", "o\u00b7ben", "!", "Nach", "o\u00b7ben", "!", "Nach", "o\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "$.", "APPR", "ADV", "$.", "APPR", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.12": {"text": "Nach oben! Nach oben! Nach oben!", "tokens": ["Nach", "o\u00b7ben", "!", "Nach", "o\u00b7ben", "!", "Nach", "o\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "$.", "APPR", "ADV", "$.", "APPR", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Geld winkt dir als Lohn.", "tokens": ["Geld", "winkt", "dir", "als", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "KOUS", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Aber lieben \u2013 aber lieben \u2013", "tokens": ["A\u00b7ber", "lie\u00b7ben", "\u2013", "a\u00b7ber", "lie\u00b7ben", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "aber lieben mu\u00dft du es schon.", "tokens": ["a\u00b7ber", "lie\u00b7ben", "mu\u00dft", "du", "es", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "PPER", "PPER", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Such \u2013 such", "tokens": ["Such", "\u2013", "such"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "XY"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "suche immer nach dem Gl\u00fcck.", "tokens": ["su\u00b7che", "im\u00b7mer", "nach", "dem", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann kommt es \u2013 wenn es will.", "tokens": ["Dann", "kommt", "es", "\u2013", "wenn", "es", "will", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Dein Herz", "tokens": ["Dein", "Herz"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "ist ein Serienst\u00fcck; einmal steht es still.", "tokens": ["ist", "ein", "Se\u00b7ri\u00b7en\u00b7st\u00fcck", ";", "ein\u00b7mal", "steht", "es", "still", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Wenn du dich dann nach dem goldnen Tanz", "tokens": ["Wenn", "du", "dich", "dann", "nach", "dem", "gold\u00b7nen", "Tanz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "pr\u00e4sentierst", "tokens": ["pr\u00e4\u00b7sen\u00b7tierst"], "token_info": ["word"], "pos": ["ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "zur gro\u00dfen Bilanz:", "tokens": ["zur", "gro\u00b7\u00dfen", "Bi\u00b7lanz", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "\u00bbich hoffe, man wird mich hier loben!", "tokens": ["\u00bb", "ich", "hof\u00b7fe", ",", "man", "wird", "mich", "hier", "lo\u00b7ben", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PIS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Da unten lag ich immer oben!\u00ab", "tokens": ["Da", "un\u00b7ten", "lag", "ich", "im\u00b7mer", "o\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Kann sein, da\u00df DIE STIMME spricht:", "tokens": ["Kann", "sein", ",", "da\u00df", "DiE", "StIM\u00b7ME", "spricht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "$,", "KOUS", "NE", "NE", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Mensch, dein Leben \u2013", "tokens": ["Mensch", ",", "dein", "Le\u00b7ben", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Mensch, dein Leben \u2013", "tokens": ["Mensch", ",", "dein", "Le\u00b7ben", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.14": {"text": "Ja, ein Leben war das nicht.", "tokens": ["Ja", ",", "ein", "Le\u00b7ben", "war", "das", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "PDS", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}