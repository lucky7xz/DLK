{"textgrid.poem.48258": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Arm oder reich", "genre": "verse", "period": "N.A.", "pub_year": 1895, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbsagen Sie, sind Sie dem lieben Gold", "tokens": ["\u00bb", "sa\u00b7gen", "Sie", ",", "sind", "Sie", "dem", "lie\u00b7ben", "Gold"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "In der Tat so wenig hold,", "tokens": ["In", "der", "Tat", "so", "we\u00b7nig", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Blicken Sie wirklich, fast stolz, auf die H\u00fcter,", "tokens": ["Bli\u00b7cken", "Sie", "wirk\u00b7lich", ",", "fast", "stolz", ",", "auf", "die", "H\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "$,", "ADV", "ADJD", "$,", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Aller m\u00f6glichen irdischen G\u00fcter,", "tokens": ["Al\u00b7ler", "m\u00f6g\u00b7li\u00b7chen", "ir\u00b7di\u00b7schen", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "ADJA", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Ist der Kohinoor, dieser \u203aBerg des Lichts\u2039,", "tokens": ["Ist", "der", "Ko\u00b7hi\u00b7no\u00b7or", ",", "die\u00b7ser", "\u203a", "Berg", "des", "Lichts", "\u2039", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PDAT", "ADJA", "NN", "ART", "NN", "$(", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Ihnen allen Ernstes nichts?\u00ab", "tokens": ["Ih\u00b7nen", "al\u00b7len", "Erns\u00b7tes", "nichts", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PIAT", "NN", "PIS", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "So stellen zuzeiten die Fragen sich ein,", "tokens": ["So", "stel\u00b7len", "zu\u00b7zei\u00b7ten", "die", "Fra\u00b7gen", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VVFIN", "ART", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "Und ich sage dann \u00bbja\u00ab und sag' auch \u00bbnein\u00ab.", "tokens": ["Und", "ich", "sa\u00b7ge", "dann", "\u00bb", "ja", "\u00ab", "und", "sag'", "auch", "\u00bb", "nein", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$(", "PTKANT", "$(", "KON", "VVFIN", "ADV", "$(", "PTKANT", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wie meistens hierlandes die Dinge liegen,", "tokens": ["Wie", "meis\u00b7tens", "hier\u00b7lan\u00b7des", "die", "Din\u00b7ge", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Bei dem Spatzenflug, den unsre Adler fliegen", "tokens": ["Bei", "dem", "Spat\u00b7zen\u00b7flug", ",", "den", "uns\u00b7re", "Ad\u00b7ler", "flie\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "(nicht viel h\u00f6her als ein Scheunentor),", "tokens": ["(", "nicht", "viel", "h\u00f6\u00b7her", "als", "ein", "Scheu\u00b7nen\u00b7tor", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKNEG", "ADV", "ADJD", "KOKOM", "ART", "NN", "$(", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Zieh' ich das Armsein entschieden vor.", "tokens": ["Zieh'", "ich", "das", "Arm\u00b7sein", "ent\u00b7schie\u00b7den", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Dies Armsein ist mir schon deshalb genehmer,", "tokens": ["Dies", "Arm\u00b7sein", "ist", "mir", "schon", "des\u00b7halb", "ge\u00b7neh\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PPER", "ADV", "PAV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil f\u00fcr den Alltag um vieles bequemer.", "tokens": ["Weil", "f\u00fcr", "den", "All\u00b7tag", "um", "vie\u00b7les", "be\u00b7que\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "APPR", "PIS", "ADJD", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Von Vettern und Verwandtenhaufen", "tokens": ["Von", "Vet\u00b7tern", "und", "Ver\u00b7wand\u00b7ten\u00b7hau\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Werd' ich nie und nimmer belaufen,", "tokens": ["Werd'", "ich", "nie", "und", "nim\u00b7mer", "be\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "KON", "ADV", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Es gibt \u2013 und daf\u00fcr will Dank ich zollen \u2013", "tokens": ["Es", "gibt", "\u2013", "und", "da\u00b7f\u00fcr", "will", "Dank", "ich", "zol\u00b7len", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KON", "PAV", "VMFIN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Keine Menschen, die irgend was von mir wollen,", "tokens": ["Kei\u00b7ne", "Men\u00b7schen", ",", "die", "ir\u00b7gend", "was", "von", "mir", "wol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "ADV", "PWS", "APPR", "PPER", "VMFIN", "$,"], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Ich h\u00f6re nur selten der Glocke Ton,", "tokens": ["Ich", "h\u00f6\u00b7re", "nur", "sel\u00b7ten", "der", "Glo\u00b7cke", "Ton", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Keiner ruft mich ans Telefon,", "tokens": ["Kei\u00b7ner", "ruft", "mich", "ans", "Te\u00b7le\u00b7fon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "Ich kenne kein Hasten und kenne kein Streben", "tokens": ["Ich", "ken\u00b7ne", "kein", "Has\u00b7ten", "und", "ken\u00b7ne", "kein", "Stre\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "KON", "VVFIN", "PIAT", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Und kann jeden Tag mir selber leben.", "tokens": ["Und", "kann", "je\u00b7den", "Tag", "mir", "sel\u00b7ber", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Und doch, wenn ich irgend etwas geschrieben,", "tokens": ["Und", "doch", ",", "wenn", "ich", "ir\u00b7gend", "et\u00b7was", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das, weil niemand es will, mir liegen geblieben,", "tokens": ["Das", ",", "weil", "nie\u00b7mand", "es", "will", ",", "mir", "lie\u00b7gen", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PIS", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "VVPP", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Oder wenn ich Druckfehler ausgereutet,", "tokens": ["O\u00b7der", "wenn", "ich", "Druck\u00b7feh\u00b7ler", "aus\u00b7ge\u00b7reu\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+++-+-+-", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Da wei\u00df ich recht wohl, was Geld bedeutet,", "tokens": ["Da", "wei\u00df", "ich", "recht", "wohl", ",", "was", "Geld", "be\u00b7deu\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$,", "PWS", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und wenn man trotzdem, zu dieser Frist,", "tokens": ["Und", "wenn", "man", "trotz\u00b7dem", ",", "zu", "die\u00b7ser", "Frist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PAV", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Den Respekt vor dem Gelde bei mir vermi\u00dft,", "tokens": ["Den", "Res\u00b7pekt", "vor", "dem", "Gel\u00b7de", "bei", "mir", "ver\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "So liegt das daran ganz allein:", "tokens": ["So", "liegt", "das", "da\u00b7ran", "ganz", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PAV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich finde die Summen hier immer zu klein.", "tokens": ["Ich", "fin\u00b7de", "die", "Sum\u00b7men", "hier", "im\u00b7mer", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Was, um mich herum hier, mit Golde sich ziert,", "tokens": ["Was", ",", "um", "mich", "he\u00b7rum", "hier", ",", "mit", "Gol\u00b7de", "sich", "ziert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "KOUI", "PRF", "APZR", "ADV", "$,", "APPR", "NN", "PRF", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ist meistens derartig, da\u00df mich's geniert;", "tokens": ["Ist", "meis\u00b7tens", "der\u00b7ar\u00b7tig", ",", "da\u00df", "mich's", "ge\u00b7niert", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "KOUS", "PIS", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der Gr\u00fcnkramh\u00e4ndler, der Wei\u00dfbierbudiker,", "tokens": ["Der", "Gr\u00fcn\u00b7kram\u00b7h\u00e4nd\u00b7ler", ",", "der", "Wei\u00df\u00b7bier\u00b7bu\u00b7di\u00b7ker", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Tantenbecourer, der Erbschaftsschlieker,", "tokens": ["Der", "Tan\u00b7ten\u00b7be\u00b7cou\u00b7rer", ",", "der", "Erb\u00b7schafts\u00b7schlie\u00b7ker", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Der Z\u00fcchter von Southdownhammelherden,", "tokens": ["Der", "Z\u00fcch\u00b7ter", "von", "South\u00b7do\u00b7wn\u00b7ham\u00b7mel\u00b7her\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Hoppegartenbarone mit Rennstallpferden,", "tokens": ["Hop\u00b7pe\u00b7gar\u00b7ten\u00b7ba\u00b7ro\u00b7ne", "mit", "Renn\u00b7stall\u00b7pfer\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$,"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Wuchrer, hochfahrend und untert\u00e4nig \u2013", "tokens": ["Wuch\u00b7rer", ",", "hoch\u00b7fah\u00b7rend", "und", "un\u00b7ter\u00b7t\u00e4\u00b7nig", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "ADJD", "$("], "meter": "+-++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Sie haben mir alle viel viel zu wenig.", "tokens": ["Sie", "ha\u00b7ben", "mir", "al\u00b7le", "viel", "viel", "zu", "we\u00b7nig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "ADV", "ADV", "PTKA", "PIS", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Beginnt erst beim F\u00fcrsten Demidoff,", "tokens": ["Be\u00b7ginnt", "erst", "beim", "F\u00fcrs\u00b7ten", "De\u00b7mi\u00b7doff", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bei Yussupoff und bei Dolgorucky,", "tokens": ["Bei", "Y\u00b7us\u00b7su\u00b7poff", "und", "bei", "Dol\u00b7go\u00b7ru\u00b7cky", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "APPR", "NE", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Bei Sklavenhaltern aus S\u00fcd-Kentucky,", "tokens": ["Bei", "Skla\u00b7ven\u00b7hal\u00b7tern", "aus", "S\u00fcd\u00b7Ken\u00b7tu\u00b7cky", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Bei Mackay und Gould, bei Bennet und Astor,", "tokens": ["Bei", "Mac\u00b7kay", "und", "Gould", ",", "bei", "Ben\u00b7net", "und", "As\u00b7tor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,", "APPR", "NE", "KON", "NN", "$,"], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "\u2013 Hierlandes schmeckt alles nach Hungerpastor \u2013", "tokens": ["\u2013", "Hier\u00b7lan\u00b7des", "schmeckt", "al\u00b7les", "nach", "Hun\u00b7ger\u00b7pas\u00b7tor", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "PIS", "APPR", "NN", "$("], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Erst in der H\u00f6he von Van der Bilt", "tokens": ["Erst", "in", "der", "H\u00f6\u00b7he", "von", "Van", "der", "Bilt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "NE", "ART", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Seh' ich ", "tokens": ["Seh'", "ich"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Der Nil m\u00fc\u00dfte durch ein Nil-Reich laufen,", "tokens": ["Der", "Nil", "m\u00fc\u00df\u00b7te", "durch", "ein", "Nil\u00b7Reich", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "China w\u00fcrd' ich meistbietend verkaufen,", "tokens": ["Chi\u00b7na", "w\u00fcrd'", "ich", "meist\u00b7bie\u00b7tend", "ver\u00b7kau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Einen Gro\u00df-Admiral w\u00fcrd' ich morgen ernennen,", "tokens": ["Ei\u00b7nen", "Gro\u00df\u00b7Ad\u00b7mi\u00b7ral", "w\u00fcrd'", "ich", "mor\u00b7gen", "er\u00b7nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.11": {"text": "Der m\u00fc\u00dfte die englische Flotte verbrennen,", "tokens": ["Der", "m\u00fc\u00df\u00b7te", "die", "eng\u00b7li\u00b7sche", "Flot\u00b7te", "ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.12": {"text": "Auf da\u00df, Gott segne seine H\u00e4nde,", "tokens": ["Auf", "da\u00df", ",", "Gott", "seg\u00b7ne", "sei\u00b7ne", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "$,", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Das Kattun-Christentum aus der Welt verschw\u00e4nde.", "tokens": ["Das", "Kat\u00b7tun\u00b7Chris\u00b7ten\u00b7tum", "aus", "der", "Welt", "ver\u00b7schw\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Sonst bin ich f\u00fcr Brot in die Suppe brocken.", "tokens": ["Sonst", "bin", "ich", "f\u00fcr", "Brot", "in", "die", "Sup\u00b7pe", "bro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}}}}