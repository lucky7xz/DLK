{"dta.poem.3274": {"metadata": {"author": {"name": "Uz, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Magister Duns.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1755", "urn": "urn:nbn:de:kobv:b4-20614-6", "language": ["de:0.99"], "booktitle": "Uz, Johann Peter: Lyrische und andere Gedichte. 2. Aufl. Ansbach, 1755."}, "poem": {"stanza.1": {"line.1": {"text": "Magister Duns, das grosse Licht,", "tokens": ["Ma\u00b7gis\u00b7ter", "Duns", ",", "das", "gros\u00b7se", "Licht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des deutschen Pindus Ehre,", "tokens": ["Des", "deut\u00b7schen", "Pin\u00b7dus", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Dichter, dessen Muse spricht,", "tokens": ["Der", "Dich\u00b7ter", ",", "des\u00b7sen", "Mu\u00b7se", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie seine Dingerlehre;", "tokens": ["Wie", "sei\u00b7ne", "Din\u00b7ger\u00b7leh\u00b7re", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der lauter Metaphysik ist,", "tokens": ["Der", "lau\u00b7ter", "Me\u00b7ta\u00b7phy\u00b7sik", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und metaphysisch lacht und k\u00fc\u00dft;", "tokens": ["Und", "me\u00b7ta\u00b7phy\u00b7sisch", "lacht", "und", "k\u00fc\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Lie\u00df j\u00fcngst bey seiner Sch\u00f6nen", "tokens": ["Lie\u00df", "j\u00fcngst", "bey", "sei\u00b7ner", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ein z\u00e4rtlich Lied ert\u00f6nen.", "tokens": ["Ein", "z\u00e4rt\u00b7lich", "Lied", "er\u00b7t\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Er sang: o Schmuck der besten Welt!", "tokens": ["Er", "sang", ":", "o", "Schmuck", "der", "bes\u00b7ten", "Welt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "FM", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Vorwurf meiner Liebe!", "tokens": ["Du", "Vor\u00b7wurf", "mei\u00b7ner", "Lie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dein Aug ists, das den Grund enth\u00e4lt", "tokens": ["Dein", "Aug", "ists", ",", "das", "den", "Grund", "ent\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Daseyn meiner Triebe.", "tokens": ["Vom", "Da\u00b7seyn", "mei\u00b7ner", "Trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.5": {"text": "Die Monas, die in mir gedenkt,", "tokens": ["Die", "Mo\u00b7nas", ",", "die", "in", "mir", "ge\u00b7denkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vermag, in deinen Reiz versenkt,", "tokens": ["Ver\u00b7mag", ",", "in", "dei\u00b7nen", "Reiz", "ver\u00b7senkt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die blinden Sinnlichkeiten", "tokens": ["Die", "blin\u00b7den", "Sinn\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Nicht l\u00e4nger zu bestreiten.", "tokens": ["Nicht", "l\u00e4n\u00b7ger", "zu", "be\u00b7strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Drauf nannt er gr\u00fcndlich hier und dort", "tokens": ["Drauf", "nannt", "er", "gr\u00fcnd\u00b7lich", "hier", "und", "dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Grund des Widerspruches", "tokens": ["Den", "Grund", "des", "Wi\u00b7der\u00b7spru\u00b7ches"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und noch so manches Modewort,", "tokens": ["Und", "noch", "so", "man\u00b7ches", "Mo\u00b7de\u00b7wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Weisheit manches Buches.", "tokens": ["Die", "Weis\u00b7heit", "man\u00b7ches", "Bu\u00b7ches", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Mann bewies, wie sichs geh\u00f6rt,", "tokens": ["Der", "Mann", "be\u00b7wies", ",", "wie", "sichs", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und bat, abstract und tiefgelehrt,", "tokens": ["Und", "bat", ",", "abs\u00b7tract", "und", "tief\u00b7ge\u00b7lehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch schulgerechte Schl\u00fcsse", "tokens": ["Durch", "schul\u00b7ge\u00b7rech\u00b7te", "Schl\u00fcs\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Um seiner Chloris K\u00fcsse.", "tokens": ["Um", "sei\u00b7ner", "Chlo\u00b7ris", "K\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Das arme Kind erschrack und floh;", "tokens": ["Das", "ar\u00b7me", "Kind", "er\u00b7schrack", "und", "floh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Grazien entsprungen.", "tokens": ["Die", "Gra\u00b7zi\u00b7en", "ent\u00b7sprun\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kein Dichter hatte noch also,", "tokens": ["Kein", "Dich\u00b7ter", "hat\u00b7te", "noch", "al\u00b7so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seit Musen sind, gesungen.", "tokens": ["Seit", "Mu\u00b7sen", "sind", ",", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Bey Hecatens erbleichtem Schein", "tokens": ["Bey", "He\u00b7ca\u00b7tens", "er\u00b7bleich\u00b7tem", "Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "L\u00e4\u00dft murmelnd im erschrocknen Hayn", "tokens": ["L\u00e4\u00dft", "mur\u00b7melnd", "im", "er\u00b7schrock\u00b7nen", "Hayn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Meister im Beschw\u00f6ren", "tokens": ["Ein", "Meis\u00b7ter", "im", "Be\u00b7schw\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Dergleichen Lieder h\u00f6ren.", "tokens": ["Derg\u00b7lei\u00b7chen", "Lie\u00b7der", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Das M\u00e4dchen eilt ins nahe Thal,", "tokens": ["Das", "M\u00e4d\u00b7chen", "eilt", "ins", "na\u00b7he", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus diesem Zauberkreise.", "tokens": ["Aus", "die\u00b7sem", "Zau\u00b7ber\u00b7krei\u00b7se", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da sang Dam\u00f6t von gleicher Qual;", "tokens": ["Da", "sang", "Da\u00b7m\u00f6t", "von", "glei\u00b7cher", "Qual", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nach der Sch\u00e4fer Weise.", "tokens": ["Doch", "nach", "der", "Sch\u00e4\u00b7fer", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sein Lied, bey manchem stillen Ach!", "tokens": ["Sein", "Lied", ",", "bey", "man\u00b7chem", "stil\u00b7len", "Ach", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Flo\u00df heiter, wie der sanfte Bach,", "tokens": ["Flo\u00df", "hei\u00b7ter", ",", "wie", "der", "sanf\u00b7te", "Bach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und flo\u00df ihm aus dem Herzen,", "tokens": ["Und", "flo\u00df", "ihm", "aus", "dem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Der Quelle seiner Schmerzen.", "tokens": ["Der", "Quel\u00b7le", "sei\u00b7ner", "Schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Jhm wollte Chloris nicht entfliehn;", "tokens": ["Jhm", "woll\u00b7te", "Chlo\u00b7ris", "nicht", "ent\u00b7fliehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jhm ward ein Ku\u00df zu Lohne.", "tokens": ["Jhm", "ward", "ein", "Ku\u00df", "zu", "Loh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Musen selbst belohnten ihn", "tokens": ["Die", "Mu\u00b7sen", "selbst", "be\u00b7lohn\u00b7ten", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit einer Myrthenkrone.", "tokens": ["Mit", "ei\u00b7ner", "Myr\u00b7then\u00b7kro\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So sinnlich sch\u00e4tzt man ein Gedicht!", "tokens": ["So", "sinn\u00b7lich", "sch\u00e4tzt", "man", "ein", "Ge\u00b7dicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "O Musen! Musen! wollt ihr nicht", "tokens": ["O", "Mu\u00b7sen", "!", "Mu\u00b7sen", "!", "wollt", "ihr", "nicht"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$.", "NN", "$.", "VMFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vom P\u00f6bel euch entfernen,", "tokens": ["Vom", "P\u00f6\u00b7bel", "euch", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und Metaphystk lernen?", "tokens": ["Und", "Me\u00b7ta\u00b7phystk", "ler\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}