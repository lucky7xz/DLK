{"textgrid.poem.59612": {"metadata": {"author": {"name": "Arndt, Ernst Moritz", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1814, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Geliebtes Eiland, m\u00fctterliche Erde,", "tokens": ["Ge\u00b7lieb\u00b7tes", "Ei\u00b7land", ",", "m\u00fct\u00b7ter\u00b7li\u00b7che", "Er\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo ich von siebzehn sch\u00f6nen Jugendlenzen", "tokens": ["Wo", "ich", "von", "sieb\u00b7zehn", "sch\u00f6\u00b7nen", "Ju\u00b7gend\u00b7len\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die B\u00e4ume und die H\u00fcgel sah bekr\u00e4nzen,", "tokens": ["Die", "B\u00e4u\u00b7me", "und", "die", "H\u00fc\u00b7gel", "sah", "be\u00b7kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "O R\u00fcgen, Land voll lieblicher Geb\u00e4rde!", "tokens": ["O", "R\u00fc\u00b7gen", ",", "Land", "voll", "lieb\u00b7li\u00b7cher", "Ge\u00b7b\u00e4r\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sprich, ob ich je die Taten sehen werde,", "tokens": ["Sprich", ",", "ob", "ich", "je", "die", "Ta\u00b7ten", "se\u00b7hen", "wer\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wovon die Bilder also lieblich gl\u00e4nzen,", "tokens": ["Wo\u00b7von", "die", "Bil\u00b7der", "al\u00b7so", "lieb\u00b7lich", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df ich in andern V\u00f6lkern, andern Grenzen", "tokens": ["Da\u00df", "ich", "in", "an\u00b7dern", "V\u00f6l\u00b7kern", ",", "an\u00b7dern", "Gren\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Stets suchen mu\u00df nach Arbeit und Beschwerde?", "tokens": ["Stets", "su\u00b7chen", "mu\u00df", "nach", "Ar\u00b7beit", "und", "Be\u00b7schwer\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "All deine s\u00fc\u00dfe Sch\u00f6ne mu\u00dft' ich lassen,", "tokens": ["All", "dei\u00b7ne", "s\u00fc\u00b7\u00dfe", "Sch\u00f6\u00b7ne", "mu\u00dft'", "ich", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "All deine holde Stille mu\u00dft' ich fliehen,", "tokens": ["All", "dei\u00b7ne", "hol\u00b7de", "Stil\u00b7le", "mu\u00dft'", "ich", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich mu\u00dft' ein gr\u00f6\u00dfres Vaterland mir suchen.", "tokens": ["Ich", "mu\u00dft'", "ein", "gr\u00f6\u00df\u00b7res", "Va\u00b7ter\u00b7land", "mir", "su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "O diesen Stolz, werd' ich ihn je erfassen?", "tokens": ["O", "die\u00b7sen", "Stolz", ",", "werd'", "ich", "ihn", "je", "er\u00b7fas\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "$,", "VAFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wirst du, Germanien, noch in Freiheit bl\u00fchen,", "tokens": ["Wirst", "du", ",", "Ger\u00b7ma\u00b7ni\u00b7en", ",", "noch", "in", "Frei\u00b7heit", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "NN", "$,", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Wo Sklaven st\u00f6hnen und Tyrannen fluchen?", "tokens": ["Wo", "Skla\u00b7ven", "st\u00f6h\u00b7nen", "und", "Ty\u00b7ran\u00b7nen", "flu\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVINF", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}