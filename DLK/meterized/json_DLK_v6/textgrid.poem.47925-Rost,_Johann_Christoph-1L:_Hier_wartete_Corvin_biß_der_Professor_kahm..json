{"textgrid.poem.47925": {"metadata": {"author": {"name": "Rost, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Hier wartete Corvin bi\u00df der Professor kahm.", "genre": "verse", "period": "N.A.", "pub_year": 1741, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hier wartete Corvin bi\u00df der Professor kahm.", "tokens": ["Hier", "war\u00b7te\u00b7te", "Cor\u00b7vin", "bi\u00df", "der", "Pro\u00b7fes\u00b7sor", "kahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sein Hertz war voller Angst, sein C\u00f6rper lendenlahm.", "tokens": ["Sein", "Hertz", "war", "vol\u00b7ler", "Angst", ",", "sein", "C\u00f6r\u00b7per", "len\u00b7den\u00b7lahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJA", "NN", "$,", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Doch dieses war sein Trost, da\u00df er gescharrt, gepfiffen,", "tokens": ["Doch", "die\u00b7ses", "war", "sein", "Trost", ",", "da\u00df", "er", "ge\u00b7scharrt", ",", "ge\u00b7pfif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPOSAT", "NN", "$,", "KOUS", "PPER", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und eher nicht die Flucht, als erst aus Zwang, ergriffen.", "tokens": ["Und", "e\u00b7her", "nicht", "die", "Flucht", ",", "als", "erst", "aus", "Zwang", ",", "er\u00b7grif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ART", "NN", "$,", "KOUS", "ADV", "APPR", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er stellt, auf gutes Gl\u00fcck, sich dem Professor dar,", "tokens": ["Er", "stellt", ",", "auf", "gu\u00b7tes", "Gl\u00fcck", ",", "sich", "dem", "Pro\u00b7fes\u00b7sor", "dar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bey dem sein redlich Hertz schon l\u00e4ngst entschuldigt war;", "tokens": ["Bey", "dem", "sein", "red\u00b7lich", "Hertz", "schon", "l\u00e4ngst", "ent\u00b7schul\u00b7digt", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "ADJD", "NN", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und bath, zum Uberflu\u00df, ihm nicht die Schuld zu geben.", "tokens": ["Und", "ba\u00b7th", ",", "zum", "U\u00b7ber\u00b7flu\u00df", ",", "ihm", "nicht", "die", "Schuld", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPRART", "NN", "$,", "PPER", "PTKNEG", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "--+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "\u00bbwie konnt ich, sprach Corvin, der Menge wiederstreben!", "tokens": ["\u00bb", "wie", "konnt", "ich", ",", "sprach", "Cor\u00b7vin", ",", "der", "Men\u00b7ge", "wie\u00b7der\u00b7stre\u00b7ben", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "$,", "VVFIN", "NE", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein h\u00e4mischer Student st\u00f6\u00dft, schiebt und dr\u00e4ngt mich fort,", "tokens": ["Ein", "h\u00e4\u00b7mi\u00b7scher", "Stu\u00b7dent", "st\u00f6\u00dft", ",", "schiebt", "und", "dr\u00e4ngt", "mich", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Mit nie gef\u00fchlter Krafft und ohn ein eintzig Wort.", "tokens": ["Mit", "nie", "ge\u00b7f\u00fchl\u00b7ter", "Krafft", "und", "ohn", "ein", "eint\u00b7zig", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "KON", "APPR", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Nachschub lie\u00df mich nicht zum Wiederstande kommen.", "tokens": ["Der", "Nach\u00b7schub", "lie\u00df", "mich", "nicht", "zum", "Wie\u00b7der\u00b7stan\u00b7de", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Pressung hatte mir den Athem gleich benommen;", "tokens": ["Die", "Pres\u00b7sung", "hat\u00b7te", "mir", "den", "A\u00b7them", "gleich", "be\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch spitzt ich noch den Mund, allein er pfiff nicht sehr;", "tokens": ["Doch", "spitzt", "ich", "noch", "den", "Mund", ",", "al\u00b7lein", "er", "pfiff", "nicht", "sehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ADV", "PPER", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zum scharren traf mein Fu\u00df den Boden auch nicht mehr?", "tokens": ["Zum", "schar\u00b7ren", "traf", "mein", "Fu\u00df", "den", "Bo\u00b7den", "auch", "nicht", "mehr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "PPOSAT", "NN", "ART", "NN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Mein Hertz war w\u00fcrcklich gro\u00df, jedoch in dem Gedr\u00e4nge,", "tokens": ["Mein", "Hertz", "war", "w\u00fcrck\u00b7lich", "gro\u00df", ",", "je\u00b7doch", "in", "dem", "Ge\u00b7dr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "ADJD", "$,", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ward sein Beh\u00e4ltni\u00df nur in meiner Brust zu enge.", "tokens": ["Ward", "sein", "Be\u00b7h\u00e4lt\u00b7ni\u00df", "nur", "in", "mei\u00b7ner", "Brust", "zu", "en\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Kaum wei\u00df ich: wie ich noch hieher gekommen bin.", "tokens": ["Kaum", "wei\u00df", "ich", ":", "wie", "ich", "noch", "hie\u00b7her", "ge\u00b7kom\u00b7men", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PWAV", "PPER", "ADV", "PAV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Centaurischer Student! verdammte Reuberin!\u00ab", "tokens": ["Cen\u00b7tau\u00b7ri\u00b7scher", "Stu\u00b7dent", "!", "ver\u00b7damm\u00b7te", "Reu\u00b7be\u00b7rin", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$.", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Zum Zeichen, seine Treu und seinen Muth zu preisen,", "tokens": ["Zum", "Zei\u00b7chen", ",", "sei\u00b7ne", "Treu", "und", "sei\u00b7nen", "Muth", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wollt er Victorien die blauen Flecken weisen.", "tokens": ["Wollt", "er", "Vic\u00b7to\u00b7ri\u00b7en", "die", "blau\u00b7en", "Fle\u00b7cken", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NE", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.21": {"text": "Der rechte Hemden-Knopff war auch schon aufgemacht;", "tokens": ["Der", "rech\u00b7te", "Hem\u00b7den\u00b7Knopff", "war", "auch", "schon", "auf\u00b7ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Doch was Corvin die\u00dfmahl f\u00fcr Eifer nicht bedacht,", "tokens": ["Doch", "was", "Cor\u00b7vin", "die\u00df\u00b7mahl", "f\u00fcr", "Ei\u00b7fer", "nicht", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NE", "ADV", "APPR", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Vermied Victoria. Den d\u00fcrren Arm zu sehen,", "tokens": ["Ver\u00b7mied", "Vic\u00b7to\u00b7ria", ".", "Den", "d\u00fcr\u00b7ren", "Arm", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Lie\u00df hier die Gegenwart des Witzes nicht geschehen.", "tokens": ["Lie\u00df", "hier", "die", "Ge\u00b7gen\u00b7wart", "des", "Wit\u00b7zes", "nicht", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Sie sprach Corvinen zu und lobte seinen Muth,", "tokens": ["Sie", "sprach", "Cor\u00b7vi\u00b7nen", "zu", "und", "lob\u00b7te", "sei\u00b7nen", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und da die That gefehlt, hie\u00df sie den Willen gut.", "tokens": ["Und", "da", "die", "That", "ge\u00b7fehlt", ",", "hie\u00df", "sie", "den", "Wil\u00b7len", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "$,", "VVFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ihr stimmte Gottsched bey, die danckten seiner Treu,", "tokens": ["Ihr", "stimm\u00b7te", "Gott\u00b7sched", "bey", ",", "die", "danck\u00b7ten", "sei\u00b7ner", "Treu", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "$,", "PRELS", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und also blieb Corvin ein Freund der ersten Reihe.", "tokens": ["Und", "al\u00b7so", "blieb", "Cor\u00b7vin", "ein", "Freund", "der", "ers\u00b7ten", "Rei\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NE", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Doch der Professor sprach: Ihr Freunde setzet euch.", "tokens": ["Doch", "der", "Pro\u00b7fes\u00b7sor", "sprach", ":", "Ihr", "Freun\u00b7de", "set\u00b7zet", "euch", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "\u00bbist nicht, den Schweitzern", "tokens": ["\u00bb", "ist", "nicht", ",", "den", "Schweit\u00b7zern"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "VAFIN", "PTKNEG", "$,", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.31": {"text": "Ein Alpenriese schimpfft, in Sachsen wirds bekr\u00e4fftigt,", "tokens": ["Ein", "Al\u00b7pen\u00b7rie\u00b7se", "schimpfft", ",", "in", "Sach\u00b7sen", "wirds", "be\u00b7kr\u00e4ff\u00b7tigt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "APPR", "NE", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Da unser Ebenbild den Schauplatz selbst besch\u00e4fftigt?", "tokens": ["Da", "un\u00b7ser", "E\u00b7ben\u00b7bild", "den", "Schau\u00b7platz", "selbst", "be\u00b7sch\u00e4ff\u00b7tigt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "O Ph\u00f6bus bist auch du zu meiner Rache faul?", "tokens": ["O", "Ph\u00f6\u00b7bus", "bist", "auch", "du", "zu", "mei\u00b7ner", "Ra\u00b7che", "faul", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADV", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wo nicht so zeig es uns: Spann einen Feuergaul", "tokens": ["Wo", "nicht", "so", "zeig", "es", "uns", ":", "Spann", "ei\u00b7nen", "Feu\u00b7er\u00b7gaul"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PTKNEG", "ADV", "VVFIN", "PPER", "PPER", "$.", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Zu meinem Besten aus, damit auf diesem Pferde,", "tokens": ["Zu", "mei\u00b7nem", "Bes\u00b7ten", "aus", ",", "da\u00b7mit", "auf", "die\u00b7sem", "Pfer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "KOUS", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Der Alpen Polyphem von mir bestritten werde.", "tokens": ["Der", "Al\u00b7pen", "Po\u00b7ly\u00b7phem", "von", "mir", "be\u00b7strit\u00b7ten", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ist Bodmer erst bek\u00e4mpfft, so f\u00e4llt der Neuberin,", "tokens": ["Ist", "Bod\u00b7mer", "erst", "be\u00b7k\u00e4mpfft", ",", "so", "f\u00e4llt", "der", "Neu\u00b7be\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Die Blindheit, die sie schl\u00e4gt, auch von den Augen hin.", "tokens": ["Die", "Blind\u00b7heit", ",", "die", "sie", "schl\u00e4gt", ",", "auch", "von", "den", "Au\u00b7gen", "hin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Jedoch wen ruf ich an? den, der mich recht erh\u00f6rte,", "tokens": ["Je\u00b7doch", "wen", "ruf", "ich", "an", "?", "den", ",", "der", "mich", "recht", "er\u00b7h\u00f6r\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PPER", "PTKVZ", "$.", "ART", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.40": {"text": "Mein Bitten selbst verwarf, die L\u00e4strung nicht verwehrte?", "tokens": ["Mein", "Bit\u00b7ten", "selbst", "ver\u00b7warf", ",", "die", "L\u00e4st\u00b7rung", "nicht", "ver\u00b7wehr\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "$,", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Ihr Freunde h\u00f6ret mich: Ich bin des Eifers satt,", "tokens": ["Ihr", "Freun\u00b7de", "h\u00f6\u00b7ret", "mich", ":", "Ich", "bin", "des", "Ei\u00b7fers", "satt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Der f\u00fcr Germanien bisher gefochten hat.", "tokens": ["Der", "f\u00fcr", "Ger\u00b7ma\u00b7ni\u00b7en", "bis\u00b7her", "ge\u00b7foch\u00b7ten", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "ADV", "VVPP", "VAFIN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.43": {"text": "Der Undanck ist zu gro\u00df, folgt mir geliebte Br\u00fcder!", "tokens": ["Der", "Un\u00b7danck", "ist", "zu", "gro\u00df", ",", "folgt", "mir", "ge\u00b7lieb\u00b7te", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Hiermit leg ich das Amt des deutschen Barden nieder.", "tokens": ["Hier\u00b7mit", "leg", "ich", "das", "Amt", "des", "deut\u00b7schen", "Bar\u00b7den", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Dem Schicksal Griechenlands, der finstern Barbarey,", "tokens": ["Dem", "Schick\u00b7sal", "Grie\u00b7chen\u00b7lands", ",", "der", "fins\u00b7tern", "Bar\u00b7ba\u00b7rey", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Geb ich ins k\u00fcnfftige die\u00df Land gelassen frey.", "tokens": ["Geb", "ich", "ins", "k\u00fcnff\u00b7ti\u00b7ge", "die\u00df", "Land", "ge\u00b7las\u00b7sen", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "PDS", "NN", "VVPP", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Der deutschen Klugheit mag den Franzen zin\u00dfbar bleiben!", "tokens": ["Der", "deut\u00b7schen", "Klug\u00b7heit", "mag", "den", "Fran\u00b7zen", "zin\u00df\u00b7bar", "blei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Mein Landsmann m\u00f6ge selbst nicht orthographisch schreiben!", "tokens": ["Mein", "Lands\u00b7mann", "m\u00f6\u00b7ge", "selbst", "nicht", "or\u00b7tho\u00b7gra\u00b7phisch", "schrei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Man treff ein fremdes Wort in deutschen Schrifften an!", "tokens": ["Man", "treff", "ein", "frem\u00b7des", "Wort", "in", "deut\u00b7schen", "Schriff\u00b7ten", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Genug, ihr alle wi\u00dft, was ich umsonst gethan.", "tokens": ["Ge\u00b7nug", ",", "ihr", "al\u00b7le", "wi\u00dft", ",", "was", "ich", "um\u00b7sonst", "ge\u00b7than", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "PIS", "VVFIN", "$,", "PWS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Verstocktes Vaterland! behalt die Lorber-Crone!", "tokens": ["Ver\u00b7stock\u00b7tes", "Va\u00b7ter\u00b7land", "!", "be\u00b7halt", "die", "Lor\u00b7ber\u00b7Cro\u00b7ne", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Mein Hertz befriedigt sich mit einem bessern Lohne:", "tokens": ["Mein", "Hertz", "be\u00b7frie\u00b7digt", "sich", "mit", "ei\u00b7nem", "bes\u00b7sern", "Loh\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ein Riccoboni", "tokens": ["Ein", "Ric\u00b7co\u00b7bo\u00b7ni"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.54": {"text": "Da\u00df ihr mein Witz und Saltz gewi\u00df die Wage h\u00e4lt.\u00ab", "tokens": ["Da\u00df", "ihr", "mein", "Witz", "und", "Saltz", "ge\u00b7wi\u00df", "die", "Wa\u00b7ge", "h\u00e4lt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "KON", "NN", "ADV", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Hier nahm er seinen Kiel, und stampft ihn dreymahl nieder,", "tokens": ["Hier", "nahm", "er", "sei\u00b7nen", "Kiel", ",", "und", "stampft", "ihn", "drey\u00b7mahl", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Und schwur dreymahl dabey, er schriebe nun nichts wieder.", "tokens": ["Und", "schwur", "drey\u00b7mahl", "da\u00b7bey", ",", "er", "schrie\u00b7be", "nun", "nichts", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "$,", "PPER", "VVFIN", "ADV", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Der gute Vorsatz war den Deutschen vortheilhafft,", "tokens": ["Der", "gu\u00b7te", "Vor\u00b7satz", "war", "den", "Deut\u00b7schen", "vor\u00b7theil\u00b7hafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Allein f\u00fcr Schwaben nicht; de schrieh aus alle Krafft:", "tokens": ["Al\u00b7lein", "f\u00fcr", "Schwa\u00b7ben", "nicht", ";", "de", "schrieh", "aus", "al\u00b7le", "Krafft", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKNEG", "$.", "NE", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "\u00bbumsonst bem\u00fchst du dich, die Feder wegzulegen!", "tokens": ["\u00bb", "um\u00b7sonst", "be\u00b7m\u00fchst", "du", "dich", ",", "die", "Fe\u00b7der", "weg\u00b7zu\u00b7le\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PRF", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "La\u00df dich doch, mein Patron, durch Schwabens Bitte regen:", "tokens": ["La\u00df", "dich", "doch", ",", "mein", "Pat\u00b7ron", ",", "durch", "Schwa\u00b7bens", "Bit\u00b7te", "re\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "PPOSAT", "NN", "$,", "APPR", "NN", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Kan Deutschland wohl daf\u00fcr, da\u00df sich ein Weib vergeht?", "tokens": ["Kan", "Deutschland", "wohl", "da\u00b7f\u00fcr", ",", "da\u00df", "sich", "ein", "Weib", "ver\u00b7geht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "ADV", "PAV", "$,", "KOUS", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.62": {"text": "Vergieb, mein Philosoph, noch gr\u00f6sserer Poet!", "tokens": ["Ver\u00b7gieb", ",", "mein", "Phi\u00b7lo\u00b7soph", ",", "noch", "gr\u00f6s\u00b7se\u00b7rer", "Po\u00b7et", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PPOSAT", "NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Dein Zorn ist \u00fcbereilt; Wie? wilst du nicht mehr schreiben?", "tokens": ["Dein", "Zorn", "ist", "\u00fc\u00b7be\u00b7reilt", ";", "Wie", "?", "wilst", "du", "nicht", "mehr", "schrei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$.", "PWAV", "$.", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Bedencke, wo soll ich, wo deine Freunde bleiben?", "tokens": ["Be\u00b7den\u00b7cke", ",", "wo", "soll", "ich", ",", "wo", "dei\u00b7ne", "Freun\u00b7de", "blei\u00b7ben", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VMFIN", "PPER", "$,", "PWAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Wer nimmt sich meines Ruhms in seinen Schrifften an?", "tokens": ["Wer", "nimmt", "sich", "mei\u00b7nes", "Ruhms", "in", "sei\u00b7nen", "Schriff\u00b7ten", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Hat Deutschland auch gefehlt, was hab ich dir gethan?", "tokens": ["Hat", "Deutschland", "auch", "ge\u00b7fehlt", ",", "was", "hab", "ich", "dir", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "VVPP", "$,", "PWS", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.67": {"text": "Jedoch die Ehrfurcht soll von meinem Nutzen schweigen,", "tokens": ["Je\u00b7doch", "die", "Ehr\u00b7furcht", "soll", "von", "mei\u00b7nem", "Nut\u00b7zen", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Darf dir nur meine Hand den treuen Breitkopf zeigen.", "tokens": ["Darf", "dir", "nur", "mei\u00b7ne", "Hand", "den", "treu\u00b7en", "Breit\u00b7kopf", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "W\u00fcnscht deine Freundschafft dem die Drucker-Pressen leer,", "tokens": ["W\u00fcnscht", "dei\u00b7ne", "Freund\u00b7schafft", "dem", "die", "Dru\u00b7cke\u00b7rPres\u00b7sen", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "So halt den harten Schwur, so dicht und schreib nicht mehr.", "tokens": ["So", "halt", "den", "har\u00b7ten", "Schwur", ",", "so", "dicht", "und", "schreib", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "VVFIN", "$,", "ADV", "ADJD", "KON", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Kein Hirte, wenn ihn auch ein frecher Wolff gebissen,", "tokens": ["Kein", "Hir\u00b7te", ",", "wenn", "ihn", "auch", "ein", "fre\u00b7cher", "Wolff", "ge\u00b7bis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Hat seinen Sch\u00e4fer-Stock erz\u00f6rnet weggeschmissen.", "tokens": ["Hat", "sei\u00b7nen", "Sch\u00e4\u00b7fer\u00b7Stock", "er\u00b7z\u00f6r\u00b7net", "weg\u00b7ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Schmertzt ihn die Wunde gleich, giebt er, aus Ungeduld,", "tokens": ["Schmertzt", "ihn", "die", "Wun\u00b7de", "gleich", ",", "giebt", "er", ",", "aus", "Un\u00b7ge\u00b7duld", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,", "VVFIN", "PPER", "$,", "APPR", "NN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.74": {"text": "Der Fluhr, die W\u00f6lffe n\u00e4hrt, doch nicht hiervon die Schuld.", "tokens": ["Der", "Fluhr", ",", "die", "W\u00f6lf\u00b7fe", "n\u00e4hrt", ",", "doch", "nicht", "hier\u00b7von", "die", "Schuld", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "ADV", "PTKNEG", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Die Heerd ist ihm zu lieb, sein Amt hierum zu hassen,", "tokens": ["Die", "Heerd", "ist", "ihm", "zu", "lieb", ",", "sein", "Amt", "hie\u00b7rum", "zu", "has\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PTKA", "ADJD", "$,", "PPOSAT", "NN", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und, wegen eines Wolffs, sie vielen frey zu lassen.", "tokens": ["Und", ",", "we\u00b7gen", "ei\u00b7nes", "Wolffs", ",", "sie", "vie\u00b7len", "frey", "zu", "las\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "NN", "$,", "PPER", "PIAT", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "O Gottsched! dencke nach! Vergeht sich hier mein Mund,", "tokens": ["O", "Gott\u00b7sched", "!", "den\u00b7cke", "nach", "!", "Ver\u00b7geht", "sich", "hier", "mein", "Mund", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "VVFIN", "PTKVZ", "$.", "VVFIN", "PRF", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "So that der deine mir das gr\u00f6\u00dfte Schrecken kund.", "tokens": ["So", "that", "der", "dei\u00b7ne", "mir", "das", "gr\u00f6\u00df\u00b7te", "Schre\u00b7cken", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PPOSAT", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "La\u00df deine Gro\u00dfmuth doch nicht allzufr\u00fch verschwinden,", "tokens": ["La\u00df", "dei\u00b7ne", "Gro\u00df\u00b7muth", "doch", "nicht", "all\u00b7zu\u00b7fr\u00fch", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADV", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Es sind noch Mittel da, der Frau das Maul zu binden.", "tokens": ["Es", "sind", "noch", "Mit\u00b7tel", "da", ",", "der", "Frau", "das", "Maul", "zu", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "PTKVZ", "$,", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Jedoch mein Rath greifft nicht der klugen Kulmus vor,", "tokens": ["Je\u00b7doch", "mein", "Rath", "greifft", "nicht", "der", "klu\u00b7gen", "Kul\u00b7mus", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Die niemals Hertz und Geist in der Gefahr verlohr.", "tokens": ["Die", "nie\u00b7mals", "Hertz", "und", "Geist", "in", "der", "Ge\u00b7fahr", "ver\u00b7lohr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "KON", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Soll, sprach Victoria, ich kurtz die Meynung sagen,", "tokens": ["Soll", ",", "sprach", "Vic\u00b7to\u00b7ria", ",", "ich", "kurtz", "die", "Mey\u00b7nung", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "VVFIN", "NE", "$,", "PPER", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "So ist mein Rath, die Frau gerichtlich zu verklagen.", "tokens": ["So", "ist", "mein", "Rath", ",", "die", "Frau", "ge\u00b7richt\u00b7lich", "zu", "ver\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vor des Professors Kiel ist sie noch viel zu klein,", "tokens": ["Vor", "des", "Pro\u00b7fes\u00b7sors", "Kiel", "ist", "sie", "noch", "viel", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "VAFIN", "PPER", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Die That mu\u00df b\u00fcrgerlich an ihr gez\u00fcchtigt seyn.", "tokens": ["Die", "That", "mu\u00df", "b\u00fcr\u00b7ger\u00b7lich", "an", "ihr", "ge\u00b7z\u00fcch\u00b7tigt", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Man \u00fcbergebe sie den edlen Stadt-Gerichten,", "tokens": ["Man", "\u00fc\u00b7ber\u00b7ge\u00b7be", "sie", "den", "ed\u00b7len", "Stadt\u00b7Ge\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Durch ein gesch\u00e4rfft Verboth den Anschlag zu vernichten,", "tokens": ["Durch", "ein", "ge\u00b7sch\u00e4rfft", "Ver\u00b7both", "den", "An\u00b7schlag", "zu", "ver\u00b7nich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVPP", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Womit der Nachmittag auf morgen uns bedroht.\u00ab", "tokens": ["Wo\u00b7mit", "der", "Nach\u00b7mit\u00b7tag", "auf", "mor\u00b7gen", "uns", "be\u00b7droht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ADV", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch Gottsched ward so gleich bey diesem Schlusse roth;", "tokens": ["Doch", "Gott\u00b7sched", "ward", "so", "gleich", "bey", "die\u00b7sem", "Schlus\u00b7se", "roth", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er sch\u00fcttelte den Kopff, und gab ihr zu verstehen:", "tokens": ["Er", "sch\u00fct\u00b7tel\u00b7te", "den", "Kopff", ",", "und", "gab", "ihr", "zu", "ver\u00b7ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein kluger m\u00fc\u00dfte sich nicht allzustarck vergehen;", "tokens": ["Ein", "klu\u00b7ger", "m\u00fc\u00df\u00b7te", "sich", "nicht", "all\u00b7zu\u00b7starck", "ver\u00b7ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "PRF", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So stritten Dichter nicht. \u00bbDenn sprach er: thut mein Mund,", "tokens": ["So", "strit\u00b7ten", "Dich\u00b7ter", "nicht", ".", "\u00bb", "Denn", "sprach", "er", ":", "thut", "mein", "Mund", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PTKNEG", "$.", "$(", "KON", "VVFIN", "PPER", "$.", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df ich getroffen bin, vor dem Gerichte kund,", "tokens": ["Da\u00df", "ich", "ge\u00b7trof\u00b7fen", "bin", ",", "vor", "dem", "Ge\u00b7rich\u00b7te", "kund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So hat die Neuberin nichts strafbares gesaget;", "tokens": ["So", "hat", "die", "Neu\u00b7be\u00b7rin", "nichts", "straf\u00b7ba\u00b7res", "ge\u00b7sa\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PIS", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So hab ich selber mich, und nicht die Frau, verklaget.", "tokens": ["So", "hab", "ich", "sel\u00b7ber", "mich", ",", "und", "nicht", "die", "Frau", ",", "ver\u00b7kla\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPER", "$,", "KON", "PTKNEG", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Was, Schwabe, meynest du? Endeck uns deinen Rath.\u00ab", "tokens": ["Was", ",", "Schwa\u00b7be", ",", "mey\u00b7nest", "du", "?", "E\u00b7ndeck", "uns", "dei\u00b7nen", "Rath", ".", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "$,", "NN", "$,", "VVFIN", "PPER", "$.", "NN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Er folgt, indem er es mit diesen Worten that.", "tokens": ["Er", "folgt", ",", "in\u00b7dem", "er", "es", "mit", "die\u00b7sen", "Wor\u00b7ten", "that", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PPER", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.17": {"text": "\u00bbbesinnt sich Gottsched nicht auf seine Zauber-Th\u00f6ne?", "tokens": ["\u00bb", "be\u00b7sinnt", "sich", "Gott\u00b7sched", "nicht", "auf", "sei\u00b7ne", "Zau\u00b7ber\u00b7\u00b7T\u00b7h\u00f6\u00b7ne", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PRF", "NE", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Apoll ist uns geneigt; nur wir sind seine S\u00f6hne.", "tokens": ["A\u00b7poll", "ist", "uns", "ge\u00b7neigt", ";", "nur", "wir", "sind", "sei\u00b7ne", "S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVPP", "$.", "ADV", "PPER", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.19": {"text": "Ruf ihm poetisch zu, und sing ein starckes Lied,", "tokens": ["Ruf", "ihm", "po\u00b7e\u00b7tisch", "zu", ",", "und", "sing", "ein", "star\u00b7ckes", "Lied", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.20": {"text": "Da\u00df ihn vom Helicon in dieses Zimmer zieht.", "tokens": ["Da\u00df", "ihn", "vom", "He\u00b7li\u00b7con", "in", "die\u00b7ses", "Zim\u00b7mer", "zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Hier kanst du, im Vertraun, mit diesem Gotte sprechen;", "tokens": ["Hier", "kanst", "du", ",", "im", "Ver\u00b7traun", ",", "mit", "die\u00b7sem", "Got\u00b7te", "spre\u00b7chen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPRART", "NN", "$,", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der wird der Neuberin den Vorsatz unterbrechen.\u00ab", "tokens": ["Der", "wird", "der", "Neu\u00b7be\u00b7rin", "den", "Vor\u00b7satz", "un\u00b7ter\u00b7bre\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Der Rathschlag machte gleich den Dichter wieder froh,", "tokens": ["Der", "Rath\u00b7schlag", "mach\u00b7te", "gleich", "den", "Dich\u00b7ter", "wie\u00b7der", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u00bbmein Schwabe! rief er aus, Sohn!", "tokens": ["\u00bb", "mein", "Schwa\u00b7be", "!", "rief", "er", "aus", ",", "Sohn", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "PTKVZ", "$,", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.25": {"text": "Geseegnet sey der Tag, da du zu mir gekommen!", "tokens": ["Ge\u00b7seeg\u00b7net", "sey", "der", "Tag", ",", "da", "du", "zu", "mir", "ge\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Geseegnet meine Wahl, die dich in Schutz genommen!", "tokens": ["Ge\u00b7seeg\u00b7net", "mei\u00b7ne", "Wahl", ",", "die", "dich", "in", "Schutz", "ge\u00b7nom\u00b7men", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ihr Freunde bleibt und schweigt, sprecht nicht ein lautes Wort;", "tokens": ["Ihr", "Freun\u00b7de", "bleibt", "und", "schweigt", ",", "sprecht", "nicht", "ein", "lau\u00b7tes", "Wort", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Zur Hyppokrene fliegt anietzt mein Seuffzer fort.\u00ab", "tokens": ["Zur", "Hyp\u00b7po\u00b7kre\u00b7ne", "fliegt", "an\u00b7ietzt", "mein", "Seuff\u00b7zer", "fort", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hier fieng der Dichter an, den Gott herab zu bethen.", "tokens": ["Hier", "fi\u00b7eng", "der", "Dich\u00b7ter", "an", ",", "den", "Gott", "her\u00b7ab", "zu", "be\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Er zog das Fenster auf, vor das er hingetreten.", "tokens": ["Er", "zog", "das", "Fens\u00b7ter", "auf", ",", "vor", "das", "er", "hin\u00b7ge\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So zuversichtlich hat noch kein Poet getr\u00e4umt;", "tokens": ["So", "zu\u00b7ver\u00b7sicht\u00b7lich", "hat", "noch", "kein", "Po\u00b7et", "ge\u00b7tr\u00e4umt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und Gottsched noch niemals so wunderschnell gereimt;", "tokens": ["Und", "Gott\u00b7sched", "noch", "nie\u00b7mals", "so", "wun\u00b7der\u00b7schnell", "ge\u00b7reimt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.33": {"text": "Und Pimpla selbst noch nie sich sch\u00e4umender ergossen,", "tokens": ["Und", "Pim\u00b7pla", "selbst", "noch", "nie", "sich", "sch\u00e4u\u00b7men\u00b7der", "er\u00b7gos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "ADV", "ADV", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Als ihm ietzt Sylb und Vers aus seinen Lippen flossen.", "tokens": ["Als", "ihm", "ietzt", "Sylb", "und", "Vers", "aus", "sei\u00b7nen", "Lip\u00b7pen", "flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NE", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Jedoch, best\u00fcrtzter Mann, was f\u00fcr ein Ungemach!", "tokens": ["Je\u00b7doch", ",", "be\u00b7st\u00fcrtz\u00b7ter", "Mann", ",", "was", "f\u00fcr", "ein", "Un\u00b7ge\u00b7mach", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Kein Ph\u00f6bus, kein Apoll zieht deinen Versen nach.", "tokens": ["Kein", "Ph\u00f6\u00b7bus", ",", "kein", "A\u00b7poll", "zieht", "dei\u00b7nen", "Ver\u00b7sen", "nach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Wer wei\u00df! vielleicht h\u00e4lt ihn ein Liebes-Werck zur\u00fccke?", "tokens": ["Wer", "wei\u00df", "!", "viel\u00b7leicht", "h\u00e4lt", "ihn", "ein", "Lie\u00b7bes\u00b7\u00b7Werck", "zu\u00b7r\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Ein leerer Trost vor dich auf wenig Augenblicke!", "tokens": ["Ein", "lee\u00b7rer", "Trost", "vor", "dich", "auf", "we\u00b7nig", "Au\u00b7gen\u00b7bli\u00b7cke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PRF", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Du schmeichelst dir umsonst, er kennt und h\u00f6rt dich nicht.", "tokens": ["Du", "schmei\u00b7chelst", "dir", "um\u00b7sonst", ",", "er", "kennt", "und", "h\u00f6rt", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Dein Hertz ist unversch\u00e4mt, wenn sichs so viel verspricht.", "tokens": ["Dein", "Hertz", "ist", "un\u00b7ver\u00b7sch\u00e4mt", ",", "wenn", "sichs", "so", "viel", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KOUS", "PIS", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Ich halt es f\u00fcr dein Gl\u00fcck, da\u00df Ph\u00f6bus dich nicht kennet,", "tokens": ["Ich", "halt", "es", "f\u00fcr", "dein", "Gl\u00fcck", ",", "da\u00df", "Ph\u00f6\u00b7bus", "dich", "nicht", "ken\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "KOUS", "NE", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Der ist dein Freund, der dir nicht die Erh\u00f6hung g\u00f6nnet.", "tokens": ["Der", "ist", "dein", "Freund", ",", "der", "dir", "nicht", "die", "Er\u00b7h\u00f6\u00b7hung", "g\u00f6n\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,", "PRELS", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Mich wunderts ungemein, da\u00df dir, belesner Mann,", "tokens": ["Mich", "wun\u00b7derts", "un\u00b7ge\u00b7mein", ",", "da\u00df", "dir", ",", "be\u00b7les\u00b7ner", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Kein Beyspiel alter Zeit die Augen \u00f6ffnen kan.", "tokens": ["Kein", "Bey\u00b7spiel", "al\u00b7ter", "Zeit", "die", "Au\u00b7gen", "\u00f6ff\u00b7nen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "L\u00e4\u00dft dich Ovidius, wohl ohne zittern, lesen,", "tokens": ["L\u00e4\u00dft", "dich", "O\u00b7vi\u00b7dius", ",", "wohl", "oh\u00b7ne", "zit\u00b7tern", ",", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "$,", "ADV", "APPR", "VVINF", "$,", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.46": {"text": "Wie streng Apoll einmal dem Marsias gewesen?", "tokens": ["Wie", "streng", "A\u00b7poll", "ein\u00b7mal", "dem", "Mar\u00b7si\u00b7as", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "ADV", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Doch Gottsched hielt sein Gl\u00fcck f\u00fcr kleiner, als es war,", "tokens": ["Doch", "Gott\u00b7sched", "hielt", "sein", "Gl\u00fcck", "f\u00fcr", "klei\u00b7ner", ",", "als", "es", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "$,", "KOUS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "\u00bbwie? sprach er, Ph\u00f6bus macht sich noch nicht offenbahr?", "tokens": ["\u00bb", "wie", "?", "sprach", "er", ",", "Ph\u00f6\u00b7bus", "macht", "sich", "noch", "nicht", "of\u00b7fen\u00b7bahr", "?"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$.", "VVFIN", "PPER", "$,", "NE", "VVFIN", "PRF", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Und mir, der ich ihn doch in Deutschlands Tempel ehre,", "tokens": ["Und", "mir", ",", "der", "ich", "ihn", "doch", "in", "Deutschlands", "Tem\u00b7pel", "eh\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PRELS", "PPER", "PPER", "ADV", "APPR", "NE", "NE", "VVFIN", "$,"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.50": {"text": "Wo ich bey dem Altar den Fliegen Franckreichs wehre?", "tokens": ["Wo", "ich", "bey", "dem", "Al\u00b7tar", "den", "Flie\u00b7gen", "Fran\u00b7ck\u00b7reichs", "weh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "ART", "NN", "NE", "VVFIN", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.51": {"text": "Mir, der ich mich f\u00fcr ihn zum M\u00e4rtyrer gemacht?", "tokens": ["Mir", ",", "der", "ich", "mich", "f\u00fcr", "ihn", "zum", "M\u00e4r\u00b7ty\u00b7rer", "ge\u00b7macht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "PRF", "APPR", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Mir, der ich ihn so offt in meinen Vers gebracht?", "tokens": ["Mir", ",", "der", "ich", "ihn", "so", "offt", "in", "mei\u00b7nen", "Vers", "ge\u00b7bracht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Viel ists, da\u00df mich nicht l\u00e4ngst sein taubes Ohr bewogen,", "tokens": ["Viel", "ists", ",", "da\u00df", "mich", "nicht", "l\u00e4ngst", "sein", "tau\u00b7bes", "Ohr", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Da\u00df ich mich gantz und gar von Deutschland abgezogen.\u00ab", "tokens": ["Da\u00df", "ich", "mich", "gantz", "und", "gar", "von", "Deutschland", "ab\u00b7ge\u00b7zo\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "KON", "ADV", "APPR", "NE", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.55": {"text": "Hier st\u00fctzt er sich das Haupt mit seiner rechten Hand,", "tokens": ["Hier", "st\u00fctzt", "er", "sich", "das", "Haupt", "mit", "sei\u00b7ner", "rech\u00b7ten", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Und seuffzte noch einmahl: Beth\u00f6rtes Vaterland!", "tokens": ["Und", "seuffz\u00b7te", "noch", "ein\u00b7mahl", ":", "Be\u00b7th\u00f6r\u00b7tes", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Victorie sucht ihm noch klug zu wiederstreben,", "tokens": ["Vic\u00b7to\u00b7rie", "sucht", "ihm", "noch", "klug", "zu", "wie\u00b7der\u00b7stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.58": {"text": "Und Schwabe sch\u00e4mte sich, da\u00df er den Rath gegeben;", "tokens": ["Und", "Schwa\u00b7be", "sch\u00e4m\u00b7te", "sich", ",", "da\u00df", "er", "den", "Rath", "ge\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PRF", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Corvin rief aber laut. \u00bbMir f\u00e4llt noch etwas ein,", "tokens": ["Cor\u00b7vin", "rief", "a\u00b7ber", "laut", ".", "\u00bb", "Mir", "f\u00e4llt", "noch", "et\u00b7was", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "$.", "$(", "PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Ich wett, Apoll wird bald in diesem Zimmer seyn.", "tokens": ["Ich", "wett", ",", "A\u00b7poll", "wird", "bald", "in", "die\u00b7sem", "Zim\u00b7mer", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "NE", "VAFIN", "ADV", "APPR", "PDAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Gebt mir Befehl, den Gott juristisch zu citiren;", "tokens": ["Gebt", "mir", "Be\u00b7fehl", ",", "den", "Gott", "ju\u00b7ris\u00b7tisch", "zu", "ci\u00b7ti\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.62": {"text": "Der stoltze soll die Krafft von einer Sprache sp\u00fchren,", "tokens": ["Der", "stolt\u00b7ze", "soll", "die", "Krafft", "von", "ei\u00b7ner", "Spra\u00b7che", "sp\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Wodurch der Advocat Astr\u00e4en selber r\u00fchrt,", "tokens": ["Wo\u00b7durch", "der", "Ad\u00b7vo\u00b7cat", "A\u00b7str\u00e4\u00b7en", "sel\u00b7ber", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Da\u00df sie offt, \u00fcbert\u00e4ubt, so Waag als Schwerd verliehrt.", "tokens": ["Da\u00df", "sie", "offt", ",", "\u00fc\u00b7bert\u00b7\u00e4ubt", ",", "so", "Waag", "als", "Schwerd", "ver\u00b7liehrt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "VVPP", "$,", "ADV", "NE", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Ist's, fragt er: mir verg\u00f6nnt? Und als er ja vernommen!\u00ab", "tokens": ["Ist's", ",", "fragt", "er", ":", "mir", "ver\u00b7g\u00f6nnt", "?", "Und", "als", "er", "ja", "ver\u00b7nom\u00b7men", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "$.", "PPER", "VVPP", "$.", "KON", "KOUS", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Sprach er, der Kunst gewi\u00df: Nun Ph\u00f6bus sey willkommen!", "tokens": ["Sprach", "er", ",", "der", "Kunst", "ge\u00b7wi\u00df", ":", "Nun", "Ph\u00f6\u00b7bus", "sey", "will\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ART", "NN", "ADV", "$.", "ADV", "NE", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "\u00bbwas massen, fieng er an: sich wieder Gottscheds Reich", "tokens": ["\u00bb", "was", "mas\u00b7sen", ",", "fi\u00b7eng", "er", "an", ":", "sich", "wie\u00b7der", "Gott\u00b7scheds", "Reich"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWS", "VVINF", "$,", "VVFIN", "PPER", "PTKVZ", "$.", "PRF", "ADV", "NE", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.68": {"text": "Die Neuberin emp\u00f6rt, da\u00df hat Apollo gleich,", "tokens": ["Die", "Neu\u00b7be\u00b7rin", "em\u00b7p\u00f6rt", ",", "da\u00df", "hat", "A\u00b7pol\u00b7lo", "gleich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "VAFIN", "NE", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Als aller Dichter Gott, mit mehrerm zu ersehen;", "tokens": ["Als", "al\u00b7ler", "Dich\u00b7ter", "Gott", ",", "mit", "meh\u00b7rerm", "zu", "er\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "$,", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Wann aber dieses soll vor morgen noch geschehen,", "tokens": ["Wann", "a\u00b7ber", "die\u00b7ses", "soll", "vor", "mor\u00b7gen", "noch", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "VMFIN", "APPR", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Mithin noch diese Nacht hierzu beraumet ist:", "tokens": ["Mi\u00b7thin", "noch", "die\u00b7se", "Nacht", "hier\u00b7zu", "be\u00b7rau\u00b7met", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDAT", "NN", "PAV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Als wollen wir, da\u00df du, Apoll, nicht zaudernd bist,", "tokens": ["Als", "wol\u00b7len", "wir", ",", "da\u00df", "du", ",", "A\u00b7poll", ",", "nicht", "zau\u00b7dernd", "bist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "$,", "KOUS", "PPER", "$,", "NE", "$,", "PTKNEG", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Zu rechter fr\u00fcher Zeit vom Helicon zu steigen,", "tokens": ["Zu", "rech\u00b7ter", "fr\u00fc\u00b7her", "Zeit", "vom", "He\u00b7li\u00b7con", "zu", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Um Kl\u00e4gern in Person ein Mittel anzuzeigen,", "tokens": ["Um", "Kl\u00e4\u00b7gern", "in", "Per\u00b7son", "ein", "Mit\u00b7tel", "an\u00b7zu\u00b7zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "APPR", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.75": {"text": "Da\u00df ihm, doch itzt nicht mehr durch g\u00fctlichen Vergleich,", "tokens": ["Da\u00df", "ihm", ",", "doch", "itzt", "nicht", "mehr", "durch", "g\u00fct\u00b7li\u00b7chen", "Ver\u00b7gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADV", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Beklagte weichen mu\u00df. Die\u00df fordert Gottscheds Reich.\u00ab", "tokens": ["Be\u00b7klag\u00b7te", "wei\u00b7chen", "mu\u00df", ".", "Die\u00df", "for\u00b7dert", "Gott\u00b7scheds", "Reich", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "VVINF", "VMFIN", "$.", "PDS", "VVFIN", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Lichter l\u00f6schten aus. Es bebete das Zimmer,", "tokens": ["Die", "Lich\u00b7ter", "l\u00f6schten", "aus", ".", "Es", "be\u00b7be\u00b7te", "das", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und durch die Fenster drang ein ungewohnter Schimmer.", "tokens": ["Und", "durch", "die", "Fens\u00b7ter", "drang", "ein", "un\u00b7ge\u00b7wohn\u00b7ter", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den nie erblickten Gott sah Gottsched offenbahr,", "tokens": ["Den", "nie", "er\u00b7blick\u00b7ten", "Gott", "sah", "Gott\u00b7sched", "of\u00b7fen\u00b7bahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "VVFIN", "NE", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der aus dem Pomey schlo\u00df, da\u00df es Apollo war.", "tokens": ["Der", "aus", "dem", "Po\u00b7mey", "schlo\u00df", ",", "da\u00df", "es", "A\u00b7pol\u00b7lo", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vor solchem kniete der Dichter zitternd nieder,", "tokens": ["Vor", "sol\u00b7chem", "knie\u00b7te", "der", "Dich\u00b7ter", "zit\u00b7ternd", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VVFIN", "ART", "NN", "VVPP", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Die Kulmus neben ihm. Was er sprach, sag ich wieder:", "tokens": ["Die", "Kul\u00b7mus", "ne\u00b7ben", "ihm", ".", "Was", "er", "sprach", ",", "sag", "ich", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$.", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "\u00bbich, grosser Musen-Printz, ein Dichter von Natur,", "tokens": ["\u00bb", "ich", ",", "gros\u00b7ser", "Mu\u00b7sen\u00b7Printz", ",", "ein", "Dich\u00b7ter", "von", "Na\u00b7tur", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Betrat von Jugend auf ber\u00fchmter M\u00e4nner Spuhr.", "tokens": ["Be\u00b7trat", "von", "Ju\u00b7gend", "auf", "be\u00b7r\u00fchm\u00b7ter", "M\u00e4n\u00b7ner", "Spuhr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich, der ich allemahl den Musen treu gewesen,", "tokens": ["Ich", ",", "der", "ich", "al\u00b7le\u00b7mahl", "den", "Mu\u00b7sen", "treu", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "ART", "NN", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mehr B\u00fccher schreiben kan, als ich kaum durch gelesen.", "tokens": ["Mehr", "B\u00fc\u00b7cher", "schrei\u00b7ben", "kan", ",", "als", "ich", "kaum", "durch", "ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMFIN", "$,", "KOUS", "PPER", "ADV", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ich, der den Skaliger,", "tokens": ["Ich", ",", "der", "den", "Ska\u00b7li\u00b7ger", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.12": {"text": "Horatz, Longin, Bossu, Despreaux, Evremond.", "tokens": ["Ho\u00b7ratz", ",", "Lon\u00b7gin", ",", "Bos\u00b7su", ",", "De\u00b7sprea\u00b7ux", ",", "Ev\u00b7re\u00b7mond", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "NE", "$,", "NE", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Corneille, Dacier, Perrault, Furretiere,", "tokens": ["Cor\u00b7neil\u00b7le", ",", "Da\u00b7cier", ",", "Per\u00b7rault", ",", "Fur\u00b7re\u00b7tie\u00b7re", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Schwift, Aristoteles, Steel, Adison, Voltaire,", "tokens": ["Schwift", ",", "A\u00b7ris\u00b7to\u00b7te\u00b7les", ",", "Steel", ",", "A\u00b7di\u00b7son", ",", "Vol\u00b7tai\u00b7re", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Mit gr\u00f6\u00dfter Lust durchsucht; die Welschen \u00fcbersetzt;", "tokens": ["Mit", "gr\u00f6\u00df\u00b7ter", "Lust", "durch\u00b7sucht", ";", "die", "Wel\u00b7schen", "\u00fc\u00b7bers\u00b7etzt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$.", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Frantzen offt verdeutscht, und Deutschland werthgesch\u00e4tzt,", "tokens": ["Die", "Frant\u00b7zen", "offt", "ver\u00b7deutscht", ",", "und", "Deutschland", "werth\u00b7ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$,", "KON", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.17": {"text": "Es von dem Scytischen durch meinen Witz zu l\u00e4utern;", "tokens": ["Es", "von", "dem", "Scy\u00b7ti\u00b7schen", "durch", "mei\u00b7nen", "Witz", "zu", "l\u00e4u\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Sprache Horizont durch die Critic zu heitern;", "tokens": ["Der", "Spra\u00b7che", "Ho\u00b7ri\u00b7zont", "durch", "die", "Cri\u00b7tic", "zu", "hei\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ich, der in Sachsen nicht der allerletzte blieb,", "tokens": ["Ich", ",", "der", "in", "Sach\u00b7sen", "nicht", "der", "al\u00b7ler\u00b7letz\u00b7te", "blieb", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPR", "NE", "PTKNEG", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der eine Rede-Kunst und eine Dicht-Kunst schrieb,", "tokens": ["Der", "ei\u00b7ne", "Re\u00b7de\u00b7Kunst", "und", "ei\u00b7ne", "Dicht\u00b7Kunst", "schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Empfange nun den Lohn f\u00fcr Eifer und Bem\u00fchen,", "tokens": ["Emp\u00b7fan\u00b7ge", "nun", "den", "Lohn", "f\u00fcr", "Ei\u00b7fer", "und", "Be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Da\u00df Weiber emsig sind, mich beissend durchzuziehen.", "tokens": ["Da\u00df", "Wei\u00b7ber", "em\u00b7sig", "sind", ",", "mich", "beis\u00b7send", "durch\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "VAFIN", "$,", "PPER", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Du weist, Apoll, wie sich die Neuberin vergieng;", "tokens": ["Du", "weist", ",", "A\u00b7poll", ",", "wie", "sich", "die", "Neu\u00b7be\u00b7rin", "ver\u00b7gieng", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "$,", "PWAV", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Du weist, warum sie sich an meine Feinde hieng.", "tokens": ["Du", "weist", ",", "wa\u00b7rum", "sie", "sich", "an", "mei\u00b7ne", "Fein\u00b7de", "hieng", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ihr Vorspiel stach mich an und hilffst du mir nicht sorgen,", "tokens": ["Ihr", "Vor\u00b7spiel", "stach", "mich", "an", "und", "hilffst", "du", "mir", "nicht", "sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "So h\u00f6rt sie noch nicht auf und wiederholt es morgen.", "tokens": ["So", "h\u00f6rt", "sie", "noch", "nicht", "auf", "und", "wie\u00b7der\u00b7holt", "es", "mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Was that ich nicht an ihr?", "tokens": ["Was", "that", "ich", "nicht", "an", "ihr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKNEG", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Sie mahlt mein Ebenbild, und macht es l\u00e4cherlich.", "tokens": ["Sie", "mahlt", "mein", "E\u00b7ben\u00b7bild", ",", "und", "macht", "es", "l\u00e4\u00b7cher\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "O Ph\u00f6bus! thue doch an dieser Frau ein Zeichen!", "tokens": ["O", "Ph\u00f6\u00b7bus", "!", "thue", "doch", "an", "die\u00b7ser", "Frau", "ein", "Zei\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "VVFIN", "ADV", "APPR", "PDAT", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "La\u00df die Ged\u00e4chtnis-Kunst auf einmahl von ihr weichen!", "tokens": ["La\u00df", "die", "Ge\u00b7d\u00e4cht\u00b7nis\u00b7Kunst", "auf", "ein\u00b7mahl", "von", "ihr", "wei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "APPR", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "L\u00e4hm ihr die Zunge fest, damit sie mit Verdru\u00df,", "tokens": ["L\u00e4hm", "ihr", "die", "Zun\u00b7ge", "fest", ",", "da\u00b7mit", "sie", "mit", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "PTKVZ", "$,", "KOUS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Verge\u00dflich und verstummt, den Vorsatz \u00e4ndern mu\u00df.\u00ab", "tokens": ["Ver\u00b7ge\u00df\u00b7lich", "und", "ver\u00b7stummt", ",", "den", "Vor\u00b7satz", "\u00e4n\u00b7dern", "mu\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "KON", "VVFIN", "$,", "ART", "NN", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Hier h\u00f6rte Gottsched auf. Des Ph\u00f6bus G\u00f6tter-Stimme", "tokens": ["Hier", "h\u00f6r\u00b7te", "Gott\u00b7sched", "auf", ".", "Des", "Ph\u00f6\u00b7bus", "G\u00f6t\u00b7ter\u00b7Stim\u00b7me"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "PTKVZ", "$.", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Erkl\u00e4rte folgendes aus gantz gerechtem Grimme:", "tokens": ["Er\u00b7kl\u00e4r\u00b7te", "fol\u00b7gen\u00b7des", "aus", "gantz", "ge\u00b7rech\u00b7tem", "Grim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "\u00bbso sehr schrenckt nicht Apoll der B\u00fchnen Freyheit ein.", "tokens": ["\u00bb", "so", "sehr", "schrenckt", "nicht", "A\u00b7poll", "der", "B\u00fch\u00b7nen", "Frey\u00b7heit", "ein", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "VVFIN", "PTKNEG", "NN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.36": {"text": "Wer sich getroffen sind,", "tokens": ["Wer", "sich", "ge\u00b7trof\u00b7fen", "sind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.37": {"text": "Dein Lied drang, wie dein Ruhm, niemals zu meinen H\u00f6hen.", "tokens": ["Dein", "Lied", "drang", ",", "wie", "dein", "Ruhm", ",", "nie\u00b7mals", "zu", "mei\u00b7nen", "H\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PWAV", "PPOSAT", "NN", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Der Zephyr ist bestellt, die Th\u00f6ne zu verwehen,", "tokens": ["Der", "Ze\u00b7phyr", "ist", "be\u00b7stellt", ",", "die", "Th\u00f6\u00b7ne", "zu", "ver\u00b7we\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Die mir ein kleiner Geist verwegen zugeschickt.", "tokens": ["Die", "mir", "ein", "klei\u00b7ner", "Geist", "ver\u00b7we\u00b7gen", "zu\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Wenn sich ein Satyr auch nach einem Steine b\u00fcckt,", "tokens": ["Wenn", "sich", "ein", "Sa\u00b7tyr", "auch", "nach", "ei\u00b7nem", "Stei\u00b7ne", "b\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Den aufgeblehten Schwarm der Reimer zu zerstreuen,", "tokens": ["Den", "auf\u00b7ge\u00b7bleh\u00b7ten", "Schwarm", "der", "Rei\u00b7mer", "zu", "zer\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So ists ein Spiel, wobey sich meine Musen freuen.", "tokens": ["So", "ists", "ein", "Spiel", ",", "wo\u00b7bey", "sich", "mei\u00b7ne", "Mu\u00b7sen", "freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "KOUS", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Verdien erst meinen Schutz, sonst schreih mich nicht mehr an:", "tokens": ["Ver\u00b7di\u00b7en", "erst", "mei\u00b7nen", "Schutz", ",", "sonst", "schreih", "mich", "nicht", "mehr", "an", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.44": {"text": "Den G\u00f6ttern wird ein Schimpf umsonst nicht angethan.", "tokens": ["Den", "G\u00f6t\u00b7tern", "wird", "ein", "Schimpf", "um\u00b7sonst", "nicht", "an\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Und wirst du noch einmahl mich zur Erscheinung zwingen,", "tokens": ["Und", "wirst", "du", "noch", "ein\u00b7mahl", "mich", "zur", "Er\u00b7schei\u00b7nung", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "So komm ich, doch gewi\u00df, die Strafe mitzubringen,", "tokens": ["So", "komm", "ich", ",", "doch", "ge\u00b7wi\u00df", ",", "die", "Stra\u00b7fe", "mit\u00b7zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "ADV", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "So r\u00e4ch ich mich an dir und auch dein Vaterland.\u00ab", "tokens": ["So", "r\u00e4ch", "ich", "mich", "an", "dir", "und", "auch", "dein", "Va\u00b7ter\u00b7land", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPER", "KON", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Hier wich der Glantz zur\u00fcck, der Musen-Gott verschwand,", "tokens": ["Hier", "wich", "der", "Glantz", "zu\u00b7r\u00fcck", ",", "der", "Mu\u00b7sen\u00b7Gott", "ver\u00b7schwand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Und Gottsched blieb best\u00fcrtzt mit seiner Freundin knien,", "tokens": ["Und", "Gott\u00b7sched", "blieb", "be\u00b7st\u00fcrtzt", "mit", "sei\u00b7ner", "Freun\u00b7din", "kni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Bis Schwab und auch Corvin sehr laut nach Lichtern schriehen.", "tokens": ["Bis", "Schwab", "und", "auch", "Cor\u00b7vin", "sehr", "laut", "nach", "Lich\u00b7tern", "schrie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADV", "NE", "ADV", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Das Vorspiel ward hierauf von neuem vorgestellt,", "tokens": ["Das", "Vor\u00b7spiel", "ward", "hier\u00b7auf", "von", "neu\u00b7em", "vor\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PAV", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und unsre Neuberin behielt so Sieg, als Feld.", "tokens": ["Und", "uns\u00b7re", "Neu\u00b7be\u00b7rin", "be\u00b7hielt", "so", "Sieg", ",", "als", "Feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "NN", "$,", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie selbst erfuhr es bald, da\u00df er sie angeklaget;", "tokens": ["Sie", "selbst", "er\u00b7fuhr", "es", "bald", ",", "da\u00df", "er", "sie", "an\u00b7ge\u00b7kla\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich wei\u00df es nicht, wer ihr die\u00df alles wiedersaget.", "tokens": ["Ich", "wei\u00df", "es", "nicht", ",", "wer", "ihr", "die\u00df", "al\u00b7les", "wie\u00b7der\u00b7sa\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PWS", "PPER", "PDS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Dichters Schwachheit ward auch auswerts kund gemacht;", "tokens": ["Des", "Dich\u00b7ters", "Schwach\u00b7heit", "ward", "auch", "aus\u00b7werts", "kund", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADV", "ADV", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das Vorspiel erst ber\u00fchmt und Gottsched ausgelacht.", "tokens": ["Das", "Vor\u00b7spiel", "erst", "be\u00b7r\u00fchmt", "und", "Gott\u00b7sched", "aus\u00b7ge\u00b7lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "KON", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Hieraus erkennen wir das Schicksaal falscher Gr\u00f6\u00dfe;", "tokens": ["Hier\u00b7aus", "er\u00b7ken\u00b7nen", "wir", "das", "Schick\u00b7saal", "fal\u00b7scher", "Gr\u00f6\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein L\u00fcfftgen hebt ihr Kleid und zeigt uns ihre Bl\u00f6\u00dfe.", "tokens": ["Ein", "L\u00fcfft\u00b7gen", "hebt", "ihr", "Kleid", "und", "zeigt", "uns", "ih\u00b7re", "Bl\u00f6\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer mehr bedeuten will, als er doch w\u00fcrcklich ist,", "tokens": ["Wer", "mehr", "be\u00b7deu\u00b7ten", "will", ",", "als", "er", "doch", "w\u00fcrck\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVINF", "VMFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zuletzt, aus Uebermuth, sich selbst zu sehr vergi\u00dft;", "tokens": ["Zu\u00b7letzt", ",", "aus", "Ue\u00b7ber\u00b7muth", ",", "sich", "selbst", "zu", "sehr", "ver\u00b7gi\u00dft", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "NN", "$,", "PRF", "ADV", "PTKA", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer sich zu gro\u00df verliehrt, mu\u00df, f\u00fcr die Hochmuts-S\u00fcnden.", "tokens": ["Wer", "sich", "zu", "gro\u00df", "ver\u00b7liehrt", ",", "mu\u00df", ",", "f\u00fcr", "die", "Hoch\u00b7muts\u00b7S\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "PTKA", "ADJD", "VVPP", "$,", "VMFIN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit Schaden, klein genug sich endlich wieder finden.", "tokens": ["Mit", "Scha\u00b7den", ",", "klein", "ge\u00b7nug", "sich", "end\u00b7lich", "wie\u00b7der", "fin\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJD", "ADV", "PRF", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}