{"textgrid.poem.37803": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Liebe ohne Stand", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ritt ein Ritter wohl durch das Ried,", "tokens": ["Es", "ritt", "ein", "Rit\u00b7ter", "wohl", "durch", "das", "Ried", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Er hob wohl an ein neues Lied,", "tokens": ["Er", "hob", "wohl", "an", "ein", "neu\u00b7es", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gar sch\u00f6ne th\u00e4t er singen,", "tokens": ["Gar", "sch\u00f6\u00b7ne", "th\u00e4t", "er", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df Berg und Thal erklingen.", "tokens": ["Da\u00df", "Berg", "und", "Thal", "er\u00b7klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Das h\u00f6rt des K\u00f6nigs sein T\u00f6chterlein", "tokens": ["Das", "h\u00f6rt", "des", "K\u00f6\u00b7nigs", "sein", "T\u00f6ch\u00b7ter\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In ihres Vaters Lustk\u00e4mmerlein,", "tokens": ["In", "ih\u00b7res", "Va\u00b7ters", "Lust\u00b7k\u00e4m\u00b7mer\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sie flochte ihr H\u00e4rlein in Seiden,", "tokens": ["Sie", "floch\u00b7te", "ihr", "H\u00e4r\u00b7lein", "in", "Sei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Mit dem Ritter wollte sie reiten.", "tokens": ["Mit", "dem", "Rit\u00b7ter", "woll\u00b7te", "sie", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVFIN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Er nahm sie bey ihrem seidenen Schopf", "tokens": ["Er", "nahm", "sie", "bey", "ih\u00b7rem", "sei\u00b7de\u00b7nen", "Schopf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und schwung sie hinter sich auf sein Ro\u00df.", "tokens": ["Und", "schwung", "sie", "hin\u00b7ter", "sich", "auf", "sein", "Ro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie ritten in einer kleinen Weile", "tokens": ["Sie", "rit\u00b7ten", "in", "ei\u00b7ner", "klei\u00b7nen", "Wei\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wohl vier und zwanzig Meilen.", "tokens": ["Wohl", "vier", "und", "zwan\u00b7zig", "Mei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "KON", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und da sie zu dem Wald 'naus kamen,", "tokens": ["Und", "da", "sie", "zu", "dem", "Wald", "'naus", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das R\u00f6\u00dflein das will Futter han.", "tokens": ["Das", "R\u00f6\u00df\u00b7lein", "das", "will", "Fut\u00b7ter", "han", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDS", "VMFIN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbfeins Liebchen, hier wollen wir ruhen,", "tokens": ["\u00bb", "feins", "Lieb\u00b7chen", ",", "hier", "wol\u00b7len", "wir", "ru\u00b7hen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Das R\u00f6\u00dflein, das will Futter.\u00ab", "tokens": ["Das", "R\u00f6\u00df\u00b7lein", ",", "das", "will", "Fut\u00b7ter", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VMFIN", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Er spreit sein Mantel ins gr\u00fcne Gras,", "tokens": ["Er", "spreit", "sein", "Man\u00b7tel", "ins", "gr\u00fc\u00b7ne", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er bat sie, da\u00df sie zu ihm sa\u00df,", "tokens": ["Er", "bat", "sie", ",", "da\u00df", "sie", "zu", "ihm", "sa\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbfeins Liebchen, ihr m\u00fcsset mich lausen,", "tokens": ["\u00bb", "feins", "Lieb\u00b7chen", ",", "ihr", "m\u00fcs\u00b7set", "mich", "lau\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mein gelbkrau\u00df H\u00e4rlein durchzausen.\u00ab", "tokens": ["Mein", "gelb\u00b7krau\u00df", "H\u00e4r\u00b7lein", "durch\u00b7zau\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Des h\u00e4rmt sich des K\u00f6nigs sein T\u00f6chterlein,", "tokens": ["Des", "h\u00e4rmt", "sich", "des", "K\u00f6\u00b7nigs", "sein", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PRF", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Viel hei\u00dfe Thr\u00e4nen sie fallen lie\u00df,", "tokens": ["Viel", "hei\u00b7\u00dfe", "Thr\u00e4\u00b7nen", "sie", "fal\u00b7len", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er schaut ihr wohl unter die Augen,", "tokens": ["Er", "schaut", "ihr", "wohl", "un\u00b7ter", "die", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u00bbwarum weinet ihr, sch\u00f6ne Jungfraue?\u00ab", "tokens": ["\u00bb", "wa\u00b7rum", "wei\u00b7net", "ihr", ",", "sch\u00f6\u00b7ne", "Jung\u00b7frau\u00b7e", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$.", "$("], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.7": {"line.1": {"text": "\u00bbwarum sollt ich nicht weinen und traurig seyn,", "tokens": ["\u00bb", "wa\u00b7rum", "sollt", "ich", "nicht", "wei\u00b7nen", "und", "trau\u00b7rig", "seyn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PTKNEG", "VVINF", "KON", "ADJD", "VAINF", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Ich bin ja des K\u00f6nigs sein T\u00f6chterlein;", "tokens": ["Ich", "bin", "ja", "des", "K\u00f6\u00b7nigs", "sein", "T\u00f6ch\u00b7ter\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "H\u00e4tt ich meinem Vater gefolget,", "tokens": ["H\u00e4tt", "ich", "mei\u00b7nem", "Va\u00b7ter", "ge\u00b7fol\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Frau Kayserin w\u00e4r ich geworden.\u00ab", "tokens": ["Frau", "Kay\u00b7se\u00b7rin", "w\u00e4r", "ich", "ge\u00b7wor\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NE", "VAFIN", "PPER", "VAPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Kaum h\u00e4tt sie das W\u00f6rtlein ausgesagt,", "tokens": ["Kaum", "h\u00e4tt", "sie", "das", "W\u00f6rt\u00b7lein", "aus\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ihr H\u00e4uptlein auf der Erden lag,", "tokens": ["Ihr", "H\u00e4upt\u00b7lein", "auf", "der", "Er\u00b7den", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbjungfr\u00e4ulein h\u00e4ttst du geschwiegen,", "tokens": ["\u00bb", "jung\u00b7fr\u00e4u\u00b7lein", "h\u00e4ttst", "du", "ge\u00b7schwie\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Dein H\u00e4uptlein w\u00e4r dir geblieben.\u00ab", "tokens": ["Dein", "H\u00e4upt\u00b7lein", "w\u00e4r", "dir", "ge\u00b7blie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Er kriegt sie bey ihrem seidenen Schopf,", "tokens": ["Er", "kriegt", "sie", "bey", "ih\u00b7rem", "sei\u00b7de\u00b7nen", "Schopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und schlenkert sie hinter den Hollerstock:", "tokens": ["Und", "schlen\u00b7kert", "sie", "hin\u00b7ter", "den", "Hol\u00b7ler\u00b7stock", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "\u00bbda liege feins Liebchen und faule,", "tokens": ["\u00bb", "da", "lie\u00b7ge", "feins", "Lieb\u00b7chen", "und", "fau\u00b7le", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Mein junges Herze mu\u00df trauren.\u00ab", "tokens": ["Mein", "jun\u00b7ges", "Her\u00b7ze", "mu\u00df", "trau\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Er nahm sein R\u00f6\u00dflein bei dem Zaum,", "tokens": ["Er", "nahm", "sein", "R\u00f6\u00df\u00b7lein", "bei", "dem", "Zaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und band es an einen Wasserstrom.", "tokens": ["Und", "band", "es", "an", "ei\u00b7nen", "Was\u00b7ser\u00b7strom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbhier steh mein R\u00f6\u00dflein und trinke,", "tokens": ["\u00bb", "hier", "steh", "mein", "R\u00f6\u00df\u00b7lein", "und", "trin\u00b7ke", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Mein jung frisch Herze mu\u00df sinken.\u00ab", "tokens": ["Mein", "jung", "frisch", "Her\u00b7ze", "mu\u00df", "sin\u00b7ken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJD", "ADJD", "VVFIN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}