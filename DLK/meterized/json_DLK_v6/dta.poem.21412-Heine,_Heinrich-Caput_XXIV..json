{"dta.poem.21412": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Caput XXIV.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-30602-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "\u201edort auf der Commode steht noch jetzt", "tokens": ["\u201e", "dort", "auf", "der", "Com\u00b7mo\u00b7de", "steht", "noch", "jetzt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "ART", "NN", "VVFIN", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die B\u00fcste von meinem Klopstock,", "tokens": ["Die", "B\u00fcs\u00b7te", "von", "mei\u00b7nem", "Klops\u00b7tock", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Jedoch seit Jahren dient sie mir", "tokens": ["Je\u00b7doch", "seit", "Jah\u00b7ren", "dient", "sie", "mir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur noch als Haubenkopfstock.", "tokens": ["Nur", "noch", "als", "Hau\u00b7ben\u00b7kopf\u00b7stock", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "\u201edu bist mein Liebling jetzt, es h\u00e4ngt", "tokens": ["\u201e", "du", "bist", "mein", "Lieb\u00b7ling", "jetzt", ",", "es", "h\u00e4ngt"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "PPOSAT", "NN", "ADV", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Bildni\u00df zu H\u00e4upten des Bettes;", "tokens": ["Dein", "Bild\u00b7ni\u00df", "zu", "H\u00e4up\u00b7ten", "des", "Bet\u00b7tes", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und siehst du, ein frischer Lorbeer umkr\u00e4nzt", "tokens": ["Und", "siehst", "du", ",", "ein", "fri\u00b7scher", "Lor\u00b7beer", "um\u00b7kr\u00e4nzt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Den Rahmen des holden Portraites.", "tokens": ["Den", "Rah\u00b7men", "des", "hol\u00b7den", "Por\u00b7trai\u00b7tes", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "\u201enur da\u00df du meine S\u00f6hne so oft", "tokens": ["\u201e", "nur", "da\u00df", "du", "mei\u00b7ne", "S\u00f6h\u00b7ne", "so", "oft"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADV"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Genergelt, ich mu\u00df es gestehen,", "tokens": ["Ge\u00b7ner\u00b7gelt", ",", "ich", "mu\u00df", "es", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VMFIN", "PPER", "VVPP", "$,"], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Hat mich zuweilen tief verletzt;", "tokens": ["Hat", "mich", "zu\u00b7wei\u00b7len", "tief", "ver\u00b7letzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das darf nicht mehr geschehen.", "tokens": ["Das", "darf", "nicht", "mehr", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u201ees hat die Zeit dich hoffentlich", "tokens": ["\u201e", "es", "hat", "die", "Zeit", "dich", "hof\u00b7fent\u00b7lich"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "PPER", "VVFIN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Von solcher Unart geheilet,", "tokens": ["Von", "sol\u00b7cher", "Un\u00b7art", "ge\u00b7hei\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und dir eine gr\u00f6\u00dfere Toleranz", "tokens": ["Und", "dir", "ei\u00b7ne", "gr\u00f6\u00b7\u00dfe\u00b7re", "To\u00b7le\u00b7ranz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Sogar f\u00fcr Narren ertheilet.", "tokens": ["So\u00b7gar", "f\u00fcr", "Nar\u00b7ren", "er\u00b7thei\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}