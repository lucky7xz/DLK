{"dta.poem.294": {"metadata": {"author": {"name": "Gressel, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "An die zornige  Cassandra.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1716", "urn": "urn:nbn:de:kobv:b4-200905199041", "language": ["de:0.85", "nl:0.14"], "booktitle": "Celander [i. e. Gressel, Johann Georg]: Verliebte-Galante/ Sinn-Vermischte und Grab-Gedichte. Hamburg u. a., 1716."}, "poem": {"stanza.1": {"line.1": {"text": "Ach! mein Engel/ mein Verlangen!", "tokens": ["Ach", "!", "mein", "En\u00b7gel", "/", "mein", "Ver\u00b7lan\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df/ und soll ich denn vergehn?", "tokens": ["Mu\u00df", "/", "und", "soll", "ich", "denn", "ver\u00b7gehn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$(", "KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Darf ich nicht die Brust umpfangen?", "tokens": ["Darf", "ich", "nicht", "die", "Brust", "um\u00b7pfan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ach! so ists um mich geschehn!", "tokens": ["Ach", "!", "so", "ists", "um", "mich", "ge\u00b7schehn", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADV", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Stehet meinem heissen Hoffen", "tokens": ["Ste\u00b7het", "mei\u00b7nem", "heis\u00b7sen", "Hof\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kein Gut-seyn offen?", "tokens": ["Kein", "Gut\u00b7seyn", "of\u00b7fen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "So kan ich mein Sterben sehn.", "tokens": ["So", "kan", "ich", "mein", "Ster\u00b7ben", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Zornige/ ich falle nieder/", "tokens": ["Zor\u00b7ni\u00b7ge", "/", "ich", "fal\u00b7le", "nie\u00b7der", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blicket mich halb-todten an/", "tokens": ["Bli\u00b7cket", "mich", "halb\u00b7tod\u00b7ten", "an", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach kehrt doch/ ach kehret wieder!", "tokens": ["Ach", "kehrt", "doch", "/", "ach", "keh\u00b7ret", "wie\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "$(", "ADV", "VVFIN", "ADV", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df ich Athen hohlen kan/", "tokens": ["Da\u00df", "ich", "A\u00b7then", "hoh\u00b7len", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "ADJA", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und an euren sch\u00f6nen Wangen", "tokens": ["Und", "an", "eu\u00b7ren", "sch\u00f6\u00b7nen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So m\u00f6ge hangen/", "tokens": ["So", "m\u00f6\u00b7ge", "han\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Als ich ehmahls wol gethan.", "tokens": ["Als", "ich", "eh\u00b7mahls", "wol", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Sch\u00f6nes Kind/ Prei\u00df aller ", "tokens": ["Sch\u00f6\u00b7nes", "Kind", "/", "Prei\u00df", "al\u00b7ler"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$(", "NN", "PIAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eures Halses Helffenbein", "tokens": ["Eu\u00b7res", "Hal\u00b7ses", "Helf\u00b7fen\u00b7bein"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Br\u00fcste ", "tokens": ["Und", "der", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.4": {"text": "F\u00fchren mich im Zweiffel ein/", "tokens": ["F\u00fch\u00b7ren", "mich", "im", "Zweif\u00b7fel", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "ART", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ob ihr aus der G\u00f6tter Orden", "tokens": ["Ob", "ihr", "aus", "der", "G\u00f6t\u00b7ter", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zur ", "tokens": ["Zur"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Die hier will verehret seyn.", "tokens": ["Die", "hier", "will", "ver\u00b7eh\u00b7ret", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Oder/ ob ihr so gezeuget/", "tokens": ["O\u00b7der", "/", "ob", "ihr", "so", "ge\u00b7zeu\u00b7get", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als wie ander Menschen seyd?", "tokens": ["Als", "wie", "an\u00b7der", "Men\u00b7schen", "seyd", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ADJD", "NN", "VAFIN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Trifft dis ein/ so \u00fcbersteiget", "tokens": ["Trifft", "dis", "ein", "/", "so", "\u00fc\u00b7bers\u00b7tei\u00b7get"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PDS", "ART", "$(", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jhr der L\u00f6wen Grimmigkeit/", "tokens": ["Ihr", "der", "L\u00f6\u00b7wen", "Grim\u00b7mig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Indem ihr mein schlecht Verbrechen", "tokens": ["In\u00b7dem", "ihr", "mein", "schlecht", "Ver\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So hart zu r\u00e4chen", "tokens": ["So", "hart", "zu", "r\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Mit erz\u00fcrnten Augen dreut.", "tokens": ["Mit", "er\u00b7z\u00fcrn\u00b7ten", "Au\u00b7gen", "dreut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Aber Nein! eur sch\u00f6nes Wesen", "tokens": ["A\u00b7ber", "Nein", "!", "eur", "sch\u00f6\u00b7nes", "We\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PTKANT", "$.", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euch ein Bild der Gottheit hei\u00dft/", "tokens": ["Euch", "ein", "Bild", "der", "Got\u00b7theit", "hei\u00dft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der man an der Stirn kan lesen/", "tokens": ["Der", "man", "an", "der", "Stirn", "kan", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie Gnad\u2019 und Huld erwei\u00dft:", "tokens": ["Da\u00df", "sie", "Gnad'", "und", "Huld", "er\u00b7wei\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf ein unerm\u00fcdtes Flehen", "tokens": ["Auf", "ein", "un\u00b7er\u00b7m\u00fcd\u00b7tes", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird es geschehen/", "tokens": ["Wird", "es", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Da\u00df man H\u00fclff\u2019 und Rettung prei\u00dft.", "tokens": ["Da\u00df", "man", "H\u00fclff'", "und", "Ret\u00b7tung", "prei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Drum/ o G\u00f6ttin! soll ich leben!", "tokens": ["Drum", "/", "o", "G\u00f6t\u00b7tin", "!", "soll", "ich", "le\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "FM", "NN", "$.", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So stelt doch eur Z\u00fcrnen ein/", "tokens": ["So", "stelt", "doch", "eur", "Z\u00fcr\u00b7nen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "ART", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Meinen Jammer m\u00fcst ihr heben/", "tokens": ["Mei\u00b7nen", "Jam\u00b7mer", "m\u00fcst", "ihr", "he\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sonst werd\u2019 ich verlohren seyn.", "tokens": ["Sonst", "werd'", "ich", "ver\u00b7loh\u00b7ren", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Was die Seele will verzehren", "tokens": ["Was", "die", "See\u00b7le", "will", "ver\u00b7zeh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mu\u00df sich verkehren", "tokens": ["Mu\u00df", "sich", "ver\u00b7keh\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PRF", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "In beliebten Gnaden-Schein.", "tokens": ["In", "be\u00b7lieb\u00b7ten", "Gna\u00b7den\u00b7Schein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Mehr will ich mein Schatz nicht suchen/", "tokens": ["Mehr", "will", "ich", "mein", "Schatz", "nicht", "su\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil ihr eine Gottheit seyd/", "tokens": ["Weil", "ihr", "ei\u00b7ne", "Got\u00b7theit", "seyd", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sonsten w\u00fcrd\u2019 ich nicht verfluchen", "tokens": ["Sons\u00b7ten", "w\u00fcrd'", "ich", "nicht", "ver\u00b7flu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eures Busens Lieblichkeit/", "tokens": ["Eu\u00b7res", "Bu\u00b7sens", "Lieb\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die wunder-sch\u00f6nen Gaben/", "tokens": ["Und", "die", "wun\u00b7der\u00b7sch\u00f6\u00b7nen", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So den erlaben/", "tokens": ["So", "den", "er\u00b7la\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Dem der Tod das Sterben dreut.", "tokens": ["Dem", "der", "Tod", "das", "Ster\u00b7ben", "dreut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Eure Donner-reiche Blicke/", "tokens": ["Eu\u00b7re", "Don\u00b7ner\u00b7rei\u00b7che", "Bli\u00b7cke", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Augen Finster-Nacht/", "tokens": ["Und", "der", "Au\u00b7gen", "Fins\u00b7ter\u00b7Nacht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Haben mein gehabtes Gl\u00fccke/", "tokens": ["Ha\u00b7ben", "mein", "ge\u00b7hab\u00b7tes", "Gl\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu dem gr\u00f6\u00dften Schmertz gemacht;", "tokens": ["Zu", "dem", "gr\u00f6\u00df\u00b7ten", "Schmertz", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So da\u00df ich bald mu\u00df verderben", "tokens": ["So", "da\u00df", "ich", "bald", "mu\u00df", "ver\u00b7der\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADV", "VMFIN", "VVFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und H\u00fclff-lo\u00df sterben/", "tokens": ["Und", "H\u00fclff\u00b7lo\u00df", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Wo nicht eur Erbarmen lacht.", "tokens": ["Wo", "nicht", "eur", "Er\u00b7bar\u00b7men", "lacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}