{"textgrid.poem.53103": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Sustinet inconcussa minas sapientia sortis", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wil sich das Gl\u00fcck denn stets nur weiden,", "tokens": ["Wil", "sich", "das", "Gl\u00fcck", "denn", "stets", "nur", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "KON", "ADV", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Nie s\u00e4ttigen an meiner Pein?", "tokens": ["Nie", "s\u00e4t\u00b7ti\u00b7gen", "an", "mei\u00b7ner", "Pein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo wird doch endlich meinem Leiden", "tokens": ["Wo", "wird", "doch", "end\u00b7lich", "mei\u00b7nem", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Ziel vnd Maa\u00df gestecket seyn?", "tokens": ["Das", "Ziel", "vnd", "Maa\u00df", "ge\u00b7ste\u00b7cket", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Lesst auff den Hagel vnd das Wehen", "tokens": ["Lesst", "auff", "den", "Ha\u00b7gel", "vnd", "das", "We\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sich nicht einmal der Himmel sehen", "tokens": ["Sich", "nicht", "ein\u00b7mal", "der", "Him\u00b7mel", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "PTKNEG", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mit vnbew\u00f6lcktem Sonnenschein?", "tokens": ["Mit", "vn\u00b7be\u00b7w\u00f6lck\u00b7tem", "Son\u00b7nen\u00b7schein", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nachdem das Gl\u00fcck zu tausent malen", "tokens": ["Nach\u00b7dem", "das", "Gl\u00fcck", "zu", "tau\u00b7sent", "ma\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00dfher sich wider mich gelegt,", "tokens": ["Bi\u00df\u00b7her", "sich", "wi\u00b7der", "mich", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gleich wie der Plitz mit Donnerstrahlen", "tokens": ["Gleich", "wie", "der", "Plitz", "mit", "Don\u00b7ner\u00b7strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Am meisten in die Eichen schl\u00e4gt;", "tokens": ["Am", "meis\u00b7ten", "in", "die", "Ei\u00b7chen", "schl\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch wie der Feind mit wildem Hauffen", "tokens": ["Auch", "wie", "der", "Feind", "mit", "wil\u00b7dem", "Hauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein festes Thor pflegt an-zulauffen", "tokens": ["Ein", "fes\u00b7tes", "Thor", "pflegt", "an\u00b7zu\u00b7lauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das seines Landes Schl\u00fcssel tr\u00e4gt,", "tokens": ["Das", "sei\u00b7nes", "Lan\u00b7des", "Schl\u00fcs\u00b7sel", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nachdem es nie mir hold ist worden,", "tokens": ["Nach\u00b7dem", "es", "nie", "mir", "hold", "ist", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "ADJD", "VAFIN", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ger\u00e4th es noch auff solche List,", "tokens": ["Ge\u00b7r\u00e4\u00b7th", "es", "noch", "auff", "sol\u00b7che", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Vnd nimpt au\u00df vnsrer Zahl vnd Orden", "tokens": ["Vnd", "nimpt", "au\u00df", "vns\u00b7rer", "Zahl", "vnd", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den, der mein Hertz vnd Leben ist;", "tokens": ["Den", ",", "der", "mein", "Hertz", "vnd", "Le\u00b7ben", "ist", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPOSAT", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr den ich zwey-mal wolte sterben,", "tokens": ["F\u00fcr", "den", "ich", "zwey\u00b7mal", "wol\u00b7te", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn ich Ihn wieder zu erwerben", "tokens": ["Wenn", "ich", "Ihn", "wie\u00b7der", "zu", "er\u00b7wer\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vnd lebendig zu machen w\u00fcst'.", "tokens": ["Vnd", "le\u00b7ben\u00b7dig", "zu", "ma\u00b7chen", "w\u00fcst'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ach, ich vermag kein Wort zu sprechen!", "tokens": ["Ach", ",", "ich", "ver\u00b7mag", "kein", "Wort", "zu", "spre\u00b7chen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bin mir frembd vnd vnbekant,", "tokens": ["Ich", "bin", "mir", "frembd", "vnd", "vn\u00b7be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Hertz im Leibe wil mir brechen,", "tokens": ["Das", "Hertz", "im", "Lei\u00b7be", "wil", "mir", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Geist ist fern vnd abgewandt", "tokens": ["Der", "Geist", "ist", "fern", "vnd", "ab\u00b7ge\u00b7wandt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von allem, was ich thue vnd \u00fcbe,", "tokens": ["Von", "al\u00b7lem", ",", "was", "ich", "thue", "vnd", "\u00fc\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gedenck' ich an die Trew vnd Liebe,", "tokens": ["Ge\u00b7denck", "ich", "an", "die", "Trew", "vnd", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die meine Seel' in seiner fandt.", "tokens": ["Die", "mei\u00b7ne", "Seel'", "in", "sei\u00b7ner", "fandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPOSAT", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wolan, das Gl\u00fcck ist hoch gestiegen,", "tokens": ["Wo\u00b7lan", ",", "das", "Gl\u00fcck", "ist", "hoch", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch kan es nun auch weiter nicht.", "tokens": ["Doch", "kan", "es", "nun", "auch", "wei\u00b7ter", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sol ich hierunter gantz erliegen?", "tokens": ["Sol", "ich", "hier\u00b7un\u00b7ter", "gantz", "er\u00b7lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PAV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "O nein! verzeih' es mir, mein Licht,", "tokens": ["O", "nein", "!", "ver\u00b7zeih'", "es", "mir", ",", "mein", "Licht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "VVFIN", "PPER", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wil mit kl\u00e4glich-thun vnd weinen", "tokens": ["Ich", "wil", "mit", "kl\u00e4g\u00b7lich\u00b7thun", "vnd", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zwar deiner Aschen vnd Gebeinen", "tokens": ["Zwar", "dei\u00b7ner", "A\u00b7schen", "vnd", "Ge\u00b7bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Erweisen meiner Dienste Pflicht:", "tokens": ["Er\u00b7wei\u00b7sen", "mei\u00b7ner", "Diens\u00b7te", "Pflicht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch wil ich nie dem Gl\u00fccke flehen;", "tokens": ["Doch", "wil", "ich", "nie", "dem", "Gl\u00fc\u00b7cke", "fle\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es mag mit h\u00f6chster Tyranney", "tokens": ["Es", "mag", "mit", "h\u00f6chs\u00b7ter", "Ty\u00b7ran\u00b7ney"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich trotzig wider mich auffblehen,", "tokens": ["Sich", "trot\u00b7zig", "wi\u00b7der", "mich", "auff\u00b7ble\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein w\u00fcten ist mir Wind vnd Sprey:", "tokens": ["Sein", "w\u00fc\u00b7ten", "ist", "mir", "Wind", "vnd", "Sp\u00b7rey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VAFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vermag ich die\u00df Leid zu verschmertzen,", "tokens": ["Ver\u00b7mag", "ich", "die\u00df", "Leid", "zu", "ver\u00b7schmert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "So trag' ich jetzt in meinem Hertzen", "tokens": ["So", "trag'", "ich", "jetzt", "in", "mei\u00b7nem", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auch f\u00fcr dem Tode selbst nicht schew.", "tokens": ["Auch", "f\u00fcr", "dem", "To\u00b7de", "selbst", "nicht", "schew", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich hoff', es sol mir noch gelingen,", "tokens": ["Ich", "hoff'", ",", "es", "sol", "mir", "noch", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df, wann ich schon lieg' eingeh\u00fcllt,", "tokens": ["Da\u00df", ",", "wann", "ich", "schon", "lieg'", "ein\u00b7ge\u00b7h\u00fcllt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man r\u00fchmlich von mir werde singen", "tokens": ["Man", "r\u00fchm\u00b7lich", "von", "mir", "wer\u00b7de", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADJD", "APPR", "PPER", "VAFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Reime, meiner Tugend Schild:", "tokens": ["Die", "Rei\u00b7me", ",", "mei\u00b7ner", "Tu\u00b7gend", "Schild", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer ist der Feind, so noht gelitten?", "tokens": ["Wer", "ist", "der", "Feind", ",", "so", "noht", "ge\u00b7lit\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das stoltze Gl\u00fcck. Wer hat gestritten", "tokens": ["Das", "stolt\u00b7ze", "Gl\u00fcck", ".", "Wer", "hat", "ge\u00b7strit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "PWS", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vnd obgesiegt? Ein Frawen-Bild.", "tokens": ["Vnd", "ob\u00b7ge\u00b7siegt", "?", "Ein", "Fra\u00b7wen\u00b7Bild", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVPP", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}