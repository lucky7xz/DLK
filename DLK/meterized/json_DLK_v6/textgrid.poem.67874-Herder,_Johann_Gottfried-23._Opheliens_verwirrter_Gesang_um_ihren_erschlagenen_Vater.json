{"textgrid.poem.67874": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "23. Opheliens verwirrter Gesang um ihren erschlagenen Vater", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich will nicht mit ihr sprechen \u2013", "tokens": ["Ich", "will", "nicht", "mit", "ihr", "spre\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "EdELMANN.", "tokens": ["E\u00b7dEL\u00b7MANN", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Aber sie", "tokens": ["A\u00b7ber", "sie"], "token_info": ["word", "word"], "pos": ["KON", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "ist dringend, in der That von Sinnen, sie", "tokens": ["ist", "drin\u00b7gend", ",", "in", "der", "That", "von", "Sin\u00b7nen", ",", "sie"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$,", "APPR", "ART", "NN", "APPR", "NN", "$,", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "verdienet wahrlich Mitleid.", "tokens": ["ver\u00b7die\u00b7net", "wahr\u00b7lich", "Mit\u00b7leid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "K\u00f6NIGIN.", "tokens": ["K\u00f6\u00b7NI\u00b7GIN", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Was will sie?", "tokens": ["Was", "will", "sie", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.6": {"line.1": {"text": "EdELMANN.", "tokens": ["E\u00b7dEL\u00b7MANN", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Sie spricht von ihrem Vater viel. Sie sagt,", "tokens": ["Sie", "spricht", "von", "ih\u00b7rem", "Va\u00b7ter", "viel", ".", "Sie", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "sie h\u00f6r', 's geb Kniffe in der Welt, und \u00e4chzt,", "tokens": ["sie", "h\u00f6r'", ",", "'s", "geb", "Knif\u00b7fe", "in", "der", "Welt", ",", "und", "\u00e4chzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "NN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "schl\u00e4gt an die Brust sich, st\u00f6\u00dft den Strohhalm fort,", "tokens": ["schl\u00e4gt", "an", "die", "Brust", "sich", ",", "st\u00f6\u00dft", "den", "Stroh\u00b7halm", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PRF", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die Worte sagen nichts, und dennoch bringt", "tokens": ["die", "Wor\u00b7te", "sa\u00b7gen", "nichts", ",", "und", "den\u00b7noch", "bringt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PIS", "$,", "KON", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "das ungestalte Nichts die H\u00f6renden", "tokens": ["das", "un\u00b7ge\u00b7stal\u00b7te", "Nichts", "die", "H\u00f6\u00b7ren\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.6": {"text": "zum Denken; sie fang'n es ihr auf, und passen's", "tokens": ["zum", "Den\u00b7ken", ";", "sie", "fang'n", "es", "ihr", "auf", ",", "und", "pas\u00b7sen's"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$.", "PPER", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "KON", "NE"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "auf ihren eignen Sinn. Sie winkt, sie sch\u00fcttelt,", "tokens": ["auf", "ih\u00b7ren", "eig\u00b7nen", "Sinn", ".", "Sie", "winkt", ",", "sie", "sch\u00fct\u00b7telt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sie macht Gebehrden, da\u00df man glauben mu\u00df,", "tokens": ["Sie", "macht", "Ge\u00b7behr\u00b7den", ",", "da\u00df", "man", "glau\u00b7ben", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "sie denke was dabei, doch weis man nichts", "tokens": ["sie", "den\u00b7ke", "was", "da\u00b7bei", ",", "doch", "weis", "man", "nichts"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "PAV", "$,", "ADV", "PTKVZ", "PIS", "PIS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "gewi\u00df und meist ungl\u00fccklich \u2013", "tokens": ["ge\u00b7wi\u00df", "und", "meist", "un\u00b7gl\u00fcck\u00b7lich", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "HoRATIO.", "tokens": ["Ho\u00b7RA\u00b7TIO", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Es w\u00e4re gut,", "tokens": ["Es", "w\u00e4\u00b7re", "gut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "man spr\u00e4che mit ihr, denn sie k\u00f6nnte doch", "tokens": ["man", "spr\u00e4\u00b7che", "mit", "ihr", ",", "denn", "sie", "k\u00f6nn\u00b7te", "doch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "PPER", "$,", "KON", "PPER", "VMFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "in Uebeldenkenden gef\u00e4hrlichen", "tokens": ["in", "Ue\u00b7bel\u00b7den\u00b7ken\u00b7den", "ge\u00b7f\u00e4hr\u00b7li\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Verdacht erregen.", "tokens": ["Ver\u00b7dacht", "er\u00b7re\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "K\u00f6NIGIN.", "tokens": ["K\u00f6\u00b7NI\u00b7GIN", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.11": {"line.1": {"text": "La\u00dft sie ein! So gehts", "tokens": ["La\u00dft", "sie", "ein", "!", "So", "gehts"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "PTKVZ", "$.", "ADV", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "der S\u00fcnde. Meiner kranken Seele scheint", "tokens": ["der", "S\u00fcn\u00b7de", ".", "Mei\u00b7ner", "kran\u00b7ken", "See\u00b7le", "scheint"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "nun jeder Tand ein Bote grossen Ungl\u00fccks.", "tokens": ["nun", "je\u00b7der", "Tand", "ein", "Bo\u00b7te", "gros\u00b7sen", "Un\u00b7gl\u00fccks", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So voll kunstlosen Argwohns ist Unthat;", "tokens": ["So", "voll", "kunst\u00b7lo\u00b7sen", "Arg\u00b7wohns", "ist", "Un\u00b7that", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "sie f\u00fcrchtet stets und f\u00f6rdert selbst Verrath.", "tokens": ["sie", "f\u00fcrch\u00b7tet", "stets", "und", "f\u00f6r\u00b7dert", "selbst", "Ver\u00b7rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "OpHEL.", "tokens": ["Op\u00b7HEL", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.13": {"line.1": {"text": "Wo ist die sch\u00f6ne Majest\u00e4t von D\u00e4nnmark?", "tokens": ["Wo", "ist", "die", "sch\u00f6\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t", "von", "D\u00e4nn\u00b7mark", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "K\u00f6NIGIN.", "tokens": ["K\u00f6\u00b7NI\u00b7GIN", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.15": {"line.1": {"text": "Wie gehts, Ophelia?", "tokens": ["Wie", "gehts", ",", "O\u00b7phe\u00b7lia", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "NE", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}}, "stanza.16": {"line.1": {"text": "OpHEL.", "tokens": ["Op\u00b7HEL", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.17": {"line.1": {"text": "Woran soll ich dein Liebchen denn,", "tokens": ["Wo\u00b7ran", "soll", "ich", "dein", "Lieb\u00b7chen", "denn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Liebchen kennen nun?", "tokens": ["Dein", "Lieb\u00b7chen", "ken\u00b7nen", "nun", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "An seinem Pilgerhut und Stab,", "tokens": ["An", "sei\u00b7nem", "Pil\u00b7ger\u00b7hut", "und", "Stab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und seinen Sandelschuh'n.", "tokens": ["Und", "sei\u00b7nen", "San\u00b7del\u00b7schuh'", "n."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["KON", "PPOSAT", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "K\u00f6NIGIN.", "tokens": ["K\u00f6\u00b7NI\u00b7GIN", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.19": {"line.1": {"text": "Ach s\u00fcsses M\u00e4dchen, was soll dieses Lied?", "tokens": ["Ach", "s\u00fcs\u00b7ses", "M\u00e4d\u00b7chen", ",", "was", "soll", "die\u00b7ses", "Lied", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$,", "PWS", "VMFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "OpHEL.", "tokens": ["Op\u00b7HEL", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.21": {"line.1": {"text": "Sagt ihr, was 's soll? Ich bin euch, h\u00f6rt:", "tokens": ["Sagt", "ihr", ",", "was", "'s", "soll", "?", "Ich", "bin", "euch", ",", "h\u00f6rt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$.", "PPER", "VAFIN", "PPER", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Er ist todt und hin, ist todt und hin", "tokens": ["Er", "ist", "todt", "und", "hin", ",", "ist", "todt", "und", "hin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "PTKVZ", "$,", "VAFIN", "ADJD", "KON", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Gegangen ins Grab hinein.", "tokens": ["Ge\u00b7gan\u00b7gen", "ins", "Grab", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Zu seinem Haupt ein Rasen liegt,", "tokens": ["Zu", "sei\u00b7nem", "Haupt", "ein", "Ra\u00b7sen", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu F\u00fcssen ihm ein Stein.", "tokens": ["Zu", "F\u00fcs\u00b7sen", "ihm", "ein", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "K\u00f6NIGIN.", "tokens": ["K\u00f6\u00b7NI\u00b7GIN", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.23": {"line.1": {"text": "Aber Ophelia \u2013", "tokens": ["A\u00b7ber", "O\u00b7phe\u00b7lia", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["KON", "NE", "$("], "meter": "+-+--", "measure": "unknown.measure.di"}}, "stanza.24": {"line.1": {"text": "OpHEL.", "tokens": ["Op\u00b7HEL", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.25": {"line.1": {"text": "Ich bitt euch, h\u00f6rt:", "tokens": ["Ich", "bitt", "euch", ",", "h\u00f6rt", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Sein Leichenhemd wie weisser Schnee", "tokens": ["Sein", "Lei\u00b7chen\u00b7hemd", "wie", "weis\u00b7ser", "Schnee"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "K\u00f6NIGIN ", "tokens": ["K\u00f6\u00b7NI\u00b7GIN"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.27": {"line.1": {"text": "Ach, seht sie an.", "tokens": ["Ach", ",", "seht", "sie", "an", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.28": {"line.1": {"text": "OpHEL ", "tokens": ["Op\u00b7HEL"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.29": {"line.1": {"text": "Bestreut mit s\u00fcssen Blumen \u2013", "tokens": ["Be\u00b7streut", "mit", "s\u00fcs\u00b7sen", "Blu\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es ging zum Grab' hin na\u00df bethaut", "tokens": ["Es", "ging", "zum", "Grab'", "hin", "na\u00df", "be\u00b7thaut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit treuer Liebe Thr\u00e4nen. \u2013 \u2013", "tokens": ["Mit", "treu\u00b7er", "Lie\u00b7be", "Thr\u00e4\u00b7nen", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "K\u00f6NIG.", "tokens": ["K\u00f6\u00b7NIG", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.31": {"line.1": {"text": "O Hitze! trockne auf mein Hirn. Ihr Thr\u00e4nen", "tokens": ["O", "Hit\u00b7ze", "!", "trock\u00b7ne", "auf", "mein", "Hirn", ".", "Ihr", "Thr\u00e4\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$.", "ADJA", "APPR", "PPOSAT", "NN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sieb'nfach gesalzen, brennt mein Auge stumpf!", "tokens": ["Sie\u00b7b'\u00b7nfach", "ge\u00b7sal\u00b7zen", ",", "brennt", "mein", "Au\u00b7ge", "stumpf", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$,", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Beim Himmel, M\u00e4dchen, deine Raserey", "tokens": ["Beim", "Him\u00b7mel", ",", "M\u00e4d\u00b7chen", ",", "dei\u00b7ne", "Ra\u00b7se\u00b7rey"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Soll schwer bezahlet werden, da\u00df die Schale", "tokens": ["Soll", "schwer", "be\u00b7zah\u00b7let", "wer\u00b7den", ",", "da\u00df", "die", "Scha\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "VVPP", "VAINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auffliege. Rosenkn\u00f6spchen, s\u00fcsses M\u00e4dchen,", "tokens": ["Auf\u00b7flie\u00b7ge", ".", "Ro\u00b7sen\u00b7kn\u00f6spc\u00b7hen", ",", "s\u00fcs\u00b7ses", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Ophelia, liebe Schwester! Himmel, ists,", "tokens": ["O\u00b7phe\u00b7lia", ",", "lie\u00b7be", "Schwes\u00b7ter", "!", "Him\u00b7mel", ",", "ists", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$.", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ists m\u00f6glich? der Verstand ein's jungen M\u00e4dchen", "tokens": ["Ists", "m\u00f6g\u00b7lich", "?", "der", "Ver\u00b7stand", "ein's", "jun\u00b7gen", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$.", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Kann mit ein's alten Mannes Leben hinseyn!", "tokens": ["Kann", "mit", "ein's", "al\u00b7ten", "Man\u00b7nes", "Le\u00b7ben", "hin\u00b7seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Natur, du bist fein in der Liebe! fein,", "tokens": ["Na\u00b7tur", ",", "du", "bist", "fein", "in", "der", "Lie\u00b7be", "!", "fein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADJD", "APPR", "ART", "NN", "$.", "ADJD", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Du schickst von deinem Selbst ein kostbar Etwas", "tokens": ["Du", "schickst", "von", "dei\u00b7nem", "Selbst", "ein", "kost\u00b7bar", "Et\u00b7was"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "ADJD", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Dem Dinge, das du liebest, nach \u2013", "tokens": ["Dem", "Din\u00b7ge", ",", "das", "du", "lie\u00b7best", ",", "nach", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "OpHEL ", "tokens": ["Op\u00b7HEL"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.33": {"line.1": {"text": "Sie trug'n ihn auf der Baare blos,", "tokens": ["Sie", "trug'n", "ihn", "auf", "der", "Baa\u00b7re", "blos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und manche Z\u00e4hr' aufs Grab ihm flo\u00df \u2013", "tokens": ["Und", "man\u00b7che", "Z\u00e4hr'", "aufs", "Grab", "ihm", "flo\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPRART", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Fahr wohl, mein T\u00e4ubchen \u2013", "tokens": ["Fahr", "wohl", ",", "mein", "T\u00e4ub\u00b7chen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PPOSAT", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.34": {"line.1": {"text": "LaERT.", "tokens": ["LaERT", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.35": {"line.1": {"text": "H\u00e4tt'st du noch deinen Witz und wolltest mich", "tokens": ["H\u00e4tt'st", "du", "noch", "dei\u00b7nen", "Witz", "und", "woll\u00b7test", "mich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "KON", "VMFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zur Rache \u00fcberreden; K\u00f6nnt'st du's mehr?", "tokens": ["Zur", "Ra\u00b7che", "\u00fc\u00b7berr\u00b7e\u00b7den", ";", "K\u00f6nnt'st", "du's", "mehr", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$.", "VMFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "OpHEL.", "tokens": ["Op\u00b7HEL", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.37": {"line.1": {"text": "Ihr m\u00fcst singen:", "tokens": ["Ihr", "m\u00fcst", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Nieder! Nieder!", "tokens": ["Nie\u00b7der", "!", "Nie\u00b7der", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADV", "$.", "ADV", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Senken ihn nieder!", "tokens": ["Sen\u00b7ken", "ihn", "nie\u00b7der", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Wie herrlich der Schlu\u00df passet!", "tokens": ["Wie", "herr\u00b7lich", "der", "Schlu\u00df", "pas\u00b7set", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Nieder! Nieder!", "tokens": ["Nie\u00b7der", "!", "Nie\u00b7der", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADV", "$.", "ADV", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Er ist aus dem falschen Verwalter, der seines Herrn Tochter stahl.", "tokens": ["Er", "ist", "aus", "dem", "fal\u00b7schen", "Ver\u00b7wal\u00b7ter", ",", "der", "sei\u00b7nes", "Herrn", "Toch\u00b7ter", "stahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+--+--+--+--+-+", "measure": "amphibrach.penta.plus"}}, "stanza.38": {"line.1": {"text": "LaERT.", "tokens": ["LaERT", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.39": {"line.1": {"text": "Ein Denkmaal im Wahnsinn! \u2013 Andenken,", "tokens": ["Ein", "Denk\u00b7maal", "im", "Wahn\u00b7sinn", "!", "\u2013", "An\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$(", "NN", "$,"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Erinnerung, wie sie sich geh\u00f6ren.", "tokens": ["E\u00b7rin\u00b7ne\u00b7rung", ",", "wie", "sie", "sich", "ge\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.40": {"line.1": {"text": "Denn mein lieber S\u00fcsser ist all meine Lust.", "tokens": ["Denn", "mein", "lie\u00b7ber", "S\u00fcs\u00b7ser", "ist", "all", "mei\u00b7ne", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "PIAT", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "LaERT.", "tokens": ["LaERT", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.41": {"line.1": {"text": "Andenken, Gram und Jammer, die H\u00f6lle selbst", "tokens": ["An\u00b7den\u00b7ken", ",", "Gram", "und", "Jam\u00b7mer", ",", "die", "H\u00f6l\u00b7le", "selbst"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "ART", "NN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Macht sie zu Lieb' und Anmuth \u2013", "tokens": ["Macht", "sie", "zu", "Lieb'", "und", "An\u00b7muth", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NN", "KON", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.42": {"line.1": {"text": "OpHEL.", "tokens": ["Op\u00b7HEL", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.43": {"line.1": {"text": "Und wird er denn nicht wieder kommen?", "tokens": ["Und", "wird", "er", "denn", "nicht", "wie\u00b7der", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wird er denn nicht wieder kommen?", "tokens": ["Und", "wird", "er", "denn", "nicht", "wie\u00b7der", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nein! nein! er ist todt!", "tokens": ["Nein", "!", "nein", "!", "er", "ist", "todt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PTKANT", "$.", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Geh auch ins Todesbett,", "tokens": ["Geh", "auch", "ins", "To\u00b7des\u00b7bett", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Er wird nicht kommen! Er kann nicht kommen!", "tokens": ["Er", "wird", "nicht", "kom\u00b7men", "!", "Er", "kann", "nicht", "kom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVINF", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.44": {"line.1": {"text": "Schneewei\u00df, Silber war sein Bart,", "tokens": ["Schnee\u00b7wei\u00df", ",", "Sil\u00b7ber", "war", "sein", "Bart", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fl\u00e4chsenzart sein Scheitel war.", "tokens": ["Fl\u00e4ch\u00b7senz\u00b7art", "sein", "Schei\u00b7tel", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Er ist hin, Er ist hin!", "tokens": ["Er", "ist", "hin", ",", "Er", "ist", "hin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Werfen wir's Seufzen hin,", "tokens": ["Wer\u00b7fen", "wir's", "Seuf\u00b7zen", "hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Hab er die seel'ge Ruh.", "tokens": ["Hab", "er", "die", "seel'\u00b7ge", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Und alle Christenseelen. Gott mit euch \u2013", "tokens": ["Und", "al\u00b7le", "Chris\u00b7ten\u00b7see\u00b7len", ".", "Gott", "mit", "euch", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$.", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}