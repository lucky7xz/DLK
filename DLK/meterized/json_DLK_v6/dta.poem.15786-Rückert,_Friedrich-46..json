{"dta.poem.15786": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "46.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1839", "urn": "urn:nbn:de:kobv:b4-200905195122", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die Sprache wirst du bald unter- bald \u00fcbersch\u00e4tzen,", "tokens": ["Die", "Spra\u00b7che", "wirst", "du", "bald", "un\u00b7ter", "bald", "\u00fc\u00b7bersc\u00b7h\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "TRUNC", "ADV", "VVINF", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Jenach du willst in sie und aus ihr \u00fcbersetzen.", "tokens": ["Je\u00b7nach", "du", "willst", "in", "sie", "und", "aus", "ihr", "\u00fc\u00b7bers\u00b7et\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "APPR", "PPER", "KON", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Denn jede hat in sich etwas Un\u00fcbersetzbars,", "tokens": ["Denn", "je\u00b7de", "hat", "in", "sich", "et\u00b7was", "Un\u00b7\u00fc\u00b7ber\u00b7setz\u00b7bars", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "APPR", "PRF", "PIAT", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das dann bei dem Versuch dir scheinet ein Unsch\u00e4tzbars.", "tokens": ["Das", "dann", "bei", "dem", "Ver\u00b7such", "dir", "schei\u00b7net", "ein", "Un\u00b7sch\u00e4tz\u00b7bars", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ART", "NN", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "Und wie dein Geist sich mit der Uebertragung qu\u00e4lt,", "tokens": ["Und", "wie", "dein", "Geist", "sich", "mit", "der", "Ue\u00b7ber\u00b7tra\u00b7gung", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Scheint seine Sprach' ihm arm, weil grade das ihr fehlt.", "tokens": ["Scheint", "sei\u00b7ne", "Sprach'", "ihm", "arm", ",", "weil", "gra\u00b7de", "das", "ihr", "fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "ADJD", "$,", "KOUS", "ADV", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch \u00fcbersetz' aus ihr, so findest du sie reich;", "tokens": ["Doch", "\u00fc\u00b7ber\u00b7setz'", "aus", "ihr", ",", "so", "fin\u00b7dest", "du", "sie", "reich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "$,", "ADV", "VVFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So findest du zuletzt die zwei ungleichsten gleich;", "tokens": ["So", "fin\u00b7dest", "du", "zu\u00b7letzt", "die", "zwei", "un\u00b7gleichs\u00b7ten", "gleich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "CARD", "ADJA", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Verschiednen Blumen gleich, in ihrer Art vollkommen,", "tokens": ["Ver\u00b7schied\u00b7nen", "Blu\u00b7men", "gleich", ",", "in", "ih\u00b7rer", "Art", "voll\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "$,", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df nichts hinzugethan kann seyn noch weggenommen.", "tokens": ["Da\u00df", "nichts", "hin\u00b7zu\u00b7ge\u00b7than", "kann", "seyn", "noch", "weg\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "VMFIN", "PPOSAT", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Es w\u00e4re doch, beim Lenz! ein seltsames Ergetzen,", "tokens": ["Es", "w\u00e4\u00b7re", "doch", ",", "beim", "Lenz", "!", "ein", "selt\u00b7sa\u00b7mes", "Er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "APPRART", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-++-+--", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Rosen in Mohn und Mohn in Rosen \u00fcbersetzen.", "tokens": ["Ro\u00b7sen", "in", "Mohn", "und", "Mohn", "in", "Ro\u00b7sen", "\u00fc\u00b7bers\u00b7et\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.7": {"line.1": {"text": "In fremder Sprache sieht befremdlich Alles aus,", "tokens": ["In", "frem\u00b7der", "Spra\u00b7che", "sieht", "be\u00b7fremd\u00b7lich", "Al\u00b7les", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ADJD", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie alles ungewohnt im unbekannten Haus.", "tokens": ["Wie", "al\u00b7les", "un\u00b7ge\u00b7wohnt", "im", "un\u00b7be\u00b7kann\u00b7ten", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Doch willst du dir daselbst gefallen als ein Gast,", "tokens": ["Doch", "willst", "du", "dir", "da\u00b7selbst", "ge\u00b7fal\u00b7len", "als", "ein", "Gast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "PAV", "VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mu\u00dft du vergessen da\u00df zu Haus du's anders hast.", "tokens": ["Mu\u00dft", "du", "ver\u00b7ges\u00b7sen", "da\u00df", "zu", "Haus", "du's", "an\u00b7ders", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "KOUS", "APPR", "NN", "NE", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Dann von dem fremden Schmuck, soviel dir mag behagen,", "tokens": ["Dann", "von", "dem", "frem\u00b7den", "Schmuck", ",", "so\u00b7viel", "dir", "mag", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Magst du in deinem Sinn mit dir nach Hause tragen,", "tokens": ["Magst", "du", "in", "dei\u00b7nem", "Sinn", "mit", "dir", "nach", "Hau\u00b7se", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPOSAT", "NN", "APPR", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Und dort anbringen, was du dir hast eingepr\u00e4gt,", "tokens": ["Und", "dort", "an\u00b7brin\u00b7gen", ",", "was", "du", "dir", "hast", "ein\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "$,", "PWS", "PPER", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soweit es sich mit Hausbequemlichkeit vertr\u00e4gt.", "tokens": ["So\u00b7weit", "es", "sich", "mit", "Haus\u00b7be\u00b7quem\u00b7lich\u00b7keit", "ver\u00b7tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Dazu n\u00fctzt der Verkehr der Sprachen und Gedanken,", "tokens": ["Da\u00b7zu", "n\u00fctzt", "der", "Ver\u00b7kehr", "der", "Spra\u00b7chen", "und", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Da\u00df man erweitert, wenn schon auf nicht hebt, die Schranken.", "tokens": ["Da\u00df", "man", "er\u00b7wei\u00b7tert", ",", "wenn", "schon", "auf", "nicht", "hebt", ",", "die", "Schran\u00b7ken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVPP", "$,", "KOUS", "ADV", "APPR", "PTKNEG", "VVFIN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Beschr\u00e4nktheit nur ist arm, Beschr\u00e4nkung aber reich;", "tokens": ["Be\u00b7schr\u00e4nk\u00b7theit", "nur", "ist", "arm", ",", "Be\u00b7schr\u00e4n\u00b7kung", "a\u00b7ber", "reich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "ADJD", "$,", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer etwas seyn will, kann nicht alles seyn zugleich.", "tokens": ["Wer", "et\u00b7was", "seyn", "will", ",", "kann", "nicht", "al\u00b7les", "seyn", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VAINF", "VMFIN", "$,", "VMFIN", "PTKNEG", "PIS", "PPOSAT", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}