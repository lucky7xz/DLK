{"textgrid.poem.42481": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Maria Theresia, die deutsche Frau,", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Maria Theresia, die deutsche Frau,", "tokens": ["Ma\u00b7ria", "The\u00b7re\u00b7sia", ",", "die", "deut\u00b7sche", "Frau", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die gro\u00dfe Kaiserin, nimmt es genau", "tokens": ["Die", "gro\u00b7\u00dfe", "Kai\u00b7se\u00b7rin", ",", "nimmt", "es", "ge\u00b7nau"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "ADJD"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit ihrer katholischen Religion;", "tokens": ["Mit", "ih\u00b7rer", "ka\u00b7tho\u00b7li\u00b7schen", "Re\u00b7li\u00b7gi\u00b7on", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "F\u00fcr die andern Bekenntnisse hat sie den Fron.", "tokens": ["F\u00fcr", "die", "an\u00b7dern", "Be\u00b7kennt\u00b7nis\u00b7se", "hat", "sie", "den", "Fron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Sie verfolgt die Evangelischen, wo sie kann,", "tokens": ["Sie", "ver\u00b7folgt", "die", "E\u00b7van\u00b7ge\u00b7li\u00b7schen", ",", "wo", "sie", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Doch d\u00fcrfen sie nach Siebenb\u00fcrgen ziehn;", "tokens": ["Doch", "d\u00fcr\u00b7fen", "sie", "nach", "Sie\u00b7ben\u00b7b\u00fcr\u00b7gen", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Dorthin tut sie sie in den Bann,", "tokens": ["Dor\u00b7thin", "tut", "sie", "sie", "in", "den", "Bann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Dorthin darf ihr Glaube mit ihnen fliehn.", "tokens": ["Dor\u00b7thin", "darf", "ihr", "Glau\u00b7be", "mit", "ih\u00b7nen", "fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "In Linz liegen drei Schiffe bereit;", "tokens": ["In", "Linz", "lie\u00b7gen", "drei", "Schif\u00b7fe", "be\u00b7reit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "CARD", "NN", "ADJD", "$."], "meter": "-++--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auf Deck stehn, gedr\u00e4ngt, im Abschiedsleid,", "tokens": ["Auf", "Deck", "stehn", ",", "ge\u00b7dr\u00e4ngt", ",", "im", "Ab\u00b7schieds\u00b7leid", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,", "VVPP", "$,", "APPRART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Viele Familien Hand in Hand", "tokens": ["Vie\u00b7le", "Fa\u00b7mi\u00b7li\u00b7en", "Hand", "in", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "NN", "APPR", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Zur Abfahrt ins ferne Karpathenland.", "tokens": ["Zur", "Ab\u00b7fahrt", "ins", "fer\u00b7ne", "Kar\u00b7pa\u00b7then\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+--+--", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Sie schluchzen ihren Bergen den Scheidegru\u00df,", "tokens": ["Sie", "schluch\u00b7zen", "ih\u00b7ren", "Ber\u00b7gen", "den", "Schei\u00b7de\u00b7gru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Dann tr\u00e4gt die Donau f\u00fcr immer sie weg;", "tokens": ["Dann", "tr\u00e4gt", "die", "Do\u00b7nau", "f\u00fcr", "im\u00b7mer", "sie", "weg", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "APPR", "ADV", "PPER", "PTKVZ", "$."], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.7": {"text": "Sie setzen in die Ferne den Fu\u00df,", "tokens": ["Sie", "set\u00b7zen", "in", "die", "Fer\u00b7ne", "den", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Wo keiner von ihnen kennt Stein und Steg.", "tokens": ["Wo", "kei\u00b7ner", "von", "ih\u00b7nen", "kennt", "Stein", "und", "Steg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Noch sind die Taue nicht gel\u00f6st,", "tokens": ["Noch", "sind", "die", "Tau\u00b7e", "nicht", "ge\u00b7l\u00f6st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch harrt man des Rufs, der vom Lande st\u00f6\u00dft.", "tokens": ["Noch", "harrt", "man", "des", "Rufs", ",", "der", "vom", "Lan\u00b7de", "st\u00f6\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ein letztes Kommando, warum kommt es nicht?", "tokens": ["Ein", "letz\u00b7tes", "Kom\u00b7man\u00b7do", ",", "wa\u00b7rum", "kommt", "es", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ob in Wien es den R\u00e4ten an Mut gebricht?", "tokens": ["Ob", "in", "Wi\u00b7en", "es", "den", "R\u00e4\u00b7ten", "an", "Mut", "ge\u00b7bricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NE", "PPER", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "--+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bbein feste Burg ist unser Gott,\u00ab", "tokens": ["\u00bb", "ein", "fes\u00b7te", "Burg", "ist", "un\u00b7ser", "Gott", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das klingt auf einmal von allen her;", "tokens": ["Das", "klingt", "auf", "ein\u00b7mal", "von", "al\u00b7len", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADV", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Sie ertragen den Schmerz, sie ertragen den Spott,", "tokens": ["Sie", "er\u00b7tra\u00b7gen", "den", "Schmerz", ",", "sie", "er\u00b7tra\u00b7gen", "den", "Spott", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.8": {"text": "Ihr Glaube ist ihre einzige Wehr.", "tokens": ["Ihr", "Glau\u00b7be", "ist", "ih\u00b7re", "ein\u00b7zi\u00b7ge", "Wehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Pl\u00f6tzlich am Ufer Gedr\u00e4ng und Gewirr,", "tokens": ["Pl\u00f6tz\u00b7lich", "am", "U\u00b7fer", "Ge\u00b7dr\u00e4ng", "und", "Ge\u00b7wirr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "NN", "KON", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "W\u00fcster L\u00e4rm, Kreischen, Johlen, Geklirr:", "tokens": ["W\u00fcs\u00b7ter", "L\u00e4rm", ",", "Krei\u00b7schen", ",", "Joh\u00b7len", ",", "Ge\u00b7klirr", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NE", "$,", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Es eilen viele B\u00fcttel an Bord,", "tokens": ["Es", "ei\u00b7len", "vie\u00b7le", "B\u00fct\u00b7tel", "an", "Bord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und einer verk\u00fcndet mit rauhem Wort:", "tokens": ["Und", "ei\u00b7ner", "ver\u00b7k\u00fcn\u00b7det", "mit", "rau\u00b7hem", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "\u00bbwir haben Befehl: fahrt ab, fahrt zu,", "tokens": ["\u00bb", "wir", "ha\u00b7ben", "Be\u00b7fehl", ":", "fahrt", "ab", ",", "fahrt", "zu", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "NN", "$.", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Doch bleiben hier eure Kinder daf\u00fcr,", "tokens": ["Doch", "blei\u00b7ben", "hier", "eu\u00b7re", "Kin\u00b7der", "da\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "PAV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Da\u00df ihnen einst wird die himmlische Ruh,", "tokens": ["Da\u00df", "ih\u00b7nen", "einst", "wird", "die", "himm\u00b7li\u00b7sche", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Sonst sterben sie schutzlos am Ketzergeschw\u00fcr.\u00ab", "tokens": ["Sonst", "ster\u00b7ben", "sie", "schutz\u00b7los", "am", "Ket\u00b7zer\u00b7ge\u00b7schw\u00fcr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.5": {"line.1": {"text": "Die Leute sind erst wie vernichtet, erstarrt;", "tokens": ["Die", "Leu\u00b7te", "sind", "erst", "wie", "ver\u00b7nich\u00b7tet", ",", "er\u00b7starrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "KOKOM", "VVPP", "$,", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das war ein Befehl, wie keiner so hart.", "tokens": ["Das", "war", "ein", "Be\u00b7fehl", ",", "wie", "kei\u00b7ner", "so", "hart", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PWAV", "PIS", "ADV", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Unm\u00f6glich! \u00bbZ\u00f6gert nicht, fahrt ab!", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "!", "\u00bb", "Z\u00f6\u00b7gert", "nicht", ",", "fahrt", "ab", "!"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$.", "$(", "VVFIN", "PTKNEG", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Befehl mu\u00df bestehn! Es brach euch der Stab!\u00ab", "tokens": ["Der", "Be\u00b7fehl", "mu\u00df", "be\u00b7stehn", "!", "Es", "brach", "euch", "der", "Stab", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "$.", "$("], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Wir k\u00f6nnen doch ohne die Kinder nicht fort!", "tokens": ["Wir", "k\u00f6n\u00b7nen", "doch", "oh\u00b7ne", "die", "Kin\u00b7der", "nicht", "fort", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "\u00bbgut! \u00c4ndert den Glauben, und ihr bleibt zu Haus.\u00ab", "tokens": ["\u00bb", "gut", "!", "\u00c4n\u00b7dert", "den", "Glau\u00b7ben", ",", "und", "ihr", "bleibt", "zu", "Haus", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "VVFIN", "ART", "NN", "$,", "KON", "PPER", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Der Glaube ist unser einziger Hort.", "tokens": ["Der", "Glau\u00b7be", "ist", "un\u00b7ser", "ein\u00b7zi\u00b7ger", "Hort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "\u00bbso wandert ihr ohne Kinder aus.\u00ab", "tokens": ["\u00bb", "so", "wan\u00b7dert", "ihr", "oh\u00b7ne", "Kin\u00b7der", "aus", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Auf Erden gibt es kein schwerer Leid:", "tokens": ["Auf", "Er\u00b7den", "gibt", "es", "kein", "schwe\u00b7rer", "Leid", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "V\u00e4ter und M\u00fctter sind bereit,", "tokens": ["V\u00e4\u00b7ter", "und", "M\u00fct\u00b7ter", "sind", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie k\u00fcssen die Kinder zum letztenmal,", "tokens": ["Sie", "k\u00fcs\u00b7sen", "die", "Kin\u00b7der", "zum", "letz\u00b7ten\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und sinken zur\u00fcck in die marterndste Qual.", "tokens": ["Und", "sin\u00b7ken", "zu\u00b7r\u00fcck", "in", "die", "mar\u00b7ternds\u00b7te", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Eine Stimme: Sto\u00dft ab! Die Sonne verschied.", "tokens": ["Ei\u00b7ne", "Stim\u00b7me", ":", "Sto\u00dft", "ab", "!", "Die", "Son\u00b7ne", "ver\u00b7schied", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "In Gottes Namen soll es sein!", "tokens": ["In", "Got\u00b7tes", "Na\u00b7men", "soll", "es", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dann singen sie alle das Lutherlied,", "tokens": ["Dann", "sin\u00b7gen", "sie", "al\u00b7le", "das", "Lu\u00b7ther\u00b7lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Die Schiffe verschwinden im Abendschein:", "tokens": ["Die", "Schif\u00b7fe", "ver\u00b7schwin\u00b7den", "im", "A\u00b7bend\u00b7schein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "Nehmen sie den Leib,", "tokens": ["Neh\u00b7men", "sie", "den", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Gut, Ehr, Kind und Weib:", "tokens": ["Gut", ",", "Ehr", ",", "Kind", "und", "Weib", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "La\u00df fahren dahin!", "tokens": ["La\u00df", "fah\u00b7ren", "da\u00b7hin", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "PAV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Sie habens kein'n Gewinn,", "tokens": ["Sie", "ha\u00b7bens", "kein'n", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Reich mu\u00df uns doch bleiben.", "tokens": ["Das", "Reich", "mu\u00df", "uns", "doch", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}